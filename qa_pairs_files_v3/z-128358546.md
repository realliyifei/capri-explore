# A Survey on Practical Applications of Multi-Armed and Contextual Bandits

CorpusID: 128358546 - [https://www.semanticscholar.org/paper/b24e6b0539d6e27d82c60fa7c53a1d0905e41a19](https://www.semanticscholar.org/paper/b24e6b0539d6e27d82c60fa7c53a1d0905e41a19)

Fields: Mathematics, Business, Computer Science

## (s4) Dynamic Pricing
(p4.0) Online retailer companies are often faced with the dynamic pricing problem: the company must decide on real-time prices for each of its multiple products. The company can run price experiments (make frequent price changes) to learn about demand and maximize long-run profits. The authors in [Misra et al., 2018] propose a dynamic price experimentation policy, where the company has only incomplete demand information. For this general setting, authors derive a pricing algorithm that balances earning an immediate profit vs. learning for future profits. The approach combines multi-armed bandit with partial identification of consumer demand from economic theory. Similar to [Misra et al., 2018], authors in [Mueller et al., 2018] consider high-dimensional dynamic multi-product pricing with an evolving lowdimensional linear demand model. They show that the revenue maximization problem reduces to an online bandit convex optimization with side information given by the observed demands. The approach applies a bandit convex optimization algorithm in a projected low-dimensional space spanned by the latent product features, while simultaneously learning this span via online singular value decomposition of a carefully-crafted matrix containing the observed demands.
