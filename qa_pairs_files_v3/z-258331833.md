# Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond

CorpusID: 258331833 - [https://www.semanticscholar.org/paper/131c6f328c11706de2c43cd16e0b7c5d5e610b6a](https://www.semanticscholar.org/paper/131c6f328c11706de2c43cd16e0b7c5d5e610b6a)

Fields: Computer Science, Linguistics

## (s8) Finetuning data
(p8.0) When deploying a model for downstream tasks, it is essential to consider three primary scenarios based on the availability of annotated data: zero, few, and abundant. In this section, we provide a succinct overview of the appropriate models to employ for each scenario. Zero annotated data: In scenarios where annotated data is unavailable, utilizing LLMs in a zero-shot setting proves to be the most suitable approach. LLMs have been shown to outperform previous zero-shot methods [120]. Additionally, the absence of a parameter update process ensures that catastrophic forgetting [49] is avoided since the language model parameters remain unaltered.

(p8.1) Few annotated data: In this case, the few-shot examples are directly incorporated in the input prompt of LLMs, which is named as in-context learning, and these examples can effectively guide LLMs to generalize to the task. As reported in [16], one-shot and few-shot performance make significant gains, even matching the performance of the SOTA
