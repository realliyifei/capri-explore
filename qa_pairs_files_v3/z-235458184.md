# A Survey on Semi-Supervised Learning for Delayed Partially Labelled Data Streams

CorpusID: 235458184 - [https://www.semanticscholar.org/paper/ff0e0cbb8ff6da3c7077e1d6aad3adbf6d11315a](https://www.semanticscholar.org/paper/ff0e0cbb8ff6da3c7077e1d6aad3adbf6d11315a)

Fields: Computer Science

## (s8) METHODS
(p8.0) Supervised machine learning is defined by using labelled data to train algorithms to predict unseen and unlabelled instances. These unlabelled examples do not influence algorithm anyhow. In most applications, obtaining labelled data is time-consuming and expensive, as labelling often depends upon human annotators. On the other hand, acquiring unlabelled data is an easier task, but these data cannot update supervised models directly. Semi-supervised learning is a paradigm of learning that exploit unlabelled data to leverage models trained with labelled data.

(p8.1) The caveat is that semi-supervised learning methods make strong assumptions about the data or the model [86,103]. For example, one can assume a common underlying density across points belonging to a single class, or a common manifold underlying the points of each class. Figure 2 illustrates two such examples. Deciding which class to assign the test data point is relatively intuitive looking at all data points, but is not clear when considering labelled data points. This highlights precisely the advantages of using the unlabelled points.
## (s10) Self-training
(p10.0) Self-training figures as another commonly used technique for semi-supervised learning. The idea is to let a classifier learn from its previous mistakes and try to reinforce itself. Self-training acts as a wrapper algorithm that takes any arbitrary classifier. Therefore, if we have an existing, fullysupervised learner that is complicated and hard to modify, self-training is an approach worth considering. Self-training has seen its application in natural language processing tasks such as word sense disambiguation [98] and sentiment analysis [62].

(p10.1) In an offline scenario, self-training works as follows. Given a dataset S that consists of a set of labelled data and unlabelled data such that = ∪ , a classifier is trained on and after that used to predict the labels in . The predictions with a high confidence score are assumed true and added to as new labelled data. The process repeats until convergence. When implementing a self-training algorithm, we must ponder the following issues: (i) how to evaluate the confidence of a prediction, and (ii) what the threshold for a "high" confidence score is? These issues remain relevant in an online scenario. Additionally, the learner must be adapted to learn incrementally from labelled and unlabelled instances coming from the stream.
## (s14) FAIR COMPARATIVE ANALYSIS
(p14.0) Like other machine learning methods, SSL methods should be evaluated in a realistic process to verify their capabilities while considering other applicable methods. Van Engelen and Hoos [86] observed that additional factors have to be considered during evaluation compared to fully supervised learning scenarios.

(p14.1) First and foremost, the question arises of whether the use of a semi-supervised approach yields performance gains compared to supervised methods [71]. Furthermore, a comparison of an SSL method of interest with other SSL methods is required. Similarly to other machine learning methods, the selection of the data for which predictions are evaluated has to be followed by calculating performance measures. Interestingly, due to the latency of ground truth labels, multiple predictions made for a single instance at different times before the arrival of its true label may be considered in the evaluation [45]. The objective of this section is to address the unique aspects of the evaluation of semi-supervised stream mining methods while taking into account non-negligible delays in the availability of ground truth labels.
## (s21) Evaluation based on removing unlabelled instances.
(p21.0) Another way of comparing the performance of a fully supervised method with the performance of an SSL method is based on removing unlabelled instances. Unlike the former approach, under this scenario, the initial data stream has to be a partially labelled data stream Ψ, rather than fully labelled. The objective of the evaluation is to verify the merits of using unlabelled instances by comparing results attained on the partially labelled Ψ with the results provided by a fully supervised method on a fully labelled stream L (Ψ) i.e. the Ψ stream constrained to fully labelled instances. Indeed, the interest in semi-supervised learning is partly driven by the abundance of unlabelled data combined with scarce labelled data. In such cases removing unlabelled instances is acceptable rather than removing already scarce labels.

(p21.1) Among others, Oliver et al. [71] removed unlabelled instances to verify whether the performance obtained by training a model on ∪ (i.e. union of labelled data and unlabelled data) is better than the performance observed on labelled instances alone. Oliver et al. [71] observed that such a baseline is also frequently reported in other studies.
