# A SURVEY ON HUMAN ACTION RECOGNITION

CorpusID: 255942153 - [https://www.semanticscholar.org/paper/200a067b06bde6d5b684ed47edf17f9e67283539](https://www.semanticscholar.org/paper/200a067b06bde6d5b684ed47edf17f9e67283539)

Fields: Computer Science

## (s20) Egocentric Video Datasets
(p20.0) ADL. The ADL [106] dataset consists of 20 egocentric videos collected by 20 people. Action annotations and object annotations are provided, with a total of 18 action categories and 44 objects annotated.

(p20.1) GTEA Gaze+. The GTEA [40] dataset was performed by 4 different subjects, consisting of 7 long-term activities, 28 videos with a total of 11 action categories, captured using head mounted cameras.

(p20.2) Dogcentric. The Dogcentric [61] dataset, one of the most popular FPV datasets, consists of 209 videos (102 training videos and 107 test videos), with a variety of first-person actions divided into 10 action categories.

(p20.3) EGTEA Gaze+. EGTEA Gaze+ [84] is the largest and most comprehensive FPV action and gaze dataset. Specifically, it contains 86 unique phases of 28 hours cooking activities from 32 subjects, with 10,325 action annotations, 19 verbs, 51 nouns, and 106 unique actions. Moreover, the videos come with audio and gaze tracking, human annotations of actions and hand masks are provided simultaneously.

(p20.4) EpicKitchens-55/100. EpicKitchens-55 [26] was recorded by 32 participants in four cities using head mounted cameras in their native kitchen environments, with 55 hours of video totaling 39,594 action clips. Meanwhile, the action is defined as a combination of verbs and nouns for a total of 125 verb classes and 331 noun classes. EpicKitchens-100 [27]is an extension of Epickitchens-55, which contains 100 hours of 90k action clips, including 97 verb classes and 300 noun classes, recorded by 45 participants in their kitchens in 4 cities. 
