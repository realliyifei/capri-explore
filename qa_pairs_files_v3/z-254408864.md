# A Comprehensive Survey on Multi-hop Machine Reading Comprehension Approaches

CorpusID: 254408864 - [https://www.semanticscholar.org/paper/bad1ea60373fc77c1ff82c5ff99f1fd38c972ae8](https://www.semanticscholar.org/paper/bad1ea60373fc77c1ff82c5ff99f1fd38c972ae8)

Fields: Computer Science, Linguistics

## (s0) INTRODUCTION
(p0.0) Machine reading comprehension (MRC) is one of the most important and long-standing topics in the Natural Language Machine reading comprehension (MRC) is one of the most important and long-standing topics in Natural Language Processing (NLP). MRC provides a way to evaluate an NLP system's capability for natural language understanding. An MRC task, in brief, refers to the ability of a computer to read and understand natural language context and then find the answer to questions about that context. The emergence of large-scale single-document MRC datasets, such as SQuAD [1], CNN/Daily mail [2], has led to increased attention to this topic and different models have been proposed to address the MRC problem, such as (Chen, Bolton, and Manning, 2016) Adriana Trigiani is an Italian American best-selling author of sixteen books, television writer, film director, and entrepreneur based in Greenwich Village, New York City. (2) Based on Trigiani's 2000 best-selling novel of the same name, the story is set in the actual Virginia town of Big Stone Gap circa 1970s. The first attempt to improve the simple single-hop MRC task happened with emerging of some datasets like TriviaQA [15] and NarrativeQA [16]. These datasets addressed more challenges by introducing multiple passages per each question and also presenting a more complex kind of questions that couldn't be answered with one single sentence. Although this kind of question was more complex than single-hop questions, they still could be answered by a few nearby sentences within one passage, which means they mostly do not need multi-hop reasoning. They are generally known as the multi-passage or multi-document dataset that
## (s13) Commonsense Algorithm consists of Commonsense Selection Representation to select useful relational knowledge paths and
(p13.0) Commonsense Model Incorporation to fill the gaps of reasoning between hops of inference using Necessary and Optional Information Cell (NOIC).  [29] QFE: Nishida et al. [30] proposed a model for explainable multi-hop QA named Query Focused Extractor (QFE) which is based on a summarization idea. They use the multi-task learning of the QA model for answer selection and QFE for evidence extraction.

(p13.1) QFE as the main part of this model adaptively determines the number of evidence sentences by considering the dependency among the evidence sentences and the coverage of the question. Unlike other approaches that extract each evidence sentence separately, QFE uses an RNN and attention mechanism to consider important information in the question and the relationships between sentences. This query-aware recurrent structure enables QFE to consider the dependency among the evidence sentences and cover the important information in the question sentence. In brief, the main goal of QFE is to summarize the context according to the question. Query-focused summarization is the task of summarizing the source document with regard to the given query. The multitask learning with QFE is general in the sense that it can be combined with any QA model. The overview of QFE is shown in Figure 11. is the current summarization vector, is the query vector considering the current summarization, is the extracted sentence, updates the RNN state. Figure 11: Overview of Query Focused Extractor at step t [30] TAP: Bhargav et al. [31] proposed a deep neural architecture, called TAP (Translucent Answer Prediction) cover of two main ideas: (1) Local Interaction: Each sentence should be understood in the context of its neighboring sentences and the question, (2) Global Interaction: A global (inter-passage) interaction among sentences must be identified and used for supporting facts. TAP is a hierarchical architecture that tries to capture the local and global interactions between the sentences and consists of two main parts: (Figure 12)

(p13.2) • Local and Global Interaction eXtractor (LoGIX) with three layers: local layer to obtain intra-passage dependencies, Global Layer to obtain inter-passage dependencies, and Supporting Facts Prediction Layer to calculate the probability that a sentence is a supporting fact.
## (s15) •
(p15.0) The Answer Proposer (AP) module uses the constructed reasoning tree to predict an answer from every root-to-leaf path.

(p15.1) •

(p15.2) The Evidence Assembler (EA) module extracts a key sentence containing the proposed answer from every path and combines them to predict the final answer. Figure 14: Architecture of EPAr [33] PathNet: Kundu et al. [34] proposed a path-based reasoning approach for multi-hop MRC which first extracts all paths in the passages based on implicit relations between entities, and then composes the passage representations along each path to compute a passage-based representation. In other words, the passages representation is achieved by considering the paths.

(p15.3) They first find all possible path from passages. It starts with selecting a passage that contains a head entity from the question, and then finds all entities and noun phrases from the same sentence. Afterward, it selects the next passage that contains the potential intermediate entity identified above. Finally, it is checked whether the next passage contains any of the candidate answer choices or not. The resulting will be a set of entity sequences. After obtaining all potential paths, it is time to score each path using the PathNet model based on two perspectives: 1) Context-based Path Scoring, which is based on the interaction with the question encoding, and 2) Passage-based Path Scoring, which is based on the interaction between the passage-based path encoding vector and the candidate encoding. There is an example of the process in Figure 15 which In the Rank-1 path, the model composes the implicit located in relations between (Zoo lake, Johannesburg) and (Johannesburg, Gauteng). However, this method extracts many invalid paths, then causes wasting the computing resources [35].

(p15.4) Question: (zoo lake, located in the administrative territorial entity, ?) Answer: gauteng Rank-1 Path: (zoo lake, Johannesburg, gauteng) Passage1: ... Zoo Lake is a popular lake and public park in Johannesburg, South Africa.

(p15.5) It is part of the Hermann Eckstein Park and is ... Passage2: ... Johannesburg (also known as Jozi, Joburg and Egoli) is the largest city in South Africa and is one of the 50 largest urban areas in the world. It is the provincial capital of Gauteng, which is ...
## (s19) MHQA-GRN:
(p19.0) Song et al. [40] focused on inferring global context as an important key in multi-hop reading comprehension, while previous studies approximate global evidence with local coreference information with DAG-styled GRU. They proposed a model for better connecting global evidence, with a more complex graph compared to DAGs. They construct an entity graph with three types of edges: the edge between the same entity within a passage, the edges between two mentions of different entities within a context window, and coreference-typed edges. The graph might also have cycles which makes it difficult to apply a DAG network to it. (A graph with three types of edges and a DAG graph are shown in Figure 21).

(p19.1) For inferring the global context, the related information of the constructed graph has been merged. In this study, two recent graph neural networks have been applied to this graph: graph convolutional network (GCN) and graph recurrent network (GRN) for evidence aggregation. Afterward, an attention mechanism is applied in order to match the hidden states at each graph encoding step with the question representation. Finally, a probability distribution is calculated from the matching results. The architecture of this model is shown in Figure 22. However, this model still only implicitly combines knowledge from all passages, and are therefore unable to provide explicit reasoning paths [28]. DFGN: Xiao et al. [41] proposed a model to improve the interaction between the information of documents and the entity graph.

(p19.2) They proposed a fusion process of Doc2Graph and Graph2Doc for multi-hop reasoning that leads to a less noisy entity graph and more accurate answers. The process of constructing dynamic entity graph iterates in multiple rounds to achieve multi-hop reasoning. In each round, DFGN generates and reasons on a dynamic graph, where irrelevant entities are masked out while only reasoning sources are preserved, via a mask prediction module. Then the fusion block not only aggregates information from documents to the entity graph (doc2graph) but also propagate the information of the entity graph back to document representations (graph2doc). Figure 23 illustrates the Fusion block in DFGN which consists of:
## (s20) •
(p20.0) Passing information from tokens to entities by computing entity embeddings from tokens (Doc2Graph flow).

(p20.1) • Propagating information over the entity graph.

(p20.2) • Passing information from the entity graph to document tokens, as the final prediction is on tokens (Graph2Doc flow). However, this model still only implicitly combines knowledge from all passages, and are therefore unable to provide explicit reasoning paths [28]. BAG: Cao, Fang, and Tao [43] proposed a Bi-directional Attention Entity Graph Convolutional Network (BAG) with a focus on Relational Graph Convolutional Network (RGCN) to realize multi-hop reasoning by message propagating across different entity nodes in graphs and generating transformed representations of original ones. The R-GCN is employed to handle high-relational data characteristics and make use of different edge types. It uses graph neural networks to obtain the relationship between entities, or add a self-attention mechanism into the model, so as to obtain a gain in the result. They first construct an entity graph and apply graph convolutional networks to obtain a relation-aware representation of nodes. Then, the bidirectional attention mechanism is used to generate the representation of query-aware nodes. As it is shown in Figure 25, the model has five layers, Entity Graph Construction, Multi-level Features, GCN, Bi-directional Attention, and Output. However, as the number of inferences increases, the complexity of models will rise sharply due to the iteration of the message passing algorithm, resulting in low efficiency [35]. Figure 25: Architecture of BAG [43] CogQA: Ding et al. [44] to mimic the process of the human brain, proposed the CogQA framework that builds a cognitive graph inspired by dual-process theory. This theory approves that the human brain first retrieves relevant information implicitly and unconsciously, and finally an explicit and conscious reasoning process is applied to that relevant information. The cognitive graph structure in this framework can offer ordered and entity-level explainability and suits relational reasoning. Based on this theory, the proposed model has two components:

(p20.3) • Implicit Extraction (System 1) in which the relevant information, like question-relevant entities, and candidates answer, are extracted from paragraphs. Then, the extracted relevant entities are used to construct a cognitive graph.

(p20.4) Such a graph can be seen as working memory.

(p20.5) • Explicit Reasoning (System 2) in which the reasoning procedure is applied to the graph to guide System 1 to extract the next-hop entities. The main part of System 1 is BERT, and the main part of System 2 is GNN.
## (s22) HDE:
(p22.0) Tu et al. [46] proposed a more complex graph named Heterogeneous Document-Entity (HDE) graph with different types of nodes and edges. This graph can cover different granularity levels of information in context and also enables rich information interaction among different types of nodes for accurate reasoning. The nodes in the HDE graph are candidates, documents, and entities. Besides, it has seven types of edges: 1) between a document node and a candidate node that appears in the same document.

(p22.1) 2) between a document node and its entity node. 3) between a candidate node and its entity node. 4) between two entity nodes from the same document. 5) between two entity nodes from different documents but they are mentions of the same candidate or query subject. 6) All candidate nodes connect with each other. 7) Entity nodes that do not meet previous conditions are connected as well. Figure 30 is an example of an HDE graph. In this figure, green nodes indicate documents, yellow nodes denote candidates, and blue nodes stand for entities. In addition, dash lines indicate type 1 edges, dash-dotted lines denote type 2 edges, square dot lines indicate type 3 edges, the red line denotes type 4 edge, the purple line indicates type 5 edge, and black lines indicate type 6 edges. The type 7 edge is not shown in this figure. As Figure 31 shows This model can be categorized into three parts: initializing HDE graph nodes with co-attention and self-attention-based context encoding, and reasoning over HDE graph with GNN-based message passing algorithms and score accumulation from updated HDE graph nodes representations.

(p22.2) However, [35] have shown that if the number of inferences increases, the complexity of models will rise sharply due to the iteration of cumbersome message passing algorithm, resulting in low efficiency.  [46] SAE: Tu et al. [47] proposed an interpretable system named Select, Answer, and Explain (SAE) with multi-hop reasoning graphs based on GNN with contextual sentence embeddings as nodes. This kind of sentence graph makes lead to an interpretable model because it can directly output supporting sentences with the answer prediction. The edges capture the global information presented within each document and also the cross-document reasoning path. Also, the contextual sentence embedding used in GNN is summarized over token representations based on a novel mixed attentive pooling mechanism. The attention weight is calculated from both answer span logits and self-attention output on token representations. This attention-based interaction enables the exploitation of complementary information between "answer" and "explain" tasks. The SAE system first filters unrelated documents, and selects gold documents using a document classifier trained with a novel pairwise learning-to-rank loss function.

(p22.3) The gold documents are then fed into a model to predict the answer and supporting sentences. The model is a multi-task learning process which means while the answer prediction is accomplished at the token level, the support sentence is predicted as a node classification task at the sentence level. As it is shown in Figure 32, the selection module consists of:

(p22.4) •

(p22.5) The Multi-Head Self-Attention (MHSA) layer to capture interaction among documents
## (s28) Models Performance:
(p28.0) In this section we will show the performance of the models. This investigation is helpful in several ways; it will determine the stat-of-the-result, and also shows which models and techniques has achieved the best result. On the other hand, it can show the overall performance and effectiveness of each technique in multi-hop MRC To evaluate the results of the models we need to use the evaluation metrics of the datasets. HotpotQA [11] and Wikihop [55], are two populare datasets among the reviewed studies as it has been clear in Figure 46 in which shows the percentage of use of two datasets among the reviewed models from 2018 to 2022. Then they provide a proper situation for evaluating the model's performance. 
