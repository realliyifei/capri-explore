# 第 ** 卷 第 * 期 中文信息学报 Overview of the CCKS 2019 Knowledge Graph Evaluation Track: Entity, Rela- tion, Event and QA

CorpusID: 212633633
 
tags: #Computer_Science

URL: [https://www.semanticscholar.org/paper/81374b14e36bd993f20d92b9fca0a822c47e382a](https://www.semanticscholar.org/paper/81374b14e36bd993f20d92b9fca0a822c47e382a)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | False |
| By Annotator      | (Not Annotated) |

---

第 ** 卷 第 * 期 中文信息学报 Overview of the CCKS 2019 Knowledge Graph Evaluation Track: Entity, Rela- tion, Event and QA


Vol 
，no 
，201 
Xianpei Han 
Institute of Software
Chinese Information Processing Laboratory
Chinese Academy of Sciences
100190BeijingChina

Zhichun Wang 
School of Artificial Intelligence
Beijing Normal University
100875BeijingChina

Jiangtao Zhang 
The 305 Hospital of Peo-ple's Liberation Army
100017BeijingChina

Department of Computer Science and Technology
Tsinghua University
100084, China; 5. Yidu Cloud100000Bei-jing, BeijingChina

Qinghua Wen 
Department of Computer Science and Technology
Tsinghua University
100084, China; 5. Yidu Cloud100000Bei-jing, BeijingChina

Wenqi Li 
Buzhou Tang 
Harbin Institute of Technology
China; 7. Baidu518055, 100193Shenzhen, BeijingGuangdongChina

Qi Wang 
Zhifan Feng 
Yang Zhang 
Yajuan Lu 
Haitao Wang 
School of Computer Science & Technology
Soochow University
China; 9. Gowild215006, 215002Suzhou, SuzhouJiangsu, JiangsuChina

Wenliang Chen 
School of Computer Science & Technology
Soochow University
China; 9. Gowild215006, 215002Suzhou, SuzhouJiangsu, JiangsuChina

Hao Shao 
Yubo Chen 
Institute of Au-tomation, Chinese Academy of Sciences
11. School of Artificial Intelligence
13. School of Computer Science and Engineering
National Laboratory of Pattern Recognition
University of Chinese Academy of Sciences
12. Ant Financial100190, 100049, 310000Beijing, Beijing, HangzhouZhejiangChina;, China;, China

Southeast University
211189NanjingJiangsuChina

Kang Liu 
Institute of Au-tomation, Chinese Academy of Sciences
11. School of Artificial Intelligence
13. School of Computer Science and Engineering
National Laboratory of Pattern Recognition
University of Chinese Academy of Sciences
12. Ant Financial100190, 100049, 310000Beijing, Beijing, HangzhouZhejiangChina;, China;, China

Southeast University
211189NanjingJiangsuChina

Jun Zhao 
Institute of Au-tomation, Chinese Academy of Sciences
11. School of Artificial Intelligence
13. School of Computer Science and Engineering
National Laboratory of Pattern Recognition
University of Chinese Academy of Sciences
12. Ant Financial100190, 100049, 310000Beijing, Beijing, HangzhouZhejiangChina;, China;, China

Southeast University
211189NanjingJiangsuChina

Taifeng Wang 
Kezun Zhang 
Meng Wang 
Key Laboratory of Computer Network and Information Integration
Southeast University
211189NanjingJiangsuChina

Yinlin Jiang 
Guilin Qi 
Key Laboratory of Computer Network and Information Integration
Southeast University
211189NanjingJiangsuChina

Lei Zou 
Peking University
100871BeijingChina

Sen Hu 
Peking University
100871BeijingChina

Minhao Zhang 
Peking University
100871BeijingChina

Yinnian Lin 
Peking University
100871BeijingChina


JOURNAL OF CHINESE INFORMATION PROCESSING


第 ** 卷 第 * 期 中文信息学报 Overview of the CCKS 2019 Knowledge Graph Evaluation Track: Entity, Rela- tion, Event and QA

Knowledge graph models world knowledge as concepts, entities, and the relationships between them, 2 中文信息学报 第**卷 which has been widely used in many real-world tasks. CCKS 2019 held an evaluation track with 6 tasks and attracted more than 1,600 teams. In this paper we give an overview of the knowledge graph evaluation tract at CCKS 2019.By reviewing the task definition, successful methods, useful resources, good strategies and research challenges associated with each task in CCKS 2019, this paper can provide a helpful reference for developing knowledge graph applications and conducting future knowledge graph researches.
 [2] 
。它不仅是 NLP 相关任务如信息检索、 信息抽取以及问答系统等的重要基础工作 [3] ，同 时对诸多实际临床应用如合并症分析、综合症监 测、不良药物事件检测以及药物相互作用的分析 等具有巨大促进作用 [4] 。 国际上先后出现了一些围绕电子病历命名实 体识别的公开评测及标注数据集， 主要有 i2b2 [5] ， ShARe CLEF eHealth [6] 以及 SemEval [7] ，但这些评 测大多面向英文电子病历。为了更好的促进中文 电子病历相关研究的发展，填补国内面向中文电 子病历命名实体识别评测竞赛及标注数据集的空 白，清华大学知识工程实验室联合医渡云北京科 技有限公司、哈尔滨工业大学(深圳)组织了这 次评测任务。 任务定义 本任务是全国知识图谱与语义计 算大会(CCKS)围绕中文电子病历语义化开展的 系列评测的一个延续，包括两个子任务：

(1) 医疗命名实体识别： CCKS 2017 [8] ， 2018 [1] 评测任务的延续， 对 2018 年度数据集做了标注修 订。形式化定义如下： 输入： 1.电子病历的自然语言文本集合： = { % , ⋯ ( }, + = 〈 +% , ⋯ +. 〉 2.预定义类别： = { % , ⋯ 2 } 输出： 实 体 提 及 和 所 属 类 别 对 的 集 合 ： {〈 % , 2 4 〉, 〈 5 , 2 6 〉, ⋯ 〈 7 , 2   (2)数据集:   [14] 目前，有监督的关系抽取方法 [15,16,17,18] 
数据集的统计信息如表 2 和表 3 所示。 评 估 方 法 子 任 务 1 采 用 传 统 的 精 确 率 (Precision) 、 召回率 (Recall) 以及 F1-Measure 作为评测指标。 参赛系统的输出结果集合记为 = { % , 5 … 2 }，人工标注的结果(Gold Standard) 集合记为 = { % , 5 … . }。集合元素为一个实体 提及， 表示为四元组〈 , S , T , 〉， 表示文档， S 和 T 分别对应实体提及在文档 中的起止 下标， 表示实体提及所属预定义类别。遵循国际 惯例，分别从两个层面进行评价。 严格指标 我们定义 + ∈ 与 C ∈ 严格等价，标注数据集由训练集、 验证集、 评测集组成。 其中训练集中包括 9 万条短文本标注数据，验证 集包括 1 万条短文本数据，评测集包含 3 万条短 文本数据， 所有数据通过人工众包方式标注生成。 标注数据集主要来自于真实的互联网网页标 题数据，是用户检索 Query 对应的有展现及点击 的网页，短文本平均长度为 21.73 中文字符，覆 盖了不同领域(如人物、 电影、 电视、 小说、 软件、 组织机构、事件等垂类)的实体以及通用概念。 (3)评估方法： 我们以 F1 分值作为评价指标， 对于给定的中 文短文本，实体链指策略输出的结果中包含给定 中文短文本中出现的所有命名实体的链指结果。 我们通过将输出结果与人工标准集合进行比较来 计算准确率(Precision)，召回率(Recall)和 F1 分值(F1 score)。 具体计算过程如下所示： 给 定 短 文 本 输 入 ( 用 Text 表 示 ， 其 属 于 golden 标注集) ， 此 Text 中有 N 个实体 mention： . = { % , 5 , j … . } ， 每个实体 mention 链接 到知识库的实体 id 为： . = { % , 5 , j … . } ，实 体 标 注 系 统 输 出 标 注 结 果 如 下 ： ′ . = { ′ % , ′ 5 , ′ j … ′ . } ，则实体标注的准确率定义如 下： P = ∑ | . ∩ ′ . | .+ CRF 的实体识别方法； (b)在 ERNIE [11] /BERT [12] 等 语言模型进行微调(fine-tune) + CRF 的实体识 别方法。 图 1 基于序列标注的实体识别 方法二：基于双指针标注的实体识别方法 如图 2 所示，主要采用双指针标注的方式， 通过建模并标注实体的开始位置和终止位置。 图 2 基于双指针标注的实体识别 (2)实体消歧： 方法一：基于多分类的实体消歧方法： 如图 3 所示，将输入短文本和待消歧实体的 描述文本分别输入到 ERNIE/BERT，将输入短文本 CLS (Special Classification Embedding，用 于分类的向量，会聚集所有的分类信息，一般是 整体序列的向量表示)位置输出向量和实体文本 CLS 位置的输出向量连接到一起得到实体的向量 表示，经过 Dropout 层和全连接层，最后进行 … ERNIE/BERT CRF … BiLSTM CRF O B I O B I … other features word embedding char embedding … (a) (b) O B I O B I … … ERNIE/BERT BiLSTM Sigmod 0 1 0 0 0 0 … 1 0 0 0 0 0 Softmax 多分类。 图 3 基于多分类的实体消歧模型 方法二：基于二分类的实体消歧方法： 如图 4 所示，将输入短文本和待消歧实体的 描述文本拼接，输入到 BERT，将 CLS 位置输出向 量以及候选实体对应开始和结束位置对应的特征 向量连接到一起，经过全连接层，最后 Sigmoid 激活得到候选实体的概率得分。 图 4 基于二分类的实体消歧模型 方法三：基于排序的实体消歧方法: 如图 5 所示，使用语义匹配的思路，计算待 消歧文本(输入文本)和知识库中候选实体间的 相似度，通过神经网络对它们分别建模并得到各 自的向量表示，然后通过相似度度量方法进行匹 配度打分，选择得分最高的候选实体输出。 图 5 基于排序的实体消歧模型 2. 4 评测性能及结果分析 如表 7 所示，表 7 展示了本次评测 Top10 团 队的相关信息和得分情况，其中 Top7 团队的 F1 值都达到了 0.79 以上，Top5 团队均在模型中引 入 BERT、ERNIE 等预训练语言模型并取得了良好 的效果，同时 Top10 队伍中亦有多个团队通过各 种形式引入知识来提升整体模型的效果，如基于 知识图谱的实体嵌入(entity embedding)和实体 mention 嵌入(mention embedding)等，知识增强 对模型效果的提示发挥着非常关键的作用。 同时，我们也发现，模型融合仍是提升算法 效果的重要手段，Top5 团队都采用了模型融合来 提升整体效果。 表 7 Top10 团队信息及得分 排名 队伍名 参赛单位 F1 值 1 Free 东北大学 0.中文信息学报 第 2*卷 互进行整体建模，可能是进一步提升效果的新思 路。 随着预训练语言模型(BERT、ERNIE 等)的快 速发展，一些基于预训练语言模型的零样本学习 的实体链指方案 [13] 也被提出，而其本身也是充分 利用知识来解决样本问题和跨领域的泛化问题。 分析与研究表明，实体链指任务面临着开放 域、行业场景、少样本学习等带来的新挑战，结 合相应的问题场景，探索更多更好的知识增强技 术，运用神经网络的强大学习建模能力进一步提 升实体链指技术效果可能是未来研究的主要方向。 3 任务三：人物关系抽取 3. 1 任务介绍 作为 CCKS2019 的一项评测任务，人物关系 抽取的目标是，从给定的句子中识别出指定人物 实体对的关系。根据评价方式的不同，本次评测 任务又分为两个子任务： Sent-Track 和 Bag-Track。 在 Sent-Track 中，关系预测是在句子级别上进行 的。而在 Bag-Track 中，关系预测是在包级别上 进行的，所有包含相同实体的句子组成一个包。 在本次评测任务中， 一共有 358 支队伍报名参加， 其中 147 支队伍提交了有效成绩。 人物关系抽取是一个非常有潜力的研究方向。 一方面，关系抽取作为信息抽取的一个重要子任 务，是智能问答、信息检索等许多智能应用的重 要基础，和知识图谱的构建有着密切的联系；另 一方面，人作为社会的重要组成单位，研究人与 人之间的关系是十分必要和有价值的。被广 泛使用，并且表现出了非常好的性能。但是，有 监督的方法往往需要大量的标注数据用于训练， 人工标注训练数据是十分耗时费力的。为了解决 这个问题，Mintz 等人 [19] 提出了远程监督的概念。 他们认为，如果两个实体< s , t >在知识库中具 有关系 ， 那么所有包含这两个实体的句子都会在 某种程度上表达他们的这种关系。通过远程监督 的方法，我们可以通过对齐知识库和文本，自动 地构建大量标注数据。 然而，通过远程监督方法生成的数据不可避 免地存在错误标注的问题，特别是测试数据的错 误会导致在比较模型性能时出现错误评估的问题。 为了解决这个问题，我们可以让标注人员对测试 数据进行标注。本次评测任务中，我们使用一个 专 门 用 于 人 物 关 系 抽 取 的 中 文 数 据 集 (Inter- Personal Relationship Extraction , IPRE) [20] 。在这个数 据集中，验证集和测试集是经过人工标注的，训 练集是远程监督自动生成的。 3. 2 数据集及评估方法 本次评测任务的文本数据主要来自于互联网 网页文本，通过远程监督自动标注和人工标注相 结 合 的 方 法 生 成 标 注 数 据 。 由 于 目 前 没 有 像 Freebase 这样的中文知识库提供足够多的人物关 系三元组用于文本对齐，我们需要从维基风格的 网页上抽取三元组。通过实体的类别、名字长度 等多种方式对网页中的所有实体进行过滤，最后 我们构建了一个包含 942,344 个人物实体的人名 表。根据人名表，我们进一步挑选网页信息框 (infobox)中三元组，这些三元组中的实体都在 人名表中出现。我们对三元组中出现的关系表达 进行合并和去噪， 并定义了一组包含 34 种人物关 系的集合。最后，我们将这些三元组对齐文本， 得到了超过 41,000 个句子和 4,214 个包。 表 8 IPRE 中数据的划分与标注 数据集 比例 包 远程监督 人工标注 训练集 70% 2948 Ö ´ 验证集 10% 416 Ö Ö 测试集 30% 850 Ö Ö 如表 8 所示， 在得到远程监督生成的数据后， 我们将其按 7:1:2 的比例切分成训练集、验证集 和测试集。其中，验证集和测试集是经过人工标 注的。为了模拟真实的关系抽取场景，我们对各 个部分的数据集引入了大量自动构建的 NA 数据。 NA 关系是一种特殊的关系，表示实体对不存在 指定的人物关系表中的关系。因此，验证集和训 练集中的 NA 数据除了少部分来源于人工标注， 大部分是来源于后期数据构建时引入的自动构建 数据。 在 Sent-Track 和 Bag-Track 两个子任务中， 我们都使用 % 值作为评价指标。 在计算 % 值时， 我 们不考虑 NA。具体来说，如果一个句子或包被预 测有多个关系，那么它是否预测有 NA 关系不会 影响 % 值的计算。记 WwW 是系统预测结果中所有 句子或包的非 NA 关系数量， Wtx 是标准答案中 非 NA 关系的数量， g 是预测正确的关系数量， 则 Sent-Track 和 Bag-Track 的评价指标可定义为： = g WwW , = g Wtx , % = 2 在本次评测中，Sent-Track 和 Bag-Track 都有 一个公开成绩排行榜(A 榜)和非公开成绩排行 榜(B 榜) 。所有的测试数据一开始就全部发布， 测试数据按 1:1 的比例切分成了两部分。对于参 赛队伍提交的每份预测结果，我们在其中固定的 50%测试集数据和全部测试集数据上计算 F1 值， 分别记为 A 分和 B 分。在比赛期间，我们只根据 A 分显示 A 榜，而对应的 B 分进行排名得到 B 榜。B 榜在比赛结束后公布，作为各个参赛队伍 的最终成绩。 表 9 Sent-Track 和 Bag-Track 前十名成绩 Sent-Track Bag-Track 排名 队伍 A 分 B 分 排名 队伍 A 分 B 分 1 格物致知 0.

## 3 典型模型与系统

自从 BERT [12] 发布后， 它很快超过 ELMo [21] [22] 和 GloVe [23] 
， 成为目前 NLP 领域最火的一个语言模型， 在许多 NLP 任务中表现出了非常好的性能。和传统的训 练 词 向 量 的 方 法 不 同 ， 例 如 Skip-Gram物性别预测的开源工具 5 已经取得了不错的效果， 姓氏也可以用于血亲关系尤其是父子关系的预测 上来。此外，也可以通过一些句子中的关键词对 关系的预测结果进行纠正，如"夫" 、 "妻"等。 考虑到数据分布的不平衡性，一些队伍如 NEU_DM1 队删除了近一半的关系，以减少这部 分数据对整体预测结果的影响，他们的实验结果 也证明这种思路是有效的。此外，为了扩充训练 语料，RE 小分队队使用翻译工具 6 对训练数据进 行翻译，再将翻译的结果再翻译回中文从而扩充 训练数据。针对数据不平衡的问题，格物致知队 则使用下采样和上采样相结合的方法数据进行预 处理，从而在一定程度上缓解了这个问题。 3. 4 评测性能及结果分析 在表 9 中，我们给出了 Sent-Track 和 Bag- Track 前十名的成绩。值得注意的是，因为我们的 排名策略，最后排名有一些变化。
正如前面提到的那样， 预测结果中是否有 NA 关系不会影响 % 值的计算，并且评测数据中各关 系的分类也是不平衡的。这就导致，如果一个关 系抽取系统对其中几个大类的预测有非常好的性 能时，在整体数据上的性能也同样会很好。在测 试集数据中， "现夫" 、 "现妻" 、 "生父" 、 "生母" 、 "儿子" 、 "恋人" 、 "老师"这七种关系占据了大 多数。 在 Sent-Track 中， 2300 个标准答案中有 2000 个属于这七类；在 Bag-Track 中，740 个标准答案  
PDF 文件的信息定位和提取。 PDF 类型的文件 是按字符和位置存储的，缺少其内容的结构化信 息，段落和表格之间没有明显、清晰的边界。该 特性增大了对其信息自动抽取的难度，同时也提 高了对性能的要求。因此，如何准确地保留 PDF 文档中的显式的结构化信息，如段落、表格等， 并减少噪声是解决该问题的重点和难点； 表格信息提取。 与传统的文档信息抽取不同， 表格的前后文本内容中也包含了相关的信息，要 深入挖掘表格的信息， 需要结合其上下文的内容， 进行综合分析。 信息的不确定性。并非每个公告都会包含所 有有关数据，如部分人事变动仅有离职者而没有 继任者，模型在尽可能提取相关信息的同时，还 需要考虑特定键值是否缺失的情况。 任务组织 本次测评由东南大学认知智能研究所组织， 时间安排如下： • 评测任务发布：4 月 1 日 • 报名时间：4 月 1 日 -4 月 20 日 • 训练及验证数据发布：4 月 20 日 • 评测文件提交：7 月 20 日 • 评测时间：7 月 25 日 • 评测论文提交：8 月 15 日 本次评测依托 bien-data 平台展开，评测网 站 链 接 为 ： https://biendata.com/competi- tion/ccks_2019_5/。 本次测评训练数据为公开发 布的公众公司定期报告文件。组织者将提供训练 数据集和验证集(包括公告 PDF 原文和对应的结 构化数据)，供参赛选手训练算法模型和参与验 证排名。评测数据为训练数据集和验证集同一类 型公告，为防止作弊和人工介入，评测数据将包 含非公开发布的年报和公告 PDF 文件 (人为制造) ， 评测数据不提前进行发布。参赛者须提供可调用 的 API，组织者将基于评测数据在指定评测时间 统一调用 API 来给出最终分数。 评测过程中，组织者对参赛者的 API 调用处 理时间和结果返回时间设置上限，若一条评测数 据未能在限定时间内返回结果，该评测数据及对 应的信息点将按抽取失败计入评价指标计算中。 参赛情况 本次测评共有 98 支队伍， 共 318 名参赛者参 加。 其中企业参赛队、 研究机构参赛队分别有 xx、 xx 支。 经过测评， 提交有效结果的队伍有 xx 支， 其中有 6 支队伍提交了测评论文。 5. 2 数据集及评估方法 数据描述 本次测评训练数据为公开发布的公众公司定 期报告文件。组织者将提供训练数据集和验证集 (包括公告 PDF 原文和对应的结构化数据)，供 参赛选手训练算法模型和参与验证排名。评测数 据为训练数据集和验证集同一类型公告，为防止 作弊和人工介入，评测数据将包含非公开发布的 年报和公告 PDF 文件(人为制造)，同时，评测 数据不提前进行发布。参赛者须提供可调用的 API， 组织者将基于评测数据在指定评测时间统一 调用 API 来给出最终分数。 评价指标 两 个 子 任 务 的 评 价 均 采 用 传 统 的 正 确 率 (Precision)、召回率(Recall)和 F1 值作为 评价指标。将文本集合记为 T={t1, t2 ,
## 8 〉}
8其中 + = 〈 + , + , + 〉是出现在文档d + 中的医疗 实体提及(mention) ， + 和 + 分别表示 + 在 + 中的起止位置， 2 < ∈ 表示所属的预定义类别。要求 实体提及之间不重叠，即 + < +?% 。 预定义类别：P = { % , 5 ⋯ 2 } 输出: 预 定 义 类 别 的 答 案 实 体 集 合 ： {〈 + , B C , ⟨ % , 5 , ⋯ F ⟩H〉},1 ≤ ≤ , 1 ≤ ≤ 其中 F 为 + 中出现的属于 C 答案实体(字符 串，无需位置信息) ，每个类别可包含 0 或多个实 体。 组织安排 本任务由清华大学知识工程实验 室统筹组织，创建了专门的评测交流讨论组： CCKS2019-clinic@googlegroups.com。时间安排 如下：本任务预定义类别包括： 疾病和诊断、 检查、 

检验、手术、药物、解剖部位六大类。 

(2)医疗实体及属性抽取(跨院迁移) ：在 
医疗实体识别的基础上，对预定义实体属性进行 
抽取。该子任务为迁移学习任务，即在只提供目 
标场景少量标注数据的情况下，通过其他场景的 
标注数据及非标注数据进行目标场景的识别任务。 
形式化定义如下： 
输入： 

1. 电 子 病 历 的 自 然 语 言 文 本 集合： = 
{ % , d 5 ⋯ ( }, 
+ = 〈 +% , +5 ⋯ +. 〉 
2. l 评测任务发布： 4 月 1 日 
l 报名时间：4 月 1 日-7 月 10 日 
l 训练数据发布(第一批)：5 月 6 日 
l 训练数据发布(第二批)：6 月 2 日 
l 测试样例数据发布：7 月 20 日 
l 测试数据发布及测试结果提交：7 月 30 日 
l 评测论文提交：8 月 15 日 
评测结果在 biendata 网站 
1 上进行在线提交， 

采用实时打榜的方式进行。最终由任务组织者综 
合考虑网站得分、结果可复现性(要求参赛队提 
交代码及文档) 、方法模型及外部资源(词典、非 
本评测提供的标注数据等)等因素给出最终成绩 
排名。 
参赛情况 本次评测共吸引了来自院校科研 
机构、工业界及医疗机构的 200 多支队伍参赛。 
参赛情况如表 1 所示。 
表 1 参赛情况 
任务 报名数 
结果提交 
代码提交 论文 
1 
226 
44 
10 
7 
2 
152 
6 
6 
4 

1. 2 数据集及评估方法 
数据集描述 两个子任务的数据集均由医渡云 (北 
京)技术有限公司提供，并组织专业的医学团队 
进行人工标注，仅限 CCKS 竞赛评测用 
2 。 




，BERT 可以提供更丰富、语义更强的上 下文表示。在这次评测任务中，在 BERT 输出后 简单地添加一个全连接层进行分类或者用 BERT 的代替词向量作为输入的两种主流方法都取得了 非常好的成绩。考虑到 BERT 可能会过拟合实体 的名称，LEKG 队在使用 BERT 时用两个固定的 名字"刘伟明" 、 "李静"替代了句子中的给定的人物实体对。 
由于 Sent-Track 和 Bag-Track 使用同样的数 
据集，并且包级别的关系抽取方法有更好的抗噪 
性，许多队伍将 Bag-track 的预测结果转换成了 
Sent-track 的预测结果。 任务转换的关键在于检查 
包中的句子是否表达了包的这种关系。训练一个 
二分类器或者使用特征模板匹配的方式都是非常 
好的选择。在本次评测任务中，NEU_DM1 队和 
格物致知队都使用了这种转换技巧，他们的实验 
结果表明这个方法是简单有效的。 
特征工程是提高关系抽取系统性能的一种简 
单有效的方法，需要对原数据进行仔细的分析。 
就人物关系而言，由于数据本身的特点，有一些 
特征如性别、姓氏，可以有效地利用进行人物关 
系的识别和预测。目前一些基于中文人名进行人 

5 https://pypi.org/project/ngender 




Track 和 Bag-Track 两个子任务中最好的系统的 F1 值分别达到了 54.3%和 63.0%。本次评测任务 所 使 用 的 数 据 集 及 其 标 准 答 案 可 以 在 https://github.com/SUDA-HLT/IPRE 下载。 输入："公司 A 涉嫌违规交易，其下属子公 司 B 和公司 C 遭到了调查"， "交易违规" 输出： "公司 A" 、"提现困难"、 "交易违规"等 21 个事件 类型， 如果事件不属于预定义的 21 个事件类型则 标注为"其它"类型。训练集、A 榜阶段测试集 和 B 榜阶段测试集中的样本分布如表 10 所示， 各 数据集中不同事件类型的样本分布如表 11 所示。 在表 10 和表 11 中 Train 代表训练集、Eval 代表 A 榜测试集， Test 代表 B 榜测试集， Test_pure 代 表 B 榜测试集中去处噪音数据的样本数量统计。 表 10 不同数据集样本数量统计 队 伍 中 ， 采 用 最 多 的 序 列 标 注 模 型 为 典型的方法是基于 BERT 的阅读理解模型， 在该类 方法中首先在事件类型 (问题) 前面添加 special classification token[CLS]标记，然后问题和段 落连接在一起，中间使用 special tokens[SEP] 分开。序列通过 token Embedding、segment embedding 和 positional embedding 输入到 BERT。 最后， 通过全连接层和 softmax 函数将 BERT 的最 评测性能及结果分析 此次评测的 A 榜和 B 榜 TOP 20 结果如表 12 和 表 13 所 示 。 详 细 比 赛 结 果 参 见 ： https://www.biendata.com/competition/ccks_2019_4/中文信息学报 
第 2*卷 

中有 560 个属于这七类。 
我们分别分析了 Sent-Track 和 Bag-Track 前 
三名的结果，他们都在一定程度上放弃了对一些 
小类别关系的预测，而把重点放在一些大类关系 

的预测上。我们通过 % 值比较了每个系统在各关 
系上性能，所有的系统都在这七类关系中的大多 
数关系上取得了很好的效果。大致可以看出，这 
几类的关系的预测结果和整体的预测结果是正相 

图 6 Top-N 系统预测结果融合的上界 

关的。值得注意的是，这几个系统都在"恋人" 
关系的预测上表现得非常差。我们随机的采样了 
测试集中一些能体现"恋人"关系的句子，尽管 
这些句子中大都有"相恋" 、 "男友" 、 "女友"这 
些关键词，但系统更倾向于把它们预测为 NA。另 
外，前三名的系统更喜欢把 NA 预测为"生父" 。 
人工检查表明许多只能表达"父母-子女"关系的 
句子被错误地预测成了"生父" 。当然，测试集中 
引入的远程监督生成的 NA 数据中也产生了一定 
的影响。 
为了给以后的研究提供一个参考上界，我们 
融合了前十名队伍系统的预测结果。对于每个包 
或句子，只要其中一支队伍给出了正确答案，我 
们就认为是正确的。 如图 6 所示， 我们可以看出， 
随着融合的结果增加，F1 值的提升明显。令人惊 
讶的是 Sent-Track 的上界最后超过了 Bag-Track 
的上界。这可能是因为一个包往往有多个关系， 
相比于只有一个关系的句子预测，包预测的难度 
更大一些。 

3. 5 任务总结 
CCKS2019 人物关系抽评测由 Sent-Track 和 
Bag-Track 两个子任务组成。 任务目标是识别所给 
句子中两个人物实体的关系。今年，来自不同单 
位组织的 358 支队伍参加了比赛。其中，Sent-
4 任务四：面向金融领域的事件主体抽取 

4. 1 任务介绍 
任务背景： 事件抽取是信息抽取的重要任务， 
也是知识图谱自动构建、文本语义理解、自动问 
答、舆情监控等多种自然语言处理任务的基础。 
事件知识、特别是事件的类型和主体知识，在金 
融领域中具有重要作用，能为风险预警、智能投 
顾等应用提供重要决策参考。在风险预警方面， 
风险事件的主体识别可以辅助事件热度、事件演 
化和事件影响的监控，从而进行相应的决策和响 
应。在智能投顾方面，事件是投资分析和资产管 
理的重要决策因子，事件主体的识别能辅助发现 
潜在客户，为智能推荐和投顾提供支持。 
任务定义：在此背景下，该评测任务旨在从 
互联网上真实存在的新闻数据中抽取特定类型事 
件的主体。即给定一段文本 T，和事件类型 S，从 
文本 T 中抽取事件类型为 S 的事件主体 E(如果 
事件主体为多个，输出事件主体 E 的集合) 。形式 
化表示如下： 
输入：一段文本 T 和事件类型 S 
输出：事件主体 E(E 的集合) 
示例： 

任务难点：事件抽取一直以来是信息抽取中 
的难点问题，面向金融领域的事件主体抽取同样 
面临着诸多难点和挑战：1.语言表达的多样性， 
金融领域事件主体的实体类型一般为公司、机构 
或者人物，然而，数据来源广泛、表述风格不一 
的文本中，事件主体经常会以别称、简称或者代 
称的形式出现，语言表达的多样性对事件主体的 
识别提出了挑战。2.多事件表达的干扰性，一段 
文本会经常提到多个事件，一个实体也会同时参 
与到多个事件中。因此，如何从同时含有多个事 
件的文本中精确的找到特定类型事件的主体是一 
个挑战。3.事件主体的共现性，在金融领域的文 
本中会经常涉及多个相同类型事件的比较和统一 
表述，因此在同一段文本中同一类型的事件主体 
会有多个的情况，如何同时精准的识别出同一类 
型事件的多个主体是该任务的又一挑战。 
任务的 组织及参赛情况： 该评测任务采用 
Biendata 在线评测平台，任务共分为 A 榜、B 榜 
两个阶段，A 榜测试阶段共持续 3 个月，A 榜阶段 
发布了训练集和测试集 A，每支队伍每天可以提 
交不超过 3 次的测试结果，在线测试平台可以实 
时更新队伍的最新排名。B 榜阶段共持续 4 天，B 
榜阶段发布了测试集 B，每支队伍每天可以提交 
不超过 3 次的测试结果，在线测试平台可以实时 
更新队伍的最新排名，最终排名以 B 榜阶段测试 
成绩和提交报告说明为准。该次比赛共计吸引了 
1169 名参赛者，487 支参赛队伍，包括：清华大 
学、北京大学、上海交通大学、复旦大学、浙江 
大学、哈尔滨工业大学、北京航空航天大学、北 
京邮电大学、哥伦比亚大学、曼彻斯特大学、香 
港理工大学、悉尼大学、芝加哥大学、香港城市 
大学等高校；中国科学院计算技术研究所、中国 
科学院软件技术研究所、中国科学院上海高等研 
究院、中国航空综合技术研究所、中国运载火箭 
技术研究院等科研机构；微众银行、平安科技、 
民生科技、腾讯、百度、谷歌创新工场、美团、 
字节跳动、京东、微软、IBM、国泰君安、网易等 
互联网和金融企业，具体参赛人员单位比例如图 
7 所示。 

图 7 参赛人员单位统计 
4. 2 数据集及评估方法 
数据集来源：该评测数据集的文本内容来自 
于互联网上金融领域的相关新闻语料。数据爬取 
后首先进行数据清洗和数据过滤，主要是去掉无 
效的字符和内容。 
数据集构建方法：该评测数据由专业的标注 
人员从文本段中标注出事件类型和对应的事件主 
体(同一段文本中若出现多个事件类型和多个事 
件主体分别标注成<单一事件类型,多个事件主体> 
的组合) 。 标注数据经过多个标注人员的标注和投 
票，最后进行抽样校验。 
数据统计：该评测数据集中共定义了"业绩 
下滑" 数据名称 
样本数量 

Train(训练集) 
17815 

Eval(A 榜测试) 
3500 

Test(B 榜测试) 
135519 

Test_pure(B 榜测试) 
6988 

评估方法： 本次任务采用精确率 (Precision, 
P) 、召回率(Recall, R) 、F1 值(F1-measure, 
F1)来评估事件主体的识别效果。 
事件主体精确率=识别事件主体与标注相同/ 
识别事件主体总数量 
事件主体召回率=识别事件主体与标注相同/ 
标注事件主体总数量 
事件主体 F1 值=(2*事件主体精确率*事件主 
体召回率)/(事件主体精确率+事件主体召回率) 
4. 3 典型模型与系统 
中文信息学报 
第 2*卷 

本次评测中参赛队伍将面向金融领域的事件 
主体抽取任务建模成序列标注和阅读理解两种任 
务，最终排名靠前的队伍会在上述两种建模任务 
基础上利用模型集成， 提升系统的鲁棒性和性能。 
下面分别介绍基于序列标注的方法和基于阅读理 
解的方法，然后再简要介绍模型集成的方法。 

表 11 各数据集中不同事件类型的样本数量统计 

基于序列标注的方法：在该类方法中，参赛 
选手将面向金融领域的事件主体抽取任务建模成 
序列标注任务。输入为待抽取文本和事件类型， 
该类方法针对输入文本中的每个字进行标注，判 
断其是否为符合条件的事件主体，一般采用 BIO 
的标注模式。在进行序列标注时，有两种建模事 
件类型的方法，一种是将 22(含其他类)个事件 
类别进行向量化表示，然后将其拼接到字向量后 
作为序列标注的输入；另一种是将事件类型的描 
述文本直接和输入文本进行拼接，然后直接输入 
到序列标注模型中，不进行额外特殊处理。在参 
赛 的 BiLSTM+CRF 
[24] 和 Bert 
[12] 模型。 

基于阅读理解的方法：在该类方法中，参赛 
选手将面向金融领域的事件主体抽取任务建模成 

阅读理解任务。将输入文本看作阅读理解任务中 
的文档， 将事件类型看作阅读理解任务中的问题。 
终隐藏状态转换为答案跨度的概率。 
基于模型集成的方法：基于阅读理解的方法 
和基于序列标注的方法各有优势，基于序列标注 
的方法能充分捕捉多个事件主体之间的依存关系， 
基于阅读理解的方法能更好的挖掘文本和事件类 
型的语义关系。在单一模型中，不同的模型参数 
或模型设置也会得到不同的性能，为了充分利用 
多模型的优势，增加系统的鲁棒性，很多参赛队 
伍都采用了模型集成的方法， 主要分为两类方法， 
一类是基于阅读理解的模型和基于序列标注模型 
的融合，一类是不同参数的单一模型融合。在此 
次比赛中，模型融合的方法多采用结果融合的方 
法，即取多个模型结果的并集。 
4. 4 表 12 A 榜 TOP 20 队伍成绩 
排名 
队伍名 
F1 值 

1 
我是谁我从哪里来我要去哪里 
0.93917 
2 
DOTA 
0.93819 
3 
L 
0.93464 
4 
哪吒 
0.93335 
5 
西南交大一枝花儿 
0.93027 
6 
BasinSpace 
0.92925 
7 
糯米糍 
0.92864 
8 
Axxx 
0.92833 
9 
xiayang321 
0.92809 
10 
炸鱼薯条 
0.92648 
11 
MSKJ 站上 KG 星球之巅 
0.9262 
12 
c_c 
0.92599 
13 
落霞与孤鹜齐飞 
0.92597 
14 
秋水共长天一色 
0.92587 
15 
GDUFSER 
0.92584 
16 
蓝光剑侠天晴晚 
0.9258 
17 
bdy 
0.92514 
18 
zc1 
0.92479 
19 
hihishenxian 
0.92445 
20 
Dragon 
0.92363 

通过对上述 A 榜和 B 榜的分析，我们发现： 
(1)在单一模型中，基于阅读理解的方法性能普 
遍比基于序列标注方法的性能高，造成这种现象 
的原因可能是该次比赛中一个事件对应多个主体 

事件类型 
Train Eval 
Test Test_pure 

业绩下滑 
686 
148 
0 
0 

提现困难 
56 
10 
6520 
570 

失联跑路 
43 
9 
4470 
342 

资产负面 
116 
25 
1434 
203 

交易违规 
1732 
330 
0 
0 

产品违规 
62 
12 
1098 
107 

歇业停业 
34 
3 
7066 
331 

不能履职 
1326 
247 
0 
0 

涉嫌传销 
500 
104 
8254 
2033 

公司股市异常 
2 
0 
6 
6 

其他 
3141 
598 
0 
0 

涉嫌违法 
616 
134 
32775 
412 

财务造假 
592 
113 
0 
0 

涉嫌非法集资 
1644 
333 
9665 
1608 

资金账户风险 
312 
60 
0 
0 

重组失败 
1045 
238 
0 
0 

投诉维权 
96 
18 
38854 
159 

高管负面 
215 
39 
1280 
306 

信批违规 
2513 
497 
0 
0 

评级调整 
861 
155 
0 
0 

实控人股东变更 
1827 
345 
0 
0 

涉嫌欺诈 
396 
81 
23754 
911 
的样本少于一个事件对应一个主体的样本。 
(2)基于模型集成的方法更鲁棒，基于模型集成 
的方法在 B 榜上性能的降幅小于基于单一模型的 
方法的性能降幅。 
表 13 B 榜 TOP 20 队伍成绩 
排名 
队伍名 
F1 值 

1 
糯米糍 
0.83902 
2 
GDUFSER 
0.83784 
3 
L 
0.83784 
4 
hihishenxian 
0.83572 
5 
DOTA 
0.83503 
6 
JJ 
0.83445 
7 
konroy 
0.83248 
8 
NLPxiaoxu 
0.8319 
9 
justin 
0.83146 
10 
国士无双 
0.83129 
11 
Brad 
0.83129 
12 
我不会武功 
0.83083 
13 
哪吒 
0.83062 
14 
牛杂 
0.82993 
15 
炸鱼薯条 
0.82991 
16 
我是谁我从哪里来我要去哪里 
0.82902 
17 
MSKJ 站上 KG 星球之巅 
0.82816 
18 
zc1 
0.82809 
19 
yaohua 
0.82769 
20 
便利贴 
0.8264 

4. 5 任务总结 
事件知识在金融领域有着不可或缺的地位， 
面向金融领域的事件主体发现是一个富有挑战的 
任务，该任务可以建模成序列标注任务，也可以 
建模成阅读理解任务，大规模预训练语言模型的 
引入会使相关方法进一步提升性能。在该任务建 
模过程中要重点考虑事件类型的编码方式以及事 
件类型和表述文本之间的语义关系。除了事件主 
体以外，事件发生的时间、涉及的金额和产品对 
于金融风控和智能投顾也有借鉴意义，未来可以 
尝试将该任务进一步扩展，抽取出事件主体以外 
的更多事件知识。 

5 任务五：公众公司公告信息抽取 

5. 1 任务介绍 
随着金融科技的发展和全球资本市场的不断 
扩大， 在金融领域， 每一天都有海量的数据产生， 
而与之形成强烈对比的是有限的人力以及人脑所 
能处理信息的极限能力。因此，依靠传统的人工 
方式已经无法应对投研分析、风险控制、金融监 
管和事件关联等需求，而亟需引入新的技术来提 
高信息处理效率，包括大数据分析、自然语言处 
理、知识图谱等技术，都已经开始被积极用于金 

融分析和金融监管领域。在监管方面，每一家公 
众公司都具有相关信息披露义务，由此也产生了 
大量的公告阅读和信息抽取需求。 据不完全统计， 
以沪深股市为例， 2017 年共披露公告 44 万余篇， 
2018 年共 27 万余篇，并且随着上市公司数量的 
增加这一数字也在逐年增加。每年 3 月底、4 月 
底、8 月底、10 月底为定期报告披露高峰期，最 
多的一天所发布公告达 10297 篇。 
本次评测的主要目标是针对公告文件(均以 
PDF 方式发布)中的信息抽取。作为知识图谱构 
建的基础，结构化数据是必不可少的。由此，如 
何通过自动化的技术来从各类公告中抽取信息， 
将非结构化数据转化为结构化数据是知识图谱领 
域所面临的一大挑战。 
任务定义 
本评测包含有两个子任务： 
(1)表格中的信息点提取：本任务给定某公 
众公司的年报 PDF 文件，参赛者需从文件的结构 
化财务报表(包括合并资产负债表、母公司资产 
负债表、合并利润表、合并现金流量表和母公司 
现金流量表等)中提取相关的信息点，并输出该 
表格对应的结构化数据。 
(2)文本段落中的信息点提取：本任务要求 
参赛者从公告中提取相关的重要信息点，采用的 
数据皆为"人事变动"类型的公告，其中可能包 
含有离职高管、继任者等人物的相关信息，参赛 
者需要从公告中提取出相关的信息点，并输出对 
应的结构化数据。 
两个任务的类型相似，其统一形式化定义可 
以被表示为： 
输入： 
1. 公众公司的年报文档集合/公众公司的人 
事变动公告文档集合： 
T = {t1, t2 , t3, …, tn} 
2. 预先定义的信息点类别： 
K = {k1, k2 , k3, …, kn} 
输出： 
对于每个文档，输出其包含的所有信息点类 
别对应的信息。 
Output = {(t1, kv1), (t2, kv2), (t3, 
kv3), …, (tn1, kvn1)}，其中 kvi = {(k1, v1) , 
(k2, v2), (k3, v3), …, (kn2, vn2)} 
任务难点 
本任务为公众公司公告信息提取，两个任务 
均需要先从结构化的数据中定位有效信息段落， 
再将关键信息进行提取并结构化。其主要难点在 
于： 
中文信息学报 
第 2*卷 




识库管理系统对数据进行存储和查询，我们也提供 了在线的 PKUBASE 查询终端，供选手通过浏览器 或者 API 进行在线访问。详情可见 http://pkubase.gstore-pku.com/ 数据生成 本次测评任务构建了专门的中文自然语言问答 数据集。数据集问题与答案生成过程大致分为如下 几步：第一步，人工确定自然语言问题模板。我们 认为，利用 PKUBASE 这样 RDF 格式的开放知识库生 成问题及其答案， 首先要将自然语言问题与 SPARQL 查询关联起来。因此，我们首先确定了几种典型的 SPARQL 查询图的模板，利用这些查询图的模板，补 全对应的实体与谓词信息，再进一步生成自然语言 问题。这一步是由在自然语言问答与开放知识库领 域具有专业知识的人员来完成。我们用到的问题模 板包括单跳型、双跳型、三跳型以及星型。我们将 其中的"单跳问题"模板称为简单问题模板，而其 余的均为复杂问题模板。需要注意的是，虽然我们 利用 SPARQL 查询作为生成问题的中间状态， 我们并 不强制要求参赛队伍再开发系统时将问题转化成 SPARQL 查询，再得到答案。 第二步，人工利用问题模板生成中文自然语言 问题。 这个过程就是将模板转化为具体的 SPARQL 查 询， 再转化成自然语言问题。 我们邀请了共计 22 位 来自北京大学的工作人员，他们均为中文母语者， 具有较高的中文语言水平， 并且对 RDF 和 SPARQL 查 询有所了解与研究，因此可以保证得到的问题的质 量。我们要求每位工作人员需要编写 100 道自然 语言问题，并且给出对应的答案。其中，简单问题 与复杂问题的比例为 1:1，五种不同模板的比例为 5:2:1:1:1。 在这一过程中，我们建议工作人员首先根据模 板，从 PKUBASE 中任意搜索实体，根据实体周围的 谓词补全模板，同时设置中间变量与查询变量，并 且只能设置一个查询变量。以简单问题为例，工作 人首先查询所有与"<湖上草>"这一实体相连的实 体及其谓词，并发现存在"<柳如是_(明末"秦淮八 艳"之一)> <主要作品> <湖上草>"这一三元组， 满足简单问题的模板。这时，三元组中的主语"<柳 如是_(明末"秦淮八艳"之一)>"可以被视为查询 变量，进而得到如下的 SPARQL 查询： select ?x where { ?x <主要作品> <湖上草>. } 然后， 工作人员将 SPARQL 查询改写为自然语言 问题，例如上述 SPARQL 可以改写成" 《湖上草》是 谁的诗歌？" ， 也可以改写成 "谁写了 《湖上草》 ？" 。 我们要求工作人员在改写过程中，对同样的模板尽 量使用不同的句式，并且加入指代、歧义等自然语 言现象，以保证数据集的质量和复杂程度。最后， 问题的答案直接使用对应的 SPARQL 查询得到的结 果来充当。 评价方法 本 任 务 的 评 价 指 标 包 括 宏 观 准 确 率 (Macro Precision)， 宏观召回率(Macro Recall)， Averaged F1 值。最终排名以 Averaged F1 值为基准。设 为 问题集合， + 为选手对第 个问题给出的答案集合, 为第 个问题的标准答案集合，相关计算公式如下： 所示。此类模型的第一步 是通过 NER 等方法获得问句中实体的 mention，再 通过主办方提供的数据库中 mention2ent 及其他信 息链接 mention 到数据库中对应实体列表，通过多 种设计的打分函数最终选取一个或多个与问句最相 关的实体作为核心实体，用于之后生成关系、查询 语句等。在 NER 模型方面，有的队伍使用了在线训 练好的模型[29] ，也有队伍使用 BERT-BiLSTM-CRF 并 微调以提高其在此任务中的表现[30] ；在实体打分函 基于路径匹配的模型 模型的流程图如图 9 所示。 与上一类模型类似， 此类模型同样具有识别中心实体、 问题类型的模块。 不同的是，本方法并不直接选取最优关系，而是直 接获取所有能匹配上问题类型模板的，在中心实体 周边的查询路径；之后，通过各类基于问句与查询 路径特征来给后者打分，并选取最优查询路径的模 型，最终答案便可以求得。 一般而言，即便利用各类启发性剪枝，通过上 述流程产生的候选查询路径是众多的，尤其当问题 为多跳、查询路径较长时，因此，优化查询路径的 打分方式对于此类系统是至关重要的。在本次比赛 中，表现较为突出的模型包括 BERT 语义匹配模型[30] 、Pairwise LambdaRank[31] 等。 图 9 基于路径匹配的模型 除此之外，完全基于规则的传统系统也出现在 本次比赛中， 部分队伍亦使用 Ensemble 融合多个系 统结果以试图达到单个系统无法企及的性能，各类 不同的系统各有优劣，启发我们进一步探索。 6. 4 评测性能及结果分析 6.4.1、最终结果 经过数月代码提交与测评验证，jchl 队最终名 列第一，下表 16 为本次比赛最终排列前 10 名的队 伍。 句子中出现的文本与知识库中 的谓词有时候差距较大；同一 个谓词 mention 也可能对应许 多个谓词。需要利用上下文信 息综合确定。 《国王的演讲》有多 少分钟？(知识库内 谓词为"片长")查 询 路 径 形式错误 当自然语言问题涉及复杂逻辑 推断，例如三跳问题，系统表 现急剧下降。大多数系统没有 考虑长查询路径的信息。 和 尼 采 来 自 同 一 国 家 的 哲 学 家 都 有 哪 些 ？ ( 问 题 共 有 三 跳) 非 问 句 形 式 有时祈使句也能当作自然语言 问题，需要特别处理。 告诉我刘翔的身高。 不 适 应 开 放领域 对于问题相对较少的领域，模 型识别、理解的准确率降低。 如 何 计 算 融 券 费 用？(融券费用实体 不常涉及)t3, …, 
tn}， 对于文本 ti， 记该文本中的信息点个数共 Gi， 
记模型提取出的信息点个数共 Ai，其中的正确信 
息点个数记为 Ni，相关计算公式如下： 

Precision = 

% 

|y| ∑ 

+ 

|y| 

+z% , + = 

|( < | 
|{ < | 

Recall = 

% 
|y| 

∑ 

+ 

|y| 
+z% 

, + = 

|( < | 

|\ < | 

F1 = 

% 

|y| ∑ 

5 * _ <  * `< 

< ?_ < 

|y| 
+z% 

5. 3 典型模型与系统 
本次评测的参赛者共提交 7 篇论文。 由于 PDF 
数据的特殊性，大部分队伍将解决该问题的方案 
分成了两个模块，即，先是从 PDF 中自动抽取相 
关的信息， 再对这些信息做进一步的分析与挖掘。 
通过对这两个模块分别进行训练和优化，模型得 
以输出更为准确的结构化数据。 分析这些论文后， 
我们将其采用的典型方法与模型总结如下： 
5.3.1 PDF 信息自动抽取模型 
解决 PDF 信息自动抽取主要有两种思路，概 
述如下。第一种是先将 PDF 文件转换为图片，再 
找到所需区域，并对其进行限定和提取。有队伍 
利用 BFS 算法对表格内内容进行定位和提取 
[25] ， 

并准确定位到表格提取的难点-跨页表格中信息 
的准确识别，通过构建页眉页脚识别模型，有效 
地解决了该任务难点； 也有队伍采用 OpenCV 接口 
和 Faster R-CNN 算法， 分别检测有线条和无线条 
的表格，同样获得了不错的效果 
[28] ； 

第二种方法基于工具将 PDF 文件转换为设定 
的格式以获取结构化信息。有队伍使用 Acrobat 
DC SDK，将 PDF 文档转换为 XML 文件，成功识别 
了大部分的文字和表格 
[27] ，但该方法会将部分表 

格错误地识别为图片，降低了模型的效果。 
5.3.2 混合模型 
任务二可被作为序列标注问题来进行建模， 
按照该思路，需要先解决命名实体识别问题。大 
部分队伍都采用了 BiLSTM-CRF 
[24] 的神经网络模 

型完成命名实体识别。 首先基于词向量进行字/词 
嵌入操作，再通过 BiLSTM 层提取文本特征，最后 
通过 CRF 层给每个单位打上标签。混合模型的效 
果相较于单个模型有显然的提高。 
5.3.3 预训练语言模型 
近来，基于大量无监督文本的深度神经网络 
预训练模型大幅地提升了各个 NLP 任务的模型效 

果。 在本评测任务中， 参赛者通过使用包括 BERT 

[12] 

在内的多种预训练模型，显著地提升了模型的效 
果。 其中， 在解决任务二时， 有队伍通过使用 BERT， 
基于上市公司公告进行了预训练，构建了针对证 
券公告领域的语料模型 caBERT 
[26] ，并针对"人事 

变动"类型公告进行了 fine-tune。通过使用 
BERT-CRF 和 caBERT，其模型的 F1 值比使用最常 
用的 BiLSTM-CRF 模型提高了 13.14%。最终，该 
模型达到 95.78%的 F1 值，在该单向任务中排名 
第一。 

表 14 子任务 1(年报抽取)评测结果 

排名 
参赛队名 
单位 
F1 平均值 
1 
美能华 
苏州美能华智能科技有限公司 
0.99750 
2 
DG 
达观数据 
0.97810 
3 
洞见时代 
洞见时代(北京)信息技术有限公司 
0.92477 
4 
guangluwutu 
中国地质大学(武汉)计算机学院 
0.89055 
5 
DataHammer 
北京理工大学 
0.88711 
6 
ChenXiuling 
平安科技 
0.82787 
7 
louis_xu 
新氦数据 
0.82423 
8 
NiHao 文本分析 
大连理工大学自然语言处理实验室 
0.74856 

表 15 子任务 2(人事公告抽取)评测结果 
排名 
参赛队名 
单位 
F1 平均值 
1 
SZSI 
深圳证券信息有限公司 
0.95779 
2 
美能华 
苏州美能华智能科技有限公司 
0.94118 
3 
DG 
达观数据 
0.93994 
4 
NiHao 文本分析 
大连理工大学自然语言处理实验室 
0.88800 
5 
DataHammer 
北京理工大学 
0.87272 
6 
louis_xu 
新氦数据 
0.86685 
7 
guangluwutu 
中国地质大学(武汉)计算机学院 
0.83445 
8 
洞见时代 
洞见时代(北京)信息技术有限公司 
0.74214 

5. 4 评测性能及结果分析 
最终评测结果的前八名如表 14、15 所示。通 
过对参赛队所提交的测试借口调用、结果验证、 
文档及评测论文的对比审核， 评测结果分析如下。 
1) 大部分参赛队伍的接口都出现调用超时的 
情况。经过逐一和参赛队伍校对，包括获取源代 
码进行本地测试，发现其中模型计算效率较差是 
造成很多测试样例信息点抽取失败的原因。如何 
快速的进行 PDF 文件解析以及抽取信息点，保证 
抽取速度，依然是较大的挑战。测试成绩较好的 
队伍，都不同程度对基于神经网络的模型进行了 
压缩和优化。 
2)两项任务的总冠军和任务二的单项冠军， 

都 针 对 不 同 领 域 在 句 法 和 文 法 上 的 差 异 基 于 
Bert 预训练生成领域词向量，将序列-触发词作 
为共同输入来触发对应元数据信息点的抽取，从 
而提高 PDF 文件信息点抽取的召回率和准确率。 
这一点具有一定的理论和实际应用价值。值得相 
关任务借鉴采纳。 
3)基于 OpenCV 和 Faster R-CNN 的表格信息 
抽取方法， 能够有效提高扫描件的线条检测精度， 
以及无线条表格的单元格识别准确度。在此基础 
上， 结合 "表格定位+表格结构识别+信息点抽取" 
的三步骤策略识别出来表格区域中的信息点，是 
提高表格信息点抽取模型效果的有效途径。 

5. 5 任务总结 
中文信息学报 
第 2*卷 

PDF 格式的文档因其优秀的展示效果，在多 
种场景下被广泛地采用，如：科学论文、官方文 
件、演示文稿等，显然地，该类文档中含有海量 
的高质量信息。然而因其侧重不同，该类文档中 
的数据并未被结构化存储，在过去，人们若要提 
取出 PDF 文档中的信息，一般只能通过人工方式 
手动进行提取。这种方法效率低下，且提取后的 
信息还需要重新编辑、排版。因此，如何准确高 
效地自动提取 PDF 文件中的信息，并将其结构化 
储存，是知识图谱领域中的一个重要课题。 
本评测希望通过将 PDF 信息抽取与下游任务 
相结合，为后续的相关任务打下基础。同时，在 
本次任务中，我们所采用的数据来自上市企业披 
露的相关文件。批量地提取并分析这类文件的信 
息，可以显著地提高相关领域从业人员的工作效 
率和工作质量。 
在本任务中，参赛者们采用了不同思路的方 
案解决了其中的难点，同时也使用了不同的模型 
建构思路提升了系统的效果。本次比赛促进了对 
PDF 中元数据抽取的相关领域研究，拓宽了学术 
界的视野。我们在后面的工作中，会继续分析垂 
直行业的具体需求，提出更有实用意义和研究价 
值的评测人物， 以促进知识图谱领域技术的进步。 

6 任务六：中文知识图谱问答 

6. 1 任务介绍 

任务定义 

本评测任务是，对于给定的一句中文问题，问 
答系统从给定知识库中选择若干实体或属性值作为 
该问题的答案。问题均为客观事实型，不包含主观 
因素。理解并回答问题的过程中可能需要进行实体 
识别、关系抽取等子任务。这些子任务的训练可以 
使用额外的资源，但是最终的答案必须来自给定的 
知识库，并且使用的额外资源必须明确说明来源。 
为了方便参赛队伍训练模型，我们专门为本次测评 
构建了专门的中文自然语言问答数据。参赛队伍可 
以自由选择是否使用提供的训练数据。 
为了保证比赛公平、公开、公正，参赛队伍的 
成绩将实时公布并排名，比赛截止后，参赛队伍必 
须提供最好结果的实现代码以及相关数据，供赛方 
进行复现。否则，将被取消最终资格。 

任务难点 

本任务为开放领域的自然语言问答， 宏观而言， 
这是一个从理解自然语言，再利用获取到的信息匹 

配知识库中数据的过程。其主要难点有： 
语义消歧，在自然语言中，词语的意思往往是 
多种多样的，要结合具体的上下文来确定词语的含 
义。并且有时就算结合了上下文信息，歧义也依旧 
存在。在中文中尤其如此。 
句法的模糊性。自然语言的文法通常是模棱两 
可的，针对一个句子通常可能会解析出多种依赖结 
构，而我们必须要仰赖语意及前后文的信息才能在 
其中选择一种最为适合的句法结构。 
问题逻辑的复杂性。当自然问题涉及复杂的逻 
辑推理和联系时，需要知识库中距离更远的信息。 

任务组织与参赛情况 

本次测评由北京大学计算机科学技术研究所与 
恒生电子股份有限公司共同组织，共有 165 个队伍 
参加。其中企业参赛队、研究机构参赛队分别有 33、 
74 至。经过测评，提交有效结果的队伍有 28 支， 
其中有 4 支队伍提交了测评论文。 

6. 2 数据集及评估方法 

数据来源 

本次测评任务使用北京大学开发的 PKUBASE 
作为指定的知识图谱。其被用于数据集的生成，并 
且选手最终给出的问题答案必须来自于该知识库。 
PKUBASE 采用当前应用最广泛的 RDF 结构，用户可 
以使用结构化的 SPARQL 语言对其进行查询。因此， 
在训练数据集中，也包括了人工给出的问题对应的 
SPARQL 查询。选手可以下载数据集后使用相应的知 
数据清洗与分割 

为了保证数据质量，我们对生成的 3847 组中文自 
然语言问答数据进行了数据整理与清洗。具体方法 
是，首先对所有 SPARQL 查询进行验证，将每一条查 
询提交给我们提供的在线查询终端，测试其是否能 
正常返回答案，以保证其格式正确，并且能够从 
PKUBASE 中得出准确的答案。然后，人工对 3847 
条自然语言问题进行审核，保证其符合中文语言规 
范和语言习惯。 
经过数据清洗后，我们总计得到了 3830 组符合要 
求的中文问答数据，并且其简单问题与复杂问题的 
比例仍旧保持在了 1:1 左右，五种模板的比例保 

持在 5:2:1:1:1 左右。随后，我们采用随机抽取的 
方法将 2083 组数据划分为训练集、验证集与测试 
集。其中，训练集包含 2298 组，验证集与测试集 
各 766 组，并且保证问题类别与问题模板的比例 
与前文提及的一致。 

Macro Precision = 

% 

|•| ∑ 

+ 

|•| 

+z% , + = 

{ < ∩\ < 
|{ < | 

Macro Recall = 

% 

|•| ∑ 

+ 

|•| 
+z% 

, + = 

{ < ∩\ < 
|\ < | 

Average F1 = 

% 
|•| 

∑ 

5_ <`< 

< ?_ < 

|•| 
+z% 

6. 3 典型模型与系统 
大多数取得较好表现的队伍将生成答案的系统 
分成多个功能模块，分别训练或优化每个模块并构 
建 pipeline 以完成最终的查询语句生成或答案选 
取。诸多功能模块中，最常被使用的包括核心实体 
识别、关系识别、问题类型识别、路径匹配与排序 
等，针对这些核心模块的优化方法成为了部分队伍 
能获得优异表现的主要原因。 
本次比赛，表现较好的几个系统可以大致分为 
两类，其一为通过实体识别、关系抽取获得答案， 
其二为通过实体识别、路径匹配选择答案，接下来 
将分别概述这二者。 

6.3.1 基于实体与关系识别的模型 
模型的流程图如图 8 数方面，简单到实体长度，复杂到实体与问句语义 
相关性(须通过模型训练)均被不同队伍使用。 
获得中心实体后，此类系统先得到该实体在数 
据库中的邻居子图，并抽取出邻居子图中所有的关 
系作为候选。对于这些关系，系统同样使用设计好 
的打分函数来评估每一者与问题的契合性，这些打 
分方式包括关系本身与问题语义相似性及对应询问 
路径中相关结点与问句的相似性等，使用到的模型 
中文信息学报 
第 2*卷 

也包括 BERT、BiLSTM [29] 等。 
同时，此类模型也大多采用一个问题类型识别 
模块以提高表现。数据集中的问题可以分为单跳问 
题与多跳问题，多跳问题在查询图结构上也有多种 
形式；通过训练，问题类型识别模型能够将问句分 
类到相应的查询图结构模板上。这些有了这些模板 
信息，便可以根据之前获得的关系取打分高的一个 
(如果问题类型为单跳) 或多个 (如果类型为多跳) 
作为结果，将其与中心实体对应的查询路径填入最 
终查询数据库得到答案。 

图 8 基于实体与关系识别的模型总体流程 

6.3.2 表 16 评测结果 
排名 
队伍名 
F1 得分 
1 
jchl 
0.73545 
2 
hlt217 
0.73075 
3 
网易互娱 AIlab-陈垚 
鑫 

0.72514 

4 
baseline 
0.70448 
5 
DUTIR 
0.67683 
6 
到此一游 
0.63510 
7 
qbuer 
0.60566 
8 
Duoduo 小分队 
0.54227 
9 
单身公寓队 
0.50658 

10 
我是一条鱼 
0.42345 

表 17 错误分类 

6.4.2 结果分析 
分析模型给出回答的错误原因往往是理解当前 
模型弱点的直接方式。 下表 17 总结出了我们发现的 
几种主要回答错误类别，同时给出了可能的错误原 
因及典型致错问题示例。 
可见，问句本身的复杂性仍然是导致错误的主 
要原因，自然语言的不确定性使得对实体、关系、 
类别的识别在很多问题上具有困难。对此，各参赛 
队使用多种模型提取上下文句义信息，结合多种基 
于规则的匹配方法综合判断，在处理问句复杂性的 
方面做出了值得借鉴的改进。 
相比往年比赛结果，本次比赛在得分上有着较 
大程度的提高，这得益于语言模型 BERT 
[12] 的提出及 

其预训练模型在诸多下游任务中的应用，相比起 
LSTM、TextCNN 等上一代模型，BERT 尤其在实体、 
关系、 问句类型识别上能达到更高的准确率。 可见， 
积极应用自然语言处理领域的新兴模型、技术是有 

错误类别 
可能错误原因 
示例 

实 体 识 别 
错误 

某些 mention 可能同时指代不 
同的实体，需要利用句子上下 
文信息进行消歧。 

《神话》是哪位导演 
的影片？( 《神话》可 
能是电视剧也可能是 
电影，需要靠下文信 
息来区分) 
谓 词 匹 配 
不准确 

利于进一步提高问答系统性能的。另一方面，在本 
次比赛得分较高的队伍均采用模块化系统的思路， 
端到端的直接生成查询方法并未受到重视，这有可 
能是因为当前数据集问句量还不够庞大，并不足以 
提供足够的隐含信息让模型来学习和理解；对于 
KBQA 任务，虽然模块化系统是直接的思路，也降低 
了训练的数据要求，但诸多在其他领域的研究发现 
端到端的模型利于计算机发现更多潜在的、人为难 
以识别的模式，反而有益于提高模型的性能。随着 
CCKS 中文问答数据集的不断丰富，将端到端模型尝 
试应用与中文问答任务是值得期待的。 
最后，大多数参赛队伍均将查询路径限定在 2 
跳内，一些队伍还将查询路径模板进一步缩减，这 
一方法对于给定数据集可能是有效地：减小路径模 
板数有助于相应模型训练出更高的识别准确率，同 
时降低了计算开销；如果复杂问题占比较少，少数 
模板就可以覆盖大多数问题，这一做法可以用较少 
损失换取在简单问题上较大的性能提升，进而取得 
更高得分。然而，为了得到面向开放领域的通用知 
识问答系统，对复杂问题占比较少的假设并不一定 
成立，仅考虑 2 跳以内的问句也许会严重影响系统 
在实际应用中的性能。因此，增强模型面对更加复 
杂多样问题的健壮性是进一步提高模型性能的必要 
条件。 

6. 5 任务总结 
针对开放领域的知识图谱问答，本次比赛的 
参赛者们提出了各类模型架构；面对此任务的难 
点，各队提出了不同解决方案，相比于往年评测 
结果切实地提高了问答系统地整体表现。本次比 
赛地拓展了学界对中文问答的认知，促进了中文 
知识图谱问答系统的继续发展。 

继去年赛方首次提出中文知识图谱自然语言 
问答数据集后，此数据集进一步修正与扩充，增 
加了大量金融领域问题，这使得数据集复杂性增 
加，更加切合开放领域、复杂问题的实际情况， 
进而促进相关领域研究不断发展。 
总之，本次测评取得一定的效果，我们会后 
续不断扩充中文知识图谱数据集的规模和多样性， 
为参赛者提供更有挑战更有意义的问题，也希望 
在今后的测评中各研究团队能继续突破，再创佳 
绩。 

https://www.biendata.com 2 非商业用途的研究者可联系通讯作者获取数据集
https://fanyi.baidu.com/

Overview of CCKS 2018 Task 1: Named Entity Recognition in Chinese Electronic Medical Records. Jiangtao Zhang, Juanzi Li, Zengtao Wen, Proceedings of China Conference on Knowledge Graph and Semantic Computing. China Conference on Knowledge Graph and Semantic ComputingJiangtao Zhang,Juanzi Li, Zengtao Wen, et al. Overview of CCKS 2018 Task 1: Named Entity Recognition in Chinese Electronic Medical Rec- ords[C]//Proceedings of China Conference on Knowledge Graph and Semantic Computing, 2019.

Category multi-representation: A unified solution for named entity recognition in clinical texts. Jiangtao Zhang, Juanzi Li, Shuai Wang, Proceedings of PAKDD. Jiangtao Zhang,Juanzi Li, Shuai Wang, et al. Category multi-representation: A unified solu- tion for named entity recognition in clinical texts[C]//Proceedings of PAKDD, 2018: 275-287.

Extracting information from textual documents in the electronic health record: a review of recent research. S M Meystre, G K Savova, Kipper-Schuler, Yearbook of medical informatics. Meystre, S.M., Savova, G.K., Kipper-Schuler, et al. Extracting information from textual docu- ments in the electronic health record: a review of recent research[J]. Yearbook of medical in- formatics. 2008, Jan: 128-144.

Clinical named entity recognition: Challenges and opportunities. S R Kundeti, J Vijayananda, S Mujjiga, Proceedings ofIEEE International Conference on Big Data. IEEE International Conference on Big DataKundeti, S.R., Vijayananda, J., Mujjiga, S., et al. Clinical named entity recognition: Chal- lenges and opportunities[C]//Proceedings ofIEEE International Conference on Big Data, 2016: 1937-1945.

i2b2/va challenge on concepts, assertions, and relations in clinical text. O Uzuner, B R South, S Shen, Journal of the American Medical Informatics Association. 185Uzuner, O., South, B.R., Shen, S., et al.2010 i2b2/va challenge on concepts, assertions, and relations in clinical text[J]. Journal of the American Medical Informatics Association, 2011,18(5)：552-556.

Overview of the share/clef ehealthevaluation lab. H Suominen, S Salantera, S Velupillai, Proceedings of CLEF. Suominen, H., Salantera S., Velupillai, S., et al. Overview of the share/clef ehealthevalua- tion lab 2013[C]//Proceedings of CLEF,2013: 212-231.

S Pradhan, N Elhadad, W W Chapman, Proceedings of SemEval@COLING. SemEval@COLING7Pradhan, S., Elhadad, N., Chapman, W.W., et al. Semeval-2014 task 7: Analysis of clinical text[C]//Proceedings of SemEval@COLING,2014: 54-62.

. 张江涛, 面向限定领域的实体识别与链接[d], 清华大 学工学博士学位论文，2018, 张江涛.面向限定领域的实体识别与链接[D]. 清华大 学工学博士学位论文，2018.

Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. J Lafferty, A Mccallum, F C N Pereira, Proceedings of Icml. Icml3Lafferty J, Mccallum A, Pereira F C N. Condi- tional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data[J]. Pro- ceedings of Icml, 2001, 3(2):282-289.

Long Short-Term Memory. S Hochreiter, J Schmidhuber, Hochreiter S, Schmidhuber J. Long Short-Term Memory[J].

. Neural Computation. 98Neural Computation, 1997, 9(8):1735- 1780.

Enhanced Representation through Knowledge Integration. Y Sun, S Wang, Y Li, Sun Y , Wang S , Li Y , et al. ERNIE: Enhanced Representation through Knowledge Integration[J]. 2019.

Pretraining of deep bidirectional transformers for language understanding. J Devlin, M W Chang, K Lee, arXiv:1810.04805arXiv preprintDevlin J, Chang M W, Lee K, et al. Bert: Pre- training of deep bidirectional transformers for language understanding[J]. arXiv preprint arXiv:1810.04805, 2018.

Zero-Shot Entity Linking by Reading Entity Descriptions. L Logeswaran, M W Chang, K Lee, arXiv:1906.07348arXiv preprintLogeswaran L, Chang M W, Lee K, et al. Zero- Shot Entity Linking by Reading Entity Descrip- tions[J]. arXiv preprint arXiv:1906.07348, 2019.

The evolution of culture: the development of civilization to the fall of Rome. L White, White L A. The evolution of culture: the devel- opment of civilization to the fall of Rome[M].

. Routledge, Routledge, 2016.

Reinforcement learning for relation classification from noisy data. J Feng, M Huang, L Zhao, Second AAAI Conference on Artificial Intelligence. Feng J, Huang M, Zhao L, et al. Reinforcement learning for relation classification from noisy data[C]//Thirty-Second AAAI Conference on Arti- ficial Intelligence. 2018.

Syntax-aware entity representations for neural relation extraction. Z He, W Chen, Z Li, J]. Artificial Intelligence. 275He Z, Chen W, Li Z, et al. Syntax-aware entity representations for neural relation extrac- tion[J]. Artificial Intelligence, 2019, 275: 602-617.

Distant supervision for relation extraction with sentence-level attention and entity. G Ji, K Liu, S He, First AAAI Conference on Artificial Intelligence. Ji G, Liu K, He S, et al. Distant supervision for relation extraction with sentence-level at- tention and entity descriptions[C]//Thirty- First AAAI Conference on Artificial Intelli- gence. 2017.

Attention-based bidirectional long short-term memory networks for relation. P Zhou, W Shi, J Tian, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational Linguistics2Short Papers)Zhou P, Shi W, Tian J, et al. Attention-based bidirectional long short-term memory networks for relation classification[C]//Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Pa- pers). 2016: 207-212.

Distant supervision for relation extraction without labeled data. M Mintz, S Bills, R Snow, Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP. the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLPAssociation for Computational Linguistics2Mintz M, Bills S, Snow R, et al. Distant super- vision for relation extraction without labeled data[C]//Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Lan- guage Processing of the AFNLP: Volume 2-Volume 2. Association for Computational Linguistics, 2009: 1003-1011.

IPRE: a Dataset for Inter-Personal Relationship Extraction. H Wang, Z He, J Ma, Wang H, He Z, Ma J, et al. IPRE: a Dataset for Inter-Personal Relationship Extraction[J].

Deep contextualized word representations. M E Peters, M Neumann, M Iyyer, arXiv:1802.05365arXiv preprintPeters M E, Neumann M, Iyyer M, et al. Deep contextualized word representations[J]. arXiv preprint arXiv:1802.05365, 2018.

Efficient estimation of word representations in vector space. T Mikolov, K Chen, G Corrado, arXiv:1301.3781arXiv preprintMikolov T, Chen K, Corrado G, et al. Efficient estimation of word representations in vector space[J]. arXiv preprint arXiv:1301.3781, 2013.

Glove: Global vectors for word. J Pennington, R Socher, C Manning, Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). the 2014 conference on empirical methods in natural language processing (EMNLP)Pennington J, Socher R, Manning C. Glove: Global vectors for word representation[C]//Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). 2014: 1532-1543.

Neural architectures for named entity recognition. G Lample, M Ballesteros, S Subramanian, arXiv:1603.01360arXiv preprintLample G, Ballesteros M, Subramanian S, et al. Neural architectures for named entity recognition[J]. arXiv preprint arXiv:1603.01360, 2016.

Variable-Size Relation Extraction and Table Information Extraction. Shaodong Hou, Yiqing Zhou, Xianming Tong, Proceedings of CCKS Tasks. CCKS TasksShaodong Hou, Yiqing Zhou, Xianming Tong: Var- iable-Size Relation Extraction and Table In- formation Extraction. In: Proceedings of CCKS Tasks (2019).

. Jing Zhu, Yongcui Deng, Yiwen Zhou, Dewang Sun, Ruibin Mao, 等: 文章标题 21An Information Extraction *期 作者. Jing Zhu, Yongcui Deng, Yiwen Zhou, Dewang Sun and Ruibin Mao: An Information Extraction *期 作者, 等: 文章标题 21

. Approach Based on Domain Language Model. Approach Based on Domain Language Model (2019).

. 毛先领 余厚金, 黄河燕: 一种面向多需求的 Pdf 文档 信息抽取方法, 年全国知识图谱与语义计算大会 任务. 5余厚金,毛先领,黄河燕: 一种面向多需求的 PDF 文档 信息抽取方法. 2019 年全国知识图谱与语义计算大会 任务 5 (2019).

. 高翔 朱耀邦, 曾彦能, 顾嘉晟, 纪达麒 李欣, 5朱耀邦,高翔,曾彦能,顾嘉晟,李欣,纪达麒,陈运 文:CCKS测评任务5 基于OpenCV和Faster R-CNN的金 融财报抽取

Multi-Module System for Open Domain Chinese Question Answering over Knowledge Base. Y Y Yang, X H He, K Zhou, Z Y Wei, Proceedings of CCKS Tasks. CCKS TasksYang, Y.y., He, X.h., Zhou, K.j. and Wei, Z.y.: Multi-Module System for Open Domain Chi- nese Question Answering over Knowledge Base. In: Proceedings of CCKS Tasks (2019).

Combining Neural Network Models with Rules for Chinese Knowledge Base Question Answering. P J Zhang, K Wu, Z K Zhu, Y H Jia, X Zhou, W Chen, Proceedings of CCKS Tasks. CCKS TasksZhang, P.j., Wu, K., Zhu, Z.k., Jia, Y.h., Zhou, X.b. and Chen, W.l.: Combining Neural Network Models with Rules for Chinese Knowledge Base Question Answering. In: Pro- ceedings of CCKS Tasks (2019).

. 尹存祥 骆金昌, 周丽芳 吴晓晖, 钟辉强: 混合语 义相似度的中文知识图谱问答系统, 年全国知识 图谱与语义计算大会任务. 6骆金昌, 尹存祥, 吴晓晖, 周丽芳, 钟辉强: 混合语 义相似度的中文知识图谱问答系统. 2019 年全国知识 图谱与语义计算大会任务 6 (2019).