# A Survey on the Role of Negation in Sentiment Analysis

CorpusID: 11591301 - [https://www.semanticscholar.org/paper/c4a5ef385e966517da0587325f37d16c15aec256](https://www.semanticscholar.org/paper/c4a5ef385e966517da0587325f37d16c15aec256)

Fields: Linguistics, Computer Science

## (s0) Introduction
(p0.0) Sentiment analysis is the task dealing with the automatic detection and classification of opinions expressed in text written in natural language. Subjectivity is defined as the linguistic expression of somebody's opinions, sentiments, emotions, evaluations, beliefs and speculations (Wiebe, 1994). Subjectivity is opposed to objectivity, which is the expression of facts. It is important to make the distinction between subjectivity detection and sentiment analysis, as they are two separate tasks in natural language processing. Sentiment analysis can be dependently or independently done from subjectivity detection, although Pang and Lee (2004) state that subjectivity detection performed prior to the sentiment analysis leads to better results in the latter. Although research in this area has started only recently, the substantial growth in subjective information on the world wide web in the past years has made sentiment analysis a task on which constantly growing efforts have been concentrated.
## (s3) Negation and Bag of Words in Supervised Machine Learning
(p3.0) Several research efforts in polarity classification employ supervised machine-learning algorithms, like Support Vector Machines, Na√Øve Bayes Classifiers or Maximum Entropy Classifiers. For these algorithms, already a low-level representation using bag of words is fairly effective (Pang et al., 2002). Using a bag-of-words representation, the supervised classifier has to figure out by itself which words in the dataset, or more precisely feature set, are polar and which are not. One either considers all words occurring in a dataset or, as in the case of Pang et al. (2002), one carries out a simple feature selection, such as removing infrequent words. Thus, the standard bag-of-words representation does not contain any explicit knowledge of polar expressions. As a consequence of this simple level of representation, the reversal of the polarity type of polar expressions as it is caused by a negation cannot be explicitly modeled.
## (s14) Bad and Not Good are Not the Same
(p14.0) The standard approach of negation modeling suggests to consider a negated polar expression, such as not bad, as an unnegated polar expression with the opposite polarity, such as good. Liu and Seneff (2009) claim, however, that this is an oversimplification of language. Not bad and good may have the same polarity but they differ in their respective polar strength, i.e. not bad is less positive than good. That is why, Liu and Seneff (2009) suggest a compositional model in which for individual adjectives and adverbs (the latter include negations) a prior rating score encoding their intensity and polarity is estimated from pros and cons of on-line reviews. Moreover, compositional rules for polar phrases, such as adverb-adjective or negation-adverb-adjective are defined exclusively using the scores of the individual words. Thus, adverbs function like universal quantifiers scaling either up or down the polar strength of the specific polar adjectives they modify. The model independently learns what negations are, i.e. a subset of adverbs having stronger negative scores than other adverbs. In short, the proposed model provides a unifying account for intensifiers (e.g. very), diminishers, polarity shifters and negation words. Its advantage is that polarity is treated compositionally and is interpreted as a continuum rather than a binary classification. This approach reflects its meaning in a more suitable manner.
## (s15) Using Negations in Lexicon Induction
(p15.0) Many classification approaches illustrated above depend on the knowledge of which natural lan-guage expressions are polar. The process of acquiring such lexical resources is called lexicon induction. The observation that negations co-occur with polar expressions has been used for inducing polarity lexicons on Chinese in an unsupervised manner (Zagibalov and Carroll, 2008). One advantage of negation is that though the induction starts with just positive polar seeds, the method also accomplishes to extract negative polar expressions since negated mentions of the positive polar seeds co-occur with negative polar expressions. Moreover, and more importantly, the distribution of the co-occurrence between polar expressions and negations can be exploited for the selection of those seed lexical items. The model presented by Zagibalov and Carroll (2008) relies on the observation that a polar expression can be negated but it occurs more frequently without the negation. The distributional behaviour of an expression, i.e. significantly often co-occurring with a negation word but significantly more often occurring without a negation word makes up a property of a polar expression. The data used for these experiments are publicly available 5 .
