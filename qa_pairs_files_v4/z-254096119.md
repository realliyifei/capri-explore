# Multimodal Learning for Multi-Omics: A Survey

CorpusID: 254096119 - [https://www.semanticscholar.org/paper/ebf69dfc9306f3c0f0dbb2bd6916b81f953d872a](https://www.semanticscholar.org/paper/ebf69dfc9306f3c0f0dbb2bd6916b81f953d872a)

Fields: Mathematics, Medicine, Biology, Computer Science

## (s1) Multi-Omics Data
(p1.0) Multi-omics data are derived from different sources: molecular omics data, radiomics, and phenomics. Molecular omics data are the traditional dimension of multi-omics data, which aim to analyze the molecular biology of human diseases and consist of genomics, transcriptomics, proteomics, metabolomics, epigenomics, microbiomics, and exposomics. Radiomics, on the other hand, studies medical images collected from medical imaging technologies. 29 Phenomics is another valuable dimension of multi-omics data that comprises clinical and biochemical data of individuals. 30 Each source of omics data has been separately studied to answer biomedical questions. While different sources of information are complementary and contribute to the discovery of unique aspects of diseases, the fusion of multiple omics modalities has widely been done in existing research. Therefore, introducing each modality of omics data and their potential applications in solving biomedical tasks helps researchers consider all omics modalities in the long run. 18,31   an overview of multiple modalities of omics data and their applications applied to biomedical studies. Besides, the multiple omics data and their fusion for various tasks are visually presented in Figure 1.
## (s12) Noisiness
(p12.0) Complex workflows for generating large-scale omics data have produced noisy multiomics data, which can arise as mislabeled samples or misvalued features. 114,115 Sample mislabeling is a well-known problem in healthcare research, and these noisy datasets can misguide the learning algorithms to find misleading patterns. Therefore, some necessary steps should be taken to rectify the errors. Mislabeled sample correction by matching methods has been used in several research works. 114,[116][117][118] Since there are unreliable samples in multi-omics data, unsupervised and selfsupervised methods may perform better than supervised methods, as reviewed in some papers. 71,[119][120][121] Misvalued features, on the other hand, can occur due to measurement errors or biological deviations. 13 Consequently, extracting meaningful information from multi-omics data is a challenging task that needs to be addressed appropriately. One technique to address this problem uses regulatory network strategies (e.g., RNA-protein interaction networks) to reduce noise based on interactions between biological datasets. 122 Some other efforts have been made to solve this problem in the literature. 123,124
## (s15) Early fusion
(p15.0) The early fusion approach directly concatenates each omics dataset to construct a single extensive dataset containing all features before being fed to learning algorithms. 128 Methods based on this approach benefit from cross-modality learning, which refers to learning by involving information obtained from multiple modalities. The development of this strategy is simple, and the final joint dataset can be used as the input for numerous classical machine learning algorithms such as artificial neural networks (ANNs), 129 support vector machines (SVMs), 130 decision trees (DTs), 131 random forests (RFs), 132 and k-nearest neighbors (k-NN). 133 Training only one single algorithm in early fusion leads to a more straightforward pipeline for implementing this approach. 2 Despite the simplicity of early fusion, the newly generated single dataset has a higher dimensionality for a relatively smaller number of patients. This problem makes the model's training difficult, decreases the performance, and increases the computational time. 134 Since there is a noticeable difference in feature dimensionality in multi-omics data, another drawback of early fusion is the model's tendency to learn more from the omics with a larger number of features. 135 Employing dimensionality reduction techniques as a pre-processing step can reduce the adverse effects of these challenges by keeping a small number of discriminating features 23,26,[136][137][138] (see Section 3.1 for details).
## (s20) Datasets description
(p20.0) In this section, we briefly review important multi-omics datasets such as TCGA, 21,195,196 Kyoto Encyclopedia of Genes and Genomes (KEGG), [197][198][199] and the Human Protein Atlas (HPA). 200 TCGA was initiated by the effort between the National Cancer Institute (NCI) and the Center for Cancer Genomics Research Institute (NHGRI) with the aim of collecting, molecularly characterizing, and analyzing many cancers in 2006. This initiative has processed more than 20,000 patients to represent 33 cancer types and provided over 2.5 petabytes of data from different modalities, including genomics, epigenomics, transcriptomics, and proteomics. According to Google Scholar metrics, TCGA has been cited over 38,500 times as of July 2022, demonstrating the project's popularity among researchers. Another initiative is the KEGG program, conducted at Kyoto University as part of the Human Genome Program in 1995. The program's objective is to assign sets of genes in the genome with higher-order functional information that can help the biological interpretation of genomic information. KEGG has analyzed different omics types, including genomics, transcriptomics, proteomics, metabolomics, and other types. As another example, HPA collects transcriptomics and proteomics data for human tissue expression profiles. Table 4 lists other studies that focus on providing multi-omics data to enable the development of multi-omics fusion workflows.
