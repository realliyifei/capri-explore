# Ear Biometrics Using Deep Learning: A Survey

CorpusID: 251654604 - [https://www.semanticscholar.org/paper/efb14c753c5500b76fe3914894403eed351d9176](https://www.semanticscholar.org/paper/efb14c753c5500b76fe3914894403eed351d9176)

Fields: Computer Science

## (s4) Building Block for Convolutional Neural Networks
(p4.0) is layer is a set of learnable filters or kernels used to slide over the entire input volume, performing a dot product between entries of the filter and the input layer [5]. e convolutional operation first extracts patches from its information in a sliding window fashion and then applies the same linear transformation to all the areas. e output of the convolutional operation is referred to as a feature map. e network will learn filters and then recognise the visual patterns that are in the input data. is is often shown asx l ij
## (s7) Fully Connected Layer.
(p7.0) e fully connected layer is used as a feature extractor. e features produced are then passed to the fully connected layers for classification. Each unit in the fully connected layer is connected to all the units in the previous layers. e last layer is usually a classifier that produces a probability map over the different classes. All the features are converted into one-dimensional feature vectors before passing into the fully connected layer. e reason that this is carried out is that spatial information in the image data is lost, has a high computational cost, and can only work with images that are of the same size [6]. is is often shown as

(p7.1) e fully connected layer is used as a feature extractor. e features produced are then passed to the fully connected layers for classification. Each unit in the fully connected layer is connected to all the units in the previous layers. e last layer is usually a classifier that produces a probability map over the different classes. All the features are converted into one-dimensional feature vectors before passing into the fully connected layer. e reason that this is carried out is that spatial information in the image data is lost, has a high computational cost, and can only work with images that are of the same size [6]. is is often shown as
## (s14) Cascaded Architecture.
(p14.0) In the cascaded architecture, the output of the CNN is concatenated with another [9]. ere are many variations with this architecture within the literature, but the input cascade is prominent. In this architecture, the output of the CNN becomes a direct input of another CNN. e input cascade is employed to concatenate the contextual information to the second CNN as additional image channels. Cascaded architecture is an improvement to the only pathway that performs multiscale label prediction separately.
## (s15) UNET.
(p15.0) UNET improves a convolutional network that resembles an encoder and decoder network designed to do biomedical image segmentation [10]. e network consists of a contracting path and an expansive path, which provides it with the u-shaped architecture. e contracting path consists of the repeated application of two convolutional layers, followed by a rectified linear measure and a top pooling layer that goes along the trail to scale back the spatial information while feature information is increased. e expansive path consists of upsampling operations combined with high-resolution features from the contraction path through skip connections.

(p15.1) UNET improves a convolutional network that resembles an encoder and decoder network designed to do biomedical image segmentation [10]. e network consists of a contracting path and an expansive path, which provides it with the u-shaped architecture. e contracting path consists of the repeated application of two convolutional layers, followed by a rectified linear measure and a top pooling layer that goes along the trail to scale back the spatial information while feature information is increased. e expansive path consists of upsampling operations combined with high-resolution features from the contraction path through skip connections.
## (s17) Visual Geometry Group
(p17.0) Architecture. Visual geometry group architecture is a network created by Visual Graphics Group researchers at Oxford University [12]. It is characterised by a pyramidal shape because it comprises a group of convolutional layers followed by pooling layers; these pooling layers make the layers narrower in shape. e benefits include keeping a good architecture used for benchmarking for any task. e pretrained networks of the VGG are also primarily used for different applications but require numerous computational resources and are slow to coach, above all when training the dataset from scratch.

(p17.1) Architecture. Visual geometry group architecture is a network created by Visual Graphics Group researchers at Oxford University [12]. It is characterised by a pyramidal shape because it comprises a group of convolutional layers followed by pooling layers; these pooling layers make the layers narrower in shape. e benefits include keeping a good architecture used for benchmarking for any task. e pretrained networks of the VGG are also primarily used for different applications but require numerous computational resources and are slow to coach, above all when training the dataset from scratch.
## (s18) GoogLeNet Architecture.
(p18.0) e GoogLeNet architecture is referred to as the inception network and was created by Google researchers [13]. It is made from twenty-two layers with two options that these layers can either convolute or pool the input. e architecture contains many beginning modules stacked over each other, allowing joint and parallel training, which helps with faster convergence. e benefits are that there is speedier training, which reduces the size. It , however, possesses an Xception network, which could increase the point for the divergence of the beginning module.

(p18.1) e GoogLeNet architecture is referred to as the inception network and was created by Google researchers [13]. It is made from twenty-two layers with two options that these layers can either convolute or pool the input. e architecture contains many beginning modules stacked over each other, allowing joint and parallel training, which helps with faster convergence. e benefits are that there is speedier training, which reduces the size. It , however, possesses an Xception network, which could increase the point for the divergence of the beginning module.
## (s20) ResNeXt Architecture.
(p20.0) ResNeXt architecture is the present state-of-the-art technique for visual perception, which is a hybridisation between inception and ResNeXt architectures [15]. ResNeXt is referred to as the aggregated residual transform network, but it is an improvement over the inception network. It splits the concept and transforms and merges in a commanding but easy way by bringing in cardinality. It uses residual learning, which will enhance the joining of the deep and wide networks. ResNeXt uses many transformations within a split, transform, and merge blocks; and the transformations in cardinality define these. ResNeXt used a mixture of VGG topology and GoogLeNet architecture to correct the spatial resolution using 3 × 3 filters within the split, transform, and merge blocks. e increase in cardinality improves the performance and produces a different and improved architecture.

(p20.1) ResNeXt architecture is the present state-of-the-art technique for visual perception, which is a hybridisation between inception and ResNeXt architectures [15]. ResNeXt is referred to as the aggregated residual transform network, but it is an improvement over the inception network. It splits the concept and transforms and merges in a commanding but easy way by bringing in cardinality. It uses residual learning, which will enhance the joining of the deep and wide networks. ResNeXt uses many transformations within a split, transform, and merge blocks; and the transformations in cardinality define these. ResNeXt used a mixture of VGG topology and GoogLeNet architecture to correct the spatial resolution using 3 × 3 filters within the split, transform, and merge blocks. e increase in cardinality improves the performance and produces a different and improved architecture.
## (s27) Convolutional and Deconvolutional Neural Networks.
(p27.0) is architecture is formed from two significant parts: convolutional and deconvolutional networks [24]. Deconvolutional networks are CNNs that operate during a reversed process, and networks extract discriminated features. e deconvolutional layers are applied for smothering the segmentation maps to get the ultimate high-resolution output.

(p27.1) is architecture is formed from two significant parts: convolutional and deconvolutional networks [24]. Deconvolutional networks are CNNs that operate during a reversed process, and networks extract discriminated features. e deconvolutional layers are applied for smothering the segmentation maps to get the ultimate high-resolution output.
## (s33) e Annotated Web Ear (AWE) Database.
(p33.0) e AWE ear database [28] was a set of public figures from web images. e database was formed from 1000 images of 100 6 Applied Computational Intelligence and Soft Computing different subjects, whose sizes varied and were tightly cropped. Both the left-and right-hand sides of the ears were taken.

(p33.1) 3.5. EarVN1.0. e EarVN1.0 database [29] comprises 28412 images of 164 Asian male and female subjects, and left-and right-hand sides of the ear were captured. It was collected during 2018 and is formed from unconstrained conditions, including camera systems and lighting conditions. e pictures are cropped from facial images to obtain the ears, and the pictures have significant variations in pose, scale, and illumination.

(p33.2) e AWE ear database [28] was a set of public figures from web images. e database was formed from 1000 images of 100 6 Applied Computational Intelligence and Soft Computing different subjects, whose sizes varied and were tightly cropped. Both the left-and right-hand sides of the ears were taken.

(p33.3) 3.5. EarVN1.0. e EarVN1.0 database [29] comprises 28412 images of 164 Asian male and female subjects, and left-and right-hand sides of the ear were captured. It was collected during 2018 and is formed from unconstrained conditions, including camera systems and lighting conditions. e pictures are cropped from facial images to obtain the ears, and the pictures have significant variations in pose, scale, and illumination.
## (s74) Building Block for Convolutional Neural Networks
(p74.0) is layer is a set of learnable filters or kernels used to slide over the entire input volume, performing a dot product between entries of the filter and the input layer [5]. e convolutional operation first extracts patches from its information in a sliding window fashion and then applies the same linear transformation to all the areas. e output of the convolutional operation is referred to as a feature map. e network will learn filters and then recognise the visual patterns that are in the input data. is is often shown asx l ij
## (s77) Fully Connected Layer.
(p77.0) e fully connected layer is used as a feature extractor. e features produced are then passed to the fully connected layers for classification. Each unit in the fully connected layer is connected to all the units in the previous layers. e last layer is usually a classifier that produces a probability map over the different classes. All the features are converted into one-dimensional feature vectors before passing into the fully connected layer. e reason that this is carried out is that spatial information in the image data is lost, has a high computational cost, and can only work with images that are of the same size [6]. is is often shown as

(p77.1) e fully connected layer is used as a feature extractor. e features produced are then passed to the fully connected layers for classification. Each unit in the fully connected layer is connected to all the units in the previous layers. e last layer is usually a classifier that produces a probability map over the different classes. All the features are converted into one-dimensional feature vectors before passing into the fully connected layer. e reason that this is carried out is that spatial information in the image data is lost, has a high computational cost, and can only work with images that are of the same size [6]. is is often shown as
## (s84) Cascaded Architecture.
(p84.0) In the cascaded architecture, the output of the CNN is concatenated with another [9]. ere are many variations with this architecture within the literature, but the input cascade is prominent. In this architecture, the output of the CNN becomes a direct input of another CNN. e input cascade is employed to concatenate the contextual information to the second CNN as additional image channels. Cascaded architecture is an improvement to the only pathway that performs multiscale label prediction separately.
## (s85) UNET.
(p85.0) UNET improves a convolutional network that resembles an encoder and decoder network designed to do biomedical image segmentation [10]. e network consists of a contracting path and an expansive path, which provides it with the u-shaped architecture. e contracting path consists of the repeated application of two convolutional layers, followed by a rectified linear measure and a top pooling layer that goes along the trail to scale back the spatial information while feature information is increased. e expansive path consists of upsampling operations combined with high-resolution features from the contraction path through skip connections.

(p85.1) UNET improves a convolutional network that resembles an encoder and decoder network designed to do biomedical image segmentation [10]. e network consists of a contracting path and an expansive path, which provides it with the u-shaped architecture. e contracting path consists of the repeated application of two convolutional layers, followed by a rectified linear measure and a top pooling layer that goes along the trail to scale back the spatial information while feature information is increased. e expansive path consists of upsampling operations combined with high-resolution features from the contraction path through skip connections.
## (s87) Visual Geometry Group
(p87.0) Architecture. Visual geometry group architecture is a network created by Visual Graphics Group researchers at Oxford University [12]. It is characterised by a pyramidal shape because it comprises a group of convolutional layers followed by pooling layers; these pooling layers make the layers narrower in shape. e benefits include keeping a good architecture used for benchmarking for any task. e pretrained networks of the VGG are also primarily used for different applications but require numerous computational resources and are slow to coach, above all when training the dataset from scratch.

(p87.1) Architecture. Visual geometry group architecture is a network created by Visual Graphics Group researchers at Oxford University [12]. It is characterised by a pyramidal shape because it comprises a group of convolutional layers followed by pooling layers; these pooling layers make the layers narrower in shape. e benefits include keeping a good architecture used for benchmarking for any task. e pretrained networks of the VGG are also primarily used for different applications but require numerous computational resources and are slow to coach, above all when training the dataset from scratch.
## (s88) GoogLeNet Architecture.
(p88.0) e GoogLeNet architecture is referred to as the inception network and was created by Google researchers [13]. It is made from twenty-two layers with two options that these layers can either convolute or pool the input. e architecture contains many beginning modules stacked over each other, allowing joint and parallel training, which helps with faster convergence. e benefits are that there is speedier training, which reduces the size. It , however, possesses an Xception network, which could increase the point for the divergence of the beginning module.

(p88.1) e GoogLeNet architecture is referred to as the inception network and was created by Google researchers [13]. It is made from twenty-two layers with two options that these layers can either convolute or pool the input. e architecture contains many beginning modules stacked over each other, allowing joint and parallel training, which helps with faster convergence. e benefits are that there is speedier training, which reduces the size. It , however, possesses an Xception network, which could increase the point for the divergence of the beginning module.
## (s90) ResNeXt Architecture.
(p90.0) ResNeXt architecture is the present state-of-the-art technique for visual perception, which is a hybridisation between inception and ResNeXt architectures [15]. ResNeXt is referred to as the aggregated residual transform network, but it is an improvement over the inception network. It splits the concept and transforms and merges in a commanding but easy way by bringing in cardinality. It uses residual learning, which will enhance the joining of the deep and wide networks. ResNeXt uses many transformations within a split, transform, and merge blocks; and the transformations in cardinality define these. ResNeXt used a mixture of VGG topology and GoogLeNet architecture to correct the spatial resolution using 3 × 3 filters within the split, transform, and merge blocks. e increase in cardinality improves the performance and produces a different and improved architecture.

(p90.1) ResNeXt architecture is the present state-of-the-art technique for visual perception, which is a hybridisation between inception and ResNeXt architectures [15]. ResNeXt is referred to as the aggregated residual transform network, but it is an improvement over the inception network. It splits the concept and transforms and merges in a commanding but easy way by bringing in cardinality. It uses residual learning, which will enhance the joining of the deep and wide networks. ResNeXt uses many transformations within a split, transform, and merge blocks; and the transformations in cardinality define these. ResNeXt used a mixture of VGG topology and GoogLeNet architecture to correct the spatial resolution using 3 × 3 filters within the split, transform, and merge blocks. e increase in cardinality improves the performance and produces a different and improved architecture.
## (s97) Convolutional and Deconvolutional Neural Networks.
(p97.0) is architecture is formed from two significant parts: convolutional and deconvolutional networks [24]. Deconvolutional networks are CNNs that operate during a reversed process, and networks extract discriminated features. e deconvolutional layers are applied for smothering the segmentation maps to get the ultimate high-resolution output.

(p97.1) is architecture is formed from two significant parts: convolutional and deconvolutional networks [24]. Deconvolutional networks are CNNs that operate during a reversed process, and networks extract discriminated features. e deconvolutional layers are applied for smothering the segmentation maps to get the ultimate high-resolution output.
## (s103) e Annotated Web Ear (AWE) Database.
(p103.0) e AWE ear database [28] was a set of public figures from web images. e database was formed from 1000 images of 100 6 Applied Computational Intelligence and Soft Computing different subjects, whose sizes varied and were tightly cropped. Both the left-and right-hand sides of the ears were taken.

(p103.1) 3.5. EarVN1.0. e EarVN1.0 database [29] comprises 28412 images of 164 Asian male and female subjects, and left-and right-hand sides of the ear were captured. It was collected during 2018 and is formed from unconstrained conditions, including camera systems and lighting conditions. e pictures are cropped from facial images to obtain the ears, and the pictures have significant variations in pose, scale, and illumination.

(p103.2) e AWE ear database [28] was a set of public figures from web images. e database was formed from 1000 images of 100 6 Applied Computational Intelligence and Soft Computing different subjects, whose sizes varied and were tightly cropped. Both the left-and right-hand sides of the ears were taken.

(p103.3) 3.5. EarVN1.0. e EarVN1.0 database [29] comprises 28412 images of 164 Asian male and female subjects, and left-and right-hand sides of the ear were captured. It was collected during 2018 and is formed from unconstrained conditions, including camera systems and lighting conditions. e pictures are cropped from facial images to obtain the ears, and the pictures have significant variations in pose, scale, and illumination.
