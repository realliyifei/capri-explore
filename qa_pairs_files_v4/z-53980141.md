# A review protocol on research partnerships: a Coordinated Multicenter Team approach

CorpusID: 53980141 - [https://www.semanticscholar.org/paper/fd0ce3914dd6027e3f9fce6e33b2afa319cdb478](https://www.semanticscholar.org/paper/fd0ce3914dd6027e3f9fce6e33b2afa319cdb478)

Fields: Business, Medicine

## (s8) Screening process and data extraction
(p8.0) The search will be executed by our academic librarian (MVD), and the results managed using Endnote™ X.7.5.3. De-duplication of search findings will be done according to Bramer's method [67]. De-duplicated results will be imported into Rayyan, a web-based tool designed to facilitate the screening process of literature reviews [68]. Prior to the actual screening process, we will choose a random sample (5%) of citations to conduct calibration screening. Two members of the Coordinated Multicenter Team (FH, KJM) will take part and review the same set of citations independently. We will calculate inter-rater agreement using the kappa statistic and start the screening process once a kappa ≥ 0.6 is achieved. Where discrepancies arise, these will be discussed and resolved by consensus or failing agreement, referred to a third team member for a final decision.

(p8.1) The screening process will be conducted in three separate rounds. In the first round, both members will screen all citations on the title only, independently and in duplicate. Citations included by at least one team member will pass title screening and will be stored in a new database for the next screening round. In the second round, both members will screen all citations on title and abstract, independently and in duplicate, guided by the following eligibility criteria: included articles must (a) describe a literature overview of research partnerships according to our definition, (b) describe a systematic search of the literature including search terms and databases, and (c) be published in the English language. Articles that (a) do not meet our definition of research partnership and/or (b) describe a review of a method or tool instead of literature overview will be excluded and the reasons for exclusion categorized. The development of search strategies for each subsequent scoping review will be informed by the classifications formulated by this review (step 2). The third round will involve gathering full-text versions of all citations meeting eligibility criteria. Using the previously described screening calibration process, the same two team members will screen full-text review papers independently and in duplicate, discussing discrepancies to consensus or failing consensus, referring them to a third team member for a final decision. Full-text screening will then be performed based on the specific eligibility criteria aligned with our research questions (see Table 1 and Appendix 2 for more details). Once a final set of eligible review papers is generated, data extraction from full-text review papers will proceed, independently, and in duplicate, using a pre-tested data extraction tool in MS Excel. The extractable data (e.g., principles, strategies, outcomes, impacts) will be summarized for different types of research partnership approaches (e.g., IKT, CBPR, PAR). Strategies to determine the risk of bias and the methodological quality of the included review papers will be developed using published guidance [56,69,70].
