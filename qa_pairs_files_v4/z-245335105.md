# A Comprehensive Analytical Survey on Unsupervised and Semi-Supervised Graph Representation Learning Methods

CorpusID: 245335105 - [https://www.semanticscholar.org/paper/b415ecb687941e1e9ef68e04a4a1c68c73483d51](https://www.semanticscholar.org/paper/b415ecb687941e1e9ef68e04a4a1c68c73483d51)

Fields: Mathematics, Computer Science

## (s34) Effect of Dimensions
(p34.0) Some previous studies have shown that the performance on the prediction task may vary if we choose different values for hyper-parameters [79,34,100,80]. For example, after reaching a certain value for dimensionality, the accuracy of prediction starts to drop when we increase it further. Most of the previous studies suggest using dimensional embedding. To summarize the results, we conduct experiments varying the dimensions of the output embedding for some shallow network-based methods. We set different parameters as described in Section 4.3 and take 20% of the dataset to train the logistic regression model while the rest of the samples in the dataset are used for the classification. We report the results of the F1-micro scores for the Pubmed dataset in Figs. 21 (a). We observe that Force2Vec, DeepWalk, and HARP perform better than other methods for various dimensional embedding. We also notice that, for lower dimensions, the F1-micro scores are not that much less compared to higher dimensions. In fact, the VERSE tool shows better performance for 16-dimensional embedding for the Pubmed dataset. RolX shows high sensitivity for different dimensions. It shows the lowest performance for 16-dimensional embedding. Then, with the increase of dimension, the F1-micro score also increases until 128-dimension. Then, it falls a little for 256-dimensional embedding. The LINE method shows similar sensitivity to the VERSE method though its F1-micro scores are lower than the VERSE.
## (s35) Effect of Various Negative Samples
(p35.0) Noise-contrastive estimation [36] is a popular technique used by most of the shallow graph embedding models [100,117,90]. Using this technique, a subset of vertices are randomly selected from a uniform distribution as negative samples which are used alongside positive samples (i.e., k-hop neighbors) to optimize the objective function. However, randomly generated negative samples may hurt the optimization function due to the selection of false negative samples and this become vital if the number of negative samples is very large. Armandpour et al. (2019) have made efforts to analyze this issue theoretically and proposed robust negative sampling techniques for graph embedding problem. NSCaching [119] is another interesting work that generates efficient negative samples for knowledge graphs. In Fig. 21 (b), we empirically show the effect on performance measures varying the number of negative samples. To conduct experiment, we choose Force2Vec, VERSE and LINE methods as they support random negative sampling approach. We take 25% of the vertices in the training set and report the F1-micro score for the rest of the testing dataset. We observe that performance score drops when we use more than 5 negative samples for the Pubmed dataset and continues to decrease for more negative samples. VERSE method is more sensitive to higher negative samples than others as its performance score significantly drops after using more than 15 negative samples for the Pubmed dataset. Note that the size of this dataset is relatively small as it has only around 19K vertices. For smaller graphs than Pubmed, the number of randomly selected negative samples will show more sensitivity than bigger graphs than the Pubmed dataset. The reason is that for bigger graphs, the probability of selecting false negative is lower compared to the smaller graphs. Thus, care must be taken to choose an effective number of negative samples rather than random selection. 
