# False Information on Web and Social Media: A Survey

CorpusID: 5058880 - [https://www.semanticscholar.org/paper/1bb23fd4252a76b55ff77ed982fc78c3e06d1452](https://www.semanticscholar.org/paper/1bb23fd4252a76b55ff77ed982fc78c3e06d1452)

Fields: Computer Science

## (s14) Textual characteristics.
(p14.0) Since most reviews include textual content, researchers have extensively studied textual and linguistic features for discerning review fraud. Several works have posited that review fraudsters minimize effort by repeating the same reviews. Jindal et al. [43] provided the first well-known characterizations of review fraud, in which the authors characterized duplicate reviews (according to Jaccard similarity) across Amazon data as cases of fraud. The authors showed that many of these fraudulent duplicate reviews were from the same user on different products, rather than different users on the same product or different products. Figure 6 shows the distribution of maximum similarity between two reviewers' reviews. At the higher similarity end, 6% of the reviewers with more than one review have a maximum similarity score of 1, which is a sudden jump indicating that many reviewers copy reviews. Furthermore, Sandulescu et al. [82] showed that many review fraudsters adjust their reviews slightly so as not to post near or exactly similar reviews and be easily caught-instead, these sophisticated fraudsters tend to post semantically similar text (i.e. instead of duplicating "the hotel room had an excellent view, " the fraudster might post "the hotel room had a superb view" instead).

(p14.1) Researchers have also focused more on the linguistic features of deceptive reviews, such as using stylistic analysis (number of words, characters, etc.), lexical analysis (number of verbs, nouns, etc.), psycholinguistic analysis (LIWC [72]), and sentiment analysis (emotion, sentiment, etc.). Mukherjee et al. [62] showed that fake reviews were shorter than real reviews, and Ott et al. [70] found that imaginative "faked" writing is typically more exaggerated and consists of more verbs, adverbs, pronouns and pre-determiners. Furthermore, deceptive text tends to have an increased focus on aspects external to the venue being reviewed (more emphasis on family, vacation, business, etc.) [70]. Looking at negative reviews, Ott el at. [69] found that fake negative review writers exaggerate too negatively, including words which communicated negative emotion far more than normal reviews  (a) Aggregate e-commerce rating behavior typically follows the J -shaped curve in blue, whereas review spammers commonly have strongly positively or negatively-biased rating distributions like those in green and red [84]. (b) Fraudulent and non-fraudulent users have bimodal rating distribution [53]. Figures reprinted with permission from [84] and [53].

(p14.2) (terrible, disappointed, etc.). Furthermore, fake reviews eschew the use of pronouns such as "I, " perhaps in order to distance themselves from the negative sentiments. Similar observations were made by Li et al. [54] on fake reviews generated by domain experts. Finally, Harris [33] demonstrated that deceptive opinion spam tends to be on average less readable than truthful reviews (measured by Average Readability Index), and is also more polarized and sentimental than those reviews, supporting previous results.
## (s23) 5.2.5
(p23.0) Debunking characteristics. Once false information spreads, attempts are made to debunk it and limit its spread. Recent research has shown that there is a significant time delay between the spread and its debunking. Zubiaga et al. [121] found that true information tends to be resolved faster than false information, which tends to take about 14 hours to be debunked. Shao et al. [86] came to a similar conclusion-they found a delay of 10-20 hours between the start of a rumor and sharing of its fact-checking contents.

(p23.1) But once debunking information reaches the rumor spreaders, do they stop spreading it or does it 'back-fire', as observed in in-lab settings [68] where corrections led to an increase in misperception? Several empirical studies on web-based false information suggest that debunking rumors is in fact effective, and people start deleting and questioning the rumor when presented with corrective information. Frigerri et al. [30] studied the spread of thousands of rumor reshare cascades on Facebook, and found that false information is more likely to be linked to debunking articles than true information. Moreover, once it is linked, it leads to a 4.4 times increase in deletion probability of false information than when it is not, and the probability is even higher if the link is made shortly after the post is created. Moreover, Zubiaga et al. [121] found that there are more tweets denying a rumor than supporting it after it is debunked, while prior to debunking, more tweets support the rumor. Furthermore, Vosoughi et al. [105] showed that there is a striking difference between replies on tweet containing false information than those containing true information-while people express fear, disgust, and surprise in replies, true information generates anticipation, sadness, joy, and trust. These differences can potentially be used to create early detection and debunking tools.
