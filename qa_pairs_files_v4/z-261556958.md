# Robust Recommender System: A Survey and Future Directions

CorpusID: 261556958 - [https://www.semanticscholar.org/paper/73d4a4e39eafc5884247f6cacf42228476ae3b54](https://www.semanticscholar.org/paper/73d4a4e39eafc5884247f6cacf42228476ae3b54)

Fields: Computer Science

## (s3) Taxonomy of Robustness in Recommender System
(p3.0) Recommender systems function as highly interactive platforms, making them vulnerable to various forms of abnormal data. These anomalies can originate from malicious activities such as injecting fake users and tampering with item information, or from natural noise which typically arises due to human errors or ambiguities in user behavior. For malicious attacks, attackers often aim to promote/nuke specific items or damage the performance of recommender systems. Generally, adversarial scenarios often restrict the attackers' abilities to manipulate a user's historical behavior. There are typically two types of attacks in recommendation scenarios, as shown in Figure 2(b): (1) Item side information modification: Attackers manipulate item side information to artificially augment the popularity of specific items [33], as depicted in the top of Figure 2(b). (2) Fake user injection (shilling attack): Introducing fake users to inflate or deflate the exposure of certain items or degrade the overall performance of the recommender systems [30,120], as shown in the bottom of Figure 2(b). It is essential to note that,  even with limitations on potential attack, several defense mechanisms against interaction-level attacks have been proposed in the literature [24,83,156,158]. For a comprehensive understanding, these defense methodologies will be elaborated upon in the subsequent sections, particularly in Section 3.2.4.

(p3.1) Natural noise mainly stems from user-generated factors such as human errors, uncertainty, and ambiguity in user behavior [151]. For instance, it may manifest in the historical interactions between users and items, such as misclicks or gifts reflecting others' tastes, as illustrated in Figure 2(c). Note that, noise can also occur in user or item side information, such as incorrect personal information or item tags. However, due to the paucity of research addressing these types of noise in the context of recommender systems [82], Figure 2(c) does not show this category.
## (s20) Adjustment of Training Process
(p20.0) Orthogonal Mapping where , is the ground truth rating andˆ, is predicted rating computing by Θ. The 1 -norm offers enhanced robustness against outliers or anomalous data in comparison to the Euclidean distance (i.e., 2 -norm). By integrating the 1 -norm regularization, the model prioritizes essential features over noise, leading to more refined recommendations. In recent times, researchers continue to innovate regularization strategies to improve the robustness of recommender systems in the presence of natural noise. As an illustration, Chen et al. [23] meld Jacobian regularization [68] with the transformer block in sequential recommender systems. This regularization enables a significant reduction in the model's susceptibility to noisy sequences, consequently delivering more consistent and trustworthy recommendations amidst noise.
## (s33) From Perspective of Applications
(p33.0) E-commerce Recommender Systems: E-commerce recommender systems, a crucial feature on platforms like Amazon and eBay, are designed to simplify product discovery for customers [116]. They function based on the historical browsing or purchasing patterns of customers, leaning heavily on user-item interaction data and item-side information. Despite their effectiveness, these systems confront several robustness concerns. One significant issue is the natural noise in user data through unintentional clicks or purchases, which may not necessarily represent the user's genuine preferences [151]. Furthermore, the system's integrity can be compromised by attackers manipulating item side information to push certain products or fabricate user profiles to manipulate a product's exposure [33]. In an e-commerce context, considerations of recommender systems' robustness are comprehensive. Beyond the strategies delineated in Sections 3 and 4, real-world applications necessitate these systems to adapt to the dynamic nature of product trends, cope with extensive product catalogs, and manage the persistent relevance of products over time. Collectively, these requisites pose new challenges in upholding robustness.
## (s40) Mitigating Gap between Defense Assumption and Attack Goal
(p40.0) A significant challenge that arises in the realm of recommender systems is the gap between defense assumptions and the actual objectives of attacks. Attacks, especially shilling attacks, often aim to promote or diminish product exposure, rather than merely undermining recommendation performance. However, many prevailing defense strategies are predicated on the notion that attackers principally aim to degrade the functionality of recommender systems. This is particularly evident in adversarial training scenarios. For instance, He et al. [56] incorporate adversarial perturbations to model parameters during its training phase. Yet, these perturbations often don't align with real-world attack patterns, meaning certain adversarial examples optimized during training might be ineffective for defense. In another approach, Wu et al. [137] positively introduce empirical risk minimizing users to counterbalance the impacts of malicious users, who are often perceived as threats to recommendation quality.
## (s41) Improving Generalization of Defense Methods
(p41.0) The generalization of defense methods in recommender systems presents a considerable challenge. A significant portion of current defense strategies is on specific constraints. For example, the approach proposed by Liu et al. [83] is tailored exclusively for models based on the Factorization Machine, while the methodology introduced by Cao et al. [20] is designed for models grounded in Reinforcement Learning. Moreover, numerous pre-processing detection techniques hinge on predefined features for detecting malicious users [11,74]. Some even resort to specific attack methods for generating supervised data [149,162]. Such specialization limits the applicability of defense methods across diverse scenarios, posing challenges to effectively countering adversarial threats in large-scale, real-world recommender systems.
