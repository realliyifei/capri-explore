# Towards Unified Deep Image Deraining: A Survey and A New Benchmark

CorpusID: 263672076 - [https://www.semanticscholar.org/paper/1a36e49fa5b01bfa2b67ed85beb040027d3b7965](https://www.semanticscholar.org/paper/1a36e49fa5b01bfa2b67ed85beb040027d3b7965)

Fields: Computer Science

## (s15) GAN-based Network Design.
(p15.0) Driven by GAN in the image generation task [98], Qian et al. [28] incorporated a GANbased architecture, where the generative network employs an attentive-recurrent network to generate an attention map.This attention map, along with the input image, is then utilized in a contextual autoencoder to generate a rain-free result.Afterwards, Zhang et al. [48] proposed a conditional GAN-based architecture with a densely-connected generator and a multi-scale discriminator.To achieve heavy rain image restoration, the method of Li et al. [43] consists of a two-stage network architecture: an initial physics-based sub-network followed by a depth-guided GAN refinement sub-network.Based on the consistency between the estimated results of the physical model and the observed image, Pan et al. [61] proposed a GAN-based network constrained by a physics model to remove rain.Motivated by the image disentanglement strategy [105], Ye et al. [71] presented a CycleGAN-based joint rain generation and removal framework by performing the translations on the simpler rain space.Ni et al. [72] put forward a rain intensity controlling GAN, which comprises three sub-networks: a main controlling network, a high-frequency rain-streak elimination network, and a background extraction network, which enables seamless control over rain intensities by leveraging interpolation techniques within the deep feature space.With the popularity of generative models [106], Wang et al. [70] introduced a variational rain generation network to implicitly infer the underlying statistical distribution of rain.
