You are building a scientific question-answering dataset.
You will be given a content extracted from a paper.
You should construct the best question that would be answered by the information that summarizes by (some of) the content. 
Only return the question itself, without anything else.

### The requirements of the question:
1. Unambiguous: clearly framed to avoid follow-up questions for clarification
2. Expert-level and natural: phrased as if asked by a domain expert conducting research
3. Answerable: should be answered by the information in the content 
4. Not overly broad: should not be so vague that it's unclear where to start
5. Standalone and not overly tailored: understandable by any expert without needing specific context or jargon anchored specifically in the given contents
6. Expect a long-form, comprehensive answer: not simply extractive or yes-no questions
7. Less than 20 words

# Given extracted content:
Paper Title: Societal Biases in Language Generation: Progress and Challenges
Section Title: Bias Definitions and Metrics
Extracted section that contain the answer to the question: 
In the context of AI fairness, the term “bias” commonly refers to skews that result in undesirable impacts (Crawford, 2017) and is quantifiable with some metric. There are relatively more existing studies on biases in NLU tasks, where it is arguably simpler to define bias metrics, since we can intuitively compare the accuracy of the task (e.g., coreference resolution, hate speech detection) for different demographics. Language generation tasks often involve stochastic generation of open-ended and lengthy texts, traits that are not directly compatible with traditional algorithmic bias definitions (e.g., equalized odds, equal opportunity, demographic parity (Dwork et al., 2012; Hardt et al., 2016)).
Because of the difficulty in defining metrics, existing works define bias loosely as demographic inequality and use intermediate proxy metrics to comparatively measure bias. Examples include:
• Regard Ratio: negative-neutral-positive regard score ratios of text generated from bias-inducing prompts (Sheng et al., 2019)
• Sentiment Ratio: negative-neutral-positive sentiment score ratios of text generated from African American English (AAE) versus White-Aligned English (WAE) prompts (Groenwold et al., 2020)
• Individual and Group Fairness through Sentiment: comparisons of the sentiment distributions of generated text across demographics and prompts (Huang et al., 2020)
• Gendered Word Co-occurrence Score: mean and standard deviations of the absolute log ratio of probabilities: P(word|female terms) to P(word|male terms) across all words in generated text (Bordia and Bowman, 2019)
There are also metrics for other bias evaluation setups in continuation generation tasks involving sentiment (Shwartz et al., 2020), the ratio of gendered words (Solaiman et al., 2019; Vig et al., 2020; Dinan et al., 2020a), and other novel metrics (Peng et al., 2020; Yeo and Chen, 2020). Studies of biases in transformation generation tasks favor metrics of accuracy in terms of successfully transforming text to have a desired property. We present a more thorough comparison of metrics in Section 5.4.
Bias metrics can also be categorized by how they define associations between demographic group attributes and text. Biases can be towards people described in text, people who produce the text, or people to whom the text is addressed (Dinan et al., 2020b). Most existing works define bias metrics through the first association—these biases are relatively easier to analyze, since both the demographic and the textual signals of bias are encapsulated within the text. There are also works that define biases towards people who produce the text (Groenwold et al., 2020) or people to whom the text is addressed (Sheng et al., 2021b), though there are relatively fewer works that study these latter associations.
Question: In recent studies of natural language generation systems, what measures of social bias have been used recently?

# Given extracted content:
Paper Title: A Survey on Contextual Embeddings
Section Title: Cross-lingual Polyglot Pre-training for Contextual Embeddings
Extracted section that contain the answer to the question: 
Cross-lingual polyglot pre-training aims to learn joint multi-lingual representations, enabling knowledge transfer from data-rich languages like English to data-scarce languages like Romanian. Based on whether joint training and a shared vocabulary are used, we divide previous work into three categories.
Joint training & shared vocabulary. Artetxe and Schwenk (2019) use a BiLSTM encoder-decoder framework with a shared BPE vocabulary for 93 languages. The framework is pre-trained using parallel corpora, including as Europarl and Tanzil. The contextual embeddings from the encoder are used to train classifiers using English corpora for downstream tasks. As the embedding space and the encoder are shared, the resultant classifiers can be transferred to any of the 93 languages without further modification. Experiments show that these classifiers achieve competitive performance on cross-lingual natural language inference, cross-lingual document classification, and parallel corpus mining.
Rosita (Mulcaire et al., 2019) pre-trains a language model using text from different languages, showing the benefits of polyglot learning on low-resource languages.
Recently, the authors of BERT developed a multi-lingual BERT which is pre-trained using the Wikipedia dump with more than 100 languages.
XLM (Lample and Conneau, 2019) uses three pre-training methods for learning cross-lingual language models: (1) Causal language modelling, where the model is trained to predict p(ti|t1, t2, ..., ti−1), (2) Masked language modelling, and (3) Translation language modelling (TLM). Parallel corpora are used, and tokens in both source and target sequences are masked for learning cross-lingual association. XLM performs strongly on cross-lingual classification, unsupervised machine translation, and supervised machine translation. XLM-R (Conneau et al., 2019) scales up XLM by training a Transformer-based masked language model on one hundred languages, using more than two terabytes of filtered CommonCrawl data. XLM-R shows that large-scale multi-lingual pre-training leads to significant performance gains for a wide range of cross-lingual transfer tasks.
Joint training & separate vocabularies. Wu et al. (2019) study the emergence of cross-lingual structures in pre-trained multi-lingual language models. It is found that cross-lingual transfer is possible even when there is no shared vocabulary across the monolingual corpora, and there are universal latent symmetries in the embedding spaces of different languages.
Separate training & separate vocabularies. Artetxe et al. (2019) use a four-step method for obtaining multi-lingual embeddings. Suppose we have the monolingual sequences of two languages L1 and L2: (1) Pre-training BERT with the vocabulary of L1 using L1’s monolingual data. (2) Replacing the vocabulary of L1 with the vocabulary of L2 and training new vocabulary embeddings, while freezing the other parameters, using L2’s monolingual data. (3) Fine-tuning the BERT model for a downstream task using labeled data in L1, while freezing L1’s vocabulary embeddings. (4) Replacing the fine-tuned BERT with L2’s vocabulary embeddings for zero-shot transfer tasks.
Question: How do multilingual NLP models handle joint vocabularies during pretraining?

# Given extracted content:
Paper Title: A Survey on Contextual Embeddings
Section Title: Countering Catastrophic Forgetting
Extracted section that contain the answer to the question: 
Learning on downstream tasks is prone to overwrite the information from pre-trained models, which is widely known as the catastrophic forgetting (McCloskey and Cohen, 1989; d’Autume et al., 2019). Previous work combats this by (1) Freezing layers, (2) Using adaptive learning rates, and (3) Regularization.
Freezing layers. Motivated by layer-wise training of neural networks (Hinton et al., 2006), training certain layers while freezing others can potentially reduce forgetting during fine-tuning. Different layer-wise tuning schedules have been studied. Long et al. (2015) freeze all layers except the top layer. Felbo et al. (2017) use “chain-thaw”, which sequentially unfreezes and fine-tunes a layer at a time. Howard and Ruder (2018) gradually unfreeze all layers one by one from top to bottom. Chronopoulou et al. (2019) apply a three-stage fine-tuning schedule: (a) randomly-initialized parameters are updated for n epochs, (b) the pre-trained parameters (except word embeddings) are then fine-tuned, (c) at last, all parameters are fine-tuned.
Adaptive learning rates. Another method to mitigate catastrophic forgetting is by using adaptive learning rates. As it is believed that the lower layers of pre-trained models tend to capture general language knowledge (Tenney et al., 2019a), Howard and Ruder (2018) use lower learning rates for lower layers when fine-tuning.
Regularization. Regularization limits the fine-tuned parameters to be close to the pre-trained parameters. Wiese et al. (2017) minimize the Euclidean distance between the fine-tuned parameters and pre-trained parameters. Kirkpatrick et al. (2017) use the Fisher information matrix to protect the weights that are identified as essential for pre-trained models.
Question: When finetuning a large language model, what are some recent methods for preventing catastrophic forgetting?

# Given extracted content:
Paper Title: Modeling Language Variation and Universals: A Survey on Typological Linguistics for Natural Language Processing
Section Title: Hand-Crafted Documentation in Typological Databases
Extracted section that contain the answer to the question: 
Typological databases are created manually by linguists. They contain taxonomies of typological features, their possible values, as well as the documentation of feature values for the world’s languages. Major typological databases, listed in Table 1, typically organize linguistic information in terms of universal features and language-specific values. For example, Figure 3 presents language-specific values for the feature number of grammatical genders for nouns on a world map. Note that each language is color-coded according to its value. Further examples for each database can be found in the rightmost column of Table 1.
Some databases store information pertaining to multiple levels of linguistic description. These include WALS (Dryer and Haspelmath 2013) and the Atlas of Pidgin and Creole Language Structures (APiCS) (Michaelis et al. 2013). Among all presently available databases, WALS has been the most widely used in NLP. In this resource, which has 142 typological features in total, features 1–19 deal with phonology, 20–29 with morphology, 30–57 with nominal categories, 58–64 with nominal syntax, 65–80 with verbal categories, 81–97 and 143–144 with word order, 98–121 with simple clauses, 122–128 with complex sentences, 129–138 with the lexicon, and 139–142 with other properties.
Other databases only cover features related to a specific level of linguistic description. For example, both Syntactic Structures of the World’s Languages (SSWL) (Collins and Kayne 2009) and AUTOTYP (Bickel et al. 2017) focus on syntax. SSWL features are manually crafted, whereas AUTOTYP features are derived automatically from primary linguistic data using scripts. The Valency Patterns Leipzig (ValPaL) (Hartmann, Haspelmath, and Taylor 2013) provides verbs as attributes and predicate–argument structures as their values (including both valency and morphosyntactic constraints). For example, in both Mandinka and Sliammon, the verb to laugh has a valency of 1; in other words, it requires only one mandatory argument, the subject. In Mandinka the subject precedes the verb, but there is no agreement requirement; in Sliammon, on the other hand, the word order does not matter, but the verb is required to morphologically agree with the subject.
For phonology, the Phonetics Information Base and Lexicon (PHOIBLE) (Moran, McCloy, and Wright 2014) collates information on segments (binary phonetic features). In the Lyon–Albuquerque Phonological Systems Database (LAPSyD) (Maddieson et al. 2013), attributes are articulatory traits, syllabic structures, or tonal systems. Finally, StressTyp2 (Goedemans, Heinz, and der Hulst 2014) deals with stress and accent patterns. For instance, in Koromfé each word’s first syllable has to be stressed, but not in Cubeo.
Other databases document various aspects of semantics. The World Loanword Database (WOLD) (Haspelmath and Tadmor 2009) documents loanwords by identifying the donor languages and the source words. The Automated Similarity Judgment Program (ASJP) (Wichmann, Holman, and Brown 2016) and the Intercontinental Dictionary Series (IDS) (Key and Comrie 2015) indicate how a meaning is lexicalized across languages: For example, the concept of WORLD is expressed as mir in Russian, and as ārkiśos. i in Tocharian A.
Although typological databases store abundant information on many languages, they suffer from shortcomings that limit their usefulness. Perhaps the most significant shortcoming of such resources is their limited coverage. In fact, feature values are missing for most languages in most databases. Other shortcomings are related to feature granularity. In particular, most databases fail to account for feature value variation within each language: They report only majority value rather than the full range of possible values and their corresponding frequencies. For example, the dominant adjective–noun word order in Italian is adjective before noun; however, the opposite order is also attested. The latter information is often missing from typological databases.
Further challenges are posed by restricted feature applicability and feature hierarchies. Firstly, some features apply, by definition, only to subsets of languages that share another feature value. For instance, WALS feature 113A documents “Symmetric and Asymmetric Standard Negation,” whereas WALS feature 114A “Subtypes of Asymmetric Standard Negation.” Although a special NA value is assigned for symmetric-negation languages in the latter, there are cases where languages without the prerequisite feature are simply omitted from the sample. Secondly, features can be partially redundant, and subsume other features. For instance, WALS feature 81A “Order of Subject, Object and Verb” encodes the same information as WALS feature 82A “Order of Subject and Verb” and 83A “Order of Object and Verb,” with the addition of the order of subject and object.
Question: What are the differences between publicly available linguistic typology databases?

# Given extracted content:
Paper Title: Modeling Language Variation and Universals: A Survey on Typological Linguistics for Natural Language Processing
Section Title: Uses of Typological Information in NLP Models
Extracted section that contain the answer to the question: 
The typological features developed as discussed in § 4 are of significant importance for NLP algorithms. Particularly, they are used in three main ways. First, they can be manually converted into rules for expert systems (§5.1); second, they can be integrated into algorithms as constraints that inject prior knowledge or tie together specific parameters across languages (§ 5.2); and, finally, they can guide data selection and synthesis (§ 5.3). All of these approaches are summarized in Table 3 and described in detail in the following sections, with a particular focus on the second approach.
An interesting example of a rule-based system in our context is the Grammar Matrix kit, presented by Bender (2016), where rule-based grammars can be generated from typological features. These grammars are designed within the framework of Minimal Recursion Semantics (Copestake et al. 2005) and can parse a natural language input string into a semantic logical form.
The Grammar Matrix consists of a universal core grammar and language-specific libraries for phenomena where typological variation is attested. For instance, the module for coordination typology expects the specification of the kind, pattern, and position of a grammatical marking, as well as the phrase types it covers. For instance, the Ono language (Trans–New Guinea) expresses it with a lexical, monosyndetic, pre-nominal marker so in noun phrases. A collection of pre-defined grammars is available through the Language CoLLAGE initiative (Bender 2014).
The most common usage of typological features in NLP is in feature engineering and constraint design for machine learning algorithms. Two popular approaches we consider here are language transfer with selective sharing, where the parameters of languages with similar typological features are tied together (§ 5.2.1), and joint multilingual learning, where typological information is used in order to bias models to reflect the properties of specific languages (see § 5.2.2).
Selective sharing. This framework was introduced by Naseem, Barzilay, and Globerson (2012) and was subsequently adopted by Täckström, McDonald, and Nivre (2013) and Zhang and Barzilay (2015). It aims at parsing sentences in a language transfer setting (see § 3.1) where there are multiple source languages and a single unobserved target language. It assumes that head–modifier relations between PoS pairs are universal, but the order of parts of speech within a sentence is language-specific. For instance, adjectives always modify nouns, but in Igbo (Niger–Congo) they linearly precede nouns, and in Nihali (isolate) they follow nouns. Leveraging this intuition, selective sharing models learn dependency relations from all source languages, while ordering is learned from typologically related languages only.
Selective sharing was originally implemented in a generative framework, factorizing the recursive generation of dependency tree fragments into two steps (Naseem, Barzilay, and Globerson 2012). The first one is universal: The algorithm selects an unordered (possibly empty) set of modifiers {M} given a head h with probability P({M}|h), where both the head and the modifiers are characterized by their PoS tags. The second step is language-specific: Each dependent m is assigned a direction d (left or right) with respect to h based on the language l, with probability P(d|m, h, l). Dependents in the same direction are eventually ordered with a probability drawn from a uniform distribution over their possible unique permutations. The total probability is then defined as follows:
P(n|h,θ1) * Σmi∈M P(mi|h,θ2) * ∏mi∈M σ(w * g(m, h, l, fl)) * 1/||MR||||ML||
In Equation (1), the first step is expressed as two factors: the estimation of the number n of modifiers, parametrized by θ1, and the actual selection of modifiers, parametrized by θ2, with the softmax function σ converting the n values into probabilities. The second step, overseeing the assignment of a direction to the dependencies, is parametrized by w, which multiplies a feature function g(), whose arguments include a typology feature vector fl. The values of all the parameters are estimated by maximizing the likelihood of the observations.
Täckström, McDonald, and Nivre (2013) proposed a discriminative implementation. In this variant, the parsing model is still parametrized by dependency relation probabilities P(M|h), but the ordering probabilities P(d|m, h, l) are replaced by a scoring function score(d|m, h, l) based on feature weights. The score is then incorporated into a discriminative training objective.
Zhang and Barzilay (2015) extended selective sharing to a tensor-based implementation, where typological features are used to adaptively tie parameters across languages. They propose a matrix factorization approach that decomposes the parameter tensors into language-specific and shared components. This approach improves efficiency by reducing the number of parameters and facilitates cross-lingual transfer.
Joint multilingual learning is another approach where typological information is used to bias models to reflect the properties of specific languages. Ammar et al. (2016) introduced a multilingual dependency parser that learns shared representations across languages while incorporating typological features as additional inputs. This model uses a neural architecture with shared and private components, where the shared components capture commonalities among languages, and the private components capture language-specific properties. The typological features are encoded as continuous vectors and are concatenated with other input features.
Tsvetkov et al. (2016) proposed a polyglot language model that incorporates phonological typological features to improve the identification of lexical borrowings and speech synthesis. Their model uses a neural network with phoneme-based input representations and typological features encoded as additional inputs. The typological features help the model to better capture cross-lingual phonetic similarities and improve performance on multilingual tasks.
Typological features can also guide data selection and synthesis. Deri and Knight (2016) used typology-based selection to improve grapheme-to-phoneme conversion. They selected training data from languages that are typologically similar to the target language, resulting in better performance on low-resource languages. 
Agić (2017) proposed a part-of-speech (PoS) divergence metric that uses typological features to select training data for syntactic parsing. This metric measures the divergence between the PoS distributions of the source and target languages, allowing the selection of the most appropriate source languages for training.
Søgaard and Wulff (2012) introduced a typology-based weighing scheme for syntactic parsing, where typological features are used to weigh training instances based on their similarity to the target language. This approach improves parsing accuracy by giving more importance to training instances from typologically similar languages.
Wang and Eisner (2017) proposed a method for synthesizing training data for word order prediction. They used typological features to guide the generation of synthetic treebanks with diverse word orders, which were then used to train a parser. This approach improves the parser's ability to handle a variety of word orders in different languages.
Ponti et al. (2018a) used typological features to preprocess training data for machine translation and sentence similarity tasks. They applied construction-based preprocessing to align the syntactic structures of the source and target languages, resulting in better translation quality and improved sentence similarity scores.
In summary, typological features play a crucial role in enhancing the performance of NLP models. They can be used to design rule-based systems, engineer features and constraints for machine learning algorithms, and guide data selection and synthesis. By leveraging typological information, researchers can improve the robustness and accuracy of NLP systems across a wide range of languages and tasks.
Question: Can you summarize the approaches used to incorporate typological information in downstream NLP tasks?

# Given extracted content:
Paper Title: Efficient Methods for Natural Language Processing: A Survey
Section Title: Sparse Modeling
Extracted section that contain the answer to the question: 
To leverage sparsity for efficiency, many models follow the mixture-of-experts (MoE) concept (Jacobs et al., 1991; Shazeer et al., 2017; Fedus et al., 2022a), which routes computation through small subnetworks instead of passing the input through the entire model. Relevant works on this line include GShard (Lepikhin et al., 2021), Switch Transformer (Fedus et al., 2022b), and ST-MoE (Zoph et al., 2022), which replace the feed forward layers in transformers with MoE layers. More recently, Rajbhandari et al. (2022) scaled transformers up by compressing and optimizing the usage of MoE. Overall, MoE models have been shown to achieve strong performance across several NLP tasks while reducing the overall resource consumption (Sec. 8). For instance, GLaM (Du et al., 2022) used only ∼1 3 of GPT-3’s energy consumption (with additional hardware-based optimization), while Rajbhandari et al. (2022) reached a 5x reduction in terms of training cost. However, MoE models have also exhibited training instabilities in practice, and may require architecture-specific implementation (Zoph et al., 2022; Mustafa et al., 2022).
Another promising direction for exploiting sparse modeling is Sparsefinder (Treviso et al., 2022), which extends the Adaptively Sparse Transformer (Correia et al., 2019) to allow a more efficient attention mechanism by identifying beforehand the sparsity pattern returned by entmax attention—a sparse alternative to (dense) softmax attention (Peters et al., 2019). Finally, sparsity can also be induced via modularity, e.g., by encapsulating task-specific parameters (Ponti et al., 2022).
Question: How can we utilize sparsity to enhance efficiency in designing NLP models?

# Given extracted content:
Paper Title: Neural Approaches to Conversational AI
Section Title: Speaker Consistency
Extracted section that contain the answer to the question: 
It has been shown that the popular seq2seq approach often produces conversations that are incoherent (Li et al., 2016b), where the system may for instance contradict what it had just said in the previous turn (or sometimes even in the same turn). While some of this effect can be attributed to the limitation of the learning algorithms, Li et al. (2016b) suggested that the main cause of this inconsistency is probably due to the training data itself. Indeed, conversational datasets (see Sec. 5.5) feature multiple speakers, which often have different or conflicting personas and backgrounds. For example, to the question “how old are you?”, a seq2seq model may give valid responses such as “23”, “27”, or “40”, all of which are represented in the training data.
This sets apart the response generation task from more traditional NLP tasks: While models for other tasks such as machine translation are trained on data that is mostly one-to-one semantically, conversational data is often one-to-many or many-to-many as the above example implies.5 As one-to-many training instances are akin to noise to any learning algorithm, one needs more expressive models that exploits a richer input to better account for such diverse responses.
To do this, Li et al. (2016b) proposed a persona-based response generation system, which is an extension of the LSTM model of Sec. 5.1.1 that uses speaker embeddings in addition to word embeddings. Intuitively, these two types of embeddings work similarly: while word embeddings form a latent space in which spacial proximity (i.e., low Euclidean distance) means two words are semantically or functionally close, speaker embeddings also constitute a latent space in which two nearby speakers tend to converse in the same way, e.g., having similar speaking styles (e.g., British English) or often talking about the same topic (e.g., sports).
Like word embeddings, speaker embedding parameters are learned jointly with all other parameters of the model from their one-hot representations. At inference time, one just needs to specify the one-hot encoding of the desired speaker to produce a response that reflects her speaking style. The global architecture of the model is displayed in Fig. 5.2, which shows that each target hidden state is conditioned not only on the previous hidden state and the current word embedding (e.g., “England”), but also on the speaker embedding (e.g., of “Rob”). This model not only helps generate more personalized responses, but also alleviates the one-to-many modeling problem mentioned earlier.
Other approaches also utilized personalized information. For example, Al-Rfou et al. (2016) presented a persona-based response generation model, but geared for retrieval using an extremely large dataset consisting of 2.1 billion responses. Their retrieval model is implemented as a binary classifier (i.e., good response or not) using a deep neural network. The distinctive feature of their model is a multi-loss objective, which augments a single-loss model p(R|I, A,C) of the response R, input I, speaker (“author”) A, and context C, by adding auxiliary losses that, e.g., model the probability of the response given the author p(R|A). This multi-loss model was shown to be quite helpful (Al-Rfou et al., 2016), as the multiple losses help cope with the fact that certain traits of the author are often correlated with the context or input, which makes it difficult to learn good speaker embedding representation. By adding a loss for p(R|A), the model is able to learn a more distinctive speaker embedding representation for the author.
More recently, Luan et al. (2017) presented an extension of the speaker embedding model of Li et al. (2016b), which combines a seq2seq model trained on conversational datasets with an autoencoder trained on non-conversational data, where the seq2seq and autoencoder are combined in a multi-task learning setup (Caruana, 1998). The tying of the decoder parameters of both seq2seq and autoencoder enables Luan et al. (2017) to train a response generation system for a given persona without actually requiring any conversational data available for that persona. This is an advantage of their approach, as conversational data for a given user or persona might not always be available. In (Bhatia et al., 2017), the idea of (Li et al., 2016b) is extended to a social-graph embedding model.
While (Serban et al., 2017) is not a persona-based response generation model per se, their work shares some similarities with speaker embedding models such as (Li et al., 2016b). Indeed, both Li et al. (2016b) and Serban et al. (2017) introduced a continuous high-dimensional variable in the target side of the model in order to bias the response towards information encoded in a vector. In the case of (Serban et al., 2017), that variable is latent, and is trained by maximizing a variational lower-bound on the log-likelihood. In the case of (Li et al., 2016b), the variable (i.e., the speaker embedding) is technically also latent, although it is a direct function of the one-hot representation of speaker. (Li et al., 2016b) might be a good fit when utterance-level information (e.g., speaker ID or topic) is available. On the other hand, the strength of (Serban et al., 2017) is that it learns a latent variable that best “explains” the data, and may learn a representation that is more optimal than the one based strictly on speaker or topic information.
Question: Why do conversation models often produce responses that are inconsistent with previous turns?

# Given extracted content:
Paper Title: [PAPER_TITLE]
Section Title: [SECTION_TITLE]
Extracted section that contain the answer to the question: 
[CONTENTS]
Question: 