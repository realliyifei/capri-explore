# A Review on Video-Based Human Activity Recognition

CorpusID: 5664472 - [https://www.semanticscholar.org/paper/f2985c9c03e0113e27a473d5f2b064de10804110](https://www.semanticscholar.org/paper/f2985c9c03e0113e27a473d5f2b064de10804110)

Fields: Computer Science

## (s11) Space-Time Volumes (STV)
(p11.0) The space-time volume (STV) is formed by temporally stacking frames over a video sequence as a 3D cuboid of spatial-temporal shape.Blank et al. [2] propose a method, by stacking segmented silhouette frame-by-frame, to form a 3D spatial-temporal shape, from which the space-time features such as local space-time saliency, action dynamics, shape structure and orientation can be extracted [2].Ke et al. [3] further uses the spatial-temporal shapes for shaped-based matching, including spatial-temporal region extraction and region matching.For region matching, an unsupervised clustering technique is applied to group the video into classes of 3D volumes of consistent appearance.In order to overcome the limitation of shape-based approaches, such as changes in camera view and variability in the speed of actions, Ke et al. [3] also incorporate Shechtman and Irani's flow-based features [51] into the classifier to improve the performance.Moreover, Dollar et al. [11] applies a spatio-temporal interest point detector to find local region of interest in the cuboids of space and time for activity recognition.First, cuboids of spatio-temporally windowed data surrounding a feature point extracted from sample behaviors are clustered to form a dictionary of cuboid prototypes.The histogram of the cuboid types is then used as an activity descriptor for object recognition.Generally, the STV features provide a proper way to combine spatial and temporal information; however, STV features normally require good segmented silhouette and are sensitive to viewpoint and occlusion.
