# Multi-Agent Deep Reinforcement Learning for Multi-Robot Applications: A Survey

CorpusID: 257884080 - [https://www.semanticscholar.org/paper/92c590df020b448c06c8eacb17cbf9c869dd88d8](https://www.semanticscholar.org/paper/92c590df020b448c06c8eacb17cbf9c869dd88d8)

Fields: Mathematics, Engineering, Medicine, Computer Science

## (s13) Coverage and Exploration
(p13.0) The goal of an MRS in a coverage path planning (CPP) application is that every point in the environment is visited by at least one robot while some constraints are satisfied (e.g., no collision among the robots) and user-defined criteria are optimized (e.g., minimizing the travel time) [145]. CPP is one of the most popular topics in robotics. For multirobot coverage, several popular algorithms exist even with performance guarantees and worst-case time bounds [146][147][148][149]. In exploration, however, the objective might not be the same as the multi-robot CPP problem. It is assumed that the sensor radius r > 0, and, therefore, the robots do not need to visit all the points on the plane. For example, the robots might be equipped with magnetic, acoustic, or infrared sensors in ground and aerial applications whereas a group of underwater vehicles might be equipped with water temperature and current measuring sensors. The robots will need GPS for outdoor localization. Such exploration can be used for mapping and searching applications among others [150][151][152]. Constraints such as maintaining wireless connectivity for robots with limited communication ranges might be present [153]. Inter-robot communication can be achieved via ZigBee or Wi-Fi. An example is shown in Figure 6.
