# A Survey on Deep Learning and Explainability for Automatic Report Generation from Medical Images

CorpusID: 245837979 - [https://www.semanticscholar.org/paper/c47611ecff497c01e8bebc1da2ffba4e9b4d9de9](https://www.semanticscholar.org/paper/c47611ecff497c01e8bebc1da2ffba4e9b4d9de9)

Fields: Computer Science, Medicine

## (s12) Domain knowledge.
(p12.0) Although all works used datasets from the medical domain to train their models, which can be considered a form of domain knowledge transfer, some works took special steps to explicitly incorporate additional knowledge from experts into their design. Concretely, we identify two incipient trends in the application of domain knowledge: 1) the use of graph neural networks right after the CNN, providing an architectural bias to guide the model to identify medical concepts and their relations from the images; and 2) enhancing the model's report generation with access to an external template database curated by experts.

(p12.1) KERP [86] incorporates knowledge at the architectural level using graph neural networks. The authors manually designed an abnormality graph and a disease graph, where each node represents an abnormality or disease, and the edges are built based on their co-occurrences in the training set. Some example abnormalities are "low lung volumes" and "enlarged heart size", whereas diseases represent a higher level of abstraction, for example "emphysema" or "consolidation". The information flows from image features (encoded by a CNN) to the abnormality graph, and then to the disease graph, via inter-node message passing. This biases the network to encode the visual information in terms of abnormalities, diseases and their relations. Similarly, Zhang et al. [162] created an observations graph, containing 20 nodes of chest abnormalities or body parts, where conditions related to the same organ or tissue are connected by edges. Their ablation analysis showed some performance gains, thanks to the graph neural network.
## (s17) Classification.
(p17.0) As explained in the Auxiliary Tasks section (5.2.5), many deep learning architectures include multi-label classification to improve performance, providing a set of classified concepts as secondary output. Even though in most papers this kind of output is not presented as an explanation of the report, we consider that its nature could improve the transparency of the model, which is an important way of improving the interpretability in a medical context [134]. By providing this detection information from an intermediate step of the model's process, an expert could further understand the internal process, validate the decision with their domain knowledge and calibrate their trust in the system.
## (s52) Domain knowledge.
(p52.0) Although all works used datasets from the medical domain to train their models, which can be considered a form of domain knowledge transfer, some works took special steps to explicitly incorporate additional knowledge from experts into their design. Concretely, we identify two incipient trends in the application of domain knowledge: 1) the use of graph neural networks right after the CNN, providing an architectural bias to guide the model to identify medical concepts and their relations from the images; and 2) enhancing the model's report generation with access to an external template database curated by experts.

(p52.1) KERP [86] incorporates knowledge at the architectural level using graph neural networks. The authors manually designed an abnormality graph and a disease graph, where each node represents an abnormality or disease, and the edges are built based on their co-occurrences in the training set. Some example abnormalities are "low lung volumes" and "enlarged heart size", whereas diseases represent a higher level of abstraction, for example "emphysema" or "consolidation". The information flows from image features (encoded by a CNN) to the abnormality graph, and then to the disease graph, via inter-node message passing. This biases the network to encode the visual information in terms of abnormalities, diseases and their relations. Similarly, Zhang et al. [162] created an observations graph, containing 20 nodes of chest abnormalities or body parts, where conditions related to the same organ or tissue are connected by edges. Their ablation analysis showed some performance gains, thanks to the graph neural network.
## (s57) Classification.
(p57.0) As explained in the Auxiliary Tasks section (5.2.5), many deep learning architectures include multi-label classification to improve performance, providing a set of classified concepts as secondary output. Even though in most papers this kind of output is not presented as an explanation of the report, we consider that its nature could improve the transparency of the model, which is an important way of improving the interpretability in a medical context [134]. By providing this detection information from an intermediate step of the model's process, an expert could further understand the internal process, validate the decision with their domain knowledge and calibrate their trust in the system.
