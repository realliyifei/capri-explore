# IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING 1 Self-Supervised Learning for Recommender Systems: A Survey

CorpusID: 247794106 - [https://www.semanticscholar.org/paper/2e6654520d8831f1721d4ec2dd1089b5d27f460f](https://www.semanticscholar.org/paper/2e6654520d8831f1721d4ec2dd1089b5d27f460f)

Fields: Computer Science

## (s28) Contrastive Loss
(p28.0) The contrastive loss is a research hotspot in the machine learning community [100], [101], and is also drawing increasing attention in SSR. Generally, the optimization goal of the contrastive loss is to maximize the mutual information (MI) between two representations h i and h j defined as:
## (s31) Pros and Cons
(p31.0) Due to the flexibility to augment data and set pretext tasks, contrastive methods expand rapidly in recent years and reach out most recommendation topics. While contrastive SSR has shown remarkable effectiveness in improving recommendation with lightweight architectures, it is often compromised by the unknown criterion for high-quality data augmentations [57]. Existing contrastive methods are mostly based on arbitrary data augmentations and are selected by trial-and-error. There have been neither rigorous understanding of how and why they work nor rules or guidelines clearly telling what good augmentations are for recommendation. In addition, some common augmentations, which were considered useful, recently even have been proved having a negative impact on recommendation performance [82]. As a result, without knowing what augmentations are informative, the contrastive task may fail.
## (s37) .1 Sample Prediction
(p37.0) Self-training [122], a flavor of semi-supervised learning, is linked to SSL in the Sample Prediction branch. The SSR model is pre-trained on the original data, and potential informative samples for the recommendation task are predicted using the pre-trained parameters as augmented data. These samples are then used to enhance the recommendation task or recursively generate better samples. The difference between SSL-based sample prediction and pure selftraining is that in semi-supervised learning, a finite number of unlabeled samples are available, while in SSL, samples are dynamically generated. Sequential recommendation models often perform poorly on short sequences due to limited user behaviors. To improve the model performance, ASReP [123] proposes to augment the short sequences with pseudo-prior items. Given ordered sequences, ASRep first pre-trains a Transformer-based encoder SASRec [108] in a reverse manner (i.e., from right-to-left) so that the encoder is capable of predicting the pseudo-prior items. An augmented sequence is obtained by appending the fabricated subsequence to the beginning of the original sequence. The encoder is then fine-tuned on the augmented sequences in a left-to-right manner to predict the next item in the original sequence.
## (s51) Theory for Augmentation Selection
(p51.0) While data augmentation is essential for improving SSR performance, most current methods rely on heuristic approaches borrowed from other fields like CV, NLP, and graph learning. However, these approaches cannot be seamlessly transplanted to recommendation to deal with the user behavior data which is tightly coupled with the scenario and blended with noises and randomness. Besides, most methods augment data based on heuristics, and search the appropriate augmentations by the cumbersome trial-anderror. Although there have been some theories that try to demystify the visual view choices in contrastive learning [138], [57], the principle for augmentation selection in recommendation is seldomly studied. A solid recommendationspecific theoretical foundation which can streamline the selection process and free people from the tedious trial-anderror work is therefore urgently needed.
## (s52) Explainable Self-Supervised Recommendation
(p52.0) Despite the promising results achieved by existing SSR models, the mechanisms behind their performance gains are not theoretically justified in most cases. These models are often considered black-boxes, with the primary goal being to achieve higher performance. However, components such as augmentations and self-supervised objectives lack reliable interpretability to demonstrate their effectiveness. Recent experiments in [82] have shown that some graph augmentations, which were previously thought to be informative, may even impair performance. Furthermore, it is unclear whether these models trade-off other properties, such as robustness, for their performance improvements. In order to create more reliable SSR models, it is crucial to understand what they have learned and how the model has been altered through self-supervised training.
