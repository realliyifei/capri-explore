# A Survey on Semi-Supervised Learning for Delayed Partially Labelled Data Streams

CorpusID: 235458184 - [https://www.semanticscholar.org/paper/ff0e0cbb8ff6da3c7077e1d6aad3adbf6d11315a](https://www.semanticscholar.org/paper/ff0e0cbb8ff6da3c7077e1d6aad3adbf6d11315a)

Fields: Computer Science

## (s8) METHODS
(p8.0) Supervised machine learning is defined by using labelled data to train algorithms to predict unseen and unlabelled instances. These unlabelled examples do not influence algorithm anyhow. In most applications, obtaining labelled data is time-consuming and expensive, as labelling often depends upon human annotators. On the other hand, acquiring unlabelled data is an easier task, but these data cannot update supervised models directly. Semi-supervised learning is a paradigm of learning that exploit unlabelled data to leverage models trained with labelled data.

(p8.1) The caveat is that semi-supervised learning methods make strong assumptions about the data or the model [86,103]. For example, one can assume a common underlying density across points belonging to a single class, or a common manifold underlying the points of each class. Figure 2 illustrates two such examples. Deciding which class to assign the test data point is relatively intuitive looking at all data points, but is not clear when considering labelled data points. This highlights precisely the advantages of using the unlabelled points.
## (s10) Self-training
(p10.0) Self-training figures as another commonly used technique for semi-supervised learning. The idea is to let a classifier learn from its previous mistakes and try to reinforce itself. Self-training acts as a wrapper algorithm that takes any arbitrary classifier. Therefore, if we have an existing, fullysupervised learner that is complicated and hard to modify, self-training is an approach worth considering. Self-training has seen its application in natural language processing tasks such as word sense disambiguation [98] and sentiment analysis [62].

(p10.1) In an offline scenario, self-training works as follows. Given a dataset S that consists of a set of labelled data and unlabelled data such that = ∪ , a classifier is trained on and after that used to predict the labels in . The predictions with a high confidence score are assumed true and added to as new labelled data. The process repeats until convergence. When implementing a self-training algorithm, we must ponder the following issues: (i) how to evaluate the confidence of a prediction, and (ii) what the threshold for a "high" confidence score is? These issues remain relevant in an online scenario. Additionally, the learner must be adapted to learn incrementally from labelled and unlabelled instances coming from the stream.
## (s12) Representation Learning
(p12.0) A general strategy for semi-supervised learning is to use unlabelled examples to build a representation of the input data, and then use this representation as input to a model for obtaining predictions. This technique is sometimes referred to as feature learning [6]. The idea is that an improved representation will lead to improved predictions; and since representation learning can naturally be an unsupervised task, training labels are not required. Figure 4 shows an illustration of this strategy.
## (s14) FAIR COMPARATIVE ANALYSIS
(p14.0) Like other machine learning methods, SSL methods should be evaluated in a realistic process to verify their capabilities while considering other applicable methods. Van Engelen and Hoos [86] observed that additional factors have to be considered during evaluation compared to fully supervised learning scenarios.

(p14.1) First and foremost, the question arises of whether the use of a semi-supervised approach yields performance gains compared to supervised methods [71]. Furthermore, a comparison of an SSL method of interest with other SSL methods is required. Similarly to other machine learning methods, the selection of the data for which predictions are evaluated has to be followed by calculating performance measures. Interestingly, due to the latency of ground truth labels, multiple predictions made for a single instance at different times before the arrival of its true label may be considered in the evaluation [45]. The objective of this section is to address the unique aspects of the evaluation of semi-supervised stream mining methods while taking into account non-negligible delays in the availability of ground truth labels.
## (s21) Evaluation based on removing unlabelled instances.
(p21.0) Another way of comparing the performance of a fully supervised method with the performance of an SSL method is based on removing unlabelled instances. Unlike the former approach, under this scenario, the initial data stream has to be a partially labelled data stream Ψ, rather than fully labelled. The objective of the evaluation is to verify the merits of using unlabelled instances by comparing results attained on the partially labelled Ψ with the results provided by a fully supervised method on a fully labelled stream L (Ψ) i.e. the Ψ stream constrained to fully labelled instances. Indeed, the interest in semi-supervised learning is partly driven by the abundance of unlabelled data combined with scarce labelled data. In such cases removing unlabelled instances is acceptable rather than removing already scarce labels.

(p21.1) Among others, Oliver et al. [71] removed unlabelled instances to verify whether the performance obtained by training a model on ∪ (i.e. union of labelled data and unlabelled data) is better than the performance observed on labelled instances alone. Oliver et al. [71] observed that such a baseline is also frequently reported in other studies.
## (s24) Key aspects of the evaluation process.
(p24.0) Let us observe that for the evaluation of SSL methods to be fair, it is important to document all the assumptions and limitations it relies on, but also alternative approaches. Let us first discuss some of the assumptions which may have a potentially significant impact on the interpretation of evaluation results and on the evaluation process needed.

(p24.1) First of all, in some studies, an assumption can be made that the number and distribution of classes in the labelled and unlabelled parts of a data stream are the same. In some tasks, such as binary classification, in which the probability that an instance has no label depends neither on the instance data nor the true label, this approach can be justified. However, as pointed out in Oliver et al. [71], the predictive performance of SSL techniques can degrade drastically when the assumption of equal distribution of classes in the labelled and unlabelled parts of a data set is not met.
