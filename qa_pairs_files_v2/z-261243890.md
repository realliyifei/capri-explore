# Computation-efficient Deep Learning for Computer Vision: A Survey

CorpusID: 261243890 - [https://www.semanticscholar.org/paper/a87947f88519dba980d0f16cdfb78ed09a8e02f0](https://www.semanticscholar.org/paper/a87947f88519dba980d0f16cdfb78ed09a8e02f0)

Fields: Computer Science, Engineering

## (s8) 3) Model Scaling.
(p8.0) On top of designing a single efficient model, it is also important to obtain a family of models that can adapt to varying computational budgets. An important principle for addressing this issue is compound scaling [29,82], which indicates that simultaneously increasing the depth, width and input resolution of a given base model will yield a family of efficient network architectures. Doll√°r et al. [137] further study how to design a proper model scaling rule in terms of the actual runtime. In addition, TinyNets [138] extend this idea to the shrinking of the model size.
## (s14) 1) Marrying 2D and 3D Convolution.
(p14.0) A basic idea is to avoid designing a pure 3D ConvNets, i.e., most of the feature extraction process may be accomplished by the efficient 2D convolution, while 3D convolution is only introduced at several particular positions. From the lens of macro-architecture, this goal can be attained by sequentially mixing 2D and 3D blocks, either first using 3D and later 2D or first 2D and later 3D [162,163]. At the micro-architecture level, the group-wise or depth-width 3D convolution can be integrated in to the transform module of 2D split-transform-merge architecture (Eq. (2)) [164,165].
## (s27) Spatial-wise Dynamic Networks
(p27.0) It has been found that different spatial locations in an image contribute unequally to the performance of vision tasks [234]. However, most existing deep models process different spatial locations with the same computation, leading to redundant computation on less important regions. To this end, spatial-wise dynamic networks are proposed to exploit the spatial redundancy in image data to achieve an improved efficiency. Based on the granularity of adaptive inference, we categorize relative works into pixel level, region level, and resolution level.
## (s28) Pixel-level Dynamic Networks
(p28.0) A typical approach to spatial-wise adaptive inference is dynamically deciding whether to compute each pixel in a convolution block based on a binary mask [235,236,237]. This form is similar to that in layer skipping and channel skipping (Sec. 3.1), except that the gating module is required to output a spatial mask. Each element of this spatial mask determines the computation of a feature pixel. In this way, the mask generators learn to locate the most discriminative regions in image features, and redundant computation on less informative pixels can be skipped.
## (s30) Resolution-level Dynamic Networks
(p30.0) Most existing vision models process different images with the same resolution. However, the input complexity could vary, and not all images require a high-resolution representation. Ideally, low-resolution representations should be sufficient for those "easy" samples with large objects and canonical features. The early work [249] proposes to adaptively zoom input images in the face detection task. The recent resolution adaptive network (RANet) [217] builds a multi-scale architecture, in which inputs are first processed with a low resolution and a small sub-network. Large sub-networks and high-resolution representations are conditionally activated based on early predictions. Instead of using a specialized structure, dynamic resolution network [250] rescales each image with the resolution predicted by a small model and feeds the rescaled image to common CNNs.

(p30.1) Note that different spatial locations are still processed equally in the aforementioned methods. We categorize the relative works in this section since they mainly utilize the spatial redundancy of image inputs for efficient inference.
## (s35) Object Detection
(p35.0) Object detection aims to answer two fundamental questions in computer vision: what visual objects are contained in the images, and where are them [8]? The classification and localization results obtained by object detection usually serve as the basis of other vision tasks, e.g., instance segmentation, image captioning, and object tracking. The algorithms for object detection can be roughly categorized into two-stage (Sec. 4.1.1) and one-stage (Sec. 4.1.2). In the following, we will discuss them respectively from the lens of computational efficiency.
## (s38) 3) Transformer-based Methods. In recent years, N. Carion et al.
(p38.0) propose an end-to-end Transformerbased detection network, DETR [285]. DETR views detection as a set prediction problem, where the results are obtained based on several object queries. Deformable DETR [286] addresses the long convergence issue of DETR by introducing a deformable mechanism to self-attention.
## (s42) Others
(p42.0) In recent years, some new ideas have been proposed to facilitate efficient semantic segmentation. For example, processing deep features with self-attention layers [306,307,308], designing segmentation models with NAS [309,310,311], adjusting the architecture of the decoder conditioned on the inputs [233]. More recently, a considerable number of papers seek to design efficient semantic segmentation models on top of ViTs [312,313,314,315,316]. These works mainly focus on achieving a state-of-the-art performance with as less computational cost as possible.
## (s44) Two-stage Approaches
(p44.0) From the lens of efficiency, a notable milestone of deep-learning-based instance segmentation is the proposing of Mask R-CNN [318]. Mask R-CNN is developed by introducing mask segmentation branches on the basis of Faster R-CNN [272]. It enjoys high computational efficiency by directly obtaining the regions of interest from the feature maps. In contrast, MaskLab [319] improved Faster R-CNN by adding the semantic segmentation and direction prediction paths. To improve the accuracy of Mask R-CNN, MS R-CNN [320] predicts the quality of the predicted instance masks and prioritizes more accurate mask predictions during validation. PANet [321] introduces a path augmentation mechanism to facilitate the bottom-up information interaction of feature maps. HTC [322] proposes a hybrid task cascade framework to learn more discriminative features progressively while integrating complementary features in the meantime.
## (s58) Hardware-aware Model Design
(p58.0) As the practical latency of models can be influenced by many factors other than theoretical computation, the commonly used FLOPs is an inaccurate proxy for network efficiency. Ideally, one should develop efficient models based on specific hardware properties. However, hand-designing networks for different hardware devices can be laborious. Therefore, automatically searching for efficient architectures is emerging as a promising direction. Compared to the traditional NAS methods [31,414], this line of works can generate appropriate models which satisfy different hardware constraints and gain realistic efficiency in practice. For example, ProxylessNAS [54] establishes a latency prediction function based on realistic tests on targeted hardware, and the predicted latency is then directly used as a regularization item in the NAS objective. A similar idea is also implemented by MnasNet [53] to search for efficient models on mobile devices. The following works FBNet [159], FBNet-v2 [415] and OFA [416] have improved NAS techniques.
## (s63) Developing Task-specialized Models
(p63.0) In addition to the architectural advancements in backbone models, tailoring deep learning methodologies to specific computer vision tasks of interest has been demonstrated as crucial. Two research challenges of particular significance in this domain can be identified. Firstly, the exploitation of representations extracted by backbones to efficiently obtain task-specific features is essential, for example, multi-scale features for object detection and multi-path fused features for semantic segmentation. A potential solution to this challenge could involve designing specialized, efficient decoders (e.g., utilizing NAS [311,437]). Secondly, it is important to streamline the multi-stage design of visual tasks (e.g., two-stage object detection [273] and instance segmentation [318] algorithms) to achieve end-to-end paradigms with minimal performance compromises. Additionally, the removal of time-consuming components, such as non-maximum suppression (NMS) [8], is crucial. A promising area for future research may involve the development of an efficient, unified, and end-to-end learnable interface for a majority of prevalent computer vision tasks [438].
## (s65) Leveraging Large-scale Training Data
(p65.0) Contemporary large visual backbone models have exhibited remarkable scalability in response to the increasing volumes of training data [6], that is, the model's performance consistently enhances as more train-ing data becomes accessible. However, it is generally arduous for computationally efficient models with a reduced number of parameters to capitalize on this high-data regime to the same extent as their larger counterparts. For example, the improvements attained by pre-training light-weighted models on expansive ImageNet-22K/JFT datasets are typically inferior to those observed in larger models [6,7,74]. This challenge is similarly experienced by self-supervised learning algorithms, where the methods effective for larger models frequently produce limited gains for smaller models [440,441]. As a result, a propitious avenue of research involves the exploration of effective scalable supervised and unsupervised learning algorithms for light-weighted models, allowing them to reap the benefits of an unlimited amount of data without incurring the expense of acquiring annotations. Some recent works on novel training algorithms have started to preliminarily explore this direction [82,442,443,444,445].
