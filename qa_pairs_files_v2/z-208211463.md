# Guidelines for the Search Strategy to Update Systematic Literature Reviews in Software Engineering

CorpusID: 208211463 - [https://www.semanticscholar.org/paper/88d81fba50ecc372f39c5c0811b3a6e5f2972abc](https://www.semanticscholar.org/paper/88d81fba50ecc372f39c5c0811b3a6e5f2972abc)

Fields: Computer Science

## (s7) SLR for evaluating the guidelines
(p7.0) The first step of our evaluation was to select a suitable SLR, requiring both an original SLR and an update of the original SLR. We wanted an SLR that had a well-motivated update, and we used the results from a separate line of research that investigated how to determine when the update of SLRs is well-motivated [42]. In [42], we identified six SLRs that are well-motivated to update and that have been updated (see Table 4). As can be seen from Table 4, two SLRs (SLR2 and SLR6) include both an original conference publication and an extended journal version of the original SLR. In both cases, the extended journal version, which is published later, covers the same search span used in the conference paper version. SLR2 is the SLR used in Section 4.1, and hence it cannot be selected at this stage. To decide upon which of the other SLR candidates to choose, we formulated a set of criteria to make an informed decision, as described in Section 3.2.

(p7.1) The SLR referred to as SLR4 used forward snowballing to update the original SLR, and hence SLR4 is not suitable for our intended comparison. It leaves four candidate SLRs. The four candidate SLRs all provide sufficient information to find and use the primary studies when doing forward snowballing, and hence the number of candidates is still four. The authors' knowledge concerning computer games and serious games is limited, and therefore SLR1 is not a suitable candidate for that reason. It leaves three candidate SLRs. Emilia Mendes is a co-author of the original SLR for SLR4, and Claes Wohlin is a co-author of the original SLR for SLR6. It leaves only SLR5 as a candidate, and hence SLR5 was selected for replicating the update using forward snowballing and accordingly evaluate the proposed guidelines.
## (s36) Threats to validity
(p36.0) Formulation: As previously stated, our recommended guidelines concerning how to best search for evidence when updating SLRs in SE are based on evidence gathered from investigating an original SLR + one update + two replications of the SLR update, which can be seen as a threat to conclusion validity. Our goal was to formulate our guidelines by using evidence from an existing SLR, its update and corresponding replications, rather than to carry out a formal experiment with a simulated scenario, or to re-do a few SLR updates ourselves. The chosen combination was the only one that had a range of different authors for the original SLR, its update and the replications, and where different search strategies were employed to identify primary studies. A separate evaluation has also been conducted and reported here to mitigate the threat to conclusion validity further.

(p36.1) The diversity of authors helped reduce bias when applying the different search methods to identify primary studies, and the use of different search strategies provided an opportunity for these to be compared; such comparison informed our guidelines. One of the authors in this paper (Mendes) has taken part in and knows the original SLR very well and has cited the original SLR in all the subsequent studies on the topic. Furthermore, many recent studies on the SLR topic were conducted with the participation of this paper's authors (not including Wohlin), who are well aware of (and cited) the original SLR. Therefore, it would seem that such knowledge could have influenced the effectiveness of the snowballing search in updating SLRs. However, studies from the other authors, retrieved using database searches, were also successfully retrieved using forward snowballing, which contradicts the "higher effectiveness" argument.

(p36.2) A potential threat towards the use of forward snowballing for updating systematic literature reviews is if a substantial number of new papers do neither cite the SLR to be updated nor the primary studies in the SLR. The situation may, for example, occur if an SLR is getting "very" old, and the area investigated has changed substantially over time. However, some foundational papers in the area ought to be cited, and hence the risk is judged to be low. Although, if this is suspected to be the case, we would suggest identifying a validation set of papers as a mitigation action. The validation set should include a collection of papers that are known by the authors and ought to be included in the updated SLR. If several of the papers in the validation set are citing neither the SLR nor the primary studies in the SLR, we would suggest that the SLR ought to be managed as a new SLR. When to update an SLR is further discussed in [42].

(p36.3) Evaluation: In this case, the threats to conclusion validity are primarily related to selection bias and evaluator bias. There is a risk that our selection of an SLR for the evaluation may bias the findings towards our guidelines. However, the inclusion criteria for the selected SLR are primarily focused on specific words. Hence, it ought to favour a database search or an indexing service search (such as Google Scholar) and not a citation search. Most inclusion criteria for SLRs regularly include some judgment based on the content, which is not the case for the selected SLR.

(p36.4) A potential threat in literature reviews is publication bias, i.e. papers with certain characteristics are more often published or more often retrieved. For example, there may be a tendency that papers with positive results are more easily published than those with negative results. However, it is probably least sensitive for forward snowballing, since it is a matter of what the papers, included in our update, cite, not that the papers are cited. Thus, forward snowballing depends on the visibility of the original SLR and the primary studies in the original SLR. The publication bias is higher for backward snowballing and database searches. For example, database searches are often done on databases serving some of the most well-established publishers, and hence the publication bias exists also when doing database searches. We found a number of papers not visible in the major databases, which points to that forward snowballing throws a broader net than searching in specific databases. In summary, any publication bias favours the guidelines over other approaches.

(p36.5) Furthermore, there is a risk that the individual researchers become biased, given that there is a vested interest in the guidelines. However, the selection of the SLR for the evaluation based on predefined criteria minimized this threat, and the composition of different teams mitigated the risk of both team and individual bias. Overall, it is judged that the design of the study and the predefined criteria for selecting an SLR to use in the evaluation help minimising the conclusion validity threats.
