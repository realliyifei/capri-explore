# Multimodal Machine Learning: A Survey and Taxonomy

CorpusID: 10137425 - [https://www.semanticscholar.org/paper/6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91](https://www.semanticscholar.org/paper/6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91)

Fields: Computer Science, Medicine

## (s11) ALIGNMENT
(p11.0) We define multimodal alignment as finding relationships and correspondences between sub-components of instances from two or more modalities. For example, given an image and a caption we want to find the areas of the image corresponding to the caption's words or phrases [98]. Another example is, given a movie, aligning it to the script or the book chapters it was based on [252].
## (s24) Hybrid data
(p24.0) In the hybrid data setting two non-parallel modalities are bridged by a shared modality or a dataset (see Figure  3c). The most notable example is the Bridge Correlational Neural Network [167], which uses a pivot modality to learn coordinated multimodal representations in presence of nonparallel data. For example, in the case of multilingual image captioning, the image modality would always be paired with at least one caption in any language. Such methods have also been used to bridge languages that might not have parallel corpora but have access to a shared pivot language, such as for machine translation [148], [167] and document transliteration [100].
