# Combinatorial Algorithms for Subsequence Matching: A Survey

CorpusID: 251889063
 
tags: #Mathematics, #Computer_Science

URL: [https://www.semanticscholar.org/paper/ebd31f5b4aea8e7fba18febee1cc58578dc35a50](https://www.semanticscholar.org/paper/ebd31f5b4aea8e7fba18febee1cc58578dc35a50)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | False |
| By Annotator      | (Not Annotated) |

---

Combinatorial Algorithms for Subsequence Matching: A Survey
10 Oct 2022

Maria Kosche maria.kosche@cs.uni-goettingen.de 
Göttingen University
Germany

Tore Koß tore.koss@cs.uni-goettingen.de 
Göttingen University
Germany

Florin Manea florin.manea@cs.uni-goettingen.de 
Göttingen University
Germany

Stefan Siemer stefan.siemer@cs.uni-goettingen.de 
Göttingen University
Germany

Combinatorial Algorithms for Subsequence Matching: A Survey
10 Oct 2022This is a revision of a paper with the same title, published in EPTCS 367, 2022, pp. 11-27 © M. Kosche, T. Koß, F. Manea & S. Siemer This work is licensed under the Creative Commons Attribution License.
In this paper we provide an overview of a series of recent results regarding algorithms for searching for subsequences in words or for the analysis of the sets of subsequences occurring in a word.

# Introduction

For a string w = w 1 w 2 . . . w n , where each w i is a single symbol from some alphabet Σ, any string v = w i 1 w i 2 . . . w i k with k ≤ n and 1 ≤ i 1 < i 2 ≤ . . . < i k ≤ n is called a subsequence (also called sometimes scattered factor or subword) of w (denoted by v w).

The concept of subsequences is employed in many different areas of computer science. Subsequences appear in areas of theoretical computer science such as, for instance, in formal languages and logics (e. g., where they are used in relation to piecewise testable languages [60,61,38,39,40], or to define the subword order and downward closures [34,47,46,66]) or in combinatorics on words, where they are used to define the notions of binomial equivalence and binomial complexity, or to introduce the notion of subword histories, [55,26,49,48,57,53,56]; however, subsequences are also used in more applied settings, e. g., for modelling concurrency [54,58,16], or in database theory (especially event stream processing [5,33,67]). Moreover, many classical algorithmic problems are based on subsequences, e. g., longest common subsequence [6] or shortest common supersequence [52], and, in particular, such problems have recently regained interest in the context of fine-grained complexity (see [14,15,1,2]).

There are two main types of algorithmic problems for subsequences investigated in the literature. Firstly, the class of matching problems, where one has to decide whether a string v is a subsequence of a string w, i. e., whether v w (the name matching comes from the fact that the string v can be seen as a pattern that has to be identified, or matched, within the string w). Secondly, the class of analysis problems, which are concerned with the algorithmic analysis of the sets Subseq k (w) of all length-k subsequences of a given string w. Some more concrete examples of analysis problems are the following: for given string w ∈ Σ + and integer k ∈ N, we want to decide whether Subseq k (w) = Σ k (the universality problem), or, for an additional string v, we want to decide whether Subseq k (v) = Subseq k (w) (the equivalence problem). For classical subsequences (as defined above), the matching problem is trivial, while the analysis problems are well-investigated and relatively well-understood. In particular, the equivalence problem was introduced by Imre Simon in his PhD thesis [60], and was intensely studied in the combinatorial pattern matching community (see [35,31,62,63,19,23] and the references therein), before being optimally solved in 2021 [32]. The work on these problems was extended to classes of constrained subsequences, for which very different results were obtained, by fundamentally different methods [21,45].

In this work we overview a series of algorithmic, combinatorial, and complexity theoretic results concerning subsequences. For their original presentation, please see [9,20,23,32,44,45,21] and the references therein.

Going a bit more into detail, the results surveyed here cover different settings and algorithmic frameworks regarding subsequences, ranging from the classical (and well motivated) case of unrestricted subsequences to some novel ones, where constrained subsequences appear.

For the case of classical subsequences, the accent of our presentation is put on analysis problems (as matching is trivial). We survey results related to the equivalence and universality problems originally presented in [9,20,23,32,44].

For the case of constrained subsequences, we feel that some more discussion about their motivation and origin would be in order. So, the notion of constrained subsequences is rooted in the following main idea: it seems unrealistic for particular scenarios to consider occurrences of v in w where the positions of w that are matching, respectively, the first and last symbol of v (or, similarly, the positions of w matching consecutive symbols of v) are very far away from each other. It seems indeed questionable, for instance, whether considering an alignment of DNA-sequences v and w where the nucleotides of v are spread over a factor of w which is several times longer than v itself (or, alternatively, where the nucleotides of v occur in w with arbitrarily long gaps between them) is still meaningful. Similarly, but in a totally different context, when observing a computation, which is represented by a string, one might be more interested in its recent history (and the sequences of events occurring there), rather than analysing the entire computation. Or, in the same setting, one might be interested in sequences of events which occur in a computation, such that the computation executed between two events in such a sequence is constrained by some precise rules.

In a similar situation, occurring this time in the context of complex event processing [5,33,67], it might be desirable to describe the situation that between the events of a job A, only events associated to a job B appear (e. g., due to unknown side-effects this leads to a failure of job A). In this case, we are interested in occurrences of a string v as a subsequence of a string w such that the gaps between the positions of w which correspond to the symbols of v, only contain symbols from a certain subset of the alphabet (i. e., the events associated to job B). Moreover, in [43], the authors introduce a query class for event streams, which is essentially based on subsequences with constraints in the form of upper and lower bounds on the length of the gap occurring between consecutive symbols (i.e., events) in the occurrences of the string (i.e., job) v in the larger string/stream w.

Moreover, the fact that in many practical scenarios (including those mentioned above) one has to process streams, which, at any moment, can only be partly accessed by our algorithms, enforces even more the idea that the case where one is interested in subsequences occurring arbitrarily in a given stream (or long string) is less realistic and less useful than the case where one is interested in the subsequences occurring in bounded ranges of the respective stream/string (which can be entirely accessed and processed at any moment by our algorithms). So, wrapping this up, in practice, it makes sense to reason both about the length and the actual content of gaps induced by an occurrence of v in w, as well as about the length of the factor (or range) of w in which such an occurrence is contained.

To this end, in our overview, for the case of constrained subsequences, we will present a series of algorithmic results for problems related to the case of subsequences in which, given strings w and v, constraints on either the factors of w in which v may occur as subsequence (called bounded range constraints, see [45]) are imposed, or constraints on the factors of w occurring between two consecutive letters of an occurrence of v in w (called gap constraints, see [21]) are imposed. In this setting, we overview results regarding the matching problem (which is no longer trivial) as well as results on analysis problems. For the original presentation of these results, as well as for a more detailed overview of the motivations for these particular classes of constrained subsequences and related work, we refer to [45,21]. This paper is structured as follows. We first give a series of general definitions and preliminaries related to subsequences in Section 2. In Section 3, the matching problem is covered and results are presented for all three cases, the classical subsequences setting, for subsequences occurring in bounded ranges, and for subsequences with gap constraints. Section 4 covers the analysis problems in respective subsections, namely the universality problem in Section 4.1, the analysis of absent subsequences in Section 4.2, and the equivalence problem in Section 4.3. We conclude with a section covering a series of related problems as well as directions for future work. The powers of a word w are defined as: w 0 = ε and w k+1 = ww k , for k ≥ 0. Define w ω as the right infinite word which has w n as prefix for all n ≥ 0. The positive integer p ≤ |w| is a period of a word w if w is a prefix of w[1 : p] ω .


# Basic Definitions

We now recall the main notion of this paper, namely the notion of subsequence.
Definition 1 (Subsequence). A word v is a subsequence of length k of w (denoted v ≤ w), where |w| = n, if there exist positions 1 ≤ i 1 < i 2 < . . . < i k ≤ n, such that v = w[i 1 ]w[i 2 ] · · · w[i k ].
The set of all subsequences of w is denoted by Subseq(w).

In the following, we will also discuss some other concepts regarding (classical) subsequences, namely subsequences with gap constraints, (partitioned into length constraints, regular constraints, or combined length and regular constraints) for the factors of w between two consecutive letters of v, and subsequences within bounded ranges (where we consider, similar to a sliding window scenario, an integer p an integer p as an upper bound on the range of a word in which a subsequence may occur).

Firstly, we introduce subsequences with gap constraints, or gapped subsequences. This presentation is based on [21]. We begin by defining the notion of gap constraints. We recall that for a string w, an embedding is a function e : Definition 2 (Gap constraints). An ℓ-tuple of gap constraints is a tuple gc = (C 1 ,C 2 , . . . ,C ℓ ) with C i ⊆ Σ We generally distinguish the following types of gap constraints:

• regular constraints if C i ∈ REG for every i ∈ [k − 1]. For every i ∈ [k − 1], the regular constraint C i is represented by a deterministic finite automaton (for short, DFA) A i accepting it.
• length constraints if, for every i ∈ [k − 1], there are L − (i), L + (i) ∈ N ∪ {0, +∞} with L − (i) ≤ L + (i), such that C i = {v ∈ Σ * | L − (i) ≤ |v| ≤ L + (i)}.
Length constraints are succinctly represented by pairs of numbers (L − (i), L + (i)), i ∈ [k − 1], in binary encoding.

• reg-len constraints if, for every i ∈ [k − 1], C i is the conjunction of a regular constraint C ′ i and a length constraint (L − (i), L + (i)), i. e.,
C i = C ′ i ∩ {v ∈ Σ * | L − (i) ≤ |v| ≤ L + (i)}. Such constraints are represented by ((L − (i), L + (i)), A ′ i ), where A ′ i is a DFA accepting C ′ i .
We move now further, and introduce the concept of p-subsequence, or subsequences occurring within bounded ranges. For this presentation, we follow [45]. Once these main concepts introduced, we can now discuss several preliminaries which are necessary for understanding the surveyed results.

Computational Model. In general, the problems surveyed here are of algorithmic nature. The computational model used to describe the algorithms is the standard unit-cost RAM with logarithmic word size: for an input of size N, each memory word can hold log N bits. Arithmetic and bitwise operations with numbers in [1 : N] are, thus, assumed to take O(1) time. In all the problems, it is assumed that we are given a word w or two words w and u, with |w| = n and |v| = m (so the size of the input is N = n + m), over an alphabet Σ = {1, 2, . . . , σ }, with 2 ≤ |Σ| = σ ≤ n + m. That is, the processed words are assumed to be sequences of integers (called letters or symbols), each fitting in O(1) memory words. This is a common assumption in string algorithms: the input alphabet is said to be an integer alphabet. For more details see, e. g., [18].

The algorithmic results (upper bounds) that are surveyed here are complemented by a series of lower bounds. In those cases, the results hold already for the case of constant alphabets. That is, they hold already when the input of the problem is restricted to words over an alphabet
Σ = {1, 2, . . . , σ }, with σ ∈ O(1).
Complexity Hypotheses. For the series of conditional lower bounds for the time of complexity of the considered problems, we now recall some standard computational problems and complexity hypotheses regarding them, respectively, on which the proofs of lower bounds are based.

The Satisfiability problem for formulas in conjunctive normal form, CNF-SAT, gets as input a Boolean formula F in conjunctive normal form as a set of clauses
F = {c 1 , c 2 , . . . , c m } over a set of variables V = {v 1 , v 2 , . . . , v n }, i. e., for every i ∈ [m], we have c i ⊆ {v 1 , ¬v 1 , . . . , v n , ¬v n }. The question is whether F is satisfiable. By k-CNF-SAT, we denote the variant where |c i | ≤ k for all i ∈ [m].
The Orthogonal Vectors problem (OV for short) gets as input two sets A, B each containing n Booleanvectors of dimension d, where d ∈ ω(log n). The question is whether there exist two vectors a ∈ A and b ∈ B which are orthogonal, i. e.,
a[i] · b[i] = 0 for every i ∈ [d].
We shall use the following algorithmic hypotheses based on CNF-SAT and OV that are common for obtaining conditional lower bounds in fine-grained complexity. In the following, poly is any fixed polynomial function:

-Exponential Time Hypothesis (ETH) [37,50]: 3-CNF-SAT cannot be solved in time 2 o(n) poly(n + m).

-Strong Exponential Time Hypothesis (SETH) [36,65]: For every ε > 0 there exists k such that k-CNF-SAT cannot be decided in O(2 n(1−ε) poly(n)) time.

The following result, which essentially formulates the Orthogonal Vectors Hypothesis (OVH), can be shown (see [12,13,65]).

Lemma 4. OV cannot be solved in O(n 2−ε poly(d)) time for any ε > 0, unless SETH fails.


# Matching problems

The matching problem MATCH for subsequences is to decide, given two words u, w ∈ Σ * with |u| = m and |w| = n, whether u is a subsequence of w. In the general case, that is without further restrictions like gap constrains or bounded ranges, it is quite easy to answer: if we go left-to-right through w and greedily search for the letters u [1] to u[m], we answer positively if and only if we find all letters from u in w. This greedy approach obviously is correct and works in linear time O(n).

Considering bounded range constraints. If we consider subsequences occurring within bounded ranges, the problem changes as follows: for u, w as above and p ∈ N with p ≥ m, we need to decide whether u is a p-subsequence of w. Simply using the greedy approach above for each range still works, but is not optimal anymore (it has O(np) complexity). However, by reading the word w left to right and maintaining an array which saves for every i ∈ [1 : m] the length of the shortest suffix of the current range w[t − p + 1 : t] containing u[1 : i] (if there is any) and updating the array when we increment t (i. e., read the a new letter of the word w), we can reduce the time complexity to O(mn) (see [45] for a more detailed description of the algorithm).


## Theorem 5. MATCH in bounded ranges can be solved in O(mn) time.

The algorithm presented in [45] can be, in fact, seen as an algorithm in the sliding window model with window of fixed size p (see [29,28,30]). More precisely, it scans the stream w left to right and, when the t th letter of the stream is scanned, it reports whether the window w[t − p + 1 : t] contains u as a subsequence. In other words, it reports whether the string w[t − p + 1 : t] is in the regular language L u = {v | u ≤ v}. The problem of checking whether the factors of a stream scanned by a sliding window are in a regular language was heavily investigated, see [27] and the references therein. In particular, from the results of [29] it follows that, for a constant u (i. e., u is not part of the input), the problem of checking whether the factors of a stream scanned by a sliding window are in the language L u cannot be solved using o(log p) bits when the window size is not changing and equals p. We note that the algorithm of [45] is optimal from this point of view: if u is constant and, thus, m ∈ O(1), it uses O(log p) bits to store the maintained data structures.

Moreover, the algorithm presented in [45] is optimal also from the time complexity point of view, unless OVH fails.
Theorem 6. MATCH in bounded ranges cannot be solved in time O(n h m g ), where h + g = 2 − ε with ε > 0, conditional to OVH.
Considering gap constraints. For subsequences with gap constraints, the matching problem is to decide, for given strings u, w, and gap constraints gc with |gc| = |u| − 1, whether u is a gc-subsequence of w (i. e., whether u ∈ Subseq(gc, w)).

The results from [21] give us the following upper bound in the case of reg-len constraints where gc denotes the given gap constraints, states(gc) denotes the total number of states of the DFAs that represent the regular constraints, size(gc) is the total size of the automata defining these constraints and nz(gc) is the number of gaps which are not equal to {ε}.

Theorem 7. MATCH with reg-len constraints can be solved in O(|w| states(gc) + size(gc)) time.

The proof given in [21] is based on a dynamic programming approach, which is implemented in the respective time complexity with the help of some relatively involved data structures, and implies that when considering only length constraints or only regular constraints (and not combined reg-len constraints), the following rectangular upper bounds hold.
Corollary 8. (1)
. MATCH with length constraints can be solved in O(|w| nz(gc)) time. (2). MATCH with regular constraints can be solved in O(|w| states(gc) + size(gc)) time.

When gc only consists of constraints that are {ε} or Σ * , respectively, the case of string matching or, respectively, subsequence matching is modelled, which can be solved in linear time. As far as length constraints are concerned, it seems that non-trivial upper bounds lead to an increase in the difficulty of the MATCH problem; a particularly efficient approach for subsequences with general length constraints is given in [11] but in the worst case it still has rectangular complexity. However, even when non-trivial length upper bounds are used, there are still some simpler particular cases. For instance, when working with strings with don't cares (or partial words), where each gap has a fixed length (i. e., the lower and upper bounds are the same), Match can be solved in time O(|w| log |p|) [17].

A reduction from the OV problem is given in [21], which shows that MATCH for non-trivial length or regular constraints is more difficult than MATCH for the classical subsequences scenario. The following conditional lower bounds for subsequences with length and/or regular gap constraints are obtained. 


# Analysis problems

When considering algorithmic analysis problems related to subsequences, typical research questions are concerned with structural properties of the set of all (constrained) subsequences occurring in a word, as well as with finding minimal (w. r. t. length or w. r. t. the subsequence relation) missing subsequences of a word.


## Universality

Generally speaking, the universality problem UNI is to decide, for given integer k and string w ∈ Σ * with |w| = n, whether the set of subsequences of length k of w equals the set Σ k . For convenience, we will also consider in the following the complement problem, i. e., non-universality problem (NUNI).
Definition 11. A word w ∈ Σ * is called k-subsequence universal (w. r. t. Σ, for short k-universal), for k ∈ N, if Subseq k (w) = Σ k . We abbreviate 1-universal by universal. The universality-index ι(w) of w ∈ Σ * is the largest k such that w is k-universal.
If ι(w) = k then w is ℓ-universal for all ℓ ≤ k. Notice that k-universality is always w. r. t. a given alphabet Σ: the word abcba is universal for Σ = {a, b, c} but it is not universal for Σ ∪ {d}.

The notion of k-universality coincides to that of k-richness introduced in [39,40]. We use the name k-universality rather than k-richness, as richness of words is also used with other meanings, see, e. g., [22,51]. We recall the arch factorisation, introduced by Hebrard [35].

Definition 12 ([35]). For w ∈ Σ * the arch factorisation of w is w = ar w (1) · · · ar w (k)r(w) for some k ∈ N 0 where ar w (i) is universal, the last letter of ar w (i), namely ar w (i)[| ar w (i)|], does not occur in ar w (i)[1 : | ar w (i)| − 1] for all i ∈ [1 : k], and alph(r(w)) ⊂ Σ. The words ar w (i) are called arches of w, r(w) is called the rest.

If the arch factorisation of w contains k ∈ N 0 arches, then ι(w) = k. The arch factorization of a word w can be computed in linear time and, as such, we could check in linear time if a given word w is kuniversal (see, e. g., [9]). The following immediate theorem based on the work of Simon [61] completely characterises the set of k-subsequence universal words, based on Hebrard's arch factorisation. This property gives us some insight in the combinatorial structure of the subsequences occurring inside words. For instance, it can be used to directly compare two words w. r. t. their universality index, or serve as a starting point for the analysis of the set of missing subsequences of words. See, for instance, [9,20,25,24,21,45].

The Edit Distance to k-Subsequence Universality. As a natural extension to the universality property from above, as one can do for almost every string property, we can ask how far is a word from fulfilling that property. That is, we can ask for the distance from a give string to the set of strings which fulfill that property, with respect to some string metric. More precisely in this section, we discuss how to compute the minimal number of edits we need to apply to a word w, with |w| = n, alph(w) = Σ, with universality index ι(w), so that it is transformed into a word with universality index k, w. r. t. the same alphabet Σ. The edits considered are insertion, deletion, substitution, and the number we want to compute can be seen as the edit distance between w and the set of k-universal words over Σ.

The first thing that we can see is that, if we want to obtain a k-universal word with k > ι(w), then it is enough to consider only insertions. Indeed, deleting a letter of a word can only restrict the set of subsequences of the respective word, while in this case we are interested in enriching it. Substituting a letter might make sense, but it can be simulated by an insertion: assume one wants to substitute the letter a on position i of a word w by a b. It is enough to insert a b next to position i, and the set of subsequences of w is enriched with all the words that could have appeared as subsequences of the word where a was actually replaced by b. We might, in the end, have some extra words in the set of subsequences, which would have been eliminated through the substitution, but it does not affect our goal of reaching k-universality.

If we want to obtain a word with universality index k, for k < ι(w), then it is enough to consider only deletions. Assume that we have a sequence of edits that transforms the word w into a word w ′ with universality index k. Now, remove all the insertions of letters from that sequence. The word w ′′ we obtain by executing this new sequence of operations clearly fulfils ι(w ′′ ) ≤ ι(w ′ ). Further, in the new sequence, replace all substitutions with deletions. We obtain a word w ′′′ with a set of subsequences strictly included in the one of w ′′ , so with ι(w ′′′ ) ≤ ι(w ′′ ). As each deletion changes the universality index by at most 1, it is clear that (a prefix of) this new sequence of deletions witnesses a shorter sequence of edits which transforms w into a word of universality index k.

So, to increase the universality index of a word it is enough to use insertions and to decrease the universality index of a word it is enough to use deletions. Nevertheless, one might be interested in what happens if we only use substitutions. In this way, we can both decrease and increase the universality index of a word. Moreover, one can see the minimal number of substitutions needed to transform w into a kuniversal word as the Hamming distance between w and the set of k-universal words. In the following we list all of the resulting theorems individually. All of the results are achieved by a dynamic programming approach combined with a sophisticated analysis of the combinatorial properties of k-universal words and some new specialized data structures. See the full proofs and algorithms in [20]. Universality and bounded range constraints. After looking into the (unrestricted) subsequence universality of a word and in particular the edit distance between a word and the set of k-universal words, we will now discuss the case of subsequences occurring in bounded ranges or words. In this case, the universality problem UNI asks to decide for given word w, alphabet Σ, and integers k and p, with |w| = n and k ≤ p ≤ n, whether p-Subseq k (w) = Σ k .

Surprisingly, in this case, we get an intractability result, complemented by a fine-grained lower bound (see [45]). For convenience, this computational hardness result is stated for NUNI. Theorem 17. NUNI for bounded ranges is NP-hard and cannot be solved in subexponential time 2 o(k) poly(k, n) unless ETH fails.

The proof for this result involves the reduction from the related problem NUNI for partial words, which asks to decide, for given list of partial words S = {w 1 , . . . , w k } over {0, 1}, where every partial word has same length L, whether there exists a word v ∈ {0, 1} L such that v is not compatible with any of the partial words in S (while in this context, two partial words u and v of the same length are compatible if, for all i ∈ [|u|], we have that either u


## [i] = v[i] or at least one of u[i] or v[i] is undefined).

Universality and gap constraints. For the case of subsequences with gap constraints, [21] presents a series of results starting with a brute force upper bound which can be derived from the results for MATCH for subsequences with gap constraints. Theorem 18. (1) The problem UNI for subsequences with length (or reg-len) constraints can be solved in time O(|Σ| k nz(gc)ℓ) (respectively, O(|Σ| k states(gc)ℓ)), where ℓ = max{|w|, |w ′ |}.

(2) For the case of a fixed alphabet Σ (i. e., |Σ| ∈ O(1)), the problem UNI Σ with length (or reg-len) constraints can be solved in time 2 O(k) nz(gc)ℓ (respectively, 2 O(k) states(gc)ℓ), where ℓ = max{|w|, |w ′ |}).

At the same time, the following lower bound (again, given for NUNI) shows that it is unlikely for significantly faster algorithms to exist.

Theorem 19. For every fixed alphabet Σ with |Σ| ≥ 3, NUNI Σ with length constraints is NP-complete, even if all length constraints are (1,5). Moreover,

• it cannot be solved in subexponential time 2 o(k) poly(|w|, k)) (unless ETH fails),

• it cannot be solved in time O(2 k(1−ε) poly(|w|, k)) (unless SETH fails).

For a fixed alphabet Σ with |Σ| = 2, NUNI Σ with length constraints is NP-complete even if each length constraint is (0, 0) or (3,9) (meaning that each gap is either empty or has length between 3 and 9).


## Absent Subsequences

In the previous sections we surveyed a series of results related to deciding whether a string contains as subsequences all strings of length up to k. Now, we focus on understanding the strings which do not occur as subsequences of a given input string.

So, in this subsection we summarize a series of algorithmic and complexity results related to decision problems concerning shortest and, respectively, minimal absent subsequences. Once more, we begin with the classical case, and then discuss the case of subsequences occurring within bounded ranges.

We begin with several definitions.


## Definition 20 (-Absent subsequences). A word v is an absent subsequence of w if v is not a subsequence of w. An absent subsequence v of w is a minimal absent subsequence (for short, MAS) of w if every proper subsequence of v is a subsequence of w. We will denote the set of all MAS of w by MAS(w). An absent subsequence v of w is a shortest absent subsequence (for short, SAS) of w if |v| ≤ |v ′ | for any other absent subsequence v ′ of w. We will denote the set of all SAS of w by SAS(w).

Absent subsequences in words. Note that, in general, any shortest absent subsequence of a word w has length ι(w) + 1, where ι(w) is the universality index of w. This already establishes a connection to the results presented in previous section. Moreover, we notice that we can easily find at least one SAS (and therefore an MAS) of w from its arch factorisation: for 1 ≤ i ≤ ι(w) let u i = ar w (i)[| ar w (i)]| be the last letter of the i th arch of w and u ι(w)+1 be any letter not occurring in r(w), then u = u 1 · · · u ι(w)+1 is an SAS of w. By refining this approach we can, for given w ∈ Σ * , build in linear time a data structure allowing us to identify a succinct representation of a SAS of any factor w[i : j] of w in constant time (and effectively output this SAS in time proportional to its length). Given u, w ∈ Σ * the problem to check whether u is an SAS or, respectively, an MAS of w is decidable in linear time (see [44]).


## Theorem 22. Given a word w of length n and a word u of length m, we can test in O(n) time whether u is an SAS or MAS of w.

In both cases, we check trivially whether u is absent from w or not. In the case we want to decide whether u is an SAS of w we simply check that |u| = ι(w) + 1. When checking whether u is an MAS we calculate the shortest prefixes of w containing u For minimal absent subsequences the problem becomes more complicated but we can still construct data structures encoding MAS(w), visualized by a directed acyclic graph called MAS-DAG, in O(n 2 σ ) time. It is worth noting here that the lexicographic smallest MAS of w is a |w| a +1 where a is the lexicographic smallest letter of Σ which occurs in w. 


## We can efficiently enumerate (with polynomial delay) all the MAS of w.

In the end of this subsection we present a result allowing us to check whether a word u can be extended to an MAS, that is checking whether there is an MAS of w having u as a prefix, and if possible calculates the shortest such MAS. Absent subsequences and bounded range constraints. We continue by considering the case when bounded range restrictions are added in the study of absent subsequences. That is, we are only interested in subsequences not occurring in any factor of fixed length p of w (but, which may occur in longer factors). We call such a sequence absent p-subsequence. Similarly we define the notions of shortest absent p-subsequences p-SAS and minimal absent p-subsequences p-MAS.


## Definition 26 (-Absent p-subsequence). The word v is an absent p-subsequence of w if v / ∈ p-Subseq(w). We also say v is p-absent from w. The word v is a p-SAS (shortest absent p-subsequence) of w if v is an absent p-subsequence of w of minimal length. The word v is a p-MAS (minimal absent p-subsequence) of w if v is an absent p-subsequence of w but all subsequences of v are p-subsequences of w.

Adding the bounded range restriction to absent subsequences complicates significantly some of the algorithmic tasks which were efficiently solved in the original setting. In particular, checking whether u is not a p-SAS of w is NP-hard and cannot be computed in subexponential time (conditional to ETH).


## Theorem 27. Deciding whether v is not a p-SAS of w is NP-hard and cannot be solved in subexponential time 2 o(k) poly(k, n, m) unless ETH fails.

We denote by pMAS the decision problem to check for given strings v, w ∈ Σ * whether v is a p-MAS of w. pMAS is still decidable in polynomial time O(|u||w|), which is also optimal unless OVH fails. An optimal algorithm is given in [45]. Similarly to the case of Theorem 5, the algorithm proposed in [45] can be seen as working in the sliding window model, with window of fixed size p. If, as in the case of the discussion following Theorem 5, we assume u (and m) to be constant, we obtain a linear time algorithm. However, its space complexity, measured in memory words, is O(p) (as we need to keep track, in this case, of entire content of the window). In fact, when m is constant, it is easy to obtain a linear time algorithm using O(1) memory words (more precisely, O(log p) bits of space) for this problem: simply try to match u and all its subsequences of length (m − 1) in w simultaneously, using the algorithm from Theorem 5. Clearly, u is a p-MAS if and only if u is not a subsequence of w, but all its subsequences of length m − 1 are. However, the constant hidden by the O-notation in the complexity of this algorithm is proportional with m 2 . It remains open whether there exists a (sliding window) algorithm for pMAS both running in O(mn) time (which is optimal, conditional to OVH) and using only O(log p) bits (which is also optimal for sliding window algorithms, see [29]).

Complementing the discussion above, one can show that it is possible to construct in linear time, for words u, w and integer p ∈ N, a string w ′ such that deciding whether u is a p-MAS of w ′ is equivalent to deciding whether u is a p-subsequence of w, so solving pSubSeqMatch for the input words u and w. Hence, the lower bound from Theorem 6 carries over, and the algorithm announced in Theorem 28 is optimal (conditional to OVH) from the time complexity point of view.

Interestingly, the study of absent subsequences was not considered yet for the case of subsequences with gap constraints.


## Equivalence

The equivalence problem for subsequences EQUI is to decide, for given strings v, w ∈ Σ * with |v| = m and |w| = n as well as an integer k, whether the sets of subsequences of length at most k of v equals the respective set of w, Subseq ≤k (v) = Subseq ≤k (w).

EQUI, and its maximization variant in which one looks for the largest k for which EQUI with inputs v, w, k is true, were among the most studied problems in relation to subsequences. In particular, Hebrard [35] presented the aforementioned maximization problem as computing a similarity measure between strings and mentions a solution of Simon [59] for this problem which runs in O(|Σ|nm) (the same solution is mentioned in [31]). Hebrard improves this (see [35]) in the case when Σ is a binary alphabet: given two bitstrings w and v, one can find the maximum k for which Subseq ≤k (v) = Subseq ≤k (w) in linear time. However, the problem of finding optimal algorithms for both EQUI and its maximization variant, in the case of general alphabets, was left open in [59,35] as the methods used in the latter paper for binary strings did not seem to scale up. In [31], Garel approaches the maximization problem and presents an algorithm based on finite automata, running in O(|Σ|n), which computes all distinguishing words u of minimum length, i. e., words which are factors of only one of the words w and v from the problem's statement. Several further improvements on the aforementioned results were reported in [19,63]. Also, in an extended abstract from 2003 [62], Simon presented another algorithm based on finite automata solving this maximization problem, which runs in O(|Σ|n), and he conjectures that it can be implemented in O(|Σ|+n). Unfortunately, the last claim was only insufficiently substantiated, and obtaining an algorithm with the claimed complexity remained open (in fact, Simon announced that a detailed description of this algorithm will follow shortly, but we were not able to find it in the literature).

Further, in [23], a novel approach to efficiently solving EQUI was introduced. This idea was to compute, for the two given words v and w and the given number k, their shortlex forms: the words which have the same set of subsequences of length at most k as v and w, respectively, and are also lexicographically smallest among all words with the respective property. Clearly, Subseq ≤k (v) = Subseq ≤k (w) if and only if the shortlex forms of v and w for k coincide.

The shortlex form of a word w of length n over Σ was computed in O(|Σ|n) time in [23], so EQUI was also solved in O(|Σ|n). A more efficient implementation of the ideas introduced in [23] was presented in [9]: the shortlex form of a word of length n over Σ can be computed in linear time O(n), so EQUI can be solved in optimal linear time. By binary searching for the smallest k for which EQUI with inputs v, w, k is true, gives an O(n log n) time solution for the corresponding optimization problem.

Later, Gawrychowski et al. [32] solved this optimization problem (finding the maximum k such that Subseq ≤k (v) = Subseq ≤k (w)) in optimal linear time, as well. However, to achieve this result a novel data structure, the Simon-Tree, was introduced. A node of depth k in the Simon-Tree of a word w corresponds to a maximal interval The maximal k such that Subseq k (v) = Subseq k (w) now equals the depth of the deepest connected nodes [1, x] in T v and [1, y] in T w . The following result holds.

Theorem 31 ([32]). Given two strings v and w, with n = |w| ≥ |v|, the largest k for which EQUI with input v, w, k is answered positively can be computed in O(n) time.

Equivalence and bounded range constraints. Considering the problem EQUI for subsequences occurring within bounded ranges leads again to a surprising intractability result. Once more, for convenience, we give this result for the complement problem, i. e., non-equivalence problem NEQUI. We are given two words v, w ∈ Σ * , and two numbers k, p ∈ N, and we want to decide whether p-Subseq k (v) = p-Subseq k (w). The hardness result obtained in [45] (and corresponding conditional lower bound) is the following.

Theorem 32. NEQUI with a bounded range constraint is NP-hard and cannot be solved in subexponential time 2 o(k) poly(k, n, m) unless ETH fails.

Equivalence and gap constraints. Finally, similarly to the case of subsequences occurring in bounded ranges, for the case of subsequences with gap constraints, one can adapt the results from [21], related to UNI, to get the following results.

Firstly, some algorithmic upper bounds.  (1,5). Moreover,

• it cannot be solved in subexponential time 2 o(k) poly(|w|, k)) (unless ETH fails),

• it cannot be solved in time O(2 k(1−ε) poly(|w|, k)) (unless SETH fails).

For every fixed alphabet Σ with |Σ| = 2, NEQUI Σ with length constraints are NP-complete even if each length constraint is (0, 0) or (3,9).


# Conclusions, Related Problems, and Future Work

In this paper, we overviewed a series of recent algorithmic and complexity theoretic results related to the matching and analysis problems for (constrained) subsequences.

An interesting problem related to the study of analysis problems for classical subsequences is the containment problem (denoted CON for short), which consists in deciding whether Subseq k (w) ⊆ Subseq k (v) for given strings w, v ∈ Σ * and integer k. This problem can be solved in polynomial time by an automata theoretic approach, as follows. We start with our input words w and v. For w we construct A w , the subsequence-automaton [19] which accepts all the subsequences of w. Assume |w| = n. Then, A w is a deterministic finite automaton, which has n + 2 states {0, ..., n, n + 1}. The initial state of this automaton is 0, and all states i, with i ∈ [n] are final; the state n + 1 is an error state. When considering subsequences with gap constraints, it seems interesting to see if the polynomiality of the matching problem is preserved under adding gap length equalities to the gap constraints, i. e., constraints of the form |gap i | = |gap j | which are satisfied by an embedding e with respect to w if |gap e (w, i)| = |gap e (w, j)|. Such length equality constraints (and more complex ones, e. g., described by linear inequalities) are of interest in the theory of string solving [3]. Unfortunately, the matching problem becomes immediately NP-hard, as it can be shown (see [21]) by adapting the NP-completeness proof for matching patterns with variables from [4].

Finally, with respect to EQUI, we can consider the following modified setting, both in the classical case and in the case of constrained subsequences (in bounded ranges, or with gap constraints). The idea is to consider the sets of subsequences with multiplicities. We present this here for subsequences with gap constraints, following [21], but this can be trivially adapted to the case of classical subsequences (see [26]), as well as to the case of subsequences with bounded-range constraints. So, we consider the gcsubsequences of the sets Subseq(gc, w) with multiplicities. For example, for w 1 = abba and w 2 = abab, we have Subseq(gc 2 , w 1 ) = Subseq(gc 2 , w 2 ) = {aa, ab, ba, bb} with gc 2 = (Σ * ). There is exactly one way of embedding aa and bb into both w 1 and w 2 . On the other hand, ab can be embedded into w 1 in two different ways and into w 2 in three different ways. More precisely, the sets of gc 2 -subsequences of w 1 and w 2 with multiplicities are {(aa, 1), (ab, 2), (ba, 2), (bb), 1} and {(aa, 1), (ab, 3), (ba, 1), (bb), 1}, respectively. So, we can now formalise this setting. For strings u and v, and a (|u| − 1)-tuple gc of gap constraints, we denote by |u| v,gc the number of distinct embeddings e : |u| → |v| that satisfy gc and v e u. For example, |bbaa| ba,gc 2 = 4, as u [1]u [3] = u [2]u [3] = u [1]u [4] = u [2]u [4] = ba. For any (k − 1)-tuple gc of gap constraints, we define the function Ψ gc (·) : Σ * → N (Σ k ) by Ψ gc (w)[p] = |w| p,gc for every p ∈ Σ k .

The equivalence problem with multiplicities is to decide, for a given (k − 1)-tuple gc of gap constraints, and strings w, v ∈ Σ * , whether Ψ gc (w) = Ψ gc (v). Note that for the case gc = (Σ * , . . . , Σ * ) this is called the k-binomial equivalence, and was studied in the area of combinatorics on words (see, e. g., [55,48,49,26]). By an automata theoretic approach one can show that the equivalence with multiplicities problem can be decided in polynomial time (in stark contrast to the NP-completeness of the case without multiplicities).

The idea, firstly introduced in [26] and then used in [21], is the following. We first construct, for the first input word w with |w| = n and a (k − 1)-tuple gc of gap constraints, a non-deterministic finite automaton A w,gc that accepts exactly the gapped subsequences p ∈ Subseq(gc, w) and has exactly Ψ gc (w) [p] accepting paths labelled with the subsequence p of w. Then, we will use the same construction for the second input word v, to obtain A v,gc . Finally, we use the algorithm of [64] to test whether A w,gc and A v,gc are path equivalent, i. e., for each word p, the number of accepting paths of A w,gc labelled with p equals the number of accepting paths of A v,gc labelled with p. If this algorithm returns a positive answer, then we can conclude that Ψ gc (w) = Ψ gc (v). Otherwise, we conclude that Ψ gc (w) = Ψ gc (v).

While the algorithm discussed above related to the equivalence problem with multiplicities runs in polynomial time O(max{|w|, |v|} 4 k 4 + size(gc)) for reg-len constraints, it would be interesting to see if faster algorithms exist. Moreover, the containment problem with multiplicities (i. e., deciding Ψ gc (w)[p] ≤ Ψ gc (v)[p] for all p ∈ Σ k ) seems to be more difficult. To our knowledge, whether the case of classical subsequences can be solved in polynomial time remains open.

While the discussion above highlights some clear open problems related to the topics covered in this paper, one could also extend this research by considering, for instance, other classes of constrained subsequences and investigating the matching and analysis problems for those classes as well.

Several other directions (not covered in this paper), in which the results overviewed here were extended and complemented, are the following. On the one hand, exactly as we did in the case of absent subsequences, one can try to generalise combinatorial and algorithmic properties from factors to subsequences. Such results are reported in, e.g., [8,7] (and the references therein), where the authors are concerned among other with identifying and representing the longest (sub-)periodic subsequences or Lyndon subsequences. On the other hand, several recent works approach topics closely related to Si-mon's congruence: [10] focuses on algorithms detecting strings having the same length-k substrings; [42] investigates the algorithmic and language theoretic properties of Simon's congruence closure of a string, i.e., the regular set of strings which are ∼ k -congruent to a given string, for a given k; last, but not least, [41] solves the string-matching in which one requires finding all factors of a given string w that are ∼ k -congruent to another string v, for a given k. All these works leave many interesting questions open.

We do not claim that this brief overview of related works is exhaustive, but we rather hope it enforces the idea that study of algorithmic properties of subsequences is a vibrant area within combinatorial pattern matching, which already produced some interesting and deep results but also leaves a multitude of challenging open problems.


[k] → [|w|] such that i < j implies e(i) < e( j) for all i, j ∈ [k], and it induces the subsequence subseq e (w) = w[e(1)]w[e(2)] . . . w[e(k)] of w. For every j ∈ [k − 1], the j th gap of w induced by e is the string gap e (w, j) = w[e( j) + 1..e( j + 1) − 1]. We say that e is the embedding of subseq e (w) in w.

## Definition 3 (
3Bounded range constraints). 1. Let v, w ∈ Σ * with |v| = m, |w| = n. The string v is called a p-subsequence of w (denoted v ≤ p w) if there exists an embedding e : [m] → [n] such that v = subseq e (w) and |w[e(1) : e(m)]| ≤ p, or equivalently e(m) − e(1) ≤ p − 1. 2. For p ∈ N and w ∈ Σ * , we denote the set of all p-subsequences of w by p-Subseq(w) = {v ∈ Σ * | v ≤ p w}. Furthermore, for k ∈ N, we denote the set of all p-subsequences of length k of w by p-Subseq k (w).

## Theorem 9 .
9MATCH with length constraints cannot be solved in O(|w| h nz(gc) g ) time with h + g = 2 − ε for some ε > 0, unless OVH fails. This holds even if |Σ| = 4 and all length constraints are (0, ℓ) with ℓ ≤ 6.Corollary 10. MATCH with regular constraints cannot be solved in O(|w| h states(gc p ) g ) time with h + g = 2 − ε for some ε > 0, unless OVH fails. This holds even if |Σ| = 4 and all regular constraints are expressed by constant size DFAs.

## Theorem 13 .
13The word w ∈ Σ * is k-universal if and only if there exist the words v i , with i ∈ [1 : k], such that v 1 · · · v k = w and alph(v i ) = Σ for all i ∈ [1 : k].

## Theorem 14 .
14Let w be a word, with |w| = n, alph(w) = Σ, and Σ = {1, 2, . . . , σ }. Let k ≥ ι(w) be an integer. We can compute the minimal number of insertions needed to apply to w in order to obtain a k-universal word (w. r. t. Σ) in O(nk) time if k ≤ n and O(T (n, σ , k)) time otherwise, where T (n, σ , k) is the time needed to compute the number kσ − n. Theorem 15. Let w be a word, with |w| = n, alph(w) = Σ, and Σ = {1, 2, . . . , σ }. Let k be an integer with k ≤ ι(w) ≤ ⌊ n σ ⌋. We can compute in O(nk) time the minimal number of deletions needed to obtain a word of universality index k (w. r. t. Σ) from w. Theorem 16. Let w be a word, with |w| = n, al ph(w) = Σ, and Σ = {1, 2, . . . , σ }. Let k be an integer 0 ≤ k ≤ ⌊ n σ ⌋. We can compute the minimal number of substitutions needed to apply to w in order to obtain a k-universal word (w. r. t. Σ) in O(nk) time.

## Theorem 21 (
21[44]).For a word w of length n we can construct in O(n) time data structures allowing us to answer in O(1) time queries sasRange(i, j): "return a representation of an SAS of w[i : j]".


Theorem 24 ([44]). For a word w, we can construct in O(n 2 σ ) time data structures allowing us to efficiently perform the following tasks: 1. We can check in O(m) time if a word u of length m is an MAS of w. 2. We can compute in polynomial time the longest MAS of w. 3. We can check in polynomial time for a given length ℓ if there exists an MAS of length ℓ of w.

## Corollary 25 .
25For a word w of length n, we can construct in O(nσ ) time data structures allowing us to answer masExt(u) queries: for a subsequence u of w, decide whether there exists an MAS uv of w, and, if yes, construct such an MAS uv of minimal length. The time needed to answer a query is O(|v| + |u|).

## Theorem 28 .
28pMAS can be solved in time O(nm), where |v| = m, |w| = n. Theorem 29. pMAS cannot be solved in time O(n h m g ) where h + g = 2 − ε with ε > 0, unless OVH fails.


[i : j] (called k-block) such that for all ℓ, ℓ ′ ∈ [i : j] it holds that Subseq k (w[ℓ : n]) = Subseq k (w[ℓ ′ : n]).Definition 30. The Simon-Tree T w associated to the word w, with |w| = n, is an ordered rooted tree. The nodes of depth k represent k−blocks of w, for 0 ≤ k ≤ n, and are defined recursively.• The root corresponds to the 0-block of the word w, i. e., the interval [1 : n].• For k > 1 and for a node a of depth k − 1, which represents a (k − 1)-block[i : j] with i < j, the children of a are exactly the blocks of the partition of [i : j] in k-blocks, ordered decreasingly (right-to-left) by their starting position. • For k > 1, each node of depth k − 1 which represents a singleton-(k − 1)-block is a leaf. The Simon-Tree T w can be constructed in linear time O(n). Furthermore, for words v, w ∈ Σ * of length |v| = m and |w| = n, Gawrychowski et al. ([32]) give a linear time algorithm to connect nodes of the Simon-Trees T v , T w . Two nodes [i, j] in T v (of depth k) and [i ′ , j ′ ] in T w (also of depth k) become connected if and only if Subseq ≤k (v[ℓ : m]) = Subseq ≤k (w[ℓ ′ : n]) for all ℓ ∈ [i : j] and ℓ ′ ∈ [i ′ , j ′ ].


Let N be the set of natural numbers, including 0. For m, n ∈ N, we define the range (or interval) of natural numbers lower bounded by m and upper bounded by n as [m : n] = {m, m + 1, . . . , n}. An alphabet Σ is a non-empty finite set of symbols (called letters). A string (or word) is a finite sequence of letters from Σ, thus an element of the free monoid Σ * . Let Σ + = Σ * \ {ε}, where ε is the empty string. The length of a string w ∈ Σ * is denoted by |w|. The i th letter of w ∈ Σ * is denoted by w[i], for i ∈ [1 : |w|]. For a ∈ Σ, let |w| a = |{i ∈ [1 : |w|] | w[i] = a}|; let alph(w) = {x ∈ Σ | |w| x > 0} be the smallest subset S ⊆ Σ such that w ∈ S * . For m, n ∈ N, with m ≤ n, we define the range (or factor) of w between positions m and n as w[m : n] = w[m]w[m + 1] . . . w[n]. If m > n, then w[m : n] is the empty word. Also, by convention, if m < 1, then w[m : n] = w[1 : n], and if n > |w|, then w[m : n] = w[m : |w|]. A factor u = w[m : n] of w is called a prefix (respectively, suffix) of w if m = 1 (respectively, n = |w|).


* for every i ∈ [ℓ]. For convenience, we set gc[i] = C i for every i ∈ [ℓ]. We say that an embedding e satisfies a (k − 1)-tuple of gap constraints gc with respect to a string w if it has the form e : [k] → [|w|], and, for every i ∈ [k − 1], gap e (w, i) ∈ C i . For a (k − 1)-tuple gc of gap constraints, the set Subseq(gc, w) contains all subsequences of w induced by embeddings that satisfy gc, i. e., Subseq(gc, w) = {subseq e (w) | e is an embedding that satisfies gc w. r. t. w}. The elements of Subseq(gc, w) are also called the gc-subsequences of w. For a (|u| − 1)-tuple gc of gap constraints, we write u gc v to denote that u e v for some embedding e : [|u|] → [|v|] that satisfies gc with respect to v, i. e., u gc v means that u is a gc-subsequence of v.


[1 : 1], u[1 : 2], . . . , u[1 : m − 1] respectively, as well as the shortest suffixes of w containing u[m : m], u[m − 1 : m], . . . , u[2 : m] respectively. Now, u is an MAS of w if and only if for every 1 ≤ i ≤ m the shortest prefix containing u[1 : i − 1] and the shortest suffix containing u[i + 1 : m] do not overlap. For the analysis of the set SAS(w) we can construct in linear time data structures, visualized by a tree called SAS-tree, which encodes SAS(w). Theorem 23 ([44]). Given a word w of length n with universality index k, we can construct in O(n) time data structures allowing us to perform the following tasks: 1. We can check in O(k) time if a word u of length k + 1 is an SAS of w. 2. We can compute in O(k) time the lexicographically smallest SAS of w. 3. We can efficiently enumerate (i. e., with polynomial delay) all the SAS of w.


Theorem 33.  (1) The problem EQUI for subsequences with length (or reg-len) constraints can be solved in time O(|Σ| k nz(gc)ℓ) (respectively, O(|Σ| k states(gc)ℓ)), where ℓ = max{|w|, |w ′ |}.(2) For fixed alphabet Σ, the problem EQUI Σ with length (or reg-len) constraints can be solved in time 2 O(k) nz(gc)ℓ (respectively, 2 O(k) states(gc)ℓ), where ℓ = max{|w|, |w ′ |}.Secondly, a couple of intractability results, doubled by conditional lower bounds.Theorem 34. For every fixed alphabet Σ with |Σ| ≥ 3, NEQUI Σ with length constraints is NP-complete, even if all length constraints are


The transition are defined as follows: for all i ∈ [n], k ∈ [n − i], and a ∈ Σ, we have a transition from state i to i + k, labelled with a, if and only if w[i + k] = a and w[i + 1..i + k − 1] does not contain the letter a. Moreover, for all i ∈ [n] and a ∈ Σ, we have a transition from state i to state n + 1, labelled with letter a, if and only if w[i + 1..n] does not contain a. For state n + 1 we have loop-transitions for all letters a ∈ Σ. It is straightforward that A w accepts exactly the non-empty subsequences of w and can be constructed in O(n|Σ|) time. For the word v, with |v| = m, we construct the automaton A v , as above, and then modify it to obtain the automaton B v by simply making the state m + 1 the single final state. Clearly, B v accepts all strings which are not subsequences of v. It can be constructed in O(m|Σ|) time. Now, we can observe that Subseq k (w) Subseq k (v) if and only if there exists a word of length at most k accepted by A w which is also accepted by B v . This can be checked in O(nm|Σ|) time by simply computing the shortest word in the intersection of the language accepted by A w with the language accepted by B v . However, it remains an interesting open problem whether a linear time algorithm exists for CON, as it exists for EQUI.

Tight Hardness Results for LCS and Other Sequence Similarity Measures. Amir Abboud, Arturs Backurs, &amp; Virginia Vassilevska, Williams, 10.1109/FOCS.2015.14Proc. FOCS 2015. FOCS 2015Amir Abboud, Arturs Backurs & Virginia Vassilevska Williams (2015): Tight Hardness Results for LCS and Other Sequence Similarity Measures. In: Proc. FOCS 2015, pp. 59-78, doi:10.1109/FOCS.2015.14.

Consequences of Faster Alignment of Sequences. Amir Abboud, Virginia Vassilevska Williams &amp; Oren Weimann, 10.1007/978-3-662-43948-7_4Proc. ICALP. ICALPAmir Abboud, Virginia Vassilevska Williams & Oren Weimann (2014): Consequences of Faster Alignment of Sequences. In: Proc. ICALP 2014, pp. 39-51, doi:10.1007/978-3-662-43948-7_4.

A survey on string constraint solving. Roberto Amadini, 10.1145/3484198ACM Computing Surveys (CSUR). 551Roberto Amadini (2021): A survey on string constraint solving. ACM Computing Surveys (CSUR) 55(1), pp. 1-38, doi:10.1145/3484198.

Finding Patterns Common to a Set of Strings. Dana Angluin, 10.1016/0022-0000(80)90041-0J. Comput. Syst. Sci. 211Dana Angluin (1980): Finding Patterns Common to a Set of Strings. J. Comput. Syst. Sci. 21(1), pp. 46-62, doi:10.1016/0022-0000(80)90041-0.

Complex Event Recognition Languages: Tutorial. Alexander Artikis, Alessandro Margara, Martín Ugarte, 10.1145/3093742.3095106Stijn Vansummeren & Matthias Weidlich. Proc. DEBS 2017Alexander Artikis, Alessandro Margara, Martín Ugarte, Stijn Vansummeren & Matthias Weidlich (2017): Complex Event Recognition Languages: Tutorial. In: Proc. DEBS 2017, pp. 7-10, doi:10.1145/3093742. 3095106.

. Ricardo A Baeza-Yates, 10.1016/0304-3975(91)90358-9doi:10. 1016/0304-3975Searching Subsequences. Theor. Comput. Sci. 782Ricardo A. Baeza-Yates (1991): Searching Subsequences. Theor. Comput. Sci. 78(2), pp. 363-376, doi:10. 1016/0304-3975(91)90358-9.

Computing Longest (Common) Lyndon Subsequences. Hideo Bannai, I Tomohiro, Tomasz Kociumaka, Dominik Köppl, &amp; Simon, J Puglisi, 10.1007/978-3-031-06678-8_10Proc. IWOCA 2022. IWOCA 2022Springer13270Lecture Notes in Computer ScienceHideo Bannai, Tomohiro I, Tomasz Kociumaka, Dominik Köppl & Simon J. Puglisi (2022): Computing Longest (Common) Lyndon Subsequences. In: Proc. IWOCA 2022, Lecture Notes in Computer Science 13270, Springer, pp. 128-142, doi:10.1007/978-3-031-06678-8_10. Extended version to appear under the title "Computing Longest Lyndon Subsequences and Longest Common Lyndon Subsequences".

Longest (Sub-)Periodic Subsequence. Hideo Bannai, I &amp; Dominik Tomohiro, Köppl, arXiv:2202.07189Hideo Bannai, Tomohiro I & Dominik Köppl (2022): Longest (Sub-)Periodic Subsequence. CoRR abs/2202.07189. arXiv:2202.07189.

Florin Manea & Dirk Nowotka (2020): Scattered Factor-Universality of Words. Laura Barker, Pamela Fleischmann, Katharina Harwardt, 10.1007/978-3-030-48516-0_2Proc. DLT 2020. DLT 202012086Laura Barker, Pamela Fleischmann, Katharina Harwardt, Florin Manea & Dirk Nowotka (2020): Scattered Factor-Universality of Words. In: Proc. DLT 2020, Lecture Notes in Computer Science 12086, pp. 14-28, doi:10.1007/978-3-030-48516-0_2.

On Strings Having the Same Length-k Substrings. Giulia Bernardini, Alessio Conte, Estéban Gabory, Roberto Grossi, Grigorios Loukides, P Solon, Giulia Pissis, Punzi &amp; Michelle, Sweering, 10.4230/LIPIcs.CPM.2022.16Proc. CPM 2022. CPM 202222317Giulia Bernardini, Alessio Conte, Estéban Gabory, Roberto Grossi, Grigorios Loukides, Solon P. Pissis, Giulia Punzi & Michelle Sweering (2022): On Strings Having the Same Length-k Substrings. In: Proc. CPM 2022, LIPIcs 223, pp. 16:1-16:17, doi:10.4230/LIPIcs.CPM.2022.16.

String matching with variable length gaps. Philip Bille, Inge Li Gørtz, Hjalte Wedel Vildhøj &amp; David Kofoed Wind, 10.1016/j.tcs.2012.03.029Theor. Comput. Sci. 443Philip Bille, Inge Li Gørtz, Hjalte Wedel Vildhøj & David Kofoed Wind (2012): String matching with vari- able length gaps. Theor. Comput. Sci. 443, pp. 25-34, doi:10.1016/j.tcs.2012.03.029.

Karl Bringmann, 10.1109/FOCS.2014.76Why Walking the Dog Takes Time: Frechet Distance Has No Strongly Subquadratic Algorithms Unless SETH Fails. Proc. FOCSKarl Bringmann (2014): Why Walking the Dog Takes Time: Frechet Distance Has No Strongly Subquadratic Algorithms Unless SETH Fails. In: Proc. FOCS 2014, pp. 661-670, doi:10.1109/FOCS.2014.76.

Fine-Grained Complexity Theory (Tutorial). Karl Bringmann, 10.4230/LIPIcs.STACS.2019.4Proc. STACS 2019. STACS 20194Karl Bringmann (2019): Fine-Grained Complexity Theory (Tutorial). In: Proc. STACS 2019, pp. 4:1-4:7, doi:10.4230/LIPIcs.STACS.2019.4.

Sketching, Streaming, and Fine-Grained Complexity of (Weighted) LCS. 10.4230/LIPIcs.FSTTCS.2018.40Proc. FSTTCS 2018. Karl Bringmann & Bhaskar Ray ChaudhuryFSTTCS 201812216Karl Bringmann & Bhaskar Ray Chaudhury (2018): Sketching, Streaming, and Fine-Grained Complexity of (Weighted) LCS. In: Proc. FSTTCS 2018, LIPIcs 122, pp. 40:1-40:16, doi:10.4230/LIPIcs.FSTTCS. 2018.40.

Multivariate Fine-Grained Complexity of Longest Common Subsequence. Karl Bringmann &amp; Marvin Künnemann, 10.1137/1.9781611975031.79Proc. nullKarl Bringmann & Marvin Künnemann (2018): Multivariate Fine-Grained Complexity of Longest Common Subsequence. In: Proc. SODA 2018, pp. 1216-1235, doi:10.1137/1.9781611975031.79.

Unshuffling a square is NP-hard. Sam Buss, &amp; Michael Soltys, 10.1016/j.jcss.2013.11.002J. Comput. Syst. Sci. 804Sam Buss & Michael Soltys (2014): Unshuffling a square is NP-hard. J. Comput. Syst. Sci. 80(4), pp. 766-776, doi:10.1016/j.jcss.2013.11.002.

Simple deterministic wildcard matching. Peter Clifford, &amp; Raphaël Clifford, 10.1016/j.ipl.2006.08.002Inf. Process. Lett. 1012Peter Clifford & Raphaël Clifford (2007): Simple deterministic wildcard matching. Inf. Process. Lett. 101(2), pp. 53-54, doi:10.1016/j.ipl.2006.08.002.

Maxime Crochemore, Christophe Hancart &amp; Thierry Lecroq, 10.1017/CBO9780511546853Algorithms on strings. Cambridge University PressMaxime Crochemore, Christophe Hancart & Thierry Lecroq (2007): Algorithms on strings. Cambridge University Press, doi:10.1017/CBO9780511546853.

Directed acyclic subsequence graph -Overview. Maxime Crochemore, Borivoj Melichar &amp; Zdenek, Tronícek, 10.1016/S1570-8667(03)00029-7J. Discrete Algorithms. 1Maxime Crochemore, Borivoj Melichar & Zdenek Tronícek (2003): Directed acyclic subsequence graph - Overview. J. Discrete Algorithms 1(3-4), pp. 255-280, doi:10.1016/S1570-8667(03)00029-7.

The Edit Distance to k-Subsequence Universality. Joel D Day, Pamela Fleischmann, Maria Kosche, Tore Koß, Florin Manea &amp; Stefan, Siemer, 10.4230/LIPIcs.STACS.2021.25Proc. STACS 2021, LIPIcs 187, Schloss Dagstuhl -Leibniz-Zentrum für Informatik. STACS 2021, LIPIcs 187, Schloss Dagstuhl -Leibniz-Zentrum für Informatik2519Joel D. Day, Pamela Fleischmann, Maria Kosche, Tore Koß, Florin Manea & Stefan Siemer (2021): The Edit Distance to k-Subsequence Universality. In: Proc. STACS 2021, LIPIcs 187, Schloss Dagstuhl -Leibniz- Zentrum für Informatik, pp. 25:1-25:19, doi:10.4230/LIPIcs.STACS.2021.25.

Joel D Day, Maria Kosche, Florin Manea, &amp; Markus, L Schmid, 10.48550/ARXIV.2206.13896Subsequences With Gap Constraints: Complexity Bounds for Matching and Analysis Problems. CoRR abs/2206.13896. To appear in the Proceedings of ISAAC 2022Joel D. Day, Maria Kosche, Florin Manea & Markus L. Schmid (2022): Subsequences With Gap Constraints: Complexity Bounds for Matching and Analysis Problems. CoRR abs/2206.13896, doi:10.48550/ARXIV. 2206.13896. To appear in the Proceedings of ISAAC 2022.

Episturmian words and some constructions of de Luca and Rauzy. Xavier Droubay, Jacques Justin &amp; Giuseppe, Pirillo, 10.1016/S0304-3975(99)00320-5Theor. Comput. Sci. 2551-2Xavier Droubay, Jacques Justin & Giuseppe Pirillo (2001): Episturmian words and some constructions of de Luca and Rauzy. Theor. Comput. Sci. 255(1-2), pp. 539-553, doi:10.1016/S0304-3975(99)00320-5.

Testing Simon's congruence. Lukas Fleischer, &amp; Manfred Kufleitner, 10.4230/LIPIcs.MFCS.2018.62Proc. MFCS 2018. MFCS 2018117Lukas Fleischer & Manfred Kufleitner (2018): Testing Simon's congruence. In: Proc. MFCS 2018, LIPIcs 117, pp. 62:1-62:13, doi:10.4230/LIPIcs.MFCS.2018.62.

Scattered Factor Universality -The Power of the Remainder. 10.48550/ARXIV.2104.09063To appear in Proc. DCFS 2022. Pamela Fleischmann, Sebastian Bernhard Germann & Dirk NowotkaPamela Fleischmann, Sebastian Bernhard Germann & Dirk Nowotka (2021): Scattered Factor Universality -The Power of the Remainder. CoRR abs/2104.09063, doi:10.48550/ARXIV.2104.09063. To appear in Proc. DCFS 2022.

Pamela Fleischmann, Lukas Haschke, Annika Huch, 10.48550/ARXIV.2202.07981Annika Mayrock & Dirk Nowotka (2022): m-Nearly k-Universal Words -Investigating Simon Congruence. Pamela Fleischmann, Lukas Haschke, Annika Huch, Annika Mayrock & Dirk Nowotka (2022): m-Nearly k-Universal Words -Investigating Simon Congruence. CoRR abs/2202.07981, doi:10.48550/ARXIV.2202. 07981.

Testing k-binomial equivalence. D Dominik, Pawel Freydenberger, Juhani Gawrychowski, Karhumäki, 10.48550/ARXIV.1509.00622Florin Manea & Wojciech Rytter. Pȃun 65th birthdayDominik D. Freydenberger, Pawel Gawrychowski, Juhani Karhumäki, Florin Manea & Wojciech Rytter (2015): Testing k-binomial equivalence. CoRR abs/1509.00622, pp. 239-248, doi:10.48550/ARXIV.1509. 00622. Multidisciplinary Creativity, a collection of papers dedicated to G. Pȃun 65th birthday.

Language recognition in the sliding window model. Moses Ganardi, GermanyUniversity of SiegenPh.D. thesisMoses Ganardi (2019): Language recognition in the sliding window model. Ph.D. thesis, University of Siegen, Germany.

Automata Theory on Sliding Windows. Moses Ganardi, Danny Hucke, Daniel König, 10.4230/LIPIcs.STACS.2018.31Proc. STACS 2018, LIPIcs 96, Schloss Dagstuhl -Leibniz-Zentrum für Informatik. STACS 2018, LIPIcs 96, Schloss Dagstuhl -Leibniz-Zentrum für Informatik3114Moses Ganardi, Danny Hucke, Daniel König, Markus Lohrey & Konstantinos Mamouras (2018): Automata Theory on Sliding Windows. In: Proc. STACS 2018, LIPIcs 96, Schloss Dagstuhl -Leibniz-Zentrum für Informatik, pp. 31:1-31:14, doi:10.4230/LIPIcs.STACS.2018.31.

Querying Regular Languages over Sliding Windows. Moses Ganardi, Danny Hucke &amp; Markus, Lohrey, 10.4230/LIPIcs.FSTTCS.2016.18Proc. FSTTCS 2016, LIPIcs 65, Schloss Dagstuhl -Leibniz-Zentrum für Informatik. FSTTCS 2016, LIPIcs 65, Schloss Dagstuhl -Leibniz-Zentrum für Informatik1814Moses Ganardi, Danny Hucke & Markus Lohrey (2016): Querying Regular Languages over Sliding Win- dows. In: Proc. FSTTCS 2016, LIPIcs 65, Schloss Dagstuhl -Leibniz-Zentrum für Informatik, pp. 18:1- 18:14, doi:10.4230/LIPIcs.FSTTCS.2016.18.

Sliding Window Property Testing for Regular Languages. Moses Ganardi, Danny Hucke, Markus Lohrey &amp; Tatiana, Starikovskaya, 10.4230/LIPIcs.ISAAC.2019.6Proc. ISAAC 2019, LIPIcs 149, Schloss Dagstuhl -Leibniz-Zentrum für Informatik. ISAAC 2019, LIPIcs 149, Schloss Dagstuhl -Leibniz-Zentrum für Informatik6Moses Ganardi, Danny Hucke, Markus Lohrey & Tatiana Starikovskaya (2019): Sliding Window Property Testing for Regular Languages. In: Proc. ISAAC 2019, LIPIcs 149, Schloss Dagstuhl -Leibniz-Zentrum für Informatik, pp. 6:1-6:13, doi:10.4230/LIPIcs.ISAAC.2019.6.

Minimal Separators of Two Words. Emmanuelle Garel, 10.1007/BFb0029795Proc. CPM 1993. CPM 1993684Emmanuelle Garel (1993): Minimal Separators of Two Words. In: Proc. CPM 1993, Lecture Notes in Computer Science 684, pp. 35-53, doi:10.1007/BFb0029795.

Efficiently Testing Simon's Congruence. Pawel Gawrychowski, Maria Kosche, Tore Koß, Florin Manea &amp; Stefan, Siemer, 10.4230/LIPIcs.STACS.2021.34Proc. STACS 2021, LIPIcs 187, Schloss Dagstuhl -Leibniz-Zentrum für Informatik. STACS 2021, LIPIcs 187, Schloss Dagstuhl -Leibniz-Zentrum für Informatik34Pawel Gawrychowski, Maria Kosche, Tore Koß, Florin Manea & Stefan Siemer (2021): Efficiently Testing Simon's Congruence. In: Proc. STACS 2021, LIPIcs 187, Schloss Dagstuhl -Leibniz-Zentrum für Informatik, pp. 34:1-34:18, doi:10.4230/LIPIcs.STACS.2021.34.

Complex event recognition in the Big Data era: a survey. Nikos Giatrakos, Elias Alevizos, Alexander Artikis, Antonios Deligiannakis &amp; Minos, N Garofalakis, 10.1007/s00778-019-00557-wdoi:10.1007/ s00778-019-00557-wVLDB J. 291Nikos Giatrakos, Elias Alevizos, Alexander Artikis, Antonios Deligiannakis & Minos N. Garofalakis (2020): Complex event recognition in the Big Data era: a survey. VLDB J. 29(1), pp. 313-352, doi:10.1007/ s00778-019-00557-w.

Decidability, complexity, and expressiveness of first-order logic over the subword ordering. Simon Halfon, Philippe Schnoebelen &amp; Georg Zetzsche, 10.5555/3329995.3330076Proc. LICS 2017. LICS 2017Simon Halfon, Philippe Schnoebelen & Georg Zetzsche (2017): Decidability, complexity, and expressiveness of first-order logic over the subword ordering. In: Proc. LICS 2017, pp. 1-12, doi:10.5555/3329995. 3330076.

An algorithm for distinguishing efficiently bit-strings by their subsequences. Jean-Jacques Hebrard, 10.1016/0304-3975(91)90170-7Theor. Comput. Sci. 821Jean-Jacques Hebrard (1991): An algorithm for distinguishing efficiently bit-strings by their subsequences. Theor. Comput. Sci. 82(1), pp. 35-49, doi:10.1016/0304-3975(91)90170-7.

On the Complexity of k-SAT. Russell Impagliazzo &amp; Ramamohan, Paturi, 10.1006/jcss.2000.1727J. Comput. Syst. Sci. 622Russell Impagliazzo & Ramamohan Paturi (2001): On the Complexity of k-SAT. J. Comput. Syst. Sci. 62(2), pp. 367-375, doi:10.1006/jcss.2000.1727.

Which Problems Have Strongly Exponential Complexity?. Russell Impagliazzo, Ramamohan Paturi &amp; Francis Zane, 10.1006/jcss.2001.1774J. Comput. Syst. Sci. 634Russell Impagliazzo, Ramamohan Paturi & Francis Zane (2001): Which Problems Have Strongly Exponential Complexity? J. Comput. Syst. Sci. 63(4), pp. 512-530, doi:10.1006/jcss.2001.1774.

On the index of Simon's congruence for piecewise testability. 10.1016/j.ipl.2014.11.008Inf. Process. Lett. Prateek Karandikar, Manfred Kufleitner & Philippe Schnoebelen1154Prateek Karandikar, Manfred Kufleitner & Philippe Schnoebelen (2015): On the index of Simon's congruence for piecewise testability. Inf. Process. Lett. 115(4), pp. 515-519, doi:10.1016/j.ipl.2014.11.008.

The Height of Piecewise-Testable Languages with Applications in Logical Complexity. Prateek Karandikar &amp; Philippe Schnoebelen, 10.4230/LIPIcs.CSL.2016.37Proc. CSL 2016. CSL 20166222Prateek Karandikar & Philippe Schnoebelen (2016): The Height of Piecewise-Testable Languages with Ap- plications in Logical Complexity. In: Proc. CSL 2016, LIPIcs 62, pp. 37:1-37:22, doi:10.4230/LIPIcs. CSL.2016.37.

The height of piecewise-testable languages and the complexity of the logic of subwords. Prateek Karandikar &amp; Philippe Schnoebelen, 10.23638/LMCS-15(2:6)2019Log. Methods Comput. Sci. 152Prateek Karandikar & Philippe Schnoebelen (2019): The height of piecewise-testable languages and the complexity of the logic of subwords. Log. Methods Comput. Sci. 15(2), doi:10.23638/LMCS-15(2:6)2019.

Simon's Congruence Pattern Matching. Sungmin Kim, Yo-Sub Han, &amp; Sang-Ki Ko, To appear in the proceedings of ISAAC 2022Sungmin Kim, Yo-Sub Han & Sang-Ki Ko (2022): Simon's Congruence Pattern Matching. To appear in the proceedings of ISAAC 2022.

On Simon's Congruence Closure of a String. Sungmin Kim, Yo-Sub Han, Sang-Ki Ko &amp; Kai Salomaa, 10.1007/978-3-031-13257-5_10doi:10. 1007/978-3-031-13257-5_10Proc. DCFS 2022, Lecture Notes in Computer Science 13439. DCFS 2022, Lecture Notes in Computer Science 13439SpringerSungmin Kim, Yo-Sub Han, Sang-Ki Ko & Kai Salomaa (2022): On Simon's Congruence Closure of a String. In: Proc. DCFS 2022, Lecture Notes in Computer Science 13439, Springer, pp. 127-141, doi:10. 1007/978-3-031-13257-5_10.

Discovering Event Queries from Traces: Laying Foundations for Subsequence-Queries with Wildcards and Gap-Size Constraints. Sarah Kleest-Meißner, Rebecca Sattler, Markus L Schmid, 10.4230/LIPIcs.ICDT.2022.18Proc. ICDT 2022, LIPIcs 220, Schloss Dagstuhl -Leibniz-Zentrum für Informatik. ICDT 2022, LIPIcs 220, Schloss Dagstuhl -Leibniz-Zentrum für Informatik18Sarah Kleest-Meißner, Rebecca Sattler, Markus L. Schmid, Nicole Schweikardt & Matthias Weidlich (2022): Discovering Event Queries from Traces: Laying Foundations for Subsequence-Queries with Wildcards and Gap-Size Constraints. In: Proc. ICDT 2022, LIPIcs 220, Schloss Dagstuhl -Leibniz-Zentrum für Informatik, pp. 18:1-18:21, doi:10.4230/LIPIcs.ICDT.2022.18.

Absent Subsequences in Words. Maria Kosche, Tore Koß, Florin Manea &amp; Stefan, Siemer, 10.1007/978-3-030-89716-1_8Proc. RP 2021. RP 2021ChamSpringer International PublishingMaria Kosche, Tore Koß, Florin Manea & Stefan Siemer (2021): Absent Subsequences in Words. In: Proc. RP 2021, Springer International Publishing, Cham, pp. 115-131, doi:10.1007/978-3-030-89716-1_8.

Maria Kosche, Tore Koß, Florin Manea &amp; Viktoriya, Pak, 10.48550/ARXIV.2207.09201Subsequences in Bounded Ranges: Matching and Analysis Problems. To appear in the proceedings of RP 2022Maria Kosche, Tore Koß, Florin Manea & Viktoriya Pak (2022): Subsequences in Bounded Ranges: Match- ing and Analysis Problems. CoRR abs/2207.09201, doi:10.48550/ARXIV.2207.09201. To appear in the proceedings of RP 2022.

The Subtrace Order and Counting First-Order Logic. Dietrich Kuske, 10.1007/978-3-030-50026-9_21Proc. CSR 2020. CSR 202012159Dietrich Kuske (2020): The Subtrace Order and Counting First-Order Logic. In: Proc. CSR 2020, Lecture Notes in Computer Science 12159, pp. 289-302, doi:10.1007/978-3-030-50026-9_21.

Languages Ordered by the Subword Order. Dietrich Kuske, &amp; Georg Zetzsche, 10.1007/978-3-030-17127-8_20Proc. FOSSACS 2019, Lecture Notes in Computer Science 11425. FOSSACS 2019, Lecture Notes in Computer Science 11425Dietrich Kuske & Georg Zetzsche (2019): Languages Ordered by the Subword Order. In: Proc. FOSSACS 2019, Lecture Notes in Computer Science 11425, pp. 348-364, doi:10.1007/978-3-030-17127-8_20.

Computing the k-binomial Complexity of the Thue-Morse Word. Marie Lejeune, Julien Leroy &amp; Michel Rigo, 10.1007/978-3-030-24886-4_21doi:10.1007/ 978-3-030-24886-4_21Proc. DLT 2019. DLT 201911647Marie Lejeune, Julien Leroy & Michel Rigo (2019): Computing the k-binomial Complexity of the Thue- Morse Word. In: Proc. DLT 2019, Lecture Notes in Computer Science 11647, pp. 278-291, doi:10.1007/ 978-3-030-24886-4_21.

Generalized Pascal triangle for binomial coefficients of words. Julien Leroy, Michel Rigo &amp; Manon, Stipulanti, 10.1016/j.aam.2016.04.006Electron. J. Combin. 24136Julien Leroy, Michel Rigo & Manon Stipulanti (2017): Generalized Pascal triangle for binomial coefficients of words. Electron. J. Combin. 24(1.44), p. 36 pp., doi:10.1016/j.aam.2016.04.006.

Daniel Lokshtanov, Dániel Marx &amp; Saket, Saurabh, 10.1007/978-3-319-21275-3_14Lower bounds based on the Exponential Time Hypothesis. Bull. EATCS 105. Daniel Lokshtanov, Dániel Marx & Saket Saurabh (2011): Lower bounds based on the Exponential Time Hypothesis. Bull. EATCS 105, pp. 41-72, doi:10.1007/978-3-319-21275-3_14.

Aldo De Luca, Amy Glen &amp; Luca, Q Zamboni, 10.1016/j.tcs.2008.06.009Rich, Sturmian, and trapezoidal words. 407Aldo de Luca, Amy Glen & Luca Q. Zamboni (2008): Rich, Sturmian, and trapezoidal words. Theor. Comput. Sci. 407(1-3), pp. 569-573, doi:10.1016/j.tcs.2008.06.009.

The Complexity of Some Problems on Subsequences and Supersequences. David Maier, 10.1145/322063.322075J. ACM. 252David Maier (1978): The Complexity of Some Problems on Subsequences and Supersequences. J. ACM 25(2), pp. 322-336, doi:10.1145/322063.322075.

Subword Histories and Parikh Matrices. Alexandru Mateescu, Arto Salomaa &amp; Sheng, Yu , 10.1016/j.jcss.2003.04.001J. Comput. Syst. Sci. 681Alexandru Mateescu, Arto Salomaa & Sheng Yu (2004): Subword Histories and Parikh Matrices. J. Comput. Syst. Sci. 68(1), pp. 1-21, doi:10.1016/j.jcss.2003.04.001.

William E Riddle, 10.1016/0096-0551(79)90009-2An Approach to Software System Modelling and Analysis. Comput. Lang. 4(1). William E. Riddle (1979): An Approach to Software System Modelling and Analysis. Comput. Lang. 4(1), pp. 49-66, doi:10.1016/0096-0551(79)90009-2.

Another generalization of abelian equivalence: Binomial complexity of infinite words. Michel Rigo, &amp; Pavel Salimov, 10.1016/j.tcs.2015.07.025Theor. Comput. Sci. 601Michel Rigo & Pavel Salimov (2015): Another generalization of abelian equivalence: Binomial complexity of infinite words. Theor. Comput. Sci. 601, pp. 47-57, doi:10.1016/j.tcs.2015.07.025.

Arto Salomaa, 10.1016/j.tcs.2005.03.024Connections Between Subwords and Certain Matrix Mappings. 340Arto Salomaa (2005): Connections Between Subwords and Certain Matrix Mappings. Theoret. Comput. Sci. 340(2), pp. 188-203, doi:10.1016/j.tcs.2005.03.024.

Absoluteness of subword inequality is undecidable. Shinnosuke Seki, 10.1016/j.tcs.2011.10.017Theor. Comput. Sci. 418Shinnosuke Seki (2012): Absoluteness of subword inequality is undecidable. Theor. Comput. Sci. 418, pp. 116-120, doi:10.1016/j.tcs.2011.10.017.

Software Descriptions with Flow Expressions. Alan C Shaw, 10.1109/TSE.1978.231501IEEE Trans. Software Eng. 43Alan C. Shaw (1978): Software Descriptions with Flow Expressions. IEEE Trans. Software Eng. 4(3), pp. 242-254, doi:10.1109/TSE.1978.231501.

Imre Simon: An Algorithm to Distinguish Words efficiently by their Subwords. unpublishedImre Simon: An Algorithm to Distinguish Words efficiently by their Subwords. unpublished.

Hierarchies of events with dot-depth one. Imre Simon, Ph.D. thesisImre Simon (1972): Hierarchies of events with dot-depth one. Ph.D. thesis.

Imre Simon, 10.1007/3-540-07407-4_23Autom. Theor. Form. Lang., 2nd GI Conf. 33Piecewise testable eventsImre Simon (1975): Piecewise testable events. In: Autom. Theor. Form. Lang., 2nd GI Conf., LNCS 33, pp. 214-222, doi:10.1007/3-540-07407-4_23.

Words distinguished by their subwords (extended Abstract). Imre Simon, Proc. WORDS 2003. WORDS 200327Imre Simon (2003): Words distinguished by their subwords (extended Abstract). In: Proc. WORDS 2003, TUCS General Publication 27, pp. 6-13.

Common Subsequence Automaton. Zdenek Tronícek, 10.1007/3-540-44977-9_28Lecture Notes in Computer Science 2608. Proc. CIAA 2002Zdenek Tronícek (2002): Common Subsequence Automaton. In: Proc. CIAA 2002 (Revised Papers), Lecture Notes in Computer Science 2608, pp. 270-275, doi:10.1007/3-540-44977-9_28.

A Polynomial-Time Algorithm for the Equivalence of Probabilistic Automata. Wen-Guey Tzeng, 10.1137/0221017SIAM J. Comput. 212Wen-Guey Tzeng (1992): A Polynomial-Time Algorithm for the Equivalence of Probabilistic Automata. SIAM J. Comput. 21(2), pp. 216-227, doi:10.1137/0221017.

Hardness of Easy Problems: Basing Hardness on Popular Conjectures such as the Strong Exponential Time Hypothesis (Invited Talk). Virginia Vassilevska, Williams , 10.4230/LIPIcs.IPEC.2015.17doi:10. 4230/LIPIcs.IPEC.2015.17Proc. IPEC 2015. IPEC 2015Virginia Vassilevska Williams (2015): Hardness of Easy Problems: Basing Hardness on Popular Conjectures such as the Strong Exponential Time Hypothesis (Invited Talk). In: Proc. IPEC 2015, pp. 17-29, doi:10. 4230/LIPIcs.IPEC.2015.17.

The Complexity of Downward Closure Comparisons. Georg Zetzsche, 10.4230/LIPIcs.ICALP.2016.123Proc. ICALP 2016. ICALP 201655Georg Zetzsche (2016): The Complexity of Downward Closure Comparisons. In: Proc. ICALP 2016, LIPIcs 55, pp. 123:1-123:14, doi:10.4230/LIPIcs.ICALP.2016.123.

On complexity and optimization of expensive queries in complex event processing. Haopeng Zhang, Yanlei Diao &amp; Neil Immerman, 10.1145/2588555.2593671Proc. SIGMOD. SIGMODHaopeng Zhang, Yanlei Diao & Neil Immerman (2014): On complexity and optimization of expensive queries in complex event processing. In: Proc. SIGMOD 2014, pp. 217-228, doi:10.1145/2588555.2593671.