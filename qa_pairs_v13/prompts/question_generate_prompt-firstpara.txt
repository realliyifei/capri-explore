You are building a scientific question-answering dataset.
You will be given a content extracted from a paper.
You should construct the best question that would be answered by the information that summarizes by (some of) the content. 
Only return the question itself, without anything else.

# The requirements of the question:
1. Unambiguous: clearly framed to avoid follow-up questions for clarification.
2. Expert-level and natural: phrased as if asked by a domain expert conducting research
3. Answerable: should be answered by the information in the content 
4. Not overly broad: should not be so vague that it's unclear where to start
5. Standalone and not overly tailored: understandable by any expert without needing specific context or jargon anchored specifically in the given contents
6. Expect a long-form, comprehensive answer: not simply extractive or yes-no questions
7. Less than 20 words

# Given extracted content:
Paper Title: Societal Biases in Language Generation: Progress and Challenges
Section Title: Bias Definitions and Metrics
Extracted first paragraph of the section that contain the answer to the question:
In the context of AI fairness, the term “bias” commonly refers to skews that result in undesirable impacts (Crawford, 2017) and is quantifiable with some metric. There are relatively more existing studies on biases in NLU tasks, where it is arguably simpler to define bias metrics, since we can intuitively compare the accuracy of the task (e.g., coreference resolution, hate speech detection) for different demographics. Language generation tasks often involve stochastic generation of open-ended and lengthy texts, traits that are not directly compatible with traditional algorithmic bias definitions (e.g., equalized odds, equal opportunity, demographic parity (Dwork et al., 2012; Hardt et al., 2016)).
Question: In recent studies of natural language generation systems, what measures of social bias have been used recently?

# Given extracted content:
Paper Title: A Survey on Contextual Embeddings
Section Title: Cross-lingual Polyglot Pre-training for Contextual Embeddings
Extracted first paragraph of the section that contain the answer to the question:
Cross-lingual polyglot pre-training aims to learn joint multi-lingual representations, enabling knowledge transfer from data-rich languages like English to data-scarce languages like Romanian. Based on whether joint training and a shared vocabulary are used, we divide previous work into three categories.
Question: How do multilingual NLP models handle joint vocabularies during pretraining?

# Given extracted content:
Paper Title: A Primer on Contrastive Pretraining in Language Processing: Methods, Lessons Learned and Perspectives
Section Title: Noise Contrastive Estimation (NCE)
Extracted first paragraph of the section that contain the answer to the question:
Noise contrastive estimation is the objective used by most contrastive learning approaches within NLP. Thus, we briefly outline its main variants and the core ideas behind them, while pointing to [Ma and Collins, 2018]1 for detailed, yet readily understandable explanations of the two main NCE variants. Both variants can intuitively be understood as a sub-sampled softmax with K negative samples a−i and one positive sample a+i . The first variant expresses NCE as a binary objective (loss) in the form of maximum log likelihood, where only K negatives are considered.
Question: In contrastive learning objectives, what are recent perspectives on negative sampling?

# Given extracted content:
Paper Title: Modeling Language Variation and Universals: A Survey on Typological Linguistics for Natural Language Processing
Section Title: Hand-Crafted Documentation in Typological Databases
Extracted first paragraph of the section that contain the answer to the question:
Typological databases are created manually by linguists. They contain taxonomies of typological features, their possible values, as well as the documentation of feature values for the world’s languages. Major typological databases, listed in Table 1, typically organize linguistic information in terms of universal features and language-specific values. For example, Figure 3 presents language-specific values for the feature number of grammatical genders for nouns on a world map. Note that each language is color-coded according to its value. Further examples for each database can be found in the rightmost column of Table 1.
Question: What are the differences between publicly available linguistic typology databases?

# Given extracted content:
Paper Title: Analysis Methods in Neural Language Processing: A Survey
Section Title: Linguistic phenomena
Extracted first paragraph of the section that contain the answer to the question:
Different kinds of linguistic information have been analyzed, ranging from basic properties like sentence length, word position, word presence, or simple word order, to morphological, syntactic, and semantic information. Phonetic/phonemic information, speaker information, and style and accent information have been studied in neural network models for speech, or in joint audio-visual models. See Table SM1 for references.
Question: What linguistic phenomena can be caught by NLP models?

# Given extracted content:
Paper Title: Efficient Methods for Natural Language Processing: A Survey
Section Title: Sparse Modeling
Extracted first paragraph of the section that contain the answer to the question:
To leverage sparsity for efficiency, many models follow the mixture-of-experts (MoE) concept (Jacobs et al., 1991; Shazeer et al., 2017; Fedus et al., 2022a), which routes computation through small subnetworks instead of passing the input through the entire model. Relevant works on this line include GShard (Lepikhin et al., 2021), Switch Transformer (Fedus et al., 2022b), and ST-MoE (Zoph et al., 2022), which replace the feed forward layers in transformers with MoE layers. More recently, Rajbhandari et al. (2022) scaled transformers up by compressing and optimizing the usage of MoE. Overall, MoE models have been shown to achieve strong performance across several NLP tasks while reducing the overall resource consumption (Sec. 8). For instance, GLaM (Du et al., 2022) used only ∼1 3 of GPT-3’s energy consumption (with additional hardware-based optimization), while Rajbhandari et al. (2022) reached a 5x reduction in terms of training cost. However, MoE models have also exhibited training instabilities in practice, and may require architecture-specific implementation (Zoph et al., 2022; Mustafa et al., 2022).
Question: How can we utilize sparsity to enhance efficiency in designing NLP models?

# Given extracted content:
Paper Title: Neural Approaches to Conversational AI
Section Title: Speaker Consistency
Extracted first paragraph of the section that contain the answer to the question:
It has been shown that the popular seq2seq approach often produces conversations that are incoherent (Li et al., 2016b), where the system may for instance contradict what it had just said in the previous turn (or sometimes even in the same turn). While some of this effect can be attributed to the limitation of the learning algorithms, Li et al. (2016b) suggested that the main cause of this inconsistency is probably due to the training data itself. Indeed, conversational datasets (see Sec. 5.5) feature multiple speakers, which often have different or conflicting personas and backgrounds. For example, to the question “how old are you?”, a seq2seq model may give valid responses such as “23”, “27”, or “40”, all of which are represented in the training data.
Question: Why do conversation models often produce responses that are inconsistent with previous turns?

# Given extracted content:
Paper Title: [PAPER_TITLE]
Section Title: [SECTION_TITLE]
Extracted first paragraph of the section that contain the answer to the question:
[CONTENTS]
Question: 