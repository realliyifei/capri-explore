# A Survey on Causal Inference for Recommendation

CorpusID: 257637133 - [https://www.semanticscholar.org/paper/301b07ecba0864c5bad4039d6a0bc93687417443](https://www.semanticscholar.org/paper/301b07ecba0864c5bad4039d6a0bc93687417443)

Fields: Computer Science

## (s10) PO-BASED METHOD
Number of References: 3

(p10.0) Many causal recommendation approaches, especially in early research, focus on applying the potential outcome framework proposed by Donald B. Rubin [54,108,129] to the effect evaluation of the recommendation policy, more specifically, on the optimization functions in traditional deep-learning-based methods and on the reward functions in reinforcement-learning-based methods. Figure 5 provides the strategies, the objectives concerning the PO framework. As shown in Figure 5, There are generally two strategies in the potential outcome framework for RS, i.e., inverse propensity score and causal effect. It is worth mentioning that in this survey, a model estimating causal effects without a causal graph will be regarded as a PO-based model, while a model with a causal graph will be regarded as an SCM-based one, though both frameworks involve the estimation of causal effects. In this section, some related causal recommendation approaches are introduced in proper order according to the strategies shown in Figure 5.
## (s22) Doubly Robust.
Number of References: 12

(p22.0) Doubly Robust (DR) [22,26,56,143] is another powerful and effective causal method account for the MNAR issue. To understand DR, let us consider the two common-used approaches to mitigate against MNAR: direct method (DM) [7] and IPS [114]. The former designs a model (linear regression, deep neural network, etc.) to directly learn the missing outcomes based on the observed data, which has low variance due to the advantage of supervised learning but suffers from high bias caused by unmet IID assumptions, denoted as [114]: where^( , ) is the estimated outcomes. The latter, though unbiased theoretically, often causes training losses to oscillate stemming from the inverse of propensity with high variance [134]. What DR does is to combine the direct method and IPS, which takes advantage of both and overcomes their limitations:

(p22.1) DR uses the estimated outcomes to decrease the variance of IPS. It is also doubly robust in that it is consistent with the policy reward value if either the propensity scores or the imputed outcomes are accurate for all user-item pairs [114,143].

(p22.2) By the way, advanced versions like Switch-DR [145] and DRos (Doubly Robust with Optimistic Shrinkage) [131] are proposed to further control the variance.
## (s38) DICE [WWW'21]
Number of References: 9

(p38.0) Counterfactual inference with separate structures Fig. 15. Separate-learning-counterfactual-inference, a common pattern of SCM-based causal inference for recommender systems, learns causal effect with a separate structure or multi-task framework and performs counterfactual inference during testing. Though a popular tool, instrumental variable seems to find little application in recommender systems because of the difficulty of finding variables that satisfy the conditions of instrumental variables. As already cited above, Sharma et al. [124] utilize an instantaneous shock in direct traffic as an instrumental variable to evaluate the recommendation effect. Si et al. [126] propose a model-agnostic framework named IV4Rec that effectively decomposes the embedding vectors into two parts: the causal part indicating a user's personal preference for an item, and the non-causal part merely reflects the statistical dependencies between users and items such as exposure mechanism and display position,  [162] Intervention on the treatment MF, LightGCN, etc. Data insufficiency 2021 CauSeR [42].

(p38.1) Intervention on the treatment SR-GNN [153] Popularity bias in SBRSs 2021 MCT [135] Back-door criterion, CATE (self-designed) Disability employment 2021 DecRS [140] Intervention on the treatment FM, NFM [44] Bias amplification 2021 PDA [176] Intervention with users' search behaviors as the instrumental variable. More specifically, it modifies the traditional IV method, using the residual of the least square regression as the causal embedding instead of discarding it. The causal graph is illustrated in Fig. 17.
## (s43) Fairness and Explanation
Number of References: 4

(p43.0) The counterfactual technique is a natural tool for the evaluation of fairness since we can compare the outcome (ratings, recommendation lists, etc.) in the real world and in the counterfactual world in which only users' sensitive features (e.g., gender and race) are intervened [53,149]. As for explanation, counterfactuals describe a dependency on the external facts that lead to certain outcomes, and thus allow researchers to reason about the behavior of a black-box algorithm [? ]. Literature on counterfactual explanation also resorts to the "minimum" idea in counterfactuals. For example, [33] presents PRINCE (Provider-side Interpretability with Counterfactual Evidence) to search for a set of minimal actions performed by the user that, if removed, changes the recommendation to a different item, in a heterogeneous information network with users, items, and so on. To understand the point, consider the following example. If a user who has bought an iPhone and followed
