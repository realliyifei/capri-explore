# Multimodal Learning for Multi-Omics: A Survey

CorpusID: 254096119 - [https://www.semanticscholar.org/paper/ebf69dfc9306f3c0f0dbb2bd6916b81f953d872a](https://www.semanticscholar.org/paper/ebf69dfc9306f3c0f0dbb2bd6916b81f953d872a)

Fields: Computer Science, Medicine, Biology, Mathematics

## (s1) Multi-Omics Data
Number of References: 3

(p1.0) Multi-omics data are derived from different sources: molecular omics data, radiomics, and phenomics. Molecular omics data are the traditional dimension of multi-omics data, which aim to analyze the molecular biology of human diseases and consist of genomics, transcriptomics, proteomics, metabolomics, epigenomics, microbiomics, and exposomics. Radiomics, on the other hand, studies medical images collected from medical imaging technologies. 29 Phenomics is another valuable dimension of multi-omics data that comprises clinical and biochemical data of individuals. 30 Each source of omics data has been separately studied to answer biomedical questions. While different sources of information are complementary and contribute to the discovery of unique aspects of diseases, the fusion of multiple omics modalities has widely been done in existing research. Therefore, introducing each modality of omics data and their potential applications in solving biomedical tasks helps researchers consider all omics modalities in the long run. 18,31   an overview of multiple modalities of omics data and their applications applied to biomedical studies. Besides, the multiple omics data and their fusion for various tasks are visually presented in Figure 1.
## (s11) Heterogeneity
Number of References: 4

(p11.0) Each omics type has been collected using different high-throughput technologies, which have produced heterogeneous datasets. The heterogeneity of multi-omics data generates various data distributions and different data types (e.g., discrete, continuous, numerical, and categorical). 26 This variety of data distributions and types causes a considerable challenge to the learning model. Therefore, utilizing appropriate normalization and scaling approaches before any analysis has an essential role in achieving better performance. 20,112,113 Another way to deal with heterogeneity is using late fusion to build a different model for each omics data and then combine the results (see Section 4.2 for details).
## (s20) Datasets description
Number of References: 7

(p20.0) In this section, we briefly review important multi-omics datasets such as TCGA, 21,195,196 Kyoto Encyclopedia of Genes and Genomes (KEGG), [197][198][199] and the Human Protein Atlas (HPA). 200 TCGA was initiated by the effort between the National Cancer Institute (NCI) and the Center for Cancer Genomics Research Institute (NHGRI) with the aim of collecting, molecularly characterizing, and analyzing many cancers in 2006. This initiative has processed more than 20,000 patients to represent 33 cancer types and provided over 2.5 petabytes of data from different modalities, including genomics, epigenomics, transcriptomics, and proteomics. According to Google Scholar metrics, TCGA has been cited over 38,500 times as of July 2022, demonstrating the project's popularity among researchers. Another initiative is the KEGG program, conducted at Kyoto University as part of the Human Genome Program in 1995. The program's objective is to assign sets of genes in the genome with higher-order functional information that can help the biological interpretation of genomic information. KEGG has analyzed different omics types, including genomics, transcriptomics, proteomics, metabolomics, and other types. As another example, HPA collects transcriptomics and proteomics data for human tissue expression profiles. Table 4 lists other studies that focus on providing multi-omics data to enable the development of multi-omics fusion workflows.
