# Deep Unfolding for Communications Systems: A Survey and Some New Directions

CorpusID: 189762507 - [https://www.semanticscholar.org/paper/ee29c8642006b67422f2813494c4c1f23bb698a3](https://www.semanticscholar.org/paper/ee29c8642006b67422f2813494c4c1f23bb698a3)

Fields: Engineering, Computer Science, Mathematics

## (s12) C. Loss Functions
Number of References: 5

(p12.0) Novel application-tailored cost functions can improve the convergence of the training process. This can not only lead to better results for the same computational effort, but it may also enable real-time and online training of unfolded structures. Some examples of customized loss functions already exist (e.g., [29] uses a soft bit error function, [49] proposes a syndrome-based cost function, and [50] uses a cost function that is tailored to the quantum error-correction scenario), but they are mostly limited to channel decoding. All works on MIMO detection/precoding that we have described [9]- [15] use the standard mean-squared error (MSE) cost function. The MSE cost function has the advantage that closed-form solutions or very accurate iterative approximations can be derived in many cases. However, the MSE is not necessarily a good proxy for the error rate performance of the system. For example, in a multi-user MIMO setting, the system error rate will most likely be dominated by the user with the largest MSE. When optimizing an unfolded algorithm, even when the algorithm itself has been derived assuming an MSE cost function, it is typically easy to learn the optimal set of parameters for a different cost function. In the multiuser MIMO example mentioned previously, this could be the maximum MSE over all users, or even the maximum MSE over all users and all channel realizations in the training dataset.
