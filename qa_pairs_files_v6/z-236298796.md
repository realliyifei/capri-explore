# Flying Free: A Research Overview of Deep Learning in Drone Navigation Autonomy

CorpusID: 236298796 - [https://www.semanticscholar.org/paper/f1e33066557b26f24113450c9a852f7821aea874](https://www.semanticscholar.org/paper/f1e33066557b26f24113450c9a852f7821aea874)

Fields: Engineering, Computer Science

## (s17) Common Learning Models
Number of References: 6

(p17.0) Three particular Deep Learning models appear most frequently in the research pool in support of autonomous decision making. Firstly, "VGG-16" [40] is a CNN image classifier that has been trained on the "ImageNet" dataset [41] of over 14 million images matched to thousands of labels. VGG-16 supports wide-ranging image classification or can serve as a base for transfer learning with fine-tuning using images specific to a target drone environment. The majority of research works that adopt it or the object detection model "YoloV3" [42] in the research pool use it as a base for collision avoidance or object detection/distinction. The "ResNet" architecture [43] originates from a CNN-based paper discussing the optimisation of the "AlexNet" architecture [44] through the utilisation of residual layer "shortcuts" that can approximate the activity of entire neural layers. Similar to VGG-16, ResNet is trained on the ImageNet dataset. The benefit of ResNet's shortcuts architecture is a considerable reduction of processing overhead, resulting in efficient models with low response times but maintaining comparable accuracy. This is favourable for drone operations that require a low CPU overhead. "DroNet" is more specific to the area of autonomous drone navigation and applies manually labelled car and bicycle footage as training data for navigation in an urban environment. Outputs for DroNet from a single image are specific to the purposes of drone navigation, providing a steering angle, to keep the drone navigating while avoiding obstacles, and a collision probability, to let the UAV recognize dangerous situations and promptly react to them. As a purpose-built autonomous drone network, the DroNet work [22] is highly cited and used as a base network for several other papers in the research pool.
## (s20) Issues
Number of References: 2

(p20.0) Most research works explain their approach to model training and testing, explaining the chosen ground truth, labels and descriptions of how the navigation system interfaces with the CNN model. One issue to highlight, however, is a lack of uniformity of metrics in the domain. Some papers evaluate their approach using environment-specific metrics, such as the number of successful laps [46] and performance at different speeds [23]. In the DNN research space, the inclusion of visual descriptions of architectures and evaluation results comparing similar architectural or function-level approaches is crucial to the explainability of the project. The use of research work-specific metrics, when displayed without connection to a more common metric such as accuracy, makes it difficult to compare the performance of autonomous navigation approaches across the domain.
