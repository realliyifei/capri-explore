# The Sentiment Problem: A Critical Survey towards Deconstructing Sentiment Analysis

## Question

How is sentiment defined in the context of finance, and what are the common assumptions made about it in most studies?

## URLs

1. https://ar5iv.org/html/2411.13180. [2411.13180] Investor Sentiment in Asset Pricing Models: A Review of Empirical Evidence
2. https://ar5iv.org/html/2312.14978. [2312.14978] On Quantifying Sentiments of Financial News -- Are We Doing the Right Things?
3. https://ar5iv.org/html/2404.08681. [2404.08681] EFSA: Towards Event-Level Financial Sentiment Analysis
4. https://ar5iv.org/html/2411.00420. [2411.00420] Evaluating Company-specific Biases in Financial Sentiment Analysis using Large Language Models
5. https://ar5iv.org/html/2401.05799. [2401.05799] Designing Heterogeneous LLM Agents for Financial Sentiment Analysis
6. https://ar5iv.org/html/1811.02886. [1811.02886] Using Stock Prices as Ground Truth in Sentiment Analysis to Generate Profitable Trading Signals
7. https://ar5iv.org/html/1908.10063. [1908.10063] FinBERT: Financial Sentiment Analysis with Pre-trained Language Models
8. https://ar5iv.org/html/2405.01586. [2405.01586] Transfer Learning and Transformer Architecture for Financial Sentiment Analysis

## Answer (I don't know?: ✗)

In the context of finance, sentiment is defined as the extraction of sentiments or opinions from written language, specifically regarding financial texts. This includes the classification of financial statements, analyst reports, and other related documents as expressing positive, negative, or neutral sentiments [1] [4]. The task of sentiment analysis aims to capture the emotional tone and implications behind the specific language used in financial discourse, which often employs specialized vocabulary and tends to utilize vague expressions rather than clear-cut positive or negative terms [2].

Common assumptions made in most studies concerning financial sentiment include the belief that the sentiment expressed in text accurately reflects the true opinions of the authors and, by extension, the prevailing market sentiment [3]. This assumption is critical as it underpins the rationale for using sentiment analysis to inform investment decisions. Consequently, if the sentiment analysis misrepresents the underlying opinions, it could lead to trading decisions that are based on skewed or inaccurate interpretations of market conditions. 

Additionally, there is an implicit reliance on existing methodologies, such as sentiment dictionaries tailored to financial language, while acknowledging their limitations. For example, while sentiment analysis models trained on general text corpora are deemed unsuitable due to their inability to effectively interpret the specialized language of finance, the dictionaries based on "word counting" face challenges in capturing deeper semantic meanings [2] [4].

Another assumption is that data drawn from platforms like StockTwits, where users label their posts as 'bullish' or 'bearish,' might reflect authentic sentiment. However, this is complicated by evidence of biases in user-generated labels. It has been observed that day traders may mislabel their sentiment, with 'Hold' labels tending to convey a positive sentiment rather than a neutral position [3]. Hence, reliance on such biases can mislead sentiment analysis and, ultimately, affect trading strategies negatively.

Overall, the definition of sentiment in finance involves discerning nuanced emotional tones in specialized text, while prevalent assumptions implicate the authenticity of expressed sentiments and the accuracy of classification methods employed.

1. [1]:  https://ar5iv.org/html/2411.00420, [2411.00420] Evaluating Company-specific Biases in Financial Sentiment Analysis using Large Language Models
2. [2]:  https://ar5iv.org/html/1908.10063, [1908.10063] FinBERT: Financial Sentiment Analysis with Pre-trained Language Models
3. [3]:  https://ar5iv.org/html/1811.02886, [1811.02886] Using Stock Prices as Ground Truth in Sentiment Analysis to Generate Profitable Trading Signals
4. [4]:  https://ar5iv.org/html/1908.10063, [1908.10063] FinBERT: Financial Sentiment Analysis with Pre-trained Language Models
5. [5]:  https://ar5iv.org/html/2405.02454, No Title
---
1. [1]:  Passage ID 1: and stock performance.Index Terms: large language model, sentiment analysis, bias, financial text miningI IntroductionWith the advancement of natural language processing (NLP) technology, financial and economic text mining—such as analyzing financial statements, analyst reports, social media texts and newspaper articles—has become an essential tool for investment decisions, understanding economic trends, and improving operational efficiency in financial institutions[1, 2].In particular, sentiment analysis of financial and economic text data has played a crucial role in understanding investor decision-making and market trends.The use of large language models (LLMs) in sentiment analysis has raised expectations for higher quality sentiment evaluation [3, 4].However, since financial and investment decisions typically have significant risk, both accuracy and reliability are required in predictions [5, 6].Therefore, ensuring that LLM outputs are accurate and trustworthy
2. [2]:  Passage ID 2: the last decade (Guo et al., 2016).The principal research interest for this thesis is the polarity analysis, which is classifying text as positive, negative or neutral, in a specific domain. It requires to address two challenges: 1) The most sophisticated classification methods that make use of neural nets require vast amounts of labeled data and labeling financial text snippets requires costly expertise. 2) The sentiment analysis models trained on general corpora are not suited to the task, because financial texts have a specialized language with unique vocabulary and have a tendency to use vague expressions instead of easily-identified negative/positive words.Using carefully crafted financial sentiment lexicons such as Loughran and McDonald (2011) (Loughran andMcdonald, 2011) may seem a solution because they incorporate existing financial knowledge into textual analysis. However, they are based on ”word counting” methods, which come short in analyzing deeper semantic meaning
3. [3]:  Passage ID 3: need to reduce the scope of information is made by [9], where the common misclassification of sentiment in financial texts was the motivation for constructing a sentiment dictionary specifically tuned to language used in financial literature.A major assumption made in all related work that we are familiar with, is that the sentiment expressed in text reflects the true opinions held by the authors, and by extension the true market sentiment. The implications of such an assumption could result in trading decisions being based on information not representative of the true underlying market sentiment. Some works choose to use self-labelled data such as messages posted on StockTwits, a financial communication platform where users can label their posts as ‘bullish’ or ‘bearish’. However there is evidence of strong biases present in the recommendations made by day traders, in particular with self-disclosed Hold labels actually conveying a positive sentiment rather than neutral [18]. This
4. [4]:  Passage ID 4: different perspectives in Section 6. Finally, we conclude with Section 7.2. Related LiteratureThis section describes previous research conducted on sentiment analysis in finance (2.1) and text classification using pre-trained language models (2.2).2.1. Sentiment analysis in financeSentiment analysis is the task of extracting sentiments or opinions of people from written language (Liu, 2012). We can divide the recent efforts into two groups: 1) Machine learning methods with features extracted from text with ”word counting” (Agarwal andMittal, 2016; Whitelawet al., 2005; Martineau andFinin, 2009; Tripathyet al., 2016), 2) Deep learning methods, where text is represented by a sequence of embeddings (Severyn andMoschitti, 2015; Araque et al., 2017; Zhanget al., 2018). The former suffers from inability to represent the semantic information that results from a particular sequence of words, while the latter is often deemed as too ”data-hungry” as it learns a much higher
5. [5]:  Passage ID 5: of the text analysis task, and then the model executes the task based on the description. However, the ambiguous nature of sentiment outlined above raises an important question: How do large language models understand the task of “sentiment analysis” when prompted to do it? If the model’s understanding of sentiment is not consistent with the researcher’s, they may not be measuring what they think they are. Further, if sentiment is a confounded measurement, would text analysis improve if we disambiguate the term and measure more precise concepts? In the following sections I present answers to these questions.2 Data and MethodsI approach these questions by using LLMs to classify documents three different times: once for sentiment, once for emotional valence, and a final time for stance (opinion). I then evaluate which of the classification approaches is best able to recover manual labels from two data sets, and examine how well sentiment classifications correlate with both opinion