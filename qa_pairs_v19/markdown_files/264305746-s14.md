# The Sentiment Problem: A Critical Survey towards Deconstructing Sentiment Analysis

## Question

How is sentiment defined in the context of finance, and what are the common assumptions made about it in most studies?

## URLs

1. https://ar5iv.org/html/2411.13180. [2411.13180] Investor Sentiment in Asset Pricing Models: A Review of Empirical Evidence
2. https://ar5iv.org/html/2312.14978. [2312.14978] On Quantifying Sentiments of Financial News -- Are We Doing the Right Things?
3. https://ar5iv.org/html/2404.08681. [2404.08681] EFSA: Towards Event-Level Financial Sentiment Analysis
4. https://ar5iv.org/html/2411.00420. [2411.00420] Evaluating Company-specific Biases in Financial Sentiment Analysis using Large Language Models
5. https://ar5iv.org/html/2401.05799. [2401.05799] Designing Heterogeneous LLM Agents for Financial Sentiment Analysis
6. https://ar5iv.org/html/1811.02886. [1811.02886] Using Stock Prices as Ground Truth in Sentiment Analysis to Generate Profitable Trading Signals
7. https://ar5iv.org/html/1908.10063. [1908.10063] FinBERT: Financial Sentiment Analysis with Pre-trained Language Models
8. https://ar5iv.org/html/2405.01586. [2405.01586] Transfer Learning and Transformer Architecture for Financial Sentiment Analysis

## Answer (I don't know?: ✗)

In the context of finance, sentiment analysis is defined as the task of extracting sentiments or opinions of people from written language related to financial topics. This involves classifying texts—such as financial statements, analyst reports, and social media posts—as positive, negative, or neutral, which is particularly important for understanding investor decision-making and market trends [1][4]. Financial sentiment analysis is intricate due to the specialized vocabulary and often vague expressions used in financial texts, as the language may not readily lend itself to clear-cut positive or negative classifications [2].

Common assumptions made in most studies regarding sentiment in financial texts include the belief that the sentiments expressed in these texts reflect the true opinions of the authors, and by extension, the actual market sentiment [3]. This assumption implies that the classification of sentiment can provide insights into how market participants perceive value and risk, influencing trading decisions significantly [3]. However, such assumptions can lead to potentially misleading inferences if the sentiments are not truly representative. For example, biases are prevalent in self-reported sentiments, such as those on platforms like StockTwits, where traders label their messages but may convey sentiments that do not accurately represent their true intentions [3]. Self-disclosed "Hold" positions have been shown to often imply a positive sentiment rather than a neutral one, which can skew data interpretations [3].

Furthermore, challenges in training sentiment analysis models due to the unique characteristics of financial language further complicate these assumptions. Models trained on general corpora, for instance, may not perform well on financial texts, leading to inaccuracies in sentiment classification [2][4]. Hence, while the premise of sentiment reflecting true market feelings is foundational in the literature, it is encumbered by risks of misclassification and biased interpretations, suggesting the necessity for specialized approaches and adjustments in definitions and methodologies related to sentiment analysis in the financial domain. 

Thus, the significance and execution of sentiment analysis in finance hinge on a careful understanding of both the subjective nature of sentiments and the technical requirements of accurately capturing them, necessitating concise frameworks and sophisticated evaluation methods to ensure reliable outputs [1][5].

1. [1]:  https://ar5iv.org/html/2411.00420, [2411.00420] Evaluating Company-specific Biases in Financial Sentiment Analysis using Large Language Models
2. [2]:  https://ar5iv.org/html/1908.10063, [1908.10063] FinBERT: Financial Sentiment Analysis with Pre-trained Language Models
3. [3]:  https://ar5iv.org/html/1811.02886, [1811.02886] Using Stock Prices as Ground Truth in Sentiment Analysis to Generate Profitable Trading Signals
4. [4]:  https://ar5iv.org/html/1908.10063, [1908.10063] FinBERT: Financial Sentiment Analysis with Pre-trained Language Models
5. [5]:  https://ar5iv.org/html/2405.02454, No Title
---
1. [1]:  Passage ID 1: and stock performance.Index Terms: large language model, sentiment analysis, bias, financial text miningI IntroductionWith the advancement of natural language processing (NLP) technology, financial and economic text mining—such as analyzing financial statements, analyst reports, social media texts and newspaper articles—has become an essential tool for investment decisions, understanding economic trends, and improving operational efficiency in financial institutions[1, 2].In particular, sentiment analysis of financial and economic text data has played a crucial role in understanding investor decision-making and market trends.The use of large language models (LLMs) in sentiment analysis has raised expectations for higher quality sentiment evaluation [3, 4].However, since financial and investment decisions typically have significant risk, both accuracy and reliability are required in predictions [5, 6].Therefore, ensuring that LLM outputs are accurate and trustworthy
2. [2]:  Passage ID 2: the last decade (Guo et al., 2016).The principal research interest for this thesis is the polarity analysis, which is classifying text as positive, negative or neutral, in a specific domain. It requires to address two challenges: 1) The most sophisticated classification methods that make use of neural nets require vast amounts of labeled data and labeling financial text snippets requires costly expertise. 2) The sentiment analysis models trained on general corpora are not suited to the task, because financial texts have a specialized language with unique vocabulary and have a tendency to use vague expressions instead of easily-identified negative/positive words.Using carefully crafted financial sentiment lexicons such as Loughran and McDonald (2011) (Loughran andMcdonald, 2011) may seem a solution because they incorporate existing financial knowledge into textual analysis. However, they are based on ”word counting” methods, which come short in analyzing deeper semantic meaning
3. [3]:  Passage ID 3: need to reduce the scope of information is made by [9], where the common misclassification of sentiment in financial texts was the motivation for constructing a sentiment dictionary specifically tuned to language used in financial literature.A major assumption made in all related work that we are familiar with, is that the sentiment expressed in text reflects the true opinions held by the authors, and by extension the true market sentiment. The implications of such an assumption could result in trading decisions being based on information not representative of the true underlying market sentiment. Some works choose to use self-labelled data such as messages posted on StockTwits, a financial communication platform where users can label their posts as ‘bullish’ or ‘bearish’. However there is evidence of strong biases present in the recommendations made by day traders, in particular with self-disclosed Hold labels actually conveying a positive sentiment rather than neutral [18]. This
4. [4]:  Passage ID 4: different perspectives in Section 6. Finally, we conclude with Section 7.2. Related LiteratureThis section describes previous research conducted on sentiment analysis in finance (2.1) and text classification using pre-trained language models (2.2).2.1. Sentiment analysis in financeSentiment analysis is the task of extracting sentiments or opinions of people from written language (Liu, 2012). We can divide the recent efforts into two groups: 1) Machine learning methods with features extracted from text with ”word counting” (Agarwal andMittal, 2016; Whitelawet al., 2005; Martineau andFinin, 2009; Tripathyet al., 2016), 2) Deep learning methods, where text is represented by a sequence of embeddings (Severyn andMoschitti, 2015; Araque et al., 2017; Zhanget al., 2018). The former suffers from inability to represent the semantic information that results from a particular sequence of words, while the latter is often deemed as too ”data-hungry” as it learns a much higher
5. [5]:  Passage ID 5: of the text analysis task, and then the model executes the task based on the description. However, the ambiguous nature of sentiment outlined above raises an important question: How do large language models understand the task of “sentiment analysis” when prompted to do it? If the model’s understanding of sentiment is not consistent with the researcher’s, they may not be measuring what they think they are. Further, if sentiment is a confounded measurement, would text analysis improve if we disambiguate the term and measure more precise concepts? In the following sections I present answers to these questions.2 Data and MethodsI approach these questions by using LLMs to classify documents three different times: once for sentiment, once for emotional valence, and a final time for stance (opinion). I then evaluate which of the classification approaches is best able to recover manual labels from two data sets, and examine how well sentiment classifications correlate with both opinion