# Multiword Expression Processing: A Survey under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license Computational Linguistics

## Question

How do methods using parallel corpora identify and filter multiword expression (MWE) candidates in multilingual discovery?

## URLs

1. https://ar5iv.org/html/2011.03783. [2011.03783] AlphaMWE: Construction of Multilingual Parallel Corpora with MWE Annotations
2. https://ar5iv.org/html/1903.10921. [1903.10921] A New Approach for Semi-automatic Building and Extending a Multilingual Terminology Thesaurus11footnote 1Preprint of an article submitted for consideration in International Journal on Artificial Intelligence Tools © 2019 copyright World Scientific Publishing Company https://www.worldscientific.com/worldscinet/ijait
3. https://ar5iv.org/html/2210.04545. [2210.04545] Automatic Evaluation and Analysis of Idioms in Neural Machine Translation
4. https://ar5iv.org/html/2310.18345. [2310.18345] A Survey on Semantic Processing Techniques
5. https://ar5iv.org/html/2310.14610. [2310.14610] That was the last straw, we need more: Are Translation Systems Sensitive to Disambiguating Context?
6. https://ar5iv.org/html/2306.06205. [2306.06205] Morphosyntactic Probing of Multilingual BERT Models
7. https://ar5iv.org/html/2011.14190. [2011.14190] Using Multiple Subwords to Improve English-Esperanto Automated Literary Translation Quality
8. https://ar5iv.org/html/2401.16313. [2401.16313] Machine Translation Meta Evaluation through Translation Accuracy Challenge Sets
9. https://ar5iv.org/html/2409.01087. [2409.01087] Pre-Trained Language Models for Keyphrase Prediction: A Review
10. https://ar5iv.org/html/2307.06435. [2307.06435] A Comprehensive Overview of Large Language Models

## Answer (I don't know?: ✗)

Methods using parallel corpora to identify and filter multiword expression (MWE) candidates in multilingual discovery typically involve several key processes. These processes are primarily grounded in the construction and annotation of multilingual corpora, machine translation, and advanced data collection techniques.

Firstly, the creation of multilingual parallel corpora with MWE annotations involves gathering source texts in various languages and aligning them to facilitate comparison. One significant project, AlphaMWE, focuses on annotating multiword expressions (MWEs) within its multilingual datasets, which includes languages such as English, Chinese, Polish, and German [1], [5]. The identification of these MWEs relies on thorough manual annotation aligned with the definitions provided in the PARSEME shared task [1], ensuring that the MWEs identified are relevant and accurately represented across languages.

Once the parallel corpora are established, machine translation (MT) is employed to translate the source text into target languages. This includes a rigorous post-editing phase where human annotators refine the translations and possibly flag MWEs that have unique meanings or usages in different languages [1], [5]. The challenges faced during this translation process, particularly concerning the accurate representation of MWEs, are significant and form a critical basis for filtering candidates [5]. Various error types encountered by MT systems are categorized, which informs the understanding and debugging of how MWEs are handled across different MT models [5]. This categorization aids in refining the identification process by highlighting common translation pitfalls related to MWEs.

Moreover, the process of identifying MWE candidates can leverage tools developed for specific tasks. For instance, a phrase-matching tool has been created to search for idioms and specific expressions within parallel datasets, which automates the extraction and annotation of these linguistic features [3]. Such tools enhance the efficiency of identifying potential MWEs by systematically comparing the spans in which these expressions occur in the source and target languages.

Quality control remains a pivotal aspect throughout these methodologies. The AlphaMWE project emphasizes strict quality control measures during the translation and annotation stages to mitigate errors, confirming that outputs are not only accurate in language translation but also in the representation of MWEs [1], [5]. This dual-layered approach of both manual checking and developing automated tools ensures that the MWE candidates identified are robust and reliable for further NLP tasks.

In conclusion, methods that use parallel corpora in multilingual discovery of MWEs combine manual annotation, machine translation with meticulous post-editing, and automated tools for data collection, all under stringent quality control measures. This integrated approach supports the accurate filtering and identification of multiword expressions across languages, which is crucial for advancing research in machine translation and other NLP applications.

1. [1]:  https://ar5iv.org/html/2011.03783, [2011.03783] AlphaMWE: Construction of Multilingual Parallel Corpora with MWE Annotations
2. [2]:  https://ar5iv.org/html/2210.04545, [2210.04545] Automatic Evaluation and Analysis of Idioms in Neural Machine Translation
3. [3]:  https://ar5iv.org/html/2210.04545, [2210.04545] Automatic Evaluation and Analysis of Idioms in Neural Machine Translation
4. [4]:  https://ar5iv.org/html/2011.03783, [2011.03783] AlphaMWE: Construction of Multilingual Parallel Corpora with MWE Annotations
5. [5]:  https://ar5iv.org/html/2011.03783, [2011.03783] AlphaMWE: Construction of Multilingual Parallel Corpora with MWE Annotations
---
1. [1]:  Passage ID 1: Science > Computation and LanguagearXiv:2011.03783 (cs)  [Submitted on 7 Nov 2020]Title:AlphaMWE: Construction of Multilingual Parallel Corpora with MWE AnnotationsAuthors:Lifeng Han, Gareth Jones, Alan Smeaton View a PDF of the paper titled AlphaMWE: Construction of Multilingual Parallel Corpora with MWE Annotations, by Lifeng Han and 2 other authorsView PDFAbstract:In this work, we present the construction of multilingual parallel corpora with annotation of multiword expressions (MWEs). MWEs include verbal MWEs (vMWEs) defined in the PARSEME shared task that have a verb as the head of the studied terms. The annotated vMWEs are also bilingually and multilingually aligned manually. The languages covered include English, Chinese, Polish, and German. Our original English corpus is taken from the PARSEME shared task in 2018. We performed machine translation of this source corpus followed by human post editing and annotation of target MWEs. Strict quality control was applied
2. [2]:  Passage ID 2: and Carlos Ramisch, editors. 2021.Proceedings ofthe 17th Workshop on Multiword Expressions (MWE 2021). Association forComputational Linguistics, Online.Dou and Neubig (2021)Zi-Yi Dou and Graham Neubig. 2021.Wordalignment by fine-tuning embeddings on parallel corpora.In Proceedings of the 16th Conference of the European Chapterof the Association for Computational Linguistics: Main Volume, pages2112–2128, Online. Association for Computational Linguistics.Dyer et al. (2013)Chris Dyer, Victor Chahuneau, and Noah A. Smith. 2013.A simple, fast, andeffective reparameterization of IBM model 2.In Proceedings of the 2013 Conference of the North AmericanChapter of the Association for Computational Linguistics: Human LanguageTechnologies, pages 644–648, Atlanta, Georgia. Association forComputational Linguistics.Fadaee et al. (2018)Marzieh Fadaee, Arianna Bisazza, and Christof Monz. 2018.Examining the tip of theiceberg: A data set for idiom
3. [3]:  Passage ID 3: on Empirical Methods inNatural Language Processing (EMNLP), pages 4896–4907, Online. Associationfor Computational Linguistics.Zaninello and Birch (2020)Andrea Zaninello and Alexandra Birch. 2020.Multiwordexpression aware neural machine translation.In Proceedings of the 12th Language Resources and EvaluationConference, pages 3816–3825, Marseille, France. European Language ResourcesAssociation.Appendix A Idiom Data CollectionWe collected parallel data with idioms in the source side andannotated the spans in which the idioms occur within each sentence.This enables us to conduct controlled experiments and to support our targeted evaluation metrics and our analysis.To collect the data,we created a phrase-matching tool that searches for idioms in parallel dataand extracts and annotates the retrieved pairs (Figure 8).Figure 8: Overview of the process for collecting the idiom parallel data.Figure 9: Overview of the process for collecting the idiom
4. [4]:  Passage ID 4: PDF of the paper titled AlphaMWE: Construction of Multilingual Parallel Corpora with MWE Annotations, by Lifeng Han and 2 other authorsView PDFOther Formatsview license  Current browse context: cs.CL< prev  |   next >new | recent | 2020-11 Change to browse by: cscs.AIReferences & CitationsNASA ADSGoogle ScholarSemantic ScholarDBLP - CS Bibliographylisting | bibtex Lifeng HanGareth J. F. JonesAlan F. Smeaton aexport BibTeX citationLoading...BibTeX formatted citation×loading...Data provided by: Bookmark Bibliographic ToolsBibliographic and Citation ToolsBibliographic Explorer ToggleBibliographic Explorer (What is the Explorer?)Connected Papers ToggleConnected Papers (What is Connected Papers?)Litmaps ToggleLitmaps (What is Litmaps?)scite.ai Togglescite Smart Citations (What are Smart Citations?)Code, Data, MediaCode, Data and Media Associated with this
5. [5]:  Passage ID 5: is taken from the PARSEME shared task in 2018. We performed machine translation of this source corpus followed by human post editing and annotation of target MWEs. Strict quality control was applied for error limitation, i.e., each MT output sentence received first manual post editing and annotation plus second manual quality rechecking. One of our findings during corpora preparation is that accurate translation of MWEs presents challenges to MT systems. To facilitate further MT research, we present a categorisation of the error types encountered by MT systems in performing MWE related translation. To acquire a broader view of MT issues, we selected four popular state-of-the-art MT models for comparisons namely: Microsoft Bing Translator, GoogleMT, Baidu Fanyi and DeepL MT. Because of the noise removal, translation post editing and MWE annotation by human professionals, we believe our AlphaMWE dataset will be an asset for cross-lingual and multilingual research, such as MT and