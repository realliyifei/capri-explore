# Through the Lens of Core Competency: Survey on Evaluation of Large Language Models

## Question

How do datasets like RealToxicityPrompts and BAD help in understanding and evaluating harmful content in large language models (LLMs)?

## URLs

1. https://ar5iv.org/html/2405.10659. [2405.10659] Realistic Evaluation of Toxicity in Large Language Models
2. https://ar5iv.org/html/2410.12974. [2410.12974] BenchmarkCards: Large Language Model and Risk Reporting
3. https://ar5iv.org/html/2401.05561. [2401.05561] TrustLLM: Trustworthiness in Large Language Models
4. https://ar5iv.org/html/2410.15821. [2410.15821] The effect of fine-tuning on language model toxicity
5. https://ar5iv.org/html/2401.05778. [2401.05778] Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems
6. https://ar5iv.org/html/2403.14988. [2403.14988] Risk and Response in Large Language Models: Evaluating Key Threat Categories
7. https://ar5iv.org/html/2411.00027. [2411.00027] Personalization of Large Language Models: A Survey
8. https://ar5iv.org/html/2407.18418. [2407.18418] The Art of Refusal: A Survey of Abstention in Large Language Models
9. https://ar5iv.org/html/2009.11462. [2009.11462] Untitled Document
10. https://ar5iv.org/html/2308.05374. [2308.05374] Untitled Document

## Answer (I don't know?: âœ—)

Error: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable