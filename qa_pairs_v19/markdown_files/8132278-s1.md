# A Survey of Idiomatic Preposition-Noun-Verb Triples on Token Level

## Question

How can idiomatic and literal uses of multiword expressions (MWEs) be automatically distinguished, and what are some methods used for English?

## URLs

1. https://ar5iv.org/html/2403.02009
2. https://ar5iv.org/html/2304.14333
3. https://ar5iv.org/html/2211.05201
4. https://ar5iv.org/html/2204.10050
5. https://ar5iv.org/html/2411.02610
6. https://ar5iv.org/html/2410.03394
7. https://ar5iv.org/html/2308.13961
8. https://ar5iv.org/html/2401.15393
9. https://ar5iv.org/html/1810.09947

## Answer

## I don't know?: False

The automatic distinction between idiomatic and literal uses of multiword expressions (MWEs) in Natural Language Processing (NLP) is a complex challenge that hinges on the semantic representation of expressions and their contextual usage. Idiomatic expressions exhibit linguistic behavior that significantly differs from literal combinations of words, affecting their syntactic and semantic structures [1] [2]. 

One effective approach for this distinction involves leveraging semantic text similarity tasks, where models are trained to represent MWEs adequately in context. This often incorporates tasks that identify whether a sentence contains an idiomatic expression alongside a semantic similarity measure that analyzes the meaning of the expressions based on various contextual frameworks [1] [2]. The training for such models can utilize diverse datasets annotated for idiomatic and literal meanings, which may include multiple languages, with English being a primary focus [1] [2].

In practice, to automate this distinction effectively, systems can be built employing various linguistic features and machine learning techniques. For instance, the use of machine learning classifiers that take into account the syntactic structures, semantic roles, and contextual cues of sentences can prove beneficial. These classifiers can be trained on annotated corpora where instances of MWEs are explicitly tagged as idiomatic or literal, allowing the model to learn the distinct patterns associated with each use [4] [5].

Additionally, different settings regarding the amount of training data can be employed in various subtasks. This flexibility enables researchers to model complexities related to MWEs effectively, adapting methodologies based on data availability and the specificities of the idiomatic expressions they aim to distinguish [1] [2].

Machine Translation Evaluation (MTE) also plays a critical role in identifying MWEs by assessing how well systems can recognize and translate them in an accurate and meaning-equivalent manner. This evaluation could include a Human-in-the-Loop approach, where human evaluators assess the fluency and adequacy of translations involving MWEs, thus contributing to a better understanding and enhancement of automatic detection mechanisms [4] [5].

In conclusion, distinguishing between idiomatic and literal uses of MWEs inherently requires sophisticated NLP systems that utilize semantic contextual analysis and robust machine learning models trained on specifically annotated datasets. Continued research into text similarity and the nuances of MWEs remains vital in improving these automated systems.

1. [1]:  https://ar5iv.org/html/2204.10050, [2204.10050] SemEval-2022 Task 2: Multilingual Idiomaticity Detection and Sentence Embedding
2. [2]:  https://ar5iv.org/html/2204.10050, [2204.10050] SemEval-2022 Task 2: Multilingual Idiomaticity Detection and Sentence Embedding
3. [3]:  https://ar5iv.org/html/2204.10050, [2204.10050] SemEval-2022 Task 2: Multilingual Idiomaticity Detection and Sentence Embedding
4. [4]:  https://ar5iv.org/html/2211.05201, [2211.05201] HilMeMe: A Human-in-the-Loop Machine Translation Evaluation Metric Looking into Multi-Word Expressions
5. [5]:  https://ar5iv.org/html/2211.05201, [2211.05201] HilMeMe: A Human-in-the-Loop Machine Translation Evaluation Metric Looking into Multi-Word Expressions
---
1. [1]:  Passage ID 1: at identifying whether a sentence contains an idiomatic expression, and (b) a task based on semantic text similarity which requires the model to adequately represent potentially idiomatic expressions in context. Each Subtask includes different settings regarding the amount of training data. Besides the task description, this paper introduces the datasets in English, Portuguese, and Galician and their annotation procedure, the evaluation metrics, and a summary of the participant systems and their results. The task had close to 100 registered participants organised into twenty five teams making over 650 and 150 submissions in the practice and evaluation phases respectively.1 IntroductionMultiword Expressions (MWEs) are a challenge for natural language processing (NLP), as their linguistic behaviour (e.g., syntactic, semantic) differs from that of generic word combinations Baldwin and Kim (2010); Ramisch and Villavicencio (2018). Moreover, MWEs are pervasive in all domains Biber
2. [2]:  Passage ID 2: at identifying whether a sentence contains an idiomatic expression, and (b) a task based on semantic text similarity which requires the model to adequately represent potentially idiomatic expressions in context. Each Subtask includes different settings regarding the amount of training data. Besides the task description, this paper introduces the datasets in English, Portuguese, and Galician and their annotation procedure, the evaluation metrics, and a summary of the participant systems and their results. The task had close to 100 registered participants organised into twenty five teams making over 650 and 150 submissions in the practice and evaluation phases respectively.1 IntroductionMultiword Expressions (MWEs) are a challenge for natural language processing (NLP), as their linguistic behaviour (e.g., syntactic, semantic) differs from that of generic word combinations Baldwin and Kim (2010); Ramisch and Villavicencio (2018). Moreover, MWEs are pervasive in all domains Biber
3. [3]:  Passage ID 3: at identifying whether a sentence contains an idiomatic expression, and (b) a task based on semantic text similarity which requires the model to adequately represent potentially idiomatic expressions in context. Each Subtask includes different settings regarding the amount of training data. Besides the task description, this paper introduces the datasets in English, Portuguese, and Galician and their annotation procedure, the evaluation metrics, and a summary of the participant systems and their results. The task had close to 100 registered participants organised into twenty five teams making over 650 and 150 submissions in the practice and evaluation phases respectively.1 IntroductionMultiword Expressions (MWEs) are a challenge for natural language processing (NLP), as their linguistic behaviour (e.g., syntactic, semantic) differs from that of generic word combinations Baldwin and Kim (2010); Ramisch and Villavicencio (2018). Moreover, MWEs are pervasive in all domains Biber
4. [4]:  Passage ID 4: Multi-word Expressions (MWEs). MWEs have played a bottleneck in many Natural Language Processing (NLP) tasks including MT. MWEs can be used as one of the main factors to distinguish different MT systems by looking into their capabilities on recognising and translating MWEs in an accurate and meaning equivalent manner.Keywords: Machine Translation Evaluation, Multi-word Expressions, Human-in-the-Loop Evaluation, Fluency and Adequacy, Domain-specific Terminology\newciteslanguageresourceLanguage ResourcesHilMeMe: A Human-in-the-Loop Machine Translation Evaluation Metric Looking into Multi-Word ExpressionsLifeng HanThe University of Manchesterlifeng.han@manchester.ac.ukAbstract content1.   IntroductionMachine Translation Evaluation (MTE) has been a long-term challenging research topic since the development of MT. MTE plays an important role in MT development and quality evaluation.Popular automatic evaluation metrics have failed to correctly
5. [5]:  Passage ID 5: Multi-word Expressions (MWEs). MWEs have played a bottleneck in many Natural Language Processing (NLP) tasks including MT. MWEs can be used as one of the main factors to distinguish different MT systems by looking into their capabilities on recognising and translating MWEs in an accurate and meaning equivalent manner.Keywords: Machine Translation Evaluation, Multi-word Expressions, Human-in-the-Loop Evaluation, Fluency and Adequacy, Domain-specific Terminology\newciteslanguageresourceLanguage ResourcesHilMeMe: A Human-in-the-Loop Machine Translation Evaluation Metric Looking into Multi-Word ExpressionsLifeng HanThe University of Manchesterlifeng.han@manchester.ac.ukAbstract content1.   IntroductionMachine Translation Evaluation (MTE) has been a long-term challenging research topic since the development of MT. MTE plays an important role in MT development and quality evaluation.Popular automatic evaluation metrics have failed to correctly