# Survey Article Inter-Coder Agreement for Computational Linguistics

## Question

What detailed information should researchers provide when reporting reliability data in computational linguistics studies?

## URLs

1. https://ar5iv.org/html/2410.23186. [2410.23186] Reliability of Topic Modeling
2. https://ar5iv.org/html/1901.02543. [1901.02543] Computational Register Analysis and Synthesis
3. https://ar5iv.org/html/2410.22954. [2410.22954] Retrieval-Augmented Generation with Estimation of Source Reliability
4. https://ar5iv.org/html/2406.13415. [2406.13415] Factual Confidence of LLMs: on Reliability and Robustness of Current Estimators
5. https://ar5iv.org/html/2412.03854. [2412.03854] What Do Machine Learning Researchers Mean by "Reproducible"?
6. https://ar5iv.org/html/2303.04526. [2303.04526] Student’s t-Distribution: On Measuring the Inter-Rater Reliability When the Observations are Scarce
7. https://ar5iv.org/html/2407.13578. [2407.13578] Large Language Models as Reliable Knowledge Bases?
8. https://ar5iv.org/html/2301.10684. [2301.10684] Consistency is Key: Disentangling Label Variation in Natural Language Processing with Intra-Annotator Agreement
9. https://ar5iv.org/html/2409.10713. [2409.10713] “The Data Says Otherwise” – Towards Automated Fact-checking and Communication of Data Claims
10. https://ar5iv.org/html/2402.17649. [2402.17649] Beyond prompt brittleness: Evaluating the reliability and consistency of political worldviews in LLMs

## Answer (I don't know?: ✓)

I don't know. The provided context does not contain specific information about what detailed information researchers should include when reporting reliability data in computational linguistics studies. The passages discuss various aspects of natural language processing (NLP), such as user trust, sample-efficient language learning, question-answering systems, and the complexities in evaluation but do not explicitly address the standards or requirements for reliability reporting in studies. Therefore, the context is insufficient to answer the question fully and precisely.

1. [1]:  https://ar5iv.org/html/2305.12544, No Title
2. [2]:  https://ar5iv.org/html/2305.12544, No Title
3. [3]:  https://ar5iv.org/html/2410.04981, No Title
4. [4]:  https://ar5iv.org/html/2209.12617, No Title
5. [5]:  https://ar5iv.org/html/2209.12617, No Title
---
1. [1]:  Passage ID 1: a lack of trust from the users. A promising solution is to provide reliable sources for the facts output by a model, by attaching references and showing any additional reasoning steps. For example, citations can be included along with its bibliography, or pointers to documents in the training data (or a document database) can be attached to the output. Such a system should evaluate the extent to which these sources back up the claims made by the model.12 Efficient NLPBackground.Efficient NLP is a research direction aiming to optimize the use of resources for NLP models. This objective arises from theneed to address the challenges posed by the increasing scale of language models and their growing resource consumption present new challenges for NLP advances (Touvron et al., 2023b; Zhang et al., 2023).Indeed, it is widely acknowledged that scaling up is an essential approach for achieving state-of-the-art performance on NLP tasks, especially those skills emerged with the
2. [2]:  Passage ID 2: can stay focused on the experiment and follow guidelines. Additionally, it is difficult to control confounding variables when you have no control over the subjects of the experiment.Research Directions.1.Sample-efficient language learning. This is an area ripe with opportunities to advance our understanding of language and develop more data efficient NLP tools. There is a great need for fundamental and theoretical research into sample-efficient language learning. Computational theories and algorithms for achieving state-of-the-art on smaller data regimes are an exciting area for researchers interested in core NLP, and the pursuit of the state-of-the-art performance may soon be rerouted to data-efficiency scores.Related to this direction is the goal of establishing baselines for sample-efficient lamnguage learning. Having a lower-bound goal (e.g. X hours of interaction achieving Y score) can enable the NLP community to have a more accurate understanding of progress in terms
3. [3]:  Passage ID 3: to do human evaluation: A brief introduction to user studies in nlp.Natural Language Engineering, 29(5):1199–1222.SciScore (2024)SciScore. 2024.The best methods review tool for scientific research.https://sciscore.com/.Accessed: 12 June 2024.Semmelrock et al. (2023)Harald Semmelrock, Simone Kopeinik, Dieter Theiler, Tony Ross-Hellauer, and Dominik Kowald. 2023.Reproducibility in machine learning-driven research.arXiv preprint arXiv:2307.10320.Soliman and Siponen (2022)Wael Soliman and Mikko Siponen. 2022.What do we really mean by rigor in information systems research?Su et al. (2023)Hongjin Su, Weijia Shi, Jungo Kasai, Yizhong Wang, Yushi Hu, Mari Ostendorf, Wen-tau Yih, Noah A. Smith, Luke Zettlemoyer, and Tao Yu. 2023.One embedder, any task: Instruction-finetuned text embeddings.In Findings of the Association for Computational Linguistics: ACL 2023, pages 1102–1121, Toronto, Canada. Association for Computational
4. [4]:  Passage ID 4: or search engine. In the last decades, many QA systems have been proposed to address the requirements of different question-answering tasks. Furthermore, many error scores have been introduced, e.g., based on n-gram matching, word embeddings, or contextual embeddings to measure the performance of a QA system. This survey attempts to provide a systematic overview of the general framework of QA, QA paradigms, benchmark datasets, and assessment techniques for a quantitative evaluation of QA systems. The latter is particularly important because not only is the construction of a QA system complex but also its evaluation. We hypothesize that a reason, therefore, is that the quantitative formalization of human judgment is an open problem.keywords: Natural Language Processing, Question Answering, Knowledge Sources, Deep learning, Machine Learning, Neural-based Techniques, Evaluation Scores1 IntroductionNatural language processing (NLP) is an important branch of artificial intelligence
5. [5]:  Passage ID 5: or search engine. In the last decades, many QA systems have been proposed to address the requirements of different question-answering tasks. Furthermore, many error scores have been introduced, e.g., based on n-gram matching, word embeddings, or contextual embeddings to measure the performance of a QA system. This survey attempts to provide a systematic overview of the general framework of QA, QA paradigms, benchmark datasets, and assessment techniques for a quantitative evaluation of QA systems. The latter is particularly important because not only is the construction of a QA system complex but also its evaluation. We hypothesize that a reason, therefore, is that the quantitative formalization of human judgment is an open problem.keywords: Natural Language Processing, Question Answering, Knowledge Sources, Deep learning, Machine Learning, Neural-based Techniques, Evaluation Scores1 IntroductionNatural language processing (NLP) is an important branch of artificial intelligence