# A Decade of Knowledge Graphs in Natural Language Processing: A Survey

## Question

How do entity extraction and relation extraction play a role in building new Knowledge Graphs?

## URLs

1. https://ar5iv.org/html/2210.11231
2. https://ar5iv.org/html/2404.17593
3. https://ar5iv.org/html/2409.03284
4. https://ar5iv.org/html/2404.12493
5. https://ar5iv.org/html/2306.02051
6. https://ar5iv.org/html/2305.13168
7. https://ar5iv.org/html/2312.03022
8. https://ar5iv.org/html/2411.17388
9. https://ar5iv.org/html/2407.06564
10. https://ar5iv.org/html/2312.09753

## Answer

## I don't know?: False

Entity extraction and relation extraction are crucial components in the construction of Knowledge Graphs (KGs). Both processes contribute significantly to transforming unstructured text data into a structured format that can be easily queried and analyzed.

Entity extraction, often referred to as Named Entity Recognition (NER), is the localization and classification of named entities in text into predefined categories such as persons, organizations, locations, etc. This process is critical as it identifies the entities that will form the nodes of the Knowledge Graph. For example, in the sentence ‚ÄúKylian Mbapp√© grew up in Bondy," the model identifies "Kylian Mbapp√©" as a person and "Bondy" as a location, which are then represented as nodes in the KG [1][3].

Once entities are identified, the next step is relation extraction. This involves identifying and defining the relationships that exist between these entities, typically represented as triples (subject, relation, object). For instance, the relation between "Kylian Mbapp√©" and "Bondy" can be expressed as a triple (Kylian Mbapp√©, person-place-lived, Bondy) [1]. Relation extraction is essential for understanding the connections between entities, which provides the graph with semantic meaning.

The combination of entity and relation extraction allows for the creation of a rich, interconnected graph structure. Traditional methods of NER and relation extraction, while effective, encounter limitations such as reliance on predefined types and often require supervised learning [2]. However, recent advancements leverage large language models (LLMs) that can adapt to various tasks with little to no task-specific training, enhancing the scalability and flexibility of KG construction [4]. 

Moreover, the task of entity and relation extraction can be integrated into a single, streamlined information extraction pipeline, which can include various components such as coreference resolution and cross-document entity linking, as laid out in IE systems [3]. The seamless integration of these tasks supports the iterative improvement of the KG by refining connections and ensuring consistency across the data sourced from unstructured texts.

While machine learning approaches have significantly improved entity extraction capabilities [3], challenges remain for relation extraction due to the complexity and ambiguities often found in natural language [4]. Hence, contemporary research continues to explore innovative frameworks and architectures, such as the ones proposed by Kumar et al., that combine different models for NER and relation extraction to optimize the construction of KGs from raw text [4][5]. 

In summary, both entity extraction and relation extraction are foundational to automated KG construction. They not only facilitate the organization of unstructured data into structured formats but also expand the utility of KGs for diverse applications like information retrieval, reasoning, and inference [2], thereby making them indispensable in the field of natural language processing.

1. [1]:  https://ar5iv.org/html/2312.03022, [2312.03022] Beyond Isolation: Multi-Agent Synergy for Improving Knowledge Graph Construction
2. [2]:  https://ar5iv.org/html/2409.03284, [2409.03284] iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models
3. [3]:  https://ar5iv.org/html/2404.17593, [2404.17593] A Continual Relation Extraction Approach for Knowledge Graph Completeness
4. [4]:  https://ar5iv.org/html/2411.17388, [2411.17388] Can LLMs be Good Graph Judger for Knowledge Graph Construction?
5. [5]:  https://ar5iv.org/html/2312.03022, [2312.03022] Beyond Isolation: Multi-Agent Synergy for Improving Knowledge Graph Construction
---
1. [1]:  Passage ID 1: of NER in discerning such elements is instrumental in extracting meaningful information from textual data and facilitating the organization of KGs.Relation Extraction. The crucial task of knowledge graph construction involves simultaneously extracting entity mentions and their relations, represented as triples (subject, relation, object), from unstructured texts.Given the input sentences, the desired outputs are relational triples (eh,r,et)subscriptùëí‚Ñéùëüsubscriptùëíùë°(e_{h},r,e_{t}), where ehsubscriptùëí‚Ñée_{h} is the head entity, rùëür is the relation, and etsubscriptùëíùë°e_{t} is the tail entity.For instance, given the sentence ‚ÄúKylian Mbapp√© grew up in Bondy, one of the Parisian suburbs with working-class, mostly immigrant residents.‚Äù, the model should identify two entities Kylian Mbapp√© and Bondy, together with their relation person-place-lived, described as triple (Kylian Mbapp√©, person-place-lived, Bondy).Event Extraction: The automated extraction of events from unstructured natural
2. [2]:  Passage ID 2: Graphs (KGs) is crucial for structuring data and making it accessible, allowing users to search for information effectively. KGs also facilitate insights, inference, and reasoning.Traditional NLP methods, such as named entity recognition and relation extraction, are key in information retrieval but face limitations, including the use of predefined entity types and the need for supervised learning.Current research leverages large language models‚Äô capabilities, such as zero- or few-shot learning. However, unresolved and semantically duplicated entities and relations still pose challenges, leading to inconsistent graphs and requiring extensive post-processing. Additionally, most approaches are topic-dependent.In this paper, we propose iText2KG111The code and the dataset are available at https://github.com/AuvaLab/itext2kg, a method for incremental, topic-independent KG construction without post-processing. This plug-and-play, zero-shot method is applicable across a wide range of KG
3. [3]:  Passage ID 3: texts on web pages, and chats, are one of the challenges in information management systems. To analyze and interpret unstructured text data, it must be represented in a structured form. One way of representing unstructured data in the structured form is the use of knowledge graphs (KGs)¬†[1]. An information extraction (IE) pipeline is generally organized as the product of several analysis components, e.g.: named entity (NE) tagging; syntactic analysis; coreference resolution within a document; entity, relation and event extraction (semantic analysis); and cross-document coreference resolution¬†[2]. Semantic analysis in IE systems might be carried out on the KG.Recent KG construction approaches utilize machine learning-based approaches instead of rule-based techniques for NE and relation extraction (RE). The machine learning-based approaches obtain impressive results in the NE tagging¬†[3], while they do not show this performance on RE¬†[4]. Detection of relations between entity pairs
4. [4]:  Passage ID 4: few-shot information extraction abilities. They propose that closed-source LLMs like ChatGPT excel at information extraction tasks and simpler IE tasks such as entity typing. However, they encounter difficulties when it comes to more intricate tasks such as relation extraction and event extraction[13]. To address that, Kumar et al.[31] propose a unified approach to construct knowledge graphs from unprocessed text, incorporating a framework that includes two PLMs driven components. They initially fine-tuned a PLM for named entity recognition, enabling it to identify entities within raw text. Subsequently, they introduced a ‚Äù2-model BERT‚Äù architecture to address the challenge of relation extraction. Grapher[32] presents an end-to-end multi-stage system. The approach initially employs LLMs to generate knowledge graph entities, subsequently utilizing a straightforward relation construction head to facilitate the effective creation of knowledge graphs from textual descriptions. GPT-RE[33]
5. [5]:  Passage ID 5: concentrating on refining problem-solving capabilities for a singular complex task.In this study, we inherit previous methods by presenting an interactive architecture tailored for a knowledge graph construction team comprising agents with distinct expert skills.A departure from prior work, our innovation lies in introducing the challenge of completing multiple information extractions, aligning with the principles of feedback compatibility.3. PreliminariesIn this paper, we apply our approach, cooperKGC, to three representative tasks of knowledge graph construction, namely: Named Entity Recognition (NER), Relation Extraction (RE) and Event Extraction (EE).Notably, since these three tasks are relevant in some way, we leave the exploration of cross-domain collaboration for future work.We provide definitions for these sub-tasks and then explain the basic structure of current models.3.1. Task DefinitionFigure 2. The overview of our CooperKGC.Named Entity Recognition.