# A Survey of Deep Learning for Mathematical Reasoning

## Question

How does Chain-of-thought prompting (CoT) improve mathematical reasoning in large language models (LLMs)?

## URLs

1. https://ar5iv.org/html/2201.11903. [2201.11903] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models
2. https://ar5iv.org/html/2411.11984. [2411.11984] Understanding Chain-of-Thought in LLMs through Information Theory
3. https://ar5iv.org/html/2406.06592. [2406.06592] Improve Mathematical Reasoning in Language Models by Automated Process Supervision
4. https://ar5iv.org/html/2410.10336. [2410.10336] CoMAT: Chain of Mathematically Annotated Thought Improves Mathematical Reasoning
5. https://ar5iv.org/html/2409.20441. [2409.20441] Instance-adaptive Zero-shot Chain-of-Thought Prompting
6. https://ar5iv.org/html/2305.15408. [2305.15408] Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective
7. https://ar5iv.org/html/2409.12183. [2409.12183] To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning
8. https://ar5iv.org/html/2409.19381. [2409.19381] MetaMath: Integrating Natural Language and Code for Enhanced Mathematical Reasoning in Large Language Models
9. https://ar5iv.org/html/2309.13339. [2309.13339] Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic

## Answer (I don't know?: âœ—)

Error: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable