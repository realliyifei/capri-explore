# A Short Survey on Sense-Annotated Corpora

## Question

What are the main WordNet sense-annotated corpora, and why are they significant for Word Sense Disambiguation?

## URLs

1. https://ar5iv.org/html/1802.04744. [1802.04744] A Short Survey on Sense-Annotated Corpora
2. https://ar5iv.org/html/1905.05677. [1905.05677] Untitled Document
3. https://ar5iv.org/html/2004.14325. [2004.14325] Don’t Neglect the Obvious: On the Role of Unambiguous Words in Word Sense Disambiguation
4. https://ar5iv.org/html/2102.05260. [2102.05260] SensPick: Sense Picking for Word Sense Disambiguation
5. https://ar5iv.org/html/1508.01346. [1508.01346] Word sense disambiguation: a survey
6. https://ar5iv.org/html/2107.01540. [2107.01540] Persian-WSD-Corpus: A Sense Annotated Corpus for Persian All-words Word Sense Disambiguation

## Answer (I don't know?: ✓)

I don't know. The context provided does not contain any information regarding WordNet sense-annotated corpora or their significance for Word Sense Disambiguation. The passages focus on synthetic dataset generation for query formulation and the workings of question answering (QA) algorithms, but they do not discuss WordNet or related concepts. Thus, there is insufficient information to answer your question accurately.

1. [1]:  https://ar5iv.org/html/2410.00427, No Title
2. [2]:  https://ar5iv.org/html/2209.12617, No Title
3. [3]:  https://ar5iv.org/html/2209.12617, No Title
4. [4]:  https://ar5iv.org/html/2209.12617, No Title
5. [5]:  https://ar5iv.org/html/2209.12617, No Title
---
1. [1]:  Passage ID 1: familiar with all existing fields of study and struggle to phrase their queries using the correct terminology. Due to the absence of datasets that map search goals expressed in layman’s terms to NLP topics, we created a synthetic multi-class dataset using GPT-3.5-Turbo (version: 0613) OpenAI (2022). We prompted the LLM to generate questions on the 12 main topics in our taxonomy using three distinct personas: a computer science student with only peripheral NLP knowledge, a businessperson with practical experience of NLP tools but minimal technical expertise, and a non-technical, non-academic individual whose technology use is limited to basic tasks. Persona-specific prompting yielded diverse inquiries in layman’s language. For example, the question “How are computers able to respond when we ask them questions?” was generated for the topic Natural Language Interfaces. To account for questions unrelated to NLP, we also generated a set of out-of-scope questions such as “Who discovered the
2. [2]:  Passage ID 2: 120; 117; 121; 118; 32. However, when the classification of questions is ambiguous, the system must allow for multiple types of answers.Analyzing the question and detecting the answer type, or finding the embeddings of most similar vectors of question and context, is one of the core tasks of QA algorithms. The QA algorithms also facilitate the query formulation during the query processing stage via parsing the passing tokens with precise descriptions in order to identify what kind of answer is supposed to be returned (e.g., paragraph, description, etc). Different strategies have been proposed to deal with such requirements, such as: Regular Expressions (regex), Part-of-Speech (POS), matched n-gram features, finding the first noun phrase after the question headword ‘wh*’, and Named Entity Recognition (NER) to identify the given tokens such as human, place, location, entity. The question types classification with different answer types have been investigated in many studies such
3. [3]:  Passage ID 3: 120; 117; 121; 118; 32. However, when the classification of questions is ambiguous, the system must allow for multiple types of answers.Analyzing the question and detecting the answer type, or finding the embeddings of most similar vectors of question and context, is one of the core tasks of QA algorithms. The QA algorithms also facilitate the query formulation during the query processing stage via parsing the passing tokens with precise descriptions in order to identify what kind of answer is supposed to be returned (e.g., paragraph, description, etc). Different strategies have been proposed to deal with such requirements, such as: Regular Expressions (regex), Part-of-Speech (POS), matched n-gram features, finding the first noun phrase after the question headword ‘wh*’, and Named Entity Recognition (NER) to identify the given tokens such as human, place, location, entity. The question types classification with different answer types have been investigated in many studies such
4. [4]:  Passage ID 4: 120; 117; 121; 118; 32. However, when the classification of questions is ambiguous, the system must allow for multiple types of answers.Analyzing the question and detecting the answer type, or finding the embeddings of most similar vectors of question and context, is one of the core tasks of QA algorithms. The QA algorithms also facilitate the query formulation during the query processing stage via parsing the passing tokens with precise descriptions in order to identify what kind of answer is supposed to be returned (e.g., paragraph, description, etc). Different strategies have been proposed to deal with such requirements, such as: Regular Expressions (regex), Part-of-Speech (POS), matched n-gram features, finding the first noun phrase after the question headword ‘wh*’, and Named Entity Recognition (NER) to identify the given tokens such as human, place, location, entity. The question types classification with different answer types have been investigated in many studies such
5. [5]:  Passage ID 5: 120; 117; 121; 118; 32. However, when the classification of questions is ambiguous, the system must allow for multiple types of answers.Analyzing the question and detecting the answer type, or finding the embeddings of most similar vectors of question and context, is one of the core tasks of QA algorithms. The QA algorithms also facilitate the query formulation during the query processing stage via parsing the passing tokens with precise descriptions in order to identify what kind of answer is supposed to be returned (e.g., paragraph, description, etc). Different strategies have been proposed to deal with such requirements, such as: Regular Expressions (regex), Part-of-Speech (POS), matched n-gram features, finding the first noun phrase after the question headword ‘wh*’, and Named Entity Recognition (NER) to identify the given tokens such as human, place, location, entity. The question types classification with different answer types have been investigated in many studies such