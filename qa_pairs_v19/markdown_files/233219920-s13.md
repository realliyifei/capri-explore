# Relational World Knowledge Representation in Contextual Language Models: A Review

## Question

How does linearizing knowledge base triples enhance the training of language models?

## URLs

1. https://ar5iv.org/html/2402.11541. [2402.11541] Counter-intuitive: Large Language Models Can Better Understand Knowledge Graphs Than We Thought
2. https://ar5iv.org/html/2407.09506. [2407.09506] Integrating Large Language Models with Graph-based Reasoning for Conversational Question Answering
3. https://ar5iv.org/html/2410.20724. [2410.20724] Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation
4. https://ar5iv.org/html/2306.08302. [2306.08302] Unifying Large Language Models and Knowledge Graphs: A Roadmap
5. https://ar5iv.org/html/2406.08223. [2406.08223] Research Trends for the Interplay between Large Language Models and Knowledge Graphs
6. https://ar5iv.org/html/2409.10294. [2409.10294] MGSA: Multi-Granularity Graph Structure Attention for Knowledge Graph-to-Text Generation
7. https://ar5iv.org/html/2308.14436. [2308.14436] Bridging the KB-Text Gap: Leveraging Structured Knowledge-aware Pre-training for KBQA
8. https://ar5iv.org/html/2409.03155. [2409.03155] Debate on Graph: a Flexible and Reliable Reasoning Framework for Large Language Models

## Answer (I don't know?: ✗)

Linearizing knowledge base (KG) triples enhances the training of language models (LLMs) by effectively transforming structured information into formats that the models can understand and utilize for generating output. This transformation includes the conversion of triples into linearized representations, reasoning paths, or natural language text. Such approaches allow for the effective integration of knowledge into LLM prompts, thereby enriching the context that the models use during training and inference, specifically in tasks that involve complex knowledge, such as complex question answering (CQA) [3] [4].

Several studies have highlighted how LLMs can benefit from well-structured knowledge representations. For example, researchers have noted that providing high-quality, relevant knowledge to pre-trained LLMs through optimal prompting strategies significantly aids in the comprehension of KG information [3]. The process of converting KGs into linearly represented formats, including natural language descriptions or reasoning paths, helps LLMs grasp complex relationships embedded within the KGs and enhances their ability to produce accurate outputs during tasks requiring this knowledge.

Moreover, the importance of this transformation is underscored by the observation that LLMs tend to perform effectively even with "messy, noisy, and linearized" KG information. This suggests that a less structured form of knowledge representation can still be beneficial for LLMs, contradicting the initial assumption that well-designed natural language prompts would yield better performance [4]. The adaptability of LLMs to various forms of input allows them to utilize the logic and relationships structured in KGs efficiently, leading to improved reasoning capabilities.

Additionally, innovative approaches such as few-shot learning and the use of embeddings specifically designed to capture linguistic features further refine how knowledge is processed. For instance, methods like the SGPT embedding technique enable LLMs to encode linguistic traits from questions, facilitating better understanding when paired with the knowledge extracted through linearized triples [5]. These methods showcase the potential of using LLMs in the context of relation extraction and query generation wherein comprehension of complex data relationships is critical.

In summary, linearizing KG triples serves as a vital bridge between structured knowledge and the training capabilities of LLMs by:
1. Transforming structured data into comprehensible formats that LLMs can process,
2. Enhancing the model's ability to understand and generate responses for complex tasks,
3. Allowing for more versatile use cases, as evidenced by the successful application of various prompting techniques that utilize linearized representations of KG information in practical scenarios like CQA and SPARQL query generation [4][5].

1. [1]:  https://ar5iv.org/html/2402.11541, [2402.11541] Counter-intuitive: Large Language Models Can Better Understand Knowledge Graphs Than We Thought
2. [2]:  https://ar5iv.org/html/2406.08223, [2406.08223] Research Trends for the Interplay between Large Language Models and Knowledge Graphs
3. [3]:  https://ar5iv.org/html/2402.11541, [2402.11541] Counter-intuitive: Large Language Models Can Better Understand Knowledge Graphs Than We Thought
4. [4]:  https://ar5iv.org/html/2402.11541, [2402.11541] Counter-intuitive: Large Language Models Can Better Understand Knowledge Graphs Than We Thought
5. [5]:  https://ar5iv.org/html/2406.08223, [2406.08223] Research Trends for the Interplay between Large Language Models and Knowledge Graphs
---
1. [1]:  Passage ID 1: discussed in Section 2, the NL text generated by the underperforming triple-to-text generation model will affect LLM’s ability to understand KG and further perform CQA.To eliminate the impact of the Triple-to-text model on LLM, we leverage a Relation Extraction (RE) benchmark to generate QA pairs, in which the document and its relevant ground-truth triples are provided.Since the triples in each document can represent the logical structure of the entities, we consider them as a comprehensive knowledge graph mapping the document.Specifically, to generate QA pairs based on each document, we adopted the dataset construction method employed in LC-QuAD 2.0 Dubey et al. (2019). We first filled the triples into many different templates and constructed questions, and then used ChatGPT to paraphrase the questions, ensuring the diversity and complexity of questions. Following this approach, as illustrated in Figure 2(b), we generated 1-hop, 2-hop, and 3-hop questions for each document. This
2. [2]:  Passage ID 2: on diverse corpora to improve language models’ understanding of complex language structures, leading to a more nuanced interpretation of linguistic patterns.Huguet Cabot and Navigli enhanced relation extraction by training a specialized BART-style model [32] with a novel triplet linearization technique, which demonstrates the importance of supervised fine-tuning in advancing LLMs for complex tasks like relation extraction.Few-shot learning, which relies on a limited number of labeled examples, faces significant challenges in machine learning. The lack of data can cause problems like overfitting and difficulty in understanding complex data relationships, as pointed out by [33].The advent of LLMs has been a significant breakthrough in overcoming few-shot learning challenges.Xu et al. introduced two strategies for using LLMs in relation extraction: 1) in-context learning (ICL) and 2) data generation. ICL involves using detailed prompts with task definitions and labels to help LLMs
3. [3]:  Passage ID 3: of LLMs depends on the KG inference module (maybe need training). However, this approach lacks the consideration for leveraging LLMs in the process of KG understanding and reasoning.Consequently, researchers have recently shown a keen interest in exploring how to supply high-quality relevant knowledge to pre-trained LLMs via constructing optimal prompts, thereby facilitating the model’s comprehension of KG Sorensen et al. (2022); White et al. (2023); Li et al. (2023); Wen et al. (2023); Hu et al. (2024). This more lightweighted approach involves converting the KG into linearly represented triples, reasoning paths, or natural language (NL) textual representations (sentences or a paragraph) and concatenating them to the input prompt to query the LLMs. To compensate for the loss of structured information, researchers strive to generate NL texts by effectively organizing structured knowledge Sun et al. (2020); Brate et al. (2022). However, the generation of KG-to-text itself poses a
4. [4]:  Passage ID 4: knowledge in KGs on-the-fly remains inadequate.Researchers often co-train KG embeddings and LLM parameters to equip LLMs with the ability of comprehending KG knowledge.However, this resource-hungry training paradigm significantly increases the model learning cost and is also unsuitable for non-open-source, black-box LLMs.In this paper, we employ complex question answering (CQA) as a task to assess the LLM’s ability of comprehending KG knowledge.We conducted a comprehensive comparison of KG knowledge injection methods (from triples to natural language text), aiming to explore the optimal prompting method for supplying KG knowledge to LLMs, thereby enhancing their comprehension of KG.Contrary to our initial expectations, our analysis revealed that LLMs effectively handle messy, noisy, and linearized KG knowledge, outperforming methods that employ well-designed natural language (NL) textual prompts.This counter-intuitive finding provides substantial insights for future research on
5. [5]:  Passage ID 5: Question 5, which examines the effectiveness of LLMs in generating natural language queries, particularly focusing on the conversion of textual descriptions into query languages like SPARQL or Cypher for KGs.Constructing SPARQL queries from natural language questions is challenging, as it demands an understanding of both the question itself and the underlying patterns within the KG [74]. Rony et al. introduced a novel embedding technique called SGPT, tailored to encode linguistic features from the question, and suggested training methods that make use of a pre-trained language model to produce a SPARQL query. Kovriguina et al. proposed a one-shot generative approach, termed SPARQLGEN, which aims to generate SPARQL queries by augmenting LLMs with pertinent context provided in a single prompt. This prompt encompasses the question, an RDF subgraph necessary for answering the question, and an example of a correct SPARQL query for a different question.Pliukhin et al. devised a method that