# Pre-train, Prompt and Recommendation: A Comprehensive Survey of Language Modelling Paradigm Adaptations in Recommender Systems

## Question

What is the training objective of Auto-regressive Modelling (AM), and what are its limitations and potential solutions?

## URLs

1. https://ar5iv.org/html/2410.18962. [2410.18962] Where Am I and What Will I See: An Auto-Regressive Model for Spatial Localization and View Prediction
2. https://ar5iv.org/html/2409.00046. [2409.00046] Rethinking Molecular Design: Integrating Latent Variable and Auto-Regressive Models for Goal Directed Generation
3. https://ar5iv.org/html/2410.05711. [2410.05711] Diffusion Auto-regressive Transformer for Effective Self-supervised Time Series Forecasting
4. https://ar5iv.org/html/2408.14461. [2408.14461] A domain decomposition-based autoregressive deep learning model for unsteady and nonlinear partial differential equations
5. https://ar5iv.org/html/2309.13638. [2309.13638] Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to Solve
6. https://ar5iv.org/html/2407.17274. [2407.17274] Revolutionizing Text-to-Image Retrieval as Autoregressive Token-to-Voken Generation
7. https://ar5iv.org/html/2207.14255. [2207.14255] Efficient Training of Language Models to Fill in the Middle
8. https://ar5iv.org/html/2411.16585. [2411.16585] MarketGPT: Developing a Pre-trained transformer (GPT) for Modeling Financial Time Series
9. https://ar5iv.org/html/1912.12220. [1912.12220] On Network Traffic Forecasting using Autoregressive Models

## Answer (I don't know?: ✗)

The training objective of autoregressive modeling (AM), particularly in the context of large language models (LLMs), is primarily next-word prediction. This means that during training, these models are tasked with predicting the next word in a sequence based on the preceding words in a given text dataset, typically sourced from the Internet [2]. This objective influences how LLMs process and generate language, as all their abilities emerge from this autoregressive substrate, even when they are applied to tasks that appear fundamentally different, such as solving math problems [2].

However, there are several limitations associated with this training approach. One significant issue arises from the nature of the training data and the optimization processes inherent in these models. The complexity involved in the size of training data and the multiple optimization problems can lead to variations in model parameters that may hinder accurate predictions [3]. Furthermore, a single model may not be adequate to capture all scenarios, resulting in the necessity for combined or hybrid models, which can further complicate the training process and reduce model flexibility [3].

Another limitation is the mismatch between the statistical properties that LLMs adapt to and the real-world tasks they are applied to. This mismatch may result in unpredictable behaviors or inconsistencies in performance, akin to human quirks shaped by their own training and experiences [4]. Since LLMs are fundamentally statistical systems, they are particularly sensitive to the statistics of word sequences found in their training data, which means that their effectiveness can be heavily influenced by these underlying statistical structures [4].

To address these limitations, one potential solution lies in developing better training techniques that consider not just next-word prediction but also incorporate a more diverse set of tasks and data distributions. This could involve using hybrid modeling approaches that blend different techniques and address the limitations of single models [3]. Moreover, diversifying training data and augmenting it with tasks that demand a broader range of reasoning or knowledge may enhance the adaptability and robustness of LLMs.

In summary, the primary training objective of autoregressive modeling in LLMs is next-word prediction, which shapes the model's capabilities and influences its performance across various tasks. However, the limitations of single-model dependency and statistical mismatch necessitate further research into hybrid models and diversified training approaches to improve the reliability and generalizability of these systems [2] [3] [4].

1. [1]:  https://ar5iv.org/html/2309.13638, [2309.13638] Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to Solve
2. [2]:  https://ar5iv.org/html/2309.13638, [2309.13638] Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to Solve
3. [3]:  https://ar5iv.org/html/1912.12220, [1912.12220] On Network Traffic Forecasting using Autoregressive Models
4. [4]:  https://ar5iv.org/html/2309.13638, [2309.13638] Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to Solve
5. [5]:  https://ar5iv.org/html/2309.13638, [2309.13638] Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to Solve
---
1. [1]:  Passage ID 1: two tasks that seem equally complex to a human; and they have greater difficulty on examples with low-probability answers than high-probability ones, even when the task is deterministic.Both of these properties—as well as several others that we have discussed above—can be attributed to the way that LLM training focuses on the statistics of word sequences. In sum, our efforts to understand language models should consider both their sparks of artificial general intelligence and their embers of autoregression.LimitationsThroughout the paper, we have noted several limitations of the general approach we have proposed as well as the specific experiments we have run. Here we collect the most important limitations. First, the teleological perspective that we have argued for can be incomplete. Therefore, we do not claim that teleological analysis should be the only way that the field studies LLMs; rather, it should be one of many perspectives that can inform analyses. Second, the
2. [2]:  Passage ID 2: that it was trained to perform. For the LLMs that have been the focus of recent attention in AI, this task is autoregression—next-word prediction (Elman, 1991; Bengio, Ducharme, and Vincent, 2000; Radford et al., 2018)—performed over Internet text.As described in more detail in the next section, we argue that a full understanding of LLMs should be strongly informed by the fact that this is their primary training objective. We therefore hypothesize that, even when they are asked to perform tasks that seem very different from next-word prediction—e.g., solving math problems—their performance on such tasks is highly influenced by the autoregressive substrate from which all of their abilities emerge.That is, if we continue with the example of solving math problems, it is important to view the LLM not as a “math problem solver” but rather as a “statistical next-word prediction system being used to solve math problems.”A mismatch between the problem that a system developed to solve and
3. [3]:  Passage ID 3: the size of training data and optimization and estimation steps of autoregressive algorithms presented in Section II have become crucial. That is, a modeling problem actually consists of multiple optimization problems whose results reshape the intended model and this issue leads to uncountably different models with varying parameters.In certain cases, even a single well-identified model becomes insufficient to make accurate predictions and the solution consequently converges to combined or hybrid models. It increases complexity and required time for training, and decreases flexibility of the models as they rely on various dependent parameters. This issue also leads to development or employment of different techniques on network traffic analysis such as machine learning and neural networks. Indeed emerging techniques bring their own issues on the table and it strongly becomes a trade-off between complexity and accuracy. Moreover, when other performance metrics such as prediction
4. [4]:  Passage ID 4: in our visual field (Wandell, 1995). We anticipate that goals, training distribution, and model architecture create opportunities for similar mismatches in machines.2.2 Hypothesized embers of autoregressionDo LLMs face anything analogous to humans’ back pain, love for fatty foods, and blind spots—any quirks attributable to a mismatch between what they “adapted” to do and what they are used for? To answer this question, we must consider the types of solutions that would arise from the pressures that shape LLMs. First, the fact that LLMs are neural networks makes them statistical systems. The other two factors—the task of next-word prediction and the training distribution of Internet text—dictate which statistics they are sensitive to: the statistics of word sequences in Internet text. Building on this analysis, we make the following three predictions about LLM performance (some additional predictions are listed in 1.2 on page 1.2):•Even when there is no difference in the
5. [5]:  Passage ID 5: "dark"); } else { localStorage.setItem("ar5iv_theme", "light"); } } else { localStorage.setItem("ar5iv_theme", "dark"); } detectColorScheme(); }Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to SolveR. Thomas McCoy  Shunyu Yao  Dan Friedman  Matthew Hardy  Thomas L. Griffiths(Princeton University)One-sentence summary:To understand what language models are, we must understand what we have trained them to be.Abstract:The widespread adoption of large language models (LLMs) makes it important to recognize their strengths and limitations. We argue that in order to develop a holistic understanding of these systems we need to consider the problem that they were trained to solve: next-word prediction over Internet text.By recognizing the pressures that this task exerts we can make predictions about the strategies that LLMs will adopt, allowing us to reason about when they will succeed or fail.This