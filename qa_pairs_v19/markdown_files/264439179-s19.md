# A Survey on Detection of LLMs-Generated Content

## Question

How have pretrained language models enhanced the efficiency of watermarking techniques?

## URLs

1. https://ar5iv.org/html/2411.05091
2. https://ar5iv.org/html/2409.00089
3. https://ar5iv.org/html/2312.07913
4. https://ar5iv.org/html/2410.19096
5. https://ar5iv.org/html/2407.04794
6. https://ar5iv.org/html/2301.10226
7. https://ar5iv.org/html/2401.06829
8. https://ar5iv.org/html/2409.10570
9. https://ar5iv.org/html/2311.05863

## Answer

## I don't know?: False

Pre-trained language models (PLMs) have significantly contributed to the advancement of watermarking techniques, particularly by optimizing the embedding process and improving resistance to various attacks. The development of specialized medical PLMs (Med-PLMs) has demonstrated remarkable improvements in the efficiency of watermark embedding. For instance, a recent method has reduced the watermark embedding time from 10 hours to just 10 seconds, which greatly enhances operational efficiency in medical applications [1].

Furthermore, as PLMs have evolved, they exhibit robustness against an array of attacks designed to undermine watermark integrity. The findings indicate that traditional watermarking techniques, while they can maintain high text quality and watermark retention (such as KGW and Exponential watermarks), still have vulnerabilities, especially to different types of attacks [3]. Therefore, the integration of pre-trained models allows for a more strategic embedding of watermarks, which can adapt to these challenges.

In the context of medical applications, the deployment of Med-PLMs for specific Natural Language Understanding (NLU) tasks like named entity recognition, relation extraction, and question answering also highlights the necessity of effective watermark embedding strategies that do not compromise the performance of the model [4]. As these models perform better by leveraging specialized medical datasets, they also enhance watermarking by enabling nuanced techniques that can protect sensitive medical information without detracting from the model's task performance.

Moreover, the overall advancements in neural language models (NLMs), because of their ability to capture complex semantic and syntactic patterns, raise the bar for the sophistication needed in watermarking approaches. These models are not only adept at generating coherent text but also in tasks that require high accuracy, such as medical diagnosis [3]. Consequently, as watermarking techniques are adapted to exploit the strengths of PLMs, they inherently become more effective and efficient.

In summary, pre-trained language models, especially in specialized domains like medicine, have boosted the effectiveness and efficiency of watermarking techniques by fast-tracking embedding processes and enhancing resilience against various attack methodologies. The ongoing evolution of PLMs suggests a continual improvement in watermarking strategies, with the potential for novel methods that further secure machine-generated text [2][4].

[1]: https://ar5iv.org/html/2409.10570, [2409.10570] Protecting Copyright of Medical Pre-trained Language Models: Training-Free Backdoor Watermarking
[2]: https://ar5iv.org/html/2402.17608, No Title
[3]: https://ar5iv.org/html/2407.04794, [2407.04794] On Evaluating The Performance of Watermarked Machine-Generated Texts Under Adversarial Attacks
[4]: https://ar5iv.org/html/2409.10570, [2409.10570] Protecting Copyright of Medical Pre-trained Language Models: Training-Free Backdoor Watermarking
[5]: https://ar5iv.org/html/2306.05524, No Title

[1]: Passage ID 1: watermarks across various medical downstream tasks. Additionally, our method demonstrates robustness against various attacks and significantly enhances the efficiency of watermark embedding, reducing the embedding time from 10 hours to 10 seconds.IntroductionIn the field of Natural Language Processing (NLP), pre-trained language models followed by fine-tuning on specific tasks have become the standard approach (Devlin et al. 2019; Brown et al. 2020; Touvron et al. 2023). This approach is especially crucial in the medical domain, where most downstream datasets contain patient privacy information and are not publicly available (Wang et al. 2023).However, traditional pre-trained models often underperform in the medical domain due to their general-purpose nature, prompting the development of specialized Med-PLMs (Lee et al. 2020; Gu et al. 2021; Wu et al. 2024), which are pre-trained on medical domain texts. Model owners often deploy their Med-PLMs in the Machine Learning as a
[2]: Passage ID 2: (Belinkov and Glass, 2019) has been the focus of many studies in the recent NLP research. It has been extensively shown that pre-trained Neural Language Models (NLMs) are able to capture syntax- and semantic-sensitive phenomena (Hewitt and Manning, 2019; Pimentel et al., 2020; Li et al., 2022) and that there is a correlation between the degree of linguistic knowledge and its ability to solve correctly a downstream task (Miaschi et al., 2020; Sarti et al., 2021), although it is still highly debated (Ravichander et al., 2021). However, it has also been demonstrated that introducing additional linguistic information (Wang et al., 2019b; Zhou et al., 2020; Glavaš and Vulić, 2021) during the pre-training phase can enhance models’ performances. In addition, several works showed that transfer learning methods, such as fine-tuning on intermediate supporting tasks, are highly beneficial to improve pre-trained models’ performance in the resolution of multiple final target tasks (Phang et al.,
[3]: Passage ID 3: KGW and Exponential watermarks offer high text quality and watermark retention but remain vulnerable to most attacks;(2) Post-text attacks are found to be more efficient and practical than pre-text attacks;(3) Pre-text watermarks are generally more imperceptible, as they do not alter text fluency, unlike post-text watermarks;(4) Additionally, combined attack methods can significantly increase effectiveness, highlighting the need for more robust watermarking solutions.Our study underscores the vulnerabilities of current techniques and the necessity for developing more resilient schemes. IntroductionLarge Language Models (LLMs) are rapidly advancing in capability, demonstrating remarkable proficiency across a wide range of applications.From generating coherent and contextually appropriate text to assisting in complex tasks such as code generation [6, 21, 44, 74, 75], medical diagnosis [26, 65, 14], and content creation [17, 39, 54], LLMs are revolutionizing various
[4]: Passage ID 4: et al. 2023) and can be reliably extracted across different tasks presents a significant challenge.Figure 1: Process of developing, deploying and applying medical pre-trained language models to various downstream tasks.Although some backdoor watermarking methods have been proposed to protect pre-trained language models in general domains (Li et al. 2023a; Gu et al. 2023), applying these methods to Med-PLMs presents three challenges. First, current methods mainly focus on downstream tasks like text classification by using large corpus datasets to further train PLMs and embedding watermarks by poisoning the [CLS] representation of text containing trigger words. However, Med-PLMs are often used in medical natural language understanding (Med-NLU) tasks such as named entity recognition (NER), relation extraction (RE), and question answering (QA), as well as medical natural language generation (Med-NLG) tasks such as dialogue systems. These tasks do not rely solely on the [CLS]
[5]: Passage ID 5: black-box approaches [85]. Requiring full access to the target LLM, white-box approaches implant watermarks into LLM outputs and detect the watermarks to identify machine-generated texts. However, the owners of LLMs are increasingly reluctant to open-source their models, black-box approaches that only gather the output of LLMs have attracted more interest. They can be further categorized into (1) feature-based by examining hand-crafted statistical disparities, linguistic patterns, and fact verification [85]; and (2) model-based by learning another language model, which is good at discriminating linguistic characteristics between human-written and machine-generated texts. Our approach falls into the second category.2.3 Related WorkNeural Language Model. The neural networks for word probability modeling have been developed since 2000s [7, 84, 15]. The recurrent neural network (RNN) family [7] aggregates the historical contextual information in text and uses the memory of history