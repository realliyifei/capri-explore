# A Survey on Automatically-Constructed WordNets and their Evaluation: Lexical and Word Embedding-based Approaches

## Question

What are the challenges and methods involved in the manual evaluation of synsets in automatically-constructed WordNets?

## URLs

1. https://ar5iv.org/html/1704.03223
2. https://ar5iv.org/html/2205.10412
3. https://ar5iv.org/html/2204.03251
4. https://ar5iv.org/html/2303.01847
5. https://ar5iv.org/html/2409.06386
6. https://ar5iv.org/html/2107.00333
7. https://ar5iv.org/html/2101.09619
8. https://ar5iv.org/html/2406.20054

## Answer

## I don't know?: True

I don't know. The context provided does not specifically discuss the challenges and methods involved in the manual evaluation of synsets in automatically-constructed WordNets. While there are mentions of concept extraction, evaluation frameworks, and linguistic behaviors, none of the given passages explicitly address the criteria, challenges, or methodologies related to the manual evaluation of synsets in WordNet. Hence, I cannot construct a precise and supported answer to your question based on the available information.

[1]: https://ar5iv.org/html/2310.18345, No Title
[2]: https://ar5iv.org/html/2305.14070, No Title
[3]: https://ar5iv.org/html/2305.14070, No Title
[4]: https://ar5iv.org/html/2204.10050, No Title
[5]: https://ar5iv.org/html/2204.10050, No Title

[1]: Passage ID 1: Current concept extraction methods were evaluated on an application task, e.g., sentiment analysis to SenticNet or testing specific relationships, e.g., hypernym and hyponym relationship to ConceptNet and WordNet extension. The issue with such an evaluation method is that it can only reflect the effectiveness of a developed knowledge base or concept extraction method on a specific domain. Since different knowledge bases have different application targets, it’s hard to evaluate and compare them with unified criteria. It would be valuable to propose a framework for knowledge base evaluation that is independent of specific tasks. It would be helpful to understand the quality of included concepts, relationships, and their representations.More concept extraction applications. Despite the attention some scholars have given to neuro-symbolic AI, the body of related works remains relatively scant in comparison to end-to-end neural network models. One possible explanation for this disparity
[2]: Passage ID 2: usually involve experiments in which word embeddings are compared with human judgements about word relations, and may be divided into various categories. For example, Bakarov, (2018) arranges them as follows:aconscious evaluation including tasks like semantic similarity, analogy, thematic fit, concept categorisation, synonym detection, and outlier word detection;bsubconscious evaluation in tasks like semantic priming, neural activation patterns, and eye movement data;cthesaurus-based evaluations, including thesaurus vectors, dictionary definition graph, cross-match test, semantic difference and semantic networks; anddlanguage-driven of phonosemantic analysis and bi-gram co-occurrence frequency.In this paper, we concentrate mainly on the conscious evaluation tasks. These vary from testing morphosyntactic agreement patterns, like number and gender (Warstadt et al.,, 2020), to more semantic-related information, like the implications of negation (Ettinger,,
[3]: Passage ID 3: Nowadays, the most prominent approaches are based on deep neural networks, such as BERT. However, they lack transparency and interpretability, and are often seen as blackboxes, which affect their applicability in downstream tasks as well as the comparison of different architectures or even the same model trained on different corpora or hyperparameters. In this paper, we propose a set of intrinsic evaluation tasks that inspect the linguistic information encoded in models developed for Brazilian Portuguese. These tasks are designed to evaluate how different language models generalise information related to grammatical structures and multiword expressions (MWEs), thus allowing for an assessment of whether the model has learned different linguistic phenomena.The dataset that was developed for these tasks is composed by a series of sentences with a single masked word and a cue that narrows down the context.This dataset is divided into MWEs and grammatical structures, and the latter is
[4]: Passage ID 4: at identifying whether a sentence contains an idiomatic expression, and (b) a task based on semantic text similarity which requires the model to adequately represent potentially idiomatic expressions in context. Each Subtask includes different settings regarding the amount of training data. Besides the task description, this paper introduces the datasets in English, Portuguese, and Galician and their annotation procedure, the evaluation metrics, and a summary of the participant systems and their results. The task had close to 100 registered participants organised into twenty five teams making over 650 and 150 submissions in the practice and evaluation phases respectively.1 IntroductionMultiword Expressions (MWEs) are a challenge for natural language processing (NLP), as their linguistic behaviour (e.g., syntactic, semantic) differs from that of generic word combinations Baldwin and Kim (2010); Ramisch and Villavicencio (2018). Moreover, MWEs are pervasive in all domains Biber
[5]: Passage ID 5: at identifying whether a sentence contains an idiomatic expression, and (b) a task based on semantic text similarity which requires the model to adequately represent potentially idiomatic expressions in context. Each Subtask includes different settings regarding the amount of training data. Besides the task description, this paper introduces the datasets in English, Portuguese, and Galician and their annotation procedure, the evaluation metrics, and a summary of the participant systems and their results. The task had close to 100 registered participants organised into twenty five teams making over 650 and 150 submissions in the practice and evaluation phases respectively.1 IntroductionMultiword Expressions (MWEs) are a challenge for natural language processing (NLP), as their linguistic behaviour (e.g., syntactic, semantic) differs from that of generic word combinations Baldwin and Kim (2010); Ramisch and Villavicencio (2018). Moreover, MWEs are pervasive in all domains Biber