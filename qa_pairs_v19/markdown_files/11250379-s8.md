# A Survey on Automatic Speech Recognition with an Illustrative Example on Continuous Speech Recognition of Mandarin

## Question

How does incorporating linguistic context dependency enhance recognition accuracy in continuous Mandarin speech recognition?

## URLs

1. https://ar5iv.org/html/2310.09680. [2310.09680] Improved Contextual Recognition in Automatic Speech Recognition Systems by Semantic Lattice Rescoring
2. https://ar5iv.org/html/2403.01255. [2403.01255] Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey
3. https://ar5iv.org/html/2409.10969. [2409.10969] Enhancing Multilingual Speech Generation and Recognition Abilities in LLMs with Constructed Code-switched Data
4. https://ar5iv.org/html/2406.10313. [2406.10313] CNVSRC 2023: The First Chinese Continuous Visual Speech Recognition Challenge
5. https://ar5iv.org/html/2408.14991. [2408.14991] Speech Recognition Transformers: Topological-lingualism Perspective
6. https://ar5iv.org/html/1711.01946. [1711.01946] MANDARIN TONE MODELING USING RECURRENT NEURAL NETWORKS
7. https://ar5iv.org/html/2408.10524. [2408.10524] XCB: an effective contextual biasing approach to bias cross-lingual phrases in speech recognition
8. https://ar5iv.org/html/2108.01122. [2108.01122] AUTOMATIC RECOGNITION OF SUPRASEGMENTALS IN SPEECH

## Answer (I don't know?: ✓)

I don't know. The context provided does not include specific information about incorporating linguistic context dependency in continuous Mandarin speech recognition or how it enhances recognition accuracy. The passages focus on various aspects of large language models, conversational abilities, context learning, and reasoning tasks, but they do not explicitly address techniques or findings related to Mandarin speech recognition specifically. Thus, the context is insufficient to answer the question directly.

1. [1]:  https://ar5iv.org/html/2402.13551, No Title
2. [2]:  https://ar5iv.org/html/2411.13577, No Title
3. [3]:  https://ar5iv.org/html/2411.13577, No Title
4. [4]:  https://ar5iv.org/html/2411.13577, No Title
5. [5]:  https://ar5iv.org/html/2407.05682, No Title
---
1. [1]:  Passage ID 1: WeChat AIliyanlxu@tencent.com moyumyu@global.tencent.com1 IntroductionText comprehension has been advanced significantly ascribed to Large Language Models (LLMs), especially with long context window enabled via techniques such as positional scaling Xiong et al. (2023); Peng et al. (2024) and efficient attention Wang et al. (2023); Chen et al. (2024). Nevertheless, though extending context window could resolve certain long context tasks end-to-end, e.g. question answering, more fine-grained tasks that require explicit global dependency beyond local evidence still remain a challenge.In book-level narrative understanding particularly, such as retrieving relevant plot passages of queries Xu et al. (2023b), or identifying recap passages of a given plot Li et al. (2024), each local passage in a novel rather serves specific purposes to other parts than being isolated, which may be easily neglected in the end-to-end process without explicit modeling these global dependency
2. [2]:  Passage ID 2: conversational ability, and further exploration is still needed in this area of evaluation. Explicitly requiring a spoken dialogue model to perform speech translation is not a typical use case in conversational scenarios. In most cases, when a user asks a question in a different language or with a distinct accent, the model is expected to automatically respond in the same language that the user is using. In this context, it seems more reasonable to evaluate the accuracy of the model’s generated speech in terms of language identification, combined with subjective human assessments, as a more intuitive and appropriate evaluation method.Context Learning. The context learning capability is crucial for maintaining the coherence of an entire conversation. Similar to a memory function, the challenge lies in how to preserve this capability when relying solely on speech. Typically, the evaluation of a spoken dialogue model’s context learning ability depends on specific long-duration dialogue
3. [3]:  Passage ID 3: conversational ability, and further exploration is still needed in this area of evaluation. Explicitly requiring a spoken dialogue model to perform speech translation is not a typical use case in conversational scenarios. In most cases, when a user asks a question in a different language or with a distinct accent, the model is expected to automatically respond in the same language that the user is using. In this context, it seems more reasonable to evaluate the accuracy of the model’s generated speech in terms of language identification, combined with subjective human assessments, as a more intuitive and appropriate evaluation method.Context Learning. The context learning capability is crucial for maintaining the coherence of an entire conversation. Similar to a memory function, the challenge lies in how to preserve this capability when relying solely on speech. Typically, the evaluation of a spoken dialogue model’s context learning ability depends on specific long-duration dialogue
4. [4]:  Passage ID 4: conversational ability, and further exploration is still needed in this area of evaluation. Explicitly requiring a spoken dialogue model to perform speech translation is not a typical use case in conversational scenarios. In most cases, when a user asks a question in a different language or with a distinct accent, the model is expected to automatically respond in the same language that the user is using. In this context, it seems more reasonable to evaluate the accuracy of the model’s generated speech in terms of language identification, combined with subjective human assessments, as a more intuitive and appropriate evaluation method.Context Learning. The context learning capability is crucial for maintaining the coherence of an entire conversation. Similar to a memory function, the challenge lies in how to preserve this capability when relying solely on speech. Typically, the evaluation of a spoken dialogue model’s context learning ability depends on specific long-duration dialogue
5. [5]:  Passage ID 5: from Previous MistakesHao Sun1,Yong Jiang2††thanks:     Corresponding Author.,Bo Wang3Yingyan Hou4,Yan Zhang1*,Pengjun Xie2,Fei Huang21Peking University,3Beijing Institute of Technology2Alibaba Group,4Chinese Academy of Sciencessunhao@stu.pku.edu.cn1 IntroductionIn recent years, large language models (LLMs) have achieved superior performance on a wide range of reasoning tasks, which include mathematic reasoning Xia et al. (2024); Yamauchi et al. (2023); Imani et al. (2023); Lewkowycz et al. (2022), commonsense reasoning Bian et al. (2023); Krause and Stolzenburg (2023); Zhao et al. (2024), symbolic reasoning Dave et al. (2024); Kojima et al. (2022); Qian et al. (2022), and so on.To enhance these capabilities further and to align model processing closer to human-like reasoning, recent research has increasingly focused on in-context learning (ICL) Ye et al. (2023); Shum et al. (2023); Zhang et al. (2022), where models generate responses based on a few