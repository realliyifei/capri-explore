# A Survey on Intelligent Poetry Generation: Languages, Features, Techniques, Reutilisation and Evaluation

## Question

How do English poetry generation systems typically handle metre and rhyme?

## URLs

1. https://ar5iv.org/html/2406.15267. [2406.15267] Evaluating Diversity in Automatic Poetry Generation
2. https://ar5iv.org/html/2410.15299. [2410.15299] Does ChatGPT Have a Poetic Style?
3. https://ar5iv.org/html/2305.08493. [2305.08493] Creative Data Generation: A Review Focusing on Text and Poetry
4. https://ar5iv.org/html/2406.18906. [2406.18906] Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets
5. https://ar5iv.org/html/2406.03450. [2406.03450] What is the Best Way for ChatGPT to Translate Poetry?
6. https://ar5iv.org/html/2210.13669. [2210.13669] Help me write a poem: Instruction Tuning as a Vehicle for Collaborative Poetry Writing
7. https://ar5iv.org/html/1711.00938. No content available
8. https://ar5iv.org/html/2002.02511. [2002.02511] Introducing Aspects of Creativity in Automatic Poetry Generation
9. https://ar5iv.org/html/1908.08861. [1908.08861] Neural Poetry: Learning to Generate Poems using SyllablesThis is a post-peer-review, pre-copyedit version of an article published in LNCS, volume 11730. The final authenticated version is available online at: https://doi.org/10.1007/978-3-030-30490-4_26
10. https://ar5iv.org/html/2103.03775. [2103.03775] There Once Was a Really Bad Poet, It Was Automated but You Didn’t Know It

## Answer (I don't know?: ✗)

English poetry generation systems typically employ various techniques to handle metre and rhyme, drawing on advancements in both statistical methods and neural network architectures.

Statistical methods have formed a foundational approach, as seen in the work of Greene et al. (2010), who utilized unsupervised learning to identify word stress patterns in Italian poetry and applied those patterns to generate English poetry, ensuring adherence to rhythmic constraints [1]. These explorations highlight the importance of structural elements like metre and rhyme in poetry generation.

In more recent developments, neural networks have largely replaced earlier methods due to their flexibility and power. Ghazvininejad et al. (2018) introduced a neural poetry translation system that translates French poetry to English while conforming to user-specified rhythm and rhyme patterns, outperforming traditional phrase-based machine translation methods [1]. This indicates a trend towards using sophisticated algorithms that can adapt more fluidly to the constraints of poetic forms.

The architecture of poetry generation systems varies, with many modern implementations utilizing encoder-decoder structures that include Long Short-Term Memory (LSTM) networks. For example, Lau et al. (2018) developed the Deep-speare model, specifically designed for generating Shakespearean sonnets, which employs three distinct neural networks to manage rhythm, rhyme, and word choice [3] [4]. Such systems emphasize the need for a meticulously coordinated handling of both content and form to produce aesthetically pleasing poetry.

Attention mechanisms further enhance generation capabilities by allowing models to focus on specific aspects of the text when generating each line or verse. This can significantly improve the compliance to rhyming schemes and rhythmic structures [3] [4]. Additionally, the Storyline algorithm proposed in some systems strategically chooses the last word of each line—critical for maintaining rhyme—before generating the rest of the line, showcasing a targeted method of ensuring poetic fidelity [3].

In a process that reflects a more hands-off approach, contemporary neural models like ByGPT5 leverage large datasets without strict human guidance in model design, thereby learning to generate poetry that adheres to style constraints such as rhyme autonomously [5]. This evolution reflects a shift towards creating systems that can operate with less manual intervention while still producing text that meets established poetic standards.

Nevertheless, despite these advancements, empirical evaluations reveal that while generated poems often achieve notable quality, they typically still do not fully match the craftsmanship of human-generated poetry—an area where human aesthetic judgement plays an essential role in determining the success of generated work [4]. 

Overall, English poetry generation systems utilize a combination of statistical analysis, advanced neural network techniques, attention mechanisms, and collaborative human input to effectively handle the complexities of metre and rhyme, continually refining their outputs to enhance creative quality.

1. [1]:  https://ar5iv.org/html/2406.03450, [2406.03450] What is the Best Way for ChatGPT to Translate Poetry?
2. [2]:  https://ar5iv.org/html/1908.08861, [1908.08861] Neural Poetry: Learning to Generate Poems using SyllablesThis is a post-peer-review, pre-copyedit version of an article published in LNCS, volume 11730. The final authenticated version is available online at: https://doi.org/10.1007/978-3-030-30490-4_26
3. [3]:  https://ar5iv.org/html/2103.03775, [2103.03775] There Once Was a Really Bad Poet, It Was Automated but You Didn’t Know It
4. [4]:  https://ar5iv.org/html/2002.02511, [2002.02511] Introducing Aspects of Creativity in Automatic Poetry Generation
5. [5]:  https://ar5iv.org/html/2406.15267, [2406.15267] Evaluating Diversity in Automatic Poetry Generation
---
1. [1]:  Passage ID 1: (2010). This research explored how statistical machine translation systems could produce translations that adhere to constraints such as length, rhythm, and rhyme.Subsequently, Greene et al. (2010) used statistical methods to translate rhymed poetry, achieving the translation of Italian poetry into English. Through unsupervised learning, they identified word stress patterns in an original poetry corpus, which were then utilized in generating English poetry.Ghazvininejad et al. (2018) introduced the first neural poetry translation system, capable of translating French poetry into English while adhering to user-specified target rhythm and rhyme patterns. This system demonstrated greater flexibility than phrase-based machine translation (PBMT) systems, consistently generating translations that fit any specified scheme.Chakrabarty et al. (2021) conducted an empirical study on poetry translation, highlighting a crucial yet often overlooked issue: advanced machine translation systems,
2. [2]:  Passage ID 2: Learning Language Models Recurrent Neural Networks Natural Language Generation.1 IntroductionNatural Language Generation (NLG) is a challenging problem that has drawn a lot of attention in the Natural Language Processing (NLP) community [15, 17]. NLG is crucial for multiple NLP applications and problems, such as dialogue systems [20], text summarization [4], and text paraphrasing [7].Poem generation is an instance of NLG that is particularly fascinating for its peculiar features. Verses have precise structures, rhyme and meter that convey an aesthetic and rhythmic sound to the poetry. This expressive art of language is ancient and spread across all cultures in the world.Automatically creating poems requires a strong attention to both the content and the form. The machine has to capture the linguistic features that strongly characterize a certain poet, as well as the semantics of the poet’s production, that are influenced by their personal experiences and by their literary
3. [3]:  Passage ID 3: 2019). However, their large-scale neural network models take advantage of the Chinese quatrain database, which has more than 150k training examples. In contrast, LimGen uses less than 300 limericks. Most modern poetry-generation systems are encoder-decoder style recurrent networks (e.g. character-level and word-level LSTMs) with modifications such as various forms of attention mechanisms. Lau et al. (2018) integrated these techniques and proposed Deep-speare, which represents the state-of-the-art for Shakespearean sonnet generation. In our experiments, we have adapted and re-trained Deep-speare for limerick generation. Empirically, it cannot compete with LimGen.For handling rhyming constraints, unlike Ghazvininejad et al. (2016) and Benhart et al. (2018) who generate the last word of each line before generating the rest of the line, our proposed Storyline algorithm selects a probability distribution for the last word of each line.Beyond poetry generation, templates are often used
4. [4]:  Passage ID 4: controlling for style in Chinese poetry. They found that with enough training data, adequate results could be achieved. Problems related to poetic structure were addressed by Hopkins and Kiela (2017). They generated rhythmic poetry by training the network on only a single type of poetry to ensure produced poems adhered to a single rhythmic structure. It was found in human evaluations that while the poems produced were rated to be of lower quality than human produced poems, they were indistinguishable from human produced poems. Lau et al. (2018) took the LSTM approach one step further with the Deepspeare model by employing an attention mechanism to model interactions among generated words. They also use three neural networks, one for rhythm, one for rhyming and another for word choice in their quest to generate Shakespeare-like sonnets.Vaswani et al. (2017) developed a deep neural architecture called the Transformer that did away with any sort of need for recurrence. The Transformer
5. [5]:  Passage ID 5: While early modern systems were heavily hand-engineered Gervás (2001), more recent approaches are all trained on collections of human poetry Lau et al. (2018); Jhamtani et al. (2019); Agarwal and Kann (2020) but still extensively utilize human guidance e.g. to enforce formal characteristics of poetry such as rhyming Wöckener et al. (2021). Belouadi and Eger (2023) have recently released a character-level decoder-only LLM (ByGPT5) capable of learning style-constraints such as rhyming without human involvement in model design.Chakrabarty et al. (2022) propose a collaborative system for poetry,which can follow human instructions to write poems. Theymeasure creativity of the generated poems via crowd workers, who decidewhich of two poems is more creative. While Chakrabarty et al. (2022) do not define creativity, it could be considered as generating novel poems outside the training data set; in contrast, we measure diversity by assessing whether poetry generation systems generate