# Through the Lens of Core Competency: Survey on Evaluation of Large Language Models

## Question

What are the methods used to assess the quality of text generated with sentiment in NLP tasks?

## URLs

1. https://ar5iv.org/html/2408.01527. [2408.01527] Analyzing LLMs’ Capabilities to Establish Implicit User Sentiment of Software Desirability* *The authors wish to thank Creighton University and Dakota State University for their generous financial support of this research.
2. https://ar5iv.org/html/2310.05312. [2310.05312] Quality Assurance of A GPT-based Sentiment Analysis System: Adversarial Review Data Generation and Detection
3. https://ar5iv.org/html/2405.09770. [2405.09770] Optimization Techniques for Sentiment Analysis Based on LLM (GPT-3)
4. https://ar5iv.org/html/2404.10503. [2404.10503] A Sentiment Analysis of Medical Text Based on Deep Learning
5. https://ar5iv.org/html/2409.17885. [2409.17885] Sentiment Analysis of ML Projects: Bridging Emotional Intelligence and Code Quality
6. https://ar5iv.org/html/2407.13069. [2407.13069] Dynamic Sentiment Analysis with Local Large Language Models using Majority Voting: A Study on Factors Affecting Restaurant Evaluation
7. https://ar5iv.org/html/2311.11250. [2311.11250] A Comprehensive Review on Sentiment Analysis: Tasks, Approaches and Applications
8. https://ar5iv.org/html/2405.04053. [2405.04053] Evaluating Text Summaries Generated by Large Language Models Using OpenAI’s GPT
9. https://ar5iv.org/html/2309.02045. [2309.02045] Enhance Multi-domain Sentiment Analysis of Review Texts through Prompting Strategies
10. https://ar5iv.org/html/2205.06439. [2205.06439] AEON: A Method for Automatic Evaluation of NLP Test Cases

## Answer (I don't know?: ✗)

The quality of text generated in sentiment analysis tasks in NLP can be assessed using several methods, which include both traditional validation techniques and modern approaches enabled by advancements in large language models (LLMs). 

1. **Manual Label Recovery**: One method to assess the quality of generated sentiment text is to evaluate how well the machine-generated classifications correlate with manual labels. This process involves classifying documents multiple times using sentiment, emotional valence, and stance assessments, then comparing those classifications against human-annotated labels. This approach helps identify which classification methods best recover the intended sentiment categories from the text [1].

2. **Supervised Learning Approaches**: In sentiment analysis, supervised learning methods are commonly utilized. These rely on annotated datasets (labeled data) to train a prediction model. This model builds feature vectors based on text data and learns to predict sentiments for unseen data. The performance of such models is determined by how accurately they can classify new text based on previous training, offering a measure of the quality of sentiment classification [2][3].

3. **Benchmark Datasets**: Utilizing benchmark datasets is vital for evaluating sentiment analysis methods. Reviews and meta-analyses, such as Pang and Lee (2008), provide insights into the effectiveness of various techniques on standardized datasets, which allows for comparison across different models and methodologies in sentiment classification [2].

4. **Negation and Context Handling**: Another important aspect of quality assessment involves the methods for detecting and handling negation in text. Automated systems that can identify negation and adjust polarity (turning positive sentiments to negative and vice versa) enhance the accuracy of sentiment analysis. Techniques that incorporate context through decontraction systems, as well as methods that leverage lexicons and antonym dictionaries, can also improve sentiment classification quality [5].

5. **Custom Categorization**: For tasks that involve highly specific or customized sentiment categories, researchers may employ dictionary-based techniques or data-driven pipelines. Dictionary methods utilize keyword lists corresponding to sentiment categories, while data-driven methods require coding documents into predefined categories before training models on this coded data. These methods facilitate a more tailored sentiment analysis and can be critical in assessing quality in specific contexts [4].

6. **Performance Metrics**: In addition to the aforementioned methods, standard performance metrics such as accuracy, precision, recall, and F1-score are often employed to quantify the effectiveness of sentiment analysis models. These metrics provide a quantitative assessment of how well models predict sentiment compared to actual sentiments indicated in the dataset.

The combination of these methodologies and techniques allows researchers and practitioners to comprehensively assess the quality of text generated in sentiment analysis tasks within NLP, improving both the understanding and execution of sentiment classification [1][4][5].

1. [1]:  https://ar5iv.org/html/2405.02454, No Title
2. [2]:  https://ar5iv.org/html/2311.11250, [2311.11250] A Comprehensive Review on Sentiment Analysis: Tasks, Approaches and Applications
3. [3]:  https://ar5iv.org/html/2311.11250, [2311.11250] A Comprehensive Review on Sentiment Analysis: Tasks, Approaches and Applications
4. [4]:  https://ar5iv.org/html/2302.03490, No Title
5. [5]:  https://ar5iv.org/html/2302.02291, No Title
---
1. [1]:  Passage ID 1: of the text analysis task, and then the model executes the task based on the description. However, the ambiguous nature of sentiment outlined above raises an important question: How do large language models understand the task of “sentiment analysis” when prompted to do it? If the model’s understanding of sentiment is not consistent with the researcher’s, they may not be measuring what they think they are. Further, if sentiment is a confounded measurement, would text analysis improve if we disambiguate the term and measure more precise concepts? In the following sections I present answers to these questions.2 Data and MethodsI approach these questions by using LLMs to classify documents three different times: once for sentiment, once for emotional valence, and a final time for stance (opinion). I then evaluate which of the classification approaches is best able to recover manual labels from two data sets, and examine how well sentiment classifications correlate with both opinion
2. [2]:  Passage ID 2: Turney and Littman, 2003; Wiebe et al, 2000) worked on sentiments analysis and opinions mining. Nasukawa et al. (Nasukawa and Yi, 2003) showed the high precision result on customer reviews and news articles available over web pages. They classified the specific subjects from a document in positive or negative polarity. This paper’s result rise in interest to other researchers in this domain. The influential 2008 review of Pang and Lee (Pang and Lee, 2008) covers techniques and approaches that promise to directly enable opinion-oriented information-seeking systems on benchmark datasets in recent research. Here, we discuss sentiment analysis in NLP, including its different methods, such as supervised and unsupervised.2.1.1 Supervised ApproachIt is based on the annotated dataset (labeled data) to build a prediction model. This approach builds a feature vector of the text, either aspect or word frequency, then the model learns (training) on the dataset and gives prediction for unseen
3. [3]:  Passage ID 3: Turney and Littman, 2003; Wiebe et al, 2000) worked on sentiments analysis and opinions mining. Nasukawa et al. (Nasukawa and Yi, 2003) showed the high precision result on customer reviews and news articles available over web pages. They classified the specific subjects from a document in positive or negative polarity. This paper’s result rise in interest to other researchers in this domain. The influential 2008 review of Pang and Lee (Pang and Lee, 2008) covers techniques and approaches that promise to directly enable opinion-oriented information-seeking systems on benchmark datasets in recent research. Here, we discuss sentiment analysis in NLP, including its different methods, such as supervised and unsupervised.2.1.1 Supervised ApproachIt is based on the annotated dataset (labeled data) to build a prediction model. This approach builds a feature vector of the text, either aspect or word frequency, then the model learns (training) on the dataset and gives prediction for unseen
4. [4]:  Passage ID 4: 2020).A well-known subtask of text classification is sentiment classification (also known as sentiment analysis, or opinion mining), which aims to distinguish the subjective information in the text, such as positive or negative sentiment (Pang and Lee, 2007).However, the existing tools only do well in categories that are easy to predict. If the categorization is customized and very specific to a study context, then there are two common solutions. One is to use dictionary-based methods, by a list of frequent keywords that correspond to a certain category (Albaugh et al., 2013) or using general linguistic dictionaries such as the Linguistic Inquiry and Word Count (LIWC) dictionary (Pennebaker et al., 2001).The second way is to adopt the data-driven pipeline, which requires human hand coding of documents into a predetermined set of categories, then train an NLP model to learn the text classification task (Sun et al., 2019), and verify the performance of the NLP model on a held-out
5. [5]:  Passage ID 5: tool, we answered the following two questions:•RQ1: How do we detect negation in a given text?•RQ2: How can a automated system apply negation to appropriate words to improve sentiment analysis?NLP was used mainly because it guides the extraction of information from texts in their natural form. The most frequent lexicon-based technique for negation is to reverse the polarity of the object that is affected by the negator in a sentence (Jurek et al., 2015). This study presents an alternative approach by developing a disambiguation function that can be used to average out the polarity scores of the negated word antonyms using five dictionaries. Beyond sentiment detection, we propose using antonyms to construct a human-readable semantic construction of the entire sentence, taking a context-based approach into consideration. First, detecting negation in a sentence requires the use of an automated decontraction system, as some negations may be in contraction mode e.g.,