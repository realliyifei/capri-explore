# GPTEval: A Survey on Assessments of ChatGPT and GPT-4

## Question

How effective were ChatGPT and GPT-4 in handling ambiguity in Natural Language Inference tasks?

## URLs

1. https://ar5iv.org/html/2304.03439. [2304.03439] Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4
2. https://ar5iv.org/html/2404.11972. [2404.11972] Aligning Language Models to Explicitly Handle Ambiguity
3. https://ar5iv.org/html/2305.05862. [2305.05862] Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text Analytics? A Study on Several Typical Tasks
4. https://ar5iv.org/html/2405.12063. [2405.12063] CLAMBER: A Benchmark of Identifying and Clarifying Ambiguous Information Needs in Large Language Models
5. https://ar5iv.org/html/2411.18337. [2411.18337] Can LLMs assist with Ambiguity? A Quantitative Evaluation of various Large Language Models on Word Sense Disambiguation
6. https://ar5iv.org/html/2312.11511. [2312.11511] ComplexityNet: Increasing LLM Inference Efficiency by Learning Task Complexity
7. https://ar5iv.org/html/2402.17717. [2402.17717] AmbigNLG: Addressing Task Ambiguity in Instruction for NLG

## Answer (I don't know?: ✗)

ChatGPT and GPT-4 demonstrate some effectiveness in handling Natural Language Inference (NLI) tasks, but they face notable challenges, particularly regarding ambiguity. The evaluation results indicate mixed performance outcomes for both models in NLI tasks, especially when dealing with tasks that require logical reasoning. For instance, while ChatGPT achieves a modest 57.30% accuracy in certain logical reasoning tasks, it still falls short of RoBERTa's performance, which indicates that ChatGPT may struggle more with nuanced interpretations that are crucial when ambiguity is present in the NLI context [4]. 

Furthermore, despite some success in logical reasoning benchmarks, both models have limitations. Their performance on the NLI task is not particularly strong when the instructions are complex or require detailed reasoning. ChatGPT’s accuracy on the MNLI dev set (55.40%) reflects these difficulties, suggesting that the model is not well-optimized for effectively handling three-label NLI questions that often involve ambiguous contexts [4]. 

In contrast, GPT-4 generally shows better performance than ChatGPT on more complex reasoning tasks, yet it still exhibits similar challenges in the NLI domain. For instance, its accuracy on the ConTRoL test set is slightly lower than ChatGPT's at 56.40%, highlighting potential issues with ambiguous inferences [4]. On other datasets such as ConjNLI and MED, while GPT-4 achieved higher accuracies (72.71% and 89.42% respectively), these tasks may not fully encapsulate the difficulties posed by ambiguity in everyday language use [4]. Therefore, while GPT-4 potentially offers a greater capacity for understanding complex and nuanced situations compared to ChatGPT, ambiguous queries in NLI tasks can still lead to performance barriers for both models.

Additionally, the overall performance of both models against traditional fine-tuning methods reveals that they can reason logically better; however, inherent challenges in handling new and out-of-distribution data persist, suggesting that ambiguity—especially in novel contexts—remains a significant hurdle [5]. Thus, while advancements are noted in the evaluation of ChatGPT and GPT-4, their effectiveness in robustly managing ambiguity in NLI tasks appears limited, necessitating further refinement and context-aware improvements for optimal performance.

1. [1]:  https://ar5iv.org/html/2304.03439, [2304.03439] Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4
2. [2]:  https://ar5iv.org/html/2305.05862, [2305.05862] Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text Analytics? A Study on Several Typical Tasks
3. [3]:  https://ar5iv.org/html/2304.03439, [2304.03439] Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4
4. [4]:  https://ar5iv.org/html/2304.03439, [2304.03439] Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4
5. [5]:  https://ar5iv.org/html/2304.03439, [2304.03439] Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4
---
1. [1]:  Passage ID 1: ChatGPT and GPT-4 in this domain. Previous ChatGPT evaluation indicates that ChatGPT performs better on deductive reasoning than inductive ones Bang et al. (2023) and that ChatGPT performs better on factual inputs Qin et al. (2023). After the release of GPT-4, we will discuss two tasks for evaluating its logical reasoning abilities: multi-choice reading comprehension and natural language inference. Both tasks are reasoning-heavy and serve as a playground for testing models’ reasoning abilities. Several logical reasoning datasets have been released under the two tasks. These benchmarks proved to be difficult to solve for PLMs. We hope this report will shed more light on the logical reasoning ability of ChatGPT and GPT-4. Our contributions are as follows:1. We test ChatGPT and GPT-4 on two logical reasoning tasks: multi-choice reading comprehension and natural language inference. We conduct experiments on multiple logical reasoning benchmarks to analyze the logical reasoning ability
2. [2]:  Passage ID 2: in IE, but can inherently benefit QA.5 DiscussionsComparison over LLMs.We are able to benchmark the performance of ChatGPT and GPT-4 with four other LLMs on five tasks with eight datasets. ChatGPT and GPT-4 significantly outperforms others in almost all datasets except the NER task. It is interesting to observe that both models perform better on financial NLP tasks than BloombergGPT, which was specifically trained on financial corpora. This might be due to the larger model size of the two models. Finally, GPT-4 constantly shows 10+% boost over ChatGPT in straightforward tasks such as Headlines and FiQA SA. For challenging tasks like RE and QA, GPT-4 can introduce 20-100% performance growth. This indicates that GPT-4 could be the first choice for financial NLP tasks before a more powerful LLM emerges.Prompt Engineering Strategies.We adopted two commonly used prompting strategies: few-shot and chain-of-thoughts. We constantly observe 1% to 4% performance boost on ChatGPT
3. [3]:  Passage ID 3: as well as ChatGPT, is a newly-released language model developed by OpenAI, designed to understand and generate multi-modal contents. GPT-4 is promoted to possess even more powerful capabilities in tasks that require logical reasoning. Logical reasoning is essential to human intelligence, enabling us to draw conclusions, make predictions, and solve problems based on given information. Incorporating logical reasoning into language models like GPT-4 can revolutionize natural language understanding (NLU) systems, making them more accurate, robust, and capable of understanding complex information in natural language.The evaluation of ChatGPT and GPT-4 for logical reasoning tasks explores their performance on several logical reasoning benchmarks, detailing the strengths and limitations of ChatGPT and GPT-4 in this domain. Previous ChatGPT evaluation indicates that ChatGPT performs better on deductive reasoning than inductive ones Bang et al. (2023) and that ChatGPT performs better on
4. [4]:  Passage ID 4: ChatGPT gives 57.30% accuracy, over 7 percent higher than that of RoBERTa. For comparison, ChatGPT gives 55.40% accuracy on the MNLI dev set, which is significantly lower than that of RoBERTa, which indicates that ChatGPT is not optimized for answering three-labeled natural language inference questions. Since it is noticed that ChatGPT is not good at following NLI task instructions, we provide an in-context example to help the model generate task labels, as shown in Figure 2.Overall, the results show that ChatGPT surpasses fine-tuned RoBERTa by only a small margin for logical reasoning NLI datasets.3.2.2 The performance of GPT-4We test GPT-4’s performance on logical reasoning NLI datasets. On the ConTRoL test set (805 instances), GPT-4 performs slightly lower than ChatGPT, yielding a 56.40% accuracy. The performance of GPT-4 on the ConjNLI test (623 instances) and the MED test (5382 instances) is significantly better, with an accuracy of 72.71% and 89.42%, respectively.
5. [5]:  Passage ID 5: ones. The experiment results show that ChatGPT and GPT-4 outperform the traditional fine-tuning method on most logical reasoning benchmarks, indicating that these two models can better reason logically. However, both models face challenges in handling new and out-of-distribution data. Besides, ChatGPT and GPT-4 do not perform astonishingly well on the natural language inference task requiring logical reasoning.ReferencesBang et al. (2023)Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie,Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, andPascale Fung. 2023.A multitask, multilingual,multimodal evaluation of chatgpt on reasoning, hallucination, andinteractivity.Bowman et al. (2015)Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning.2015.A large annotatedcorpus for learning natural language inference.In Proceedings of the 2015 Conference on Empirical Methods inNatural Language