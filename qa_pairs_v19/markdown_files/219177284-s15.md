# Conversational Machine Comprehension: a Literature Review

## Question

What are the two main approaches to integrating conversational history in machine comprehension models?

## URLs

1. https://ar5iv.org/html/2006.00671. [2006.00671] Conversational Machine Comprehension: a Literature Review
2. https://ar5iv.org/html/1810.06683. [1810.06683] FlowQA: Grasping Flow in History for Conversational Machine Comprehension
3. https://ar5iv.org/html/2104.11394. [2104.11394] BERT-CoQAC: BERT-based Conversational Question Answering in Context
4. https://ar5iv.org/html/1905.05412. [1905.05412] BERT with History Answer Embedding for Conversational Question Answering
5. https://ar5iv.org/html/2405.13003. [2405.13003] A Survey on Recent Advances in Conversational Data Generation
6. https://ar5iv.org/html/1909.10743. [1909.10743] An Empirical Study of Content Understanding in Conversational Question Answering
7. https://ar5iv.org/html/2401.12576. [2401.12576] LLMCheckup: Conversational Examination of Large Language Models via Interpretability Tools
8. https://ar5iv.org/html/2407.12363. [2407.12363] Conversational Query Reformulation with the Guidance of Retrieved Documents

## Answer (I don't know?: ✗)

In the context of integrating conversational history into machine comprehension models, two main approaches are highlighted.

1. **History Answer Embedding**: This approach focuses on the seamless integration of conversation history into a Conversational Question Answering (ConvQA) model. It is described as conceptually simple yet highly effective, allowing the model to utilize the history of answers within the conversation efficiently. This methodology aligns with the BERT model architecture, which serves as the foundational framework for managing conversational context effectively [5]. The effectiveness of this approach emphasizes the importance of relevant conversation history rather than using the entire history indiscriminately, which can introduce extraneous noise and lead to decreased performance [2].

2. **History Selection Mechanism**: This approach involves selecting only the relevant parts of the conversational history that contribute significantly to answering the current question. It aims to address the challenge of processing an entire conversational context by filtering out unnecessary information [1][2]. By selectively incorporating past dialogues, the model improves accuracy and responsiveness in generating answers. The implementation of this mechanism is critical because utilizing all context information without discernment can result in performance deterioration due to noise signals [2].

Both approaches confront the challenges of understanding context within multi-turn conversations. They work towards refining how conversational history is modeled, maximizing the model's effectiveness in generating contextually appropriate answers while minimizing potential performance declines associated with irrelevant information.

1. [1]:  https://ar5iv.org/html/2104.11394, [2104.11394] BERT-CoQAC: BERT-based Conversational Question Answering in Context
2. [2]:  https://ar5iv.org/html/2104.11394, [2104.11394] BERT-CoQAC: BERT-based Conversational Question Answering in Context
3. [3]:  https://ar5iv.org/html/2104.11394, [2104.11394] BERT-CoQAC: BERT-based Conversational Question Answering in Context
4. [4]:  https://ar5iv.org/html/1810.06683, [1810.06683] FlowQA: Grasping Flow in History for Conversational Machine Comprehension
5. [5]:  https://ar5iv.org/html/1905.05412, [1905.05412] BERT with History Answer Embedding for Conversational Question Answering
---
1. [1]:  Passage ID 1: QA systems has always been a challenging task in natural language processing and used as a benchmark to evaluate machine’s ability of natural language understanding. However, such systems often struggle when the question answering is carried out in multiple turns by the users to seek more information based on what they have already learned, thus, giving rise to another complicated form called Conversational Question Answering (CQA). CQA systems are often criticized for not understanding or utilizing the previous context of the conversation when answering the questions. To address the research gap, in this paper, we explore how to integrate the conversational history into the neural machine comprehension system. On one hand, we introduce a framework based on publicly available pre-trained language model called BERT for incorporating history turns into the system. On the other hand, we propose a history selection mechanism that selects the turns that are relevant and contributes the most
2. [2]:  Passage ID 2: model called BERT for incorporating history turns into the system. On the other hand, we propose a history selection mechanism that selects the turns that are relevant and contributes the most to answer the current question. Experimentation results revealed that our framework is comparable in performance with the state-of-the-art models on the QuAC111http://quac.ai/ leader board. We also conduct a number of experiments to show the side effects of using entire context information which brings unnecessary information and noise signals resulting in a decline in the model’s performance.Keywords: Machine comprehension Information retrieval Deep Learning Deep Learning Applications1 IntroductionThe field of conversational AI can be divided in to three categories namely, goal-oriented dialogue systems, chat-oriented dialogue systems, and question answering (QA) dialogue systems.The former two have been very researched upon topics, resulting in a number of successful dialogue agents
3. [3]:  Passage ID 3: searches its database to find an appropriate solution of that query. This could turn into a multi-turn conversation ifthe user needs to have more detailed information about the topic. The ability to take into account previous utterances is key to building interactive QA dialogue systems that can keep conversations active and useful. Yet, modeling conversation history in an effective way is still an open challenge in such systems.Existing approaches have tried to address the problem of history conversation modelingby prepending history questions and answers to the current question and source passage [4]. Though this seems to be a simple method to improve the answer’s accuracy, in reality it fails to do so. Another approach used complex Graph Neural Networks [5] to deal with this issue. One recent work [6] introduced the use of history answer embeddings but theydid not consider using relevant context rather than used entire history turns to find the answer span. Also, they did not
4. [4]:  Passage ID 4: history, which is the main focus in our work.7 ConclusionWe presented a novel Flow component for conversational machine comprehension.By applying Flow to a state-of-the-art machine comprehension model, our model encodes the conversation history more comprehensively, and thus yields better performance. When evaluated on two recently proposed conversational challenge datasets and three domains of a sequential instruction understanding task (through reduction), FlowQA outperforms existing models.While our approach provides a substantial performance gain, there is still room for improvement. In the future, we would like to investigate more efficient and fine-grained ways to model the conversation flow, as well as methods that enable machines to engage more active and natural conversational behaviors, such as asking clarification questions.AcknowledgmentsWe would like to thank anonymous reviewers, Jonathan Berant, Po-Sen Huang and Mark Yatskar, who helped improve the
5. [5]:  Passage ID 5: question or use complicated attention mechanisms to model the history. We propose a conceptually simple yet highly effective approach referred to as history answer embedding. It enables seamless integration of conversation history into a conversational question answering (ConvQA) model built on BERT (Bidirectional Encoder Representations from Transformers). We first explain our view that ConvQA is a simplified but concrete setting of conversational search, and then we provide a general framework to solve ConvQA. We further demonstrate the effectiveness of our approach under this framework. Finally, we analyze the impact of different numbers of history turns under different settings to provide new insights into conversation history modeling in ConvQA.††journalyear: 2019††copyright: acmcopyright††conference: Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval; July 21–25, 2019; Paris, France††booktitle: Proceedings of the 42nd