# Multiword Expression Processing: A Survey under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license Computational Linguistics

## Question

What are the primary challenges and limitations in assessing the quality of multiword expression (MWE) translation in machine translation systems?

## URLs

1. https://ar5iv.org/html/2406.13698. [2406.13698] MMTE: Corpus and Metrics for Evaluating Machine Translation Quality of Metaphorical Language
2. https://ar5iv.org/html/2407.03518. [2407.03518] Improving LLM Abilities in Idiomatic Translation
3. https://ar5iv.org/html/2210.04545. [2210.04545] Automatic Evaluation and Analysis of Idioms in Neural Machine Translation
4. https://ar5iv.org/html/2005.10583. [2005.10583] MultiMWE: Building a Multi-lingual Multi-Word Expression (MWE) Parallel Corpora
5. https://ar5iv.org/html/2310.07081. [2310.07081] Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting
6. https://ar5iv.org/html/1907.10676. [1907.10676] Semantic Web for Machine Translation: Challenges and Directions
7. https://ar5iv.org/html/2407.03658. [2407.03658] GPT-4 vs. Human Translators: A Comprehensive Evaluation of Translation Quality Across Languages, Domains, and Expertise Levels
8. https://ar5iv.org/html/2401.16313. [2401.16313] Machine Translation Meta Evaluation through Translation Accuracy Challenge Sets
9. https://ar5iv.org/html/2112.13833. [2112.13833] HOPE: A Task-Oriented and Human-Centric Evaluation Framework Using Professional Post-Editing Towards More Effective MT Evaluation
10. https://ar5iv.org/html/2406.15175. [2406.15175] Enhancing Idiomatic Representation in Multiple Languages via an Adaptive Contrastive Triplet Loss

## Answer (I don't know?: ✗)

The translation of multiword expressions (MWEs) in machine translation (MT) systems faces several primary challenges and limitations. 

First, one critical challenge is the complexity and variability of MWEs themselves. MWEs are not merely combinations of individual words; they often carry meanings that differ from the literal translations of their components. This necessitates that MT systems differentiate between the surface form of the words and their idiomatic meanings. For instance, translating metaphorical expressions like "kick the bucket" requires an understanding of the idiomatic context rather than a straightforward word-for-word translation. Failing to account for this can lead to inadequate or incorrect translations [1][4].

Another significant challenge relates to the low availability of high-quality multilingual or bilingual MWE corpora, which are essential for training effective MT models. The lack of comprehensive datasets for MWEs limits the ability of systems to learn from diverse linguistic contexts, thereby impacting their performance on translation tasks. Currently, the research community acknowledges a scarcity of freely available bilingual MWE corpora, which hampers the development and evaluation of MWE handling in multiple languages [2]. 

Additionally, the integration of MWEs into broader NLP applications, including MT, poses its own set of issues. Incorporating such expressions requires sophisticated detection, decomposition, and semantic understanding capabilities within the MT systems, which are often still underdeveloped. Research indicates that merely focusing on the syntactic structure without deep semantic insight leads to suboptimal translation outcomes, particularly in capturing the correct meaning and nuance of MWEs in different contexts [1][4].

Word sense disambiguation (WSD) also plays a crucial role in this context. MWEs are inherently linked to WSD; they can present ambiguities that require contextual understanding. For example, without accurate phrase boundary detection, an MT system may struggle with effectively identifying and translating MWEs, resulting in awkward or incorrect translations if the model fails to recognize the MWE as a cohesive unit [4][5].

Furthermore, studies indicate that while advanced techniques like neural machine translation (NMT) can improve accuracy, they still struggle with unseen words and complex MWEs that have not been previously encountered in training datasets. This indicates a persistent vulnerability in translation systems regarding MWEs, as the incorporation of MWEs into NMT often requires additional modeling strategies that are not universally applicable across languages [5].

In summary, the primary challenges in assessing the quality of MWE translation in MT systems include the idiomatic nature and variability of MWEs, the insufficient availability of multilingual corpora, the need for improved detection and semantic comprehension of MWEs, and the inherent difficulties associated with word sense disambiguation. Overcoming these challenges is crucial for enhancing the quality of MWE translation in machine translation applications [1][2][4][5].

1. [1]:  https://ar5iv.org/html/2005.10583, [2005.10583] MultiMWE: Building a Multi-lingual Multi-Word Expression (MWE) Parallel Corpora
2. [2]:  https://ar5iv.org/html/2005.10583, [2005.10583] MultiMWE: Building a Multi-lingual Multi-Word Expression (MWE) Parallel Corpora
3. [3]:  https://ar5iv.org/html/2310.07081, [2310.07081] Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting
4. [4]:  https://ar5iv.org/html/2005.10583, [2005.10583] MultiMWE: Building a Multi-lingual Multi-Word Expression (MWE) Parallel Corpora
5. [5]:  https://ar5iv.org/html/2005.10583, [2005.10583] MultiMWE: Building a Multi-lingual Multi-Word Expression (MWE) Parallel Corpora
---
1. [1]:  Passage ID 1: of this paper.2.1. Machine Translation and Multiword ExpressionsMT methods seek to translate one human language into another one. MT belongs to a branch of computational linguistics (CL) and artificial intelligence (AI), in which researchers try to use computational modeling to address linguistic text translation problems. It is a very challenging task for MT to achieve both accuracy of translated information and fluency at the level of a human expert’s performance or what linguists expect as output. There are many reasons for this, one of which is that the use of MWEs presents a significant obstacle for a machine to learn and generate human languages in a natural form. We use three examples to illustrate the importance of correct use of MWEs in MT.We use ZH/Zh to represent Chinese, and EN/En as English. We use pinyin (pīnyīn) to annotate the Báihuà Chinese for its pronunciation and tones (phoneticism). The MT outputs in the examples were from Google Translator engine [Vaswani
2. [2]:  Passage ID 2: Machine Translation, Language Resource, EvaluationMultiMWE: Building a Multi-lingual Multi-Word Expression (MWE) Parallel CorporaLifeng Han1, Gareth J.F. Jones1 and Alan F. Smeaton21 ADAPT Research Centre2 Insight Centre for Data AnalyticsSchool of Computing, Dublin City University, Glasnevin, Dublin 9, Irelandlifeng.han@adaptcentre.ie; {gareth.jones, alan.smeaton}@dcu.ieAbstract content1. IntroductionThe use of multi-word expressions (MWEs) has become a hot topic in research in the field of natural language processing (NLP). Topics of interests in MWEs include issues such as MWE detection [Maldonado et al., 2017], MWE decomposition, and the integration of MWEs into other NLP applications such as Machine Translation (MT). However, to support research into the multilingual use of MWEs, the availability of bilingual or multi-lingual MWE corpora is very limited. The only freely available bilingual MWE corpora that we are aware of, at the submission
3. [3]:  Passage ID 3: Workshop on Multiword Expressions (MWE), pages 38–42, Gothenburg, Sweden. Association for Computational Linguistics.Shao et al. (2017)Yutong Shao, Rico Sennrich, Bonnie Webber, and Federico Fancellu. 2017.Evaluating machine translation performance on chinese idioms with a blacklist method.Toral and Way (2018)Antonio Toral and Andy Way. 2018.What level of quality can neural machine translation attain on literary text?In J Moorkens, S Castilho, F Gaspari, and S Doherty, editors, Translation Quality Assessment: Technologies and Applications. Springer, Cham.Unbabel (2019)Unbabel. 2019.Why translating idioms is hard.Vaswani et al. (2017)Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017.Attention is all you need.Wang et al. (2017)Rui Wang, Masao Utiyama, Lemao Liu, Kehai Chen, and Eiichiro Sumita. 2017.Instance weighting for neural machine translation domain
4. [4]:  Passage ID 4: tasks, including MT. This is due to their very frequent appearances and their concept specific presentation. How to recognize MWEs correctly and translate them in a meaning-preserving way, instead of merely surface word translation is a challenging task. This section introduces existing research work in this area.MWEs in MT are related to word sense disambiguation (WSD) [Vickrey et al., 2005, Chan et al., 2007], phrase boundary detection, and semantics [Van de Cruys andVillada Moirón, 2007]. Instead of a single word case in WSD, MWEs are multiple-word expressions, which can be translated in an awkward way if the translation model cannot translate the actual meaning of the MWE in the sentence and context, such as metaphorical MWEs (‘apple of someone’s eyes’, ‘kick the bucket’, listed as simple examples). Addressing MWE translation also addresses the semantic aspects of translation in addition to issues of syntax, e.g. MWE boundary (detection) and its affects on overall sentence
5. [5]:  Passage ID 5: [Skadina, 2016] which discussed various MWEs in English-Latvian MT. Recent interesting work [Ebrahim et al., 2017] focused on phrasal verb MWEs in Arabic-English phrase-based SMT. Similar to the work above, we use different bilingual MWE extraction workflows and integrate the extracted MWE pairs into training corpora.2.3.2. NMT+MWEThis section introduces work on the incorporation of MWEs in NMT.MWEs can appear in different kinds of examples, such as Names Entities (NE) [Han et al., 2013] when the entities appear as a chunk of several words. In [Li et al., 2019], the author applied a character level sequence to sequence modeling to translate named entities and then integrated this into an overall NMT system on a Chinese-to-English task. This model was originally designed to solve the unseen word translation issue, but the results show that NEs in NMT helps to improve overall translation effectiveness as measured by BLEU score. It showed the model can derive higher quality