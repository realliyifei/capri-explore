# Recent Neural Methods on Dialogue State Tracking for Task-Oriented Dialogue Systems: A Survey

## Question

What strategies have been proposed to improve latency in dialogue state tracking (DST) models, and how do these strategies address the latency issues?

## URLs

1. https://ar5iv.org/html/2407.21633. [2407.21633] Zero-Shot Cross-Domain Dialogue State Tracking via Dual Low-Rank Adaptation
2. https://ar5iv.org/html/2410.18209. [2410.18209] CorrectionLM: Self-Corrections with SLM for Dialogue State Tracking
3. https://ar5iv.org/html/2306.01386. [2306.01386] ChatGPT for Zero-shot Dialogue State Tracking: A Solution or an Opportunity?
4. https://ar5iv.org/html/2311.09758. [2311.09758] OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking
5. https://ar5iv.org/html/2403.13112. [2403.13112] Encode Once and Decode in Parallel: Efficient Transformer Decoding
6. https://ar5iv.org/html/2305.17020. [2305.17020] Diable: Efficient Dialogue State Tracking as Operations on Tables
7. https://ar5iv.org/html/2405.10992. [2405.10992] Overcoming Catastrophic Forgetting by Exemplar Selection in Task-oriented Dialogue System
8. https://ar5iv.org/html/2303.06245. [2303.06245] AUTODIAL: Efficient Asynchronous Task-Oriented Dialogue Model
9. https://ar5iv.org/html/2410.11239. [2410.11239] HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR Applications

## Answer (I don't know?: ✗)

To improve latency in Dialogue State Tracking (DST) models, several strategies have been proposed, particularly focusing on the efficiency of computational resources while leveraging the capabilities of large language models (LLMs).

One prominent strategy is the orchestration of general-purpose LLMs with task-specific models, known as specialized language models (SLMs). This approach aims to enhance efficiency by combining the strengths of both types of models, thereby achieving significant reduction in computational costs without sacrificing performance. For instance, in research detailing efficient orchestration, it was noted that the combination could lead to a reduction of over 50% in computational costs associated with DST [5]. This reduction directly addresses latency by decreasing the computational resources required for model inference, which in turn translates to faster response times in dialogue systems.

Moreover, fine-tuning pre-trained LLMs has shown promise in improving DST performance in more resource-constrained environments. These models, while originally designed for diverse tasks, can be fine-tuned on specific DST tasks to enhance their accuracy and efficiency when extracting user intent from the dialogue history [1] [3]. Such fine-tuning enables the models to perform more effectively without the need for extensive computational resources typically required by unmodified LLMs.

Another key strategy involves leveraging in-context learning capabilities of LLMs. This method allows models like ChatGPT to perform zero-shot or few-shot learning by using prompts that include human-authored task descriptions or exemplars of DST tasks. Research has indicated that approaches such as these can lead to state-of-the-art performance in DST without the need for exhaustive training on large datasets [2]. By efficiently utilizing context, such models can minimize latency because they can quickly adapt to new tasks or requirements without the overhead of extensive retraining.

Furthermore, recent advancements suggest incorporating retrievers that fetch useful exemplars to aid the in-context learning process, optimizing the performance in DST scenarios even further [1]. This strategy enhances the model's ability to adapt during conversations by providing relevant examples in real-time, which reduces the need for computation-intensive operations that typically contribute to latency.

Overall, by integrating general-purpose and task-specific models, fine-tuning approaches, and employing in-context learning techniques, these strategies collectively address latency challenges in DST models. They optimize both the computational efficiency and effectiveness of dialogue systems, facilitating quicker and more responsive interactions in task-oriented dialogues [2][5].

1. [1]:  https://ar5iv.org/html/2311.09758, [2311.09758] OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking
2. [2]:  https://ar5iv.org/html/2306.01386, [2306.01386] ChatGPT for Zero-shot Dialogue State Tracking: A Solution or an Opportunity?
3. [3]:  https://ar5iv.org/html/2311.09758, [2311.09758] OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking
4. [4]:  https://ar5iv.org/html/2305.17020, [2305.17020] Diable: Efficient Dialogue State Tracking as Operations on Tables
5. [5]:  https://ar5iv.org/html/2311.09758, [2311.09758] OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking
---
1. [1]:  Passage ID 1: dialogues involving structured data typically rely on Dialogue State Tracking (DST), where user intent is extracted from the dialogue history between a user and the agent in the form of slot values associated with a predefined schema. Pre-trained language models that are fine-tuned have been used in DST for a few years, including both autoregressive LMs Ham et al. (2020); Hosseini-Asl et al. (2020); Peng et al. (2020) and sequence-to-sequence models Lee et al. (2021); Su et al. (2022); Bang et al. (2023); Imrattanatrai and Fukuda (2023); Wang et al. (2023). These methods generally rely on the availability of a substantial training corpus to achieve good performance.LLMs enable zero-shot or few-shot learning Brown et al. (2020). For DST, Xie et al. (2022); Hudeček and Dušek (2023) prompts LLM with human-authored task descriptions or in-context exemplars. Hu et al. (2022) improves the in-context learning for DST performance by incorporating a retriever to fetch useful exemplars.
2. [2]:  Passage ID 2: language models, trained on large amounts of diverse data, hold the promise of solving any kind of task without task-specific training. We present preliminary experimental results on the ChatGPT research preview, showing that ChatGPT achieves state-of-the-art performance in zero-shot DST. Despite our findings, we argue that properties inherent to general purpose models limit their ability to replace specialized systems.We further theorize that the in-context learning capabilities of such models will likely become powerful tools to support the development of dedicated and dynamic dialogue state trackers.1 IntroductionDialogue state tracking (DST) is a critical component for task-oriented dialogue systems. Its purpose is to extract and track user’s goals throughout a conversation Young et al. (2010). DST is challenging due to the infinite possibilities of user/agent conversations, and because services and schemas/APIs that dialogue systems interface are subject to constant
3. [3]:  Passage ID 3: Efficient Orchestration of Language Models for Dialogue State TrackingChia-Hsuan LeeUniversity of Washingtonchiahlee@uw.edu                      Hao ChengMicrosoft Researchchehao@microsoft.com                      Mari OstendorfUniversity of Washingtonostendor@uw.edu1 IntroductionLarge Language Models (LLMs) have emerged as a powerful tool for performing a wide array of tasks. However, they come with increasingly high computational costs as the sizes grow. Because many tasks have computation resource constraints, there is substantial interest in architectures that reduce costs but still take advantage of LLM capabilities. Conversational systems associated with task-oriented dialogues, such as virtual assistants, typically have such resource constraints.Task-oriented dialogues involving structured data typically rely on Dialogue State Tracking (DST), where user intent is extracted from the dialogue history between a user and the agent in the
4. [4]:  Passage ID 4: IntroductionFigure 1: Diable approach to DST. The figure presents the first two turns of a dialogue (user’s utterances are orange, system’s are green). When the conversation starts, the state table is empty. At each dialogue turn, the system outputs a table update operation (either INSERT or DELETE), and the state is modified accordingly. Dialogue state tracking (DST; Jacqmin et al., 2022) is the task of tracking user requests from the dialogue history in the form of slot-value pairs (Henderson et al., 2014; Mrkšić et al., 2015; Rastogi et al., 2020a). The slots are defined in a domain-specific schema and represent the fields that need to be extracted from the dialogue to execute queries in the backend and generate responses. Recent generative approaches to DST based on language models (Wu et al., 2019; Kim et al., 2020) often use the entire dialogue history as input and represent the state, at each turn, as the concatenation of all the slots in the schema, where inactive slots
5. [5]:  Passage ID 5: reduction of over 50% in computational costs.2 Dialogue State TrackingIn this work, we focus on combining general-purpose LLMs and task-specific SLMs to achieve better efficiency for dialogue state tracking (DST).In the following, we first provide the necessary task setups and then detail the two representative DST models using LLMs and SLMs respectively.A task-oriented dialogue (TOD) consists of a sequence of exchanges between two parties, each of which is initialized by the user and followed by a response from the system.Here, we denote each exchange as a turn leading to a sequence, U1,A1,…,UT,ATsubscript𝑈1subscript𝐴1…subscript𝑈𝑇subscript𝐴𝑇U_{1},A_{1},...,U_{T},A_{T}, where Utsubscript𝑈𝑡U_{t} and Atsubscript𝐴𝑡A_{t} represent the user utterance and the system response, respectively.For the t𝑡t-th turn, the user provides a new utterance Utsubscript𝑈𝑡U_{t}, and the system agent responds with utterance Atsubscript𝐴𝑡A_{t}.At turn t𝑡t, the corresponding dialogue context is