# Recent Neural Methods on Dialogue State Tracking for Task-Oriented Dialogue Systems: A Survey

## Question

What strategies have been proposed to improve latency in dialogue state tracking (DST) models, and how do these strategies address the latency issues?

## URLs

1. https://ar5iv.org/html/2407.21633. [2407.21633] Zero-Shot Cross-Domain Dialogue State Tracking via Dual Low-Rank Adaptation
2. https://ar5iv.org/html/2410.18209. [2410.18209] CorrectionLM: Self-Corrections with SLM for Dialogue State Tracking
3. https://ar5iv.org/html/2306.01386. [2306.01386] ChatGPT for Zero-shot Dialogue State Tracking: A Solution or an Opportunity?
4. https://ar5iv.org/html/2311.09758. [2311.09758] OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking
5. https://ar5iv.org/html/2403.13112. [2403.13112] Encode Once and Decode in Parallel: Efficient Transformer Decoding
6. https://ar5iv.org/html/2305.17020. [2305.17020] Diable: Efficient Dialogue State Tracking as Operations on Tables
7. https://ar5iv.org/html/2405.10992. [2405.10992] Overcoming Catastrophic Forgetting by Exemplar Selection in Task-oriented Dialogue System
8. https://ar5iv.org/html/2303.06245. [2303.06245] AUTODIAL: Efficient Asynchronous Task-Oriented Dialogue Model
9. https://ar5iv.org/html/2410.11239. [2410.11239] HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR Applications

## Answer (I don't know?: ✗)

To improve latency in dialogue state tracking (DST) models, several strategies have been proposed, particularly focusing on the efficient orchestration of language models (LLMs) and the combination of general-purpose and task-specific models. 

One significant strategy is the integration of general-purpose LLMs with task-specific structured language models (SLMs). This combination enhances the efficiency of DST by allowing the system to leverage the strengths of both types of models. General-purpose LLMs can perform a wide array of tasks due to their extensive pre-training, while SLMs are designed to handle specific tasks more efficiently. This hybrid approach can lead to a notable reduction in computational costs, reportedly over 50% [1][5]. This reduction directly addresses latency issues, enabling faster response times in task-oriented dialogue systems (TODs), which need to maintain efficiency, especially under resource constraints [2][3].

Additionally, the employment of efficient architectures tailored to reduce the high computational costs associated with larger LLMs is emphasized. As LLMs grow in size, their resource demands increase significantly, leading to higher latency in processing user queries. By developing new architectures that optimize the use of LLMs while managing computational cost effectively, researchers aim to strike a balance between performance and latency [3]. This is particularly important in conversational systems, where timely interactions are critical.

In-context learning has been highlighted as another technique to enhance latency performance in DST. This method allows models like ChatGPT to perform effectively on DST tasks without needing extensive retraining or task-specific adjustments. By showing promising results in zero-shot implementations, these models can quickly adapt to new dialog systems, helping to reduce latency by avoiding lengthy training cycles [2][4].

Furthermore, recent approaches streamline the dialogue history processing. Efficiently updating state information, such as by using table operations (INSERT or DELETE), allows the system to track user requests while minimizing the overhead associated with more conventional methods of managing dialogue state [4]. This can lead to quicker updates and a more responsive dialogue experience, further addressing latency concerns.

Overall, the combination of leveraging the power of LLMs with SLMs, creating efficient architectures to handle computational constraints, utilizing in-context learning capabilities, and employing streamlined methods for state tracking constitute the primary strategies to improve latency in DST models. These innovations allow dialogue systems to process user interactions more rapidly and effectively while maintaining high performance levels.

1. [1]:  https://ar5iv.org/html/2311.09758, [2311.09758] OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking
2. [2]:  https://ar5iv.org/html/2306.01386, [2306.01386] ChatGPT for Zero-shot Dialogue State Tracking: A Solution or an Opportunity?
3. [3]:  https://ar5iv.org/html/2311.09758, [2311.09758] OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking
4. [4]:  https://ar5iv.org/html/2305.17020, [2305.17020] Diable: Efficient Dialogue State Tracking as Operations on Tables
5. [5]:  https://ar5iv.org/html/2311.09758, [2311.09758] OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking
---
1. [1]:  Passage ID 1: dialogues involving structured data typically rely on Dialogue State Tracking (DST), where user intent is extracted from the dialogue history between a user and the agent in the form of slot values associated with a predefined schema. Pre-trained language models that are fine-tuned have been used in DST for a few years, including both autoregressive LMs Ham et al. (2020); Hosseini-Asl et al. (2020); Peng et al. (2020) and sequence-to-sequence models Lee et al. (2021); Su et al. (2022); Bang et al. (2023); Imrattanatrai and Fukuda (2023); Wang et al. (2023). These methods generally rely on the availability of a substantial training corpus to achieve good performance.LLMs enable zero-shot or few-shot learning Brown et al. (2020). For DST, Xie et al. (2022); Hudeček and Dušek (2023) prompts LLM with human-authored task descriptions or in-context exemplars. Hu et al. (2022) improves the in-context learning for DST performance by incorporating a retriever to fetch useful exemplars.
2. [2]:  Passage ID 2: language models, trained on large amounts of diverse data, hold the promise of solving any kind of task without task-specific training. We present preliminary experimental results on the ChatGPT research preview, showing that ChatGPT achieves state-of-the-art performance in zero-shot DST. Despite our findings, we argue that properties inherent to general purpose models limit their ability to replace specialized systems.We further theorize that the in-context learning capabilities of such models will likely become powerful tools to support the development of dedicated and dynamic dialogue state trackers.1 IntroductionDialogue state tracking (DST) is a critical component for task-oriented dialogue systems. Its purpose is to extract and track user’s goals throughout a conversation Young et al. (2010). DST is challenging due to the infinite possibilities of user/agent conversations, and because services and schemas/APIs that dialogue systems interface are subject to constant
3. [3]:  Passage ID 3: Efficient Orchestration of Language Models for Dialogue State TrackingChia-Hsuan LeeUniversity of Washingtonchiahlee@uw.edu                      Hao ChengMicrosoft Researchchehao@microsoft.com                      Mari OstendorfUniversity of Washingtonostendor@uw.edu1 IntroductionLarge Language Models (LLMs) have emerged as a powerful tool for performing a wide array of tasks. However, they come with increasingly high computational costs as the sizes grow. Because many tasks have computation resource constraints, there is substantial interest in architectures that reduce costs but still take advantage of LLM capabilities. Conversational systems associated with task-oriented dialogues, such as virtual assistants, typically have such resource constraints.Task-oriented dialogues involving structured data typically rely on Dialogue State Tracking (DST), where user intent is extracted from the dialogue history between a user and the agent in the
4. [4]:  Passage ID 4: IntroductionFigure 1: Diable approach to DST. The figure presents the first two turns of a dialogue (user’s utterances are orange, system’s are green). When the conversation starts, the state table is empty. At each dialogue turn, the system outputs a table update operation (either INSERT or DELETE), and the state is modified accordingly. Dialogue state tracking (DST; Jacqmin et al., 2022) is the task of tracking user requests from the dialogue history in the form of slot-value pairs (Henderson et al., 2014; Mrkšić et al., 2015; Rastogi et al., 2020a). The slots are defined in a domain-specific schema and represent the fields that need to be extracted from the dialogue to execute queries in the backend and generate responses. Recent generative approaches to DST based on language models (Wu et al., 2019; Kim et al., 2020) often use the entire dialogue history as input and represent the state, at each turn, as the concatenation of all the slots in the schema, where inactive slots
5. [5]:  Passage ID 5: reduction of over 50% in computational costs.2 Dialogue State TrackingIn this work, we focus on combining general-purpose LLMs and task-specific SLMs to achieve better efficiency for dialogue state tracking (DST).In the following, we first provide the necessary task setups and then detail the two representative DST models using LLMs and SLMs respectively.A task-oriented dialogue (TOD) consists of a sequence of exchanges between two parties, each of which is initialized by the user and followed by a response from the system.Here, we denote each exchange as a turn leading to a sequence, U1,A1,…,UT,ATsubscript𝑈1subscript𝐴1…subscript𝑈𝑇subscript𝐴𝑇U_{1},A_{1},...,U_{T},A_{T}, where Utsubscript𝑈𝑡U_{t} and Atsubscript𝐴𝑡A_{t} represent the user utterance and the system response, respectively.For the t𝑡t-th turn, the user provides a new utterance Utsubscript𝑈𝑡U_{t}, and the system agent responds with utterance Atsubscript𝐴𝑡A_{t}.At turn t𝑡t, the corresponding dialogue context is