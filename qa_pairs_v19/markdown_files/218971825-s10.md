# Language (Technology) is Power: A Critical Survey of "Bias" in NLP

## Question

What strategies do the authors propose to overcome the limitations of current NLP systems in handling African-American English (AAE)?

## URLs

1. https://ar5iv.org/html/2401.01262. [2401.01262] Fairness Certification for Natural Language Processing and Large Language Models
2. https://ar5iv.org/html/2005.14050. [2005.14050] Language (Technology) is Power: A Critical Survey of “Bias” in NLP
3. https://ar5iv.org/html/2108.03362. [2108.03362] On Measures of Biases and Harms in NLP
4. https://ar5iv.org/html/2107.03451. [2107.03451] Anticipating Safety Issues in E2E Conversational AI: Framework and Tooling
5. https://ar5iv.org/html/2310.15055. [2310.15055] Towards Conceptualization of “Fair Explanation”: Disparate Impacts of anti-Asian Hate Speech Explanations on Content Moderators
6. https://ar5iv.org/html/2112.11446. [2112.11446] Scaling Language Models: Methods, Analysis & Insights from Training Gopher
7. https://ar5iv.org/html/2206.08325. [2206.08325] Characteristics of Harmful Text: Towards Rigorous Benchmarking of Language Models
8. https://ar5iv.org/html/2104.08758. [2104.08758] Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus
9. https://ar5iv.org/html/2009.11462. [2009.11462] Untitled Document

## Answer (I don't know?: ✗)

The authors propose several strategies to overcome the limitations of current Natural Language Processing (NLP) systems in their handling of African-American English (AAE). These strategies are informed by a need to engage deeply with the existing literature on AAE, racial hierarchies, and raciolinguistic ideologies.

First, the authors emphasize the importance of placing AAE within the context of its speakers, primarily Black individuals in the U.S. who face systemic anti-Black racism. They argue that understanding the sociolinguistic dynamics around AAE, including how it is perceived (often viewed negatively as "bad" English), is critical to addressing biases in NLP systems [1]. Failing to engage with this literature results in a lack of context for analyzing “bias” in NLP systems as it concerns AAE, leading to incomplete or misguided conclusions about the capabilities and deficiencies of such systems [1].

Second, the authors advocate for the development and deployment of NLP systems that do not stigmatize or disenfranchise speakers of AAE. They suggest that researchers should focus on how NLP applications can produce negative outcomes for these communities and work to ensure that even well-meaning systems do not impose notions of linguistic inadequacy on AAE users [2]. This can involve understanding and incorporating the ways AAE speakers interact with NLP systems that were not designed for their linguistic style [2]. 

Moreover, the authors recommend that NLP practitioners draw on anti-racist language pedagogy to challenge the prevailing deficit perspective associated with AAE and other racialized language practices. This pedagogy can inform the design of NLP systems which respect linguistic diversity and do not merely seek to correct or accommodate speakers of AAE [5]. 

Lastly, the authors suggest that a systematic re-evaluation of the decision-making processes involved in the development of NLP systems is necessary. This involves shifting power dynamics away from oppressive institutional practices towards more equitable engagements with the communities affected by these technologies [3]. Engaging with the relevant literature and community perspectives can assist in reimagining these relationships to address the allocational harms often produced by NLP systems [2] [3].

In conclusion, the authors advocate for an inclusive approach that not only acknowledges but actively incorporates the linguistic rights and identities of AAE speakers into NLP development, thereby mitigating biases and promoting equitable systems.

1. [1]:  https://ar5iv.org/html/2005.14050, [2005.14050] Language (Technology) is Power: A Critical Survey of “Bias” in NLP
2. [2]:  https://ar5iv.org/html/2005.14050, [2005.14050] Language (Technology) is Power: A Critical Survey of “Bias” in NLP
3. [3]:  https://ar5iv.org/html/2005.14050, [2005.14050] Language (Technology) is Power: A Critical Survey of “Bias” in NLP
4. [4]:  https://ar5iv.org/html/2005.14050, [2005.14050] Language (Technology) is Power: A Critical Survey of “Bias” in NLP
5. [5]:  https://ar5iv.org/html/2005.14050, [2005.14050] Language (Technology) is Power: A Critical Survey of “Bias” in NLP
---
1. [1]:  Passage ID 1: practices to avoid negative perceptions or tweet removal.More importantly, none of these papers engage with the literature on AAE, racial hierarchies in the U.S., and raciolinguistic ideologies. By failing to engage with this literature—thereby treating AAE simply as one of many non-Penn Treebank varieties of English or perhaps as another challenging domain—work analyzing “bias” in NLP systems in the context of AAE fails to situate these systems in the world. Who are the speakers of AAE? How are they viewed? We argue that AAE as a language variety cannot be separated from its speakers—primarily Black people in the U.S., who experience systemic anti-Black racism—and the language ideologies that reinforce and justify racial hierarchies.Even after decades of sociolinguistic efforts to legitimize AAE, it continues to be viewed as “bad” English and its speakers continue to be viewed as linguistically inadequate—a view called the deficit perspective Alim et al. (2016); Rosa and Flores
2. [2]:  Passage ID 2: communities.We emphasize that engaging with the literature on AAE, racialhierarchies in the U.S., and raciolinguistic ideologies can generatenew lines of engagement. These lines include work on the ways that thedecisions made during the development and deployment of NLP systemsproduce stigmatization and disenfranchisement, and work on AAE use inpractice, such as the ways that speakers of AAE interact with NLPsystems that were not designed for them. This literature can also helpresearchers and practitioners address the allocational harms that maybe produced by NLP systems, and ensure that even well-intentioned NLPsystems do not position racialized communities as needing linguisticintervention or accommodation to dominant language practices. Finally,researchers and practitioners wishing to design better systems canalso draw on a growing body of work on anti-racist language pedagogythat challenges the deficit perspective of AAE and other racializedlanguage practices(e.g.
3. [3]:  Passage ID 3: shift power toward oppressive institutions (e.g., by enabling predictions that communities do not want made, linguistically based unfair allocation of resources or opportunities Rosa and Flores (2017), surveillance, or censorship), or away from such institutions?▷▷\trianglerightWho is involved in the development and deployment of NLP systems? How do decision-making processes maintain power relations between technologists and communities affected by NLP systems? Can these processes be changed to reimagine these relations?5 Case studyTo illustrate our recommendations, we present a case study covering work on African-American English (AAE).555This language variety hashad many different names over the years, but is now generally called African-American English(AAE), African-American Vernacular English (AAVE), orAfrican-American Language (AAL)Green (2002); Wolfram and Schilling (2015); Rickford and King (2016). Work analyzing “bias” in the context of AAE has shown that
4. [4]:  Passage ID 4: African American English?’ To this his boss responded: ‘Well, Apple products are for the premium market.”’The reality, of course, is that speakers of AAE tend not to represent the “premium market” precisely because of institutions and policies that help to maintain racial hierarchies by systematically denying them the opportunities to develop wealth that are available to white Americans Rothstein (2017)—an exclusion that is reproduced in technology by countless decisions like the one described above.Engaging with the literature outlined above situates the systembehaviors that are described as “bias,” providing a foundation fornormative reasoning. Researchers and practitioners should be concernedabout “racial bias” in toxicity detection systems not only becauseperformance differences impair system performance, but becausethey reproduce longstanding injustices of stigmatization anddisenfranchisement for speakers of AAE. In re-stigmatizing AAE, theyreproduce language
5. [5]:  Passage ID 5: wishing to design better systems canalso draw on a growing body of work on anti-racist language pedagogythat challenges the deficit perspective of AAE and other racializedlanguage practices(e.g. Flores and Chaparro, 2018; Baker-Bell, 2019; Martínez and Mejía, 2019),as well as the work that we described in section 4.3 onreimagining the power relations between technologists and communitiesaffected by technology.6 ConclusionBy surveying 146 papers analyzing “bias” in NLP systems,we found that (a) their motivations are often vague, inconsistent, andlacking in normative reasoning; and (b) their proposed quantitativetechniques for measuring or mitigating “bias” are poorly matched totheir motivations and do not engage with the relevantliterature outside of NLP. To help researchers and practitioners avoidthese pitfalls, we proposed three recommendations that should guidework analyzing “bias” in NLP systems, and, for each, provided several concrete research questions. These