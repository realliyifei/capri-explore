# Multiword Expression Processing: A Survey under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license Computational Linguistics

## Question

How does MWE-aware parsing effectively tackle the challenges posed by non-compositionality and discontiguity in multiword expressions?

## URLs

1. https://ar5iv.org/html/2303.06623
2. https://ar5iv.org/html/1805.08438
3. https://ar5iv.org/html/1510.07193

## Answer

## I don't know?: False

MWE-aware parsing addresses the challenges of non-compositionality and discontiguity in multiword expressions (MWEs) by employing specific strategies that recognize and manage the unique characteristics of MWEs in natural language processing (NLP) systems.

Firstly, non-compositionality refers to the fact that the meaning of a multiword expression cannot be directly inferred from the meanings of its individual components. This poses a significant challenge for NLP models because traditional models often operate under the assumption that the meaning of phrases can be deduced from their constituent words. MWE-aware parsing tackles this by effectively capturing the idiomatic and contextual meanings that are inherent in MWEs. For instance, Sag et al. (2002) highlight the idiomaticity problem, stressing that MWEs can often have meanings that are distinct from their individual words, which necessitates specialized handling by models [1]. The use of semantic markup schemes, as referenced in the context, also supports the identification and processing of MWEs, allowing for a more nuanced understanding of their meanings [3].

Secondly, discontiguity presents another challenge, where the constituents of an MWE are not always adjacent in the text (e.g., "turn the volume up"). This requires NLP systems to recognize and reconstruct the relationships between these separated components. MWE-aware parsing can utilize techniques such as shallow parsing, which breaks complex sentences into manageable parts, thereby facilitating the identification of MWEs even when their components are distributed across a sentence [4]. For example, the processes described by Zhang and El-Gohary (2019) in the context of parsing methods underscore the need for approaches that can handle discontiguous elements effectively while maintaining high parsing performance [3].

Moreover, MWE-aware parsing is particularly useful in fields rich in technical terminology, like building regulations, where the accurate extraction and understanding of MWEs are essential for compliance checking and alignment with standards [4]. By implementing MWE-aware methodologies, these systems can more reliably capture the specialized language and references that are common in such domains, thus enhancing performance in applications such as information extraction and compliance checking.

Additionally, the importance of MWEs in translation and other applications highlights the necessity for frameworks that can accurately render these expressions. The unrecognized MWEs may lead to erroneous translations and affect the quality of text summaries or search results [5]. Consequently, by focusing on the inherent complexity and unique nature of MWEs, MWE-aware parsing ensures that systems are better equipped to handle the non-compositional and discontiguous challenges, leading to improved processing outcomes.

In summary, MWE-aware parsing effectively tackles the non-compositionality and discontiguity challenges in MWEs by employing specialized recognition strategies, semantic markup, and tailored parsing techniques to ensure that the meanings and relationships of MWEs are accurately captured and processed within NLP applications [2][3][5].

1. [1]:  https://ar5iv.org/html/2109.04413, No Title
2. [2]:  https://ar5iv.org/html/2401.15393, No Title
3. [3]:  https://ar5iv.org/html/2110.01295, No Title
4. [4]:  https://ar5iv.org/html/2110.01295, No Title
5. [5]:  https://ar5iv.org/html/2209.08016, No Title
---
1. [1]:  Passage ID 1: consisting of the novel MWE dataset and the two associated tasks in Section 3. We discuss our experiments and results for these two tasks in Section 4, before presenting a discussion of the more interesting elements of our findings in Section 5. We present our conclusions and possible avenues of future work in Section 6.2 Related workThe problems posed by MWEs to NLP models have been known for some time Sag et al. (2002); Constant et al. (2017); Shwartz and Dagan (2019). For instance, Sag et al. (2002) refer to the idiomaticity problem and place the need for effective processing of MWEs on par with that for word sense disambiguation to be able to effectively process text. While their analysis focused on symbolicmethods, this problem still persists:Shwartz and Dagan (2019) showed, using six tasks, that contextual pre-trained language models, capable of handling polysemy, continued to be unable to effectively handle idiomatic MWEs, although they tend to do better than their
2. [2]:  Passage ID 2: are ubiquitous, affect various applications, and as such have been extensively addressed in NLP research (Sag et al., 2002; Baldwin and Kim, 2010).Although the widely used transformer-based language models have been analyzed regarding their ability to represent various types of linguistic knowledge, we still lack consolidated insights into their processing of MWE semantics.The present survey provides a critical overview of existing work on this issue.By definition, the meaning of a MWE is distributed over multiple constituents.111This also applies to closed compounds realized as a single orthographic unit (e.g. flashback) which comprises clearly identifiable constituents (flash and back).In some cases, these can be separated by intervening material (e.g. turn the volume up).For any model, it is more challenging to capture the meaning of multiple lexical elements than that of a single word.The overall meaning may further be compositional to various degrees, i.e. similar to the
3. [3]:  Passage ID 3: complex sentences into parts that are easier to process Zhang and El-Gohary (2019), and (2) more-or-less idiosyncratic semantic markup schemes that help identify requirements and their components in text, e.g., Hjelseth and Nisbet (2011) and Zhang and El-Gohary (2016b). Efforts to automate such shallow parsing approaches encountered performance issues when handling \MWEs Zhang and El-Gohary (2019); Zhang and Nora (2020).Although the proper handling of \MWEs is a key issue in \NLPSiskind (1996); Sag et al. (2002); Ramisch et al. (2018), extracting \MWEs is especially relevant to \IEin domains rich in technical terms Baldwin and Kim (2010) – such as the building regulations. Processing \MWEs is a general requirement for \ACC, because both single and multi-word concepts mentioned in regulations have to be aligned with components and values found in \BIM(\BIM) models. Such \BIMmodels rely on standards, such as the \IFC(\IFC) data model, to facilitate amongst others compliance checking
4. [4]:  Passage ID 4: complex sentences into parts that are easier to process Zhang and El-Gohary (2019), and (2) more-or-less idiosyncratic semantic markup schemes that help identify requirements and their components in text, e.g., Hjelseth and Nisbet (2011) and Zhang and El-Gohary (2016b). Efforts to automate such shallow parsing approaches encountered performance issues when handling \MWEs Zhang and El-Gohary (2019); Zhang and Nora (2020).Although the proper handling of \MWEs is a key issue in \NLPSiskind (1996); Sag et al. (2002); Ramisch et al. (2018), extracting \MWEs is especially relevant to \IEin domains rich in technical terms Baldwin and Kim (2010) – such as the building regulations. Processing \MWEs is a general requirement for \ACC, because both single and multi-word concepts mentioned in regulations have to be aligned with components and values found in \BIM(\BIM) models. Such \BIMmodels rely on standards, such as the \IFC(\IFC) data model, to facilitate amongst others compliance checking
5. [5]:  Passage ID 5: be done before one can claim that NLP and Machine Translation (MT) systems process MWEs successfully [12].The study of multiword expressions in NLP has been gaining prominence, and in recent years the number of researchers and projects focusing on them has increased dramatically. The successful computational treatment of MWEs is essential for NLP, including MT and Translation Technology. The inability to detect MWEs automatically may result in incorrect (and even unfortunate) automatic translations and may jeopardise the performance of applications such as text summarisation and web search.Multiword expressions do not only play a crucial role in the computational treatment of natural languages. Often terms are multiword expressions (and not single words), making them highly relevant to terminology. The requirement for correct rendering of MWEs in translation and interpretation highlights their importance in these fields. Given the pervasive nature of MWEs, they play a crucial