# Multiword Expression Processing: A Survey under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license Computational Linguistics

## Question

How does MWE-aware parsing effectively tackle the challenges posed by non-compositionality and discontiguity in multiword expressions?

## URLs

1. https://ar5iv.org/html/2303.06623. [2303.06623] MWE as WSD: Solving Multiword Expression Identification with Word Sense Disambiguation
2. https://ar5iv.org/html/1805.08438. [1805.08438] Paracompositionality, MWEs and Argument Substitution
3. https://ar5iv.org/html/1510.07193. [1510.07193] Statistical Parsing by Machine Learning from a Classical Arabic Treebank

## Answer (I don't know?: ✓)

I don't know. 

The context provided does not specifically address how MWE-aware parsing effectively tackles the challenges of non-compositionality and discontiguity in multiword expressions (MWEs). While it discusses various aspects of MWEs, such as their significance in natural language processing (NLP), the problems they pose to NLP models, and some methods of identifying MWEs, the details on how parsing mechanisms specifically address issues related to non-compositionality and discontiguity are not included. Additionally, the passages mention various approaches and models in the literature, but they do not elaborate on the mechanisms employed in MWE-aware parsing to tackle these specific challenges.

1. [1]:  https://ar5iv.org/html/2109.04413, No Title
2. [2]:  https://ar5iv.org/html/2110.01295, No Title
3. [3]:  https://ar5iv.org/html/2209.08016, No Title
4. [4]:  https://ar5iv.org/html/2208.07832, No Title
5. [5]:  https://ar5iv.org/html/2208.07832, No Title
---
1. [1]:  Passage ID 1: consisting of the novel MWE dataset and the two associated tasks in Section 3. We discuss our experiments and results for these two tasks in Section 4, before presenting a discussion of the more interesting elements of our findings in Section 5. We present our conclusions and possible avenues of future work in Section 6.2 Related workThe problems posed by MWEs to NLP models have been known for some time Sag et al. (2002); Constant et al. (2017); Shwartz and Dagan (2019). For instance, Sag et al. (2002) refer to the idiomaticity problem and place the need for effective processing of MWEs on par with that for word sense disambiguation to be able to effectively process text. While their analysis focused on symbolicmethods, this problem still persists:Shwartz and Dagan (2019) showed, using six tasks, that contextual pre-trained language models, capable of handling polysemy, continued to be unable to effectively handle idiomatic MWEs, although they tend to do better than their
2. [2]:  Passage ID 2: complex sentences into parts that are easier to process Zhang and El-Gohary (2019), and (2) more-or-less idiosyncratic semantic markup schemes that help identify requirements and their components in text, e.g., Hjelseth and Nisbet (2011) and Zhang and El-Gohary (2016b). Efforts to automate such shallow parsing approaches encountered performance issues when handling \MWEs Zhang and El-Gohary (2019); Zhang and Nora (2020).Although the proper handling of \MWEs is a key issue in \NLPSiskind (1996); Sag et al. (2002); Ramisch et al. (2018), extracting \MWEs is especially relevant to \IEin domains rich in technical terms Baldwin and Kim (2010) – such as the building regulations. Processing \MWEs is a general requirement for \ACC, because both single and multi-word concepts mentioned in regulations have to be aligned with components and values found in \BIM(\BIM) models. Such \BIMmodels rely on standards, such as the \IFC(\IFC) data model, to facilitate amongst others compliance checking
3. [3]:  Passage ID 3: be done before one can claim that NLP and Machine Translation (MT) systems process MWEs successfully [12].The study of multiword expressions in NLP has been gaining prominence, and in recent years the number of researchers and projects focusing on them has increased dramatically. The successful computational treatment of MWEs is essential for NLP, including MT and Translation Technology. The inability to detect MWEs automatically may result in incorrect (and even unfortunate) automatic translations and may jeopardise the performance of applications such as text summarisation and web search.Multiword expressions do not only play a crucial role in the computational treatment of natural languages. Often terms are multiword expressions (and not single words), making them highly relevant to terminology. The requirement for correct rendering of MWEs in translation and interpretation highlights their importance in these fields. Given the pervasive nature of MWEs, they play a crucial
4. [4]:  Passage ID 4: (MT) [17, 16], which depends on a clear distinction between word tokens and phrases, has to be re-thought to accommodate MWEs [8, 29]. The usual approach in these applications is to identify MWEs first, and then treat them accordingly. Therefore, detecting MWEs is a key research area in NLP.In recent years, the identification of MWEs has been modelled as a supervised machine learning task where the machine learning models are trained on an annotated dataset. As we explain in Section 2, several datasets have been released to train these machine learning models. Furthermore shared tasks such as SemEval-2016 Task 10 [28] and PARSEME [27] have contributed to develop datasets. In recent years, neural network-based models, and in particular architectures incorporating RecurrentNeural Networks (RNNs) such as Long Short Term Memory (LSTM) and Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance in MWE identification tasks [27]. Usually, these models utilise
5. [5]:  Passage ID 5: (MT) [17, 16], which depends on a clear distinction between word tokens and phrases, has to be re-thought to accommodate MWEs [8, 29]. The usual approach in these applications is to identify MWEs first, and then treat them accordingly. Therefore, detecting MWEs is a key research area in NLP.In recent years, the identification of MWEs has been modelled as a supervised machine learning task where the machine learning models are trained on an annotated dataset. As we explain in Section 2, several datasets have been released to train these machine learning models. Furthermore shared tasks such as SemEval-2016 Task 10 [28] and PARSEME [27] have contributed to develop datasets. In recent years, neural network-based models, and in particular architectures incorporating RecurrentNeural Networks (RNNs) such as Long Short Term Memory (LSTM) and Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance in MWE identification tasks [27]. Usually, these models utilise