# Conversational Machine Comprehension: a Literature Review

## Question

What are the components and functions of a typical Conversational Machine Comprehension (CMC) model?

## URLs

1. https://ar5iv.org/html/2104.10810. [2104.10810] A Short Survey of Pre-trained Language Models for Conversational AI-A New Age in NLP
2. https://ar5iv.org/html/2104.11394. [2104.11394] BERT-CoQAC: BERT-based Conversational Question Answering in Context
3. https://ar5iv.org/html/2006.00671. [2006.00671] Conversational Machine Comprehension: a Literature Review
4. https://ar5iv.org/html/2201.05176. [2201.05176] Neural Approaches to Conversational Information Retrieval
5. https://ar5iv.org/html/2405.12801. [2405.12801] Comparing Neighbors Together Makes it Easy: Jointly Comparing Multiple Candidates for Efficient and Effective Retrieval
6. https://ar5iv.org/html/2409.18996. [2409.18996] From Linguistic Giants to Sensory Maestros: A Survey on Cross-Modal Reasoning with Large Language Models
7. https://ar5iv.org/html/2305.11897. [2305.11897] Critical Appraisal of Artificial Intelligence-Mediated Communication
8. https://ar5iv.org/html/2303.00164. [2303.00164] A Mixed-Methods Approach to Understanding User Trust after Voice Assistant Failures

## Answer (I don't know?: ✗)

I don’t know. The context provided does not contain specific information about the components and functions of a typical Conversational Machine Comprehension (CMC) model. It discusses the advancements in natural language processing (NLP) and the emergence of multimodal language models (MLLMs), highlighting their capabilities such as reasoning across different modalities and integrating visual and textual information [1][4]. However, it does not explicitly define or detail the architecture, components, or functions specific to CMC models. Without this crucial information, I cannot provide a complete and precise answer.

1. [1]:  https://ar5iv.org/html/2411.06284, No Title
2. [2]:  https://ar5iv.org/html/2411.06284, No Title
3. [3]:  https://ar5iv.org/html/2104.10810, [2104.10810] A Short Survey of Pre-trained Language Models for Conversational AI-A New Age in NLP
4. [4]:  https://ar5iv.org/html/2411.06284, No Title
5. [5]:  https://ar5iv.org/html/2411.06284, No Title
---
1. [1]:  Passage ID 1: virtual assistant could understand and respond to a user’s mood based on their tone of voice, facial expression, and choice of words, much like a human would.2 The Convergence of Natural Language Processing (NLP) and Computer Vision: The Emergence of MLLMsThe fusion of natural language processing (NLP) and computer vision has been a game-changer in AI, giving rise to MLLMs. This convergence allows machines to reason across different modalities, offering a more comprehensive understanding of the world.Key Historical Milestones:•Image Captioning (2015-Present): Early models like Show, Attend, and Tell combined Convolutional Neural Networks (CNNs) for image analysis with Recurrent Neural Networks (RNNs) for text generation. This marked the beginning of machines being able to ”describe” what they ”see”.•Visual Question Answering (VQA): These tasks required models to combine visual and textual inputs to generate meaningful answers. For example, a model might be asked,
2. [2]:  Passage ID 2: virtual assistant could understand and respond to a user’s mood based on their tone of voice, facial expression, and choice of words, much like a human would.2 The Convergence of Natural Language Processing (NLP) and Computer Vision: The Emergence of MLLMsThe fusion of natural language processing (NLP) and computer vision has been a game-changer in AI, giving rise to MLLMs. This convergence allows machines to reason across different modalities, offering a more comprehensive understanding of the world.Key Historical Milestones:•Image Captioning (2015-Present): Early models like Show, Attend, and Tell combined Convolutional Neural Networks (CNNs) for image analysis with Recurrent Neural Networks (RNNs) for text generation. This marked the beginning of machines being able to ”describe” what they ”see”.•Visual Question Answering (VQA): These tasks required models to combine visual and textual inputs to generate meaningful answers. For example, a model might be asked,
3. [3]:  Passage ID 3: processing††ccs: Computing methodologies Intelligent agents††ccs: Computing methodologies Neural networks1. IntroductionDespite much progress in the field of natural language processing and intelligent agents, the conversational part for communication between a human and a machine is still in its inception phase. It is only recently that neural generative models had gotten the attention of researchers and improved the field of conversational AI drastically. With a large amount of available ‘big data’ and advanced deep learning methods, the objective of designing digital conversation systems as our virtual assistant is no longer a dream.Based on functionality, conversational AI can be categorized into three categories: 1) task-oriented systems, 2) chat-oriented systems, and 3) question answering systems (Gaoet al., 2018). Task-oriented dialogue systems are designed to complete a specific task on the user’s behalf such as booking hotels, making a restaurant reservation or
4. [4]:  Passage ID 4: answering.The integration of multimodal data has opened up new possibilities for AI applications. MLLMs can generate detailed descriptions of images, providing valuable assistance in fields like accessibility and content creation. These models can answer questions about images, demonstrating their ability to understand and reason about visual content. MLLMs also enable the creation of rich multimedia content, combining text, images, and audio to produce engaging and informative outputs.The field of NLP has undergone significant transformations over the past few decades, driven by advancements in computational power, the availability of large-scale datasets, and breakthroughs in machine learning algorithms. This journey can be broadly categorized into several key phases:1.Rule-based systems (1950s-1980s): Early NLP approaches relied heavily on hand-crafted rules and linguistic knowledge bases. While these systems could perform well in narrow domains, they struggled with the
5. [5]:  Passage ID 5: answering.The integration of multimodal data has opened up new possibilities for AI applications. MLLMs can generate detailed descriptions of images, providing valuable assistance in fields like accessibility and content creation. These models can answer questions about images, demonstrating their ability to understand and reason about visual content. MLLMs also enable the creation of rich multimedia content, combining text, images, and audio to produce engaging and informative outputs.The field of NLP has undergone significant transformations over the past few decades, driven by advancements in computational power, the availability of large-scale datasets, and breakthroughs in machine learning algorithms. This journey can be broadly categorized into several key phases:1.Rule-based systems (1950s-1980s): Early NLP approaches relied heavily on hand-crafted rules and linguistic knowledge bases. While these systems could perform well in narrow domains, they struggled with the