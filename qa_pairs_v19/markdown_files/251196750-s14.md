# "Do you follow me?": A Survey of Recent Approaches in Dialogue State Tracking

## Question

How are recent approaches tackling the performance drop in Dialogue State Tracking (DST) models caused by input variations?

## URLs

1. https://ar5iv.org/html/2211.05503. [2211.05503] MoNET: Tackle State Momentum via Noise-Enhanced Training for Dialogue State Tracking
2. https://ar5iv.org/html/2311.06345. [2311.06345] Schema Graph-Guided Prompt for Multi-Domain Dialogue State Tracking
3. https://ar5iv.org/html/2310.14970. [2310.14970] Towards LLM-driven Dialogue State Tracking
4. https://ar5iv.org/html/2407.21633. [2407.21633] Zero-Shot Cross-Domain Dialogue State Tracking via Dual Low-Rank Adaptation
5. https://ar5iv.org/html/2101.09374. [2101.09374] Slot Self-Attentive Dialogue State Tracking
6. https://ar5iv.org/html/2308.15053. [2308.15053] Adapting Text-based Dialogue State Tracker for Spoken Dialogues
7. https://ar5iv.org/html/2404.08559. [2404.08559] MoPE: Mixture of Prefix Experts for Zero-Shot Dialogue State Tracking
8. https://ar5iv.org/html/2405.13003. [2405.13003] A Survey on Recent Advances in Conversational Data Generation
9. https://ar5iv.org/html/1907.03040. [1907.03040] BERT-DST: Scalable End-to-End Dialogue State Tracking with Bidirectional Encoder Representations from Transformer

## Answer (I don't know?: ‚úó)

Recent approaches to tackling the performance drop in Dialogue State Tracking (DST) models caused by input variations primarily focus on enhancing the models' flexibility, robustness, and their ability to handle long dialogues effectively. These efforts are pivotal because traditional DST systems tend to struggle when faced with varying input forms, particularly as dialogue lengths increase.

One prominent technique is the use of improved error correction strategies that address the issue of error propagation in dialogues. For instance, Tian et al. (2021a) propose a two-pass dialogue state generation method that allows the system to correct potential errors made in earlier dialogue turns, thereby enhancing accuracy across the conversation [4]. Additionally, alternative strategies such as turn-based objective functions, as suggested by Manotumruksa et al. (2021), penalize incorrect predictions made in earlier turns to mitigate the impact of early missteps on the overall dialogue state tracking performance [4].

Furthermore, there has been a call for the development of more robust downstream policies, which enhance the resilience of DST systems to input variations by ensuring they can adjust to changes in user intent and goals effectively [3]. Recent studies highlight the need for models capable of efficiently processing lengthy dialogues since performance tends to degrade rapidly as dialogue length increases. This aspect is crucial, as lengthy exchanges often lead to more complex variations in the input, necessitating models that can retain contextual information over extended interactions [4].

Another approach is the incorporation of in-context tuning mechanisms that leverage examples to fine-tune language models (LMs) for specific tasks such as DST. Studies by Gururangan et al. (2020) and Liu et al. (2022) demonstrate that fine-tuning with examples, as opposed to relying solely on in-context learning (ICL), can significantly improve model performance across various language tasks, including DST. This process helps the models to adapt better to variations in user inputs by learning from real examples, thus equipping them with a broader understanding of potential dialogue states [5].

Additionally, diverse input incorporation is being actively explored. Some recent studies posit that adding task descriptions related to dialogue system slots or slot value examples as input data can help models navigate variations more effectively by providing explicit contextual information [2]. This strategy equips DST systems with better reference points amid different user utterances.

In conclusion, addressing the performance challenges in DST models due to input variations involves a blend of error correction techniques, robust policy development, fine-tuning with example-based learning, and the inclusion of descriptive task-related input. These advancements are in response to the critical need for flexible and efficient dialogue handling, ultimately improving user interaction experiences [3] [4].

1. [1]:  https://ar5iv.org/html/2311.15623, No Title
2. [2]:  https://ar5iv.org/html/2308.15053, [2308.15053] Adapting Text-based Dialogue State Tracker for Spoken Dialogues
3. [3]:  https://ar5iv.org/html/2207.14627, No Title
4. [4]:  https://ar5iv.org/html/2207.14627, No Title
5. [5]:  https://ar5iv.org/html/2212.02851, No Title
---
1. [1]:  Passage ID 1: studies, for simplicity, often avoided using external contextual knowledge, instead, relying on transformations of latent representations in PLMs as sources of contextual knowledge. Although these latent representations are context-aware, they remain susceptible to interpretability issues. Some solutions, such as using a specialized neural component to extract contextualized word representations Peters et¬†al. (2018) Liu et¬†al. (2019), require additional fine-tuning.In contrast, our approach employs a computationally efficient algorithm to capture semantic patterns in the entire training corpus and generates features that guide attention to semantically important tokens in the input sequence. This process and the resulting features can be easily analyzed and understood.3 Model3.1 Task: Dialogue State TrackingDialogue State Tracking (DST) involves receiving the dialogue history, the current dialogue turn, and dialogue state history as inputs and yields the updated dialogue
2. [2]:  Passage ID 2: We show that post-processing can mitigate errors in words such as proper nouns. (3) We successfully construct a dialogue system that performs well with spoken utterance input.2 Related Work2.1 Dialogue State TrackingDialogue state tracking (DST) is one of the components of a task-oriented dialogue system that maps partial dialogues to the dialogue state. It usually extracts the user‚Äôs goal and intent in the form of a slot-value pair through the user and system dialogue conversation.As an example in Table¬†1, the DST task is to extract dialogue states such as the value of guesthouse in the slot of hotel-type and the value of bangkok city in the slot of restaurant-name from user‚Äôs utterance. There are several methods have recently attracted attention in DST tasks.Dialogue Systems with Description Input Some works have been proposed which include task descriptions as input, where the descriptions related to the dialog system slot or slot value examples are added as input data
3. [3]:  Passage ID 3: to a more robust downstream policy van Niekerk et¬†al. (2021).These studies are rare in their kind and call for more similar work.5 ConclusionDialogue state tracking is a crucial component of a conversational agent to identify the user‚Äôs needs at each turn of the conversation.A growing body of work is addressing this task and we have outlined the latest developments.After giving an overview of the task and the different datasets available, we have categorized modern neural approaches according to the inference of the dialogue state.Despite encouraging results on benchmarks such as MultiWOZ, these systems lack flexibility and robustness, which are critical skills for a dialogue system.In recent years, many works have sought to address these limitations and we have summarized the advances.However, there are still significant challenges to be addressed in the future.There are many interesting avenues and we have proposed three key features of DST models to guide future
4. [4]:  Passage ID 4: through regularization techniques Heck et¬†al. (2022).Related to this, an understudied aspect is dealing with utterances that deviate from the norm in the case of a written dialogue system.A DST model must be able to take into account all the history and adjust its predictionsof the dialogue state using all available information.Many works have found that performance degrades rapidly as the dialogue length increases. Another critical aspect is therefore efficiently processing long dialogues Zhang et¬†al. (2021).The dialogue state condenses important information, but correcting an error made in an earlier turn may be difficult. To overcome this error propagation issue, Tian et¬†al. (2021a) use a two-pass dialogue state generation to correct potential errors, whileManotumruksa et¬†al. (2021) propose a turn-based objective function to penalize the model for incorrect prediction in early turns.Despite this need, Jakobovits et¬†al. (2022) have shown that popular DST datasets are not
5. [5]:  Passage ID 5: schema.Recent efforts have shown that the shortcomings of ICL (Liu et¬†al., 2022; Min et¬†al., 2022) can be overcome through in-context tuning of LMs.Gururangan et¬†al. (2020) and Liu et¬†al. (2022) demonstrate the improved performance of models fine-tuned with examples compared to ICL over a variety of language tasks. In this work, we leverage this concept specifically for DST.3 ApproachWe first present the background and some definitions for dialogue state tracking before describing our approach.3.1 DST BackgroundA task-oriented dialogue consists of a multi-turn conversation between a user UùëàU and the system Aùê¥A. Given a dialogue context Ctsubscriptùê∂ùë°C_{t} as the sequence of utterances until turn tùë°t, (i.e.) Ct=[A1,U1,‚Ä¶,At,Ut]subscriptùê∂ùë°subscriptùê¥1subscriptùëà1‚Ä¶subscriptùê¥ùë°subscriptùëàùë°C_{t}=[A_{1},U_{1},...,A_{t},U_{t}], the goal of DST is to predict the dialogue state ytsubscriptùë¶ùë°y_{t}, defined as a set of (slot, value)