# "Do you follow me?": A Survey of Recent Approaches in Dialogue State Tracking

## Question

How are recent approaches tackling the performance drop in Dialogue State Tracking (DST) models caused by input variations?

## URLs

1. https://ar5iv.org/html/2211.05503. [2211.05503] MoNET: Tackle State Momentum via Noise-Enhanced Training for Dialogue State Tracking
2. https://ar5iv.org/html/2311.06345. [2311.06345] Schema Graph-Guided Prompt for Multi-Domain Dialogue State Tracking
3. https://ar5iv.org/html/2310.14970. [2310.14970] Towards LLM-driven Dialogue State Tracking
4. https://ar5iv.org/html/2407.21633. [2407.21633] Zero-Shot Cross-Domain Dialogue State Tracking via Dual Low-Rank Adaptation
5. https://ar5iv.org/html/2101.09374. [2101.09374] Slot Self-Attentive Dialogue State Tracking
6. https://ar5iv.org/html/2308.15053. [2308.15053] Adapting Text-based Dialogue State Tracker for Spoken Dialogues
7. https://ar5iv.org/html/2404.08559. [2404.08559] MoPE: Mixture of Prefix Experts for Zero-Shot Dialogue State Tracking
8. https://ar5iv.org/html/2405.13003. [2405.13003] A Survey on Recent Advances in Conversational Data Generation
9. https://ar5iv.org/html/1907.03040. [1907.03040] BERT-DST: Scalable End-to-End Dialogue State Tracking with Bidirectional Encoder Representations from Transformer

## Answer (I don't know?: ✗)

Recent approaches addressing the performance drop in Dialogue State Tracking (DST) models due to input variations have focused on integrating sophisticated methods and leveraging pre-trained language models to enhance model resilience and accuracy. Key strategies are highlighted in the context of evolving methodologies for DST tasks.

One significant issue encountered by traditional DST models is that they often struggle with "state momentum," wherein previously predicted slot values tend to remain static during state updates. This phenomenon can lead to performance degradation, especially when user intent changes and corrections are necessary for wrongly predicted slot values [5]. To combat this, various recent methods have incorporated the previously predicted state alongside current dialogue history to maintain awareness of potential variations and improve the dynamism of slot-value prediction [5].

Furthermore, innovative approaches have emerged by reframing DST as related tasks that capitalize on more advanced language processing capabilities. For instance, Gao et al. (2019) restructured DST as a reading comprehension task, prompting models to infer the dialogue state from the context more robustly. Meanwhile, Shin et al. (2022) contextualized DST as dialogue summarization, allowing a model to recover the dialogue state through predefined rules after generating summaries [2]. These methodologies enhance the model's ability to adjust to shifts in dialogue patterns and comprehend user intent more effectively.

The introduction of large language models, such as Codex-Davinci-002 and ChatGPT, also importantly contributes to addressing performance drops in DST. These models can encapsulate complex linguistic patterns and dependencies within multi-turn conversations, thus demonstrating resilience to error propagation that often affects performance as dialogue progresses [3]. Notably, the LDST model exemplified in the context shows slower declines in performance compared to standard models during multiple dialogue turns, signifying its robustness [3].

Moreover, studies focusing on multi-domain dialogue state tracking have acknowledged the efficacy of pre-trained language models in improving performance across varied domains. This emphasis on utilizing rich representations from these models allows DST systems to become more adaptable to dynamic and contextually diverse dialogues, effectively mitigating performance drops linked to input variations [4].

In conclusion, recent approaches to DST are increasingly characterized by a blend of innovative problem framing, integration of advanced language models, and strategic use of historical dialogue state information. These methods aim to create a more responsive and accurate dialogue system that can cope with the complexities and variations inherent in natural language conversations.

1. [1]:  https://ar5iv.org/html/2308.15053, [2308.15053] Adapting Text-based Dialogue State Tracker for Spoken Dialogues
2. [2]:  https://ar5iv.org/html/2404.08559, [2404.08559] MoPE: Mixture of Prefix Experts for Zero-Shot Dialogue State Tracking
3. [3]:  https://ar5iv.org/html/2310.14970, [2310.14970] Towards LLM-driven Dialogue State Tracking
4. [4]:  https://ar5iv.org/html/1907.03040, [1907.03040] BERT-DST: Scalable End-to-End Dialogue State Tracking with Bidirectional Encoder Representations from Transformer
5. [5]:  https://ar5iv.org/html/2211.05503, [2211.05503] MoNET: Tackle State Momentum via Noise-Enhanced Training for Dialogue State Tracking
---
1. [1]:  Passage ID 1: We show that post-processing can mitigate errors in words such as proper nouns. (3) We successfully construct a dialogue system that performs well with spoken utterance input.2 Related Work2.1 Dialogue State TrackingDialogue state tracking (DST) is one of the components of a task-oriented dialogue system that maps partial dialogues to the dialogue state. It usually extracts the user’s goal and intent in the form of a slot-value pair through the user and system dialogue conversation.As an example in Table 1, the DST task is to extract dialogue states such as the value of guesthouse in the slot of hotel-type and the value of bangkok city in the slot of restaurant-name from user’s utterance. There are several methods have recently attracted attention in DST tasks.Dialogue Systems with Description Input Some works have been proposed which include task descriptions as input, where the descriptions related to the dialog system slot or slot value examples are added as input data
2. [2]:  Passage ID 2: approach.With the widespread adoption of large language models, Hu et al. (2022) and Heck et al. (2023) have turned to powerful language models like Codex-Davinci-002 and ChatGPT to tackle the DST challenge.However, these models have enormous parameters, making both training and inference processes difficult and costly.Simultaneously, the approaches to solving the DST problem have become increasingly diverse.Gao et al. (2019) reformulated DST as a reading comprehension task by answering the question: “What is the state of the current dialogue?"Shin et al. (2022) framed DST as a dialogue summarization problem.They trained a text-to-text template-based dialogue summary language model and recovered the dialogue state from the summarization using predefined rules.Hu et al. (2022) utilized a code-based large language model, formulating DST as a text-to-SQL problem, where the dialogue state is generated as an SQL query.Parameter Efficient Transfer Learning for DSTPETL for DST
3. [3]:  Passage ID 3: we visualize the JGA score for each dialogue turn in Figure 6 to demonstrate the effectiveness in addressing error propagation.The result clearly shows that as the number of dialogue turns increases, the performance of all methods experiences a decline. However, our LDST model demonstrates a remarkable resilience to error propagation, showcasing a significantly slower decline compared to LLaMa and the best baseline method. These results emphasize the LDST model’s capacity to capture and comprehend complex linguistic patterns and dependencies in multi-round conversations, making it a promising solution to mitigate the challenges associated with the DST task.5 Related Work5.1 Multi-Domain Dialogue State TrackingRecent studies in multi-domain DST have extensively utilized the pre-trained language models to achieve high-performance results Ravuru et al. (2022); Yu et al. (2022); Sun et al. (2022); Feng et al. (2021); Wang et al. (2022b); Xu et al. (2023c).For example, Xie
4. [4]:  Passage ID 4: state tracking, belief tracking, task-oriented dialogue systems, BERT1 IntroductionDialogue state tracking (DST), a core component in today’s task-oriented dialogue systems, maintains user’s intentional states through the course of a dialogue. The dialogue states predicted by DST are used by the downstream dialogue management component to produce API calls to a backend database and generate responses to the user  [1]. A dialogue state is often expressed as a collection of slot-value pairs.The set of slots and their possible values are often domain-specific, defined in a domain ontology.Many state-of-the-art approaches operate on a fixed ontology, by performing classification over a predefined set of slot values or iteratively scoring slot-value pairs from the ontology  [2, 3, 4]. However, such models can be inefficient or infeasible when the ontology is dynamic (e.g., movie, restaurant), innumerable (e.g., time), or simply not exposed by an external database [5, 6].In this
5. [5]:  Passage ID 5: 2007; Thomson and Young, 2010; Young et al., 2010).Earlier DST approaches predict the state directly from the dialogue history (natural language utterances) (Mrkšić et al., 2017; Xu and Hu, 2018; Wu et al., 2019; Chen et al., 2020a).Since the dialogue state is condensed structural information memorizing all dialogue history, recent methods incorporate the previously predicted state as the input besides the dialogue history(Ouyang et al., 2020; Kim et al., 2020; Ye et al., 2021).Conventional DST models taking the previous state as the input usually show the characteristic that the previously predicted slot values tend to be kept unchanged when predicting the current state, defined as state momentum in this paper.The state momentum makes DST models struggle to modify the previous prediction, which affects the performance when the values of some slots need to be updated as the user’s intent changes, and there exist wrongly predicted slot values that need to be corrected.Figure 1