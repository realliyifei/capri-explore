# Let's Negotiate! A Survey of Negotiation Dialogue Systems

## Question

How is supervised learning utilized in negotiation dialogue systems to predict strategies and generate responses?

## URLs

1. https://ar5iv.org/html/2212.09072. [2212.09072] Let’s Negotiate! A Survey of Negotiation Dialogue Systems
2. https://ar5iv.org/html/2402.01097. [2402.01097] Let’s Negotiate! A Survey of Negotiation Dialogue Systems
3. https://ar5iv.org/html/2305.13626. [2305.13626] Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration
4. https://ar5iv.org/html/1808.09637. [1808.09637] Decoupling Strategy and Generation in Negotiation Dialogues
5. https://ar5iv.org/html/2410.01555. [2410.01555] ACE: A LLM-based Negotiation Coaching System
6. https://ar5iv.org/html/2402.13550. [2402.13550] Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues
7. https://ar5iv.org/html/2311.00262. [2311.00262] Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents

## Answer (I don't know?: ✗)

Supervised learning plays a significant role in negotiation dialogue systems, particularly in predicting negotiation strategies and generating appropriate responses. It focuses on mimicking human behavior by using historical negotiation data to train models. One prominent approach involves adopting a sequence-to-sequence (Seq2Seq) model to determine the necessary actions by maximizing the likelihood of the training data based on past interactions, thus assisting in decision-making during negotiations [4]. 

He et al. (2018) further refine this approach by advocating for fine-tuning supervised models to optimize specific dialogue reward functions, which include: the utility function for the final price from both buyer and seller perspectives, the differences in utilities between the two agents, and the total number of utterances exchanged during the dialogue [1][4]. This is crucial as it allows models not just to mimic behavior but to actively engage in strategic decision-making aligning with a defined objective.

Zhou et al. (2020) introduce an additional layer to this by training a strategy predictor to ascertain whether a specific negotiation strategy is likely to occur in the forthcoming utterance using supervised training. Consequently, this enables the system to generate responses that are conditioned on the user’s utterance, the dialogue context, and the predicted negotiation strategy [1][4]. This methodology effectively intertwines negotiation strategy prediction with the generation of natural language responses, allowing for more nuanced interactions that consider both the context and strategic objectives.

Moreover, integrating supervised learning with neural network models has become increasingly prevalent. Recent advancements in using end-to-end neural models support the simultaneous learning of dialogue strategies and language realization from human-human dialogues. This reflects a shift toward enhancing both goal-oriented and open-domain dialogues, as observed in various studies [2][3]. However, challenges remain, such as difficulties in controlling and interpreting these strategies, as well as issues related to optimizing agent goals that may sometimes lead to suboptimal solutions in the context of reinforcement learning [2].

In summary, supervised learning in negotiation dialogue systems is utilized to model human-like behavior, predict strategies effectively, and generate coherent and contextually appropriate responses. The methods employed by researchers leverage these algorithms to enhance the negotiation capabilities of agents, thus aiming to create more interactive and beneficial outcomes for users engaged in negotiations [3][4].

1. [1]:  https://ar5iv.org/html/2212.09072, [2212.09072] Let’s Negotiate! A Survey of Negotiation Dialogue Systems
2. [2]:  https://ar5iv.org/html/1808.09637, [1808.09637] Decoupling Strategy and Generation in Negotiation Dialogues
3. [3]:  https://ar5iv.org/html/2410.01555, [2410.01555] ACE: A LLM-based Negotiation Coaching System
4. [4]:  https://ar5iv.org/html/2402.01097, [2402.01097] Let’s Negotiate! A Survey of Negotiation Dialogue Systems
5. [5]:  https://ar5iv.org/html/2311.00262, [2311.00262] Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents
---
1. [1]:  Passage ID 1: of the training data. However, supervised learning only aims to mimic the average human behavior, so He et al. (2018) propose to finetune the supervised model to directly optimize for a particular dialogue reward function, which is defined as i) the utility function of the final price for the buyer and seller ii) the difference between two agents’ utilities iii) the number of utterances in the dialogue. Zhou et al. (2020) train a strategy predictor to predict whether a certain negotiation strategy occurred in the next utterance using supervised training. The system response would be generated conditioned on the user utterance, dialogue context, and the predicted negotiation strategy. In addition, Joshi et al. (2021) incorporate a pragmatic strategies graph network with the seq2seq model to create an interpretable policy learning paradigm. Recently, Dutt et al. (2021b) propose a generalisedframework for identifying resisting strategies in persuasive negotiations using a pre-trained
2. [2]:  Passage ID 2: of that strategy via generation of natural language (e.g.,“I really need a car so I can go to work, but all I have is 6000, any more and I won’t be able to feed my children.”).Most past work in NLP on negotiation focuses on strategy (dialogue management)with either no natural language Cuayáhuitl et al. (2015); Cao et al. (2018)or canned responses Keizer et al. (2017); Traum et al. (2008).Recently, end-to-end neural models Lewis et al. (2017); He et al. (2017) are used tosimultaneously learn dialogue strategy and language realizationfrom human-human dialogues,following the trend of using neural network models on bothgoal-oriented dialogue Wen et al. (2017a); Dhingra et al. (2017)and open-domain dialogue Sordoni et al. (2015); Li et al. (2017); Lowe et al. (2017).However, these models have two problems:(i) it is hard to control and interpret the strategies,and (ii) directly optimizing the agent’s goal through reinforcement learningoften leads to degenerate solutions
3. [3]:  Passage ID 3: judged as helpful by English languages learners and have also had a demonstrable effect on actual learning outcomes Liang et al. (2023).Prior work on developing systems for negotiation training has been fairly limited. These systems can only be interacted with by selecting from a list of pre-written options and deliver “canned” responses as a reply. Despite these limitations, prior work has shown that interacting with virtual agents can improve learners’ understanding of negotiations Gratch et al. (2016).2.2 NegotiationMethods that have applied LLMs to the area of negotiation have been focused on building negotiation chat agents. These methods typically use existing negotiation data to perform supervised learning or offline reinforcement learning on a negotiation model Lewis et al. (2017); He et al. (2018); Verma et al. (2022); Zhan et al. (2024). More recent work has focused on examining and enhancing the negotiation capabilities of prompt-based negotiation agents Schneider
4. [4]:  Passage ID 4: negotiation skills. It allows agents to leverage parameterized DQN to learn a comprehensive negotiation strategy that integrates linguistic communication skills and bidding strategies.3.4.2 Supervised LearningSupervised learning (SL) is another popular paradigm for policy learning. Lewis et al. (2017) adopt a Seq2Seq model to learn what action should be taken by maximizing the likelihood of the training data. However, supervised learning only aims to mimic the average human behavior, so He et al. (2018) propose to apply a supervised model to directly optimize a particular dialogue reward function, which is characterized by i) the utility function of the final price for the buyer and seller ii) the differences between two agents’ utilities iii) the number of utterances in the dialogue. Zhou et al. (2020) first train a strategy predictor to predict whether a certain negotiation strategy occurred in the next utterance using supervised training. Then, the response generation
5. [5]:  Passage ID 5: following their original designs, we adapt these systems into the applications studied in our experiments.Ask-an-Expert (Zhang et al., 2023a)  This method is originally proposed for emotional support dialogues, whose prompt is directly adopted in our experiments.In order to further accommodate the other two applications, we simply change the role in the pre-defined questions for asking the expert LLM, as shown in Table 19.Negotiation DialoguesSystemAssume you are the bargain expert to reach a better deal with the seller. Given the conversation history, answer the question. Please answer with only one short and succinct sentence.UserThe following is the conversation history: [conversation]Question: How did the seller feel? Answer:Assistant[answer1]UserThe following is the conversation history: [conversation]Question: Why did the seller feel that way? Answer:Assistant[answer2]UserThe following is the conversation