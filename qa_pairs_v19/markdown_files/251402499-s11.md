# Abstractive Meeting Summarization: A Survey

## Question

How do dialogue acts contribute to improving abstractive meeting summarization, especially in contexts involving decisions?

## URLs

1. https://ar5iv.org/html/2210.09894
2. https://ar5iv.org/html/2406.07494
3. https://ar5iv.org/html/2404.11124
4. https://ar5iv.org/html/2409.02413
5. https://ar5iv.org/html/2404.19007
6. https://ar5iv.org/html/2107.03175
7. https://ar5iv.org/html/2405.11055
8. https://ar5iv.org/html/1910.00825

## Answer

## I don't know?: False

Dialogue acts play a significant role in enhancing abstractive meeting summarization by providing essential information regarding the communicative intent behind utterances. This understanding of the structure and function of dialogue within meetings can be leveraged to create more coherent and contextually relevant summaries.

The concept of dialogue acts involves categorizing parts of conversation based on their intended function, such as whether they introduce, respond to, or acknowledge another utterance. In the context of meeting summarization, recognizing these acts can significantly facilitate the identification of key information that influences decision-making processes. For instance, Goo and Chen (2018) demonstrated how dialogue acts can be effectively utilized to improve the performance of abstractive meeting summarization models, indicating that systematically incorporating these structural representations leads to better modeling outcomes for the summarization tasks [2].

Moreover, the introduction of discourse structures can also enhance the extraction and synthesis of relevant information from meeting transcripts. Feng et al. (2020) showed that representing transcripts as discourse graphs, inspired by Segmented Discourse Representation Theory (SDRT), can improve abstractive summarization efficiency. This approach allows for a better understanding of how information flows during the meeting and highlights salient decisions or statements that should be captured in a summary [2].

Additionally, integrating auxiliary information, such as dialogue discourse and dialogue acts, helps to address challenges associated with interpreting the dynamics of extended meetings. Given that meetings may have numerous participants, each contributing various utterances that lead to important decisions, analyzing these dialogue acts becomes crucial to understand the conversational context. This understanding can prevent the loss of nuance in decision-making discussions, which is often the case when solely relying on literal interpretations of utterances.

In summary, dialogue acts enhance the quality and relevance of abstractive meeting summarization by offering insights into the communicative intentions behind interactions, which is critical in contexts where specific decisions are being analyzed. By implementing these insights into summarization models, researchers can significantly improve the coherence and utility of generated summaries, ensuring they accurately reflect the important decision-making processes occurring during meetings. The combined effects of using dialogue acts and discourse structures thus empower summarization techniques to handle the complexities inherent in capturing the essence of discussions in real-world settings [1] [2].

1. [1]:  https://ar5iv.org/html/2107.03175, [2107.03175] A Survey on Dialogue Summarization: Recent Advances and New Frontiers
2. [2]:  https://ar5iv.org/html/2405.11055, [2405.11055] Leveraging Discourse Structure for Extractive Meeting Summarization
3. [3]:  https://ar5iv.org/html/2406.07494, [2406.07494] CADS: A Systematic Literature Review on the Challenges of Abstractive Dialogue Summarization
4. [4]:  https://ar5iv.org/html/2406.07494, [2406.07494] CADS: A Systematic Literature Review on the Challenges of Abstractive Dialogue Summarization
5. [5]:  https://ar5iv.org/html/2405.11055, [2405.11055] Leveraging Discourse Structure for Extractive Meeting Summarization
---
1. [1]:  Passage ID 1: years witness a growing trend of abstractive meeting summarization methods Shang et al. (2018).With the development of neural networks, many works have explored the application of deep learning in meeting the summarization task and have achieved remarkable success Zhu et al. (2020).Although deep learning-based methods have strong modeling abilities, taking only literal information into consideration is not sufficient.This is because there are diverse interactive signals among meeting utterances and the long meeting transcripts further pose challenges to traditional sequence-to-sequence models.To this end, some works devote efforts to incorporate auxiliary information for better modeling meetings, such as dialogue discourse Feng et al. (2021b), dialogue acts Goo and Chen (2018) and domain terminologies Koay et al. (2020).Besides, several strategies are carefully devised to handle long meeting transcripts, including hierarchical modeling strategy Zhu et al. (2020), sliding window
2. [2]:  Passage ID 2: instance; that is, whether it serves to introduce or answer a question, to acknowledge another utterance or so on. In this vein, Feng et al. (2020) showed that representing the content of a meeting transcript as a discourse graph in the style of Segmented Discourse Representation Theory (SDRT; Asher, 1993; Lascarides and Asher, 2008) can improve performance on abstractive meeting summarization, while Goo and Chen (2018) demonstrated the value of dialogue acts (Jurafsky et al., 1997; Allen and Core, 1997) for the same task.Similarly, Liu et al. (2019) showed that supplementing transcripts with multi-modal information about participants’ head orientation and eye gaze can help to identify salient information in a meeting.In this paper, we exploit information on discourse structure to improve extractive summarization. While abstractive summarization is generally preferable for spontaneous conversation (Murray et al., 2010), focusing on extractive summarization is valuable for multiple
3. [3]:  Passage ID 3: we discuss the possible implications of the recently explored large language models and conclude that despite a potential shift in relevance and difficulty, our described challenge taxonomy remains relevant.1 IntroductionFigure 1: Overview of the big six challenges in dialogue summarization, a short description of the challenges, and the estimation of their progress derived from related sub-challenges. Green means mostly mitigated, orange means good progress, and red stands for marked challenges still exist.Abstractive dialogue summarization, a task within Natural Language Processing (NLP) and text summarization, entails condensing key information from conversations into succinct and coherent summaries (?).This sub-field of text summarization is gaining prominenceand is relevant for various real-world scenarios, including customer service (e.g., social media (?) and e-commerce (?)), healthcare (?), daily life (?), meetings (?), and open-domain conversations (e.g.,
4. [4]:  Passage ID 4: we discuss the possible implications of the recently explored large language models and conclude that despite a potential shift in relevance and difficulty, our described challenge taxonomy remains relevant.1 IntroductionFigure 1: Overview of the big six challenges in dialogue summarization, a short description of the challenges, and the estimation of their progress derived from related sub-challenges. Green means mostly mitigated, orange means good progress, and red stands for marked challenges still exist.Abstractive dialogue summarization, a task within Natural Language Processing (NLP) and text summarization, entails condensing key information from conversations into succinct and coherent summaries (?).This sub-field of text summarization is gaining prominenceand is relevant for various real-world scenarios, including customer service (e.g., social media (?) and e-commerce (?)), healthcare (?), daily life (?), meetings (?), and open-domain conversations (e.g.,
5. [5]:  Passage ID 5: Natural Language Processing, pages 8484–8495, Singapore. Association for Computational Linguistics.Feng et al. (2020)Xiachong Feng, Xiaocheng Feng, Bing Qin, and Xinwei Geng. 2020.Dialogue discourse-aware graph model and data augmentation for meeting summarization.In Proceeding of The 30th International Joint Conference on Artificial Intelligence.Goo and Chen (2018)Chih-Wen Goo and Yun-Nung Chen. 2018.Abstractive dialogue summarization with sentence-gated modeling optimized by dialogue acts.In 2018 IEEE Spoken Language Technology Workshop (SLT), pages 735–742. IEEE.Hu et al. (2023)Yebowen Hu, Timothy Ganter, Hanieh Deilamsalehy, Franck Dernoncourt, Hassan Foroosh, and Fei Liu. 2023.MeetingBank: A benchmark dataset for meeting summarization.In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 16409–16423, Toronto, Canada. Association for Computational Linguistics.Janin et al.