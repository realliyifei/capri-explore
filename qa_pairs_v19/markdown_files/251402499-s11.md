# Abstractive Meeting Summarization: A Survey

## Question

How do dialogue acts contribute to improving abstractive meeting summarization, especially in contexts involving decisions?

## URLs

1. https://ar5iv.org/html/2210.09894. [2210.09894] Taxonomy of Abstractive Dialogue Summarization: Scenarios, Approaches and Future Directions
2. https://ar5iv.org/html/2406.07494. [2406.07494] CADS: A Systematic Literature Review on the Challenges of Abstractive Dialogue Summarization
3. https://ar5iv.org/html/2404.11124. [2404.11124] What’s under the hood: Investigating Automatic Metrics on Meeting Summarization
4. https://ar5iv.org/html/2409.02413. [2409.02413] Abstractive Text Summarization: State of the Art, Challenges, and Improvements
5. https://ar5iv.org/html/2404.19007. [2404.19007] How did we get here? Summarizing conversation dynamics
6. https://ar5iv.org/html/2107.03175. [2107.03175] A Survey on Dialogue Summarization: Recent Advances and New Frontiers
7. https://ar5iv.org/html/2405.11055. [2405.11055] Leveraging Discourse Structure for Extractive Meeting Summarization
8. https://ar5iv.org/html/1910.00825. [1910.00825] Abstractive Dialog Summarization with Semantic Scaffolds

## Answer (I don't know?: ✗)

Dialogue acts significantly enhance abstractive meeting summarization by providing structured information about the roles that utterances play within the dialogue. This structure facilitates an improved understanding of the flow and dynamics of conversations, ultimately leading to better summary generation.

Dialogue acts refer to the communicative intents behind utterances, such as asking questions, acknowledging previous statements, or directing attention to specific topics. These acts are crucial because they add context to the utterances, enabling summarization models to discern which information is significant for decision-making. Goo and Chen (2018) demonstrated the value of using dialogue acts in abstractive dialogue summarization, showing that when these acts are incorporated, models can generate more relevant and contextually rich summaries [2] [4]. The insights into how speakers interact—whether to agree, dispute, or seek clarification—allow models to prioritize information that is particularly vital for decisions made during the meeting.

Additionally, the conversation's discourse structure can be represented as a discourse graph, as presented by Feng et al. (2020), which further enhances the model's comprehension of conversational dynamics [2]. This approach allows the summarization model to visualize interrelations among utterances and determine how each contributes toward the collective understanding of decisions being made. The exploitation of discourse structure encourages an organized representation of dialogue, enabling the model to capture key decisions and their rationales more effectively.

Moreover, incorporating multi-modal cues such as participants' head orientation and eye gaze, as shown by Liu et al. (2019), complements the dialogue acts by highlighting non-verbal signals that may indicate agreement or the importance of certain topics during discussions. Such multi-modal cues, when integrated into the summarization process, can indicate which decisions are salient and should be prominent in the final summary [2].

Overall, the combination of dialogue acts, discourse structure, and potentially beneficial multi-modal information confers a layered understanding upon the summarization model, allowing it to synthesize decision-relevant information more effectively. The capacity to assess which dialogue acts prompt decisions and how they interplay with contextual dialogue elements ultimately elevates the quality and relevance of abstractive meeting summaries, thus providing invaluable insights amid complex discussions.

1. [1]:  https://ar5iv.org/html/2107.03175, [2107.03175] A Survey on Dialogue Summarization: Recent Advances and New Frontiers
2. [2]:  https://ar5iv.org/html/2405.11055, [2405.11055] Leveraging Discourse Structure for Extractive Meeting Summarization
3. [3]:  https://ar5iv.org/html/2406.07494, [2406.07494] CADS: A Systematic Literature Review on the Challenges of Abstractive Dialogue Summarization
4. [4]:  https://ar5iv.org/html/2405.11055, [2405.11055] Leveraging Discourse Structure for Extractive Meeting Summarization
5. [5]:  https://ar5iv.org/html/2405.11055, [2405.11055] Leveraging Discourse Structure for Extractive Meeting Summarization
---
1. [1]:  Passage ID 1: years witness a growing trend of abstractive meeting summarization methods Shang et al. (2018).With the development of neural networks, many works have explored the application of deep learning in meeting the summarization task and have achieved remarkable success Zhu et al. (2020).Although deep learning-based methods have strong modeling abilities, taking only literal information into consideration is not sufficient.This is because there are diverse interactive signals among meeting utterances and the long meeting transcripts further pose challenges to traditional sequence-to-sequence models.To this end, some works devote efforts to incorporate auxiliary information for better modeling meetings, such as dialogue discourse Feng et al. (2021b), dialogue acts Goo and Chen (2018) and domain terminologies Koay et al. (2020).Besides, several strategies are carefully devised to handle long meeting transcripts, including hierarchical modeling strategy Zhu et al. (2020), sliding window
2. [2]:  Passage ID 2: instance; that is, whether it serves to introduce or answer a question, to acknowledge another utterance or so on. In this vein, Feng et al. (2020) showed that representing the content of a meeting transcript as a discourse graph in the style of Segmented Discourse Representation Theory (SDRT; Asher, 1993; Lascarides and Asher, 2008) can improve performance on abstractive meeting summarization, while Goo and Chen (2018) demonstrated the value of dialogue acts (Jurafsky et al., 1997; Allen and Core, 1997) for the same task.Similarly, Liu et al. (2019) showed that supplementing transcripts with multi-modal information about participants’ head orientation and eye gaze can help to identify salient information in a meeting.In this paper, we exploit information on discourse structure to improve extractive summarization. While abstractive summarization is generally preferable for spontaneous conversation (Murray et al., 2010), focusing on extractive summarization is valuable for multiple
3. [3]:  Passage ID 3: we discuss the possible implications of the recently explored large language models and conclude that despite a potential shift in relevance and difficulty, our described challenge taxonomy remains relevant.1 IntroductionFigure 1: Overview of the big six challenges in dialogue summarization, a short description of the challenges, and the estimation of their progress derived from related sub-challenges. Green means mostly mitigated, orange means good progress, and red stands for marked challenges still exist.Abstractive dialogue summarization, a task within Natural Language Processing (NLP) and text summarization, entails condensing key information from conversations into succinct and coherent summaries (?).This sub-field of text summarization is gaining prominenceand is relevant for various real-world scenarios, including customer service (e.g., social media (?) and e-commerce (?)), healthcare (?), daily life (?), meetings (?), and open-domain conversations (e.g.,
4. [4]:  Passage ID 4: Natural Language Processing, pages 8484–8495, Singapore. Association for Computational Linguistics.Feng et al. (2020)Xiachong Feng, Xiaocheng Feng, Bing Qin, and Xinwei Geng. 2020.Dialogue discourse-aware graph model and data augmentation for meeting summarization.In Proceeding of The 30th International Joint Conference on Artificial Intelligence.Goo and Chen (2018)Chih-Wen Goo and Yun-Nung Chen. 2018.Abstractive dialogue summarization with sentence-gated modeling optimized by dialogue acts.In 2018 IEEE Spoken Language Technology Workshop (SLT), pages 735–742. IEEE.Hu et al. (2023)Yebowen Hu, Timothy Ganter, Hanieh Deilamsalehy, Franck Dernoncourt, Hassan Foroosh, and Fei Liu. 2023.MeetingBank: A benchmark dataset for meeting summarization.In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 16409–16423, Toronto, Canada. Association for Computational Linguistics.Janin et al.
5. [5]:  Passage ID 5: literature for its potential utility in downstream tasks. Our work is among the few studies that focus on this effort, especially for dialogues.2 Related workMeeting summarization.Most work focuses on abstractive summarization and tends to be organized in three interconnected streams (Rennard et al., 2023b). The first focuses on enhancing transcripts with additional information—such as annotations for dialogue acts (Goo and Chen, 2018), discourse structure (Feng et al., 2020) or visual cues (Liu et al., 2019)—that is assumed to be relevant for abstracting important content from a transcript. While adding information does show improvement, few papers actually quantify how much information is gained from adding linguistical features; Indeed, Goo and Chen (2018) worked on a version of AMI that lacked the current version of abstractive summaries, making it difficult to draw conclusions that are comparable to more recent works. Additionally, Feng et al. (2020) used a global node to