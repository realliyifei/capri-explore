# Multiword Expression Processing: A Survey under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license Computational Linguistics

## Question

How do statistical machine translation systems determine the most probable translations during the decoding process?

## URLs

1. https://ar5iv.org/html/2205.00978. [2205.00978] Quality-Aware Decoding for Neural Machine Translation
2. https://ar5iv.org/html/2104.05336. [2104.05336] Machine Translation Decoding beyond Beam Search
3. https://ar5iv.org/html/2310.06707. [2310.06707] Quality Control at Your Fingertips: Quality- Aware Translation Models
4. https://ar5iv.org/html/2005.10283. [2005.10283] Is MAP Decoding All You Need? The Inadequacy of the Mode in Neural Machine Translation
5. https://ar5iv.org/html/2210.05193. [2210.05193] Viterbi Decoding of Directed Acyclic Transformer for Non-Autoregressive Machine Translation
6. https://ar5iv.org/html/2405.18922. [2405.18922] Understanding and Addressing the Under-Translation Problem from the Perspective of Decoding Objective
7. https://ar5iv.org/html/1808.10006. [1808.10006] Correcting Length Bias in Neural Machine Translation
8. https://ar5iv.org/html/2405.18348. [2405.18348] Can Automatic Metrics Assess High-Quality Translations?
9. https://ar5iv.org/html/2409.17943. [2409.17943] On Translating Technical Terminology: A Translation Workflow for Machine-Translated Acronyms

## Answer (I don't know?: ✓)

I don't know. The context provided does not offer specific details about how statistical machine translation (SMT) systems determine the most probable translations during the decoding process. While it mentions that SMT systems rely on machine learning algorithms and utilize large parallel corpora for input, there are no explicit descriptions of the decoding mechanism or the probabilistic models used within SMT systems. Therefore, the context is insufficient to answer the question completely and precisely.

1. [1]:  https://ar5iv.org/html/2408.06124, No Title
2. [2]:  https://ar5iv.org/html/1807.10854, No Title
3. [3]:  https://ar5iv.org/html/2404.08661, No Title
4. [4]:  https://ar5iv.org/html/2404.08661, No Title
5. [5]:  https://ar5iv.org/html/2409.17943, [2409.17943] On Translating Technical Terminology: A Translation Workflow for Machine-Translated Acronyms
---
1. [1]:  Passage ID 1: in Section V before making conclusions in Section VI.II Literature ReviewThe current popular approach in machine translation involves utilizing modern neural networks, which are trained on extensive datasets containing millions to billions of parameters. This approach has proven to achieve substantial quality improvements. At the same time, traditional methods are now less commonly used due to their limitations in dealing with new domains and expensive cost and language pairs with significantly different word orders [2].Many works on neural machine translation rely on an encoder-decoder architecture [3]. Cho et al. [4] introduced the RNN Encoder-Decoder with two RNN networks to improve phrase representation using conditional probabilities. This model captures semantically and syntactically meaningful representations of linguistic phrases. Sutskever et al. [5] created a sequence-to-sequence network using multilayered LSTMs to encode input sequences into fixed-dimensional
2. [2]:  Passage ID 2: the top performers in classifying types of questions using the TREC database [146].Between their requirement for such understanding and their ease of examination due to the typical encoder–decoder structure they use,neural machine translation (NMT) systems (Section IV-G) are splendid testbeds for researching internal semantic representations. Poliak et al. [147] trained encoders on four different language pairs: English and Arabic, English and Spanish, English and Chinese, and English and German. The decoding classifiers were trained on four distinct datasets: Multi-NLI [148], which is an expanded version of SNLI [149], as well as three recast datasets from the JHU Decompositional Semantics Initiative [150] (FrameNet Plus or FN+ [151], Definite Pronoun Resolution or DPR [152], and Semantic Proto-Roles or SPR [153]). None of the results were particularly strong, although they were strongest in SPR. This led to the conclusion that NMT models do a poor job of capturing paraphrased
3. [3]:  Passage ID 3: highly automation and efficiency are its two main problems. (2) A corpus-based system with statistical machine translation (SMT) or phrase-based machine translation (PB- SMT) as the primary method uses machine learning algorithms by using a large amount of parallel corpus as input, overcoming the problem of using labor work to boost efficiency automatically (Lopez, 2008); however, it has issues such as with translation for idiomatic expressions, compound words that have to be translated by more than one word, long dependencies, and ambiguous words with different meanings depending on contexts (Nießen, 2000). (3) The currently predominant neural machine translation (NMT) system has gained the most extensive popularity in machine translation domain. In contrast to more established system SMT, NMT makes use of its architecture and capacity to capture complex sentence dependencies, which suggests that it has a great deal of potential to become a new trend in machine translation.
4. [4]:  Passage ID 4: this dissertation, translationese in neural machine translation is detected with human translation as reference, measured by a metric named translation relations.1.1 Choice of NMT system and its human parityThere are three types of machine translation systems guiding the current machine translation domain, and they are rule-based machine translation, statistical machine translation, and neural machine translation. More details are introduced in the following part. (1) Rule-based machine translation (RBMT) converts the source languages to target languages based on the linguistics-based rules specified by humans (Hutchins, 1995), featuring consistency and stability but low efficiency (Dove, 2012). Different languages have their own rules and contain oceans of text information; therefore, highly automation and efficiency are its two main problems. (2) A corpus-based system with statistical machine translation (SMT) or phrase-based machine translation (PB- SMT) as the primary
5. [5]:  Passage ID 5: language processing (NLP) do – predict the next word in a series of words. While high-resource languages like English and French are reported to achieve near human parity using common metrics for measurement such as BLEU and COMET, we find that an important step is being missed: the translation of technical terms, specifically acronyms. Some state-of-the art machine translation systems like Google Translate which are publicly available can be erroneous when dealing with acronyms – as much as 50% in our findings. This article addresses acronym disambiguation for MT systems by proposing an additional step to the SL–TL (FR–EN) translation workflow where we first offer a new acronym corpus for public consumption and then experiment with a search-based thresholding algorithm that achieves nearly 10% increase when compared to Google Translate and OpusMT.1 IntroductionWith the myriad of artificial intelligence tools available for professional translators, it can be hard for translators