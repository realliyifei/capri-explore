# Anaphora With Non-nominal Antecedents in Computational Linguistics: a Survey under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license Computational Linguistics

## Question

What are shell nouns, and how do they relate to their shell content? Can you provide examples of these relationships?

## URLs

1. https://ar5iv.org/html/2101.10554. [2101.10554] 1 Introduction
2. https://ar5iv.org/html/1706.02256. [1706.02256] A Mention-Ranking Model for Abstract Anaphora Resolution
3. https://ar5iv.org/html/2101.09619. [2101.09619] Implementing WordNet Measures of Lexical Semantic Similarity in a Fuzzy Logic Programming SystemWork partially funded by the State Research Agency (AEI) of the Spanish Ministry of Science and Innovation under grant PID2019-104735RB-C42 (SAFER), by the Spanish Ministry of Economy and Competitiveness, under the grants TIN2016-76843-C4-2-R (MERINET), TIN2017-86217-R (CAVI-ART-2), and by the Comunidad de Madrid, under the grant S2018/TCS-4339 (BLOQUES-CM), co-funded by EIE Funds of the European Union.
4. https://ar5iv.org/html/2205.12825. [2205.12825] A Paradigm Change for Formal Syntax: Computational Algorithms in the Grammar of English
5. https://ar5iv.org/html/2406.00537. [2406.00537] Towards an ontology of portions of matter to support multi-scale analysis and provenance tracking
6. https://ar5iv.org/html/2206.14055. [2206.14055] Towards Lexical Gender Inference: A Scalable Methodology using Online Databases
7. https://ar5iv.org/html/2306.08832. [2306.08832] Contrasting intra-modal and ranking cross-modal hard negatives to enhance visio-linguistic compositional understanding
8. https://ar5iv.org/html/2402.16159. [2402.16159] DistALANER: Distantly Supervised Active Learning Augmented Named Entity Recognition in the Open Source Software Ecosystem
9. https://ar5iv.org/html/1610.04533. [1610.04533] A Comprehensive Comparative Study of Word and Sentence Similarity Measures
10. https://ar5iv.org/html/2205.10192. [2205.10192] On the Trade-off between Redundancy and Local Coherence in Summarization

## Answer (I don't know?: ✓)

I don't know. The context provided does not contain any information regarding shell nouns, their definitions, relationships to shell content, or examples of these relationships. The passages focus on various topics and studies related to natural language processing (NLP) but do not address this specific concept. Therefore, the information required to answer the question about shell nouns is insufficient in the given context.

1. [1]:  https://ar5iv.org/html/2310.11644, No Title
2. [2]:  https://ar5iv.org/html/2310.11644, No Title
3. [3]:  https://ar5iv.org/html/2408.10962, No Title
4. [4]:  https://ar5iv.org/html/2410.11627, No Title
5. [5]:  https://ar5iv.org/html/2411.14198, No Title
---
1. [1]:  Passage ID 1: in Natural Language Processing and Computational Natural Language Learning, 2012, pp. 523–534.[85]E. Sandhaus, “The New York Times Annotated Corpus,” Linguistic Data Consortium, Philadelphia, vol. 6, no. 12, p. e26752, 2008.[86]G. Stanovsky, J. Ficler, I. Dagan, and Y. Goldberg, “Getting More Out Of Syntax with PropS,” arXiv preprint arXiv:1603.01648, 2016.[87]N. FitzGerald, J. Michael, L. He, and L. Zettlemoyer, “Large-Scale QA-SRL Parsing,” arXiv preprint arXiv:1805.05377, 2018.[88]F. Mesquita, J. Schmidek, and D. Barbosa, “Effectiveness and Efficiency of Open Relation Extraction,” in Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, 2013, pp. 447–457.[89]Y. Xu, M.-Y. Kim, K. M. Quinn, R. Goebel, and D. Barbosa, “Open Information Extraction with Tree Kernels,” in Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2013,
2. [2]:  Passage ID 2: in Natural Language Processing and Computational Natural Language Learning, 2012, pp. 523–534.[85]E. Sandhaus, “The New York Times Annotated Corpus,” Linguistic Data Consortium, Philadelphia, vol. 6, no. 12, p. e26752, 2008.[86]G. Stanovsky, J. Ficler, I. Dagan, and Y. Goldberg, “Getting More Out Of Syntax with PropS,” arXiv preprint arXiv:1603.01648, 2016.[87]N. FitzGerald, J. Michael, L. He, and L. Zettlemoyer, “Large-Scale QA-SRL Parsing,” arXiv preprint arXiv:1805.05377, 2018.[88]F. Mesquita, J. Schmidek, and D. Barbosa, “Effectiveness and Efficiency of Open Relation Extraction,” in Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, 2013, pp. 447–457.[89]Y. Xu, M.-Y. Kim, K. M. Quinn, R. Goebel, and D. Barbosa, “Open Information Extraction with Tree Kernels,” in Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2013,
3. [3]:  Passage ID 3: of the 16th Conference of the European Chapter ofthe Association for Computational Linguistics: System Demonstrations, 2021.[311]Veysel Kocaman and David Talby.Spark NLP: Natural language understanding at scale.Software Impacts, page 100058, 2021.[312]Patrick J. Burns.Building a Text Analysis Pipeline for Classical Languages,pages 159–176.De Gruyter Saur, Berlin, Boston, 2019.[313]Jacobo Myerston.grecy.https://github.com/jmyerston/greCy, 2022.[314]Bart Jongejan and Hercules Dalianis.Automatic training of lemmatization rules that handle morphologicalchanges in pre-, in- and suffixes alike.In Keh-Yih Su, Jian Su, Janyce Wiebe, and Haizhou Li, editors, Proceedings of the Joint Conference of the 47th Annual Meeting of the ACLand the 4th International Joint Conference on Natural Language Processing ofthe AFNLP, pages 145–153, Suntec, Singapore, August 2009. Association forComputational Linguistics.[315]Evelien de Graaf, Silvia
4. [4]:  Passage ID 4: NLP.Nature Machine Intelligence, 5(10):1161–1174.Hupkes et al. (2018)Dieuwke Hupkes, Sara Veldhoen, and Willem Zuidema. 2018.Visualisation and’diagnostic classifiers’ reveal how recurrent andrecursive neural networks process hierarchical structure.Journal of Artificial Intelligence Research, 61:907–926.Kempe and Brooks (2008)Vera Kempe and Patricia J Brooks. 2008.Second language learning of complex inflectional systems.Language Learning, 58(4):703–746.Kim et al. (2016)Yoon Kim, Yacine Jernite, David Sontag, and Alexander Rush. 2016.Character-aware neural language models.In Proceedings of the AAAI conference on artificialintelligence, volume 30.Kudo (2018)Taku Kudo. 2018.Subword regularization:Improving neural network translation models with multiple subwordcandidates.In Proceedings of the 56th Annual Meeting of the Associationfor Computational Linguistics (Volume 1: Long Papers), pages 66–75,Melbourne, Australia. Association
5. [5]:  Passage ID 5: and conceptual development, 3:406.Slobin (2013)Dan I Slobin. 2013.Crosslinguistic evidence for the language-making capacity.In The crosslinguistic study of language acquisition, pages 1157–1256. Psychology Press.Søgaard (2022)Anders Søgaard. 2022.Should we ban English NLP for a year?In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 5254–5260, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.Song et al. (2021)Xinying Song, Alex Salcianu, Yang Song, Dave Dopson, and Denny Zhou. 2021.Fast WordPiece Tokenization.In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 2089–2103, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.Tan et al. (2020)Samson Tan, Shafiq Joty, Lav Varshney, and Min-Yen Kan. 2020.Mind your inflections! Improving NLP for non-standard Englishes with Base-Inflection