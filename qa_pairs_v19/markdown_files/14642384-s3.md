# DISCOURSE-NEW DETECTORS FOR DEFINITE DESCRIPTION RESOLUTION: A SURVEY AND A PRELIMINARY PROPOSAL

## Question

How are decision trees used to classify definite descriptions as either discourse-new or anaphoric?

## URLs

1. https://ar5iv.org/html/1911.09994. [1911.09994] Anaphora Resolution in Dialogue Systems for South Asian Languages
2. https://ar5iv.org/html/2204.04282. [2204.04282] Classification of Natural Language Processing Techniques for Requirements Engineering
3. https://ar5iv.org/html/2305.11529. [2305.11529] A Sequence-to-Sequence Approach for Arabic Pronoun Resolution

## Answer (I don't know?: ✓)

I don't know. The context provided does not include any specific information about how decision trees are employed to classify definite descriptions as either discourse-new or anaphoric. While there are references to decision trees in the context of anaphora resolution and various techniques in natural language processing (NLP) [3][4], these passages do not detail the methodology or approach specific to classifying definite descriptions using decision trees. Thus, the information is insufficient to provide a precise answer to the question.

1. [1]:  https://ar5iv.org/html/2204.04282, [2204.04282] Classification of Natural Language Processing Techniques for Requirements Engineering
2. [2]:  https://ar5iv.org/html/1911.09994, [1911.09994] Anaphora Resolution in Dialogue Systems for South Asian Languages
3. [3]:  https://ar5iv.org/html/1911.09994, [1911.09994] Anaphora Resolution in Dialogue Systems for South Asian Languages
4. [4]:  https://ar5iv.org/html/2305.11529, [2305.11529] A Sequence-to-Sequence Approach for Arabic Pronoun Resolution
5. [5]:  https://ar5iv.org/html/1807.02226, No Title
---
1. [1]:  Passage ID 1: of semantic analysis techniques.Discourse. A NLP technique at this level focuses on the properties of the text as a whole that convey meaning by making connections between component sentences. Several types of discourse processing can occur at this level, two of the most common being anaphora resolution and coreference resolution [55].Pragmatic. This is the highest level of NLP. To reach this level, NLP techniques need to be able to achieve human-like language understanding, the ultimate goal of natural language understanding (NLU). This entails inferring extra meaning from texts that is not actually encoded in them [55] and understanding narratives according to different contexts and with respect to different actors and their intentions [33]. This requires NLP tools to have world knowledge and human intelligence, and the ability to project semantics and sentics dynamically [33]. Pragmatic analysis appears to be the most challenging NLP curve to jump [33].It is assumed that
2. [2]:  Passage ID 2: these languages, which are constrained to context and domain. In this paper, we venture a new strategy using neural networks for resolving anaphora in human-human dialogues. The architecture chiefly consists of three components, a shallow parser for extracting features, a feature vector generator which produces the word embeddings, and a neural network model which will predict the antecedent mention of an anaphora. The system has been trained and tested on Telugu conversation corpus we generated. Given the advantage of the semantic information in word embeddings and appending actor, gender, number, person and part of plural features the model has reached an F1-score of 86.1 IntroductionThroughout the information era, we have seen a shift in human-computer interactions, from clicks to chats. Conversational agents and dialogue systems are becoming prominent with the daily advances in the field of Artificial Intelligence. Technology will be effective if it can reach for the vaster
3. [3]:  Passage ID 3: been done in Hindi, Bengali, and Tamil. Dakwale et al. (2013) built a hybrid approach for anaphora resolution in Hindi using dependency parser and a decision tree classifier. Jonnalagadda and Mamidi (2015) proposed a rule-based system for anaphora resolution in Telugu dialog systems, After preprocessing the data using Morphological analyzer and POS tagger they used a set of hard-coded rules to deal with different types of pronouns.Clark (2015) has done pioneering work in coreference resolution using deep learning that automatically learns dense vector representations for mention pairs for English and Chinese. He built them using the word embeddings in the mention and surrounding context, which will maintain the semantic similarity. Despite using a few hand-engineered features, he trained an incremental coreference system that can utilize entity-level information. His mention pair model acted as an inspiration for our feature representations, and we updated it for free word order
4. [4]:  Passage ID 4: the rise in popularity of Deep Learning, research in Arabic anaphora resolution continued to employ both statistical machine learning algorithms [15] and a hybrid approach incorporating linguistic rules [9]. The classification problem was approached using algorithms such as Naive Bayes, K-nearest neighbors (KNN), and linear logistic regression. The proposed solutions were evaluated using the QurAna corpus, explicitly focusing on pronominal anaphors. They were framed as a classification task for each potential anaphor-candidate pair represented by preceding NP phrases.In Mathlouthi and Bouzid’s study [16], published in 2016, a novel approach to Arabic anaphora resolution was presented that deviates from the existing solutions. This approach is based on Reinforcement Learning, which utilizes the principles of rewards and punishments to learn from past experiences and make decisions using Markov Decision Process to resolve pronominal anaphora. The authors aim to address the limitations
5. [5]:  Passage ID 5: In other cases, it may be less obvious. Again, certain propositions will specify further details or explain aspects of another proposition and the connections in the network can be made accordingly. A common discourse feature is quotation. The quoted text becomes a semantic representation that specifies the theme of the speech act. Another common discourse-level connector is sequence. For example, “She was frightened. She ran.” In this example the first sentence leads the way to the actions in the second. This could be represented as, (frighten >> [{past}, {agent} >> she]) >> {seq} >> (run >> [{past}, {agent} >> she]). Unless made explicit by concepts in the sentences themselves, these discourse-level connections tend to be implied or inferred and thus will not normally be part of a first pass of converting surface text into a semantic representation.4 Natural Language Generation (Realisation) and ParsingWhile our representation stands on its own as a way of understanding