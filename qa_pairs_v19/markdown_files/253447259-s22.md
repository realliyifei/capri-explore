# Grammatical Error Correction: A Survey of the State of the Art

## Question

What is the break-it-fix-it (BIFI) approach in grammatical error correction, and how does it work?

## URLs

1. https://ar5iv.org/html/2106.06600. [2106.06600] Break-It-Fix-It: Unsupervised Learning for Program Repair
2. https://ar5iv.org/html/2109.06822. [2109.06822] LM-Critic: Language Models for Unsupervised Grammatical Error Correction
3. https://ar5iv.org/html/2410.20838. [2410.20838] A Simple Yet Effective Corpus Construction Framework for Indonesian Grammatical Error Correction
4. https://ar5iv.org/html/2407.11854. [2407.11854] Zero-shot Cross-Lingual Transfer for Synthetic Data Generation in Grammatical Error Detection
5. https://ar5iv.org/html/2211.05166. [2211.05166] Grammatical Error Correction: A Survey of the State of the Art
6. https://ar5iv.org/html/2309.10089. [2309.10089] HTEC: Human Transcription Error Correction

## Answer (I don't know?: ✗)

The Break-It-Fix-It (BIFI) approach is a novel method designed primarily for the task of program repair but holds potential applications in areas like grammatical error correction (GEC) as well. The key feature of BIFI is its use of both a 'fixer' and a 'critic' to generate realistic paired data, which is crucial for training effective error correction models.

BIFI operates on the premise of training a fixer to convert "bad" inputs—such as code with errors—into "good" outputs, or error-free codes. The methodology includes two fundamental steps: (1) gathering realistic examples of bad inputs and (2) using a critic (for instance, a compiler or analyzer) to evaluate whether the fixer's outputs are indeed accurate corrections or remain erroneous [2] [5]. 

Initially, traditional methods use synthetic data composed of (bad, good) pairs generated by corrupting good examples through methods like token dropping, which often fail to reflect the true distribution of real-world errors [1] [3]. This leads to low performance when models trained on such data encounter actual errors. BIFI seeks to address this issue by beginning with synthetic paired data and then refining this data with real-world examples.

The BIFI algorithm involves a cycle of training and evaluation: (1) it applies the initial fixer to real bad examples, using the critic to assess and retain only those pairs where the fixer's output is validated as good; (2) the fixer is then trained not only on these validated pairs but also on real bad examples [4] [5]. This dual reliance on both the critic and real data helps to create a distribution of training data that is more aligned with the errors that occur naturally.

Furthermore, BIFI is contrasted with techniques like backtranslation used in unsupervised machine translation. While backtranslation insufficiently verifies noise in translations, BIFI's integration of a critic ensures higher accuracy in fixing and pairing, improving the overall quality of the training data generated [4].

Ultimately, the BIFI method demonstrates a sophisticated approach to error correction, aiming to produce more reliable and realistic training datasets that enhance the performance of models in tasks like grammatical error correction and beyond [2] [5]. By effectively blending synthetic approaches with real-world data verification, BIFI emerges as a pivotal strategy in NLP and related fields.

1. [1]:  https://ar5iv.org/html/2109.06822, [2109.06822] LM-Critic: Language Models for Unsupervised Grammatical Error Correction
2. [2]:  https://ar5iv.org/html/2106.06600, [2106.06600] Break-It-Fix-It: Unsupervised Learning for Program Repair
3. [3]:  https://ar5iv.org/html/2106.06600, [2106.06600] Break-It-Fix-It: Unsupervised Learning for Program Repair
4. [4]:  https://ar5iv.org/html/2106.06600, [2106.06600] Break-It-Fix-It: Unsupervised Learning for Program Repair
5. [5]:  https://ar5iv.org/html/2106.06600, [2106.06600] Break-It-Fix-It: Unsupervised Learning for Program Repair
---
1. [1]:  Passage ID 1: rely on a combination of human-labeled data (i.e., ⟨⟨\langlebad, good⟩⟩\rangle pairs) Nicholls (2003); Yannakoudakis et al. (2011); Bryant et al. (2019) andsynthetic data, which are generated by corrupting good sentences into ⟨⟨\langlesynthetic bad, good⟩⟩\rangle pairs Awasthi et al. (2019); Kiyono et al. (2019).Human-labeled pairs are representative of real human errors but are expensive to obtain, while synthetic pairs are cheap but are unrealistic, deviating from the distribution of grammatical errors humans make Grundkiewicz et al. (2019). How to obtain inexpensive yet realistic paired data to improve GEC remains a key challenge, especially in domains or languages with no labeled GEC data Napoles et al. (2019); Náplava and Straka (2019).Break-It-Fix-It (BIFI; Yasunaga and Liang (2021)) is a recent method to obtain realistic paired data from unlabeled data, which has shown promise in the task of source code repair. The idea of BIFI is that using an initial fixer (e.g., trained
2. [2]:  Passage ID 2: is that the repair task has a critic, which motivated our BIFI algorithm: BIFI (i) uses the critic to verify if the generated examples are actually fixed or broken (Eq 6, 8), and (ii) trains the fixer on real bad examples besides examples generated by the breaker (Eq 9). We found these techniques improve the correctness of the generated training data (§4.3.3).While we focused on code repair in this work, we hope that BIFI can be applied to unsupervised MT and style transfer by introducing a human-based or learned critic.6 ConclusionWe considered the problem of learning a fixer from unpaired data and a critic (code analyzer or compiler), and proposed a new approach, Break-It-Fix-It (BIFI).The idea of BIFI is to train a breaker and use the critic to amass more realistic and correct paired data for training the fixer.Using two code repair datasets (GitHub-Python and DeepFix), we showed how BIFI adapts baseline fixers towards realistic distributions of code errors, achieving
3. [3]:  Passage ID 3: "light"); } } else { localStorage.setItem("ar5iv_theme", "dark"); } detectColorScheme(); }Break-It-Fix-It: Unsupervised Learning for Program RepairMichihiro Yasunaga    Percy Liang  AbstractWe consider repair tasks: given a critic (e.g., compiler) that assesses the quality of an input, the goal is to train a fixer that converts a bad example (e.g., code with syntax errors) into a good one (e.g., code with no syntax errors).Existing works create training data consisting of (bad, good) pairs by corrupting good examples using heuristics (e.g., dropping tokens). However, fixers trained on this synthetically-generated data do not extrapolate well to the real distribution of bad inputs.To bridge this gap, we propose a new training approach, Break-It-Fix-It (BIFI), which has two key ideas:(i) we use the critic to check a fixer’s output on real bad inputs and add good (fixed) outputs to the training data,and (ii) we train a breaker to generate realistic bad code
4. [4]:  Passage ID 4: of code errors.The BIFI algorithm is related to backtranslation in unsupervised machine translation (Lample et al., 2018a),which uses a target-to-source model to generate noisy sources and trains a source-to-target model to reconstruct the targets (e.g., the bad-side and good-side in our repair task can be viewed as the source and target).BIFI differs from backtranslation in two ways: it uses the critic to verify if the generated examples are actually fixed or broken (step 1 and 3), and it trains the fixer on real bad examples in addition to examples generated by the breaker (step 4), which improves the correctness and distributional match of generated paired data.We evaluate our proposed approach on two code repair datasets:∙∙\bulletGitHub-Python: We collected a new dataset of 3M Python code snippets from github.com.The task is to repair errors caught by the Python AST parser. We set the initial fixer to be an encoder-decoder Transformer (Vaswani et al., 2017) trained on
5. [5]:  Passage ID 5: error (center) from the corrected code (left), multiple tokens (in this case, a pair of indent and dedent) need to be inserted or dropped accordingly, which random perturbations would generate with extremely low probability.This distribution mismatch between synthetic data and real data results in low performance (§4).To address this challenge, we propose Break-It-Fix-It (BIFI), an approach that adapts the fixer automatically towards real distributions of bad examples.Concretely, we first start from the synthetic paired data ⟨⟨\langlesynthetic bad, good⟩⟩\rangle and train an initial fixer as in prior works (see Figure 3 top left; initialization).We then perform the following cycle (see Figure 3 bottom right): (1) weapply the initial fixer to the real bad examples and use the critic to assess if the fixer’s output is good—if good, we keep the pair; (2) we train a breaker on the resulting paired data—as this data consists of real code errors, intuitively, the breaker learns to