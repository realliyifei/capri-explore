# A Systematic Survey of Text Worlds as Embodied Natural Language Environments

## Question

How do procedurally generated environments enhance the ability of simulations to generalize, compared to environments that are statically initialized?

## URLs

1. https://ar5iv.org/html/2409.17652. [2409.17652] FactorSim: Generative Simulation via Factorized Representation
2. https://ar5iv.org/html/2012.13681. [2012.13681] Improving the Generalization of End-to-End Driving through Procedural Generation
3. https://ar5iv.org/html/2412.01770. [2412.01770] Robot Learning with Super-Linear Scaling
4. https://ar5iv.org/html/2305.04180. [2305.04180] Train a Real-world Local Path Planner in One Hour via Partially Decoupled Reinforcement Learning and Vectorized Diversity
5. https://ar5iv.org/html/2107.04132. [2107.04132] A Systematic Survey of Text Worlds as Embodied Natural Language Environments
6. https://ar5iv.org/html/2412.00243. [2412.00243] Realistic Corner Case Generation for Autonomous Vehicles with Multimodal Large Language Model
7. https://ar5iv.org/html/2410.22308. [2410.22308] Environment as Policy: Learning to Race in Unseen Tracks
8. https://ar5iv.org/html/2408.04054. [2408.04054] NAVINACT: Combining Navigation and Imitation Learning for Bootstrapping Reinforcement Learning
9. https://ar5iv.org/html/2410.10766. [2410.10766] Adaptive Diffusion Terrain Generator for Autonomous Uneven Terrain Navigation

## Answer (I don't know?: ✗)

Procedurally generated environments enhance the ability of simulations to generalize compared to statically initialized environments primarily by introducing variability and reducing overfitting. In static environments, the structure remains unchanged every time the simulation is run, which can lead agents to overfit their solutions to specific instances of a task and fail to learn general skills applicable to a broader range of scenarios [3]. Overfitting occurs because agents learn to exploit the exact features and patterns present in the static environment rather than developing a robust understanding that generalizes to new, unseen environments [4].

In contrast, procedurally generated environments provide a diverse set of possible interactions and layouts, allowing agents to encounter various configurations of the same underlying task. For instance, the TextWorld simulator can specify high-level parameters to create multiple room and object setups with goal conditions, leading to a random environment that still allows for successful task completion [2]. This variability compels agents to adapt their strategies to different contexts and enhances their ability to generalize learned behaviors across varying scenarios, leading to improved performance on modified tasks that were not part of the original training setup [3].

Furthermore, the ability to generate environments centered around specific goal conditions means that agents can be trained on diverse but related tasks, helping them to build foundational skills that transfer to new situations [2]. This method counters the limitations of static benchmarks that may contain regularities or artifacts exploited by machine learning systems, fostering a more realistic learning experience that challenges agents to synthesize their understanding rather than mere recognition of patterns [4]. 

Overall, the enhanced diversity and adaptability offered by procedural generation play a crucial role in fostering agents' ability to generalize their learning, allowing for more robust performance across a wider array of tasks and environments [3] [4].

1. [1]:  https://ar5iv.org/html/2107.04132, [2107.04132] A Systematic Survey of Text Worlds as Embodied Natural Language Environments
2. [2]:  https://ar5iv.org/html/2107.04132, [2107.04132] A Systematic Survey of Text Worlds as Embodied Natural Language Environments
3. [3]:  https://ar5iv.org/html/2107.04132, [2107.04132] A Systematic Survey of Text Worlds as Embodied Natural Language Environments
4. [4]:  https://ar5iv.org/html/2302.04752, No Title
5. [5]:  https://ar5iv.org/html/2410.18529, No Title
---
1. [1]:  Passage ID 1: procedural environments, but those environments have limited complexity, and require agents to complete straightforward tasks. Economically creating complex, interactive environments that simulate a significant fraction of real world interactions are still well beyond current simulators or libraries – but required for higher-fidelity interactive worlds that have multiple meaningful paths toward achieving task goals. Generating these environments semi-automatically (e.g. Ammanabrolu et al., 2020a) may offer a partial solution. Independent of tooling, libraries and other middleware offer near-term solutions to more complex environment modeling, much in the same way 3D game engines are regularly coupled with physics engine middleware to dramatically reduce the time required to implement forces, collisions, lighting, and other physics-based modeling. Currently, few analogs exist for text worlds. The addition of a chemistry engine that knows that ice warmed above the freezing point will
2. [2]:  Passage ID 2: help address this need by generating variations of environments centered around specific goal conditions.The TextWorld simulator Côté et al. (2018) allows specifying high-level parameters such as the number of rooms, objects, and winning conditions, then uses a random walk to procedurally generate environment maps in the Inform7 language meeting those specifications, using either forward or backward chaining during generation to verify tasks can be successfully completed in the random environment. As an example, the First TextWorld Problems shared task222https://competitions.codalab.org/competitions/21557 used TextWorld to generate 5k variations of a cooking environment, divided into train, development, and test sets. Similarly, Murugesan et al. Murugesan et al. (2020a) introduce TextWorld CommonSense (TWC), a simple generative environment for household cleaning tasks, modelled as a pick-and-place task where agents must pick up common objects from the floor, and place them in their
3. [3]:  Passage ID 3: for agents to learn common-sense reasoning. Côté et al. Côté et al. (2018) further curate this list, replacing 20 games without scores to those more useful for RL agents. The Jericho benchmark Hausknecht et al. (2020) includes 32 interactive fiction games that support Jericho’s in-built methods for score and world-change detection, out of a total of 56 games known to support these features.4.4 Generative EnvironmentsA difficulty with statically-initialized environments is that because their structure is identical each time the simulation is run, rather than learning general skills, agents quickly overfit to learn solutions to an exact instantiation of a particular task and environment, and rarely generalize to unseen environments Chaudhury et al. (2020). Procedurally generated environments help address this need by generating variations of environments centered around specific goal conditions.The TextWorld simulator Côté et al. (2018) allows specifying high-level parameters
4. [4]:  Passage ID 4: will generalize. In practice, this is rare,except for benchmarks created using automatic synthesis.Benchmarks must avoid artifacts that machine learning systemscan exploit. As discussed in section 2.1,in many cases, it has been found that high levels ofsuccess can be attained on benchmarks by exploiting regularitieswhich are arbitrary artifacts of the way the benchmark was constructed,rather than reflecting either an understanding of the question or theuse of background commonsense knowledge.Simulated physical environments should be realistic, natural, rich,and interactive.Two dimensional environments, environments where time is discrete,environments where the only objects arerectangular blocks, environments where the only moving objects are collidingbilliard balls, purely passive environments where the AI can only observeand not act, environments where the AIs actions are carried out “by magic”,worlds where objects only move when the agent is directly manipulating
5. [5]:  Passage ID 5: in robotic tasks, with SayCan being a notable exception. More work is needed to improve LLM integration with robotic visual perception and decision-making (Wang et al., 2024b).5.2.4. Game EnvironmentsSimulating real-world challenges in game environments, e.g., strategic planning in chess (Toshniwal et al., 2021), collaborative building in Minecraft (Narayan-Chen et al., 2019; Jayannavar et al., 2020), and procedural level generation in educational games (Hooshyar et al., 2018), is common. We further divide game environments w.r.t. the task they focus on: Structured, Strategic, and Predictive Environments feature deterministic environments like chess and Othello (Toshniwal et al., 2021; Li et al., 2022b), where state, action, and observation spaces are defined by the positions and legal moves on the board. Collaborative and Interactive Virtual Worlds like Minecraft involve 3D environments where agents manipulate blocks and navigate using a limited view of the world (Narayan-Chen