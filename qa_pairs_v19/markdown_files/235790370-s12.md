# A Systematic Survey of Text Worlds as Embodied Natural Language Environments

## Question

How do procedurally generated environments enhance the ability of simulations to generalize, compared to environments that are statically initialized?

## URLs

1. https://ar5iv.org/html/2409.17652. [2409.17652] FactorSim: Generative Simulation via Factorized Representation
2. https://ar5iv.org/html/2012.13681. [2012.13681] Improving the Generalization of End-to-End Driving through Procedural Generation
3. https://ar5iv.org/html/2412.01770. [2412.01770] Robot Learning with Super-Linear Scaling
4. https://ar5iv.org/html/2305.04180. [2305.04180] Train a Real-world Local Path Planner in One Hour via Partially Decoupled Reinforcement Learning and Vectorized Diversity
5. https://ar5iv.org/html/2107.04132. [2107.04132] A Systematic Survey of Text Worlds as Embodied Natural Language Environments
6. https://ar5iv.org/html/2412.00243. [2412.00243] Realistic Corner Case Generation for Autonomous Vehicles with Multimodal Large Language Model
7. https://ar5iv.org/html/2410.22308. [2410.22308] Environment as Policy: Learning to Race in Unseen Tracks
8. https://ar5iv.org/html/2408.04054. [2408.04054] NAVINACT: Combining Navigation and Imitation Learning for Bootstrapping Reinforcement Learning
9. https://ar5iv.org/html/2410.10766. [2410.10766] Adaptive Diffusion Terrain Generator for Autonomous Uneven Terrain Navigation

## Answer (I don't know?: ✗)

Procedurally generated environments significantly enhance the ability of simulations to generalize compared to statically initialized environments. The primary limitation of static environments is that their structure remains unchanged across different simulation runs. This lack of variability causes agents to overfit, learning solutions specific to the exact tasks and environments encountered during training. Consequently, agents rarely manage to generalize to new, unseen environments [3].

In contrast, procedurally generated environments dynamically create variations of the settings and tasks, specifically centered around defined goal conditions. This process enables the generation of diverse training scenarios, which helps agents to develop and learn more general skills rather than memorizing specific solutions [2][3]. For instance, the TextWorld simulator allows for high-level parameter specifications—such as the number of rooms, objects, and winning conditions—which are used to procedurally generate environment maps. This variability ensures that agents are exposed to a broad spectrum of scenarios, enhancing their ability to adapt and generalize through learning [2].

Moreover, the introduction of generative models in procedural generation further augments this capability. For example, Ammanabrolu et al. (2020a) demonstrated a system that automatically constructs interactive fiction environments based on a narrative framework. By employing knowledge graphs and generative techniques, this system creates extensive and nuanced environments that provide unique learning experiences, again promoting better generalization [4]. 

In the context of reinforcement learning, procedurally generated environments are particularly beneficial because they provide a landscape where agents must continuously adjust and adapt to new configurations and challenges. The Jericho benchmark and structures like TextWorld utilize procedural generation to present a wide variety of interactive fiction tasks that promote common-sense reasoning [3]. This helps prepare agents for real-world complexities that they may not have been trained on directly.

Overall, procedurally generated environments directly address the overfitting issue associated with static environments by ensuring variability and diversity in training scenarios, thus allowing agents to learn transferable skills that can be applied in novel situations [2][3]. This adaptability is crucial for developing robust AI that can perform effectively in unpredictable, real-world conditions.

1. [1]:  https://ar5iv.org/html/2107.04132, [2107.04132] A Systematic Survey of Text Worlds as Embodied Natural Language Environments
2. [2]:  https://ar5iv.org/html/2107.04132, [2107.04132] A Systematic Survey of Text Worlds as Embodied Natural Language Environments
3. [3]:  https://ar5iv.org/html/2107.04132, [2107.04132] A Systematic Survey of Text Worlds as Embodied Natural Language Environments
4. [4]:  https://ar5iv.org/html/2107.04132, [2107.04132] A Systematic Survey of Text Worlds as Embodied Natural Language Environments
5. [5]:  https://ar5iv.org/html/2012.13681, [2012.13681] Improving the Generalization of End-to-End Driving through Procedural Generation
---
1. [1]:  Passage ID 1: procedural environments, but those environments have limited complexity, and require agents to complete straightforward tasks. Economically creating complex, interactive environments that simulate a significant fraction of real world interactions are still well beyond current simulators or libraries – but required for higher-fidelity interactive worlds that have multiple meaningful paths toward achieving task goals. Generating these environments semi-automatically (e.g. Ammanabrolu et al., 2020a) may offer a partial solution. Independent of tooling, libraries and other middleware offer near-term solutions to more complex environment modeling, much in the same way 3D game engines are regularly coupled with physics engine middleware to dramatically reduce the time required to implement forces, collisions, lighting, and other physics-based modeling. Currently, few analogs exist for text worlds. The addition of a chemistry engine that knows that ice warmed above the freezing point will
2. [2]:  Passage ID 2: help address this need by generating variations of environments centered around specific goal conditions.The TextWorld simulator Côté et al. (2018) allows specifying high-level parameters such as the number of rooms, objects, and winning conditions, then uses a random walk to procedurally generate environment maps in the Inform7 language meeting those specifications, using either forward or backward chaining during generation to verify tasks can be successfully completed in the random environment. As an example, the First TextWorld Problems shared task222https://competitions.codalab.org/competitions/21557 used TextWorld to generate 5k variations of a cooking environment, divided into train, development, and test sets. Similarly, Murugesan et al. Murugesan et al. (2020a) introduce TextWorld CommonSense (TWC), a simple generative environment for household cleaning tasks, modelled as a pick-and-place task where agents must pick up common objects from the floor, and place them in their
3. [3]:  Passage ID 3: for agents to learn common-sense reasoning. Côté et al. Côté et al. (2018) further curate this list, replacing 20 games without scores to those more useful for RL agents. The Jericho benchmark Hausknecht et al. (2020) includes 32 interactive fiction games that support Jericho’s in-built methods for score and world-change detection, out of a total of 56 games known to support these features.4.4 Generative EnvironmentsA difficulty with statically-initialized environments is that because their structure is identical each time the simulation is run, rather than learning general skills, agents quickly overfit to learn solutions to an exact instantiation of a particular task and environment, and rarely generalize to unseen environments Chaudhury et al. (2020). Procedurally generated environments help address this need by generating variations of environments centered around specific goal conditions.The TextWorld simulator Côté et al. (2018) allows specifying high-level parameters
4. [4]:  Passage ID 4: Starspace-generated environments over those generated by a random baseline. In a more restricted domain, Ammanabrolu et al. Ammanabrolu et al. (2019) show that two models, one Markov chain model, the other a generative language model (GPT-2), are capable of generating quests in a cooking environment, while there is a tradeoff between human ratings of quest creativity and coherence.Ammanabrolu et al. Ammanabrolu et al. (2020a) propose a large-scale end-to-end solution to world generation that automatically constructs interactive fiction environments based on a story (such as Sherlock Holmes) provided as input. Their system first builds a knowledge graph of the story by framing KG construction as a question answering task, using their model (AskBERT) to populate this graph. The system then uses either a rule-based baseline or a generative model (GPT-2) to generate textual descriptions of the world from this knowledge graph. User studies show that humans generally prefer these
5. [5]:  Passage ID 5: interaction in self driving.However, most of the existing simulators have a limited number of maps thus fail to provide the diverse training environments for the agent to learn and generalize. It remains challenging to evaluate the generalization of the trained agents. Moreover, it’s hard to modify the existing simulator to apply the procedural generation technique we used in this work. For example, in CARLA, the town is manually designed with hard-coded buildings, road structures and so on. To address the generalization issue, we abstract the driving scene and integrate the procedural generation (PG) in the proposed simulator to generate a huge amount of diverse training and test data.Procedural Generation.Procedural Generation (PG) or Procedural Content Generation (PCG) are first adopted in the video game industry [13]. It refers to the practice of utilizing algorithms to automatically generate game content including levels, maps, racing tracks, etc [25, 26]. Many machine