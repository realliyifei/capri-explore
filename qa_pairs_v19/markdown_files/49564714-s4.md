# Modeling Language Variation and Universals: A Survey on Typological Linguistics for Natural Language Processing

## Question

How does parameter sharing work in multilingual joint learning, and what are its implications for designing models?

## URLs

1. https://ar5iv.org/html/2305.13286
2. https://ar5iv.org/html/2305.14230
3. https://ar5iv.org/html/2209.01530
4. https://ar5iv.org/html/2406.17257
5. https://ar5iv.org/html/2408.01394
6. https://ar5iv.org/html/2112.13619
7. https://ar5iv.org/html/2402.17934
8. https://ar5iv.org/html/2209.05735
9. https://ar5iv.org/html/1911.01464

## Answer

I don't know. The context provided does not include any information about parameter sharing in multilingual joint learning or its implications for designing models. The passages focus primarily on adaptive and domain-specific machine translation, the use of language models, and general aspects of natural language processing (NLP), but they do not address technical details or implications related to parameter sharing in multilingual settings. Thus, the information is insufficient to answer your question.

[1]: https://ar5iv.org/html/2401.14559, No Title
[2]: https://ar5iv.org/html/2401.14559, No Title
[3]: https://ar5iv.org/html/2305.12544, No Title
[4]: https://ar5iv.org/html/2209.12617, No Title
[5]: https://ar5iv.org/html/2209.12617, No Title

[1]: Passage ID 1: common in translation settings, due to the lack of specialised datasets and terminology, or inconsistency and inaccuracy of available in-domain translations (Axelrod et al.,, 2011; Haddow and Koehn,, 2012).Recent advances in language modelling techniques in general and large-scale language models (LLMs) in particular have shown significant potential in improving a wide range of NLP tasks. Inspired by this idea, this research aims to answer two major Research Questions (RQ):RQ1In scenarios involving human interaction and continuous feedback, can we employ language models to improve the quality of adaptive MT at inference time? In the subsequent sections, I will be referring to this question as “Adaptive and Interactive MT”.RQ2In the absence of sufficient in-domain data, can we use pre-trained LLMs to improve the process of NMT domain adaptation? In the following sections, I will be referring to this question as “Domain-specific Text Generation for MT”.Figure 1.1:
[2]: Passage ID 2: I examined how to leverage language modelling techniques in general and LLMs in particular to improve translation features that involve human interaction and continuous feedback, such as adaptive MT, terminology-constrained MT, domain-aware automatic post-editing, auto-suggestion and auto-completion. In the second research question, I addressed a common scenario in the translation industry, namely receiving highly specialised projects, where there is hardly any parallel in-domain data. In such scenarios where there is insufficient in-domain data to fine-tune MT models, producing translations that are consistent with the relevant context is challenging. One way to address this question is through domain-specific text generation with LLMs and then fine-tuning an MT model using the generated bilingual in-domain synthetic data. Furthermore, this question overlaps with the first question, since real-time adaptive MT with LLMs can serve as an alternative approach to address in-domain data
[3]: Passage ID 3: or a handful of other major languages and address mostly Western cultures. However, there are many important questions in social science that require large-scale, multilingual, and multicultural analyses. For instance, how do languages evolve, or how do values vary across cultures? This is an area for future work that can lead to compounding impacts on the social sciences.7 NLP for Online EnvironmentsBackground.The impact of NLP on online environments can be observed through two adversarial phenomena: content generation andmoderation. The rapid generation of content, such as LLM-generated articles and social media updates, can besupported by variousstakeholders. It is very likely that many can achieve high click-through rates to their websites by generating fakenews and disinformation, which raises concerning social issues that necessitatetimely regulation.Conversely, moderation is a form of gate-keeping. By using NLP to monitor and analyze user-generated content on
[4]: Passage ID 4: Knowledge Sources, Deep learning, Machine Learning, Neural-based Techniques, Evaluation Scores1 IntroductionNatural language processing (NLP) is an important branch of artificial intelligence (AI) concerned with text understanding and text generation. The former subject is studied in the sub-branch natural language understanding (NLU) 1; 2; 3 and the latter in natural language generation (NLG) 4; 5. Over the years, both fields, i.e., NLU and NLG developed enormously with an extensive literature which requires nowadays a dedicated discussion of specialized subtasks when presenting approaches or methods thereof despite the fact that a systems understanding of NLP can only be achieved holistically.In this paper, we focus on subtasks of NLP centered around question answering (QA). The task of a QA system is to find an answer (output) in the form of a natural language for a given question (input) usually presented in form of a sentence. While our focus is on QA systems and their
[5]: Passage ID 5: Knowledge Sources, Deep learning, Machine Learning, Neural-based Techniques, Evaluation Scores1 IntroductionNatural language processing (NLP) is an important branch of artificial intelligence (AI) concerned with text understanding and text generation. The former subject is studied in the sub-branch natural language understanding (NLU) 1; 2; 3 and the latter in natural language generation (NLG) 4; 5. Over the years, both fields, i.e., NLU and NLG developed enormously with an extensive literature which requires nowadays a dedicated discussion of specialized subtasks when presenting approaches or methods thereof despite the fact that a systems understanding of NLP can only be achieved holistically.In this paper, we focus on subtasks of NLP centered around question answering (QA). The task of a QA system is to find an answer (output) in the form of a natural language for a given question (input) usually presented in form of a sentence. While our focus is on QA systems and their