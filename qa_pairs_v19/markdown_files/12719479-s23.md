# Survey Article Inter-Coder Agreement for Computational Linguistics

## Question

How does annotator bias affect the interpretation of agreement coefficients like π and κ in computational linguistics?

## URLs

1. https://ar5iv.org/html/2408.15204. [2408.15204] Can Unconfident LLM Annotations Be Used for Confident Conclusions?
2. https://ar5iv.org/html/2411.15634. [2411.15634] "All that Glitters": Approaches to Evaluations with Unreliable Model and Human Annotations
3. https://ar5iv.org/html/2406.17947. [2406.17947] Untitled Document
4. https://ar5iv.org/html/2111.07997. [2111.07997] Annotators with Attitudes: How Annotator Beliefs And Identities Bias Toxic Language Detection
5. https://ar5iv.org/html/2104.00640. [2104.00640] AmbiFC: Fact-Checking Ambiguous Claims with Evidence
6. https://ar5iv.org/html/2404.16958. [2404.16958] A Closer Look at Classification Evaluation Metrics and a Critical Reflection of Common Evaluation Practice
7. https://ar5iv.org/html/2411.04424. [2411.04424] Bayesian Calibration of Win Rate Estimation with LLM Evaluators
8. https://ar5iv.org/html/2409.09412. [2409.09412] Label Convergence: Defining an Upper Performance Bound in Object Recognition through Contradictory Annotations
9. https://ar5iv.org/html/2210.14531. [2210.14531] Unifying Data Perspectivism and Personalization: An Application to Social Norms

## Answer (I don't know?: ✓)

I don't know. The provided context does not contain specific information regarding how annotator bias affects the interpretation of agreement coefficients like π and κ in computational linguistics. The passages mention various researchers and their works related to human label variation, subjective bias, and disagreements in textual inferences, but none specifically address the implications of annotator bias on agreement coefficients. Therefore, the context is insufficient to form a complete answer to the question.

1. [1]:  https://ar5iv.org/html/2404.15720, No Title
2. [2]:  https://ar5iv.org/html/2404.15720, No Title
3. [3]:  https://ar5iv.org/html/2407.14822, No Title
4. [4]:  https://ar5iv.org/html/2402.14101, No Title
5. [5]:  https://ar5iv.org/html/2306.00539, No Title
---
1. [1]:  Passage ID 1: in neural information processing systems, 32.Nie et al. (2020)Yixin Nie, Xiang Zhou, and Mohit Bansal. 2020.What can welearn from collective human opinions on natural language inference data?In Proceedings of the 2020 Conference on Empirical Methods inNatural Language Processing (EMNLP), pages 9131–9143, Online. Associationfor Computational Linguistics.Orlikowski et al. (2023)Matthias Orlikowski, Paul Röttger, Philipp Cimiano, and Dirk Hovy. 2023.TheEcological Fallacy in Annotation: Modeling Human Label Variation goes beyondSociodemographics.In Proceedings of the 61st Annual Meeting of the Associationfor Computational Linguistics Volume 2: Short Papers, pages 1017–1029. ACL.Peterson et al. (2019)Joshua C Peterson, Ruairidh M Battleday, Thomas L Griffiths, and OlgaRussakovsky. 2019.Human uncertainty makes classification more robust.In Proceedings of the IEEE/CVF International Conference onComputer Vision, pages 9617–9626.Plank
2. [2]:  Passage ID 2: in neural information processing systems, 32.Nie et al. (2020)Yixin Nie, Xiang Zhou, and Mohit Bansal. 2020.What can welearn from collective human opinions on natural language inference data?In Proceedings of the 2020 Conference on Empirical Methods inNatural Language Processing (EMNLP), pages 9131–9143, Online. Associationfor Computational Linguistics.Orlikowski et al. (2023)Matthias Orlikowski, Paul Röttger, Philipp Cimiano, and Dirk Hovy. 2023.TheEcological Fallacy in Annotation: Modeling Human Label Variation goes beyondSociodemographics.In Proceedings of the 61st Annual Meeting of the Associationfor Computational Linguistics Volume 2: Short Papers, pages 1017–1029. ACL.Peterson et al. (2019)Joshua C Peterson, Ruairidh M Battleday, Thomas L Griffiths, and OlgaRussakovsky. 2019.Human uncertainty makes classification more robust.In Proceedings of the IEEE/CVF International Conference onComputer Vision, pages 9617–9626.Plank
3. [3]:  Passage ID 3: Linguistics (Volume 1: Long Papers), pages 866–876.Pryzant et al. (2020)Reid Pryzant, Richard Diehl Martinez, Nathan Dass, Sadao Kurohashi, Dan Jurafsky, and Diyi Yang. 2020.Automatically neutralizing subjective bias in text.In Proceedings of the aaai conference on artificial intelligence, volume 34, pages 480–489.Rahutomo et al. (2012)Faisal Rahutomo, Teruaki Kitasuka, and Masayoshi Aritsugi. 2012.Semantic cosine similarity.In The 7th international student conference on advanced science and technology ICAST, volume 4, page 1.Rao and Tetreault (2018)Sudha Rao and Joel Tetreault. 2018.Dear sir or madam, may i introduce the gyafc dataset: Corpus, benchmarks and metrics for formality style transfer.arXiv preprint arXiv:1803.06535.Reif et al. (2021)Emily Reif, Daphne Ippolito, Ann Yuan, Andy Coenen, Chris Callison-Burch, and Jason Wei. 2021.A recipe for arbitrary text style transfer with large language models.arXiv preprint
4. [4]:  Passage ID 4: Ian Kennedy, Breon Haskett, and Alina Arseniev-Koehler. 2021.Reconsidering annotator disagreement about racist language: Noise or signal?In Proceedings of the Ninth International Workshop on Natural Language Processing for Social Media, pages 81–90.Liu et al. (2019)Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.Roberta: A robustly optimized bert pretraining approach.arXiv preprint arXiv:1907.11692.Pavlick and Kwiatkowski (2019)Ellie Pavlick and Tom Kwiatkowski. 2019.Inherent disagreements in human textual inferences.Transactions of the Association for Computational Linguistics, 7:677–694.Plank (2022)Barbara Plank. 2022.The “problem” of human label variation: On ground truth in data, modeling and evaluation.In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 10671–10682, Abu Dhabi, United Arab Emirates.
5. [5]:  Passage ID 5: Pryzant, Richard Diehl Martinez, Nathan Dass, Sadao Kurohashi, DanJurafsky, and Diyi Yang. 2020.Automatically neutralizing subjective bias in text.In The Thirty-Fourth AAAI Conference on ArtificialIntelligence, AAAI 2020, The Thirty-Second Innovative Applications ofArtificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposiumon Educational Advances in Artificial Intelligence, EAAI 2020, New York,NY, USA, February 7-12, 2020, pages 480–489. AAAI Press.Radford et al. (2018)Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. 2018.Improving language understanding by generative pre-training.Radford et al. (2019)Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, IlyaSutskever, et al. 2019.Language models are unsupervised multitask learners.OpenAI blog, 1(8):9.Rao and Tetreault (2018)Sudha Rao and Joel R. Tetreault. 2018.Dear Sir or Madam,May I Introduce the GYAFC Dataset: Corpus, Benchmarks andMetrics