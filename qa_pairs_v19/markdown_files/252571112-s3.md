# SHAP-Based Explanation Methods: A Review for NLP Interpretability

## Question

What are the available methods and algorithms for efficiently approximating SHAP values, and how do they differ from each other?

## URLs

1. https://ar5iv.org/html/2301.00174. [2301.00174] Efficient Methods for Approximating the Shapley Value for Asset Sharing in Energy Communities
2. https://ar5iv.org/html/2310.19245. [2310.19245] Efficient Shapley Performance Attribution for Least-Squares Regression
3. https://ar5iv.org/html/2406.11730. [2406.11730] CHG Shapley: Efficient Data Valuation and Selection towards Trustworthy Machine Learning
4. https://ar5iv.org/html/2301.04727. [2301.04727] A Quantum Algorithm for Shapley Value Estimation
5. https://ar5iv.org/html/2410.06815. [2410.06815] shap-select: Lightweight Feature Selection Using SHAP Values and Regression
6. https://ar5iv.org/html/2410.01917. [2410.01917] Provably Accurate Shapley Value Estimation via Leverage Score Sampling
7. https://ar5iv.org/html/2412.01460. [2412.01460] A Comprehensive Study of Shapley Value in Data Analytics
8. https://ar5iv.org/html/2207.07605. [2207.07605] Algorithms to estimate Shapley value feature attributions
9. https://ar5iv.org/html/2410.06300. [2410.06300] Amortized SHAP values via sparse Fourier function approximation

## Answer (I don't know?: ✗)

There are several methods and algorithms designed to efficiently approximate SHAP (SHapley Additive exPlanations) values, each differing in terms of flexibility, computational efficiency, and applicability to various model types. 

1. **Model-Agnostic Approaches**: These methods are designed to work with any model and include:
   - **Permutation Methods**: These involve rearranging the dataset to assess the impact of each feature on model output [3].
   - **Multilinear Extension**: This approach extends the Shapley value to multilinear functions [3].
   - **FastSHAP**: This method learns a separate model (an explainer) to estimate Shapley values quickly, trained through a process that amortizes the weighted least squares problem across many data examples. FastSHAP provides rapid approximations but can exhibit imperfect accuracy and variability across different training runs [5]. 
   
   Model-agnostic approaches are generally more flexible but may be slower due to their stochastic nature [3].

2. **Model-Specific Approaches**: These methods are tailored to specific types of models and tend to be faster:
   - **LinearSHAP**: This method suits linear models by providing exact Shapley value calculations under certain conditions [2].
   - **TreeSHAP**: Applicable to tree-based models, this method simplifies the computation significantly by leveraging the structure of these models [3].
   - **DeepSHAP**: This is tailored for deep learning models, combining concepts from both Shapley values and DeepLIFT for efficient estimation of feature contributions [2].

Each of these model-specific methods tends to have lower computational load compared to model-agnostic methods for their respective model types. However, they lack the flexibility that model-agnostic methods provide, which can be a disadvantage when working with diverse datasets or model architectures [3].

3. **Sampling and Other Approximation Strategies**: Various approximation strategies exist, such as sampling combinations of features (IME) and weighted linear regression (KernelSHAP) [3]. These methods aim to reduce computational complexity that is typically exponential in the number of features [3]. For instance, KernelSHAP consistently outperforms some other methods in terms of convergence, yielding lower estimation errors with the same number of samples [5].

In summary, the choice of SHAP value approximation method largely depends on the specific application requirements and model architecture. Model-agnostic approaches provide valuable flexibility across various models but at the cost of computational speed, while model-specific approaches deliver efficiency but may limit generalizability.

1. [1]:  https://ar5iv.org/html/2410.06300, [2410.06300] Amortized SHAP values via sparse Fourier function approximation
2. [2]:  https://ar5iv.org/html/2207.07605, [2207.07605] Algorithms to estimate Shapley value feature attributions
3. [3]:  https://ar5iv.org/html/2207.07605, [2207.07605] Algorithms to estimate Shapley value feature attributions
4. [4]:  https://ar5iv.org/html/2406.11730, [2406.11730] CHG Shapley: Efficient Data Valuation and Selection towards Trustworthy Machine Learning
5. [5]:  https://ar5iv.org/html/2207.07605, [2207.07605] Algorithms to estimate Shapley value feature attributions
---
1. [1]:  Passage ID 1: of all possible “coalitions” of other features). Therefore, approximating them and speeding up the computation has received attention in a variety of settings. SHAP value computation can easily dominate the computation time of industry-level machine learning solutions on datasets with millions or more entries (Yang, 2021). Yang (2021) point out that industrial applications sometimes require hundreds of millions of samples to be explained. Examples include feed ranking, ads targeting, and subscription propensity models. In these modeling pipelines, spending tens of hours in model interpretation becomes a significant bottleneck (Yang, 2021) and one usually needs to resort to multiple cores and parallel computing.Significant work has gone into speeding up the computation of SHAP values for a variety of settings. In the (ensemble of) trees setting, full access to the tree structure is assumed. Yang (2021); Bifet et al. (2022) provide theoretical and practical computational speedups to
2. [2]:  Passage ID 2: LinearSHAP [28]LinearConditionalParametricNoNoNoInterventional TreeSHAP [16]TreeMarginalEmpiricalNoYesYesPath-dependent TreeSHAP [16]TreeConditionalEmpirical*NoNoYesDeepLIFT [17]DeepBaselineExactNoNoYesDeepSHAP [15]DeepMarginalEmpiricalNoNoYesDASP [33]DeepBaselineExactNoNoNo♣Shallow ShapNet [34]DeepBaselineExactNoYesYesDeep ShapNet [34]DeepBaselineExactNoNoYesTable 1: Methods to estimate Shapley value explanations. We order approaches based on whether or not they are model-agnostic. Then, there are two factors of complexity. The first is the estimation strategy to handle the exponential complexity of Shapley values. For the model-agnostic approaches, the strategies include semivalue (SV), random
3. [3]:  Passage ID 3: complexity that is exponential in the number of features.The original SHAP paper [15] therefore discussed several strategies for approximating Shapley values, including weighted linear regression (KernelSHAP [15]), sampling featurecombinations(IME [21]), and several model-specific approximations (LinearSHAP [15, 28], MaxSHAP [15], DeepSHAP [15, 29]). Since the original work, other methods have been developed to estimate Shapley value explanations more efficiently, using model-agnostic strategies (permutation [30], multilinear extension [31], FastSHAP [32])andmodel-specific strategies (linear models [28], tree models [16], deep models [29, 33, 34]). Of these two categories, model-agnostic approaches are more flexible but stochastic, whereas model-specific approaches aresignificantly faster to calculate.To better understand the model-agnostic approaches, wepresent a categorization of the approximation algorithmsbased on equivalent mathematical definitions of the Shapley value,
4. [4]:  Passage ID 4: problem of trustworthy machine learning is explaining the decision-making process of models to enhance the transparency of data-driven algorithms. However, the high complexity of machine learning model training and inference processes obscures an intuitive understanding of their internal mechanisms. Approaching trustworthy machine learning from a data-centric perspective (Liu et al., 2023) offers a new perspective for research. For trustworthy model inference, a representative algorithm is the SHAP (Lundberg and Lee, 2017), which quantitatively attributes model outputs to input features, clarifying which features influence specific results the most. SHAP and its variants(Kwon and Zou, 2022b) are widely applied in data analysis and healthcare. For trustworthy model training, the Data Shapley algorithm (Ghorbani and Zou, 2019) stands out. It quantitatively attributes a model’s performance to each training data point, identifying valuable data that improves performance and noisy data that
5. [5]:  Passage ID 5: strategy [54], our empirical evaluation shows that the KernelSHAP estimator consistently outperforms this approach in terms ofits convergence (i.e., consistently lower estimation error given an equal number of samples)(Appendix Figures 6, 7, 8).Finally, the last approach based on the least squares characterization is FastSHAP [32, 59].FastSHAP learns a separatemodel (an explainer) to estimate Shapley values in a single forward pass, and it is trained by amortizing the WLS problem (Eq. 8) across many data examples. As a consequence of its WLS training objective, the globally optimal estimation model is a function that outputs exact Shapley values.Since the explanation model will generally be non-optimal, the resultant estimates offer imperfect accuracy and are random across separate training runs[32]. The major advantage of FastSHAP is that developers can frontload the cost oftraining the explanation model, thereby providing subsequent users with fast Shapley value