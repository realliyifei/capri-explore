# SHAP-Based Explanation Methods: A Review for NLP Interpretability

## Question

What are the available methods and algorithms for efficiently approximating SHAP values, and how do they differ from each other?

## URLs

1. https://ar5iv.org/html/2301.00174. [2301.00174] Efficient Methods for Approximating the Shapley Value for Asset Sharing in Energy Communities
2. https://ar5iv.org/html/2310.19245. [2310.19245] Efficient Shapley Performance Attribution for Least-Squares Regression
3. https://ar5iv.org/html/2406.11730. [2406.11730] CHG Shapley: Efficient Data Valuation and Selection towards Trustworthy Machine Learning
4. https://ar5iv.org/html/2301.04727. [2301.04727] A Quantum Algorithm for Shapley Value Estimation
5. https://ar5iv.org/html/2410.06815. [2410.06815] shap-select: Lightweight Feature Selection Using SHAP Values and Regression
6. https://ar5iv.org/html/2410.01917. [2410.01917] Provably Accurate Shapley Value Estimation via Leverage Score Sampling
7. https://ar5iv.org/html/2412.01460. [2412.01460] A Comprehensive Study of Shapley Value in Data Analytics
8. https://ar5iv.org/html/2207.07605. [2207.07605] Algorithms to estimate Shapley value feature attributions
9. https://ar5iv.org/html/2410.06300. [2410.06300] Amortized SHAP values via sparse Fourier function approximation

## Answer (I don't know?: ✗)

There are several methods and algorithms for efficiently approximating SHAP (SHapley Additive exPlanations) values, each offering unique characteristics and performance trade-offs. These methods can generally be categorized into model-agnostic and model-specific approaches.

1. **Model-Agnostic Approaches**: These methods are designed to work across different types of machine learning models. Examples include:
   - **KernelSHAP**: This method uses weighted linear regression to approximate Shapley values and consistently outperforms other estimators in terms of convergence and lower estimation error [5].
   - **Permutation**: This technique evaluates the importance of features by measuring the change in model performance after randomly permuting feature values [3].
   - **Multilinear Extension**: This approach provides a manner of evaluating the contribution of each feature by extending the value function used in Shapley calculations to higher dimensions [3].
   - **FastSHAP**: FastSHAP is notable for using a separate model, referred to as an explainer, to estimate Shapley values efficiently in a single forward pass. It trains this explanation model by amortizing the weighted least squares problem across multiple data examples, although it may yield imperfect accuracy across separate runs [5].

2. **Model-Specific Approaches**: These methods leverage particular characteristics of specific model types, resulting in faster computations than model-agnostic methods. Examples include:
   - **LinearSHAP**: This method is tailored for linear models, providing exact Shapley values under the assumption of a linear relationship between features [3].
   - **TreeSHAP**: Specific for tree-based models, TreeSHAP can utilize the underlying structure of decision trees to compute SHAP values much faster than general-purpose methods, offering both marginal and empirical solutions [2].
   - **DeepSHAP**: This method applies to deep learning models and combines the ideas behind SHAP with approaches like DeepLIFT, aiming for efficient computation while accounting for the layers and complexities of neural networks [3].

The choice between these methods usually hinges on the specific model being used and the computational resources available. Model-agnostic approaches, while more flexible, tend to be slower and less precise compared to model-specific approaches. Conversely, model-specific methods, despite their speed and efficiency, are constrained to the models they are designed for.

In summary, the landscape of SHAP approximation methods is diverse, characterized by trade-offs between flexibility, speed, and accuracy depending on whether they are model-agnostic or model-specific, and the inherent complexities associated with different types of machine learning models [1][4][5].

1. [1]:  https://ar5iv.org/html/2410.06300, [2410.06300] Amortized SHAP values via sparse Fourier function approximation
2. [2]:  https://ar5iv.org/html/2207.07605, [2207.07605] Algorithms to estimate Shapley value feature attributions
3. [3]:  https://ar5iv.org/html/2207.07605, [2207.07605] Algorithms to estimate Shapley value feature attributions
4. [4]:  https://ar5iv.org/html/2406.11730, [2406.11730] CHG Shapley: Efficient Data Valuation and Selection towards Trustworthy Machine Learning
5. [5]:  https://ar5iv.org/html/2207.07605, [2207.07605] Algorithms to estimate Shapley value feature attributions
---
1. [1]:  Passage ID 1: of all possible “coalitions” of other features). Therefore, approximating them and speeding up the computation has received attention in a variety of settings. SHAP value computation can easily dominate the computation time of industry-level machine learning solutions on datasets with millions or more entries (Yang, 2021). Yang (2021) point out that industrial applications sometimes require hundreds of millions of samples to be explained. Examples include feed ranking, ads targeting, and subscription propensity models. In these modeling pipelines, spending tens of hours in model interpretation becomes a significant bottleneck (Yang, 2021) and one usually needs to resort to multiple cores and parallel computing.Significant work has gone into speeding up the computation of SHAP values for a variety of settings. In the (ensemble of) trees setting, full access to the tree structure is assumed. Yang (2021); Bifet et al. (2022) provide theoretical and practical computational speedups to
2. [2]:  Passage ID 2: LinearSHAP [28]LinearConditionalParametricNoNoNoInterventional TreeSHAP [16]TreeMarginalEmpiricalNoYesYesPath-dependent TreeSHAP [16]TreeConditionalEmpirical*NoNoYesDeepLIFT [17]DeepBaselineExactNoNoYesDeepSHAP [15]DeepMarginalEmpiricalNoNoYesDASP [33]DeepBaselineExactNoNoNo♣Shallow ShapNet [34]DeepBaselineExactNoYesYesDeep ShapNet [34]DeepBaselineExactNoNoYesTable 1: Methods to estimate Shapley value explanations. We order approaches based on whether or not they are model-agnostic. Then, there are two factors of complexity. The first is the estimation strategy to handle the exponential complexity of Shapley values. For the model-agnostic approaches, the strategies include semivalue (SV), random
3. [3]:  Passage ID 3: complexity that is exponential in the number of features.The original SHAP paper [15] therefore discussed several strategies for approximating Shapley values, including weighted linear regression (KernelSHAP [15]), sampling featurecombinations(IME [21]), and several model-specific approximations (LinearSHAP [15, 28], MaxSHAP [15], DeepSHAP [15, 29]). Since the original work, other methods have been developed to estimate Shapley value explanations more efficiently, using model-agnostic strategies (permutation [30], multilinear extension [31], FastSHAP [32])andmodel-specific strategies (linear models [28], tree models [16], deep models [29, 33, 34]). Of these two categories, model-agnostic approaches are more flexible but stochastic, whereas model-specific approaches aresignificantly faster to calculate.To better understand the model-agnostic approaches, wepresent a categorization of the approximation algorithmsbased on equivalent mathematical definitions of the Shapley value,
4. [4]:  Passage ID 4: problem of trustworthy machine learning is explaining the decision-making process of models to enhance the transparency of data-driven algorithms. However, the high complexity of machine learning model training and inference processes obscures an intuitive understanding of their internal mechanisms. Approaching trustworthy machine learning from a data-centric perspective (Liu et al., 2023) offers a new perspective for research. For trustworthy model inference, a representative algorithm is the SHAP (Lundberg and Lee, 2017), which quantitatively attributes model outputs to input features, clarifying which features influence specific results the most. SHAP and its variants(Kwon and Zou, 2022b) are widely applied in data analysis and healthcare. For trustworthy model training, the Data Shapley algorithm (Ghorbani and Zou, 2019) stands out. It quantitatively attributes a model’s performance to each training data point, identifying valuable data that improves performance and noisy data that
5. [5]:  Passage ID 5: strategy [54], our empirical evaluation shows that the KernelSHAP estimator consistently outperforms this approach in terms ofits convergence (i.e., consistently lower estimation error given an equal number of samples)(Appendix Figures 6, 7, 8).Finally, the last approach based on the least squares characterization is FastSHAP [32, 59].FastSHAP learns a separatemodel (an explainer) to estimate Shapley values in a single forward pass, and it is trained by amortizing the WLS problem (Eq. 8) across many data examples. As a consequence of its WLS training objective, the globally optimal estimation model is a function that outputs exact Shapley values.Since the explanation model will generally be non-optimal, the resultant estimates offer imperfect accuracy and are random across separate training runs[32]. The major advantage of FastSHAP is that developers can frontload the cost oftraining the explanation model, thereby providing subsequent users with fast Shapley value