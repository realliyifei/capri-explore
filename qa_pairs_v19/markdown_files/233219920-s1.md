# Relational World Knowledge Representation in Contextual Language Models: A Review

## Question

What distinguishes encyclopedic knowledge bases from commonsense knowledge bases, and could you provide examples of each?

## URLs

1. https://ar5iv.org/html/2411.03964. [2411.03964] What Really is Commonsense Knowledge?
2. https://ar5iv.org/html/2212.13428. [2212.13428] A Survey on Knowledge-Enhanced Pre-trained Language Models
3. https://ar5iv.org/html/2302.04752. [2302.04752] Benchmarks for Automated Commonsense Reasoning: A Survey
4. https://ar5iv.org/html/2211.00989. [2211.00989] How Stable is Knowledge Base Knowledge?
5. https://ar5iv.org/html/2001.04170. [2001.04170] Joint Reasoning for Multi-Faceted Commonsense Knowledge
6. https://ar5iv.org/html/2303.16421. [2303.16421] ChatGPT is a Knowledgeable but Inexperienced Solver: An Investigation of Commonsense Problem in Large Language Models
7. https://ar5iv.org/html/2208.09292. [2208.09292] UnCommonSense: Informative Negative Knowledge about Everyday Concepts
8. https://ar5iv.org/html/2306.08302. [2306.08302] Unifying Large Language Models and Knowledge Graphs: A Roadmap

## Answer (I don't know?: ✗)

Encyclopedic knowledge bases and commonsense knowledge bases differ primarily in their focus and the type of knowledge they represent. 

Encyclopedic knowledge bases are collections that emphasize factual knowledge about real-world objects, concepts, or events. This knowledge is typically presented in structured formats, such as triples that consist of a head entity, a tail entity, and their relationship. For example, a triple in a knowledge base such as DBPedia might be (Barack Obama, birthPlace, Honolulu), which conveys a factual relationship about Obama’s birthplace [4]. Such knowledge bases are designed to provide reliable, factual information and are typically used for applications requiring precision in established information.

In contrast, commonsense knowledge bases focus on knowledge that reflects everyday reasoning and understanding of social norms and human behavior. This type of knowledge accounts for the implicit knowledge that people use to navigate their daily lives and engage in decision-making. Examples of commonsense knowledge bases include ConceptNet and ASER, which provide knowledge encompassing more subjective or culturally influenced understandings of the world, such as the relationship between actions and typical human reactions [4][5]. 

The distinction also lies in the types of reasoning these knowledge bases support. While encyclopedic knowledge bases facilitate factual retrieval and explicit relationships, commonsense knowledge bases enable reasoning about everyday situations and expectations that are not always explicitly detailed in factual terms. This difference underscores the complementarity of both types of knowledge: encyclopedic knowledge bases provide a foundational layer of hard facts, while commonsense knowledge fills in the gaps of inference and social understanding that pure factual knowledge cannot address [4][5].

In summary, encyclopedic knowledge bases are characterized by their structure and factual nature, as seen in databases like DBPedia, while commonsense knowledge bases, such as ConceptNet, enrich our understanding with nuanced insights into human interaction and social constructs [4] [5].

1. [1]:  https://ar5iv.org/html/2305.12544, No Title
2. [2]:  https://ar5iv.org/html/2303.16421, [2303.16421] ChatGPT is a Knowledgeable but Inexperienced Solver: An Investigation of Commonsense Problem in Large Language Models
3. [3]:  https://ar5iv.org/html/2303.16421, [2303.16421] ChatGPT is a Knowledgeable but Inexperienced Solver: An Investigation of Commonsense Problem in Large Language Models
4. [4]:  https://ar5iv.org/html/2305.12544, No Title
5. [5]:  https://ar5iv.org/html/2212.13428, [2212.13428] A Survey on Knowledge-Enhanced Pre-trained Language Models
---
1. [1]:  Passage ID 1: construction of such knowledge bases is an interesting direction and requires many challenges to be addressed, such as knowledge coverage, factuality of the knowledge, knowledge linking, and so on. These challenges are amplified when the knowledge bases are constructed for specialized domains such as healthcare or chemistry. However, once these problems are addressed, researchers will be able to utilize LLMs to dynamically curate a knowledge base from up-to-date raw text and an ontology for complex applications such as tracking medication interactions from articles from PubMed.3.General and Cultural Commonsense. Cultural knowledge available in NLP models is often limited to a handful of Western cultures and does not account for the vast diversity of the cultural views of the world (Arora et al., 2023). With the increasingly wide spread of NLP applications, this limitation may result in direct adverse impact on the users of these applications, by not accounting for their values,
2. [2]:  Passage ID 2: these types of commonsense knowledge require a deeper understanding of human behavior and social interactions, and they appear infrequently in text corpora. This suggests that current LLMs need to be improved on these domains of commonsense, which requires models to go beyond superficial semantic understanding and learn about human behaviors.4 Are GPTs Aware of the Commonsense Knowledge for Answering a Question?In Section 3, we found that GPTs perform well on commonsense QA datasets. This intrigues us to explore whether GPTs are experienced experts that are aware of what knowledge is needed and can leverage the knowledge for question answering, or if they are inexperienced problem solvers that rely on memorizing a large amount of information that covers the questions.To answer this question, we sample 20 questions from each commonsense QA dataset and ask ChatGPT “What knowledge is necessary for answering this question?”. For datasets that have ≥\geq10 wrong answered
3. [3]:  Passage ID 3: Are GPTs aware of the underlying commonsense knowledge for answering a specific question?(4) Can GPTs effectively leverage commonsense for answering questions?Answering these questions is crucial for understanding the capabilities and limitations of LLMs and for developing better methods to evaluate and improve their performance on commonsense tasks.In this paper, to evaluate models’ ability in answering commonsense questions, we use 11 commonsense QA datasets that cover 8 diverse commonsense domains including physical, social, temporal, and numerical reasoning, etc. Firstly, We ask models to answer these questions and evaluate the accuracy of their responses. To evaluate whether large language models have an understanding of the necessary commonsense knowledge for answering these questions, we ask the model to describe the necessary knowledge and evaluate whether the descriptions are accurate. To assess whether large language models can recall and describe the necessary knowledge
4. [4]:  Passage ID 4: it is debatable whether language models truly reason or just generate statistically-alike sequences, and to what extent AI systems can learn to reason from few-shot exemplars.4 Knowledge BasesBackground.A knowledge base is a collection of facts about real-world objects, abstract concepts, or events. The knowledge inside a knowledge base is usually represented as a triplet consisting of a head entity, a tail entity, and their relationships. For instance (Barack Obama, birthPlace, Honolulu) is an example of a triplet indicating a place-of-birth relationship. Some knowledge bases focus more on factual knowledge, such as DBPedia (Auer et al., 2007) and YAGO (Suchanek et al., 2007), while others focus more on commonsense, such as ConceptNet (Speer et al., 2017) and ASER (Zhang et al., 2020).Knowledge bases have found use in many downstream applications, including relation extraction (Weston et al., 2013), machine reading (Yang and Mitchell, 2017), and reflection generation
5. [5]:  Passage ID 5: contrast to encyclopedic knowledge, domain knowledge is knowledge of a specific, specialized field discipline, such as biomedical, e-commerce, and sentiment, which are explored a lot, as shown in Table II.Biomedical knowledge is usually represented as triples containing symptoms or diseases as head or tail entities, e.g., (bacterial pneumonia, with associated morphology, inflammation).E-commerce knowledge is formed with product names, while their descriptions are represented by a set of phrases.For example, the product “iPhone XS” is described as “iOS; 4G signal; T-Mobile service; OLED screen; …”.Sentiment knowledge could be represented in many ways, including sentiment words, word polarity, etc.3.2 Formats of KnowledgeThere are four formats of knowledge that are often incorporated into PLMs, i.e., entity lexicon, knowledge graph, plain text, and labeled images.3.2.1 Entity LexiconTo incorporate knowledge through entities, we need to integrate knowledge embeddings