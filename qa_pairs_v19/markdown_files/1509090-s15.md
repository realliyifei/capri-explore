# Multiword Expression Processing: A Survey under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license Computational Linguistics

## Question

What challenges are associated with using annotated data sets in supervised methods for discovering multiword expressions?

## URLs

1. https://ar5iv.org/html/2405.08497
2. https://ar5iv.org/html/2208.07832
3. https://ar5iv.org/html/2403.02009
4. https://ar5iv.org/html/2204.10050
5. https://ar5iv.org/html/2411.02610
6. https://ar5iv.org/html/2007.11381
7. https://ar5iv.org/html/2406.15175
8. https://ar5iv.org/html/2410.14074
9. https://ar5iv.org/html/2405.02861

## Answer

The challenges associated with using annotated data sets in supervised methods for discovering multiword expressions (MWEs) primarily stem from the unique linguistic characteristics of MWEs, the variability in idiomatic expressions, and the limitations related to training data availability.

Firstly, MWEs pose a significant challenge in natural language processing (NLP) because their linguistic behavior—spanning syntactic and semantic aspects—differs markedly from that of generic word combinations. This variability complicates the task of accurately identifying MWEs within texts, as the meanings and syntactic roles of these expressions often cannot be deduced from their individual components alone [1] [2]. 

Secondly, the reliance on annotated datasets can introduce additional difficulties. For example, the accuracy of the models depends heavily on the quality and comprehensiveness of the annotations. Inadequate or inconsistent annotations may lead to poor model performance. Furthermore, the challenge of scaling annotated datasets to different languages and contexts adds to the complexity, as was illustrated by the introduction of datasets in multiple languages like English, Portuguese, and Galician [1] [2]. 

Moreover, the task often demands extensive amounts of training data to effectively capture the subtleties of MWEs. The context-dependent nature of idiomatic expressions means that models require a substantial array of examples to generalize well across different instances [1]. However, this presupposes that sufficient annotated training data is available, which is often not the case in practice, as noted in the context regarding the shortage of available training data for top-performing methods [3] [4].

Lastly, even when deep neural models prove effective in identifying MWEs, this does not negate the potential benefits of integrating linguistically motivated features into these methods. The future direction suggests that further exploration through ablation studies may enhance understanding and improve the impact of these features, potentially leading to more accurate models [3] [4]. 

In summary, the main challenges faced when using annotated datasets in supervised methods for discovering MWEs include the distinct linguistic properties of MWEs that complicate identification, the dependence on high-quality annotations, the need for substantial training data, and the exploration of integrating linguistic features with powerful neural models. These factors collectively impede the development and effectiveness of supervised learning approaches in the domain of multiword expressions in NLP.

[1]: https://ar5iv.org/html/2204.10050, [2204.10050] SemEval-2022 Task 2: Multilingual Idiomaticity Detection and Sentence Embedding
[2]: https://ar5iv.org/html/2204.10050, [2204.10050] SemEval-2022 Task 2: Multilingual Idiomaticity Detection and Sentence Embedding
[3]: https://ar5iv.org/html/2204.10050, [2204.10050] SemEval-2022 Task 2: Multilingual Idiomaticity Detection and Sentence Embedding
[4]: https://ar5iv.org/html/2204.10050, [2204.10050] SemEval-2022 Task 2: Multilingual Idiomaticity Detection and Sentence Embedding
[5]: https://ar5iv.org/html/2401.15393, No Title

[1]: Passage ID 1: at identifying whether a sentence contains an idiomatic expression, and (b) a task based on semantic text similarity which requires the model to adequately represent potentially idiomatic expressions in context. Each Subtask includes different settings regarding the amount of training data. Besides the task description, this paper introduces the datasets in English, Portuguese, and Galician and their annotation procedure, the evaluation metrics, and a summary of the participant systems and their results. The task had close to 100 registered participants organised into twenty five teams making over 650 and 150 submissions in the practice and evaluation phases respectively.1 IntroductionMultiword Expressions (MWEs) are a challenge for natural language processing (NLP), as their linguistic behaviour (e.g., syntactic, semantic) differs from that of generic word combinations Baldwin and Kim (2010); Ramisch and Villavicencio (2018). Moreover, MWEs are pervasive in all domains Biber
[2]: Passage ID 2: at identifying whether a sentence contains an idiomatic expression, and (b) a task based on semantic text similarity which requires the model to adequately represent potentially idiomatic expressions in context. Each Subtask includes different settings regarding the amount of training data. Besides the task description, this paper introduces the datasets in English, Portuguese, and Galician and their annotation procedure, the evaluation metrics, and a summary of the participant systems and their results. The task had close to 100 registered participants organised into twenty five teams making over 650 and 150 submissions in the practice and evaluation phases respectively.1 IntroductionMultiword Expressions (MWEs) are a challenge for natural language processing (NLP), as their linguistic behaviour (e.g., syntactic, semantic) differs from that of generic word combinations Baldwin and Kim (2010); Ramisch and Villavicencio (2018). Moreover, MWEs are pervasive in all domains Biber
[3]: Passage ID 3: training data is not available.While the top performing methods across this task have been driven by deep neural models independent of linguistic features, we highlight that this does not imply that the addition of linguistically motivated features does not lead to improvements on the task. Instead, it points to the possibility of integrating these methods into the more powerful neural models in future work where an ablation study might shed more light on the impact of each feature.AcknowledgementsThis work was partially supported by the UK EPSRC grant EP/T02450X/1, by the CDT in Speech and Language Technologies and their Applications (UKRI grant number EP/S023062/1), by a Ramón y Cajal grant (RYC2019-028473-I), and by the grant ED431F 2021/01 (Galician Government).ReferencesBaldwin and Kim (2010)Timothy Baldwin and Su Nam Kim. 2010.Multiword expressions.In Nitin Indurkhya and Fred J. Damerau, editors, Handbook ofNatural Language Processing, pages 267–292. CRC
[4]: Passage ID 4: training data is not available.While the top performing methods across this task have been driven by deep neural models independent of linguistic features, we highlight that this does not imply that the addition of linguistically motivated features does not lead to improvements on the task. Instead, it points to the possibility of integrating these methods into the more powerful neural models in future work where an ablation study might shed more light on the impact of each feature.AcknowledgementsThis work was partially supported by the UK EPSRC grant EP/T02450X/1, by the CDT in Speech and Language Technologies and their Applications (UKRI grant number EP/S023062/1), by a Ramón y Cajal grant (RYC2019-028473-I), and by the grant ED431F 2021/01 (Galician Government).ReferencesBaldwin and Kim (2010)Timothy Baldwin and Su Nam Kim. 2010.Multiword expressions.In Nitin Indurkhya and Fred J. Damerau, editors, Handbook ofNatural Language Processing, pages 267–292. CRC
[5]: Passage ID 5: editors,Multiword Expressions in Lexical Resources. Linguistic, Lexicographicand Computational Perspectives, Phraseology and Multiword Expressions.Language Science Press, Berlin.Seo et al. (2017)Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, and Hannaneh Hajishirzi. 2017.Bidirectionalattention flow for machine comprehension.In Proceedings of the Fifth International Conference onLearning Representations (ICLR 2017).Shwartz and Dagan (2019)Vered Shwartz and Ido Dagan. 2019.Still a pain in theneck: Evaluating text representations on lexical composition.Transactions of the Association for Computational Linguistics,7:403–419.Sinha et al. (2021)Koustuv Sinha, Robin Jia, Dieuwke Hupkes, Joelle Pineau, Adina Williams, andDouwe Kiela. 2021.Maskedlanguage modeling and the distributional hypothesis: Order word matterspre-training for little.In Proceedings of the 2021 Conference on EmpiricalMethods in Natural Language Processing, pages 2888–2913,