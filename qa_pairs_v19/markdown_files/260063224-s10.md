# How to Control Sentiment in Text Generation: A Survey of the State-of-the-Art in Sentiment-Control Techniques

## Question

How are recent methods modifying token distribution to control sentiment in text generation?

## URLs

1. https://ar5iv.org/html/2103.00676. [2103.00676] Token-Modification Adversarial Attacks for Natural Language Processing: A Survey
2. https://ar5iv.org/html/2405.11891. [2405.11891] Unveiling and Manipulating Prompt Influence in Large Language Models
3. https://ar5iv.org/html/2103.11070. [2103.11070] Attribute Alignment: Controlling Text Generation from Pre-trained Language Models
4. https://ar5iv.org/html/2212.10938. [2212.10938] Critic-Guided Decoding for Controlled Text Generation
5. https://ar5iv.org/html/2408.12599. [2408.12599] Controllable Text Generation for Large Language Models: A Survey
6. https://ar5iv.org/html/2404.05143. [2404.05143] Plug and Play with Prompts: A Prompt Tuning Approach for Controlling Text Generation
7. https://ar5iv.org/html/2402.11218. [2402.11218] Controlled Text Generation for Large Language Model with Dynamic Attribute Graphs
8. https://ar5iv.org/html/2311.07430. [2311.07430] Controlled Text Generation for Black-box Language Models via Score-based Progressive Editor
9. https://ar5iv.org/html/2405.01490. [2405.01490] Controllable Text Generation in the Instruction-Tuning Era
10. https://ar5iv.org/html/2311.14479. [2311.14479] Controlled Text Generation via Language Model Arithmetic

## Answer (I don't know?: ✗)

Recent methods for controlling sentiment in text generation through token distribution modifications are focused on improving the alignment between generated text and desired attributes, such as sentiment or topic. By utilizing advancements in controllable text generation (CTG), these approaches aim to manage how language models produce text that aligns with specific user intentions and values.

One key strategy involves the use of a constraint function, which shapes the decoding process of the language model. This function informs the model about the specific attributes (like sentiment) to consider during text generation [2]. Researchers have highlighted the use of alignment functions that guide pre-trained language models without altering their underlying parameters. This method contrasts with traditional approaches, which often employ a discriminator to perturb the token-level distribution. Instead, alignment functions leverage the same data to direct the model's outputs towards the target sentiment efficiently [5].

Furthermore, advancements in understanding token distributions across layers of language models allow researchers to conceptualize these distributions' evolution over outputs. However, there has been a noted lack of systematic evaluation across different datasets and linguistic patterns, which presents challenges in applying these findings universally across various large language models (LLMs) [3]. 

In addition, surveys on sentiment control within CTG emphasize the importance of managing sentiment effectively in generated text, noting the shortcomings of conventional CTG methods that are primarily statistical in nature [4]. By advocating for improvements through representation disentanglement and causal inference, researchers are seeking to refine how sentiment is integrated into the text generation process [4].

Overall, recent methods are enhancing the control over sentiment expression in LLM outputs through a combination of alignment functions and improved understanding of token distributions, while also challenging and re-evaluating traditional approaches to ensure more reliable and value-aligned text generation.

1. [1]:  https://ar5iv.org/html/2212.10938, [2212.10938] Critic-Guided Decoding for Controlled Text Generation
2. [2]:  https://ar5iv.org/html/2405.01490, [2405.01490] Controllable Text Generation in the Instruction-Tuning Era
3. [3]:  https://ar5iv.org/html/2405.11891, [2405.11891] Unveiling and Manipulating Prompt Influence in Large Language Models
4. [4]:  https://ar5iv.org/html/2408.12599, [2408.12599] Controllable Text Generation for Large Language Models: A Survey
5. [5]:  https://ar5iv.org/html/2103.11070, [2103.11070] Attribute Alignment: Controlling Text Generation from Pre-trained Language Models
---
1. [1]:  Passage ID 1: ∗∗\ast Work done during an internship at NAVER AI Lab.††footnotetext: ††\dagger Corresponding authors.1 IntroductionRecent breakthroughs in large language models (LMs) have allowed them to generate sentences that are as much more natural and plausible as real-world text  Radford et al. (2019); Brown et al. (2020); Kim et al. (2021).However, there are potential risks in simply generating text by following the training data distribution because the real-world data include harmful, offensive, or socially biased expressions Lu et al. (2022); Liu et al. (2021); Gehman et al. (2020); Hosseini et al. (2017).The LMs also may generate misinformation, the so-called Hallucination problem, leading to untrustworthy generation results Holtzman et al. (2018).To mitigate these risks and accomplish the text generation goals, many methods for controlling the language models have been proposed Keskar et al. (2019); Krause et al. (2020); Yang and Klein (2021); Dathathri et al. (2019), but
2. [2]:  Passage ID 2: in the future.1 IntroductionRecent advances in Natural Language Processing (NLP) (Jones, 1994; Chowdhary & Chowdhary, 2020) have highlighted emergent capabilities of Large Language Models (LLMs) on a wide range of NLP tasks (Wei et al., 2022; Brown et al., 2020). Despite their impressive performance, they can be hard to control and produce outputs that are not in line with human intentions and values (Zamfirescu-Pereira et al., 2023; Cao et al., 2023). To achieve widespread adoption, LLMs must demonstrate that their outputs can be reliably controlled and aligned with the values and will of the end user.Over the years, several methods have risen to the challenge of controllable text generation (Yang & Klein, 2021; Lu et al., 2022; Liu et al., 2021; Dathathri et al., 2020; Mireshghallah et al., 2022; Zhang et al., 2023a). These methods typically employ a constraint function and use signals from this function to modify the decoding procedure, sample from the LLM, or perform
3. [3]:  Passage ID 3: A Expanding the Theory of token distributionsRecent studies (Nostalgebraist, 2020; Geva et al., 2021; 2022; Dar et al., 2023) indicate that token hidden states across layers can be projected into the embedding space utilizing the language modeling head (LM head). Consequently, token representations can be conceptualized as evolving distributions over the vocabulary. Nevertheless, when applying this finding to recent LLMs for designing our explanation method, several gaps emerge. Firstly, a systematic evaluation of token distributions across datasets with different linguistic patterns, including syntax, morphology, and semantics, is lacking. While much research centers on GPT2-series models, the adaptability of these findings to other latest LLMs, like LLaMA (Touvron et al., 2023), is insufficiently explored. Additionally, most studies focus on the last token that is utilized to make predictions, overlooking the effects of using LM head to project other input tokens. To address these
4. [4]:  Passage ID 4: et al., 1986), LSTMs (Hochreiter and Schmidhuber, 1997), GANs (Radford et al., 2016), Transformers (Vaswani et al., 2017), and VAEs (Kingma and Welling, 2022), with a strong focus on real-world applications.How to Control Sentiment in Text Generation: A Survey of the State-of-the-Art in Sentiment-Control Techniques (Lorandi and Belz, 2023) provides an in-depth look at sentiment control within CTG, highlighting the challenges and importance of managing sentiment in generated text.A Recent Survey on Controllable Text Generation: A Causal Perspective (Wang et al., 2024b) critiques traditional CTG methods focused on statistical correlations, advocating for improvements via representation disentanglement, causal inference, and knowledge augmentation.A Survey of Controllable Text Generation using Transformer-based Pre-trained Language Models (Zhang et al., 2023b) focuses on Transformer-based pre-trained models in CTG. While it discusses the evolving capabilities and limitations of
5. [5]:  Passage ID 5: representations.In contrast to recent efforts on training a discriminator to perturb the token level distribution for an attribute, we use the same data to learn an alignment function to guide the pre-trained, non-controlled language model to generate texts with the target attribute without changing the original language model parameters.We evaluate our method on sentiment- and topic-controlled generation,and show large performance gains over previous methods while retaining fluency and diversity.1 IntroductionWhile large pre-trained language models (LM) have advanced text generation with coherent language by training on a large amount of unlabeled data Radford et al. (2018); Yang et al. (2019); Raffel et al. (2020), they are not controllable. For instance, given the prompt “The issue focused on”, GPT-2 Radford et al. (2019) can generate a high-quality sentence, but it cannot take extra input such as “positive” or “business” to guide the sentence towards a positive sentiment