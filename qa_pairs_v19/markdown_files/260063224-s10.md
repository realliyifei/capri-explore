# How to Control Sentiment in Text Generation: A Survey of the State-of-the-Art in Sentiment-Control Techniques

## Question

How are recent methods modifying token distribution to control sentiment in text generation?

## URLs

1. https://ar5iv.org/html/2103.00676. [2103.00676] Token-Modification Adversarial Attacks for Natural Language Processing: A Survey
2. https://ar5iv.org/html/2405.11891. [2405.11891] Unveiling and Manipulating Prompt Influence in Large Language Models
3. https://ar5iv.org/html/2103.11070. [2103.11070] Attribute Alignment: Controlling Text Generation from Pre-trained Language Models
4. https://ar5iv.org/html/2212.10938. [2212.10938] Critic-Guided Decoding for Controlled Text Generation
5. https://ar5iv.org/html/2408.12599. [2408.12599] Controllable Text Generation for Large Language Models: A Survey
6. https://ar5iv.org/html/2404.05143. [2404.05143] Plug and Play with Prompts: A Prompt Tuning Approach for Controlling Text Generation
7. https://ar5iv.org/html/2402.11218. [2402.11218] Controlled Text Generation for Large Language Model with Dynamic Attribute Graphs
8. https://ar5iv.org/html/2311.07430. [2311.07430] Controlled Text Generation for Black-box Language Models via Score-based Progressive Editor
9. https://ar5iv.org/html/2405.01490. [2405.01490] Controllable Text Generation in the Instruction-Tuning Era
10. https://ar5iv.org/html/2311.14479. [2311.14479] Controlled Text Generation via Language Model Arithmetic

## Answer (I don't know?: ✗)

The context provided highlights various approaches and findings related to controlling sentiment in text generation using large language models (LLMs). Recent research indicates that controlling the sentiment in generated text involves modifications to token distributions within these models.

One of the primary approaches to controlling sentiment is through controllable text generation (CTG) techniques. These methods generally incorporate a constraint function that influences the decoding process to align generated outputs with specific sentiments or user intentions [2]. By leveraging signals from this constraint function, the sampling from the LLM can be tailored to produce text with desired emotional undertones, thereby modifying the probability distribution of tokens generated in response to specific prompts [2].

Further exploration of token distributions indicates potential for sentiment control through the manipulation of token hidden states across layers in LLMs. This involves projecting these states into embedding spaces, allowing for a more nuanced understanding and modification of how individual tokens contribute to the overall sentiment of generated text [3]. Specifically, it has been noted that existing studies often overlook the implications of using the language modeling head to project not just the last token but also other input tokens which can influence sentiment [3]. This suggests that a systematic evaluation of token distributions can yield new insights into how sentiments can be articulated more effectively based on linguistic patterns.

Several recent surveys on the state-of-the-art sentiment control techniques also delve into the challenges faced in this area. For instance, the survey titled *How to Control Sentiment in Text Generation* discusses the spectrum of techniques and highlights the importance of managing sentiment within generated text, addressing both the theoretical and practical implications of these control mechanisms [5]. It implies that understanding the underlying distributions of tokens and how they can be manipulated is critical in developing better sentiment control methods [5].

Moreover, recent critiques of traditional CTG methods point out the need for improvements that go beyond merely statistical correlations, advocating for techniques that incorporate representation disentanglement and causal inference [5]. This suggests a shift towards more sophisticated models that consider the underlying structures influencing sentiment rather than relying solely on observed patterns.

In summary, recent methods in controlling sentiment in text generation largely focus on modifying token distributions through constraint functions, deeper analyses of token hidden states, and the application of advanced techniques that aim to disentangle sentiment from mere statistical associations. These developments highlight a promising direction in which NLP research may proceed to better align generated text with human emotional and contextual expectations [2][3][5].

1. [1]:  https://ar5iv.org/html/2212.10938, [2212.10938] Critic-Guided Decoding for Controlled Text Generation
2. [2]:  https://ar5iv.org/html/2405.01490, [2405.01490] Controllable Text Generation in the Instruction-Tuning Era
3. [3]:  https://ar5iv.org/html/2405.11891, [2405.11891] Unveiling and Manipulating Prompt Influence in Large Language Models
4. [4]:  https://ar5iv.org/html/2410.00427, No Title
5. [5]:  https://ar5iv.org/html/2408.12599, [2408.12599] Controllable Text Generation for Large Language Models: A Survey
---
1. [1]:  Passage ID 1: ∗∗\ast Work done during an internship at NAVER AI Lab.††footnotetext: ††\dagger Corresponding authors.1 IntroductionRecent breakthroughs in large language models (LMs) have allowed them to generate sentences that are as much more natural and plausible as real-world text  Radford et al. (2019); Brown et al. (2020); Kim et al. (2021).However, there are potential risks in simply generating text by following the training data distribution because the real-world data include harmful, offensive, or socially biased expressions Lu et al. (2022); Liu et al. (2021); Gehman et al. (2020); Hosseini et al. (2017).The LMs also may generate misinformation, the so-called Hallucination problem, leading to untrustworthy generation results Holtzman et al. (2018).To mitigate these risks and accomplish the text generation goals, many methods for controlling the language models have been proposed Keskar et al. (2019); Krause et al. (2020); Yang and Klein (2021); Dathathri et al. (2019), but
2. [2]:  Passage ID 2: in the future.1 IntroductionRecent advances in Natural Language Processing (NLP) (Jones, 1994; Chowdhary & Chowdhary, 2020) have highlighted emergent capabilities of Large Language Models (LLMs) on a wide range of NLP tasks (Wei et al., 2022; Brown et al., 2020). Despite their impressive performance, they can be hard to control and produce outputs that are not in line with human intentions and values (Zamfirescu-Pereira et al., 2023; Cao et al., 2023). To achieve widespread adoption, LLMs must demonstrate that their outputs can be reliably controlled and aligned with the values and will of the end user.Over the years, several methods have risen to the challenge of controllable text generation (Yang & Klein, 2021; Lu et al., 2022; Liu et al., 2021; Dathathri et al., 2020; Mireshghallah et al., 2022; Zhang et al., 2023a). These methods typically employ a constraint function and use signals from this function to modify the decoding procedure, sample from the LLM, or perform
3. [3]:  Passage ID 3: A Expanding the Theory of token distributionsRecent studies (Nostalgebraist, 2020; Geva et al., 2021; 2022; Dar et al., 2023) indicate that token hidden states across layers can be projected into the embedding space utilizing the language modeling head (LM head). Consequently, token representations can be conceptualized as evolving distributions over the vocabulary. Nevertheless, when applying this finding to recent LLMs for designing our explanation method, several gaps emerge. Firstly, a systematic evaluation of token distributions across datasets with different linguistic patterns, including syntax, morphology, and semantics, is lacking. While much research centers on GPT2-series models, the adaptability of these findings to other latest LLMs, like LLaMA (Touvron et al., 2023), is insufficiently explored. Additionally, most studies focus on the last token that is utilized to make predictions, overlooking the effects of using LM head to project other input tokens. To address these
4. [4]:  Passage ID 4: familiar with all existing fields of study and struggle to phrase their queries using the correct terminology. Due to the absence of datasets that map search goals expressed in layman’s terms to NLP topics, we created a synthetic multi-class dataset using GPT-3.5-Turbo (version: 0613) OpenAI (2022). We prompted the LLM to generate questions on the 12 main topics in our taxonomy using three distinct personas: a computer science student with only peripheral NLP knowledge, a businessperson with practical experience of NLP tools but minimal technical expertise, and a non-technical, non-academic individual whose technology use is limited to basic tasks. Persona-specific prompting yielded diverse inquiries in layman’s language. For example, the question “How are computers able to respond when we ask them questions?” was generated for the topic Natural Language Interfaces. To account for questions unrelated to NLP, we also generated a set of out-of-scope questions such as “Who discovered the
5. [5]:  Passage ID 5: et al., 1986), LSTMs (Hochreiter and Schmidhuber, 1997), GANs (Radford et al., 2016), Transformers (Vaswani et al., 2017), and VAEs (Kingma and Welling, 2022), with a strong focus on real-world applications.How to Control Sentiment in Text Generation: A Survey of the State-of-the-Art in Sentiment-Control Techniques (Lorandi and Belz, 2023) provides an in-depth look at sentiment control within CTG, highlighting the challenges and importance of managing sentiment in generated text.A Recent Survey on Controllable Text Generation: A Causal Perspective (Wang et al., 2024b) critiques traditional CTG methods focused on statistical correlations, advocating for improvements via representation disentanglement, causal inference, and knowledge augmentation.A Survey of Controllable Text Generation using Transformer-based Pre-trained Language Models (Zhang et al., 2023b) focuses on Transformer-based pre-trained models in CTG. While it discusses the evolving capabilities and limitations of