# A Survey of Computational Framing Analysis Approaches

## Question

How does incorporating metadata improve the interpretability of topics in Structural Topic Modeling (STM)?

## URLs

1. https://ar5iv.org/html/1705.09296. [1705.09296] Neural Models for Documents with Metadata
2. https://ar5iv.org/html/1803.11045. [1803.11045] Computer-Assisted Text Analysis for Social Science: Topic Models and Beyond
3. https://ar5iv.org/html/2104.02496. [2104.02496] Exploring Topic-Metadata Relationships with the STM: A Bayesian Approach
4. https://ar5iv.org/html/1802.02163. [1802.02163] How to Make Causal Inferences Using TextsWe thank Edo Airoldi, Peter Aronow, Matt Blackwell, Sarah Bouchat, Chris Felton, Mark Handcock, Erin Hartman, Rebecca Johnson, Gary King, Ian Lundberg, Rich Nielsen, Thomas Richardson, Matt Salganik, Melissa Sands, Fredrik Sävje, Arthur Spirling, Alex Tahk, Endre Tvinnereim, Hannah Waight, Hanna Wallach, Simone Zhang and numerous seminar participants for useful discussions about making causal inference with texts. We also thank Dustin Tingley for early conversations about potential SUTVA concerns with respect to STM and sequential experiments as a possible way to combat it.
5. https://ar5iv.org/html/2410.24126. [2410.24126] Multi-environment Topic Models
6. https://ar5iv.org/html/2409.15340. [2409.15340] WISDOM: An AI-powered framework for emerging research detection using weak signal analysis and advanced topic modeling
7. https://ar5iv.org/html/2103.13550. [2103.13550] Untitled Document
8. https://ar5iv.org/html/2207.01487. [2207.01487] State of the Art of Audio- and Video-Based Solutions for AAL

## Answer (I don't know?: ✗)

Incorporating metadata into Structural Topic Modeling (STM) significantly enhances the interpretability of topics by allowing researchers to explore the relationships between discovered topics and document-specific characteristics. This relationship is vital for context-based analysis, as metadata often encompasses valuable information such as the author's identity, publication date, and other document attributes that can influence the nature and relevance of topics discussed within the text.

One of the foundational improvements introduced by STM, as noted by Roberts et al. (2013), is the incorporation of document covariates through a generalized linear model (GLM) framework. This extension allows researchers to assess how different factors—such as the author's background or the topicality of a publication—impact the distribution of topics within a body of text [1][3]. For instance, the author-topic model developed by Rosen-Zvi et al. (2004) demonstrates that the author's identity can directly shape the topics investigated, like how a biologist is more inclined to write about biological themes than sociopolitical ones [2]. By including such metadata, STM helps link authors or other contextual elements to particular topics, leading to a richer understanding of the data.

Moreover, the methodology applied within STM—such as using repeated Ordinary Least Squares (OLS) regressions on sampled topic proportions relative to metadata covariates [4]—allows for a statistical exploration of these relationships. By applying Monte Carlo sampling techniques in this regression framework, researchers can estimate topic contributions and their significance concerning the metadata, thus enhancing the interpretability of the relationships among the identified topics [4].

The conceptual shift introduced by Laurens et al. (2016), which suggests using Beta regression instead of OLS and advocating a Bayesian approach, further emphasizes the need for rigorous statistical methods to derive insights from topic modeling [4]. Such methodological improvements not only facilitate more accurate modeling of data but also promote more robust inferential claims about the relationships between metadata and topics.

Despite these advancements, it must be acknowledged that the integration of complex models like STM can be challenging for social scientists who may not be well-versed in machine learning techniques and programming [5]. Addressing the associated learning curve through explainable user interfaces emerges as a pivotal opportunity, which can equip researchers to better navigate the complexities of these models and derive actionable insights from the metadata-topic relationships effectively [5]. 

In conclusion, the incorporation of metadata into STM fosters enhanced interpretability by explicitly connecting document characteristics to topic distributions. This connection is achieved through advanced statistical modeling techniques, promoting a nuanced understanding of how various factors influence topic formation and relevance in textual analysis.

1. [1]:  https://ar5iv.org/html/1803.11045, [1803.11045] Computer-Assisted Text Analysis for Social Science: Topic Models and Beyond
2. [2]:  https://ar5iv.org/html/1803.11045, [1803.11045] Computer-Assisted Text Analysis for Social Science: Topic Models and Beyond
3. [3]:  https://ar5iv.org/html/1803.11045, [1803.11045] Computer-Assisted Text Analysis for Social Science: Topic Models and Beyond
4. [4]:  https://ar5iv.org/html/2104.02496, [2104.02496] Exploring Topic-Metadata Relationships with the STM: A Bayesian Approach
5. [5]:  https://ar5iv.org/html/1803.11045, [1803.11045] Computer-Assisted Text Analysis for Social Science: Topic Models and Beyond
---
1. [1]:  Passage ID 1: LDA framework by asking questions involving document covariates that facilitate hypothesis testing. In response to these problems, Roberts et al. (2013) introduced structural topic model (STM) as a general causal inference framework for hypothesis testing for document covariates.IV Structural Topic Model & Multi-ModalityIn this section, I review literature by social scientists to reconcile two major problems with the standard topic model framework: the lack of causal inference and multi-modality.The first issue I address is that standard (down-stream) metadata topic models (e.g. Author-Topic, Dynamic, etc.) make point but not standard error estimates to facilitate statistical hypothesis testing. The next problem is that computational methods for topic model inference, as it is an NP-hard problem [68], [69], can provide local optima but cannot guarantee global optima, which is termed multi-modality. This problem threatens the stability of a topic model output and can lead
2. [2]:  Passage ID 2: LDA framework has been generalized to include document metadata variables within the algorithm which thus require modifications to the computational methods as well. Later in Section 4, I’ll discuss how such metadata variable extensions has an impact on the computational methods possible when introducing the structural topic model (STM).II-C Model Extensions for Document MetadataA second theme in topic modeling literature deals with the inclusion of metadata variables into the model. One of the first examples of such a model is the author-topic model proposed by Rosen-Zvi et al. (2004). The original motivation was the explicit point that who the author is will have a direct impact on what topics are discussed in a publication (e.g., a biologist will more likely write about topics in biology than sociology or politics). In contrast, LDA does not take into account any document variables (like author) and thus fails to incorporate author into the model. Using only LDA, the only
3. [3]:  Passage ID 3: error estimates. This problem is directly contrary to the tradition of causal inference that employs statistical confidence within the social sciences to determine causation (for example [63]). In an effort to reconcile this problem, Roberts et al. (2013) and Roberts et al. (2014) introduced the structural topic model (STM) by incorporating a generalized linear model (GLM) framework for document metadata by extending elements of three previous topic model extensions: CTM, DMR and SAGE.Let’s first start with CTM. Blei and Lafferty (2007) introduce the correlated topic model (CTM) to provide more realism to the original LDA model which incorporates a more flexible correlation structure than the independence assumption assumed in LDA. The model replaces the Dirichlet assumption for topic proportions as used in LDA with a logistic normal distribution. The main advantage of the CTM versus the LDA is improved predictive power: “A Dirichlet-based model will predict items based on the
4. [4]:  Passage ID 4: Matthias Aßenmacher1♠♠\spadesuit  Sandra Wankmüller2♢♢\diamondsuit&Christian Heumann1♠♠\spadesuitAbstractTopic models such as the Structural Topic Model (STM) estimate latent topical clusters within text. An important step in many topic modeling applications is to explore relationships between the discovered topical structure and metadata associated with the text documents. Methods used to estimate such relationships must take into account that the topical structure is not directly observed, but instead being estimated itself. The authors of the STM, for instance, perform repeated OLS regressions of sampled topic proportions on metadata covariates by using a Monte Carlo sampling technique known as the method of composition. In this paper, we propose two improvements: first, we replace OLS with more appropriate Beta regression. Second, we suggest a fully Bayesian approach instead of the current blending of frequentist and Bayesian methods. We demonstrate our improved methodology
5. [5]:  Passage ID 5: problems. Nevertheless, a major impediment to the expansion of STM (and machine learning algorithms in general) for most social scientists is the high knowledge barriers to use these models. Given the quick development of such models, many social scientists may lack the training and experience in machine learning and computational programming to implement and to analyze topic models. To address this concern, a potential research opportunity with the STM model is through an explainable user interface (visualization) that can aid social scientists in hypothesis testing large collections of text documents. The importance of this opportunity is exemplified through DARPA’s recent Explainable Artificial Intelligence (XAI) program [80].Figure 14: Explainable Artificial Intelligence (XAI) from DARPA (2016)An inherent problem with most machine learning techniques and tasks for decision makers is the lack of explanation of why a specific prediction or choice was made by the algorithm.