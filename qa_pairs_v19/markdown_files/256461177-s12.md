# A Survey of Computational Framing Analysis Approaches

## Question

How does incorporating metadata improve the interpretability of topics in Structural Topic Modeling (STM)?

## URLs

1. https://ar5iv.org/html/1705.09296. [1705.09296] Neural Models for Documents with Metadata
2. https://ar5iv.org/html/1803.11045. [1803.11045] Computer-Assisted Text Analysis for Social Science: Topic Models and Beyond
3. https://ar5iv.org/html/2104.02496. [2104.02496] Exploring Topic-Metadata Relationships with the STM: A Bayesian Approach
4. https://ar5iv.org/html/1802.02163. [1802.02163] How to Make Causal Inferences Using TextsWe thank Edo Airoldi, Peter Aronow, Matt Blackwell, Sarah Bouchat, Chris Felton, Mark Handcock, Erin Hartman, Rebecca Johnson, Gary King, Ian Lundberg, Rich Nielsen, Thomas Richardson, Matt Salganik, Melissa Sands, Fredrik Sävje, Arthur Spirling, Alex Tahk, Endre Tvinnereim, Hannah Waight, Hanna Wallach, Simone Zhang and numerous seminar participants for useful discussions about making causal inference with texts. We also thank Dustin Tingley for early conversations about potential SUTVA concerns with respect to STM and sequential experiments as a possible way to combat it.
5. https://ar5iv.org/html/2410.24126. [2410.24126] Multi-environment Topic Models
6. https://ar5iv.org/html/2409.15340. [2409.15340] WISDOM: An AI-powered framework for emerging research detection using weak signal analysis and advanced topic modeling
7. https://ar5iv.org/html/2103.13550. [2103.13550] Untitled Document
8. https://ar5iv.org/html/2207.01487. [2207.01487] State of the Art of Audio- and Video-Based Solutions for AAL

## Answer (I don't know?: ✗)

Incorporating metadata into Structural Topic Modeling (STM) enhances the interpretability of topics by explicitly linking them to relevant contextual information, which aids in hypothesis testing and understanding underlying patterns in the data. The metadata, which might include factors such as author information or document characteristics, allows researchers to elucidate how various influences shape the topics presented in the text.

Firstly, traditional topic modeling methods, like LDA, do not account for document covariates, which means that the connection between topics and their contextual factors is neglected [2]. STM addresses this limitation by integrating metadata variables into the model, allowing researchers to explore how the identity of authors, publication context, and other relevant metadata directly influence the topics discussed in the texts [2]. For instance, an author’s discipline can suggest that certain topics are more likely to be emphasized—such as a biologist discussing topics in biology rather than sociology or politics [2].

Secondly, by connecting the estimated topic proportions to metadata covariates through statistical regression methods (such as the repeated OLS regressions mentioned), STM facilitates a clearer interpretation of the relationship between topics and their contextual influences [4]. Since the topical structure itself is not directly observable, employing these regression methods helps quantify the association between topics and metadata, thus allowing for meaningful inferences about how context impacts content [4].

Furthermore, improvements proposed in recent STM methodologies, such as using Beta regression instead of OLS and adopting a fully Bayesian framework, also enhance interpretability by providing more appropriate statistical modeling techniques for estimating relationships between topics and metadata [4]. These advancements allow for more nuanced insights into how metadata impacts the topical structure, thereby refining the understanding of the topics extracted from the text.

Additionally, the acknowledgment of causal inference within social sciences—by employing statistical confidence measures—helps frame the understanding of how metadata affects topics in a way that aligns with established methodologies in social research [3]. This is significant for social scientists who are often concerned with causal relationships and interpretation, thereby making STM a more valuable tool in this context.

Finally, the growing emphasis on explainable artificial intelligence (XAI) in relation to STM could further assist researchers by providing visualizations and interfaces that simplify understanding complex model outputs. Such tools can help demystify how specific predictions or topic structures are derived from the underlying metadata, thus increasing the overall interpretability of the topics generated by STM [5].

In conclusion, incorporating metadata into STM not only enhances the model’s ability to reflect real-world influences on topical content but also improves interpretability through statistical modeling, causal inference frameworks, and potential advancements in visualization, thereby equipping researchers with clearer insights into the data.

1. [1]:  https://ar5iv.org/html/1803.11045, [1803.11045] Computer-Assisted Text Analysis for Social Science: Topic Models and Beyond
2. [2]:  https://ar5iv.org/html/1803.11045, [1803.11045] Computer-Assisted Text Analysis for Social Science: Topic Models and Beyond
3. [3]:  https://ar5iv.org/html/1803.11045, [1803.11045] Computer-Assisted Text Analysis for Social Science: Topic Models and Beyond
4. [4]:  https://ar5iv.org/html/2104.02496, [2104.02496] Exploring Topic-Metadata Relationships with the STM: A Bayesian Approach
5. [5]:  https://ar5iv.org/html/1803.11045, [1803.11045] Computer-Assisted Text Analysis for Social Science: Topic Models and Beyond
---
1. [1]:  Passage ID 1: LDA framework by asking questions involving document covariates that facilitate hypothesis testing. In response to these problems, Roberts et al. (2013) introduced structural topic model (STM) as a general causal inference framework for hypothesis testing for document covariates.IV Structural Topic Model & Multi-ModalityIn this section, I review literature by social scientists to reconcile two major problems with the standard topic model framework: the lack of causal inference and multi-modality.The first issue I address is that standard (down-stream) metadata topic models (e.g. Author-Topic, Dynamic, etc.) make point but not standard error estimates to facilitate statistical hypothesis testing. The next problem is that computational methods for topic model inference, as it is an NP-hard problem [68], [69], can provide local optima but cannot guarantee global optima, which is termed multi-modality. This problem threatens the stability of a topic model output and can lead
2. [2]:  Passage ID 2: LDA framework has been generalized to include document metadata variables within the algorithm which thus require modifications to the computational methods as well. Later in Section 4, I’ll discuss how such metadata variable extensions has an impact on the computational methods possible when introducing the structural topic model (STM).II-C Model Extensions for Document MetadataA second theme in topic modeling literature deals with the inclusion of metadata variables into the model. One of the first examples of such a model is the author-topic model proposed by Rosen-Zvi et al. (2004). The original motivation was the explicit point that who the author is will have a direct impact on what topics are discussed in a publication (e.g., a biologist will more likely write about topics in biology than sociology or politics). In contrast, LDA does not take into account any document variables (like author) and thus fails to incorporate author into the model. Using only LDA, the only
3. [3]:  Passage ID 3: error estimates. This problem is directly contrary to the tradition of causal inference that employs statistical confidence within the social sciences to determine causation (for example [63]). In an effort to reconcile this problem, Roberts et al. (2013) and Roberts et al. (2014) introduced the structural topic model (STM) by incorporating a generalized linear model (GLM) framework for document metadata by extending elements of three previous topic model extensions: CTM, DMR and SAGE.Let’s first start with CTM. Blei and Lafferty (2007) introduce the correlated topic model (CTM) to provide more realism to the original LDA model which incorporates a more flexible correlation structure than the independence assumption assumed in LDA. The model replaces the Dirichlet assumption for topic proportions as used in LDA with a logistic normal distribution. The main advantage of the CTM versus the LDA is improved predictive power: “A Dirichlet-based model will predict items based on the
4. [4]:  Passage ID 4: Matthias Aßenmacher1♠♠\spadesuit  Sandra Wankmüller2♢♢\diamondsuit&Christian Heumann1♠♠\spadesuitAbstractTopic models such as the Structural Topic Model (STM) estimate latent topical clusters within text. An important step in many topic modeling applications is to explore relationships between the discovered topical structure and metadata associated with the text documents. Methods used to estimate such relationships must take into account that the topical structure is not directly observed, but instead being estimated itself. The authors of the STM, for instance, perform repeated OLS regressions of sampled topic proportions on metadata covariates by using a Monte Carlo sampling technique known as the method of composition. In this paper, we propose two improvements: first, we replace OLS with more appropriate Beta regression. Second, we suggest a fully Bayesian approach instead of the current blending of frequentist and Bayesian methods. We demonstrate our improved methodology
5. [5]:  Passage ID 5: problems. Nevertheless, a major impediment to the expansion of STM (and machine learning algorithms in general) for most social scientists is the high knowledge barriers to use these models. Given the quick development of such models, many social scientists may lack the training and experience in machine learning and computational programming to implement and to analyze topic models. To address this concern, a potential research opportunity with the STM model is through an explainable user interface (visualization) that can aid social scientists in hypothesis testing large collections of text documents. The importance of this opportunity is exemplified through DARPA’s recent Explainable Artificial Intelligence (XAI) program [80].Figure 14: Explainable Artificial Intelligence (XAI) from DARPA (2016)An inherent problem with most machine learning techniques and tasks for decision makers is the lack of explanation of why a specific prediction or choice was made by the algorithm.