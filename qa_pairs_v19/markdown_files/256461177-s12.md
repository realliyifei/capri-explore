# A Survey of Computational Framing Analysis Approaches

## Question

How does incorporating metadata improve the interpretability of topics in Structural Topic Modeling (STM)?

## URLs

1. https://ar5iv.org/html/1705.09296. [1705.09296] Neural Models for Documents with Metadata
2. https://ar5iv.org/html/1803.11045. [1803.11045] Computer-Assisted Text Analysis for Social Science: Topic Models and Beyond
3. https://ar5iv.org/html/2104.02496. [2104.02496] Exploring Topic-Metadata Relationships with the STM: A Bayesian Approach
4. https://ar5iv.org/html/1802.02163. [1802.02163] How to Make Causal Inferences Using TextsWe thank Edo Airoldi, Peter Aronow, Matt Blackwell, Sarah Bouchat, Chris Felton, Mark Handcock, Erin Hartman, Rebecca Johnson, Gary King, Ian Lundberg, Rich Nielsen, Thomas Richardson, Matt Salganik, Melissa Sands, Fredrik Sävje, Arthur Spirling, Alex Tahk, Endre Tvinnereim, Hannah Waight, Hanna Wallach, Simone Zhang and numerous seminar participants for useful discussions about making causal inference with texts. We also thank Dustin Tingley for early conversations about potential SUTVA concerns with respect to STM and sequential experiments as a possible way to combat it.
5. https://ar5iv.org/html/2410.24126. [2410.24126] Multi-environment Topic Models
6. https://ar5iv.org/html/2409.15340. [2409.15340] WISDOM: An AI-powered framework for emerging research detection using weak signal analysis and advanced topic modeling
7. https://ar5iv.org/html/2103.13550. [2103.13550] Untitled Document
8. https://ar5iv.org/html/2207.01487. [2207.01487] State of the Art of Audio- and Video-Based Solutions for AAL

## Answer (I don't know?: ✗)

Incorporating metadata into Structural Topic Modeling (STM) significantly improves the interpretability of topics by providing context that highlights relationships between the content and documentary factors associated with the text. This enhances both the quality of topic interpretation and the relevance of the insights derived from the model.

Firstly, the inclusion of metadata allows for a more nuanced understanding of how specific variables—such as author information—affect the topics discussed in documents. For instance, as noted in the literature, models like the author-topic model explicitly suggest that an author's background (e.g., a biologist versus a sociologist) will influence the topics they cover, which is a consideration that standard Latent Dirichlet Allocation (LDA) models neglect [2]. By incorporating such metadata, STM models can capture these dynamics, ultimately yielding insights that reflect the socio-cultural and contextual factors surrounding the creation of the documents analyzed.

Moreover, incorporating metadata extends the mathematical framework of STM, aligning it more closely with causal inference methodologies central to social sciences. This is vital because the traditional LDA model does not provide standard error estimates that facilitate meaningful statistical hypothesis testing [1][3]. By implementing a generalized linear model (GLM) framework within STM to account for metadata, researchers can obtain more robust estimates, thereby enriching the interpretability of the topics and the confidence surrounding the causal relationships inferred from the topic models [3].

The method of composition used by STM further aids in the interpretation of text data, as it involves performing repeated Ordinary Least Squares (OLS) regressions of sampled topic proportions on metadata covariates. This approach synthesizes the latent topical structure with the metadata, allowing researchers to discern how different factors influence topic prevalence [4]. 

Additionally, proposed improvements to STM methodologies, such as replacing OLS with more suitable regression techniques (like Beta regression) and adopting a fully Bayesian approach, aim to enhance the explicability of the results derived from the model. These improvements would facilitate a clearer understanding of how topics vary with changes in the covariates, thus further improving interpretability [4].

Lastly, the integration of unique metadata extends beyond just improving statistical reliability; it also addresses the interpretational gaps that often accompany machine learning applications in social sciences. Many researchers feel intimidated by complex models, and the use of an explainable user interface could alleviate these concerns, fostering a better grasp of how metadata influences topics and helping social scientists make informed decisions based on model outputs [5].

In summary, incorporating metadata into STM not only improves the statistical foundation of the model for hypothesis testing but also enhances the clarity and relevance of the insights gained, solidifying its utility in the social sciences and increasing the interpretability of the underlying topics identified.

1. [1]:  https://ar5iv.org/html/1803.11045, [1803.11045] Computer-Assisted Text Analysis for Social Science: Topic Models and Beyond
2. [2]:  https://ar5iv.org/html/1803.11045, [1803.11045] Computer-Assisted Text Analysis for Social Science: Topic Models and Beyond
3. [3]:  https://ar5iv.org/html/1803.11045, [1803.11045] Computer-Assisted Text Analysis for Social Science: Topic Models and Beyond
4. [4]:  https://ar5iv.org/html/2104.02496, [2104.02496] Exploring Topic-Metadata Relationships with the STM: A Bayesian Approach
5. [5]:  https://ar5iv.org/html/1803.11045, [1803.11045] Computer-Assisted Text Analysis for Social Science: Topic Models and Beyond
---
1. [1]:  Passage ID 1: LDA framework by asking questions involving document covariates that facilitate hypothesis testing. In response to these problems, Roberts et al. (2013) introduced structural topic model (STM) as a general causal inference framework for hypothesis testing for document covariates.IV Structural Topic Model & Multi-ModalityIn this section, I review literature by social scientists to reconcile two major problems with the standard topic model framework: the lack of causal inference and multi-modality.The first issue I address is that standard (down-stream) metadata topic models (e.g. Author-Topic, Dynamic, etc.) make point but not standard error estimates to facilitate statistical hypothesis testing. The next problem is that computational methods for topic model inference, as it is an NP-hard problem [68], [69], can provide local optima but cannot guarantee global optima, which is termed multi-modality. This problem threatens the stability of a topic model output and can lead
2. [2]:  Passage ID 2: LDA framework has been generalized to include document metadata variables within the algorithm which thus require modifications to the computational methods as well. Later in Section 4, I’ll discuss how such metadata variable extensions has an impact on the computational methods possible when introducing the structural topic model (STM).II-C Model Extensions for Document MetadataA second theme in topic modeling literature deals with the inclusion of metadata variables into the model. One of the first examples of such a model is the author-topic model proposed by Rosen-Zvi et al. (2004). The original motivation was the explicit point that who the author is will have a direct impact on what topics are discussed in a publication (e.g., a biologist will more likely write about topics in biology than sociology or politics). In contrast, LDA does not take into account any document variables (like author) and thus fails to incorporate author into the model. Using only LDA, the only
3. [3]:  Passage ID 3: error estimates. This problem is directly contrary to the tradition of causal inference that employs statistical confidence within the social sciences to determine causation (for example [63]). In an effort to reconcile this problem, Roberts et al. (2013) and Roberts et al. (2014) introduced the structural topic model (STM) by incorporating a generalized linear model (GLM) framework for document metadata by extending elements of three previous topic model extensions: CTM, DMR and SAGE.Let’s first start with CTM. Blei and Lafferty (2007) introduce the correlated topic model (CTM) to provide more realism to the original LDA model which incorporates a more flexible correlation structure than the independence assumption assumed in LDA. The model replaces the Dirichlet assumption for topic proportions as used in LDA with a logistic normal distribution. The main advantage of the CTM versus the LDA is improved predictive power: “A Dirichlet-based model will predict items based on the
4. [4]:  Passage ID 4: Matthias Aßenmacher1♠♠\spadesuit  Sandra Wankmüller2♢♢\diamondsuit&Christian Heumann1♠♠\spadesuitAbstractTopic models such as the Structural Topic Model (STM) estimate latent topical clusters within text. An important step in many topic modeling applications is to explore relationships between the discovered topical structure and metadata associated with the text documents. Methods used to estimate such relationships must take into account that the topical structure is not directly observed, but instead being estimated itself. The authors of the STM, for instance, perform repeated OLS regressions of sampled topic proportions on metadata covariates by using a Monte Carlo sampling technique known as the method of composition. In this paper, we propose two improvements: first, we replace OLS with more appropriate Beta regression. Second, we suggest a fully Bayesian approach instead of the current blending of frequentist and Bayesian methods. We demonstrate our improved methodology
5. [5]:  Passage ID 5: problems. Nevertheless, a major impediment to the expansion of STM (and machine learning algorithms in general) for most social scientists is the high knowledge barriers to use these models. Given the quick development of such models, many social scientists may lack the training and experience in machine learning and computational programming to implement and to analyze topic models. To address this concern, a potential research opportunity with the STM model is through an explainable user interface (visualization) that can aid social scientists in hypothesis testing large collections of text documents. The importance of this opportunity is exemplified through DARPA’s recent Explainable Artificial Intelligence (XAI) program [80].Figure 14: Explainable Artificial Intelligence (XAI) from DARPA (2016)An inherent problem with most machine learning techniques and tasks for decision makers is the lack of explanation of why a specific prediction or choice was made by the algorithm.