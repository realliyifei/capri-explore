# A Survey on Automatically-Constructed WordNets and their Evaluation: Lexical and Word Embedding-based Approaches

## Question

How do threshold values influence precision and recall in evaluating automatically-constructed Persian WordNets?

## URLs

1. https://ar5iv.org/html/1704.03223. [1704.03223] Persian Wordnet Construction using Supervised Learning
2. https://ar5iv.org/html/2205.10412. [2205.10412] Current Trends and Approaches in Synonyms Extraction: Potential Adaptation to Arabic
3. https://ar5iv.org/html/1606.03143. [1606.03143] PerSum: Novel Systems for Document Summarization in Persian
4. https://ar5iv.org/html/2305.11731. [2305.11731] Persian Typographical Error Type Detection Using Deep Neural Networks on Algorithmically-Generated Misspellings
5. https://ar5iv.org/html/2104.14751. [2104.14751] A Survey on sentiment analysis in Persian: A Comprehensive System Perspective Covering Challenges and Advances in Resources, and Methods
6. https://ar5iv.org/html/1907.04149. [1907.04149] Answer Extraction for Why Arabic Questions Answering Systems: EWAQ
7. https://ar5iv.org/html/2005.01879. [2005.01879] FarsBase-KBP: A Knowledge Base Population System for the Persian Knowledge Graph
8. https://ar5iv.org/html/2106.00145. [2106.00145] Corpus-Based Paraphrase Detection Experiments and Review
9. https://ar5iv.org/html/2405.13071. [2405.13071] 1 Introduction
10. https://ar5iv.org/html/2103.00020. [2103.00020] Learning Transferable Visual Models From Natural Language Supervision

## Answer (I don't know?: ✓)

I don't know. The context provided does not contain any information related to threshold values, precision, recall, or their influence on the evaluation of automatically-constructed Persian WordNets specifically. The passages reference various studies, conferences, and methodologies within the field of Natural Language Processing (NLP) but do not address the specific question regarding Persian WordNets or the interplay of threshold values with precision and recall metrics. Therefore, I cannot construct a meaningful answer based on the given information.

1. [1]:  https://ar5iv.org/html/2211.02483, No Title
2. [2]:  https://ar5iv.org/html/2407.03895, No Title
3. [3]:  https://ar5iv.org/html/2407.03895, No Title
4. [4]:  https://ar5iv.org/html/2410.11627, No Title
5. [5]:  https://ar5iv.org/html/2403.14840, No Title
---
1. [1]:  Passage ID 1: on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2153–2162, Hong Kong, China. Association for Computational Linguistics.[15] Zhengbao Jiang, Jun Araki, Haibo Ding, and Graham Neubig. 2021. How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering. Transactions of the Association for Computational Linguistics, 9:962–977.[16] Karen Hambardzumyan, Hrant Khachatrian, and Jonathan May. 2021. WARP: Word-level Adversarial ReProgramming. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 4921–4933, Online. Association for Computational Linguistics.[17] Xiang Lisa Li and Percy Liang. 2021. Prefix-Tuning: Optimizing Continuous Prompts for Generation. In Proceedings of the 59th Annual Meeting
2. [2]:  Passage ID 2: EMNLP 2014 - 2014 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference. pp. 898–906 (2014). https://doi.org/10.3115/v1/d14-1097[55]Mejer, A., Crammer, K.: Confidence in structured-prediction using Confidence-Weighted models. In: EMNLP 2010 - Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference. pp. 971–981 (2010)[56]Mendonça, V., Sardinha, A., Coheur, L., Santos, A.L.: Query Strategies, Assemble! Active Learning with Expert Advice for Low-resource Natural Language Processing. In: 2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE). pp. 1–8 (Jul 2020). https://doi.org/10.1109/FUZZ48607.2020.9177707[57]Miller, S., Guinness, J., Zamanian, A.: Name tagging with word clusters and discriminative training. In: HLT-NAACL 2004 - Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, Proceedings of the Main Conference.
3. [3]:  Passage ID 3: EMNLP 2014 - 2014 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference. pp. 898–906 (2014). https://doi.org/10.3115/v1/d14-1097[55]Mejer, A., Crammer, K.: Confidence in structured-prediction using Confidence-Weighted models. In: EMNLP 2010 - Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference. pp. 971–981 (2010)[56]Mendonça, V., Sardinha, A., Coheur, L., Santos, A.L.: Query Strategies, Assemble! Active Learning with Expert Advice for Low-resource Natural Language Processing. In: 2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE). pp. 1–8 (Jul 2020). https://doi.org/10.1109/FUZZ48607.2020.9177707[57]Miller, S., Guinness, J., Zamanian, A.: Name tagging with word clusters and discriminative training. In: HLT-NAACL 2004 - Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, Proceedings of the Main Conference.
4. [4]:  Passage ID 4: NLP.Nature Machine Intelligence, 5(10):1161–1174.Hupkes et al. (2018)Dieuwke Hupkes, Sara Veldhoen, and Willem Zuidema. 2018.Visualisation and’diagnostic classifiers’ reveal how recurrent andrecursive neural networks process hierarchical structure.Journal of Artificial Intelligence Research, 61:907–926.Kempe and Brooks (2008)Vera Kempe and Patricia J Brooks. 2008.Second language learning of complex inflectional systems.Language Learning, 58(4):703–746.Kim et al. (2016)Yoon Kim, Yacine Jernite, David Sontag, and Alexander Rush. 2016.Character-aware neural language models.In Proceedings of the AAAI conference on artificialintelligence, volume 30.Kudo (2018)Taku Kudo. 2018.Subword regularization:Improving neural network translation models with multiple subwordcandidates.In Proceedings of the 56th Annual Meeting of the Associationfor Computational Linguistics (Volume 1: Long Papers), pages 66–75,Melbourne, Australia. Association
5. [5]:  Passage ID 5: Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3632–3636, Hong Kong, China. Association for Computational Linguistics.Vinyals et al. (2015)Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. 2015.Pointer networks.In Advances in Neural Information Processing Systems, volume 28. Curran Associates, Inc.Wu and Dredze (2020)Shijie Wu and Mark Dredze. 2020.Are all languages created equal in multilingual bert?In Proceedings of the 5th Workshop on Representation Learning for NLP, page 120–130, Online. Association for Computational Linguistics.Yarowsky and Wicentowski (2000)David Yarowsky and Richard Wicentowski. 2000.Minimally supervised morphological analysis by multimodal alignment.In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, pages 207–216, Hong Kong. Association for Computational Linguistics.Zhao et al.