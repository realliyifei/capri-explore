# A Survey of Evaluation Methods of Generated Medical Textual Reports

## Question

How is medical correctness assessed in the generation of medical reports, and what are the criteria involved?

## URLs

1. https://ar5iv.org/html/2410.17357. [2410.17357] Image-aware Evaluation of Generated Medical Reports
2. https://ar5iv.org/html/2408.13988. [2408.13988] Automatic Medical Report Generation: Methods and Applications
3. https://ar5iv.org/html/2412.02971. [2412.02971] MedAutoCorrect: Image-Conditioned Autocorrection in Medical Reporting
4. https://ar5iv.org/html/2406.11143. [2406.11143] Scorecards for Synthetic Medical Data Evaluation and Reporting
5. https://ar5iv.org/html/2401.13267. [2401.13267] Dual-modal Dynamic Traceback Learning for Medical Report Generation
6. https://ar5iv.org/html/2404.17778. [2404.17778] MRScore: Evaluating Radiology Report Generation with LLM-based Reward System
7. https://ar5iv.org/html/2410.23769. [2410.23769] The Potential of LLMs in Medical Education: Generating Questions and Answers for Qualification Exams
8. https://ar5iv.org/html/2405.10842. [2405.10842] Automated Radiology Report Generation: A Review of Recent Advances
9. https://ar5iv.org/html/2411.17301. [2411.17301] ER2Score: LLM-based Explainable and Customizable Metric for Assessing Radiology Reports with Reward-Control Loss
10. https://ar5iv.org/html/2410.00379. [2410.00379] CXPMRG-Bench: Pre-training and Benchmarking for X-ray Medical Report Generation on CheXpert Plus Dataset

## Answer (I don't know?: ✗)

In the generation of medical reports using language models (LLMs), medical correctness is primarily assessed through a combination of human expert evaluation based on several defined criteria. These assessments focus on the reliability and accuracy of the information produced by the LLMs.

The evaluation of medical correctness involves several key criteria, including coherence, sufficiency of key information, information correctness, and professionalism. Coherence evaluates the contextual relevance and rationality in how information is presented, ensuring that it forms a clear and comprehensible narrative. This is crucial for generating reports that are easy to understand and follow logically [3].

Sufficiency of key information refers to the LLMs' ability to extract, abstract, and organize important and complete information from the input reports. This criterion ensures that the generated content allows the recipient to formulate a reasonable response, which is critical in medical contexts where complete information is necessary for decision-making [3]. 

Information correctness directly assesses whether the generated questions and answers contain reliable and accurate medical information. Human medical experts rate the generated content based on how accurate and trustworthy the statements are in relation to established medical knowledge [3][4]. In the context of evaluating AI-generated questions, experts noted that while many LLMs achieve scores reflecting good coherence and information correctness, the rating for sufficiency of key information was notably lower, indicating potential gaps that could impact medical decision-making [2].

Professionalism is another important criterion, as it evaluates the appropriateness of the language and tone used in the reports. This includes the use of technical terminology and the formality expected in medical writing [1][3]. The assessment of professionalism ensures that the AI-generated outputs meet the standards expected in medical communication.

In summary, the assessment of medical correctness in the generation of medical reports by LLMs hinges on these four criteria: coherence, sufficiency of key information, information correctness, and professionalism. Each of these aspects plays a vital role in ensuring that the generated medical texts are not only accurate but also suitable for their intended professional context [1][2][3][4]. The interplay and balance among these criteria guide the refinement of LLMs for better performance in generating reliable medical documentation [5].

1. [1]:  https://ar5iv.org/html/2410.23769, [2410.23769] The Potential of LLMs in Medical Education: Generating Questions and Answers for Qualification Exams
2. [2]:  https://ar5iv.org/html/2410.23769, [2410.23769] The Potential of LLMs in Medical Education: Generating Questions and Answers for Qualification Exams
3. [3]:  https://ar5iv.org/html/2410.23769, [2410.23769] The Potential of LLMs in Medical Education: Generating Questions and Answers for Qualification Exams
4. [4]:  https://ar5iv.org/html/2410.23769, [2410.23769] The Potential of LLMs in Medical Education: Generating Questions and Answers for Qualification Exams
5. [5]:  https://ar5iv.org/html/2410.23769, [2410.23769] The Potential of LLMs in Medical Education: Generating Questions and Answers for Qualification Exams
---
1. [1]:  Passage ID 1: in determining whether the questions are professionally appropriate, the LLMs still incur a loss of critical information during the process of extracting and abstracting information from the input reports.Furthermore, human medical experts evaluated the AI-generated answers based on four criteria: coherence, factual consistency, evidence of statement, and professionalism. Figure 2 depicts the average scores of different LLMs’ answers toward a same sampled set of AI-generated questions. It can be observed that the average score for question answering is lower than that for question generation, with LLMs’ ratings hovering around 3.5 across all evaluation metrics. This indicates a significant gap between the performance of LLMs and the critical requirements of human experts for medical open-ended question answering. Moreover, with the task of question answering in the specific domain of elderly chronic diseases under prompting of limited references, identifying and improving strategies
2. [2]:  Passage ID 2: of the AI-generated questions by human medical experts, focusing on four criteria: coherence, sufficiency of key information, information correctness, and professionalism. Figure 1 visualizes the average rating results of human experts on the question generation of different LLMs based on a same sampled set of elderly chronic disease admission reports. It can be noted that the majority of LLMs achieve scores over 4 in terms of coherence and information correctness, and achieve scores nearly 4 in terms of professionalism, whereas the average score for sufficient of key information is relatively lower, with one scoring below 3.5 in general. This phenomenon may indicate that human experts were satisfied with the contextual semantic correctness and readability of AI-generated questions. However, in determining whether the questions are professionally appropriate, the LLMs still incur a loss of critical information during the process of extracting and abstracting information from the input
3. [3]:  Passage ID 3: Human evaluationWe evaluated the performance of LLMs on producing qualification examinations for medical education through human medical expert assessment. Specifically, we focused on two tasks: generating open-ended questions based on admission reports and generating corresponding open-ended answers to the examination questions. (1) For the generation of examination questions, we assessed from four perspectives: coherence, sufficiency of key information, information correctness, and professionalism. Coherence refers to the contextual relevance and rationality between the information, viewpoints, and sentences, forming a clear and easily comprehensible text. Sufficient key information refers to the ability of LLMs to extract, abstract, and organize important and complete information from the input reports, which is adequate for the examinee to formulate a reasonable response based on this background information. Information correctness indicates whether the question is reliable and
4. [4]:  Passage ID 4: answers for medical qualification exams aimed at medical students, interns and residents can be a significant focus of future research.1 IntroductionIn the interdisciplinary field of artificial intelligence and medicine, text generation is a challenging yet significant task. The rise of deep learning has brought great opportunities to the medical text generation, especially the booming development of Transformer-based autoregressive language models, which has considerably enhanced the model’s ability to process long contextual semantics, thereby enabling the generation of coherent and comprehensive text. Further, the automated generation of patient reports, doctor-patient question answering, and diagnostic reasoning, all rely on extensive and high-quality medical corpora. Nevertheless, due to hospital privacy protection requirements and the challenges in data sharing, LLMs show limited generalization to real-world medical usage.Researchers have employed fine-tuning, prompting
5. [5]:  Passage ID 5: question answering. Moreover, with the task of question answering in the specific domain of elderly chronic diseases under prompting of limited references, identifying and improving strategies to refine these four evaluation aspects shows a proper direction for subsequent research efforts.Subsequently, we tasked medical experts with evaluating and correcting a subset of flawed AI-generated answers in the form of open-ended short text. We sampled these evaluations and corrections as new prompt engineering materials, allowing the model to judge whether a correction is needed for the sampled AI-generated question-answer pairs, and to provide new answers. We intermingled the answers rectified by the model with those in the regular AI-generated answer in the evaluation phase, without the human experts being aware of which were directly generated, and which were rectified. Figure 3 shows the comparison of directly generated answers and those modified by the LLMs. It can be observed that,