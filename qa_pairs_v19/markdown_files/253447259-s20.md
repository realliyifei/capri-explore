# Grammatical Error Correction: A Survey of the State of the Art

## Question

What are the advantages and limitations of the edit generation approach in Grammatical Error Correction (GEC)?

## URLs

1. https://ar5iv.org/html/2402.15930. [2402.15930] Evaluating Prompting Strategies for Grammatical Error Correction Based on Language Proficiency
2. https://ar5iv.org/html/2109.06822. [2109.06822] LM-Critic: Language Models for Unsupervised Grammatical Error Correction
3. https://ar5iv.org/html/2404.14914. [2404.14914] Pillars of Grammatical Error Correction: Comprehensive Inspection Of Contemporary Approaches In The Era of Large Language Models
4. https://ar5iv.org/html/2410.10349. [2410.10349] LLM-based Code-Switched Text Generation for Grammatical Error Correction
5. https://ar5iv.org/html/2410.15539. [2410.15539] Grammatical Error Correction for Low-Resource Languages: The Case of Zarma
6. https://ar5iv.org/html/2408.09565. [2408.09565] Grammatical Error Feedback: An Implicit Evaluation Approach
7. https://ar5iv.org/html/2005.06600. [2005.06600] A Comprehensive Survey of Grammar Error Correction
8. https://ar5iv.org/html/2410.23507. [2410.23507] Efficient and Interpretable Grammatical Error Correction with Mixture of Experts
9. https://ar5iv.org/html/2311.09517. [2311.09517] GEE! Grammar Error Explanation with Large Language Models

## Answer (I don't know?: ‚úì)

I don't know. The context provided does not include specific information regarding the advantages and limitations of the edit generation approach in Grammatical Error Correction (GEC). While there are mentions of large language models (LLMs) and their performance in GEC, including issues like overcorrection and differences based on language proficiency, the context does not explicitly address the edit generation approach itself or how it compares to other methods. Without this essential information, I cannot provide a precise answer to the question.

1. [1]:  https://ar5iv.org/html/2404.14914, [2404.14914] Pillars of Grammatical Error Correction: Comprehensive Inspection Of Contemporary Approaches In The Era of Large Language Models
2. [2]:  https://ar5iv.org/html/2311.09517, [2311.09517] GEE! Grammar Error Explanation with Large Language Models
3. [3]:  https://ar5iv.org/html/2402.15930, [2402.15930] Evaluating Prompting Strategies for Grammatical Error Correction Based on Language Proficiency
4. [4]:  https://ar5iv.org/html/2402.15930, [2402.15930] Evaluating Prompting Strategies for Grammatical Error Correction Based on Language Proficiency
5. [5]:  https://ar5iv.org/html/2005.06600, [2005.06600] A Comprehensive Survey of Grammar Error Correction
---
1. [1]:  Passage ID 1: systems, comparing the efficiency of ensembling and ranking methods, and exploring the application of large language models to GEC as single-model systems, as parts of ensembles, and as ranking methods. We set new state-of-the-art performance111https://nlpprogress.com/english/grammatical_error_correction.html (Accessed 10 March 2024). with F0.5subscriptùêπ0.5F_{0.5} scores of 72.8 on CoNLL-2014-test and 81.4 on BEA-test, respectively. To support further advancements in GEC and ensure the reproducibility of our research, we make our code, trained models, and systems‚Äô outputs publicly available.222https://github.com/grammarly/pillars-of-gec1 IntroductionGrammatical Error Correction (GEC) is the task of correcting human text for spelling and grammatical errors. There is a wide variety of GEC approaches and model architectures. In recent years, most systems have used Transformer-based architectures Bryant et¬†al. (2023). A current trend involves writing prompts for Large Language
2. [2]:  Passage ID 2: reveals that our pipeline produces 93.9%percent93.993.9\% and 98.0%percent98.098.0\% correct explanations for German and Chinese data, respectively. To encourage further research in this area, we will open-source our data and code.111https://github.com/Yixiao-Song/GEE-with-LLMs1 IntroductionGrammatical error correction (GEC) is a practical and valuable application of natural language processing that facilitates both proofreading of text and language learning. Recent advances in large language models (LLMs) have significantly improved the capabilities of GEC systems (Wang et¬†al., 2021; Bryant et¬†al., 2023); however, they are unable to explain errors in natural language alongside providing correction.Error explanation is crucial to language learning and teaching (Ellis, 2010): while corrections are a form of implicit feedback, they are not as impactful as explicit feedback, which involves pointing out errors and providing meta-linguistic information to the user (e.g., rules of
3. [3]:  Passage ID 3: of language tasks, such as translation, summarization, and question answering, often achieving state-of-the-art results (Brown et¬†al., 2020).One such application of LLMs is Grammatical Error Correction (GEC).GEC is a challenging task in NLP that involves detecting and correcting grammatical mistakes in written text.LLMs like GPT have shown promising results in this domain, with their ability to generate fluent, grammatically correct text (e.g., Coyne et¬†al., 2023; Loem et¬†al., 2023).However, despite their impressive performance, these models are not without limitations.For example, LLMs have a tendency to overcorrect, leading to higher recall but lower precision measures (Fang et¬†al., 2023).Grammatical Error Correction has been a pivotal task in NLP, with numerous methodologies and systems being developed over the years to improve its performance.Prior to the advent of LLMs, the most effective GEC systems have predominantly adopted one of two paradigms: sequence-to-sequence
4. [4]:  Passage ID 4: for grammatical error correction (GEC) with selected large language models (LLM) based on language proficiency. GEC using generative LLMs has been known for overcorrection where results obtain higher recall measures than precision measures.The writing examples of English language learners may be different from those of native speakers.Given that there is a significant differences in second language (L2) learners‚Äô error types by their proficiency levels, this paper attempts to reduce overcorrection by examining the interaction between LLM‚Äôs performance and L2 language proficiency.Our method focuses on zero-shot and few-shot prompting and fine-tuning models for GEC for learners of English as a foreign language based on the different proficiency.We investigate GEC results and find that overcorrection happens primarily in advanced language learners‚Äô writing (proficiency C) rather than proficiency A (a beginner level) and proficiency B (an intermediate level).Fine-tuned LLMs, and even
5. [5]:  Passage ID 5: and LanguagearXiv:2005.06600 (cs)  [Submitted on 2 May 2020]Title:A Comprehensive Survey of Grammar Error CorrectionAuthors:Yu Wang, Yuelin Wang, Jie Liu, Zhuo Liu View a PDF of the paper titled A Comprehensive Survey of Grammar Error Correction, by Yu Wang and 3 other authorsView PDFAbstract:Grammar error correction (GEC) is an important application aspect of natural language processing techniques. The past decade has witnessed significant progress achieved in GEC for the sake of increasing popularity of machine learning and deep learning, especially in late 2010s when near human-level GEC systems are available. However, there is no prior work focusing on the whole recapitulation of the progress. We present the first survey in GEC for a comprehensive retrospect of the literature in this area. We first give the introduction of five public datasets, data annotation schema, two important shared tasks and four standard evaluation metrics. More importantly, we discuss four