# Discourse-Oriented Anaphora Resolution in Natural Language Understanding: A Review

## Question

How does the discourse-cohesion approach use cohesive ties to aid in coreference resolution?

## URLs

1. https://ar5iv.org/html/2205.10192. [2205.10192] On the Trade-off between Redundancy and Local Coherence in Summarization
2. https://ar5iv.org/html/2404.19505. [2404.19505] Context-Aware Machine Translation with Source Coreference Explanation
3. https://ar5iv.org/html/2102.10979. [2102.10979] Towards Personalised and Document-level Machine Translation of Dialogue
4. https://ar5iv.org/html/2305.11529. [2305.11529] A Sequence-to-Sequence Approach for Arabic Pronoun Resolution
5. https://ar5iv.org/html/2006.05621. [2006.05621] Understanding Points of Correspondence between Sentences for Abstractive Summarization
6. https://ar5iv.org/html/2406.07081. [2406.07081] Efficiently Exploring Large Language Models for Document-Level Machine Translation with In-context Learning
7. https://ar5iv.org/html/2001.02380. [2001.02380] A Neural Approach to Discourse Relation Signal Detection
8. https://ar5iv.org/html/2305.10196. [2305.10196] A Survey on Zero Pronoun Translation
9. https://ar5iv.org/html/1809.00647. [1809.00647] Automatic Event Salience Identification

## Answer (I don't know?: ✗)

The discourse-cohesion approach utilizes cohesive ties to enhance coreference resolution by focusing on the relationships and connections between text elements, which can help clarify references made in a document. This approach is grounded in the understanding that cohesive devices—such as references, repetition, and other forms of lexical cohesion—play a crucial role in creating coherence in texts.

Cohesive ties serve as markers that link sentences and phrases, allowing for a better comprehension of who or what is being referred to, especially in complex sentences where multiple referents may exist. For instance, pronominal and nominal referencing (e.g., using pronouns like "he" or nouns like "the car") are essential cohesive devices identified in discourse-cohesion theory. These ties enable the identification of antecedents for pronouns or other referential expressions, thereby improving coreference resolution [1][4].

Moreover, the process of sentence fusion—merging separate sentences into a coherent whole—further emphasizes the importance of cohesive ties. By creating a dataset that contains documents alongside source and fusion sentences, researchers can examine how points of correspondence (which are cohesive devices that tie sentences together) contribute to better understanding and resolving references [4]. This methodology helps bridge gaps between coreference resolution and summarization tasks, facilitating clearer interpretation of text through identified cohesive links [4].

In practice, the discourse-cohesion approach employs contextual information from the surrounding text. For instance, coreference resolution can benefit from insights derived from previous studies that indicate Transformer models are capable of tracking cohesion phenomena provided they have sufficient context available [5]. By preprocessing documents to mark cohesion features before applying machine learning models, the discourse-cohesion approach significantly stabilizes performance in coreference resolution tasks [5].

To summarize, the discourse-cohesion approach employs cohesive ties to aid in coreference resolution by leveraging the connections and relationships established by cohesive devices to clarify references in text. This is achieved through a detailed understanding of discourse relations and the development of datasets designed to enhance the merging of sentence meanings, ultimately leading to more coherent translations and improved NLP outcomes.

1. [1]:  https://ar5iv.org/html/2102.10979, [2102.10979] Towards Personalised and Document-level Machine Translation of Dialogue
2. [2]:  https://ar5iv.org/html/2006.05621, [2006.05621] Understanding Points of Correspondence between Sentences for Abstractive Summarization
3. [3]:  https://ar5iv.org/html/2001.02380, [2001.02380] A Neural Approach to Discourse Relation Signal Detection
4. [4]:  https://ar5iv.org/html/2006.05621, [2006.05621] Understanding Points of Correspondence between Sentences for Abstractive Summarization
5. [5]:  https://ar5iv.org/html/2102.10979, [2102.10979] Towards Personalised and Document-level Machine Translation of Dialogue
---
1. [1]:  Passage ID 1: resolution have attracted great interest in the recent years (e.g. Rønning et al., 2018; Jwalapuram et al., 2020). Previous research on cohesion within DocNMT has revealed that verb phrase ellipsis, coreference and reiteration (a type of lexical cohesion) may be particularly erroneous in MT (e.g. Tiedemann and Scherrer, 2017; Bawden et al., 2018; Voita et al., 2020).Coherence phenomenaCoherence is consistency of text with the context of situation Halliday and Hasan (1976). MT of dialogue may be erroneous due to models not having access to extra-textual information222Note: the focus here is on sentence-level translation utilising extra-textual context., e.g.: (a) speaker gender and number, (b) interlocutor gender and number, (c) social addressing, and (d) discourse situation. Different languages may render such phenomena differently, e.g. formality in German is expressed through the formal pronoun Sie (e.g. “Are you hungry?” becomes “Bist du hungrig?” when informal and “Sind Sie
2. [2]:  Passage ID 2: five categories of cohesion: reference, lexical cohesion, ellipsis, substitution and conjunction.In contrast, coherence is defined in terms of discourse relations between textual elements, such as elaboration, cause or explanation.Previous work studied discourse relations Geva et al. (2019), this paper instead focuses on text cohesion, which plays a crucial role in generating proper fusion sentences.Our dataset contains pairs of source and fusion sentences collected from news editors in a natural environment.The work is particularly meaningful to text-to-text and data-to-text generation Gatt and Krahmer (2018) that demand robust modules to merge disparate content.We contrast our dataset with previous sentence fusion datasets. McKeown et al. McKeown et al. (2010) compile a corpus of 300 sentence fusions as a first step toward a supervised fusion system. However, the input sentences have very similar meaning, though they often present lexical variations and different details. In
3. [3]:  Passage ID 3: to motivate research on theory-neutral and genre-diverse discourse processing, which would be beneficial for pushing forward theories of discourse across frameworks or formalisms. Furthermore, employing a computational approach to studying discourse relations has a promising impact on various NLP downstream tasks such as question answering and document summarization etc. For example, Narasimhan and Barzilay (2015) incorporated discourse information into the task of automated text comprehension and benefited from such information without relying on explicit annotations of discourse structure during training, which outperformed state-of-the-art text comprehension systems at the time.Towards this goal, we begin by reviewing some previous work in the traditions sketched out above in the next section, and point out some open questions which we would like to address. In Section 3 we present the discourse annotated data that we will be using, which covers a number of English text types
4. [4]:  Passage ID 4: real-world scenarios.In this paper, we present an investigation into fusing sentences drawn from a document by introducing the notion of points of correspondence, which are cohesive devices that tie any two sentences together into a coherent text.The types of points of correspondence are delineated by text cohesion theory, covering pronominal and nominal referencing, repetition and beyond.We create a dataset containing the documents, source and fusion sentences, and human annotations of points of correspondence between sentences.Our dataset bridges the gap between coreference resolution and summarization.It is publicly shared to serve as a basis for future work to measure the success of sentence fusion systems.111https://github.com/ucfnlp/points-of-correspondence1 Introduction[Source Sentences]Robert Downey Jr. is making headlines for walking out of aninterview with a British journalist who dared to veer away from thesuperhero movie Downey was there to
5. [5]:  Passage ID 5: the elided content nevertheless have been used to disambiguate it or make it more cohesive?Next, we aim to build a DocNMT system which utilises marking of cohesion phenomena to make more cohesive translation choices555Including elliptical structures in this step will depend on the result of the first experiment. (Figure 3). We apply the insights from previous research, namely that the Transformer model may track cohesion phenomena when given enough context (Voita et al., 2018), that context preprocessing stabilises performance of contextual MT models (Kim et al., 2019), solutions to the problem of long inputs in DocNMT (e.g. Ma et al., 2020; Sun et al., 2020), and finally our own analysis of the problem.Figure 3: A draft of our DocNMT pipeline architecture. We preprocess the document to mark cohesion features. Then we use the output as the data for our model.3.3 Applying Evaluation Metrics to Cohesion and Speaker PhenomenaAddressing RQ3 will involve testing the hypothesis