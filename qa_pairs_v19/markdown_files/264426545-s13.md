# Automatic Pronunciation Assessment -A Review

## Question

How have recent unsupervised methods improved the detection of mispronunciation errors in speech assessment?

## URLs

1. https://ar5iv.org/html/2201.10198. [2201.10198] Improved Mispronunciation detection system using a hybrid CTC-ATT based approach for L2 English speakers
2. https://ar5iv.org/html/2103.03023. [2103.03023] End-to-End Mispronunciation Detection and Diagnosis From Raw Waveforms
3. https://ar5iv.org/html/2207.00774. [2207.00774] Computer-assisted Pronunciation Training - Speech synthesis is almost all you need
4. https://ar5iv.org/html/2203.15937. [2203.15937] Improving Mispronunciation Detection with Wav2vec2-based Momentum Pseudo-Labeling for Accentedness and Intelligibility Assessment
5. https://ar5iv.org/html/2307.16324. [2307.16324] Mispronunciation detection using self-supervised speech representations
6. https://ar5iv.org/html/2101.06396. [2101.06396] MISPRONUNCIATION DETECTION IN NON-NATIVE (L2) ENGLISH WITH UNCERTAINTY MODELING
7. https://ar5iv.org/html/2106.03494. [2106.03494] Weakly-supervised word-level pronunciation error detection in non-native English speech
8. https://ar5iv.org/html/2310.13974. [2310.13974] Automatic Pronunciation Assessment - A Review
9. https://ar5iv.org/html/2205.02670. [2205.02670] Unsupervised Mismatch Localization in Cross-Modal Sequential Data with Application to Mispronunciations Localization
10. https://ar5iv.org/html/2403.08187. [2403.08187] Automatic Speech Recognition (ASR) for the Diagnosis of pronunciation of Speech Sound Disorders in Korean children Preprint. Under review.

## Answer (I don't know?: ✗)

Recent advancements in unsupervised methods for detecting mispronunciation errors in speech assessment have shown promising yet still sub-optimal results. Traditional approaches for mispronunciation detection have generally required significant expert input, intensive manual labeling, or reliable automatic speech recognition (ASR) results, which all involve considerable costs and resources [1] [2] [3] [4]. In contrast, the focus has shifted towards unsupervised acoustic pattern discovery, aiming to alleviate some of these constraints.

One notable study by Lee and Glass (2012) introduced a comparison-based approach that evaluates misalignment between a student’s speech and a teacher’s speech, creating a basis for identifying pronunciation discrepancies [1] [2]. This foundational work set the stage for subsequent research where Lee and Glass (2015) and Lee et al. (2016) further explored the detection of mispronunciations by analyzing the acoustic similarities among individual learners’ utterances. They proposed an n-best filtering method to address ambiguous hypotheses regarding error candidates derived from acoustic similarity clustering [1] [2].

The evolution of these techniques has not only focused on the acoustic analysis but has also integrated unsupervised learning methods, a shift towards k-means clustering on phoneme-based phonemic posterior-grams (PPGs) as proposed by Mao et al. (2018). This advancement aimed to broaden the phoneme set used in second language (L2) speech processing, thereby enhancing the capability to detect nuanced pronunciation errors that may not be captured in more traditional models [1] [2].

Nevertheless, these unsupervised methods have limitations, particularly in their accuracy. Reports indicate a lack of precision, with only 60% precision at varying recall levels (40%-80%) being achieved in actual detection scenarios [5]. A significant challenge remains the scarcity of data on mispronounced speech essential for training reliable pronunciation error detection models. To tackle this issue, innovative techniques based on phoneme-to-phoneme (P2P), text-to-speech (T2S), and speech-to-speech (S2S) conversion have emerged. These generative models can produce synthetic speech that includes both correctly pronounced and mispronounced samples, thereby augmenting the training dataset and improving the overall performance of the detection models [5].

In summary, recent unsupervised methods have made strides in examining acoustic similarities and patterns in learners’ speech, yet challenges in precision and data availability persist. The introduction of synthetic speech generation techniques offers a viable path forward, enhancing training datasets and enabling more robust models capable of detecting pronunciation errors more effectively [5]. Thus, while progress has been made, ongoing research and development are critical for establishing higher accuracy levels in unsupervised mispronunciation detection.

1. [1]:  https://ar5iv.org/html/2310.13974, [2310.13974] Automatic Pronunciation Assessment - A Review
2. [2]:  https://ar5iv.org/html/2310.13974, [2310.13974] Automatic Pronunciation Assessment - A Review
3. [3]:  https://ar5iv.org/html/2310.13974, [2310.13974] Automatic Pronunciation Assessment - A Review
4. [4]:  https://ar5iv.org/html/2310.13974, [2310.13974] Automatic Pronunciation Assessment - A Review
5. [5]:  https://ar5iv.org/html/2207.00774, [2207.00774] Computer-assisted Pronunciation Training - Speech synthesis is almost all you need
---
1. [1]:  Passage ID 1: approaches for studying mispronunciation detection typically involve the need for expert knowledge, laborious manual labeling, or dependable ASR results, all of which come with significant costs. In contrast, recent years have witnessed considerable endeavors in unsupervised acoustic pattern discovery, yielding sub-optimal outcomes. Lee and Glass (2012) initially investigated a comparison-based approach that analyzes the extent of misalignment between a student’s speech and a teacher’s speech. In subsequent studies Lee and Glass (2015); Lee et al. (2016), explored the discovery of mispronunciation errors by analyzing the acoustic similarities across individual learners’ utterances, with a proposed n-best filtering method to resolve ambiguous error candidate hypotheses derived from acoustic similarity clustering. Furthermore, Mao et al. (2018) proposed k-means clustering on phoneme-based phonemic posterior-grams (PPGs) to expand the phoneme set in L2 speech. More recently, Sini et al.
2. [2]:  Passage ID 2: approaches for studying mispronunciation detection typically involve the need for expert knowledge, laborious manual labeling, or dependable ASR results, all of which come with significant costs. In contrast, recent years have witnessed considerable endeavors in unsupervised acoustic pattern discovery, yielding sub-optimal outcomes. Lee and Glass (2012) initially investigated a comparison-based approach that analyzes the extent of misalignment between a student’s speech and a teacher’s speech. In subsequent studies Lee and Glass (2015); Lee et al. (2016), explored the discovery of mispronunciation errors by analyzing the acoustic similarities across individual learners’ utterances, with a proposed n-best filtering method to resolve ambiguous error candidate hypotheses derived from acoustic similarity clustering. Furthermore, Mao et al. (2018) proposed k-means clustering on phoneme-based phonemic posterior-grams (PPGs) to expand the phoneme set in L2 speech. More recently, Sini et al.
3. [3]:  Passage ID 3: approaches for studying mispronunciation detection typically involve the need for expert knowledge, laborious manual labeling, or dependable ASR results, all of which come with significant costs. In contrast, recent years have witnessed considerable endeavors in unsupervised acoustic pattern discovery, yielding sub-optimal outcomes. Lee and Glass (2012) initially investigated a comparison-based approach that analyzes the extent of misalignment between a student’s speech and a teacher’s speech. In subsequent studies Lee and Glass (2015); Lee et al. (2016), explored the discovery of mispronunciation errors by analyzing the acoustic similarities across individual learners’ utterances, with a proposed n-best filtering method to resolve ambiguous error candidate hypotheses derived from acoustic similarity clustering. Furthermore, Mao et al. (2018) proposed k-means clustering on phoneme-based phonemic posterior-grams (PPGs) to expand the phoneme set in L2 speech. More recently, Sini et al.
4. [4]:  Passage ID 4: approaches for studying mispronunciation detection typically involve the need for expert knowledge, laborious manual labeling, or dependable ASR results, all of which come with significant costs. In contrast, recent years have witnessed considerable endeavors in unsupervised acoustic pattern discovery, yielding sub-optimal outcomes. Lee and Glass (2012) initially investigated a comparison-based approach that analyzes the extent of misalignment between a student’s speech and a teacher’s speech. In subsequent studies Lee and Glass (2015); Lee et al. (2016), explored the discovery of mispronunciation errors by analyzing the acoustic similarities across individual learners’ utterances, with a proposed n-best filtering method to resolve ambiguous error candidate hypotheses derived from acoustic similarity clustering. Furthermore, Mao et al. (2018) proposed k-means clustering on phoneme-based phonemic posterior-grams (PPGs) to expand the phoneme set in L2 speech. More recently, Sini et al.
5. [5]:  Passage ID 5: are not able to detect pronunciation errors with high accuracy (only 60% precision at 40%-80% recall). One of the key problems is the low availability of mispronounced speech that is needed for the reliable training of pronunciation error detection models. If we had a generative model that could mimic non-native speech and produce any amount of training data, then the task of detecting pronunciation errors would be much easier. We present three innovative techniques based on phoneme-to-phoneme (P2P), text-to-speech (T2S), and speech-to-speech (S2S) conversion to generate correctly pronounced and mispronounced synthetic speech. We show that these techniques not only improve the accuracy of three machine learning models for detecting pronunciation errors but also help establish a new state-of-the-art in the field. Earlier studies have used simple speech generation techniques such as P2P conversion, but only as an additional mechanism to improve the accuracy of pronunciation error