# Transformers as Recognizers of Formal Languages: A Survey on Expressivity

## Question

How does the encoder-decoder architecture improve the processing and acceptance of strings in formal language recognition?

## URLs

1. https://ar5iv.org/html/2311.00208. [2311.00208] Transformers as Recognizers of Formal Languages: A Survey on Expressivity
2. https://ar5iv.org/html/1807.10854. [1807.10854] A Survey of the Usages of Deep Learning for Natural Language Processing
3. https://ar5iv.org/html/2406.05564. [2406.05564] Automata Extraction from Transformers
4. https://ar5iv.org/html/2108.03968. [2108.03968] Not quite there yet: Combining analogical patterns and encoder-decoder networks for cognitively plausible inflection
5. https://ar5iv.org/html/2006.01338. [2006.01338] A Survey of Neural Networks and Formal Languages 11footnote 1This work was partially supported by DARPA Safedocs Program award HR001119C0075 for which SRI is the prime contractor and Dartmouth is a subcontractor.
6. https://ar5iv.org/html/2406.00515. [2406.00515] A Survey on Large Language Models for Code Generation
7. https://ar5iv.org/html/2404.09022. [2404.09022] Navigating the Landscape of Large Language Models: A Comprehensive Review and Analysis of Paradigms and Fine-Tuning Strategies
8. https://ar5iv.org/html/2402.05121. [2402.05121] Large Language Model for Table Processing: A Survey
9. https://ar5iv.org/html/1904.06100. [1904.06100] Adapting Sequence to Sequence models for Text Normalization in Social Media

## Answer (I don't know?: âœ—)

Error: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable