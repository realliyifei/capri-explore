# A Survey of Evaluation Methods of Generated Medical Textual Reports

## Question

What is the significance of involving domain experts in the human evaluation of generated medical textual reports?

## URLs

1. https://ar5iv.org/html/2410.17357. [2410.17357] Image-aware Evaluation of Generated Medical Reports
2. https://ar5iv.org/html/2401.06775. [2401.06775] Large Language Models in Healthcare and Medical Domain: A Review
3. https://ar5iv.org/html/2402.15422. [2402.15422] A Data-Centric Approach To Generate Faithful and High Quality Patient Summaries with Large Language Models
4. https://ar5iv.org/html/2310.05694. [2310.05694] A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics
5. https://ar5iv.org/html/2406.15045. [2406.15045] Harnessing Knowledge Retrieval with Large Language Models for Clinical Report Error Correction
6. https://ar5iv.org/html/2410.23851. [2410.23851] Leveraging Large Language Models for Medical Information Extraction and Query Generation
7. https://ar5iv.org/html/2309.07430. [2309.07430] Adapted Large Language Models Can Outperform Medical Experts in Clinical Text Summarization
8. https://ar5iv.org/html/2406.15019. [2406.15019] MedOdyssey: A Medical Domain Benchmark for Long Context Evaluation Up to 200K Tokens
9. https://ar5iv.org/html/2410.00163. [2410.00163] Adapting LLMs for the Medical Domain in Portuguese: A Study on Fine-Tuning and Model Evaluation This study was funded by the São Paulo Research Foundation (FAPESP) grants 2013/07375-0, 2019/07665-4, 2023/14427-8, 2024/00789-8, and 2024/01336-7, and the National Council for Scientific and Technological Development (CNPq) grants 308529/2021-9 and 400756/2024-2. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.

## Answer (I don't know?: ✗)

Involving domain experts in the human evaluation of generated medical textual reports is crucial for several reasons that enhance the quality, reliability, and applicability of these reports in clinical practice.

Firstly, the performance of large language models (LLMs) on clinical tasks may not meet the high standards required in healthcare settings. While LLMs have shown outstanding advancements in natural language processing (NLP) capabilities, their effectiveness across diverse clinical summarization tasks remains unproven [4]. Unlike standard NLP tasks, medical tasks demand a high level of accuracy and contextual understanding due to the sensitive nature of the content and its direct impact on patient care [3]. Therefore, expert involvement is essential to ensure that the summaries generated by LLMs are not only coherent but also clinically relevant and safe for patient care.

Secondly, human evaluations by expert clinicians can assess aspects of the generated summaries that automated NLP metrics cannot adequately measure. For instance, comparing LLM-generated summaries to those created by experienced medical professionals can provide insights into completeness, correctness, and conciseness [4]. In a clinical reader study highlighted in the research, it was found that summaries from the best-adapted LLMs were often reported to be equivalent or superior to those produced by medical experts in many cases, showcasing the potential of these models when properly evaluated [4]. This form of expert evaluation also ensures that nuances in medical language and context, which machines may overlook, are addressed effectively.

Moreover, the inclusion of professionals in the evaluation process helps to maintain a standard of clinical readiness for these AI systems. Given the critical nature of medical tasks, demonstrating that AI-generated outputs align with the expectations and needs of healthcare practitioners is paramount [2]. Studies illustrate that relying solely on NLP metrics could result in misleading assessments of summary quality; thus, engaging human experts can bridge this gap, offering a more rigorous evaluation framework [2] [4]. 

In summary, the significance of involving domain experts in the evaluation of generated medical textual reports lies in enhancing the accuracy, relevance, and safety of the outputs, ultimately supporting higher-quality patient care and ensuring that AI technologies are aligned with clinical practices.

1. [1]:  https://ar5iv.org/html/2310.05694, [2310.05694] A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics
2. [2]:  https://ar5iv.org/html/2309.07430, [2309.07430] Adapted Large Language Models Can Outperform Medical Experts in Clinical Text Summarization
3. [3]:  https://ar5iv.org/html/2309.07430, [2309.07430] Adapted Large Language Models Can Outperform Medical Experts in Clinical Text Summarization
4. [4]:  https://ar5iv.org/html/2309.07430, [2309.07430] Adapted Large Language Models Can Outperform Medical Experts in Clinical Text Summarization
5. [5]:  https://ar5iv.org/html/2410.23851, [2410.23851] Leveraging Large Language Models for Medical Information Extraction and Query Generation
---
1. [1]:  Passage ID 1: it is important to note that their present capabilities do not categorize them as comprehensive AI systems. They still face performance limitations, particularly when compared to expert models, across multiple domains that necessitate domain-specific knowledge. On the other hand, the state-of-the-art LLMs demonstrate commendable performance in grasping general scientific knowledge and are capable of generating open-ended responses to science-related inquiries. Nevertheless, they are susceptible to errors, particularly when tackling questions that necessitate intricate multi-step reasoning. The exceptional proficiency in language presents a hurdle for users to accurately evaluate the factual correctness of information, thereby giving rise to a spectrum of ethical considerations.In this section, we will begin by introducing studies on the evaluation of general NLP tasks.Subsequently, we will review studies focusing on Healthcare evaluation, discussing aspects such as robustness,
2. [2]:  Passage ID 2: a concise “problem list” of medical diagnoses [42]. Lastly, there has been significant work on summarizing extended conversations between a doctor and patient into patient visit summaries [43, 44, 28].While the aforementioned contributions incorporate methods to adapt language models, they often include only a small subset of potential approaches and models, and/or they predominantly rely on evaluation via standard NLP metrics. Given the critical nature of medical tasks, demonstrating clinical readiness requires including human experts in the evaluation process. To address this, there have been recent releases of expert evaluations for instruction following [3] and radiology report generation [45]. Other work employs human experts to evaluate synthesized Cochrane review abstracts, demonstrating that NLP metrics are not sufficient to measure summary quality [46]. With this in mind, weextend our comprehensive evaluation of methods and LLMs beyond NLP metrics to incorporate a clinical
3. [3]:  Passage ID 3: significant work stress [11, 12, 13]. These tasks divert attention from direct patient care, leading to worse outcomes for patients and decreased job satisfaction for clinicians [2, 14, 15, 16].In recent years, large language models (LLMs) have gained remarkable traction, leading to widespread adoption of models such as ChatGPT [17], which excel at information retrieval, nuanced understanding, and text generation [18, 19]. Although LLM benchmarks for general natural language processing (NLP) tasks exist [20, 21], they do not evaluate performance on relevant clinical tasks. Addressing this limitation presents an opportunity to accelerate the process of clinical text summarization, hence alleviating documentation burden and improving patient care.Crucially, machine-generated summaries must be non-inferior to that of seasoned clinicians—especially when used to support sensitive clinical decision-making. Previous work has demonstrated potential across clinical NLP tasks [22, 23],
4. [4]:  Passage ID 4: Akshay S. ChaudhariStanford UniversityAbstractAnalyzing vast textual data and summarizing key information from electronic health records imposes a substantial burden on how clinicians allocate their time. Although large language models (LLMs) have shown promise in natural language processing (NLP), their effectiveness on a diverse range of clinical summarization tasks remains unproven. In this study, we apply adaptation methods to eight LLMs, spanning four distinct clinical summarization tasks: radiology reports, patient questions, progress notes, and doctor-patient dialogue. Quantitative assessments with syntactic, semantic, and conceptual NLP metrics reveal trade-offs between models and adaptation methods. A clinical reader study with ten physicians evaluates summary completeness, correctness, and conciseness; in a majority of cases, summaries from our best adapted LLMs are either equivalent (45%) or superior (36%) compared to summaries from medical experts. The ensuing safety
5. [5]:  Passage ID 5: so it eliminates transmissions of private information to third parties, ensuring data privacy.The LLM processes the clinical note and generates a query following the prompt instructions.In a real-world application of the system, the medical expert can accept the generated query as-is or modify it with further domain-specific knowledge.This interaction, illustrated with dashed arrows in Figure 1, allows for human oversight and refinement of the AI-generated content, enhancing human-AI collaboration [40].Once finalized, the query is input into an Information Retrieval (IR) system.This system leverages an index of publicly available clinical trials, and using an IR model ranks these trials based on theirrelevanceto the provided query.The process concludes with the medical expert being presented a ranked list of clinical trials, with the most relevant trial appearing first in the results.Ultimately, the expert reviews the retrieved clinical trials and selects the most appropriate