# A Survey of Evaluation Methods of Generated Medical Textual Reports

## Question

What is the significance of involving domain experts in the human evaluation of generated medical textual reports?

## URLs

1. https://ar5iv.org/html/2410.17357. [2410.17357] Image-aware Evaluation of Generated Medical Reports
2. https://ar5iv.org/html/2401.06775. [2401.06775] Large Language Models in Healthcare and Medical Domain: A Review
3. https://ar5iv.org/html/2402.15422. [2402.15422] A Data-Centric Approach To Generate Faithful and High Quality Patient Summaries with Large Language Models
4. https://ar5iv.org/html/2310.05694. [2310.05694] A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics
5. https://ar5iv.org/html/2406.15045. [2406.15045] Harnessing Knowledge Retrieval with Large Language Models for Clinical Report Error Correction
6. https://ar5iv.org/html/2410.23851. [2410.23851] Leveraging Large Language Models for Medical Information Extraction and Query Generation
7. https://ar5iv.org/html/2309.07430. [2309.07430] Adapted Large Language Models Can Outperform Medical Experts in Clinical Text Summarization
8. https://ar5iv.org/html/2406.15019. [2406.15019] MedOdyssey: A Medical Domain Benchmark for Long Context Evaluation Up to 200K Tokens
9. https://ar5iv.org/html/2410.00163. [2410.00163] Adapting LLMs for the Medical Domain in Portuguese: A Study on Fine-Tuning and Model Evaluation This study was funded by the São Paulo Research Foundation (FAPESP) grants 2013/07375-0, 2019/07665-4, 2023/14427-8, 2024/00789-8, and 2024/01336-7, and the National Council for Scientific and Technological Development (CNPq) grants 308529/2021-9 and 400756/2024-2. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.

## Answer (I don't know?: ✗)

Involving domain experts in the human evaluation of generated medical textual reports is crucial for several reasons. Firstly, the complexity and critical nature of medical tasks necessitate that evaluations go beyond standard NLP metrics, which may not adequately measure the quality and relevance of the generated reports. Human experts provide essential insights that can assess the practical applicability and clinical readiness of these reports, which automatic evaluation methods often fail to capture [2]. Their involvement ensures that the evaluations consider factors intrinsic to medical practice, such as the accuracy of diagnoses, coherence of clinical narratives, and overall professionalism [5].

Notably, the performance of LLMs in generating medical content can be significantly inferior when evaluated on criteria relevant to healthcare providers. For instance, studies indicate that LLMs receive lower average scores for question answering tasks compared to question generation, thus highlighting a performance gap that experts can help identify and address [5]. The criteria used by human evaluators—coherence, factual consistency, evidence of statements, and professionalism—underscore the qualitative aspects of generated texts that are vital for clinical contexts. These aspects often extend beyond what traditional metrics can evaluate, illustrating the necessity for domain experts to substantiate claims of reliability and effectiveness [5].

Moreover, the context-specific requirements within healthcare mean that simply generating text with high fluency is insufficient. Generated reports must not only be grammatically correct but also contextually accurate, firmly grounded in current medical knowledge and tailored to patient needs [4]. This requirement emphasizes the need for experts who can provide feedback on the usability and effectiveness of LLM-generated texts in real-world medical settings.

Furthermore, since data access in healthcare is often hindered by privacy regulations, LLMs may struggle with generalization to real-world applications. This situation is exacerbated by the limited human evaluation of NLP tools in health systems, making it difficult to measure their real-world effectiveness [3]. Involving experts in the evaluation process can address these gaps by incorporating a nuanced understanding of medical outcomes that cannot be discerned through automatic metrics alone. The feedback provided by these evaluations is vital for improving the performance and applicability of NLP tools in healthcare settings.

In conclusion, the significance of incorporating domain experts in evaluating generated medical textual reports lies in their ability to assess quality beyond surface-level fluency and conformity to metrics. Their evaluations ensure that the outputs are suitable for patient care and align with clinical standards, ultimately enhancing the efficacy and reliability of NLP-powered tools in the medical field [2] [3] [5].

1. [1]:  https://ar5iv.org/html/2310.05694, [2310.05694] A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics
2. [2]:  https://ar5iv.org/html/2309.07430, [2309.07430] Adapted Large Language Models Can Outperform Medical Experts in Clinical Text Summarization
3. [3]:  https://ar5iv.org/html/2305.12544, No Title
4. [4]:  https://ar5iv.org/html/2410.23769, No Title
5. [5]:  https://ar5iv.org/html/2410.23769, No Title
---
1. [1]:  Passage ID 1: it is important to note that their present capabilities do not categorize them as comprehensive AI systems. They still face performance limitations, particularly when compared to expert models, across multiple domains that necessitate domain-specific knowledge. On the other hand, the state-of-the-art LLMs demonstrate commendable performance in grasping general scientific knowledge and are capable of generating open-ended responses to science-related inquiries. Nevertheless, they are susceptible to errors, particularly when tackling questions that necessitate intricate multi-step reasoning. The exceptional proficiency in language presents a hurdle for users to accurately evaluate the factual correctness of information, thereby giving rise to a spectrum of ethical considerations.In this section, we will begin by introducing studies on the evaluation of general NLP tasks.Subsequently, we will review studies focusing on Healthcare evaluation, discussing aspects such as robustness,
2. [2]:  Passage ID 2: a concise “problem list” of medical diagnoses [42]. Lastly, there has been significant work on summarizing extended conversations between a doctor and patient into patient visit summaries [43, 44, 28].While the aforementioned contributions incorporate methods to adapt language models, they often include only a small subset of potential approaches and models, and/or they predominantly rely on evaluation via standard NLP metrics. Given the critical nature of medical tasks, demonstrating clinical readiness requires including human experts in the evaluation process. To address this, there have been recent releases of expert evaluations for instruction following [3] and radiology report generation [45]. Other work employs human experts to evaluate synthesized Cochrane review abstracts, demonstrating that NLP metrics are not sufficient to measure summary quality [46]. With this in mind, weextend our comprehensive evaluation of methods and LLMs beyond NLP metrics to incorporate a clinical
3. [3]:  Passage ID 3: as work to date has primarily focused on English or other high-resource languages Mondal et al. (2022) but devoted less efforts towards minority languages. Additionally, the lack of human evaluation of NLP-based health systems has made it challenging to measure their effectiveness in the real world. Current automatic evaluation metrics do not necessarily speak to patient outcomes. Hence, human-centric studies must be conducted in evaluating the efficacy of NLP-powered tools in healthcare.Research Directions.1.Healthcare benchmark construction. Although the documentation of recent LLMs reports very high performance for various medical question answering benchmarks, or medical licensing texts, there are many other tasks in healthcare that lack the data required to achieve similarly good performance. Access to medical datasets is often limited because of privacy issues, and therefore other approaches may be required to compile such benchmarks. Synthetic datasets are one such
4. [4]:  Passage ID 4: answers for medical qualification exams aimed at medical students, interns and residents can be a significant focus of future research.1 IntroductionIn the interdisciplinary field of artificial intelligence and medicine, text generation is a challenging yet significant task. The rise of deep learning has brought great opportunities to the medical text generation, especially the booming development of Transformer-based autoregressive language models, which has considerably enhanced the model’s ability to process long contextual semantics, thereby enabling the generation of coherent and comprehensive text. Further, the automated generation of patient reports, doctor-patient question answering, and diagnostic reasoning, all rely on extensive and high-quality medical corpora. Nevertheless, due to hospital privacy protection requirements and the challenges in data sharing, LLMs show limited generalization to real-world medical usage.Researchers have employed fine-tuning, prompting
5. [5]:  Passage ID 5: in determining whether the questions are professionally appropriate, the LLMs still incur a loss of critical information during the process of extracting and abstracting information from the input reports.Furthermore, human medical experts evaluated the AI-generated answers based on four criteria: coherence, factual consistency, evidence of statement, and professionalism. Figure 2 depicts the average scores of different LLMs’ answers toward a same sampled set of AI-generated questions. It can be observed that the average score for question answering is lower than that for question generation, with LLMs’ ratings hovering around 3.5 across all evaluation metrics. This indicates a significant gap between the performance of LLMs and the critical requirements of human experts for medical open-ended question answering. Moreover, with the task of question answering in the specific domain of elderly chronic diseases under prompting of limited references, identifying and improving strategies