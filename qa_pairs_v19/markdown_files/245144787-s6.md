# Measure and Improve Robustness in NLP Models: A Survey

## Question

How do adversarial attacks in computer vision and natural language processing differ in terms of perceptibility and the alteration of sentence meaning?

## URLs

1. https://ar5iv.org/html/2203.06414. [2203.06414] A Survey of Adversarial Defences and Robustness in NLP
2. https://ar5iv.org/html/2208.10251. [2208.10251] Rethinking Textual Adversarial Defense for Pre-trained Language Models
3. https://ar5iv.org/html/2311.11861. [2311.11861] Generating Valid and Natural Adversarial Examples with Large Language Models
4. https://ar5iv.org/html/1901.06796. [1901.06796] Adversarial Attacks on Deep Learning Models in Natural Language Processing: A Survey
5. https://ar5iv.org/html/2409.16491. [2409.16491] Proactive Schemes: A Survey of Adversarial Attacks for Social Good
6. https://ar5iv.org/html/2110.13980. [2110.13980] Adversarial Attacks and Defenses for Social Network Text Processing Applications: Techniques, Challenges and Future Research Directions
7. https://ar5iv.org/html/2307.15043. [2307.15043] Universal and Transferable Adversarial Attacks on Aligned Language Models
8. https://ar5iv.org/html/1903.06620. [1903.06620] On Evaluation of Adversarial Perturbations for Sequence-to-Sequence Models
9. https://ar5iv.org/html/2303.01234. [2303.01234] Fraud’s Bargain Attack: Generating Adversarial Text Samples via Word Manipulation Process
10. https://ar5iv.org/html/2407.21073. [2407.21073] Enhancing Adversarial Text Attacks on BERT Models with Projected Gradient Descent

## Answer (I don't know?: ✗)

Error: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable