# A Survey on Stance Detection for Mis-and Disinformation Identification

## Question

How is stance detection applied in the context of rumor detection and debunking, and what are its formal definitions and categories?

## URLs

1. https://ar5iv.org/html/1911.07199. [1911.07199] Rumor Detection on Social Media: Datasets, Methods and Opportunities
2. https://ar5iv.org/html/1704.00656. [1704.00656] Untitled Document
3. https://ar5iv.org/html/2312.03195. [2312.03195] Detecting Rumor Veracity with Only Textual Information by Double-Channel Structure
4. https://ar5iv.org/html/2212.09683. [2212.09683] Human-in-the-loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments
5. https://ar5iv.org/html/2407.20910. [2407.20910] Enabling Contextual Soft Moderation on Social Media through Contrastive Textual Deviation This paper is accepted for publication at the 2024 USENIX Security Symposium. Please cite accordingly.
6. https://ar5iv.org/html/2112.11185. [2112.11185] Fake News Detection Tools and Methods -- A Review
7. https://ar5iv.org/html/2405.03371. [2405.03371] Explainable Fake News Detection With Large Language Model via Defense Among Competing Wisdom
8. https://ar5iv.org/html/1804.08012. [1804.08012] Integrating Stance Detection and Fact Checking in a Unified Corpus
9. https://ar5iv.org/html/2204.11540. [2204.11540] Research Status of Deep Learning Methods for Rumor Detection
10. https://ar5iv.org/html/2010.11089. [2010.11089] Lexicon generation for detecting fake news

## Answer (I don't know?: ✗)

Stance detection is applied in the context of rumor detection and debunking as a method to assess the position or attitude of users regarding specific claims, which can aid in identifying the veracity of those claims. In the framework of multi-task learning, stance detection complements rumor detection by analyzing how user feedback varies according to public opinion trends. However, it is argued that the current stance detection approaches may sometimes have counterproductive effects, as they might mislead the overall task due to shifts in public sentiment that affect user positions on rumors [1].

In the field of Natural Language Processing (NLP), NLI (Natural Language Inference) serves as a prominent method for stance detection, treating a claim as a premise and evidence as a hypothesis. The core task is to assess whether the premise supports or contradicts the hypothesis [2]. This approach can be refined further through the inclusion of contextual information, which can bridge gaps in understanding, particularly in new topics or out-of-domain settings [2]. A significant challenge for stance detection methods is their tendency to struggle in generalizing across different topics, primarily due to a lack of adequate contextual information [2].

Formal definitions of stance detection include the identification of a claim's supportive or opposing nature regarding a hypothesis. Recent advances suggest that simply providing context-aware hypotheses is not sufficient; models should also understand contradicting statements—both supporting and refuting the claims—since such scenarios frequently arise on social media platforms [4]. This concept is termed "contrastive context awareness," advocating for a more nuanced understanding of stance that allows models to learn complex relationships between claims and counterclaims [4].

Regarding categories, stance detection can be categorized along several dimensions according to the specific characteristics of the claims being assessed. As indicated in the context, various methodologies have been proposed and tested, like using deep learning models (such as GRU) optimized for both stance detection and rumor classification, showcasing significant improvements [5]. Additionally, some approaches incorporate user credibility, evidencing the diversity of techniques aimed at enhancing the effectiveness of stance detection in rumor debunking; these may include enriching feature sets that consider user trust levels [5].

In summary, stance detection plays a crucial role in rumor detection and debunking by evaluating user perspectives, employing methods like NLI, and necessitating contextual and contradicting information to boost model performance. Furthermore, continued advancements in the field aim at mitigating current limitations, allowing for more precise and effective assessments of rumor veracity in social contexts.

1. [1]:  https://ar5iv.org/html/2204.11540, [2204.11540] Research Status of Deep Learning Methods for Rumor Detection
2. [2]:  https://ar5iv.org/html/2407.20910, [2407.20910] Enabling Contextual Soft Moderation on Social Media through Contrastive Textual Deviation This paper is accepted for publication at the 2024 USENIX Security Symposium. Please cite accordingly.
3. [3]:  https://ar5iv.org/html/2407.20910, [2407.20910] Enabling Contextual Soft Moderation on Social Media through Contrastive Textual Deviation This paper is accepted for publication at the 2024 USENIX Security Symposium. Please cite accordingly.
4. [4]:  https://ar5iv.org/html/2407.20910, [2407.20910] Enabling Contextual Soft Moderation on Social Media through Contrastive Textual Deviation This paper is accepted for publication at the 2024 USENIX Security Symposium. Please cite accordingly.
5. [5]:  https://ar5iv.org/html/2204.11540, [2204.11540] Research Status of Deep Learning Methods for Rumor Detection
---
1. [1]:  Passage ID 1: work.For the multi-task learning method that uses stance detection to help rumor detection, although users’ feedback on rumors can be used to make preliminary judgments on rumors, we believe that this method negates the role of public opinion trends. The dissemination harm of rumors is the pressure of public opinion trends. Some users who are not firm will shake their stances when observing the positions of the public. Stance detection will have a counterproductive effect on this phenomenon, which will mislead the task of rumor detection. Although some studies have used user credibility information, they still have not made any countermeasures against changes in public opinion trends. Therefore, this is also a challenge to the multi-task learning method using stance detection.The framework of  Cheng \BOthers. (\APACyear2020) is different from that shown in Figure 9. The reason is that they were inspired by  Zubiaga \BOthers. (\APACyear2018) that they classified rumors into four
2. [2]:  Passage ID 2: (RTE).NLI is a widely popular approach for detecting stance in NLP, where a claim is treated as a premise and a piece of evidence is treated as a hypothesis.The task then consists in checking if the premise entails (supports) or contradicts (refutes) the hypothesis [22].Compared to the approach of fine-tuning BERT-based models for classification tasks, NLI can be adapted with a much more granular objective for stance detection, as each claim being evaluated can be directly subjected to the most relevant piece of evidence associated with the claim.One of the major reasons existing stance detection methods fail to generalize well on detecting stance on a new topic during inference is the lack of enough contextual information about the topic or target they are subjected in the out-of-domain or zero-shot setting [28, 13].Prior research showed that providing enough context about the topic or claim being evaluated can bridge this context gap, improving stance detection models to
3. [3]:  Passage ID 3: Kalina Bontcheva.Can rumour stance alone predict veracity?In International conference on computational linguistics, 2018.[18]Oren Etzioni, Michele Banko, Stephen Soderland, and Daniel S Weld.Open information extraction from the web.Communications of the ACM, 51(12), 2008.[19]Jaynil Gaglani, Yash Gandhi, Shubham Gogate, and Aparna Halbe.Unsupervised whatsapp fake news detection using semantic search.In International Conference on Intelligent Computing and ControlSystems (ICICCS). IEEE, 2020.[20]Google.Fact check (claimreview) structured data.https://developers.google.com/search/docs/appearance/structured-data/factcheck,2023.[21]Megan Graham and Salvador Rodriguez.Twitter and facebook race to label a slew of posts making falseelection claims before all votes counted.https://www.cnbc.com/2020/11/04/twitter-and-facebook-label-trump-posts-claiming-election-stolen.html,2020.[22]Andreas Hanselowski, Hao Zhang, Zile Li,
4. [4]:  Passage ID 4: results suggest that providing a context-aware hypothesis statement is not enough to build NLI models for precise stance detection.We argue that while context awareness through the best set of hypothesis statements gives a model important contextual signals about the claim, it would be beneficial for the model to be “contrastively context-aware,” i.e., exposed to contradicting hypotheses, one supporting and one refuting the claim, which is what commonly occurs on social media.4 Contrastive Textual DeviationBased on the three requirements defined in the previous section, we aim to build an unsupervised stance detection model that overcomes the limitations of previous approaches by: i) detecting stance at a fine-grained level, ii) learning semantic representations of stance on a claim invariant fashion, and iii) encoding contrastive context awareness to learn higher level representations of stance.We first describe our proposed solution by formally defining a new task called
5. [5]:  Passage ID 5: classification task, and then share the features extracted from the two tasks for rumor detection, as Fig.9. Many experiments have proved that position detection has a huge positive impact on rumor detection. Ma \BOthers. (\APACyear2018\APACexlab\BCnt1) and  Kochkina \BOthers. (\APACyear2018) used GRU to optimize stance detection jointly, and rumor classification tasks in their work, and both achieved significant improvements. However, they assign the same weight to each user’s comment, ignoring that some untrusted users’ comment characteristics have little or even a negative effect on rumor detection..Since not all users have high credit, so  H. Zhang \BOthers. (\APACyear2021\APACexlab\BCnt2) added user confidence features and text feature embeddings in their work. Nevertheless, it still ignores the structure of the comment information  Kumar \BBA Carley (\APACyear2019) proposed a tree-structured LSTM multi-task model with convolutional units and used the tree structure to propagate