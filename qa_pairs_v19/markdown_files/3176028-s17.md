# Discourse-Oriented Anaphora Resolution in Natural Language Understanding: A Review

## Question

What are the two basic classes of coherence relations, and how are they exemplified in discourse?

## URLs

1. https://ar5iv.org/html/2403.20196. [2403.20196] Automatic Alignment of Discourse Relations of Different Discourse Annotation Frameworks
2. https://ar5iv.org/html/2403.13560. [2403.13560] eRST: A Signaled Graph Theory of Discourse Relations and Organization
3. https://ar5iv.org/html/2204.07781. [2204.07781] Towards Unification of Discourse Annotation Frameworks
4. https://ar5iv.org/html/2111.05940. [2111.05940] A Novel Corpus of Discourse Structure in Humans and Computers
5. https://ar5iv.org/html/2402.13551. [2402.13551] Graph Representation of Narrative Context: Coherence Dependency via Retrospective Questions
6. https://ar5iv.org/html/1905.05682. [1905.05682] A Unified Linear-Time Framework for Sentence-Level Discourse Parsing
7. https://ar5iv.org/html/2409.18992. [2409.18992] A Review of Mechanistic Models of Event Comprehension

## Answer (I don't know?: ✓)

I don't know. The provided context does not contain information about coherence relations or their exemplification in discourse. It mainly focuses on question answering, automatic summarization, and various applications of NLP, without addressing the specific topic of coherence relations in discourse.

1. [1]:  https://ar5iv.org/html/2203.06414, No Title
2. [2]:  https://ar5iv.org/html/2203.06414, No Title
3. [3]:  https://ar5iv.org/html/2007.08749, No Title
4. [4]:  https://ar5iv.org/html/2104.10810, No Title
5. [5]:  https://ar5iv.org/html/2411.06284, No Title
---
1. [1]:  Passage ID 1: comprehension and Question answeringQuestion answering is a task that has been extensively studied in the NLP literature, with the goal of building systems that can automatically generate answers to questions posed in a given context. This task has numerous applications, including the development of chatbots and dialogue generation systems. In order to train a system to perform this task, a neural network is trained on a large dataset of contexts, questions, and their respective answers, learning the relationships among them. The SQuAD dataset (Rajpurkar et al., 2016), for example, has been proposed for this purpose, containing a large number of context paragraphs, questions, and answers.A.5. Automatic summarizationAutomatic text summarization is a challenging NLP task that involves creating a shorter version of a larger text document. The task requires the selection of essential information from the entire text and condensing it using the sentences available in the document
2. [2]:  Passage ID 2: comprehension and Question answeringQuestion answering is a task that has been extensively studied in the NLP literature, with the goal of building systems that can automatically generate answers to questions posed in a given context. This task has numerous applications, including the development of chatbots and dialogue generation systems. In order to train a system to perform this task, a neural network is trained on a large dataset of contexts, questions, and their respective answers, learning the relationships among them. The SQuAD dataset (Rajpurkar et al., 2016), for example, has been proposed for this purpose, containing a large number of context paragraphs, questions, and answers.A.5. Automatic summarizationAutomatic text summarization is a challenging NLP task that involves creating a shorter version of a larger text document. The task requires the selection of essential information from the entire text and condensing it using the sentences available in the document
3. [3]:  Passage ID 3: recognition (ASR) and natural language understanding (NLU) offer potential solutions to generate these summaries automatically, but rigorous quantitative baselines for benchmarking research in this domain are lacking. In this paper, we bridge this gap for two tasks: classifying utterances from medical conversations according to (i) the SOAP section and (ii) the speaker role. Both are fundamental building blocks along the path towards an end-to-end, automated SOAP note for medical conversations. We provide details on a dataset that contains human and ASR transcriptions of medical conversations and corresponding machine learning optimized SOAP notes. We then present a systematic analysis in which we adapt an existing deep learning architecture to the two aforementioned tasks. The results suggest that modelling context in a hierarchical manner, which captures both word and utterance level context, yields substantial improvements on both classification tasks. Additionally, we develop and
4. [4]:  Passage ID 4: question answering systems (Gaoet al., 2018). Task-oriented dialogue systems are designed to complete a specific task on the user’s behalf such as booking hotels, making a restaurant reservation or finding products. The second category mainly focuses on carrying out a conversation with the user on open-domain topics, and question answering bots are designed to find an appropriate answer to user’s query using all its available knowledge and resources. Though, these systems have come a long way in terms of progress but conversing with such models for even a short amount of time quickly unveils the inconsistency in generated responses.A different number of strategies have been introduced over a period to address this issue. One of the standard methods of designing an NLP based project is to utilize word embeddings, pre-trained on a huge amount of unlabelled data using distributed word representations such as GloVe and Word2Vec, to initialize the first layer of the neural network. The
5. [5]:  Passage ID 5: answering.The integration of multimodal data has opened up new possibilities for AI applications. MLLMs can generate detailed descriptions of images, providing valuable assistance in fields like accessibility and content creation. These models can answer questions about images, demonstrating their ability to understand and reason about visual content. MLLMs also enable the creation of rich multimedia content, combining text, images, and audio to produce engaging and informative outputs.The field of NLP has undergone significant transformations over the past few decades, driven by advancements in computational power, the availability of large-scale datasets, and breakthroughs in machine learning algorithms. This journey can be broadly categorized into several key phases:1.Rule-based systems (1950s-1980s): Early NLP approaches relied heavily on hand-crafted rules and linguistic knowledge bases. While these systems could perform well in narrow domains, they struggled with the