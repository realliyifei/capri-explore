# Discourse-Oriented Anaphora Resolution in Natural Language Understanding: A Review

## Question

What are the two basic classes of coherence relations, and how are they exemplified in discourse?

## URLs

1. https://ar5iv.org/html/2403.20196. [2403.20196] Automatic Alignment of Discourse Relations of Different Discourse Annotation Frameworks
2. https://ar5iv.org/html/2403.13560. [2403.13560] eRST: A Signaled Graph Theory of Discourse Relations and Organization
3. https://ar5iv.org/html/2204.07781. [2204.07781] Towards Unification of Discourse Annotation Frameworks
4. https://ar5iv.org/html/2111.05940. [2111.05940] A Novel Corpus of Discourse Structure in Humans and Computers
5. https://ar5iv.org/html/2402.13551. [2402.13551] Graph Representation of Narrative Context: Coherence Dependency via Retrospective Questions
6. https://ar5iv.org/html/1905.05682. [1905.05682] A Unified Linear-Time Framework for Sentence-Level Discourse Parsing
7. https://ar5iv.org/html/2409.18992. [2409.18992] A Review of Mechanistic Models of Event Comprehension

## Answer (I don't know?: ✗)

The two basic classes of coherence relations in discourse are "cause and effect" and "temporal sequence," as derived from the comprehensive set of coherence relations proposed by Wolf and Gibson (2005) [2]. These relations serve as foundational categories that help in understanding how different parts of discourse connect with one another.

1. **Cause and Effect:** This relation indicates that one event or clause leads to or influences the occurrence of another. For example, in a discourse situation, one might describe a scenario where heavy rainfall leads to flooding, illustrating a clear cause-effect relationship.

2. **Temporal Sequence:** This coherence relation signifies that events are connected through their timing. For instance, one might say that "after I finished my homework, I went for a walk," illustrating a chronological ordering of events.

Moreover, the framework for discourse modes, as developed by Smith (2003) and refined by Friedrich (2017), categorizes types of clauses based on their roles within discourse, which includes basic states and bounded events [2]. In this context, clauses demonstrating these coherence relations can be annotated and analyzed using specific linguistic properties that enhance our understanding of how they contribute to textual coherence.

To further elaborate, discourse relations entail a complex interplay of various linguistic layers such as syntax, semantics, and pragmatics, making their representation and annotation challenging [3]. The existing discourse corpora, while sharing a common understanding of discourse relations, reveal considerable variations due to the diverse frameworks applied, which complicates their joint usage in natural language processing tasks [3] [4].

To enhance the quality and applicability of discourse corpora, aligning existing resources is crucial although it presents significant challenges due to the differing annotation frameworks [4]. Overall, understanding how coherence relations function within a discourse is vital, especially as more NLP tasks—such as sentiment analysis, machine translation, and text summarization—incorporate discourse-aware models to achieve improved performance [3]. This growing recognition of discourse structures highlights their fundamental role in both theoretical linguistics and practical applications in natural language processing.

1. [1]:  https://ar5iv.org/html/2403.13560, [2403.13560] eRST: A Signaled Graph Theory of Discourse Relations and Organization
2. [2]:  https://ar5iv.org/html/2111.05940, [2111.05940] A Novel Corpus of Discourse Structure in Humans and Computers
3. [3]:  https://ar5iv.org/html/2204.07781, [2204.07781] Towards Unification of Discourse Annotation Frameworks
4. [4]:  https://ar5iv.org/html/2403.20196, [2403.20196] Automatic Alignment of Discourse Relations of Different Discourse Annotation Frameworks
5. [5]:  https://ar5iv.org/html/2403.13560, [2403.13560] eRST: A Signaled Graph Theory of Discourse Relations and Organization
---
1. [1]:  Passage ID 1: of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1515–1520, Association for Computational Linguistics, Seattle, Washington, USA.Hoek, Evers-Vermeul, and Sanders (2019)Hoek, Jet, Jacqueline Evers-Vermeul, and Ted J.M. Sanders. 2019.Using the Cognitive approach to Coherence Relations for discourse annotation.Dialogue and Discourse, 10(2):1–33.Hovy (1990)Hovy, Eduard H. 1990.Parsimonious and profligate approaches to the question of discourse structure relations.In Proceedings of the Fifth International Workshop on Natural Language Generation, Association for Computational Linguistics, Linden Hall Conference Center, Dawson, Pennsylvania.Hughes (1996)Hughes, Rebecca. 1996.English in Speech and Writing.Routledge, London.Jurafsky and Martin (2023)Jurafsky, Daniel and James H. Martin. 2023.Speech and Language Processing. An Introduction to Natural Language Processing, Computational Linguistics, and Speech
2. [2]:  Passage ID 2: discourse modes based on the framework proposed by Smith (2003) and developed for corpora by Friedrich (2017). Examples of clause types under this framework include basic states, bounded events and generic sentences. 2) A comprehensive set of coherence relations based on Wolf and Gibson (2005). Examples of relations between clauses in this framework include cause and effect, temporal sequence and contrast. Krippendorf’s alpha for interrater agreement ranged [.45,.52].We extended these previous frameworks to better distinguish the compositional linguistic properties making up each clause label (e.g., based on Govindarajan et al., 2019), and to account for incoherent content (e.g. repetition or intuitively meaningless relations) that may explain the difference in quality between computer and human discourse. More details about the annotation procedure and its evaluation can be found in Chapter 4 of Hemmatian, 2021. The annotated corpus along with metadata and links to the code used in
3. [3]:  Passage ID 3: level is attracting more attention, and different natural language processing (NLP) tasks use discourse-aware models to obtain better performance, such as sentiment analysis (Bhatia et al., 2015), automatic essay scoring (Nadeem et al., 2019), machine translation (Sim Smith, 2017), text summarization (Xu et al., 2020) and so on.As discourse information typically involves the interaction of different levels of linguistic phenomena, including syntax, semantics, pragmatics and information structure, it is difficult to represent and annotate. Different discourse theories and discourse annotation frameworks have been proposed. Accordingly, discourse corpora annotated under different frameworks show considerable variation, and a corpus can be hardly used together with another corpus for natural language processing (NLP) tasks or discourse analysis in linguistics. Discourse parsing is a task of uncovering the underlying structure of text organization, and deep-learning based approaches are
4. [4]:  Passage ID 4: has high demand on knowledge about discourse, discourse corpora are costly to create. However, these discourse formalisms typically share similar understanding of discourse relations and their essential role in discourse building. Thus, an option to enlarge discourse corpora is to align the existing discourse corpora so that they can be used jointly. This line of work starts as early as Hovy and Maier (1992), but it remains challenging to uncover the alignment of discourse relations used in different annotation frameworks.Figure 1 shows an example of RST-style annotation. The textual spans in boxes are EDUs and the arrow-headed lines represent asymmetric discourse relations, pointing from satellites to nuclei. The labels elab(oration) and attribution denote discourse relations. As the two spans connected by the relation same-unit are equally salient, the relation is represented by undirected parallel lines. The spans are linked recursively until a full-coverage of the whole text is
5. [5]:  Passage ID 5: Linguistics (Volume 1: Long Papers), pages 1006–1017, Association for Computational Linguistics, Vancouver, Canada.Rehbein, Scholman, and Demberg (2016)Rehbein, Ines, Merel Scholman, and Vera Demberg. 2016.Annotating discourse relations in spoken language: A comparison of the PDTB and CCR frameworks.In Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC’16), pages 1039–1046, European Language Resources Association (ELRA), Portorož, Slovenia.Rutherford, Demberg, and Xue (2017)Rutherford, Attapol, Vera Demberg, and Nianwen Xue. 2017.A systematic study of neural discourse models for implicit discourse relation.In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, pages 281–291, Association for Computational Linguistics, Valencia, Spain.Sanders, Spooren, and Noordman (1992)Sanders, Ted J. M., Wilbert P.M. Spooren, and Leo G.M. Noordman.