# Multiword Expression Processing: A Survey under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license Computational Linguistics

## Question

What are the current limitations and challenges faced by identification models in recognizing discontiguous and overlapping multiword expressions (MWEs)?

## URLs

1. https://ar5iv.org/html/1809.03056

## Answer

## I don't know?: True

I don't know. The provided context does not mention discontiguous and overlapping multiword expressions (MWEs) or detail any specific limitations and challenges faced by identification models related to these types of MWEs. While the passages discuss the identification of MWEs generally in the context of NLP, mentioning issues like the non-substitutability and the ambiguous nature of MWEs, they do not directly address the specific challenges related to recognizing discontiguous and overlapping MWEs. Therefore, there is insufficient information to provide a comprehensive answer to the question.

[1]: https://ar5iv.org/html/2208.07832, No Title
[2]: https://ar5iv.org/html/2208.07832, No Title
[3]: https://ar5iv.org/html/2204.10050, No Title
[4]: https://ar5iv.org/html/2204.10050, No Title
[5]: https://ar5iv.org/html/2208.07832, No Title

[1]: Passage ID 1: (MT) [17, 16], which depends on a clear distinction between word tokens and phrases, has to be re-thought to accommodate MWEs [8, 29]. The usual approach in these applications is to identify MWEs first, and then treat them accordingly. Therefore, detecting MWEs is a key research area in NLP.In recent years, the identification of MWEs has been modelled as a supervised machine learning task where the machine learning models are trained on an annotated dataset. As we explain in Section 2, several datasets have been released to train these machine learning models. Furthermore shared tasks such as SemEval-2016 Task 10 [28] and PARSEME [27] have contributed to develop datasets. In recent years, neural network-based models, and in particular architectures incorporating RecurrentNeural Networks (RNNs) such as Long Short Term Memory (LSTM) and Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance in MWE identification tasks [27]. Usually, these models utilise
[2]: Passage ID 2: (MT) [17, 16], which depends on a clear distinction between word tokens and phrases, has to be re-thought to accommodate MWEs [8, 29]. The usual approach in these applications is to identify MWEs first, and then treat them accordingly. Therefore, detecting MWEs is a key research area in NLP.In recent years, the identification of MWEs has been modelled as a supervised machine learning task where the machine learning models are trained on an annotated dataset. As we explain in Section 2, several datasets have been released to train these machine learning models. Furthermore shared tasks such as SemEval-2016 Task 10 [28] and PARSEME [27] have contributed to develop datasets. In recent years, neural network-based models, and in particular architectures incorporating RecurrentNeural Networks (RNNs) such as Long Short Term Memory (LSTM) and Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance in MWE identification tasks [27]. Usually, these models utilise
[3]: Passage ID 3: at identifying whether a sentence contains an idiomatic expression, and (b) a task based on semantic text similarity which requires the model to adequately represent potentially idiomatic expressions in context. Each Subtask includes different settings regarding the amount of training data. Besides the task description, this paper introduces the datasets in English, Portuguese, and Galician and their annotation procedure, the evaluation metrics, and a summary of the participant systems and their results. The task had close to 100 registered participants organised into twenty five teams making over 650 and 150 submissions in the practice and evaluation phases respectively.1 IntroductionMultiword Expressions (MWEs) are a challenge for natural language processing (NLP), as their linguistic behaviour (e.g., syntactic, semantic) differs from that of generic word combinations Baldwin and Kim (2010); Ramisch and Villavicencio (2018). Moreover, MWEs are pervasive in all domains Biber
[4]: Passage ID 4: at identifying whether a sentence contains an idiomatic expression, and (b) a task based on semantic text similarity which requires the model to adequately represent potentially idiomatic expressions in context. Each Subtask includes different settings regarding the amount of training data. Besides the task description, this paper introduces the datasets in English, Portuguese, and Galician and their annotation procedure, the evaluation metrics, and a summary of the participant systems and their results. The task had close to 100 registered participants organised into twenty five teams making over 650 and 150 submissions in the practice and evaluation phases respectively.1 IntroductionMultiword Expressions (MWEs) are a challenge for natural language processing (NLP), as their linguistic behaviour (e.g., syntactic, semantic) differs from that of generic word combinations Baldwin and Kim (2010); Ramisch and Villavicencio (2018). Moreover, MWEs are pervasive in all domains Biber
[5]: Passage ID 5: (RNNs) such as Long Short Term Memory (LSTM) and Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance in MWE identification tasks [27]. Usually, these models utilise pre-trained word embedding models such as word2vec [15] and glove [22]. We describe these models in Section 2. However, these traditional word embeddings provide the same embedding for polysemous words [21] [20]. Therefore, non-substitutability and the ambiguous nature of the MWEs can cause complications with traditional word embeddings.A possible solution is to utilise neural architectures such as transformers that incorporate context more into the learning process. However, as far as we know, there has not been any research done to compare the performance of different transformer models in the MWE identification task. In this research, we empirically evaluate several transformer models in detecting MWEs to fill this gap. The findings of this research can be beneficial for many NLP