# Neuron-level Interpretation of Deep NLP Models: A Survey

## Question

How have researchers identified neurons that capture lexical concepts in deep NLP models, and what methods have they used?

## URLs

1. https://ar5iv.org/html/2206.13288. [2206.13288] Discovering Salient Neurons in deep NLP models
2. https://ar5iv.org/html/2108.13138. [2108.13138] Neuron-level Interpretation of Deep NLP Models: A Survey
3. https://ar5iv.org/html/2406.10868. [2406.10868] Analyzing Key Neurons in Large Language Models
4. https://ar5iv.org/html/2405.20331. [2405.20331] CoSy: Evaluating Textual Explanations of Neurons
5. https://ar5iv.org/html/2006.14032. [2006.14032] Compositional Explanations of Neurons
6. https://ar5iv.org/html/1807.10854. [1807.10854] A Survey of the Usages of Deep Learning for Natural Language Processing
7. https://ar5iv.org/html/2305.19911. [2305.19911] Neuron to Graph: Interpreting Language Model Neurons at Scale
8. https://ar5iv.org/html/2307.10246. [2307.10246] Deep Neural Networks and Brain Alignment: Brain Encoding and Decoding (Survey)

## Answer (I don't know?: ✗)

Researchers have employed several methods to identify neurons that capture lexical concepts in deep Natural Language Processing (NLP) models, particularly in the context of neural machine translation (NMT). One of the primary studies contributing to this understanding is by Dalvi et al. (2019), who analyzed LSTM-based NMT models. They demonstrated that specific neurons can be linked to core linguistic concepts, such as nouns, verb forms, numbers, and articles, revealing that neurons have differing levels of specialization based on the nature of the concept they represent. Their findings indicated that closed-class concepts, which do not evolve by the addition of new words (e.g., functional words), are localized to fewer neurons. In contrast, open-class concepts, which can accommodate new terms as language evolves (e.g., creatable verbs), are more widely distributed across numerous neurons [1] [2].

In addition to Dalvi et al. (2019), other studies have probed the functionalities of neurons using various techniques. For instance, researchers employing concept search methods have identified neurons through the analysis of their responses to different linguistic inputs. A notable example is the identification of a neuron associated with “horse racing,” which was subsequently shown to be a more general “racing” neuron by generating novel contexts highlighting its broader applicability [5]. This process underscores the way researchers utilize synthetic instances to explore the behavior and roles of specific neurons more deeply.

Furthermore, modern investigations are increasingly centered around transformer-based models. The analysis of these representations often employs linear compositionality analysis (LCA) to probe the learning processes within neurons and how these neurons are distributed across the model. The studies reveal that lower layers of transformer models predominantly capture shallow lexical information (like suffixes and word morphology), while more complex syntactic properties are handled by neurons in higher layers [3] [4]. This suggests a hierarchical organization of linguistic representation, where the nature of the linguistic properties determines the layer at which they are processed.

In summary, researchers have identified neurons capturing lexical concepts through a combination of concept searches, synthetic instance generation, and comprehensive analysis of neuron layers in deep learning architectures. The methodologies underline a focus on both the structural and functional aspects of neural networks in NLP, emphasizing how neurons specialize in representing various linguistic phenomena.

1. [1]:  https://ar5iv.org/html/2108.13138, [2108.13138] Neuron-level Interpretation of Deep NLP Models: A Survey
2. [2]:  https://ar5iv.org/html/2108.13138, [2108.13138] Neuron-level Interpretation of Deep NLP Models: A Survey
3. [3]:  https://ar5iv.org/html/2206.13288, [2206.13288] Discovering Salient Neurons in deep NLP models
4. [4]:  https://ar5iv.org/html/2206.13288, [2206.13288] Discovering Salient Neurons in deep NLP models
5. [5]:  https://ar5iv.org/html/2108.13138, [2108.13138] Neuron-level Interpretation of Deep NLP Models: A Survey
---
1. [1]:  Passage ID 1: specialize in core linguistic conceptsDalvi et al. (2019) in their analysis of LSTM-based NMT models found neurons that capture core linguistic concepts such as nouns, verb forms, numbers, articles, etc. They also showed that the number of neurons responsible for a concept varies based on the nature of the concept.For example: closed class555closed class concepts are part of language where new words are not added as the language evolves, for example functional words such as can, be etc. In contrast open class concepts are a pool where new words are constantly added as the language evolve, for example ”chillax” a verb formed blending ”chill” and ”relax”. concepts such as Articles (morphological category), Months of Year (semantic category) are localized to fewer neurons, whereas open class concepts such as nouns (morphological category) or event (semantic category) are distributed among a large number of neurons.Neurons exhibit monosemous and polysemous behavior. Xin et al. (2019)
2. [2]:  Passage ID 2: specialize in core linguistic conceptsDalvi et al. (2019) in their analysis of LSTM-based NMT models found neurons that capture core linguistic concepts such as nouns, verb forms, numbers, articles, etc. They also showed that the number of neurons responsible for a concept varies based on the nature of the concept.For example: closed class555closed class concepts are part of language where new words are not added as the language evolves, for example functional words such as can, be etc. In contrast open class concepts are a pool where new words are constantly added as the language evolve, for example ”chillax” a verb formed blending ”chill” and ”relax”. concepts such as Articles (morphological category), Months of Year (semantic category) are localized to fewer neurons, whereas open class concepts such as nouns (morphological category) or event (semantic category) are distributed among a large number of neurons.Neurons exhibit monosemous and polysemous behavior. Xin et al. (2019)
3. [3]:  Passage ID 3: annotated data is available. We analyze the representations trained from neural language models of which we study the recent transformer based models. We use LCA to understand: i) how concepts are learned within neurons and ii) how these neurons distribute across the network. More specifically we probe for the following questions:•Question: Do the individual neurons in the transformers capture linguistic information and which parts of the network learn more about certain linguistic phenomena?•Finding: Neurons that capture tasks such as predicting shallow lexical information (such as suffixes) or word morphology are predominantly found in the lower layers and those learning more complex properties such as syntactic information are found in the higher layers. [Section 5.1]•Question: Is certain linguistic phenomenon in a given model localized or distributed across many neurons? And how redundantly is the information preserved?•Finding: Closed-class properties like
4. [4]:  Passage ID 4: annotated data is available. We analyze the representations trained from neural language models of which we study the recent transformer based models. We use LCA to understand: i) how concepts are learned within neurons and ii) how these neurons distribute across the network. More specifically we probe for the following questions:•Question: Do the individual neurons in the transformers capture linguistic information and which parts of the network learn more about certain linguistic phenomena?•Finding: Neurons that capture tasks such as predicting shallow lexical information (such as suffixes) or word morphology are predominantly found in the lower layers and those learning more complex properties such as syntactic information are found in the higher layers. [Section 5.1]•Question: Is certain linguistic phenomenon in a given model localized or distributed across many neurons? And how redundantly is the information preserved?•Finding: Closed-class properties like
5. [5]:  Passage ID 5: by generating synthetic instances. For example, they showed that a “horse racing” neuron identified via concept search method was in fact a general “racing” neuron by generating novel contexts against this neuron.5.1.2 Linguistic ConceptsA number of studiesprobed for neurons that capture core-linguistic concepts such asmorphology,semantic tags, etc. Probing for linguistic structure is important to understand models’ capacity to generalize Marasović (2018).444but is not the only reason to carry such an analysis.For example, the holy grail in machine translation is that a proficient model needs to be aware of word morphology, grammatical structure, and semantics to do well Vauquois (1968); Jones et al. (2012). Below we discuss major findings along this line of work:Neurons specialize in core linguistic conceptsDalvi et al. (2019) in their analysis of LSTM-based NMT models found neurons that capture core linguistic concepts such as nouns, verb forms, numbers, articles,