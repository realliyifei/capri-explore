# A Survey of Active Learning for Natural Language Processing

## Question

What are the common strategies for selecting a diverse batch of instances in active learning?

## URLs

1. https://ar5iv.org/html/2403.03728. [2403.03728] Bridging Diversity and Uncertainty in Active learning with Self-Supervised Pre-Training
2. https://ar5iv.org/html/2312.15944. [2312.15944] BAL: Balancing Diversity and Novelty for Active Learning
3. https://ar5iv.org/html/2309.16139. [2309.16139] Two-Step Active Learning for Instance Segmentation with Uncertainty and Diversity Sampling
4. https://ar5iv.org/html/2207.12302. [2207.12302] Exploiting Diversity of Unlabeled Data for Label-Efficient Semi-Supervised Active Learning
5. https://ar5iv.org/html/2411.06353. [2411.06353] Deep Active Learning in the Open World
6. https://ar5iv.org/html/2107.01622. [2107.01622] Multiple-criteria Based Active Learning with Fixed-size Determinantal Point Processes
7. https://ar5iv.org/html/2405.10808. [2405.10808] ActiveLLM: Large Language Model-based Active Learning for Textual Few-Shot Scenarios
8. https://ar5iv.org/html/2412.02310. [2412.02310] Active Learning via Classifier Impact and Greedy Selection for Interactive Image Retrieval
9. https://ar5iv.org/html/2411.17444. [2411.17444] Maximally Separated Active Learning

## Answer (I don't know?: ‚úó)

In active learning, selecting a diverse batch of instances is crucial to improving model performance while minimizing labeling efforts. There are several common strategies identified in the literature, particularly focusing on representativeness and diversity of the selected instances.

1. **Dissimilarity Criteria**: One prominent strategy involves choosing instances that are dissimilar to others in both the unlabeled data pool and within the selected batch. This approach is aligned with the criteria of representativeness and diversity, which are fundamental in active learning tasks. For instance, Ebert et al.'s reinforced active learning formulation allows for a time-varying trade-off between exploration (sampling diverse instances) and exploitation (using informative instances) [1] [4]. This suggests that the model should prioritize selecting instances that are not only informative but also diverse.

2. **Uncertainty and Diversity Sampling**: Another common method is to combine uncertainty-based approaches with diversity sampling. In uncertainty sampling, instances selected from where the model‚Äôs confidence in predictions is low are considered. This is complemented by diversity sampling, which aims to ensure that the selected instances are representative of the broader dataset [5]. The trade-off between these two methods allows models to explore less certain areas of the data while also ensuring a varied set of samples.

3. **Clustering Techniques**: Many strategies involve clustering selected instances to ensure diversity. For example, Shen et al. introduced a strategy where informative samples are first selected and then clustered into classes, choosing centroids as representative samples [1]. This method emphasizes the importance of selecting instances that collectively represent the variance in the data.

4. **Model-Driven Strategies**: Some strategies are specifically designed for particular classifiers. For example, Kapoor et al. proposed a mixed exploration and exploitation strategy leveraging Gaussian Process classifiers, which balances uncertainty with the model's understanding of how data points influence current learning [4]. Similarly, Kremer et al. used SVM classifiers to select instances based on their distance from the classification hyperplane, ensuring a diversity of skill levels within the selected instances [4].

5. **Low Resource Scenarios**: The discussion around the "cold start problem" in active learning is relevant, particularly when there is a lack of an initial labeled dataset. In these scenarios, the selection of instances can be particularly challenging, as models may not generate effective predictions without sufficient labeled data to assess uncertainty or diversity effectively [2]. This underlines the need for thoughtful selection strategies in initial stages of active learning.

In summary, effective strategies for selecting a diverse batch of instances in active learning include utilizing dissimilarity criteria, integrating uncertainty and diversity sampling, employing clustering techniques, and adapting model-driven strategies. Each approach addresses unique aspects of the data and model capabilities, emphasizing the importance of a tailored selection strategy for achieving optimal learning outcomes in various applications.

1. [1]:  https://ar5iv.org/html/2107.01622, [2107.01622] Multiple-criteria Based Active Learning with Fixed-size Determinantal Point Processes
2. [2]:  https://ar5iv.org/html/2405.10808, [2405.10808] ActiveLLM: Large Language Model-based Active Learning for Textual Few-Shot Scenarios
3. [3]:  https://ar5iv.org/html/2405.10808, [2405.10808] ActiveLLM: Large Language Model-based Active Learning for Textual Few-Shot Scenarios
4. [4]:  https://ar5iv.org/html/2107.01622, [2107.01622] Multiple-criteria Based Active Learning with Fixed-size Determinantal Point Processes
5. [5]:  https://ar5iv.org/html/2309.16139, [2309.16139] Two-Step Active Learning for Instance Segmentation with Uncertainty and Diversity Sampling
---
1. [1]:  Passage ID 1: the largest impact of current models, other works also select instances with the following properties: 1) the selected instance should be dissimilar with other instances in the unlabeled data pool; and 2) the selected instance should be dissimilar with other instances in one batch. Properties 1 and 2 are considered as the representativeness and diversity criteria in the active learning task. Ebert et al. introduced a reinforced active learning formulation, which enables a time varying trade-off between exploration and exploitation [20].Shen et al. incorporated informativeness, representativeness and diversity with two different combination strategies 4. [4]: Strategy 1 first pre-selects the most informative data samples by US, then clusters them into kùëòk classes, whose centroids are the selected data samples in one batch. However, informative instances usually do not exploit the structure information of unlabeled data. Moreover, when the number of samples for clustering is small, the
2. [2]:  Passage ID 2: querying.The former scenario is increasingly relevant, as modern models often demand substantial computational resources and time, rendering them impractical for iterative training during labeling. Alternatively, the latter approach often focuses on maximizing the diversity of the selected examples and might involve techniques such as data clustering.While active learning can significantly streamline the learning process by reducing labeling efforts, most strategies encounter a cold start problem.In the absence of a sufficient initial labeled dataset (label seed), a model may struggle to make informed predictions about uncertainty or diversity [32].This challenge is pronounced when dealing with pre-trained models, which generally require fewer data instances initially.Moreover, these models often necessitate substantial time resources, thereby increasing the necessity for model mismatch scenarios.In the subsequent sections, we give an overview of active learning for pre-trained
3. [3]:  Passage ID 3: interfaces, enabling practitioners from all domains without a deep machine learning or programming background to freely implement ActiveLLM.5.1 LLM-based Active Learning StrategiesThe question remains as to how LLMs choose instances.It is nearly impossible to assess if the models truly perform the strategies they claim to execute.However, LLMs are known to be good at finding topics and patterns in texts, which could suggest that diversity sampling is a valid procedure.We expect these models are capable of identifying unique, representative, frequent, or highly information-dense instances.Similarly, we expect these models to perform well on the tasks themselves, which is why they could be relatively proficient at selecting a balanced set of all classes.However, these models cannot inspect their own internals, which means they certainly are not performing uncertainty sampling based on these internals.However, related to uncertainty, LLMs might be very well suited for
4. [4]:  Passage ID 4: classifiers on various datasets. Based on these considerations, we propose a selection strategy according to the difficulty of each unlabeled data sample and the capability of each classifier (to be detailed in Section¬†III-B1).Some AL strategies serve for specific classifiers. Kapoor et al. proposed an algorithm which balances exploration and exploitation by incorporating mean and variance estimation of the Gaussian Process classifier[18] . Kremer et al. proposed a SVM-based AL strategy by minimizing the distances between data points and classification hyperplane [19]. These model-driven active learning strategies aim to estimate how strongly learning from a data point influences the current model.In addition to these strategies that aim to find the instances with uncertainty or make the largest impact of current models, other works also select instances with the following properties: 1) the selected instance should be dissimilar with other instances in the unlabeled data pool;
5. [5]:  Passage ID 5: data. There are two major ways to select the next batch to be labeled: uncertainty-based¬†[7, 8, 9, 10, 11], which selects samples that model has low confidence in prediction, and diversity-based¬†[12, 13, 14, 15, 16], which selects samples that are representative of the dataset. Both of these active learning approaches have been successfully applied in various computer vision tasks, including image classification¬†[17, 18, 19], object detection¬†[20, 21, 22], and semantic segmentation¬†[23, 24, 25]. However, very few existing works have addressed active learning for instance segmentation, and the few existing works focus on uncertainty-based approaches.Developing an effective active learning method for instance segmentation entails addressing several crucial factors. Instance segmentation models produce diverse types of output per instance, including class distribution, bounding box location, and a dense segmentation mask. This variety complicates the task of determining the most