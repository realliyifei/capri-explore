# Coreference Resolution for the Biomedical Domain: A Survey

## Question

How do general coreference resolution models perform on biomedical datasets compared to general domain datasets?

## URLs

1. https://ar5iv.org/html/2109.12424
2. https://ar5iv.org/html/2101.00884
3. https://ar5iv.org/html/2205.12689
4. https://ar5iv.org/html/2410.13458
5. https://ar5iv.org/html/2305.16326
6. https://ar5iv.org/html/2109.08564
7. https://ar5iv.org/html/2109.02237
8. https://ar5iv.org/html/2308.04498

## Answer

## I don't know?: False

General coreference resolution models generally perform poorly on biomedical datasets in comparison to their performance on general domain datasets. This disparity can be attributed to several factors, including the unique terminology, phrasing, and the specialized nature of scientific texts that these models are not typically trained to handle.

Previous studies have indicated that general coreference resolution systems struggle with scientific text, with results showing a significant drop in performance when they are applied to biomedical datasets. For example, it has been reported that a coreference resolution system developed for the news domain achieved only a score of 14.0 F1 on the Colorado Richly Annotated Full Text (CRAFT) corpus, which highlights a reduction of 32.0 points compared to its performance on more suitable datasets [3][4]. This underperformance is largely attributed to the lack of domain-specific knowledge that these general models possess, which becomes critical when dealing with the specialized language and context found in biomedical literature [3][4].

Furthermore, other studies have noted that annotating scientific texts for coreference resolution is not only costly but requires a certain level of expertise in the field, which adds to the challenges of building large, annotated datasets necessary for training robust models [3]. In comparison, datasets in the general domain are typically larger and more varied, allowing general models to leverage a broader understanding of language, contributing to better performance in those contexts [3].

The integration of domain-specific information is essential for effectively resolving coreferences in biomedical texts. Recent advancements in machine learning and deep learning-based models have begun to incorporate biomedical knowledge, yet the transfer of learning from general models to the biomedical domain remains underexplored [2][5]. This highlights a gap where further research and development are necessary to improve coreference resolution capabilities specifically tailored for the biomedical field [5].

In summary, while general coreference resolution models may perform adequately on general domain datasets, their application in biomedical contexts reveals significant limitations due to the specificity and complexity of biomedical language. This necessitates the development of models that are better suited to understand and resolve coreferences within this specialized domain.

1. [1]:  https://ar5iv.org/html/2109.12424, [2109.12424] Coreference Resolution for the Biomedical Domain: A Survey
2. [2]:  https://ar5iv.org/html/2109.12424, [2109.12424] Coreference Resolution for the Biomedical Domain: A Survey
3. [3]:  https://ar5iv.org/html/2101.00884, [2101.00884] Coreference Resolution in Research Papers from Multiple Domains
4. [4]:  https://ar5iv.org/html/2101.00884, [2101.00884] Coreference Resolution in Research Papers from Multiple Domains
5. [5]:  https://ar5iv.org/html/2109.12424, [2109.12424] Coreference Resolution for the Biomedical Domain: A Survey
---
1. [1]:  Passage ID 1: some background on coreference resolution in the general domain.Section 3 reviews the main datasets used to study biomedical coreference.Overviews of biomedical language representation models and biomedical coreference models are provided in Sections 4 and 5, respectively.Section 6 introduces the methodology of comparing the biomedical language representation models for coreference. Section 7 presents the evaluation results including the performance of previous models and our experiments, and Section 8 concludes.2 BackgroundCoreference resolution in the general domain has a long history of being studied from early heuristic-based and rule-based approaches to recent learning-based approaches.Lee et al. (2017) proposed the first end-to-end neural coreference resolution model which uses LSTM encoder. Based on the end-to-end model, many extensions to the model have been proposed. BERT and SpanBERT were proposed to replace the LSTM encoder and achieved better performance on
2. [2]:  Passage ID 2: 2016, Li et al. 2018), machine learning-based models (Yang et al. 2004, Torii and Vijay-Shanker 2005, Su et al. 2008, Gasperin 2009, Kim et al. 2011) to recent deep learning-based models (Trieu et al. 2018, Trieu et al. 2019, Li et al. 2021). These models usually integrate biomedical specific information,typically specific rules, pre-trained embeddings and features.This paper reviews and analyses coreference datasets and models for the biomedical domain, as well as recent biomedical language representation models which can enhance coreference models with domain-specific knowledge. In addition, we conduct experiments to evaluate the ability of these language represetation models for biomedical coreference task.The structure of this paper is as follows.In Section 2 we briefly provide some background on coreference resolution in the general domain.Section 3 reviews the main datasets used to study biomedical coreference.Overviews of biomedical language representation models and
3. [3]:  Passage ID 3: 5.0 dataset [19]) in the general domain, that is data from phone conversations, news, magazines, etc.But results of previous work indicate [10, 21, 34, 44] that general coreference resolution systems perform poorly on scientific text. This is presumably caused by the specific terminology and phrasing used in a scientific domain.Some other studies state that annotating scientific text is costly since it demands certain expertise in the article’s domain [1, 5, 18].Most corpora for research papers cover only a single domain (e.g. biomedicine [10],artificial intelligence [26]) and are thus limited to these domains.As a result, the annotated corpora are relatively small and overall only a few domains are covered.Datasets for the general domain are usually much larger, but they have not been exploited yet by approaches for coreference resolution in research papers.Coreference resolution is also one of the main steps in the KG population pipeline [27, 39].However, to date it is not
4. [4]:  Passage ID 4: et al. [26, 49] train a model on three tasks (coreference resolution, entity and relation extraction) using one dataset of research papers.Sanh et al. [43] introduce a multi-task model that is trained on four tasks (mention detection, coreference resolution, entity and relation extraction) using two different datasets in the general domain.Results of some previous studies [10, 34, 21, 44] revealed that general coreference systems do not work well in the biomedical domain due to the lack of domain knowledge. For instance, on Colorado Richly Annotated Full Text (CRAFT) corpus [10] a coreference resolution system for the news domain achieves only 14.0 F1 (-32.0).To the best of our knowledge, a transfer learning approach from the general to the scientific domain has not been proposed for coreference resolution yet.2.2 Corpora for Coreference Resolution in Research PapersFor the general domain, multiple datasets exist for coreference resolution, e.g. Message Understanding
5. [5]:  Passage ID 5: ConclusionIn this paper, we review and analyse the progress of biomedical coreference datasets, biomedical language representation models and coreference models for the biomedical domain. Biomedical coreference is an essential but challenging task. Some efforts have been made in this field, but there is still a much room for improvement. The experiments which we conducted indicate biomedical domain knowledge from either pre-training on biomedical texts or integrating biomedical knowledge bases can enhance coreference models for the biomedical domain.AcknowledgementsThis research was supported in part by the China Scholarship Council, and the DALI project,ERC Grant 695662.ReferencesAlsentzer et al. (2019)Emily Alsentzer, John Murphy, William Boag, Wei-Hung Weng, Di Jindi, TristanNaumann, and Matthew McDermott. 2019.Publicly available clinical bert embeddings.In Proceedings of the 2nd Clinical Natural Language ProcessingWorkshop, pages 72–78.Batista-Navarro