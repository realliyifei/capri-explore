# Coreference Resolution for the Biomedical Domain: A Survey

## Question

How do general coreference resolution models perform on biomedical datasets compared to general domain datasets?

## URLs

1. https://ar5iv.org/html/2109.12424. [2109.12424] Coreference Resolution for the Biomedical Domain: A Survey
2. https://ar5iv.org/html/2101.00884. [2101.00884] Coreference Resolution in Research Papers from Multiple Domains
3. https://ar5iv.org/html/2205.12689. [2205.12689] Large Language Models are Few-Shot Clinical Information Extractors
4. https://ar5iv.org/html/2410.13458. [2410.13458] MedINST: Meta Dataset of Biomedical Instructions
5. https://ar5iv.org/html/2305.16326. [2305.16326] A systematic evaluation of large language models for biomedical natural language processing: benchmarks, baselines, and recommendations
6. https://ar5iv.org/html/2109.08564. [2109.08564] Slot Filling for Biomedical Information Extraction
7. https://ar5iv.org/html/2109.02237. [2109.02237] BERT might be Overkill: A Tiny but Effective Biomedical Entity Linker based on Residual Convolutional Neural Networks
8. https://ar5iv.org/html/2308.04498. [2308.04498] DialogREC+: An Extension of DialogRE to Investigate How Much Coreference Helps Relation Extraction in Dialogs

## Answer (I don't know?: ✗)

General coreference resolution models generally perform poorly on biomedical datasets compared to their performance on general domain datasets. This lack of effectiveness can be attributed to several key challenges associated with the biomedical domain.

Firstly, it has been noted that general coreference resolution systems struggle when applied to scientific texts. Studies have indicated that these systems often achieve significantly lower performance metrics—specifically, previous work reported an F1 score of only 14.0 when applying a coreference model designed for the news domain to the Colorado Richly Annotated Full Text (CRAFT) corpus, which is biomedical in nature. This represents a substantial drop of 32.0 points [5]. The primary reasons for this decline in performance hinge on the specific terminology and unique phrasing used within biomedical literature, which differ markedly from the more colloquial language found in general datasets [3] [5].

Additionally, annotating biomedical texts for coreference resolution is often both costly and requires domain-specific expertise [3]. This limitation contributes to the comparatively small size and diversity of annotated biomedical corpora, which impairs the training of robust models that could otherwise benefit from larger, more representative datasets found in the general domain. In contrast, datasets in the general domain are typically much larger and more readily available for training purposes [3][5].

Moreover, numerous studies have confirmed that the integration of biomedical-specific knowledge—achieved either through pre-training on biomedical texts or through the use of specialized biomedical knowledge bases—is essential for enhancing coreference models tailored for this domain. This suggests that general models, which often operate without this specialized training, are ill-equipped to handle the complexities of biomedical texts effectively [4]. 

In conclusion, while general coreference resolution models may show effective results within their intended domains, their performance on biomedical datasets is significantly hindered due to domain-specific language complexities and the limited availability of richly annotated data. This gap emphasizes the need for dedicated research and development in biomedical coreference resolution to enhance model adaptability and effectiveness in this challenging domain.

1. [1]:  https://ar5iv.org/html/2109.12424, [2109.12424] Coreference Resolution for the Biomedical Domain: A Survey
2. [2]:  https://ar5iv.org/html/2109.12424, [2109.12424] Coreference Resolution for the Biomedical Domain: A Survey
3. [3]:  https://ar5iv.org/html/2101.00884, [2101.00884] Coreference Resolution in Research Papers from Multiple Domains
4. [4]:  https://ar5iv.org/html/2109.12424, [2109.12424] Coreference Resolution for the Biomedical Domain: A Survey
5. [5]:  https://ar5iv.org/html/2101.00884, [2101.00884] Coreference Resolution in Research Papers from Multiple Domains
---
1. [1]:  Passage ID 1: some background on coreference resolution in the general domain.Section 3 reviews the main datasets used to study biomedical coreference.Overviews of biomedical language representation models and biomedical coreference models are provided in Sections 4 and 5, respectively.Section 6 introduces the methodology of comparing the biomedical language representation models for coreference. Section 7 presents the evaluation results including the performance of previous models and our experiments, and Section 8 concludes.2 BackgroundCoreference resolution in the general domain has a long history of being studied from early heuristic-based and rule-based approaches to recent learning-based approaches.Lee et al. (2017) proposed the first end-to-end neural coreference resolution model which uses LSTM encoder. Based on the end-to-end model, many extensions to the model have been proposed. BERT and SpanBERT were proposed to replace the LSTM encoder and achieved better performance on
2. [2]:  Passage ID 2: 2016, Li et al. 2018), machine learning-based models (Yang et al. 2004, Torii and Vijay-Shanker 2005, Su et al. 2008, Gasperin 2009, Kim et al. 2011) to recent deep learning-based models (Trieu et al. 2018, Trieu et al. 2019, Li et al. 2021). These models usually integrate biomedical specific information,typically specific rules, pre-trained embeddings and features.This paper reviews and analyses coreference datasets and models for the biomedical domain, as well as recent biomedical language representation models which can enhance coreference models with domain-specific knowledge. In addition, we conduct experiments to evaluate the ability of these language represetation models for biomedical coreference task.The structure of this paper is as follows.In Section 2 we briefly provide some background on coreference resolution in the general domain.Section 3 reviews the main datasets used to study biomedical coreference.Overviews of biomedical language representation models and
3. [3]:  Passage ID 3: 5.0 dataset [19]) in the general domain, that is data from phone conversations, news, magazines, etc.But results of previous work indicate [10, 21, 34, 44] that general coreference resolution systems perform poorly on scientific text. This is presumably caused by the specific terminology and phrasing used in a scientific domain.Some other studies state that annotating scientific text is costly since it demands certain expertise in the article’s domain [1, 5, 18].Most corpora for research papers cover only a single domain (e.g. biomedicine [10],artificial intelligence [26]) and are thus limited to these domains.As a result, the annotated corpora are relatively small and overall only a few domains are covered.Datasets for the general domain are usually much larger, but they have not been exploited yet by approaches for coreference resolution in research papers.Coreference resolution is also one of the main steps in the KG population pipeline [27, 39].However, to date it is not
4. [4]:  Passage ID 4: ConclusionIn this paper, we review and analyse the progress of biomedical coreference datasets, biomedical language representation models and coreference models for the biomedical domain. Biomedical coreference is an essential but challenging task. Some efforts have been made in this field, but there is still a much room for improvement. The experiments which we conducted indicate biomedical domain knowledge from either pre-training on biomedical texts or integrating biomedical knowledge bases can enhance coreference models for the biomedical domain.AcknowledgementsThis research was supported in part by the China Scholarship Council, and the DALI project,ERC Grant 695662.ReferencesAlsentzer et al. (2019)Emily Alsentzer, John Murphy, William Boag, Wei-Hung Weng, Di Jindi, TristanNaumann, and Matthew McDermott. 2019.Publicly available clinical bert embeddings.In Proceedings of the 2nd Clinical Natural Language ProcessingWorkshop, pages 72–78.Batista-Navarro
5. [5]:  Passage ID 5: et al. [26, 49] train a model on three tasks (coreference resolution, entity and relation extraction) using one dataset of research papers.Sanh et al. [43] introduce a multi-task model that is trained on four tasks (mention detection, coreference resolution, entity and relation extraction) using two different datasets in the general domain.Results of some previous studies [10, 34, 21, 44] revealed that general coreference systems do not work well in the biomedical domain due to the lack of domain knowledge. For instance, on Colorado Richly Annotated Full Text (CRAFT) corpus [10] a coreference resolution system for the news domain achieves only 14.0 F1 (-32.0).To the best of our knowledge, a transfer learning approach from the general to the scientific domain has not been proposed for coreference resolution yet.2.2 Corpora for Coreference Resolution in Research PapersFor the general domain, multiple datasets exist for coreference resolution, e.g. Message Understanding