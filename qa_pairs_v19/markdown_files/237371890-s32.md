# Survey of Low-Resource Machine Translation

## Question

How do modern rule-based machine translation systems, like Apertium, manage translations between languages that are closely related?

## URLs

1. https://ar5iv.org/html/2411.13453. [2411.13453] LIMBA: An Open-Source Framework for the Preservation and Valorization of Low-Resource Languages using Generative Models
2. https://ar5iv.org/html/2403.10963. [2403.10963] Pointer-Generator Networks for Low-Resource Machine Translation: Don’t Copy That!
3. https://ar5iv.org/html/2411.19855. [2411.19855] Artificial intelligence contribution to translation industry: looking back and forward
4. https://ar5iv.org/html/2411.05503. [2411.05503] KyrgyzNLP: Challenges, Progress, and Future
5. https://ar5iv.org/html/2403.19399. [2403.19399] KazParC: Kazakh Parallel Corpus for Machine Translation
6. https://ar5iv.org/html/2004.04002. [2004.04002] Transfer learning and subword sampling for asymmetric-resource one-to-many neural translation
7. https://ar5iv.org/html/1710.00923. [1710.00923] Minimal Dependency Translation: a Framework for Computer-Assisted Translation for Under-Resourced Languages

## Answer (I don't know?: ✗)

Modern rule-based machine translation systems like Apertium effectively manage translations between closely related languages by leveraging morphological and syntactical similarities inherent in these languages. Apertium, specifically designed for under-resourced and closely related language pairs, utilizes rule-based methodologies that focus on the commonalities in grammatical structure, vocabulary, and morphology among these languages [2] [3].

One of the critical aspects of Apertium's approach is its development of morphological transducers. These transducers are essential for handling the inflections and derivations that are common in Turkic languages such as Kazakh, Kyrgyz, and Tatar. By focusing on the morphological features shared by these languages, Apertium can facilitate more accurate translations by aligning grammatical rules that apply universally within the language family [1] [3]. 

The system integrates these morphological and syntactical rules into its translation processes, enabling it to generate translations that are not just literal but also contextually and grammatically appropriate for the target language. This is particularly advantageous for languages with complex morphology, as it allows the system to understand and manipulate word forms effectively [3].

Moreover, Apertium supports multiway multilingual neural machine translation (MNMT), which allows translation between multiple languages at once, capitalizing on shared linguistic attributes. Studies indicate that MNMT performs better than traditional bilingual baselines, especially in out-of-domain contexts, which is crucial for enhancing the machine translation capabilities of these closely related languages [3]. However, results suggest that in domain-specific tasks, traditional bilingual models might outperform MNMT for certain languages, illustrating that while the systems are highly adaptable, they also need continuous refinement based on the language pairs involved [3].

In summary, Apertium's management of translations between closely related languages is fundamentally rooted in its rule-based approach that emphasizes shared morphological and syntactical features, enhanced by the flexible capabilities of modern neural architectures. Its ongoing development and open-source nature encourage further customization and adaptation, enabling the continuous evolution of translation capabilities across related languages [2] [3].

1. [1]:  https://ar5iv.org/html/2411.05503, [2411.05503] KyrgyzNLP: Challenges, Progress, and Future
2. [2]:  https://ar5iv.org/html/2411.05503, [2411.05503] KyrgyzNLP: Challenges, Progress, and Future
3. [3]:  https://ar5iv.org/html/2411.05503, [2411.05503] KyrgyzNLP: Challenges, Progress, and Future
4. [4]:  https://ar5iv.org/html/1710.00923, [1710.00923] Minimal Dependency Translation: a Framework for Computer-Assisted Translation for Under-Resourced Languages
5. [5]:  https://ar5iv.org/html/2403.19399, [2403.19399] KazParC: Kazakh Parallel Corpus for Machine Translation
---
1. [1]:  Passage ID 1: M. L., Tyers, F. M.: Apertium: a free/open source platform formachine translation and basic language technology. In: Proceedings of the19th Annual Conference of the European Association for Machine Translation:Projects/Products. Baltic Journal of Modern Computing, Riga, Latvia (May30–Jun 1 2016), https://aclanthology.org/2016.eamt-2.4[20]Gatiatullin, A., Suleymanov, D., Prokopyev, N.,Khakimov, B.: About Turkic Morpheme Portal. In: CMCL. pp.226–243 (2020)[21]Google: Google Gemini: Next-Generation Model / Performance (2024),https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#performance,accessed: 2024-10-29[22]Grootendorst, M.: BERTopic: Neural topic modeling with a class-basedTF-IDF procedure. arXiv preprint arXiv:2203.05794 (2022)[23]Hoang, C. D. V., Koehn, P., Haffari, G., Cohn, T.: Iterativeback-translation for neural machine translation. In: 2nd Workshop on NeuralMachine Translation and Generation. pp. 18–24.
2. [2]:  Passage ID 2: External Tools.Existing tools and frameworks, such as Apertium [19], a platform for rule-based machine translation, can be adapted for Kyrgyz [98]. These tools often support multiple languages and can be extended to include LRLs with additional development.2.3 LLMs as a “Universal Solution”?An emerging counter-argument to developing datasets for low-resource languages (LRLs) and traditional non-LLM NLP methods suggests that next-generation large language models may surpass prior approaches across various NLP tasks, even without extensive task-specific data for training or fine-tuning. While an in-depth discussion of the limitations of this perspective is beyond our scope, it warrants careful consideration due to its implications for LRL data development.A recent example involving the Gemini 1.5 Pro model’s in-context learning is indeed impressive: When given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate
3. [3]:  Passage ID 3: languages developed in the Apertium project [19], including morphological transducers and machine translation systems for languages such as Kazakh, Kyrgyz, and Tatar. These tools support language revitalization and linguistic rights and are useful for developing NLP resources in under-resourced Turkic languages. All code is available, and the technologies are production-ready for several languages.Neural Machine Translation.Two notable works [58, 57] evaluate multiway multilingual neural machine translation (MNMT) for Turkic languages, covering 22 languages, most of them less-resourced. The comparison between bilingual baselines and MNMT models shows that MNMT performs better in out-of-domain tasks, which is useful for enhancing machine translation in under-resourced Turkic languages. Interestingly, the results also indicate that bilingual baselines often outperform MNMT models for Kyrgyz in domain-specific translations. All code and models are publicly available.Other
4. [4]:  Passage ID 4: F.,Ramírez-Sánchez, G., Tyers, F.M.:Apertium: a Free/Open-Source Platform for Rule-Based Machine Translation.Machine Translation 25, 127–144 (2011)(8)Gasser, M.: HornMorpho: a System for Morphological Processing of Amharic, Oromo, and Tigrinya.In: Proceedings of Conference on Human Language Technology for Development, Alexandria, Egypt(2011)(9)Google Translate: English-Amharic, https://translate.google.com/\#en/am/(10)McShane, M., Nirenburg, S., Cowie, J., Zacharski, R.:Embedding Knowledge Elicition and MT Systems Within a Single Architecture.Machine Translation 17, 271–305 (2002)(11)Osborne, T., Putnam, M., Gross, T.:Catenae: Introducing a Novel Unit of Syntactic Analysis.Syntax 15, 354–396 (2012)(12)Honnibal, M.:spaCy: Industrial-Strength Natural Language Processing in Python.https://spacy.io/(2016)(13)Steels, L. (ed.):Design Patterns in Fluid Construction Grammar.John Benjamins, Amsterdam (2011)(14)Wikipedia (English):
5. [5]:  Passage ID 5: Linguistics.Chujo et al. (2015)Kiyomi Chujo, Kathryn Oghigian, and Shiro Akasegawa. 2015.A corpus and grammatical browsing system for remedial EFL learners.Multiple affordances of language corpora for data-driven learning, pages 109–128.Craciunescu et al. (2004)Olivia Craciunescu, Constanza Gerding-Salas, and Susan Stringer-O’Keeffe. 2004.Machine Translation and Computer-Assisted Translation: A New Way of Translating?Machine Translation and Computer-Assisted Translation.Forcada et al. (2011)Mikel L Forcada, Mireia Ginestí-Rosell, Jacob Nordfalk, Jim O’Regan, Sergio Ortiz-Rojas, Juan Antonio Pérez-Ortiz, Felipe Sánchez-Martínez, Gema Ramírez-Sánchez, and Francis M Tyers. 2011.Apertium: a free/open-source platform for rule-based machine translation.Machine translation, 25:127–144.Hutchins (1995)W. John Hutchins. 1995.Machine Translation: A Brief History.In E.F.K. KOERNER and R.E. ASHER, editors, Concise History of the Language Sciences,