# Deep Learning for Text Style Transfer: A Survey under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license Computational Linguistics

## Question

How do false positives and false negatives affect the evaluation of text style transfer models?

## URLs

1. https://ar5iv.org/html/2011.00416. [2011.00416] Deep Learning for Text Style Transfer: A Survey
2. https://ar5iv.org/html/2412.03223. [2412.03223] Linq-Embed-Mistral Technical Report
3. https://ar5iv.org/html/2312.17242. [2312.17242] Learning to Generate Text in Arbitrary Writing Styles
4. https://ar5iv.org/html/2403.08213. [2403.08213] Can Large Language Models Identify Authorship?
5. https://ar5iv.org/html/2212.00460. [2212.00460] Language Model Pre-training on True Negatives
6. https://ar5iv.org/html/2405.03243. [2405.03243] Mind the Gap Between Synthetic and Real: Utilizing Transfer Learning to Probe the Boundaries of Stable Diffusion Generated Data
7. https://ar5iv.org/html/2404.06579. [2404.06579] Less is More for Improving Automatic Evaluation of Factual Consistency
8. https://ar5iv.org/html/2103.04264. [2103.04264] T-Miner : A Generative Approach to Defend Against Trojan Attacks on DNN-based Text Classification
9. https://ar5iv.org/html/2410.02650. [2410.02650] Undesirable Memorization in Large Language Models: A Survey

## Answer (I don't know?: ✗)

False positives and false negatives play a significant role in the evaluation of text style transfer (TST) models, impacting both accuracy and the perceived quality of the generated text.

False positives refer to instances where a TST model inaccurately predicts that a text has been successfully transferred to the target style when it has not. For instance, if a style classifier is used to evaluate model performance, and it reports a high accuracy (e.g., 90% or more), it might misleadingly suggest that the model is successfully capturing the desired stylistic change. However, this could occur due to the model's alignment with the imperfections of the classifier rather than its actual capability to perform style transfer well [1]. In this sense, reliance on classifiers can result in inflated success rates, as the model achieving high scores might be leveraging false positives stemming from adversarial strategies or errors in the classifier itself [1].

False negatives, conversely, represent cases where the TST model fails to transfer the style effectively, yet this failure goes undetected by the evaluation metric. For example, if a style classifier only reports 80% performance, even a perfect TST model might not exceed this threshold due to inherent limitations in the classifier, suggesting that some actual successes could be missed [1]. This illusion of lower transfer capability can harm the reputation and perceived practicality of TST models, leading developers to incorrectly assess model performance. 

Moreover, the interplay between semantic preservation and style transfer complicates matters. The nature of language makes it challenging to optimize one aspect without affecting the other; enhancing style transfer may inadvertently reduce the content preservation score [2]. If a model successfully alters sentiment but distorts the original content, evaluation based solely on style transfer can yield misleading conclusions about its overall effectiveness in real-world applications [3].

Additionally, the construction and design of the classifiers themselves contribute to these challenges. For instance, if a binary style classifier is not accurately diagnosing styles, this will directly influence the reported transfer strength and overall model performance [3]. Studies have indicated that even advanced models like BERT and XLNet have struggled with nuances like negation, suggesting that underlying model limitations can lead to both false positives and negatives [4]. 

In conclusion, understanding false positives and negatives is critical for accurate evaluations of TST models, as they directly influence performance metrics and interpretations. Misestimations can lead to the development of models that appear successful but may fail to deliver in practical applications due to their inability to strike a balance between style transfer and content preservation. Properly addressing these issues is essential in enhancing the reliability and robustness of evaluations in the field of NLP.

1. [1]:  https://ar5iv.org/html/2011.00416, [2011.00416] Deep Learning for Text Style Transfer: A Survey
2. [2]:  https://ar5iv.org/html/2010.12742, No Title
3. [3]:  https://ar5iv.org/html/2010.12742, No Title
4. [4]:  https://ar5iv.org/html/2302.02291, No Title
5. [5]:  https://ar5iv.org/html/2212.00460, [2212.00460] Language Model Pre-training on True Negatives
---
1. [1]:  Passage ID 1: pretrained models are imperfect in the sense that they will favor towards a certain type of methodsFor the first point, it is important to not use the same style classifier or LM in the proposed TST approach, otherwise it can overfit or hack the metrics.For the second point, we need to understand what can be the false positives and false negatives of the generated outputs. An illustrative example is that if the style classifier only reports 80+% performance (e.g., on the gender dataset Prabhumoye et al. (2018) and Amazon dataset Li et al. (2018)), even perfect style rewrites can only score 80+%, but maybe an imperfect model can score 90% because it can resemble the imperfect style classification model more and makes advantage of the false positives.Other reasons for false positives can be adversarial attacks. Jin et al. (2020b) showed that merely paraphrasing by synonyms can drop the performance of high-accuracy classification models from TextCNN Kim (2014) to BERT Devlin
2. [2]:  Passage ID 2: scores increase, content preservation scores decrease, and vice versa. A potential reason for observation might be the entanglement between semantic and stylistic properties in natural language; it is hard to separate the two properties, and changing one affects the other. Therefore, when optimizing to transfer the style in text, it is hard to maintain the sentence’s semantic, i.e., the content information.6.6 Human EvaluationWe conducted a human-based evaluation study to further evaluate the TST models’ performance. We focus our human evaluation on representative models from the three TST strategies, and the models are evaluated on sentiment transfer and formality transfer tasks.We first randomly sampled 50 negative and 50 positive sentences from the Yelp dataset for the sentiment transfer task. Next, we perform TST for the sampled sentences using PTO, DRLST and DualRL, which are the best performing models from the various TST strategies when evaluated using G-Score.
3. [3]:  Passage ID 3: can transfer the input text style, i.e. from negative to positive sentiment, it fails to preserve the original statement’s content, i.e. describing the pasta. Like many other tasks of natural language generation, the transferred sentence will also have to achieve a certain level of fluency for the TST algorithm to be useful in real-world applications. Therefore, an effective TST algorithm will have to perform well in all three evaluation criteria.Transfer strength. The transfer strength of a TST model or its ability to transfer the text style is commonly measured using Style Transfer Accuracy [41, 112, 27, 78, 52]. Typically, a binary style classifier TextCNN [86] is first pre-trained separately to predict the style label of the input sentence. The style classifier is then used to approximate the style transfer accuracy of the transferred style sentences by considering the target style as the ground truth. It is also important to note that the style classifier is not perfect. For
4. [4]:  Passage ID 4: The trick here is also that tokens are read at the same time and not in order (either left-to-right or right-to-left). This allows BERT to take the context of each word into account. Similar in its construction, XLNet (Topal et al., 2021) improved its masking mechanism with peculiar assumptions during its pre-training stage, and improved over the work done by BERT. Despite these advances, studies (Ettinger, 2020) have shown that even these approaches have still struggled with negation. Which is why this study aims to examine the problem in a holistic manner.3. MethodologyThis paper addressed two research problems by utilizing Natural Language Processing (NLP) techniques, a lexicon-based approach, and sequence labeling. To guide the design of the aforementioned automated tool, we answered the following two questions:•RQ1: How do we detect negation in a given text?•RQ2: How can a automated system apply negation to appropriate words to improve sentiment
5. [5]:  Passage ID 5: the uncertain predictions or correct the training with soft regularization. Promoting our view to sentence level, the similarity between the predicted sentence and the original sentence can also be taken into account to measure the sentence-level confidence that indicates how hard the task is, which would be beneficial to provide more fine-grained signals and thus improve the training quality. Based on the rationales above, we are motivated to design the corresponding correction and regularization techniques to mediate misconceived negatives.7 ConclusionsThe work identifies the false negative issue in language model pre-training and proposes methods to counteract it.Though discriminative PLMs may quite straightforwardly suffer from the false negative issue according to our exploration in this work, it has been completely ignored for a long time, and it is a bit surprising that maybe this work is the first one that formally considers such a big pre-training leak. To counteract