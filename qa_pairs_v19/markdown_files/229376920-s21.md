# Deep Learning for Text Style Transfer: A Survey under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license Computational Linguistics

## Question

How do false positives and false negatives affect the evaluation of text style transfer models?

## URLs

1. https://ar5iv.org/html/2011.00416. [2011.00416] Deep Learning for Text Style Transfer: A Survey
2. https://ar5iv.org/html/2412.03223. [2412.03223] Linq-Embed-Mistral Technical Report
3. https://ar5iv.org/html/2312.17242. [2312.17242] Learning to Generate Text in Arbitrary Writing Styles
4. https://ar5iv.org/html/2403.08213. [2403.08213] Can Large Language Models Identify Authorship?
5. https://ar5iv.org/html/2212.00460. [2212.00460] Language Model Pre-training on True Negatives
6. https://ar5iv.org/html/2405.03243. [2405.03243] Mind the Gap Between Synthetic and Real: Utilizing Transfer Learning to Probe the Boundaries of Stable Diffusion Generated Data
7. https://ar5iv.org/html/2404.06579. [2404.06579] Less is More for Improving Automatic Evaluation of Factual Consistency
8. https://ar5iv.org/html/2103.04264. [2103.04264] T-Miner : A Generative Approach to Defend Against Trojan Attacks on DNN-based Text Classification
9. https://ar5iv.org/html/2410.02650. [2410.02650] Undesirable Memorization in Large Language Models: A Survey

## Answer (I don't know?: ✗)

False positives and false negatives significantly impact the evaluation of text style transfer (TST) models, influencing both the perceived accuracy of these models and their overall effectiveness in practical applications.

False positives occur when a model incorrectly identifies an output as successfully transformed into the desired style when it has not. For instance, if a text style transfer model scores high on evaluating its output based on a flawed style classifier, this might give a false impression of effectiveness. In such cases, a model could achieve high performance metrics while producing outputs that are not genuinely aligned with the intended style. The issues surrounding false positives can be illustrated by the example mentioned in the context, where an imperfect style classifier may report performance levels that do not genuinely reflect the model’s capability ([1]). If high accuracy is reported, it may mislead researchers and practitioners regarding the model's utility in real-world scenarios, potentially perpetuating the usage of inadequate systems in sensitive applications like text generation.

On the other hand, false negatives arise when the model produces outputs that are indeed correct stylistic transformations, but the evaluation model fails to recognize them, leading to lower performance metrics. This problem is particularly pronounced in the case of pretrained models, which can become over-fitted or biased toward the evaluation metrics used. If the evaluation framework itself is flawed, it may label effective rewrites as unsuccessful due to the limitations of what it considers “styles” ([1]). The work discussed in the provided context emphasizes that many existing pretrained models fail to account for the quality of their samples adequately, often misclassifying accurate outputs as incorrect, thus leading to false negatives. This issue can undermine the confidence in the model's performance and lead to a lack of trust in deploying TST models.

Additionally, the evaluation of TST models must account for the varied nature of styles, as misclassification can arise when styles are not clearly defined or understood within the context of the dataset being evaluated ([2]). Models that do not correctly address these nuances may produce evaluations that reflect not the quality of the transformation itself, but rather the inability of the model to grasp the subtleties of linguistic style and context.

Ultimately, both false positives and false negatives must be carefully considered when evaluating text style transfer models. The reliance on potentially flawed classifiers can obscure the true performance of these systems and limit their application in sensitive usages, such as combating abusive language online ([5]). As the context mentions, advancements in evaluating and mitigating these errors are crucial for improving TST methodologies and fostering their adoption in socially beneficial applications. Proper evaluation techniques could help develop more robust and reliable models that genuinely reflect their performance, thereby enhancing the field's contribution to natural language processing and its socio-ethical implications.

1. [1]:  https://ar5iv.org/html/2011.00416, [2011.00416] Deep Learning for Text Style Transfer: A Survey
2. [2]:  https://ar5iv.org/html/2011.00416, [2011.00416] Deep Learning for Text Style Transfer: A Survey
3. [3]:  https://ar5iv.org/html/2212.00460, [2212.00460] Language Model Pre-training on True Negatives
4. [4]:  https://ar5iv.org/html/2212.00460, [2212.00460] Language Model Pre-training on True Negatives
5. [5]:  https://ar5iv.org/html/2011.00416, [2011.00416] Deep Learning for Text Style Transfer: A Survey
---
1. [1]:  Passage ID 1: pretrained models are imperfect in the sense that they will favor towards a certain type of methodsFor the first point, it is important to not use the same style classifier or LM in the proposed TST approach, otherwise it can overfit or hack the metrics.For the second point, we need to understand what can be the false positives and false negatives of the generated outputs. An illustrative example is that if the style classifier only reports 80+% performance (e.g., on the gender dataset Prabhumoye et al. (2018) and Amazon dataset Li et al. (2018)), even perfect style rewrites can only score 80+%, but maybe an imperfect model can score 90% because it can resemble the imperfect style classification model more and makes advantage of the false positives.Other reasons for false positives can be adversarial attacks. Jin et al. (2020b) showed that merely paraphrasing by synonyms can drop the performance of high-accuracy classification models from TextCNN Kim (2014) to BERT Devlin
2. [2]:  Passage ID 2: ethical impacts.1.0.0.0.2 Paper Selection.The neural TST papers reviewed in this survey are mainly from top conferences in NLP and artificial intelligence (AI), including ACL, EMNLP, NAACL, COLING, CoNLL, NeurIPS, ICML, ICLR, AAAI, and IJCAI. Other than conference papers, we also include some non-peer-reviewed preprint papers that can offer some insightful information about the field. The major factors for selecting non-peer-reviewed preprint papers include novelty and completeness, among others.2 What Is Text Style Transfer?This section provides an overview of the style transfer task. Section 2.1 goes through the definition of styles and the scope of this survey. Section 2.2 gives a task formulation and introduces the notations that will be used across the survey. Finally, Section 2.3 lists all the common subtasks for neural text style transfer which can save the literature review efforts for future researchers.2.1 How to Define Style?2.1.0.0.1 Linguistic
3. [3]:  Passage ID 3: the uncertain predictions or correct the training with soft regularization. Promoting our view to sentence level, the similarity between the predicted sentence and the original sentence can also be taken into account to measure the sentence-level confidence that indicates how hard the task is, which would be beneficial to provide more fine-grained signals and thus improve the training quality. Based on the rationales above, we are motivated to design the corresponding correction and regularization techniques to mediate misconceived negatives.7 ConclusionsThe work identifies the false negative issue in language model pre-training and proposes methods to counteract it.Though discriminative PLMs may quite straightforwardly suffer from the false negative issue according to our exploration in this work, it has been completely ignored for a long time, and it is a bit surprising that maybe this work is the first one that formally considers such a big pre-training leak. To counteract
4. [4]:  Passage ID 4: "light"); } } else { localStorage.setItem("ar5iv_theme", "dark"); } detectColorScheme(); }Language Model Pre-training on True NegativesZhuosheng Zhang1,2,Hai Zhao1,2,,Masao Utiyama3,Eiichiro Sumita3Corresponding author. This paper was partially supported by Key Projects of National Natural Science Foundation of China (U1836222 and 61733011).AbstractDiscriminative pre-trained language models (PLMs) learn to predict original texts from intentionally corrupted ones. Taking the former text as positive and the latter as negative samples, the PLM can be trained effectively for contextualized representation. However, the training of such a type of PLMs highly relies on the quality of the automatically constructed samples. Existing PLMs simply treat all corrupted texts as equal negative without any examination, which actually lets the resulting model inevitably suffer from the false negative issue where training is carried out on pseudo-negative data and leads to less
5. [5]:  Passage ID 5: Beneficial.An important direction of NLP for social good is to fight against abusive online text. Text style transfer can serve as a very helpful tool as it can be used to transfer malicious text to normal language. Shades of abusive language include hate speech, offensive language, sexist and racist language, aggression, profanity, cyberbullying, harassment, trolling, and toxic language Waseem et al. (2017). There are also other negative text such as propaganda Bernays (2005); Carey (1997), and others. It is widely known that malicious text is harmful to people. For example, research shows that cyberbullying victims tend to have more stress and suicidal ideation Kowalski et al. (2014), and also detachment from family and offline victimization Oksanen et al. (2014). There are more and more efforts put into combating toxic language, such as 30K content moderators that Facebook and Instagram employ Harrison (2019). Therefore, the automatic malicious-to-normal language transfer can be a