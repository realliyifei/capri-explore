# "Do you follow me?": A Survey of Recent Approaches in Dialogue State Tracking

## Question

How does adapting pre-trained language models (PLMs) to dialogues and specific target domains improve performance in dialogue state tracking (DST) tasks?

## URLs

1. https://ar5iv.org/html/2403.04656. [2403.04656] Chain of Thought Explanation for Dialogue State Tracking
2. https://ar5iv.org/html/2311.06345. [2311.06345] Schema Graph-Guided Prompt for Multi-Domain Dialogue State Tracking
3. https://ar5iv.org/html/2405.12468. [2405.12468] Leveraging Diverse Data Generation for Adaptable Zero-Shot Dialogue State Tracking
4. https://ar5iv.org/html/2405.09744. [2405.09744] Many Hands Make Light Work: Task-Oriented Dialogue System with Module-Based Mixture-of-Experts
5. https://ar5iv.org/html/2311.15623. [2311.15623] Injecting linguistic knowledge into BERT for Dialogue State Tracking
6. https://ar5iv.org/html/2411.12307. [2411.12307] Balancing Accuracy and Efficiency in Multi-Turn Intent Classification for LLM-Powered Dialog Systems in Production
7. https://ar5iv.org/html/2401.16862. [2401.16862] State Value Generation with Prompt Learning and Self-Training for Low-Resource Dialogue State Tracking
8. https://ar5iv.org/html/2305.12077. [2305.12077] Few-Shot Dialogue Summarization via Skeleton-Assisted Prompt Transfer

## Answer (I don't know?: ✗)

Adapting pre-trained language models (PLMs) to dialogues and specific target domains significantly enhances performance in dialogue state tracking (DST) tasks through several mechanisms. 

First, PLMs are pre-trained on vast amounts of text, enabling them to capture a wide range of language patterns and syntactic structures. This foundational knowledge allows them to understand user intents and the nuances of dialogue better, which is essential in DST where the goal is to accurately determine user objectives from dialogue history [1][4]. Specifically, when adapted to DST, PLMs can leverage their understanding to identify and extract the relevant slot-value pairs that represent user goals, as these goals are often formulated in varied and natural language expressions [1].

Second, the adaptation process often involves fine-tuning PLMs on domain-specific datasets that reflect the tasks and constraints relevant to the intended dialogue system. For instance, in a “Find Flight” service scenario, a fine-tuned model becomes adept at recognizing entities like “DepartureDate” and “DestinationCity” through examples that illustrate these concepts within a structured format [1][4]. This targeted training allows the model to learn the specific vocabulary and context of the domain, which enhances its accuracy and reliability in real-world applications.

Moreover, the integration of structured data within the dialogue system plays a critical role. By employing a predefined schema that aligns with user intents, DST systems can provide additional context for the model [4]. This schema-oriented approach enables the PLM to focus its attention on semantically important tokens in input sequences, allowing for better understanding and extraction of user goals [3]. Utilizing notable techniques such as prompt engineering, some models can even perform zero-shot or few-shot learning, which enables them to adapt to new tasks with limited examples, thus enhancing flexibility [4].

Additionally, the incorporation of reasoning mechanisms could further bolster model performance. By providing logical explanations for decisions made during dialogue processing, models can improve their generative capabilities. This practice has proven beneficial in enhancing reasoning skills, which is particularly useful in scenarios where user intents are complex and multifaceted [5]. The ability to articulate reasoning not only helps in model explainability, but it can also strengthen the accuracy of DST by ensuring that the system considers the rationale behind user queries [5].

In conclusion, adapting PLMs to DST tasks results in improved performance through enhanced language understanding, targeted domain knowledge acquisition, structured data integration, and the potential for improved reasoning abilities. These factors collectively contribute to more effective and user-centered dialogue systems that can accurately track and respond to user needs.

1. [1]:  https://ar5iv.org/html/2311.06345, [2311.06345] Schema Graph-Guided Prompt for Multi-Domain Dialogue State Tracking
2. [2]:  https://ar5iv.org/html/2311.06345, [2311.06345] Schema Graph-Guided Prompt for Multi-Domain Dialogue State Tracking
3. [3]:  https://ar5iv.org/html/2311.15623, [2311.15623] Injecting linguistic knowledge into BERT for Dialogue State Tracking
4. [4]:  https://ar5iv.org/html/2311.09758, No Title
5. [5]:  https://ar5iv.org/html/2403.04656, [2403.04656] Chain of Thought Explanation for Dialogue State Tracking
---
1. [1]:  Passage ID 1: systems, dialogue state tracking (DST) determines the user goals based on the previous dialogue turns, i.e. dialogue history. User goals are the tasks and purposes the user wants to accomplish through the dialogue and are typically represented as a set of pre-defined slot-value pairs corresponding to a domain-specific schema that consists of the required information to query the dialogue system. For instance, a typical “Find Flight” service has a set of airline names and their relevant characteristics (e.g., Price, DepartureTime, DepartureDate) as the dialogue constraints. The representations of user goals are a set of (slot, value) pairs, such as (DepartureDate, next Wednesday) and (DestinationCity, LAX) for the “Find Flight” service.Figure 1: Illustration of prompt-based adaptation methods: natural language prompt, in-context learning, and schema graph-induced prompt.Pre-trained language models (PLMs) achieved remarkable performance in task-oriented DST by fine-tuning with
2. [2]:  Passage ID 2: systems, dialogue state tracking (DST) determines the user goals based on the previous dialogue turns, i.e. dialogue history. User goals are the tasks and purposes the user wants to accomplish through the dialogue and are typically represented as a set of pre-defined slot-value pairs corresponding to a domain-specific schema that consists of the required information to query the dialogue system. For instance, a typical “Find Flight” service has a set of airline names and their relevant characteristics (e.g., Price, DepartureTime, DepartureDate) as the dialogue constraints. The representations of user goals are a set of (slot, value) pairs, such as (DepartureDate, next Wednesday) and (DestinationCity, LAX) for the “Find Flight” service.Figure 1: Illustration of prompt-based adaptation methods: natural language prompt, in-context learning, and schema graph-induced prompt.Pre-trained language models (PLMs) achieved remarkable performance in task-oriented DST by fine-tuning with
3. [3]:  Passage ID 3: studies, for simplicity, often avoided using external contextual knowledge, instead, relying on transformations of latent representations in PLMs as sources of contextual knowledge. Although these latent representations are context-aware, they remain susceptible to interpretability issues. Some solutions, such as using a specialized neural component to extract contextualized word representations Peters et al. (2018) Liu et al. (2019), require additional fine-tuning.In contrast, our approach employs a computationally efficient algorithm to capture semantic patterns in the entire training corpus and generates features that guide attention to semantically important tokens in the input sequence. This process and the resulting features can be easily analyzed and understood.3 Model3.1 Task: Dialogue State TrackingDialogue State Tracking (DST) involves receiving the dialogue history, the current dialogue turn, and dialogue state history as inputs and yields the updated dialogue
4. [4]:  Passage ID 4: dialogues involving structured data typically rely on Dialogue State Tracking (DST), where user intent is extracted from the dialogue history between a user and the agent in the form of slot values associated with a predefined schema. Pre-trained language models that are fine-tuned have been used in DST for a few years, including both autoregressive LMs Ham et al. (2020); Hosseini-Asl et al. (2020); Peng et al. (2020) and sequence-to-sequence models Lee et al. (2021); Su et al. (2022); Bang et al. (2023); Imrattanatrai and Fukuda (2023); Wang et al. (2023). These methods generally rely on the availability of a substantial training corpus to achieve good performance.LLMs enable zero-shot or few-shot learning Brown et al. (2020). For DST, Xie et al. (2022); Hudeček and Dušek (2023) prompts LLM with human-authored task descriptions or in-context exemplars. Hu et al. (2022) improves the in-context learning for DST performance by incorporating a retriever to fetch useful exemplars.
5. [5]:  Passage ID 5: the limited generalization capacity of these models when applied to complex scenarios in DST.This work is organized around the following three research questions:Q1: Can introducing reasoning explanations improve performance?Generative dialogue state tracking with pre-trained language (PLM) models has been proven to have decent performance Lee et al. (2021a); Shin et al. (2022) owing to PLMs’ inherent ability to understand the text-based slot names and corresponding slot schema. However, these methods still lack generalization ability according to Figure 2. We further claim that adding logical explanations could enhance generative DST models with actual reasoning ability. Chain-of-thought (CoT) Wei et al. (2022b) as a common practice used in PLMs to handle intricate tasks Chen et al. (2022b, a) by providing Reasoning Suzgun et al. (2022); Chen (2022); Zhou et al. (2022) or Explanantions Stacey et al. (2021); Marasovic et al. (2022); Lu et al. (2022). In this endeavor, we