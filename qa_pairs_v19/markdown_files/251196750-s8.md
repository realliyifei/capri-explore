# "Do you follow me?": A Survey of Recent Approaches in Dialogue State Tracking

## Question

How does adapting pre-trained language models (PLMs) to dialogues and specific target domains improve performance in dialogue state tracking (DST) tasks?

## URLs

1. https://ar5iv.org/html/2403.04656. [2403.04656] Chain of Thought Explanation for Dialogue State Tracking
2. https://ar5iv.org/html/2311.06345. [2311.06345] Schema Graph-Guided Prompt for Multi-Domain Dialogue State Tracking
3. https://ar5iv.org/html/2405.12468. [2405.12468] Leveraging Diverse Data Generation for Adaptable Zero-Shot Dialogue State Tracking
4. https://ar5iv.org/html/2405.09744. [2405.09744] Many Hands Make Light Work: Task-Oriented Dialogue System with Module-Based Mixture-of-Experts
5. https://ar5iv.org/html/2311.15623. [2311.15623] Injecting linguistic knowledge into BERT for Dialogue State Tracking
6. https://ar5iv.org/html/2411.12307. [2411.12307] Balancing Accuracy and Efficiency in Multi-Turn Intent Classification for LLM-Powered Dialog Systems in Production
7. https://ar5iv.org/html/2401.16862. [2401.16862] State Value Generation with Prompt Learning and Self-Training for Low-Resource Dialogue State Tracking
8. https://ar5iv.org/html/2305.12077. [2305.12077] Few-Shot Dialogue Summarization via Skeleton-Assisted Prompt Transfer

## Answer (I don't know?: ✗)

Adapting pre-trained language models (PLMs) to dialogues and specific target domains can significantly enhance performance in dialogue state tracking (DST) tasks through several mechanisms that leverage their contextual understanding and efficiency in handling task-oriented dialogue constraints.

First, the inherent capabilities of PLMs to comprehend text-based slot names and the corresponding slot schema offer a solid foundation for improving DST performance. When fine-tuned with extensive task-oriented dialogues, PLMs showcase remarkable efficiency in dialogue state tracking by updating dialogue states based on user goals represented as slot-value pairs, such as the example of finding a flight [1] [4]. This ability to process and understand nuanced dialogue turns allows PLMs to adapt better to user intents and nuances highlighted in the dialogue history.

Moreover, the implementation of prompt-based adaptation methods can ease computational costs associated with fine-tuning large models, improving scalability for domain adaptation. By only adjusting a small number of parameters while freezing the majority of the PLM, these methods enhance task performance without demanding extensive computational resources. This adaptation provides a scalable solution that makes it feasible to deploy PLMs in specific application contexts more efficiently [4].

Adding reasoning explanations further bolsters the generative capabilities of PLMs in DST. As research has suggested, integrating logical explanations can enhance the models' reasoning abilities in handling complex dialogue scenarios, which is a fundamental challenge in DST [3]. Techniques like chain-of-thought (CoT) reasoning can guide the model through intricate tasks in a more interpretable manner, thereby potentially increasing accuracy in determining user intents and states [3].

Additionally, the ability to generate semantic patterns across the training corpus through improved feature extraction methods is another cornerstone of the effectiveness of adapted PLMs. This approach ensures that the model stays context-aware and can effectively guide attention to the most semantically important tokens in the dialogue input [2]. The result is an enhanced understanding of how various components of the dialogue interrelate, which directly influences the model's performance in accurately tracking the dialogue state.

Finally, the therapeutic improvement stemming from utilizing linguistically grounded knowledge within PLMs significantly contributes to their efficacy in DST tasks. Transformer architectures, known for effectively modeling inter-token dependencies through self-attention mechanisms, provide a robust basis for managing the complexities of dialogue [5]. By capturing linguistic nuances in dialogue, these models can align more accurately with user intentions and provide better tracking of state changes over time.

In summary, the adaptation of PLMs to specific dialogues and target domains entails a strategic convergence of fine-tuning methodologies, prompt-based adaptations, reasoning frameworks, and linguistic insights. Each of these factors contributes to overcoming limitations in generalization and enhancing the model's ability to accurately reflect user goals in dialogue state tracking tasks.

1. [1]:  https://ar5iv.org/html/2311.06345, [2311.06345] Schema Graph-Guided Prompt for Multi-Domain Dialogue State Tracking
2. [2]:  https://ar5iv.org/html/2311.15623, [2311.15623] Injecting linguistic knowledge into BERT for Dialogue State Tracking
3. [3]:  https://ar5iv.org/html/2403.04656, [2403.04656] Chain of Thought Explanation for Dialogue State Tracking
4. [4]:  https://ar5iv.org/html/2311.06345, [2311.06345] Schema Graph-Guided Prompt for Multi-Domain Dialogue State Tracking
5. [5]:  https://ar5iv.org/html/2311.15623, [2311.15623] Injecting linguistic knowledge into BERT for Dialogue State Tracking
---
1. [1]:  Passage ID 1: systems, dialogue state tracking (DST) determines the user goals based on the previous dialogue turns, i.e. dialogue history. User goals are the tasks and purposes the user wants to accomplish through the dialogue and are typically represented as a set of pre-defined slot-value pairs corresponding to a domain-specific schema that consists of the required information to query the dialogue system. For instance, a typical “Find Flight” service has a set of airline names and their relevant characteristics (e.g., Price, DepartureTime, DepartureDate) as the dialogue constraints. The representations of user goals are a set of (slot, value) pairs, such as (DepartureDate, next Wednesday) and (DestinationCity, LAX) for the “Find Flight” service.Figure 1: Illustration of prompt-based adaptation methods: natural language prompt, in-context learning, and schema graph-induced prompt.Pre-trained language models (PLMs) achieved remarkable performance in task-oriented DST by fine-tuning with
2. [2]:  Passage ID 2: studies, for simplicity, often avoided using external contextual knowledge, instead, relying on transformations of latent representations in PLMs as sources of contextual knowledge. Although these latent representations are context-aware, they remain susceptible to interpretability issues. Some solutions, such as using a specialized neural component to extract contextualized word representations Peters et al. (2018) Liu et al. (2019), require additional fine-tuning.In contrast, our approach employs a computationally efficient algorithm to capture semantic patterns in the entire training corpus and generates features that guide attention to semantically important tokens in the input sequence. This process and the resulting features can be easily analyzed and understood.3 Model3.1 Task: Dialogue State TrackingDialogue State Tracking (DST) involves receiving the dialogue history, the current dialogue turn, and dialogue state history as inputs and yields the updated dialogue
3. [3]:  Passage ID 3: the limited generalization capacity of these models when applied to complex scenarios in DST.This work is organized around the following three research questions:Q1: Can introducing reasoning explanations improve performance?Generative dialogue state tracking with pre-trained language (PLM) models has been proven to have decent performance Lee et al. (2021a); Shin et al. (2022) owing to PLMs’ inherent ability to understand the text-based slot names and corresponding slot schema. However, these methods still lack generalization ability according to Figure 2. We further claim that adding logical explanations could enhance generative DST models with actual reasoning ability. Chain-of-thought (CoT) Wei et al. (2022b) as a common practice used in PLMs to handle intricate tasks Chen et al. (2022b, a) by providing Reasoning Suzgun et al. (2022); Chen (2022); Zhou et al. (2022) or Explanantions Stacey et al. (2021); Marasovic et al. (2022); Lu et al. (2022). In this endeavor, we
4. [4]:  Passage ID 4: methods: natural language prompt, in-context learning, and schema graph-induced prompt.Pre-trained language models (PLMs) achieved remarkable performance in task-oriented DST by fine-tuning with extensive task-oriented dialogues (Zhang et al., 2019; Wu et al., 2019; Heck et al., 2020; Feng et al., 2020). However, their performance is at the cost of a large number of computational resources as the sizes of PLMs increase rapidly.Recently, prompt-based adaption methods have been proposed, which freeze the PLM while only allowing a small number of parameters updated for downstream tasks Houlsby et al. (2019); Li and Liang (2021); Lester et al. (2021).Such prompt-based adaption eases the computational cost of fine-tuning large language models per downstream task and thus improves the scalability of domain adaption.Generally, there are two paradigms of prompt-based adaption methods for task-oriented DST:1) Natural Language Prompt uses schema descriptions and possible values in natural
5. [5]:  Passage ID 5: strategies, such as the pointer network Mrkšić et al. (2017)), and grounding responses using external context data like database query results Peng et al. (2021). Others have aimed at augmenting and denoising data, synthesizing annotations Heck et al. (2022), and translating dialogue queries to SQL Hu et al. (2022).Our work uniquely centers on the encoder module of the DST pipeline, often overshadowed in research due to the intricacy and opacity of PLMs. Even as this paper utilizes a relatively straightforward baseline to underscore the efficacy of our approach, it can seamlessly integrate into diverse works, fostering more robust and performant systems.Linguistic knowledge and PLM.Transformer-based PLMs are known for proficiently modeling inter-token dependencies, primarily covered by linguistic information domains, through the self-attention mechanism Vaswani et al. (2017).Some research works have demonstrated that transformer layers score well in synthetic dependency tasks