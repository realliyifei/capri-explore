# Survey Article Inter-Coder Agreement for Computational Linguistics

## Question

How does Krippendorff's α handle different types of disagreements in computational linguistics?

## URLs

1. https://ar5iv.org/html/2311.05074. [2311.05074] A Framework to Assess (Dis)agreement Among Diverse Rater Groups
2. https://ar5iv.org/html/2410.03775. [2410.03775] Beyond correlation: The impact of human uncertainty in measuring the effectiveness of automatic evaluation and LLM-as-a-judge
3. https://ar5iv.org/html/2208.06161. [2208.06161] Sparse Probability of Agreement
4. https://ar5iv.org/html/2404.02340. [2404.02340] Corpus Considerations for Annotator Modeling and Scaling
5. https://ar5iv.org/html/2103.12170. [2103.12170] krippendorffsalpha: An R Package for Measuring Agreement Using Krippendorff’s Alpha Coefficient
6. https://ar5iv.org/html/2406.12402. [2406.12402] Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling

## Answer (I don't know?: ✗)

Error: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable