# A Survey on Automatically-Constructed WordNets and their Evaluation: Lexical and Word Embedding-based Approaches

## Question

Why is the expansion approach often preferred for constructing WordNets, and how does it facilitate automatic synset construction?

## URLs

1. https://ar5iv.org/html/2403.20215
2. https://ar5iv.org/html/2412.02138
3. https://ar5iv.org/html/2410.23133
4. https://ar5iv.org/html/2211.12328
5. https://ar5iv.org/html/2404.12698
6. https://ar5iv.org/html/2402.12011

## Answer

The expansion approach is often preferred for constructing WordNets because it allows for localization and translation from a well-established foundational resource, such as the English Princeton WordNet (PWN). This model enables the creation of synsets in the target language by translating existing English synsets rather than creating them de novo. As noted in the context, in the expansion model, synsets from the PWN are localized into the target language, which allows for a more coherent alignment with existing lexical frameworks [2] [5]. 

This approach is especially useful because it facilitates the adaptation of a robust, pre-existing database that has already been standardized and validated through extensive linguistic research. By relying on the PWN, wordnets in other languages can be constructed more quickly and effectively, reducing the likelihood of redundancy and inconsistency that could arise from independently developing a wordnet from scratch [2][5]. 

Moreover, the expansion model helps in addressing the challenges associated with language diversity and untranslatability. For instance, in the development of the Arabic WordNet (AWN), the methodology involved utilizing language experts to identify and expand upon gaps in lexical data, thus addressing quality and completeness issues often found in automated wordnet construction [1][5]. This validates the output synsets within the cultural and linguistic context of the target language, further enhancing their usability in practical applications such as machine translation, information retrieval, and word sense disambiguation [2].

The construction of synsets through the expansion model also encourages comprehensive resource integration. For example, the Arabic WordNet (AWN V3) incorporated 9,576 synsets, alongside 236 gaps and 701 phrasets to accommodate translation needs specific to the Arabic language [1]. This expansion and the incorporation of phrasets indicate a deeper engagement with the nuances of the language, which would be challenging to achieve using purely automated methods.

Additionally, the expand model recognizes and incorporates untranslatable concepts (lexical gaps) that may not have direct counterparts in English. This aspect highlights how the expansion approach facilitates automatic synset construction by ensuring that even complex linguistic and cultural constructs are acknowledged, thus enriching the overall lexical resource [1]. 

In summary, the expansion approach to WordNet construction is preferred due to its reliance on a foundational, standardized model that aids in swift localization and ensures the inclusion of culturally significant linguistic features while enhancing quality and completeness through expert validation [5]. This methodology highlights the balance between automated processes and human expertise, promoting the creation of a more accurate and comprehensive wordnet resource.

[1]: https://ar5iv.org/html/2410.23133, [2410.23133] Crowdsourcing Lexical Diversity
[2]: https://ar5iv.org/html/2403.20215, [2403.20215] Advancing the Arabic WordNet: Elevating Content Quality
[3]: https://ar5iv.org/html/2310.18345, No Title
[4]: https://ar5iv.org/html/2310.18345, No Title
[5]: https://ar5iv.org/html/2403.20215, [2403.20215] Advancing the Arabic WordNet: Elevating Content Quality

[1]: Passage ID 1: For example, in Freihat et al. (2024), we adopted a language expert-based methodology involving two translators and an Arabic language expert to improve the quality of the Arabic wordnet. This approach addressed multiple aspects of lexico-semantic resource quality (Khalilia et al., 2021) by adding missing information and correcting errors, with a focus on handling language diversity and untranslatability. Specifically, we expanded the structure of the wordnet to include phrasets, which provide approximate phrase-level translations, and lexical gaps, representing untranslatable concepts.Our methodology was validated on the Arabic wordnet, resulting in AWN V3, which includes 9,576 synsets, 236 gaps, and 701 phrasets.Similarly, Bella et al. (2020) applied the expert-sourced expansion methodology in the development of the Scottish Gaelic wordnet. A total of 10,583 English synsets from the Princeton WordNet were translated and validated by Gaelic language experts, and then merged with
[2]: Passage ID 2: such as machine translation Poibeau (2017), information retrieval Nie (2022), or word sense disambiguation Navigli (2009).The English Princeton WordNet (PWN) (Miller, 1995), as the first wordnet, has been adapted and employed as a foundation for constructing wordnets in other languages.In general, WordNets are constructed using either the merge or the expand model Vossen (1998). In the merge model, synsets are initially created from pre-existing resources (e.g., dictionaries) in a language. Then, for translability into other languages, the synsets have to be aligned with equivalent English synsets in PWN. For example, the IndoWordNet (Bhattacharyya, 2010) was built following this model. In the expand model, PWN synsets are ‘localized’ or ‘translated’ into target languages. For example, the Polish WordNet (Piasecki et al., 2009) was constructed using this model. In either case, when mapping across languages, the PWN synsets (and thus the English language) are usually used as a
[3]: Passage ID 3: et al. (2006) proposed a taxonomy induction method to expand WordNet 2.1 concepts by automatic noun hyponym acquisition, achieving 10,000 novel synsets with 84% precision. Compared to previous methods that relied on individual classifiers to uncover new relationships based on pre-designed or automatically extracted textual patterns, the proposed approach considers input from multiple classifiers to enhance the overall structure of the taxonomy and prioritizes the optimization of the entire taxonomy structure with a probabilistic architecture. Snow et al. (2006) also proposed an (m,n)-cousin classification-based model to learn coordinate terms, which allows it to integrate heterogeneous evidence from different classifiers and choose the correct word sense to which to attach a new hypernym. The evaluation of the inferred taxonomies produced by the algorithm was conducted by directly comparing them with the WordNet 2.1 taxonomy. This was achieved by testing each taxonomy using a set of
[4]: Passage ID 4: 2017).Their ablation study also shows the importance of additional attention to the title.5.7.2 Structured Concept ExtractionCompared with keyphrase extraction-liked concept extraction, structured concept extraction aimed to develop an ontology where concepts are connected with each other by certain relationships. Here, we introduce three knowledge bases resulting from concept extraction: WordNet, ConceptNet, and SenticNet. Out of them, WordNet focuses more on a word-level ontology, ConceptNet focuses more on a concept-level ontology (e.g., also including phrases for concepts), and SenticNet is a concept-level ontology focusing on contributing to sentiment analysis tasks.WordNet is a manually developed knowledge base, where words and concepts are hierarchically organized. Snow et al. (2006) proposed a taxonomy induction method to expand WordNet 2.1 concepts by automatic noun hyponym acquisition, achieving 10,000 novel synsets with 84% precision. Compared to previous methods
[5]: Passage ID 5: the Polish WordNet (Piasecki et al., 2009) was constructed using this model. In either case, when mapping across languages, the PWN synsets (and thus the English language) are usually used as a pivot when translating words across languages.Wordnets often suffer from quality issues, in a large part due to the use of automated and semi-automated methods for building them Khalilia et al. (2021a, b). In addition, mistakes can be hard to detect as most wordnets do not contain glosses or example sentences. The above are true of the existing Arabic wordnets. The first Arabic wordnet (AWN V1) was built following the expand model (Elkateb et al., 2006) and includes 9,618 synsets translated from PWN to modern standard Arabic. Its second version (AWN V2) (Regragui et al., 2016) extended AWN V1 to 11,269 synsets and was developed using a semi-automatic method and the expand model. As we show in our paper, both wordnets suffer from correctness and completeness issues, and lack glosses and