# Recent Advances in Text-to-SQL: A Survey of What We Have and What We Expect

## Question

Why do single-domain text-to-SQL datasets remain valuable despite their inherent limitations?

## URLs

1. https://ar5iv.org/html/2410.06011
2. https://ar5iv.org/html/2406.08426
3. https://ar5iv.org/html/2408.03256
4. https://ar5iv.org/html/2406.14545
5. https://ar5iv.org/html/2408.05109
6. https://ar5iv.org/html/2410.12916
7. https://ar5iv.org/html/2406.01265
8. https://ar5iv.org/html/2403.02951
9. https://ar5iv.org/html/2407.14568

## Answer

Single-domain text-to-SQL datasets continue to hold significant value in the field of natural language processing (NLP) for various reasons, despite their inherent limitations.

Firstly, these datasets facilitate the development and evaluation of text-to-SQL systems within specific contexts. They provide a contained environment for researchers to fine-tune their models and understand the intricacies of SQL generation within a specific domain, allowing for in-depth exploration of domain-specific vocabulary and schema structures [1] [2]. The focused nature of single-domain datasets makes it easier to engineer solutions without the added complexities of cross-domain generalization, which often introduces challenges due to diverse vocabulary and question patterns [1].

Secondly, single-domain datasets serve as a foundation for baseline measurements in NLP research. They allow for the comparison of different models and techniques under controlled circumstances, helping to establish benchmarks. For example, early datasets like ATIS and GeoQuery exemplify how specific domains can inform the design of SQL queries [3]. The resulting performance insights can subsequently inform the development of more robust models intended for broader applications.

Additionally, many single-domain datasets exhibit simplified SQL query structures which can enhance comprehension and usability for model training. This simplicity can help models achieve higher accuracy and reliability when processing natural language questions specific to their domain [3].

Moreover, these datasets remain essential for addressing specific real-world applications. Many businesses and organizations operate within defined scopes where single-domain solutions are not only sufficient but preferred [5]. For instance, companies focused on a particular sector, such as travel or retail, can benefit from tailored solutions that require less computational overhead and training data compared to multi-domain systems, while still meeting user needs effectively.

Furthermore, the inherent limitations of single-domain datasets—such as linguistic complexity and schema understanding challenges—also provide avenues for academic inquiry [4]. They bring to light specific challenges related to natural language understanding, such as ambiguity and schema representation, prompting ongoing research aimed at overcoming these difficulties. Addressing these localized issues can yield advancements that eventually contribute to the performance of models across multiple domains [4].

In summary, single-domain text-to-SQL datasets continue to be valuable due to their ability to facilitate detailed research, establish benchmarks, simplify model training, cater to specific business needs, and identify key challenges within the NLP landscape. As NLP technology evolves, the insights gained from these datasets will likely remain an essential component of broader efforts in natural language processing [1] [5].

[1]: https://ar5iv.org/html/2406.08426, [2406.08426] Next-Generation Database Interfaces: A Survey of LLM-based Text-to-SQL
[2]: https://ar5iv.org/html/2410.06011, [2410.06011] Large Language Model Enhanced Text-to-SQL Generation: A Survey
[3]: https://ar5iv.org/html/2408.05109, [2408.05109] A Survey of NL2SQL with Large Language Models: Where are we, and where are we going?
[4]: https://ar5iv.org/html/2406.08426, [2406.08426] Next-Generation Database Interfaces: A Survey of LLM-based Text-to-SQL
[5]: https://ar5iv.org/html/2410.12916, [2410.12916] MSc-SQL: Multi-Sample Critiquing Small Language Models For Text-To-SQL Translation

[1]: Passage ID 1: is an essential consideration.II-A4 Cross-Domain GeneralizationText-to-SQL systems often struggle to generalize across various database scenarios and domains.Models trained on a specific domain may not perform well on the proposed questions from other domains due to the variety in vocabulary, database schema structure, and question patterns.Developing systems that can effectively generalized to new domains with minimal domain-specific training data or fine-tuning adaptation is a significant challenge [77].II-B Evolutionary ProcessThe research field of text-to-SQL has witnessed significant advancements over the years in the NLP community, having evolved from rule-based methods to deep learning-based approaches and, more recently, to integrating pre-trained language models (PLMs) and large language models (LLMs), a sketch of the evolutionary process is shown in Fig. 2.II-B1 Rule-based MethodsEarly text-to-SQL systems relied heavily on rule-based methods [11, 12,
[2]: Passage ID 2: question is a question restricted to the domain in which the database data is located and whose answer comes from its database. In essence, the question describes a SQL query. Executing the SQL query yields the answer to the question from its database[30]. Table I provides an overview of commonly used Text-to-SQL datasets, summarizing key features such as dataset size, interaction type, and domain coverage, which are essential for evaluating the generalization capability of Text-to-SQL models.Datasets in this domain typically have the following characteristics.Single/Cross Domain: database data source scenarios, according to the number of scenarios involved, can be divided into single fields and multiple fields[31], such as catering data and tourist attractions for two fields.Number of dialogue rounds: according to the number of dialogue rounds required for complete SQL generation, the dataset is divided into single and multiple rounds.SQL Complexity: Based on the SQL
[3]: Passage ID 3: were introduced which contained nl questions and databases in different languages, thus enhancing the complexity of multilingual comprehension for nl2sql systems. With the growing demand for nl2sql applications in real-world scenarios, researchers have shifted focus towards the robustness of nl2sql systems, leading to the development of datasets designed to validate robustness from multiple perspectives. The most recent advancements have introduced large datasets targeting specific real-world domains, further promoting the application and development of nl2sql systems in practice. The advancement of nl2sql datasets not only highlights the continuous progress in the nl2sql field but also reflects the new challenges that arise.VII-A Single-Domain NL2SQL DatasetsEarly nl2sql datasets focused on specific domains, often featuring simple sql query structures. The ATIS [117] dataset, for example, is centered on flight information, while GeoQuery [118] uses a database of US geographical
[4]: Passage ID 4: technical challenges for text-to-SQL implementations can be summarized as follows:II-A1 Linguistic Complexity and AmbiguityNatural language questions often contain complex linguistic representations, such as nested clauses, coreferences, and ellipses, which make it challenging to map them accurately to the corresponding part of SQL queries [41].Additionally, natural language is inherently ambiguous, with multiple possible representations for a given user question [75, 76].Resolving these ambiguities and understanding the intent behind the user question requires deep natural language understanding and the capability to incorporate context and domain knowledge [33].II-A2 Schema Understanding and RepresentationTo generate accurate SQL queries, text-to-SQL systems need to have a comprehensive understanding of the database schema, including table names, column names, and relationships between various tables.However, the database schema can be complex and vary significantly
[5]: Passage ID 5: area of natural language processing with significant real-world applications. It enables non-expert users to interact with databases using natural language queries, which are then automatically translated into SQL queries. This capability is widely applicable across various domains, including business intelligence, customer service automation, and data analysis. For example, it facilitates automating the feature selection process in tabular data prediction tasks which often involves complex aggregation queries over event histories. Furthermore, empowering translation models with database query access will allow for automated agentic workflows.Recent advances in text-to-SQL generation have primarily leveraged closed-source models like GPT-4 [25] which, combined with advanced prompting techniques, have consistently achieved state-of-the-art performance on benchmarks such as Spider [44] and BIRD [18]. However, the reliance on closed-source API-based models limits accessibility,