# Grammatical Error Correction: A Survey of the State of the Art

## Question

What challenges and transformations are involved in preprocessing human annotations for Grammatical Error Correction (GEC) systems?

## URLs

1. https://ar5iv.org/html/2211.05166. [2211.05166] Grammatical Error Correction: A Survey of the State of the Art
2. https://ar5iv.org/html/2410.16473. [2410.16473] Multi-head Sequence Tagging Model for Grammatical Error Correction
3. https://ar5iv.org/html/2403.05493. [2403.05493] To Err Is Human, but Llamas Can Learn It Too
4. https://ar5iv.org/html/2305.14734. [2305.14734] Advancements in Arabic Grammatical Error Detection and Correction: An Empirical Investigation
5. https://ar5iv.org/html/2407.00924. [2407.00924] EXCGEC: A Benchmark of Edit-wise Explainable Chinese Grammatical Error Correction
6. https://ar5iv.org/html/2005.06600. [2005.06600] A Comprehensive Survey of Grammar Error Correction
7. https://ar5iv.org/html/2312.08400. [2312.08400] Beyond English: Evaluating LLMs for Arabic Grammatical Error Correction

## Answer (I don't know?: ✗)

Preprocessing human annotations for Grammatical Error Correction (GEC) systems presents several challenges and requires specific transformations to ensure that the format aligns with the needs of GEC models. 

One of the primary challenges arises from the inherent mismatch between the way human annotators correct text and the method by which GEC systems are trained. Human annotators typically work with natural text and may apply corrections at the character level, whereas GEC systems are commonly trained on word-tokenized sentences. This discrepancy necessitates a series of preprocessing steps to reconcile the different formats used by human annotation and GEC systems [1][2].

The first transformation involves converting character-level edits made by human annotators into token-level edits, which is crucial because GEC systems evaluate and operate on a tokenized format. While this conversion can be straightforward in many cases, it occasionally presents difficulties. For instance, a character span that a human annotator has marked for correction may not correspond neatly to a single token in the tokenized representation. An example provided illustrates how correcting the form "dancing" to "danced" can involve a complex edit where "ing" is replaced with "ed." This type of transformation requires careful mapping to ensure that edits translate accurately [1].

Furthermore, there are challenges related to defining what constitutes an edit. Annotators must receive clear guidelines on how to define and categorize their corrections to maintain consistency in annotations. This is particularly vital when dealing with various error types, as GEC systems need a standardized approach to apply the corrections effectively [1][2].

As GEC has evolved and gained prominence due to advancements in machine learning and deep learning techniques, the significance of structured and accurate preprocessing has grown. With systems having reached near human-level performance, the quality of the input data—derived from human annotations—plays a critical role in the effectiveness of these models [3][4].

In conclusion, the preprocessing of human annotations for GEC systems is marked by challenges associated with converting character-level edits to token-level formats, addressing the mismatch between human and machine processing, and providing clear definitions of edits for annotators. These transformations are essential for preparing high-quality training inputs that support the development and performance of GEC systems.

1. [1]:  https://ar5iv.org/html/2211.05166, [2211.05166] Grammatical Error Correction: A Survey of the State of the Art
2. [2]:  https://ar5iv.org/html/2211.05166, [2211.05166] Grammatical Error Correction: A Survey of the State of the Art
3. [3]:  https://ar5iv.org/html/2005.06600, [2005.06600] A Comprehensive Survey of Grammar Error Correction
4. [4]:  https://ar5iv.org/html/2211.05166, [2211.05166] Grammatical Error Correction: A Survey of the State of the Art
5. [5]:  https://ar5iv.org/html/2211.05166, [2211.05166] Grammatical Error Correction: A Survey of the State of the Art
---
1. [1]:  Passage ID 1: an annotator towards a particular correction given the error types that are available (Sakaguchi et al., 2016). Ultimately, if annotators are tasked with explicitly defining the edits they make to correct a sentence, annotator guidelines must clearly define the notion of an edit.Preprocessing ChallengesWhile human annotators are trained to correct natural text, GEC systems are typically trained to correct word tokenised sentences (mainly for evaluation purposes). This mismatch means human annotations typically undergo several preprocessing steps in order to produce the desired output format (Bryant and Felice, 2016). The first of these transformations involves converting character-level edits to token-level edits. While this is often straightforward, it can sometimes be the case that a human-annotated character span does not map to a complete token; e.g. [ing →→\rightarrow ed] to denote the edit [dancing →→\rightarrow danced]. Although such cases can often (but not always) be
2. [2]:  Passage ID 2: an annotator towards a particular correction given the error types that are available (Sakaguchi et al., 2016). Ultimately, if annotators are tasked with explicitly defining the edits they make to correct a sentence, annotator guidelines must clearly define the notion of an edit.Preprocessing ChallengesWhile human annotators are trained to correct natural text, GEC systems are typically trained to correct word tokenised sentences (mainly for evaluation purposes). This mismatch means human annotations typically undergo several preprocessing steps in order to produce the desired output format (Bryant and Felice, 2016). The first of these transformations involves converting character-level edits to token-level edits. While this is often straightforward, it can sometimes be the case that a human-annotated character span does not map to a complete token; e.g. [ing →→\rightarrow ed] to denote the edit [dancing →→\rightarrow danced]. Although such cases can often (but not always) be
3. [3]:  Passage ID 3: Jie Liu, Zhuo Liu View a PDF of the paper titled A Comprehensive Survey of Grammar Error Correction, by Yu Wang and 3 other authorsView PDFAbstract:Grammar error correction (GEC) is an important application aspect of natural language processing techniques. The past decade has witnessed significant progress achieved in GEC for the sake of increasing popularity of machine learning and deep learning, especially in late 2010s when near human-level GEC systems are available. However, there is no prior work focusing on the whole recapitulation of the progress. We present the first survey in GEC for a comprehensive retrospect of the literature in this area. We first give the introduction of five public datasets, data annotation schema, two important shared tasks and four standard evaluation metrics. More importantly, we discuss four kinds of basic approaches, including statistical machine translation based approach, neural machine translation based approach, classification based approach
4. [4]:  Passage ID 4: CaoNational University of Singaporecaoh@u.nus.edu  Hwee Tou NgNational University of Singaporenght@comp.nus.edu.sg  Ted BriscoeMohamed bin Zayed University of Artificial Intelligenceted.briscoe@mbzuai.ac.aeAbstractGrammatical Error Correction (GEC) is the task of automatically detecting and correcting errors in text. The task not only includes the correction of grammatical errors, such as missing prepositions and mismatched subject-verb agreement, but also orthographic and semantic errors, such as misspellings and word choice errors respectively. The field has seen significant progress in the last decade, motivated in part by a series of five shared tasks, which drove the development of rule-based methods, statistical classifiers, statistical machine translation, and finally neural machine translation systems which represent the current dominant state of the art. In this survey paper, we condense the field into a single article and first outline some of the
5. [5]:  Passage ID 5: CaoNational University of Singaporecaoh@u.nus.edu  Hwee Tou NgNational University of Singaporenght@comp.nus.edu.sg  Ted BriscoeMohamed bin Zayed University of Artificial Intelligenceted.briscoe@mbzuai.ac.aeAbstractGrammatical Error Correction (GEC) is the task of automatically detecting and correcting errors in text. The task not only includes the correction of grammatical errors, such as missing prepositions and mismatched subject-verb agreement, but also orthographic and semantic errors, such as misspellings and word choice errors respectively. The field has seen significant progress in the last decade, motivated in part by a series of five shared tasks, which drove the development of rule-based methods, statistical classifiers, statistical machine translation, and finally neural machine translation systems which represent the current dominant state of the art. In this survey paper, we condense the field into a single article and first outline some of the