# Grammatical Error Correction: A Survey of the State of the Art

## Question

What challenges and transformations are involved in preprocessing human annotations for Grammatical Error Correction (GEC) systems?

## URLs

1. https://ar5iv.org/html/2211.05166. [2211.05166] Grammatical Error Correction: A Survey of the State of the Art
2. https://ar5iv.org/html/2410.16473. [2410.16473] Multi-head Sequence Tagging Model for Grammatical Error Correction
3. https://ar5iv.org/html/2403.05493. [2403.05493] To Err Is Human, but Llamas Can Learn It Too
4. https://ar5iv.org/html/2305.14734. [2305.14734] Advancements in Arabic Grammatical Error Detection and Correction: An Empirical Investigation
5. https://ar5iv.org/html/2407.00924. [2407.00924] EXCGEC: A Benchmark of Edit-wise Explainable Chinese Grammatical Error Correction
6. https://ar5iv.org/html/2005.06600. [2005.06600] A Comprehensive Survey of Grammar Error Correction
7. https://ar5iv.org/html/2312.08400. [2312.08400] Beyond English: Evaluating LLMs for Arabic Grammatical Error Correction

## Answer (I don't know?: ✗)

Preprocessing human annotations for Grammatical Error Correction (GEC) systems involves several challenges and transformations that are critical in adapting human-corrected text into a format suitable for GEC model training and evaluation.

One of the primary challenges is the mismatch between how human annotators correct text and the requirements of GEC systems, which typically operate on word-tokenized sentences. Human annotations often need to go through multiple preprocessing steps to align with this format. One significant transformation is converting edits made at the character level into token-level edits. While this process can be straightforward in many cases, complexities arise when a character span corrected by a human does not neatly map onto a complete token. For example, when correcting "dancing" to "danced," the edit may need to be represented as [ing → ed], which is not a direct token-to-token transformation [1] [2].

Furthermore, the need for reliable annotation guidelines is emphasized in the context of ensuring that annotators clearly define the edits they perform. This clarity is essential for translating the subjective judgments of human annotators into a standardized format that GEC systems can process effectively [1]. In instances where character-level corrections do not correspond directly to tokens, additional heuristics or rules may need to be developed to guide this conversion accurately, which adds a layer of complexity to the preprocessing task.

Another challenge is related to the data itself. High-quality annotated data is crucial for training GEC models; however, the process of gathering such data is slow and labor-intensive. There are fewer resources available in GEC compared to other natural language processing tasks like machine translation, which further complicates the preparation of training datasets [3]. The limited number of existing annotated training samples may necessitate additional techniques, such as using synthetic data generation methods like denoising autoencoders, to supplement training datasets [4]. This approach helps alleviate data scarcity but adds another layer of preprocessing complexity since synthetic data must also be carefully aligned with human annotations in terms of error types and contexts.

In summary, the preprocessing of human annotations for GEC systems involves transforming character-level edits to token-level edits, managing the complexities of non-direct mappings between these levels, and ensuring reliable annotation practices. Additionally, the need for high-quality annotated data presents challenges in both gathering and generating suitable training samples, requiring sophisticated methodologies to create a robust dataset for GEC model training [4] [5].

1. [1]:  https://ar5iv.org/html/2211.05166, [2211.05166] Grammatical Error Correction: A Survey of the State of the Art
2. [2]:  https://ar5iv.org/html/2211.05166, [2211.05166] Grammatical Error Correction: A Survey of the State of the Art
3. [3]:  https://ar5iv.org/html/2211.05166, [2211.05166] Grammatical Error Correction: A Survey of the State of the Art
4. [4]:  https://ar5iv.org/html/2410.16473, [2410.16473] Multi-head Sequence Tagging Model for Grammatical Error Correction
5. [5]:  https://ar5iv.org/html/2403.05493, [2403.05493] To Err Is Human, but Llamas Can Learn It Too
---
1. [1]:  Passage ID 1: an annotator towards a particular correction given the error types that are available (Sakaguchi et al., 2016). Ultimately, if annotators are tasked with explicitly defining the edits they make to correct a sentence, annotator guidelines must clearly define the notion of an edit.Preprocessing ChallengesWhile human annotators are trained to correct natural text, GEC systems are typically trained to correct word tokenised sentences (mainly for evaluation purposes). This mismatch means human annotations typically undergo several preprocessing steps in order to produce the desired output format (Bryant and Felice, 2016). The first of these transformations involves converting character-level edits to token-level edits. While this is often straightforward, it can sometimes be the case that a human-annotated character span does not map to a complete token; e.g. [ing →→\rightarrow ed] to denote the edit [dancing →→\rightarrow danced]. Although such cases can often (but not always) be
2. [2]:  Passage ID 2: CaoNational University of Singaporecaoh@u.nus.edu  Hwee Tou NgNational University of Singaporenght@comp.nus.edu.sg  Ted BriscoeMohamed bin Zayed University of Artificial Intelligenceted.briscoe@mbzuai.ac.aeAbstractGrammatical Error Correction (GEC) is the task of automatically detecting and correcting errors in text. The task not only includes the correction of grammatical errors, such as missing prepositions and mismatched subject-verb agreement, but also orthographic and semantic errors, such as misspellings and word choice errors respectively. The field has seen significant progress in the last decade, motivated in part by a series of five shared tasks, which drove the development of rule-based methods, statistical classifiers, statistical machine translation, and finally neural machine translation systems which represent the current dominant state of the art. In this survey paper, we condense the field into a single article and first outline some of the
3. [3]:  Passage ID 3: reliability and human judgements, common experimental settingsSection 7System ComparisonRecent state-of-the-art systemsSection 8Future ChallengesDomain generalisation, personalised systems, feedback comment generation, model interpretability, semantic errors, contextual GEC, system combination, training data selection, unsupervised approaches, multilingual GEC, spoken GEC, improved evaluationSection 9Conclusion-Table 2: Survey structure2 DataLike most tasks in NLP, the cornerstone of modern GEC systems is data. State-of-the-art neural models depend on millions or billions of words and the quality of this data is paramount to model success. Collecting high quality annotated data is a slow and laborious process however, and there are fewer resources available in GEC than other fields such as machine translation. This section hence first outlines some key considerations of data collection in GEC and highlights the importance of robust annotation
4. [4]:  Passage ID 4: training signals. To mitigate the limited number of available training samples, a new denoising autoencoder is used to generate a new synthetic dataset to be used for pretraining. Additionally, a new character-level transformation is proposed to enhance the sequence-to-edit function and improve the model’s vocabulary coverage. Our single/ensemble model achieves an F0.5 of 74.4/77.0, and 68.6/69.1 on BEA-19 (test) and CoNLL-14 (test) respectively. Moreover, evaluated on JFLEG test set, the GLEU scores are 61.6 and 61.7 for the single and ensemble models, respectively. It mostly outperforms recently published state-of-the-art results by a considerable margin.1 IntroductionGrammatical Error Correction (GEC) is the task of detecting and correcting different kinds of errors, such as punctuation, spelling, grammatical, and word choice [1]. In recent years, it has been the subject of many modeling efforts due to its ability to improve the grammaticality and readability of user-generated
5. [5]:  Passage ID 5: to improve grammatical error correction (GEC). Thus, we also fine-tune generative LMs to perform the GEC task and compare the results to prompting-based GEC results and related work.The general pipeline of our approach is straight-forward:1:Fine-tune an LM to generate errors using human error data, with correct sentences as input and sentences with errors as output.2:Apply that AEG LM to correct sentences in order to add a synthetically erroneous counterpart3:Fine-tune an LM on that synthetic dataset to correct grammatical errors. Equivalent to Step 1, with the sentence pair direction reversed.4:Continue fine-tuning GEC LM on the (typically smaller) dataset with human errors.5:Apply the models to the erroneous sentences of the benchmark test sets and evaluate the resultsNext, we describe the technical details of our implementation and the experimental setup.3.1 DataWe use two distinct types of data in our work. Firstly, we rely on datasets