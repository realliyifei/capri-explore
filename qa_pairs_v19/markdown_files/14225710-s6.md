# Survey on the Use of Typological Information in Natural Language Processing

## Question

How does incorporating typological information enhance the performance of multilingual dependency parsing?

## URLs

1. https://ar5iv.org/html/2410.07809. [2410.07809] Linguistically-Informed Multilingual Instruction Tuning: Is There an Optimal Set of Languages to Tune?
2. https://ar5iv.org/html/2404.16627. [2404.16627] Incorporating Lexical and Syntactic Knowledge for Unsupervised Cross-Lingual Transfer
3. https://ar5iv.org/html/2401.06034. [2401.06034] LinguAlchemy: Fusing Typological and Geographical Elements for Unseen Language Generalization
4. https://ar5iv.org/html/2407.05022. [2407.05022] A Principled Framework for Evaluating on Typologically Diverse Languages
5. https://ar5iv.org/html/2110.08875. [2110.08875] Predicting the Performance of Multilingual NLP Models
6. https://ar5iv.org/html/2106.02082. [2106.02082] Language Embeddings for Typology and Cross-lingual Transfer Learning
7. https://ar5iv.org/html/2310.13440. [2310.13440] The Past, Present, and Future of Typological Databases in NLP
8. https://ar5iv.org/html/1909.09279. [1909.09279] Working Hard or Hardly Working: Challenges of Integrating Typology into Neural Dependency Parsers
9. https://ar5iv.org/html/2411.14198. [2411.14198] Why do language models perform worse for morphologically complex languages?

## Answer (I don't know?: ✗)

Incorporating typological information can enhance the performance of multilingual dependency parsing by providing a structured understanding of language diversity and facilitating better generalization across languages with different syntactic structures. Several studies and advancements in the field of natural language processing (NLP) highlight the significance of typology in enhancing cross-lingual transfer performance.

Firstly, typological information allows for the coarsely grouping of languages into syntactically homogeneous clusters. This approach benefits dependency parsing, as it suggests that capturing broad similarities among groups of languages, rather than focusing solely on specific individual features, can yield better performance in transfer learning scenarios [3]. The implication here is that when languages share overarching syntactic characteristics, parsers can leverage these commonalities to improve their predictions across different languages.

Moreover, research emphasizes that typological information aligned with actual corpus statistics can enhance transfer performance. Studies have indicated that considering typological aspects consistent with empirical linguistic data yields superior results in multilingual NLP tasks [3]. This suggests that integrating data-driven typological insights can help in understanding the underlying structures shared among languages and improve parsing accuracy.

Furthermore, the NLP community has recognized that typological features, which describe language variation through established standardized databases, can serve as useful embeddings for incorporating linguistic descriptions into models [4]. These features encompass various syntactic phenomena, such as word order and noun cases, and can guide the architectural decisions in dependency parsers to account for diverse input languages effectively. Past work has demonstrated gains in performance when syntactic knowledge derived from typological features is integrated into translation and parsing models [4].

In addition, explicit acknowledgment of linguistic typology highlights the potential for facilitating cross-lingual transfer by clarifying the structural and functional features that characterize different languages. This structured approach can help in tackling divergences between languages, which is one of the challenges that has resulted in modest performance gains in current models [5]. By identifying and incorporating such typological features, models can navigate the varying syntactic realities of over 7,000 languages more competently.

Overall, the combined insights from prior research establish that the incorporation of typological information enhances multilingual dependency parsing by enabling better generalization, improving transfer performance, and systematically organizing language diversity into computable structures that facilitate the effective handling of linguistic variation. This structured approach is fundamental for advancing the capabilities of cross-lingual parsers and significantly improving their performance across diverse languages.

1. [1]:  https://ar5iv.org/html/1909.09279, [1909.09279] Working Hard or Hardly Working: Challenges of Integrating Typology into Neural Dependency Parsers
2. [2]:  https://ar5iv.org/html/2401.06034, [2401.06034] LinguAlchemy: Fusing Typological and Geographical Elements for Unseen Language Generalization
3. [3]:  https://ar5iv.org/html/1909.09279, [1909.09279] Working Hard or Hardly Working: Challenges of Integrating Typology into Neural Dependency Parsers
4. [4]:  https://ar5iv.org/html/2409.19151, [2409.19151] Can LLMs Really Learn to Translate a Low-Resource Language from One Grammar Book?
5. [5]:  https://ar5iv.org/html/1909.09279, [1909.09279] Working Hard or Hardly Working: Challenges of Integrating Typology into Neural Dependency Parsers
---
1. [1]:  Passage ID 1: (2018) and Scholivet et al. (2019) did in several cases.There are many possible hypotheses that can attempt to explain the state-of-the-art. Might neural models already implicitly learn typological information on their own? Is the hand-specified typology information sufficiently accurate — or provided in the right granularity — to always be useful? How do cross-lingual parsers use, or ignore, typology when making predictions? Without understanding answers to these questions, it is difficult to develop a principled way for robustly incorporating linguistic knowledge as an inductive bias for cross-lingual transfer.In this paper, we explore these questions in the context of two predominantly-used typology-based neural architectures for delexicalized dependency parsing.222We focus on delexicalized parsing in order to isolate the effects of syntax by removing lexical influences. The first method implements a variant of selective sharing Naseem et al. (2012); the second adds
2. [2]:  Passage ID 2: (2017) has been instrumental in extending the reach of multilingual NLP, particularly for less-resourced languages. These tools provide vector representations of languages, leveraging typological, geographical, and phylogenetic data, thus offering a structured approach to understanding linguistic diversity. Complementing this, recent research has conducted a comprehensive survey on the utilization of typological information in NLP, highlighting its potential in guiding the development of multilingual NLP technologies Ponti et al. (2019). This survey emphasized the underutilization of typological features in existing databases and the need for integrating data-driven induction of typological knowledge into machine learning algorithms.Recent advancements in prefix tuning Li and Liang (2021) and subspace learning Zhang et al. (2020) have contributed significantly to improving generalization in PLMs. These methods focus on learning prefix subspaces to stabilize the direct learning of
3. [3]:  Passage ID 3: The benefit of typological information is derived from coarsely grouping languages into syntactically-homogeneous clusters rather than from learning to leverage variations along individual typological dimensions in a compositional manner; 2) Typology consistent with the actual corpus statistics yields better transfer performance; 3) Typological similarity is only a rough proxy of cross-lingual transferability with respect to parsing.111Code: github.com/ajfisch/TypologyParser11footnotetext: The first two authors contributed equally.1 IntroductionOver the last decade, dependency parsers for resource-rich languages have steadily continued to improve. In parallel, significant research efforts have been dedicated towards advancing cross-lingual parsing. This direction seeks to capitalize on existing annotations in resource-rich languages by transferring them to the rest of the world’s over 7,000 languages Bender (2011). The NLP community has devoted substantial resources towards this
4. [4]:  Passage ID 4: in NLPThe incorporation of linguistic information into NLP models is a long-standing question with mixed results (Lakoff, 1978; Raskin, 1985; Uszkoreit, 2009; Opitz et al., 2024). Past work sees gains from incorporating syntactic knowledge into translation models using constituency parses (Currey & Heafield, 2019), grammar supertags (Nădejde et al., 2017), or tree-structured models (Sartran et al., 2022). Typological features are a useful form of linguistic description available for many languages in standardised databases (Dryer & Haspelmath, 2013; Skirgård et al., 2023a; b); features describe language variation in terms of phenomena such as word order, verb tenses, and noun cases. Feature specifications are usually drawn from grammar books by linguists, condensing fine-grained, unprocessed textual descriptions into high-level features. Typological features have been incorporated into NLP models with some success in the form of embeddings (Malaviya et al., 2017; Östling & Tiedemann,
5. [5]:  Passage ID 5: on existing annotations in resource-rich languages by transferring them to the rest of the world’s over 7,000 languages Bender (2011). The NLP community has devoted substantial resources towards this goal, such as the creation of universal annotation schemas, and the expansion of existing treebanks to diverse language families. Nevertheless, cross-lingual transfer gains remain modest when put in perspective: the performance of transfer models can often be exceeded using only a handful of annotated sentences in the target language (Section 5). The considerable divergence of language structures proves challenging for current models.One promising direction for handling these divergences is linguistic typology.Linguistic typology classifies languages according to their structural and functional features. By explicitly highlighting specific similarities and differences in languages’ syntactic structures, typology holds great potential for facilitating cross-lingual transfer O’Horan