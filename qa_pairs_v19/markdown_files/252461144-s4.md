# A Survey of Machine Translation Tasks on Nigerian Languages

## Question

What is the Rule-based Approach in machine translation, and what are its benefits and limitations?

## URLs

1. https://ar5iv.org/html/2411.11295
2. https://ar5iv.org/html/2301.00688
3. https://ar5iv.org/html/2404.08661
4. https://ar5iv.org/html/2410.00683
5. https://ar5iv.org/html/1701.04290
6. https://ar5iv.org/html/1807.02226
7. https://ar5iv.org/html/2107.04239
8. https://ar5iv.org/html/2407.08819
9. https://ar5iv.org/html/2408.06124
10. https://ar5iv.org/html/2404.14646

## Answer

## I don't know?: False

The rule-based approach to machine translation (RBMT) is a traditional method that utilizes linguistics-based rules specified by humans to convert source languages into target languages. These rules are primarily derived from various linguistic resources, including monolingual, bilingual, and multilingual dictionaries and grammatical frameworks that govern semantic, syntactic, and morphological properties of languages [2]. 

### Benefits of the Rule-based Approach:

1. **Consistency and Stability**: One of the primary advantages of RBMT is its ability to produce translations that demonstrate high levels of consistency and stability. This is because the translation process is rigorously governed by established linguistic rules, which do not deviate unless manually altered [2].

2. **Quality in Specific Areas**: RBMT often outperforms other machine translation methods, particularly Neural Machine Translation (NMT) and Statistical Machine Translation (SMT), in aspects such as verb tense, aspect, mood, and handling ambiguity in language [2]. This precision can be critical in domains where grammatical accuracy is paramount, such as legal or medical translations.

3. **Independence from Large Corpora**: Unlike NMT, which requires extensive parallel datasets for training, RBMT does not depend on large bilingual corpora. Instead, it relies on the rules that are laid out, allowing for its use even when data is sparse [2].

### Limitations of the Rule-based Approach:

1. **Manual Design and Scalability Issues**: The primary limitation of RBMT is the necessity for extensive human knowledge and design when creating the translation rules. This makes the approach less scalable as the complexity of languages increases [4], and developing the necessary rules for each language pair can be labor-intensive and time-consuming.

2. **Rigidity and Inflexibility**: Since RBMT is strictly rule-based, it tends to lack flexibility. This rigidity may prevent it from effectively adapting to new language constructs or idiomatic expressions that do not fit well within predefined rules [2].

3. **Inability to Capture Complex Contexts**: Unlike modern approaches such as NMT, RBMT struggles with capturing deep contextual meanings and complex dependencies within sentences. Its reliance on explicit rules means it can miss nuances that a more adaptable and learning-based system might manage to infer [5].

4. **Limited Application in Novel Domains**: RBMT can face significant challenges in applying its rules to new domains where language usage may differ from those for which the rules were originally designed. This limitation can hinder its effectiveness in rapidly evolving fields [3].

In summary, while RBMT offers reliable and consistent translations governed by explicit linguistic rules, its reliance on human expertise, inability to adapt to linguistic variety, and limitations in handling context and domain variability restrict its practical application, especially in comparison to more contemporary translation methods like NMT.

[1]: https://ar5iv.org/html/2107.04239, [2107.04239] A Survey on Low-Resource Neural Machine Translation
[2]: https://ar5iv.org/html/2404.08661, [2404.08661] TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations
[3]: https://ar5iv.org/html/2408.06124, [2408.06124] Utilize Transformers for translating Wikipedia category names
[4]: https://ar5iv.org/html/2107.04239, [2107.04239] A Survey on Low-Resource Neural Machine Translation
[5]: https://ar5iv.org/html/2404.08661, [2404.08661] TITLE: The comparison of translationese in machine translation and human transation in terms of translation relations

[1]: Passage ID 1: target languages, (2) exploiting data from auxiliary languages, and (3) exploiting multi-modal data. We hope that our survey can help researchers to better understand this field and inspire them to design better algorithms, and help industry practitioners to choose appropriate algorithms for their applications.1 IntroductionMachine translation (MT) automatically translates from one language to another without human labor, which brings convenience and significantly reduces the labor cost in international exchange and cooperation. Powered by deep learning, neural machine translation (NMT) Bahdanau et al. (2015); Vaswani et al. (2017) has become the dominant approach for machine translation. Compared to conventional rule-based approaches and statistical machine translation (SMT), NMT enjoys two main advantages. First, it does not require professional human knowledge and design on translation perspective (e.g., grammatical rules). Second, neural network can better capture the
[2]: Passage ID 2: machine translation (NMT). Different type has its own features in translationese. There are some work related to translationese in these three different machine translation systems. (1) Rule-based machine translationThe traditional machine translation features rule-based machine translation (RBMT), also named the knowledge-based or linguistics-oriented approach (Hutchins, 1995), which converts the source languages to target languages based on the linguistics-based rules specified by humans. These rules are largely extracted from monolingual, bilingual, and multilingual dictionaries and grammars containing semantic, syntactic, and morphological regulations.For the translation quality, RBMT generally produces the target language featuring consistency and stability without relying on a large bilingual corpus as the translation process strictly abides by the stipulated regulations. RBMT outperforms both NMT and SMT for verb tense, aspect, and mood, as well as ambiguity, according
[3]: Passage ID 3: in Section V before making conclusions in Section VI.II Literature ReviewThe current popular approach in machine translation involves utilizing modern neural networks, which are trained on extensive datasets containing millions to billions of parameters. This approach has proven to achieve substantial quality improvements. At the same time, traditional methods are now less commonly used due to their limitations in dealing with new domains and expensive cost and language pairs with significantly different word orders [2].Many works on neural machine translation rely on an encoder-decoder architecture [3]. Cho et al. [4] introduced the RNN Encoder-Decoder with two RNN networks to improve phrase representation using conditional probabilities. This model captures semantically and syntactically meaningful representations of linguistic phrases. Sutskever et al. [5] created a sequence-to-sequence network using multilayered LSTMs to encode input sequences into fixed-dimensional
[4]: Passage ID 4: NMT enjoys two main advantages. First, it does not require professional human knowledge and design on translation perspective (e.g., grammatical rules). Second, neural network can better capture the contextual information in the entire sentence, and thus conduct high quality and fluent translations.One limitation of NMT is that it needs large scale of parallel data for model training. While there are thousands of languages in the world111https://en.wikipedia.org/wiki/Language, major popular commercial translators (e.g., Google translator, Microsoft translator, Amazon translator) only support tens or a hundred languages because of the lack of large-scale parallel training data for most languages. To handle those languages with limited parallel data, many algorithms have been designed for low-resource NMT in recent years. Therefore, a review on low-resource NMT is very helpful for fresh researchers entering this area and industry practitioners. Although there already exists surveys on
[5]: Passage ID 5: highly automation and efficiency are its two main problems. (2) A corpus-based system with statistical machine translation (SMT) or phrase-based machine translation (PB- SMT) as the primary method uses machine learning algorithms by using a large amount of parallel corpus as input, overcoming the problem of using labor work to boost efficiency automatically (Lopez, 2008); however, it has issues such as with translation for idiomatic expressions, compound words that have to be translated by more than one word, long dependencies, and ambiguous words with different meanings depending on contexts (Nießen, 2000). (3) The currently predominant neural machine translation (NMT) system has gained the most extensive popularity in machine translation domain. In contrast to more established system SMT, NMT makes use of its architecture and capacity to capture complex sentence dependencies, which suggests that it has a great deal of potential to become a new trend in machine translation.