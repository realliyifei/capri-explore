# A Survey on the Role of Negation in Sentiment Analysis

## Question

How is negation typically handled in a bag-of-words model for sentiment analysis?

## URLs

1. https://ar5iv.org/html/2107.11597
2. https://ar5iv.org/html/1906.07610
3. https://ar5iv.org/html/2207.02160
4. https://ar5iv.org/html/1601.06971
5. https://ar5iv.org/html/1806.06407
6. https://ar5iv.org/html/1507.00955
7. https://ar5iv.org/html/2111.06070
8. https://ar5iv.org/html/2409.09989
9. https://ar5iv.org/html/1906.05887

## Answer

Negation in a bag-of-words model for sentiment analysis is commonly addressed using heuristic techniques and lexicon-based methods. In a bag-of-words model, text data is represented as a collection of words, disregarding the order of the words but retaining their frequency. This approach, however, presents challenges when it comes to understanding negation, as the model typically does not account for the syntactic relationships between words.

Heuristics related to negation often involve reversing the polarity of words affected by a negator in the sentence. Researchers have historically modeled negation by modifying the polarity signal of negated words or reversing it entirely when a negator (e.g., "not") is detected [3] [4]. This means that if a word like "good" appears after a negation, it could be treated as "bad" within the sentiment analysis framework.

A fundamental issue with traditional bag-of-words models is that they generally analyze words independently. This characteristic can lead to misinterpretation of sentiment when negation is involved. For instance, in the phrase "not happy," a bag-of-words model might incorrectly interpret the words "not" and "happy" separately without understanding that they interact to convey a negative sentiment [2]. 

Moreover, the scope of negation is often determined heuristically, relying on context cues and the positions of words within the sentence. Researchers may define the scope of negation by identifying common negation cues and assuming that all words located between a negation term and the next punctuation mark are affected by that negation [3]. This method is sometimes termed as finding "negation cues" in the text. 

More advanced machine learning models, like BERT and XLNet, attempt to address these limitations by taking into account the context of words beyond their immediate occurrences. However, even these state-of-the-art models have been shown to struggle with negation despite improvements, indicating that it remains a challenging aspect of sentiment analysis [1] [5].

Additionally, various automated systems aim to enhance sentiment analysis through the detection of negation alongside word polarity adjustment via machine learning techniques. Some approaches suggest utilizing antonyms or developing a semantic construction of sentences, which requires deeper analysis than what typical bag-of-words models offer [2].

In summary, while negation is typically addressed in bag-of-words sentiment analysis through heuristic methods and polarity reversal, the inherent limitations of this model—especially regarding the independent analysis of words—underscore the complexities involved. Consequently, there is ongoing research and development aimed at finding more robust methods of integrating negation into sentiment analysis frameworks.

[1]: https://ar5iv.org/html/2302.02291, No Title
[2]: https://ar5iv.org/html/2302.02291, No Title
[3]: https://ar5iv.org/html/1906.07610, [1906.07610] Improving Sentiment Analysis with Multi-task Learning of Negation
[4]: https://ar5iv.org/html/1906.07610, [1906.07610] Improving Sentiment Analysis with Multi-task Learning of Negation
[5]: https://ar5iv.org/html/2302.02291, No Title

[1]: Passage ID 1: 2019). The applicability of NLP comes in a variety of forms. In our everyday discourse, such as social media conversations, negation signals are employed. In practice, some NLP techniques used in this space are Word2Vec and GloVe (Yu et al., 2017). BERT and XLNet deliver state-of-the-art outcomes as well (Devlin et al., 2018). However, each model has its own set of constraints. Most algorithms underperform when confronted with negation, which is why it is critical to identify novel approaches to overcome this issue in the NLP domain.2.5. Word Negation and Sequence LabelingThe accuracy of NLP models such as sentiment or perception analysis depends on word negation and sequence labeling. Some NLP models typically work by analyzing each word, or sequence of words, independently. These algorithms deconstruct text into its minimum units called tokens (Webster and Kit, 1992). Once these tokens have been cleaned up, the algorithms read each word or tokenized entity independently and
[2]: Passage ID 2: tool, we answered the following two questions:•RQ1: How do we detect negation in a given text?•RQ2: How can a automated system apply negation to appropriate words to improve sentiment analysis?NLP was used mainly because it guides the extraction of information from texts in their natural form. The most frequent lexicon-based technique for negation is to reverse the polarity of the object that is affected by the negator in a sentence (Jurek et al., 2015). This study presents an alternative approach by developing a disambiguation function that can be used to average out the polarity scores of the negated word antonyms using five dictionaries. Beyond sentiment detection, we propose using antonyms to construct a human-readable semantic construction of the entire sentence, taking a context-based approach into consideration. First, detecting negation in a sentence requires the use of an automated decontraction system, as some negations may be in contraction mode e.g.,
[3]: Passage ID 3: some relevant previous work on sentiment analysis more generally, and finally provide some background on previous work on multi-task learning in NLP.2.1 Negation in sentiment modelsNegation is a frequent linguistic phenomenon which has a direct impact on sentiment analysis \@internalciteWiegand2010. Within the framework of lexicon-based sentiment analysis, researchers first attempted to model negation with simple heuristics, such as reversing \@internalciteHuandLiu2004,Polanyi2006,Kennedy2005 or modifying \@internalciteTaboada2011 the polarity signal of a negated word. This approach to tackle contextual valence shifting generally assumes that the final polarity of a text is some function of the prior polarities of adjectives, verbs, and nouns found in the text. The scope of negation is determined heuristically, by finding common negation cues and assuming all words between the cue and the next punctuation are in scope \@internalciteHuandLiu2004 or based on the distance from the
[4]: Passage ID 4: some relevant previous work on sentiment analysis more generally, and finally provide some background on previous work on multi-task learning in NLP.2.1 Negation in sentiment modelsNegation is a frequent linguistic phenomenon which has a direct impact on sentiment analysis \@internalciteWiegand2010. Within the framework of lexicon-based sentiment analysis, researchers first attempted to model negation with simple heuristics, such as reversing \@internalciteHuandLiu2004,Polanyi2006,Kennedy2005 or modifying \@internalciteTaboada2011 the polarity signal of a negated word. This approach to tackle contextual valence shifting generally assumes that the final polarity of a text is some function of the prior polarities of adjectives, verbs, and nouns found in the text. The scope of negation is determined heuristically, by finding common negation cues and assuming all words between the cue and the next punctuation are in scope \@internalciteHuandLiu2004 or based on the distance from the
[5]: Passage ID 5: The trick here is also that tokens are read at the same time and not in order (either left-to-right or right-to-left). This allows BERT to take the context of each word into account. Similar in its construction, XLNet (Topal et al., 2021) improved its masking mechanism with peculiar assumptions during its pre-training stage, and improved over the work done by BERT. Despite these advances, studies (Ettinger, 2020) have shown that even these approaches have still struggled with negation. Which is why this study aims to examine the problem in a holistic manner.3. MethodologyThis paper addressed two research problems by utilizing Natural Language Processing (NLP) techniques, a lexicon-based approach, and sequence labeling. To guide the design of the aforementioned automated tool, we answered the following two questions:•RQ1: How do we detect negation in a given text?•RQ2: How can a automated system apply negation to appropriate words to improve sentiment