# Anaphora With Non-nominal Antecedents in Computational Linguistics: a Survey under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license Computational Linguistics

## Question

What are the key assumptions of Centering Theory, and how does it model coherence and salience in discourse?

## URLs

1. https://ar5iv.org/html/1805.04993. [1805.04993] Discourse Coherence in the Wild: A Dataset, Evaluation and Methods
2. https://ar5iv.org/html/2004.14626. [2004.14626] Rethinking Coherence Modeling: Synthetic vs. Downstream Tasks
3. https://ar5iv.org/html/1507.08234. [1507.08234] Entropy and Graph Based Modelling of Document Coherence using Discourse Entities: An Application to IR

## Answer (I don't know?: ✗)

Centering Theory (CT) is a framework that plays a significant role in modeling coherence and salience in discourse. Its fundamental assumptions can be summarized as follows:

1. **Salient Entities**: Centering Theory posits that during discourse, a reader's attention is focused on a few salient entities. These entities are not merely subjects or objects; they are specifically those that are most relevant to the ongoing discourse and are thus considered to be "centers" of attention. According to CT, coherence in a text arises from how these centers shift throughout the discourse, allowing the reader to track important themes or topics [4].

2. **Discourse Purpose and Structure**: CT incorporates an understanding of not only what entities are being discussed but also the intentional structure of the discourse. The discourse purpose shapes how these entities are presented and how coherence is perceived. This factor contributes to the model by linking entities to the author's intentions, thus aiding in the organization of discourse segments [4].

3. **Attention Structure**: The model emphasizes attentional structure, stating that entities in the text exhibit patterns that signal their importance to the reader. This means that not all subjects and objects within sentences are treated equally; instead, salience must be derived from their contextual relevance. Thus, Centering Theory allows for a nuanced approach to understanding which entities are focal at any point, depending on their relevance to the overall discourse [4] [5].

CT manifests in coherence modeling by providing a framework for predicting how shifts in these attention centers affect the overall coherence of a text. For instance, the theory provides insights into how missing transitions or poorly organized segments can disrupt the flow of a text, leading to incoherence. It contributes to computational models that assess coherence by representing relationships between entities across sentences and stages in a discourse [1] [2].

To enhance CT, researchers have analyzed the limitations of existing assumptions. A common critique is that traditionally, all subjects and objects are treated as equally salient, which oversimplifies their roles in discourse. Addressing this, various enhancements have been proposed to include salience and topical weighting, considering not just grammatical roles but also contextual and semantic importance [5].

In conclusion, Centering Theory provides a robust framework to model coherence in discourse by focusing on key assumptions about salience and attentional structure, which are essential for both theoretical exploration and practical applications in natural language processing tasks such as text generation and summarization [1] [3].

1. [1]:  https://ar5iv.org/html/2004.14626, [2004.14626] Rethinking Coherence Modeling: Synthetic vs. Downstream Tasks
2. [2]:  https://ar5iv.org/html/1805.04993, [1805.04993] Discourse Coherence in the Wild: A Dataset, Evaluation and Methods
3. [3]:  https://ar5iv.org/html/2004.14626, [2004.14626] Rethinking Coherence Modeling: Synthetic vs. Downstream Tasks
4. [4]:  https://ar5iv.org/html/1507.08234, [1507.08234] Entropy and Graph Based Modelling of Document Coherence using Discourse Entities: An Application to IR
5. [5]:  https://ar5iv.org/html/1507.08234, [1507.08234] Entropy and Graph Based Modelling of Document Coherence using Discourse Entities: An Application to IR
---
1. [1]:  Passage ID 1: models.111Code and data used for evaluation available at https://ntunlpsg.github.io/project/coherence/coh-eval/1 Introduction and Related WorkCoherence is an important aspect of discourse that distinguishes a well-written text from a poorly-written one that is difficult to comprehend Halliday and Hasan (1976). Computational models that can assess coherence have applications in text generation and ranking, such as summarization, machine translation, essay scoring and dialog systems.Researchers have proposed a number of formal theories of discourse coherence, which have inspired the development of many coherence models – both traditional and neural ones. Inspired by the Centering Theory Grosz et al. (1995), the entity based local models Barzilay and Lapata (2008); Elsner and Charniak (2011b) formulate coherence in terms of syntactic roles (e.g., subject, object) of entities in nearby sentences. Another branch of models Pitler and Nenkova (2008); Lin et al. (2011); Feng et al.
2. [2]:  Passage ID 2: and discuss patterns we observed in low coherence texts in four domains.1 IntroductionDiscourse coherence is an important aspect of text quality. It encompasses how sentences are connected as well as how the entire document is organized to convey information to the reader.Developing discourse coherence models to distinguish coherent writing from incoherent writing is useful to a range of applications. An automated coherence scoring model could provide writing feedback, e.g. identifying a missing transition between topics or highlighting a poorly organized paragraph. Such a model could also improve the quality of natural language generation systems.One approach to modeling coherence is to model the distribution of entities over sentences. The entity grid Barzilay and Lapata (2005), based on Centering Theory Grosz et al. (1995), was the first of these models. Extensions to the entity grid include additional features Elsner and Charniak (2008, 2011); Feng et al. (2014), a graph
3. [3]:  Passage ID 3: ways. The most common approach has been to evaluate them on synthetic discrimination tasks that involve identifying the right order of the sentences at the local and global levels Barzilay and Lapata (2008); Elsner and Charniak (2011b); Moon et al. (2019). The other (rather infrequent) way has been to assess the impact of coherence score as an additional feature in downstream tasks like readability assessment and essay scoring Barzilay and Lapata (2008); Mesgar and Strube (2018). But since the concept of coherence goes beyond these constrained tasks and domains, so should the models.Given the recent advances in neural NLP methods, with claims of reaching human parity in machine translation Hassan et al. (2018), fluency in summarization Liu et al. (2017); Celikyilmaz et al. (2018), or context-consistent response generation Zhang et al. (2020); Hosseini-Asl et al. (2020), coherence modeling of machine-generated texts, particularly at a document-level, is now more crucial than ever
4. [4]:  Passage ID 4: units of discourse is called coherence. Several models of text coherence exist.On a high level, these models capture text regularities or patterns predicted by a theory or otherwisehypothesised to indicate coherence.For instance, according to early discourse theories [26], three core factors of text coherence are (i) the discourse purpose (intentionalstructure), (ii) the specific discourse items discussed (attentional structure), and (iii) the organisation of the discoursesegments. Of these factors, coherence models have been presented for both intentional structure [44], and discourse segments[4, 23], but attentional structure has received the most attention and is the basis for most existing models of text coherence. Oneapproach toattentional structure that has been used extensively in coherence models is Centering Theory [25, 31] (CT), whichposits that a reader’s attention is centered on a few salient entities in text, and that these exhibit patterns signalling the reader
5. [5]:  Passage ID 5: consider all subjects and objects as salient discourse entities.This assumption implies that (a) all subjects and objects are equally salient in text, and (b) all subjects and objects are topical(as opposed to having a modifying or periphrastic role in the discourse). However, neither of theseassumptions is true. Assumption (a) could be removed by including some salience weighting component in the selection of entities. In the past, this has been attemptedthrough the use of linguistic features, such as modifiers and named entity types [19]. It will be interesting to see if we canalso use statistical approximations to this end, looking into the rich IR literature in term weighting.Assumption (b) could be removed by including a similar topical weighting component, such as in [18]. In the case where coherence scores are used for IR,it makes sense to align this topical detection to the query topic, so that, for instance, coherence is computed only for documents whose topic