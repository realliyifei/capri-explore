# A Short Survey on Sense-Annotated Corpora

## Question

How does EuroSense perform multilingual disambiguation, and what is its precision across various languages?

## URLs

1. https://ar5iv.org/html/1805.04685. [1805.04685] Huge Automatically Extracted Training Sets for Multilingual Word Sense Disambiguation
2. https://ar5iv.org/html/1802.04744. [1802.04744] A Short Survey on Sense-Annotated Corpora
3. https://ar5iv.org/html/2106.06082. [2106.06082] One Sense per Translation
4. https://ar5iv.org/html/2106.06462. [2106.06462] Semi-Supervised and Unsupervised Sense Annotation via Translations
5. https://ar5iv.org/html/2104.14694. [2104.14694] Let’s Play Mono-Poly: BERT Can Reveal Words’ Polysemy Level and Partitionability into Senses
6. https://ar5iv.org/html/2407.09861. [2407.09861] \theςυβςεςτιον Σψνταξ ανδ Γραμμαρ ιν Γρεεϰ: Λανγυαγε Ρεςουρςες

## Answer (I don't know?: ✗)

EuroSense performs multilingual disambiguation by utilizing parallel corpora to create a sense-annotated corpus across multiple languages. This method integrates a graph-based disambiguation approach with a refinement leveraging distributional similarity, as demonstrated in the work of Moro et al. (2014) and Camacho-Collados et al. (2016) [2]. The construction of EuroSense aims to capitalize on the cross-complementarities of definitions of identical concepts found in various languages, effectively enhancing the disambiguation process through the use of heterogeneous sources [2].

The output of EuroSense is a sense-annotated corpus that spans 21 languages derived from the Europarl parallel corpus [2]. Evaluations conducted on EuroSense indicate that it achieves an estimated precision of over 80% for the four languages stated (English, Spanish, French, and Italian) [2]. More specifically, it can reach almost 90% precision for specific languages like German, illustrating its effectiveness in multilingual settings [2]. 

Overall, EuroSense's approach highlights the importance of multi-linguality in natural language processing by providing a framework that can support various languages and improve the accuracy of sense disambiguation across different contexts and languages.

1. [1]:  https://ar5iv.org/html/2104.14694, [2104.14694] Let’s Play Mono-Poly: BERT Can Reveal Words’ Polysemy Level and Partitionability into Senses
2. [2]:  https://ar5iv.org/html/1802.04744, [1802.04744] A Short Survey on Sense-Annotated Corpora
3. [3]:  https://ar5iv.org/html/2106.06462, [2106.06462] Semi-Supervised and Unsupervised Sense Annotation via Translations
4. [4]:  https://ar5iv.org/html/1802.04744, [1802.04744] A Short Survey on Sense-Annotated Corpora
5. [5]:  https://ar5iv.org/html/1805.04685, [1805.04685] Huge Automatically Extracted Training Sets for Multilingual Word Sense Disambiguation
---
1. [1]:  Passage ID 1: high precision version777The high coverage version of Eurosense is larger than the high precision one, but disambiguation is less accurate. of Eurosense, and create sentence pools in the same way as inEnglish, balancing the number of monosemous and polysemous words (418). We determine the number of senses for a word as the number of its Babelnet senses that are mapped to a WordNet sense.888This filtering serves to exclude BabelNetsenses that correspond to named entities andare not useful for our purposes(such as movie or album titles), and to run these experiments under similar conditions across languages.3.2 Contextualised Word RepresentationsWe experiment with representations generated by three English models: BERT Devlin et al. (2019)999We use Huggingface transformers Wolf et al. (2020)., ELMo Peters et al. (2018) and context2vec Melamud et al. (2016). BERT is a Transformer architecture Vaswani et al. (2017) that is jointly trained for a masked LM and a next sentence
2. [2]:  Passage ID 2: textual definitions from various heterogeneous sources in 263 languages. The underlying idea lies on leveraging the cross-complementarities of definitions of identical concepts from different languages and resources. The approach couples a graph-based disambiguation method [Moro et al. (2014] with a refinement based on distributional similarity [Camacho-Collados et al. (2016]. The proposed method was evaluated on four European languages (English, Spanish, French and Italian) with an estimated precision of over 80%.EuroSense.The construction of EuroSense999http://lcl.uniroma1.it/eurosense[Delli Bovi et al. (2017] follows a similar approach to SenseDefs. In this case, parallel corpora is exploited for a single multilingual disambiguation. The output is a sense-annotated corpus for 21 languages for the Europarl parallel corpus [Koehn (2005]. The estimated precision for four languages isover 80% on average, with a peak of almost 90% for German.Train-o-Matic.Similarly to the
3. [3]:  Passage ID 3: Human Language Technology,pages 240–243. Association for Computational Linguistics.Moro and Navigli (2015)Andrea Moro and Roberto Navigli. 2015.Semeval-2015 task 13: Multilingual all-words sense disambiguation andentity linking.In Proceedings of the 9th International Workshop on SemanticEvaluation, pages 288–297.Navigli (2018)Roberto Navigli. 2018.Natural language understanding: Instructions for (present and future)use.In IJCAI, pages 5697–5702.Navigli et al. (2013)Roberto Navigli, David Jurgens, and Daniele Vannella. 2013.Semeval-2013 task 12: Multilingual word sense disambiguation.In Proceedings of the Seventh International Workshop onSemantic Evaluation, pages 222–231.Navigli and Ponzetto (2012)Roberto Navigli and Simone Paolo Ponzetto. 2012.BabelNet: The automatic construction, evaluation and application ofa wide-coverage multilingual semantic network.Artificial Intelligence, 193:217–250.Pasini and Navigli
4. [4]:  Passage ID 4: J., Raganato, A., and Navigli, R.(2017).EuroSense: Automatic harvesting of multilingual sense annotationsfrom parallel text.In Proc.of ACL, volume 2, pages 594–600.Edmonds and Cotton (2001Edmonds, P. and Cotton, S.(2001).Senseval-2: overview.In Proc. of SensEval 2, pages 1–5. ACL.Eisele and Chen (2010Eisele, A. and Chen, Y.(2010).MultiUN: A Multilingual Corpus from United Nation Documents.In Proceedings of the Seventh conference on InternationalLanguage Resources and Evaluation, pages 2868–2872.Eshel et al. (2017Eshel, Y., Cohen, N., Radinsky, K., Markovitch, S., Yamada, I., and Levy, O.(2017).Named entity disambiguation for noisy text.In Proceedings of the 21st Conference on Computational NaturalLanguage Learning (CoNLL 2017), pages 58–68. Association for ComputationalLinguistics.Fellbaum (1998Fellbaum, C.(1998).WordNet: An Electronic Database.MIT Press, Cambridge, MA.Flekova and Gurevych (2016Flekova,
5. [5]:  Passage ID 5: J., Raganato, A., and Navigli, R.(2017).EuroSense: Automatic harvesting of multilingual sense annotationsfrom parallel text.In Proc.of ACL, volume 2, pages 594–600.Edmonds and Cotton, 2001Edmonds, P. and Cotton, S.(2001).Senseval-2: overview.In Proc. of SensEval 2, pages 1–5. ACL.Fellbaum, 1998Christiane Fellbaum, editor.(1998).WordNet: An Electronic Database.MIT Press, Cambridge, MA.Moro and Navigli, 2015Moro, A. and Navigli, R.(2015).Semeval-2015 task 13: Multilingual all-words sense disambiguation andentity linking.In Proc. of SemEval-2015.Moro et al., 2014Moro, A., Raganato, A., and Navigli, R.(2014).Entity Linking meets Word Sense Disambiguation: a Unified Approach.Transaction of ACL (TACL), 2:231–244.Navigli and Ponzetto, 2010Navigli, R. and Ponzetto, S. P.(2010).BabelNet: Building a very large multilingual semantic network.In Proceedings of the 48th Annual Meeting of the Association