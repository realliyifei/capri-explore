# A Practical Survey on Zero-shot Prompt Design for In-context Learning

## Question

What are the primary categories and methods for assessing prompt performance in in-context learning?

## URLs

1. https://ar5iv.org/html/2309.13205. [2309.13205] A Practical Survey on Zero-shot Prompt Design for In-context Learning
2. https://ar5iv.org/html/2404.01077. [2404.01077] Efficient Prompting Methods for Large Language Models: A Survey
3. https://ar5iv.org/html/2403.06126. [2403.06126] In-context Prompt Learning for Test-time Vision Recognition with Frozen Vision-language Model
4. https://ar5iv.org/html/2401.06766. [2401.06766] Mind Your Format: Towards Consistent Evaluation of In-Context Learning Improvements
5. https://ar5iv.org/html/2406.14955. [2406.14955] ICLEval: Evaluating In-Context Learning Ability of Large Language Models
6. https://ar5iv.org/html/2404.02054. [2404.02054] Deconstructing In-Context Learning: Understanding Prompts via Corruption
7. https://ar5iv.org/html/2112.08633. [2112.08633] Learning To Retrieve Prompts for In-Context Learning
8. https://ar5iv.org/html/2410.12878. [2410.12878] Towards More Effective Table-to-Text Generation: Assessing In-Context Learning and Self-Evaluation with Open-Source Models

## Answer (I don't know?: âœ—)

Error: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable