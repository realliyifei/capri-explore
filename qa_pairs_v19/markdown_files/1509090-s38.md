# Multiword Expression Processing: A Survey under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license Computational Linguistics

## Question

What are the primary challenges faced by machine translation systems when translating multiword expressions (MWEs)?

## URLs

1. https://ar5iv.org/html/2211.05201. [2211.05201] HilMeMe: A Human-in-the-Loop Machine Translation Evaluation Metric Looking into Multi-Word Expressions
2. https://ar5iv.org/html/1710.06313. [1710.06313] Paying Attention to Multi-Word Expressions in Neural Machine Translation
3. https://ar5iv.org/html/2308.13961. [2308.13961] Translate Meanings, Not Just Words: IdiomKB’s Role in Optimizing Idiomatic Translation with Language Models
4. https://ar5iv.org/html/2210.04545. [2210.04545] Automatic Evaluation and Analysis of Idioms in Neural Machine Translation
5. https://ar5iv.org/html/2005.10583. [2005.10583] MultiMWE: Building a Multi-lingual Multi-Word Expression (MWE) Parallel Corpora
6. https://ar5iv.org/html/2405.01502. [2405.01502] Analyzing the Role of Semantic Representations in the Era of Large Language Models
7. https://ar5iv.org/html/2305.06157. [2305.06157] Implications of Multi-Word Expressions on English to Bharti Braille Machine Translation
8. https://ar5iv.org/html/1703.08748. [1703.08748] LEPOR: An Augmented Machine Translation Evaluation Metric

## Answer (I don't know?: ✗)

Machine translation (MT) systems encounter several primary challenges when translating multi-word expressions (MWEs). These challenges stem from the inherent complexities of MWEs themselves and the limitations of MT methodologies.

Firstly, MWEs pose significant obstacles due to their idiomatic nature. Baldwin and Kim (2010) define MWEs as "lexical items that: (a) can be decomposed into multiple lexemes; and (b) display lexical, syntactic, semantic, pragmatic and/or statistical idiomaticity" [5]. This classification highlights that MWEs often cannot be directly translated word-for-word; their meanings may not be derived from the meanings of their individual components, making accurate translation difficult. For example, idiomatic expressions like "kick the bucket" cannot be translated literally without losing their meaning.

Secondly, MT systems often struggle with the integration of MWEs into the translation process. While statistical machine translation (SMT) might reproduce MWEs verbatim using standard phrase-based models, it encounters challenges with grammaticality [5]. Neural machine translation (NMT) methods, which are designed to learn and generate translations based on high-dimensional vector representations, can further complicate MWE translation. Specifically, NMT may fail to memorize and reproduce MWEs effectively, as these expressions might not appear frequently enough in training data. This loss in specific meanings can lead to translations that lack fluency and adequacy [3] [5].

Moreover, the evaluation of MT systems' capability to handle MWEs presents challenges as well. Current popular automatic evaluation metrics have proven inadequate in assessing how well these systems recognize and translate MWEs [1]. This prompts the necessity for more nuanced human-in-the-loop evaluation frameworks that account for the treatment of MWEs in MT [1].

Another challenge is the limited availability of bilingual or multilingual MWE corpora, which hampers the development of effective MT systems. These resources are crucial for training and evaluating MT systems' performance on MWEs, but are currently scarce [2]. A lack of comprehensive language resources means that MT systems often lack adequate training data to improve their accuracy when dealing with MWEs across different languages.

Lastly, various strategies have been explored to improve the translation of MWEs, such as adding bilingual pairs of automatically extracted MWE candidates to training corpora. However, results show varying levels of success, with the addition of full sentences yielding only minimal improvements in automated evaluation results [4]. This variability underscores the complex relationship between MWE handling and MT system performance.

In summary, the primary challenges faced by machine translation systems when translating MWEs encompass idiomatic meanings that complicate direct translations, difficulties in integration due to the inherent structure of NMT systems, insufficient evaluation metrics, a lack of multilingual training resources, and mixed success in applying improvement strategies. Addressing these challenges is crucial for advancing the quality and reliability of machine translation outputs involving MWEs.

1. [1]:  https://ar5iv.org/html/2211.05201, [2211.05201] HilMeMe: A Human-in-the-Loop Machine Translation Evaluation Metric Looking into Multi-Word Expressions
2. [2]:  https://ar5iv.org/html/2005.10583, [2005.10583] MultiMWE: Building a Multi-lingual Multi-Word Expression (MWE) Parallel Corpora
3. [3]:  https://ar5iv.org/html/2005.10583, [2005.10583] MultiMWE: Building a Multi-lingual Multi-Word Expression (MWE) Parallel Corpora
4. [4]:  https://ar5iv.org/html/1710.06313, [1710.06313] Paying Attention to Multi-Word Expressions in Neural Machine Translation
5. [5]:  https://ar5iv.org/html/1710.06313, [1710.06313] Paying Attention to Multi-Word Expressions in Neural Machine Translation
---
1. [1]:  Passage ID 1: Multi-word Expressions (MWEs). MWEs have played a bottleneck in many Natural Language Processing (NLP) tasks including MT. MWEs can be used as one of the main factors to distinguish different MT systems by looking into their capabilities on recognising and translating MWEs in an accurate and meaning equivalent manner.Keywords: Machine Translation Evaluation, Multi-word Expressions, Human-in-the-Loop Evaluation, Fluency and Adequacy, Domain-specific Terminology\newciteslanguageresourceLanguage ResourcesHilMeMe: A Human-in-the-Loop Machine Translation Evaluation Metric Looking into Multi-Word ExpressionsLifeng HanThe University of Manchesterlifeng.han@manchester.ac.ukAbstract content1.   IntroductionMachine Translation Evaluation (MTE) has been a long-term challenging research topic since the development of MT. MTE plays an important role in MT development and quality evaluation.Popular automatic evaluation metrics have failed to correctly
2. [2]:  Passage ID 2: Machine Translation, Language Resource, EvaluationMultiMWE: Building a Multi-lingual Multi-Word Expression (MWE) Parallel CorporaLifeng Han1, Gareth J.F. Jones1 and Alan F. Smeaton21 ADAPT Research Centre2 Insight Centre for Data AnalyticsSchool of Computing, Dublin City University, Glasnevin, Dublin 9, Irelandlifeng.han@adaptcentre.ie; {gareth.jones, alan.smeaton}@dcu.ieAbstract content1. IntroductionThe use of multi-word expressions (MWEs) has become a hot topic in research in the field of natural language processing (NLP). Topics of interests in MWEs include issues such as MWE detection [Maldonado et al., 2017], MWE decomposition, and the integration of MWEs into other NLP applications such as Machine Translation (MT). However, to support research into the multilingual use of MWEs, the availability of bilingual or multi-lingual MWE corpora is very limited. The only freely available bilingual MWE corpora that we are aware of, at the submission
3. [3]:  Passage ID 3: of this paper.2.1. Machine Translation and Multiword ExpressionsMT methods seek to translate one human language into another one. MT belongs to a branch of computational linguistics (CL) and artificial intelligence (AI), in which researchers try to use computational modeling to address linguistic text translation problems. It is a very challenging task for MT to achieve both accuracy of translated information and fluency at the level of a human expert’s performance or what linguists expect as output. There are many reasons for this, one of which is that the use of MWEs presents a significant obstacle for a machine to learn and generate human languages in a natural form. We use three examples to illustrate the importance of correct use of MWEs in MT.We use ZH/Zh to represent Chinese, and EN/En as English. We use pinyin (pīnyīn) to annotate the Báihuà Chinese for its pronunciation and tones (phoneticism). The MT outputs in the examples were from Google Translator engine [Vaswani
4. [4]:  Passage ID 4: that contain MWEs in English→→\rightarrowLatvian andEnglish→→\rightarrowCzech NMT systems. Two improvement strategies wereexplored—(1) bilingual pairs of automatically extracted MWE candidates wereadded to the parallel corpus used to train the NMT system, and (2) fullsentences containing the automatically extracted MWE candidates were added tothe parallel corpus. Both approaches allowed to increase automated evaluationresults. The best result—0.99 BLEU point increase—has been reached with thefirst approach, while with the second approach minimal improvements achieved. Wealso provide open-source software and tools used for MWE extraction andalignment inspection.1 IntroductionIt is well known that neural machine translation (NMT) has defined the new stateof the art in the last few years (Sennrich et al., 2016a, ; Wu et al.,, 2016), butthe many specific aspects of NMT outputs are not yet explored. One of which istranslation of multi-word units or multi-word expressions
5. [5]:  Passage ID 5: few years (Sennrich et al., 2016a, ; Wu et al.,, 2016), butthe many specific aspects of NMT outputs are not yet explored. One of which istranslation of multi-word units or multi-word expressions (MWEs). MWEs aredefined by Baldwin and Kim, (2010) as “lexical items that: (a) can bedecomposed into multiple lexemes; and (b) display lexical, syntactic, semantic,pragmatic and/or statistical idiomaticity”. MWEs have been a challenge forstatistical machine translation (SMT). Even if standard phrase-based models can copy MWEsverbatim, they suffer in grammaticality. NMT, on the other hand, may struggle in memorizing and reproducing MWEs,because it represents the whole sentence in a high-dimensionalvector, which can lose the specific meanings of the MWEs even in the more fine-grained attention model (Bahdanau et al.,, 2015), because MWEs may not appear frequently enoughin the training data.The goal of this research is to examine how MWEs are treated by NMT systems,compare that with