# Which *BERT? A Survey Organizing Contextualized Encoders

## Question

What are the pros and cons of using input manipulation for probing tasks in contextualized encoders?

## URLs

1. https://ar5iv.org/html/2409.13385. [2409.13385] Contextual Compression in Retrieval-Augmented Generation for Large Language Models: A Survey
2. https://ar5iv.org/html/2005.05683. [2005.05683] On the Robustness of Language Encoders against Grammatical Errors
3. https://ar5iv.org/html/2010.00854. [2010.00854] Which *BERT? A Survey Organizing Contextualized Encoders
4. https://ar5iv.org/html/2406.00053. [2406.00053] Dual Process Learning: Controlling Use of In-Context vs. In-Weights Strategies with Weight Forgetting
5. https://ar5iv.org/html/2304.00740. [2304.00740] Inspecting and Editing Knowledge Representations in Language Models
6. https://ar5iv.org/html/2110.07382. [2110.07382] Transferring Semantic Knowledge Into Language Encoders
7. https://ar5iv.org/html/2306.08193. [2306.08193] Operationalising Representation in Natural Language Processing
8. https://ar5iv.org/html/2411.06284. [2411.06284] A Comprehensive Survey and Guide to Multimodal Large Language Models in Vision-Language Tasks
9. https://ar5iv.org/html/2004.14513. [2004.14513] Asking without Telling: Exploring Latent Ontologies in Contextual Representations
10. https://ar5iv.org/html/2310.17271. [2310.17271] Understanding the Role of Input Token Characters in Language Models: How Does Information Loss Affect Performance?

## Answer (I don't know?: ✗)

Input manipulation is a methodology used in probing tasks within the realm of contextualized encoders in natural language processing (NLP). This approach has distinct advantages and disadvantages worth considering.

**Pros:**

1. **Reduced Influence of Variables**: Input manipulation draws conclusions by restructuring the probing task to resemble the pretraining task, which minimizes the variability introduced by conventional probing methods. This feature makes it more interpretable relative to traditional probing approaches, such as direct input analysis [2]. 

2. **Ability to Investigate Knowledge**: This method allows for the examination of both syntactic and semantic knowledge encoded in models. Researchers have leveraged the cloze task (word prediction) as a key probing objective to uncover insights into model capabilities [2]. 

3. **Flexibility**: The format of probing tasks can be adapted to the needs of various datasets and models. For instance, researchers can either generate new datasets or modify existing ones to serve the input manipulation methodology [2]. This flexibility can lead to nuanced evaluations of model performance across different tasks.

**Cons:**

1. **Dependency on Elicitation Patterns**: One significant drawback of input manipulation, especially in smaller models, is its dependence on the patterns used to prompt responses from the models. The success of eliciting accurate responses heavily relies on how the input is structured, which can lead to variability in results depending on the design of these prompts [2].

2. **Limitations in Small Models**: The method's effectiveness can diminish when applied to smaller models, which might not capture the intended semantics as robustly as larger models. In few-shot scenarios, where only limited examples are used for elicitation, the influence of the specific example patterns becomes even more pronounced, limiting the method's generalizability [2].

3. **Overlap with Diagnostic Classifiers**: While input manipulation can provide clear insights, it may also yield results that overlap with those obtained using diagnostic classifiers, making it somewhat redundant in certain contexts. This realization calls for a more careful consideration of when to employ input manipulation as a probing technique [3].

4. **Challenges in Knowledge Interpretation**: Despite the efforts to clarify what knowledge is encoded in models, probing tasks based on input manipulation may still leave questions unanswered regarding decision-making processes within these models. The complexity of evaluating learned knowledge remains a significant challenge [3].

In summary, input manipulation in probing tasks offers a nuanced and flexible framework for examining contextualized encoders, enhancing our understanding of their knowledge representation. However, its effectiveness can be contingent on the task design and model size, introducing potential limitations that researchers should be aware of when employing this methodology. 

In the context of a rapidly evolving field like NLP, continuous refinement of these probing techniques will further aid in uncovering the intricacies of contextualized encoders [1][4].

1. [1]:  https://ar5iv.org/html/2010.00854, [2010.00854] Which *BERT? A Survey Organizing Contextualized Encoders
2. [2]:  https://ar5iv.org/html/2010.00854, [2010.00854] Which *BERT? A Survey Organizing Contextualized Encoders
3. [3]:  https://ar5iv.org/html/2010.00854, [2010.00854] Which *BERT? A Survey Organizing Contextualized Encoders
4. [4]:  https://ar5iv.org/html/2010.00854, [2010.00854] Which *BERT? A Survey Organizing Contextualized Encoders
5. [5]:  https://ar5iv.org/html/2005.05683, [2005.05683] On the Robustness of Language Encoders against Grammatical Errors
---
1. [1]:  Passage ID 1: We cover background on contextualized encoders, pretraining objectives, efficiency, data, approaches in model interpretability, and research in multilingual systems. As there is now a large selection of models to choose from, we discuss tradeoffs that emerge between models. We hope this work provides some assistance to both those entering the NLP community and those already using contextualized encoders in looking beyond SOTA (and Twitter) to make more educated choices.AcknowledgmentsWe especially thank the (meta-)reviewers for their insightful feedback and criticisms. In addition, we thank Sabrina Mielke, Nathaniel Weir, Huda Khayrallah, Mitchell Gordon, and Shuoyang Ding for discussing several drafts of this work. This work was supported in part by DARPA AIDA (FA8750-18-2-0015) and IARPA BETTER (#2019-19051600005). The views and conclusions contained in this work are those of the authors and should not be interpreted as necessarily representing the official policies, either
2. [2]:  Passage ID 2: (2020).Input manipulation draws conclusions by recasting the probing task format into the form of the pretraining task and observing the model’s predictions. As discussed in §3, word prediction (cloze task) is a popular objective. This method has been used to investigate syntactic and semantic knowledge Goldberg (2019); Ettinger (2020); Kassner and Schütze (2019). For a specific probing task, Warstadt et al. (2019) show that cloze and diagnostic classifiers draw similar conclusions. As input manipulation is not affected by variables introduced by probing tasks and is as interpretable than inspection, we suggest more focus on this method: either by creating new datasets Warstadt et al. (2020) or recasting existing ones Brown et al. (2020) into this format. A disadvantage of this method (especially for smaller models) is the dependence on both the pattern used to elicit an answer from the model and, in the few-shot case where a couple examples are provided first, highly dependent on
3. [3]:  Passage ID 3: it is less clear what knowledge is stored in these models; how do they make decisions?In their survey, Rogers et al. (2020) find answers to the first question and also raise the second. Inspired by prior work Lipton (2018); Belinkov and Glass (2019); Alishahi et al. (2019), we organize here the major probing methods that are applicable to all encoders in hopes that future work will use comparable techniques.6.1 Probing with TasksOne technique uses the learned model as initialization for a model trained on a probing task consisting of a set of targeted natural language examples. The probing task’s format is flexible as additional, (simple) diagnostic classifiers are trained on top of a typically frozen model Ettinger et al. (2016); Hupkes et al. (2018); Poliak et al. (2018); Tenney et al. (2019b).Task probing can also be applied to the embeddings at various layers to explore the knowledge captured at each layer Tenney et al. (2019a); Lin et al. (2019); Liu et al. (2019a). Hewitt
4. [4]:  Passage ID 4: ubiquitous component in most modern NLP models. We strongly encourage more publication and publicizing of negative results and limitations. In addition to their scientific benefits,171717An EMNLP 2020 workshop is motivated by better science (https://insights-workshop.github.io/). publishing negative results in contextualized encoders can avoid significant externalities of rediscovering what doesn’t work: time, money, and electricity. Furthermore, we ask leaderboard owners to periodically publish surveys of their received submissions.The flourishing research in improving encoders is rivaled by research in interpreting them, mainly focused on discovering the boundary of what knowledge is captured by the models. For investigations that aim to sharpen the boundary, it is logical to build off of these prior results. However, we raise a concern that these encoders are all trained on similar data and have similar sizes. Future work in probing should also look across different sizes and
5. [5]:  Passage ID 5: debugging models on downstream applications. Results confirm that the performance of all tested models is affected but the degree of impact varies. To interpret model behaviors, we further design a linguistic acceptability task to reveal their abilities in identifying ungrammatical sentences and the position of errors. We find that fixed contextual encoders with a simple classifier trained on the prediction of sentence correctness are able to locate error positions. We also design a cloze test for BERT and discover that BERT captures the interaction between errors and specific tokens in context. Our results shed light on understanding the robustness and behaviors of language encoders against grammatical errors.1 IntroductionPre-trained language encoders have achieved great success in facilitating various downstream natural language processing (NLP) tasks (Peters et al., 2018; Devlin et al., 2019; Liu et al., 2019b). However, they usually assume training and test corpora are clean