# Which *BERT? A Survey Organizing Contextualized Encoders

## Question

What are the pros and cons of using input manipulation for probing tasks in contextualized encoders?

## URLs

1. https://ar5iv.org/html/2409.13385. [2409.13385] Contextual Compression in Retrieval-Augmented Generation for Large Language Models: A Survey
2. https://ar5iv.org/html/2005.05683. [2005.05683] On the Robustness of Language Encoders against Grammatical Errors
3. https://ar5iv.org/html/2010.00854. [2010.00854] Which *BERT? A Survey Organizing Contextualized Encoders
4. https://ar5iv.org/html/2406.00053. [2406.00053] Dual Process Learning: Controlling Use of In-Context vs. In-Weights Strategies with Weight Forgetting
5. https://ar5iv.org/html/2304.00740. [2304.00740] Inspecting and Editing Knowledge Representations in Language Models
6. https://ar5iv.org/html/2110.07382. [2110.07382] Transferring Semantic Knowledge Into Language Encoders
7. https://ar5iv.org/html/2306.08193. [2306.08193] Operationalising Representation in Natural Language Processing
8. https://ar5iv.org/html/2411.06284. [2411.06284] A Comprehensive Survey and Guide to Multimodal Large Language Models in Vision-Language Tasks
9. https://ar5iv.org/html/2004.14513. [2004.14513] Asking without Telling: Exploring Latent Ontologies in Contextual Representations
10. https://ar5iv.org/html/2310.17271. [2310.17271] Understanding the Role of Input Token Characters in Language Models: How Does Information Loss Affect Performance?

## Answer (I don't know?: âœ—)

Error: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable