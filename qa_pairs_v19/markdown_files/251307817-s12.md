# Rhetorical Structure Approach for Online Deception Detection: A Survey

## Question

What are the main criticisms of the original RST proposal, and how have researchers addressed these issues?

## URLs

1. https://ar5iv.org/html/2404.18307. [2404.18307] Stagnant Lakatosian Research Programmes
2. https://ar5iv.org/html/2409.16559. [2409.16559] Demystifying Issues, Causes and Solutions in LLM Open-Source Projects
3. https://ar5iv.org/html/2410.21554. [2410.21554] Information diffusion assumptions can distort our understanding of social network dynamics
4. https://ar5iv.org/html/2412.04937. [2412.04937] Who Speaks Next? Multi-party AI Discussion Leveraging the Systematics of Turn-taking in Murder Mystery Games
5. https://ar5iv.org/html/2412.04896. [2412.04896] Comprehensive Analysis and Improvements in Pansharpening Using Deep Learning
6. https://ar5iv.org/html/2412.03531. [2412.03531] A Review on Scientific Knowledge Extraction using Large Language Models in Biomedical Sciences
7. https://ar5iv.org/html/2406.00751. [2406.00751] How well do distributed representations convey contextual lexical semantics: a Thesis Proposal
8. https://ar5iv.org/html/2409.05014. [2409.05014] Unraveling Challenges with Supply-Chain Levels for Software Artifacts (SLSA) for Securing the Software Supply Chain
9. https://ar5iv.org/html/2311.17110. [2311.17110] XAI for time-series classification leveraging image highlight methods
10. https://ar5iv.org/html/2401.04122. [2401.04122] From Prompt Engineering to Prompt Science With Human in the Loop

## Answer (I don't know?: ✓)

I don't know. The context provided does not include any information about the original RST (Rhetorical Structure Theory) proposal or criticisms specific to it. It focuses instead on the evaluation of current PLMs and LLMs, issues related to LLM open-source projects, and related studies. There are no references to RST or discussions about how researchers have addressed criticisms of it.

1. [1]:  https://ar5iv.org/html/2406.00751, [2406.00751] How well do distributed representations convey contextual lexical semantics: a Thesis Proposal
2. [2]:  https://ar5iv.org/html/2409.16559, [2409.16559] Demystifying Issues, Causes and Solutions in LLM Open-Source Projects
3. [3]:  https://ar5iv.org/html/2409.16559, [2409.16559] Demystifying Issues, Causes and Solutions in LLM Open-Source Projects
4. [4]:  https://ar5iv.org/html/2409.16559, [2409.16559] Demystifying Issues, Causes and Solutions in LLM Open-Source Projects
5. [5]:  https://ar5iv.org/html/2409.16559, [2409.16559] Demystifying Issues, Causes and Solutions in LLM Open-Source Projects
---
1. [1]:  Passage ID 1: as humans, given their impressive linguistic performance? If not, to what extent do they fall short? Answering these questions is significant for both the computational and linguistic communities. For computational researchers, these insights could enhance the transparency and reliability of black-box models. For linguists, they could aid in constructing meaning systems and discovering novel meanings.Our thesis addresses these research questions by evaluating current PLMs and LLMs on various lexical meaning tasks with differing levels of granularity. We also incorporate a cross-lingual perspective, designing benchmarks for multiple languages. Additionally, we test our hypotheses by integrating theories and models from both computational and linguistic fields.Thesis ProposalIn the thesis, we initially identify various sources of ambiguity pertaining to contextual lexical meaning (refer to Section 2.1). Subsequently, we gather datasets and devise experiments to assess each
2. [2]:  Passage ID 2: have a basic understanding of text processing techniques like tokenization, stemming, and lemmatization, stop word removal. For example, a contributor reported that “–no-stream is very slow, because it ignores the stop words filled into stopping_criteria”, which indicates that operational efficiency of LLM open-source software can be enhanced after the removal of stop words (text-generation-webui #805).(3) Practitioners need to have a basic understanding of deep learning frameworks that LLMs (e.g., GPT4) are based on. Acquiring knowledge of deep learning frameworks can facilitate the fine-tuning and inference functionalities of LLMs. For example, a contributor received a message that “RuntimeError: PyTorch is not linked with support for mps devices1”, which indicates that practitioners need a basic understanding of PyTorch to deploy the software (FastChat #854).Implication 2. Practitioners should use more efficient parameter fine-tuning methods and design more robust parameter
3. [3]:  Passage ID 3: empirical studies on specific types of open-source projects. However, existing studies did not focus on investigating the issues faced by LLM open-source software from the perspective of practitioners (i.e., developers and users), nor did they explore the underlying causes of these issues and their solutions.Lin et al. (2024) had studied the issues within ChatGPT-related projects, which is a specific and popular commercial LLM, and they utilized the LDA topic modeling, which is an automatic method, to explore the topics of the issues discussed in 200 ChatGPT-related projects, but they did not explore the causes and solutions of these issues. Our study, grounded in the perspective of practitioners, aims to explore the issues within LLM open-source projects, their underlying causes, and potential solutions. We employed a manual qualitative approach to extract and analyze the data collected in the study. To ensure the representativeness of our research results, we collected projects from
4. [4]:  Passage ID 4: solutions. We employed a manual qualitative approach to extract and analyze the data collected in the study. To ensure the representativeness of our research results, we collected projects from GitHub, the largest open-source project hosting platform in the world.Ultimately, Lin et al. (2024) provided a one-tier classification of issues, comprising a total of ten categories, with the top ten keywords for each category identified by the automatic method. However, our taxonomy offers a two-tier classification of issues, comprising a total of 15 categories with corresponding types under each category. We found that only the issue category Model Reply in the issue taxonomy identified by Lin et al. (2024) is similar to the issue category Answer Issue in our classification. The other categories in their issue taxonomy are quite different from our results.7 ConclusionsIn this study, we focused on the issues that practitioners encounter when developing and using LLM open-source
5. [5]:  Passage ID 5: language models for software engineering: A systematic literature review.arXiv preprint abs/2308.10620 .Humbatova et al. (2020)Humbatova, N., Jahangirova, G., Bavota, G., Riccio, V., Stocco, A., Tonella, P., 2020.Taxonomy of real faults in deep learning systems, in: Proceedings of the 42nd International Conference on Software Engineering (ICSE), ACM. pp. 1110–1121.Israel (1992)Israel, G.D., 1992.Determining Sample Size.Fact Sheet PEOD-6. Florida, USA.Lin et al. (2024)Lin, Z., Zhang, N., Liu, C., Zheng, Z., 2024.An empirical study of chatgpt-related projects and their issues on github.arXiv preprint abs/2403.17437 .Liu et al. (2023)Liu, Y., Deng, G., Li, Y., Wang, K., Wang, Z., Wang, X., Zhang, T., Liu, Y., Wang, H., Zheng, Y., et al., 2023.Prompt injection attack against llm-integrated applications.arXiv preprint abs/2306.05499 .Malavolta et al. (2021)Malavolta, I., Lewis, G.A., Schmerl, B., Lago, P., Garlan, D., 2021.Mining