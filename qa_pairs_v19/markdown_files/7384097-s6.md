# A Survey of Word Reordering in Statistical Machine Translation: Computational Models and Language Phenomena

## Question

How is reordering managed in n-gram based Statistical Machine Translation (SMT), and what are the limitations of this approach?

## URLs

1. https://ar5iv.org/html/1502.04938. [1502.04938] A Survey of Word Reordering in Statistical Machine Translation: Computational Models and Language Phenomena
2. https://ar5iv.org/html/1809.01272. [1809.01272] Unsupervised Statistical Machine Translation
3. https://ar5iv.org/html/2109.15119. [2109.15119] Improved Statistical Machine Translation Using Monolingual Paraphrases
4. https://ar5iv.org/html/1605.04515. [1605.04515] Machine Translation Evaluation Resources and Methods: A Survey
5. https://ar5iv.org/html/2212.00138. [2212.00138] Word Alignment in the Era of Deep Learning: A Tutorial
6. https://ar5iv.org/html/1902.01313. [1902.01313] An Effective Approach to Unsupervised Machine Translation
7. https://ar5iv.org/html/1709.07809. [1709.07809] Statistical Machine Translation Draft of Chapter 13: Neural Machine Translation .
8. https://ar5iv.org/html/2011.02821. [2011.02821] Data Augmentation and Terminology Integration for Domain-Specific Sinhala-English-Tamil Statistical Machine Translation

## Answer (I don't know?: ✓)

I don't know. The context provided does not contain specific information about how reordering is managed in n-gram based Statistical Machine Translation (SMT) or the limitations of this approach. While it discusses word reordering as a statistical modeling challenge and the importance of understanding reordering phenomena across different language pairs, it does not explicitly address the mechanisms or limitations of n-gram based SMT related to reordering. The passages focus more on the broader context of word reordering in SMT, general approaches, and qualitative analyses without detailing specific methods like n-gram models.

1. [1]:  https://ar5iv.org/html/1502.04938, [1502.04938] A Survey of Word Reordering in Statistical Machine Translation: Computational Models and Language Phenomena
2. [2]:  https://ar5iv.org/html/1502.04938, [1502.04938] A Survey of Word Reordering in Statistical Machine Translation: Computational Models and Language Phenomena
3. [3]:  https://ar5iv.org/html/1502.04938, [1502.04938] A Survey of Word Reordering in Statistical Machine Translation: Computational Models and Language Phenomena
4. [4]:  https://ar5iv.org/html/1502.04938, [1502.04938] A Survey of Word Reordering in Statistical Machine Translation: Computational Models and Language Phenomena
5. [5]:  https://ar5iv.org/html/1502.04938, [1502.04938] A Survey of Word Reordering in Statistical Machine Translation: Computational Models and Language Phenomena
---
1. [1]:  Passage ID 1: and efficiency.Despite the vast amount of research published to date, the interest of the community in this problem has not decreased,and no single method appears to be strongly dominant across language pairs.Instead, the choice of the optimal approach for a new translation task still seems to be mostly driven by empirical trials.To orientate the reader in this vast and complex research area,we present a comprehensive survey of word reordering viewedas a statistical modeling challenge and as a natural language phenomenon.The survey describes in detail how word reordering is modeled within different string-based and tree-based SMT frameworksand as a stand-alone task, including systematic overviews of the literature in advanced reordering modeling.We then question why some approaches are more successful than others in different language pairs.We argue that, besides measuring the amount of reordering, it is important to understand which kinds of reordering occur in a given
2. [2]:  Passage ID 2: are more successful than others in different language pairs.We argue that, besides measuring the amount of reordering, it is important to understand which kinds of reordering occur in a given language pair.To this end, we conduct a qualitative analysis of word reordering phenomena in a diverse sample of language pairs, based on a large collection of linguistic knowledge.Empirical results in the SMT literature are shown to supportthe hypothesis that a few linguistic facts can be very useful to anticipate the reordering characteristicsof a language pair and to select the SMT framework that best suits them.1 IntroductionStatistical machine translation (SMT) is a data-driven approach to the translation of text from a natural language into another.Emerged in the 1990s and matured in the 2000’s to become widespread today,the core SMT methods [\citenameBrown et al.1990, \citenameBrown et al.1993, \citenameBerger et al.1996, \citenameKoehn, Och, and Marcu2003]learn direct
3. [3]:  Passage ID 3: detect the best permutation among them?Existing solutions to these problems range from heuristic constraints, based on word-to-word distances and completely agnostic about the sentence content, to linguistically motivated SMT frameworks where the entire translation process is guided by syntactic structure.The research in word reordering has advanced together with the core SMT research and has sometimes directed it,being one of the main motivation for the development of tree-based SMT. At the same time, the variety of word orders existing in the world languageshas pressed the SMT community to admit the importance of language-specific knowledgeand to reassess its ambitions towards a universal translation algorithm.According to the Machine Translation Archive,a scientific interest in this specific subproblem of MT started around 2006 and kept growing at a rapid pace.In 2014, the research papers mainly dedicated to reordering accounted for no less than 10% of all SMT
4. [4]:  Passage ID 4: interest in this specific subproblem of MT started around 2006 and kept growing at a rapid pace.In 2014, the research papers mainly dedicated to reordering accounted for no less than 10% of all SMT papers.222Peer-reviewed conferences, workshops and journal papers listed by the Machine Translation Archive: http://www.mt-archive.info/srch/subjects.htmDespite the abundant research, word order differences remain among the most important factors of performance in modern SMT systems, and new approaches to reordering are still proposed every year.To orientate the reader in this complex and productive research area,we present a comprehensive survey of word reordering viewedas a statistical modeling challenge and as a natural language phenomenon.Our survey notably differs from previous [\citenameCosta-jussà and Fonollosa2009] in that we do not only review the existing approaches to word reordering in SMT, but we also question why some approaches are more successful than others in
5. [5]:  Passage ID 5: in SMT outputs.Section 4 presents a qualitative analysis of word reordering across language pairs.In particular, detailed word order profiles are provided for a sample of seven widely spoken languagesrepresenting structural and geographical diversity:namely English, German, French, Arabic, Turkish, Japanese and Chinese.The same section reviews empirical results from the SMT literature showing that the proposed word order profilesare useful to anticipate the reordering characteristics of a language pair and to select the SMT framework that best suits them.The survey ends with a discussion of the strengths and weaknesses of the major approaches to reordering in SMT.2 Approaches to Word Reordering in Statistical Machine TranslationA first important distinction has to be made between word reordering performed as part of the decoding process (Sections 2.1 to 2.3)and word reordering performed before or after it as a monolingual task decoupled from the bilingual translation