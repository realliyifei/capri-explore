# The Mystery and Fascination of LLMs: A Comprehensive Survey on the Interpretation and Analysis of Emergent Abilities

## Question

How does the frequency of terms in pre-training data influence numerical reasoning performance in few-shot settings?

## URLs

1. https://ar5iv.org/html/2202.07206
2. https://ar5iv.org/html/2411.12580
3. https://ar5iv.org/html/2307.02477
4. https://ar5iv.org/html/2404.04125
5. https://ar5iv.org/html/2311.12337
6. https://ar5iv.org/html/2304.01665
7. https://ar5iv.org/html/2402.14903
8. https://ar5iv.org/html/2407.14985

## Answer

## I don't know?: False

The frequency of terms in pre-training data significantly influences the performance of language models (LMs) on few-shot numerical reasoning tasks. In the study conducted by Razeghi et al. (2022), it was found that the extrapolation abilities of pretrained LMs, particularly in few-shot settings, are closely correlated with the frequency of the terms in the pre-training datasets [1]. When terms that are less frequent in the training data appear in reasoning tasks, the model's performance can degrade, indicating that familiarity with a term enhances the model's capability to reason with it [1] [3].

The authors highlight that controlled experiments by Kassner et al. (2020) and Wei et al. (2021) confirmed the pivotal role of term frequency in memory and reasoning capabilities of LMs. These studies suggest that the likelihood of a model memorizing a certain fact or a syntactic rule is largely determined by how often those terms occur in the pre-training data [3]. This finding aligns with the broader understanding that LMs primarily rely on the distribution of terms learned during pretraining for new tasks, including numerical reasoning tasks such as arithmetic and unit conversions [1] [4].

Furthermore, the reference to Brown et al. (2020) demonstrates that evaluations of few-shot learning in LMs should consider the overlap between training and test datasets. The authors argue that merely removing instances from evaluation datasets that share n-gram overlaps with pretraining data is insufficient, as the precise occurrences of exact phrases also affect accuracy in reasoning tasks [4]. This insight implies that decreased term frequency not only inhibits performance but also complicates the ability of models to perform well on numerical reasoning tasks when confronted with unfamiliar or infrequent terms.

Overall, the implication is clear: enhancing the frequency of relevant terms in pre-training data can yield better numerical reasoning performance in LMs, particularly in scenarios where the models must infer or perform reasoning based on limited examples [1] [2] [3]. Therefore, for future developments in training LMs, a focus on ensuring a broad and representative frequency of terms related to numerical reasoning tasks may provide more robust performance in few-shot learning scenarios.

1. [1]:  https://ar5iv.org/html/2202.07206, [2202.07206] Impact of Pretraining Term Frequencies on Few-Shot Reasoning
2. [2]:  https://ar5iv.org/html/2411.12580, [2411.12580] Procedural Knowledge in Pretraining Drives Reasoning in Large Language Models
3. [3]:  https://ar5iv.org/html/2202.07206, [2202.07206] Impact of Pretraining Term Frequencies on Few-Shot Reasoning
4. [4]:  https://ar5iv.org/html/2202.07206, [2202.07206] Impact of Pretraining Term Frequencies on Few-Shot Reasoning
5. [5]:  https://ar5iv.org/html/2404.04125, [2404.04125] No “Zero-Shot” Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance
---
1. [1]:  Passage ID 1: } else { localStorage.setItem("ar5iv_theme", "light"); } } else { localStorage.setItem("ar5iv_theme", "dark"); } detectColorScheme(); }Impact of Pretraining Term Frequencies on Few-Shot ReasoningYasaman Razeghi  Robert L. Logan IV  Matt Gardner  Sameer SinghAbstractPretrained Language Models (LMs) have demonstrated ability to perform numerical reasoning by extrapolating from a few examples in few-shot settings.However, the extent to which this extrapolation relies on robust reasoning is unclear.In this paper, we investigate how well these models reason with terms that are less frequent in the pretraining data.In particular, we examine the correlations between the model performance on test instances and the frequency of terms from those instances in the pretraining data.We measure the strength of this correlationfor a number of GPT-based language models (pretrained on the Pile dataset) on various numerical deduction tasks (e.g., arithmetic and unit
2. [2]:  Passage ID 2: Logan IV, Matt Gardner, and Sameer Singh.Impact of pretraining term frequencies on few-shot numerical reasoning.In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang (eds.), Findings of the Association for Computational Linguistics: EMNLP 2022, pp.  840–854, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics.doi: 10.18653/v1/2022.findings-emnlp.59.URL https://aclanthology.org/2022.findings-emnlp.59.Singh et al. (2024)Aaditya K Singh, Ted Moskovitz, Felix Hill, Stephanie C.Y. Chan, and Andrew M Saxe.What needs to go right for an induction head? a mechanistic study of in-context learning circuits and their formation.In Forty-first International Conference on Machine Learning, 2024.URL https://openreview.net/forum?id=O8rrXl71D5.Templeton et al. (2024)Adly Templeton, Tom Conerly, Jonathan Marcus, Jack Lindsey, Trenton Bricken, Brian Chen, Adam Pearce, Craig Citro, Emmanuel Ameisen, Andy Jones, Hoagy Cunningham,
3. [3]:  Passage ID 3: 2019; Weir et al., 2020; Lin et al., 2020), mathematical (Saxton et al., 2019), and other NLP task-related (Radford et al., 2019; Shin et al., 2020) knowledge LMs acquire during pretraining.In this work, we focus on the in-context learning setup of Brown et al. (2020), who use prompts that include training examples to diagnose LMs’ few-shot learning capabilities.Impact of Frequency on LM PerformanceKassner et al. (2020) and Wei et al. (2021) perform controlled experiments varying pretraining data to characterize the extent pretraining affects LMs’ ability to learn to memorize and reason with facts as well as learn generalizable syntax rules.In line with our results, both of these works find that frequency is a distinguishing factor in whether or not the model memorizes a particular fact or syntactic rule for a verb form.Sinha et al. (2021) further demonstrate that shuffling word order during pretraining has minimal impact on an LMs’ accuracy on downstream tasks, and,
4. [4]:  Passage ID 4: models (Spithourakis & Riedel, 2018; Wallace et al., 2019).Recently, Geva et al. (2020) and Zhou et al. (2020) have proposed training schemes to help improve LMs’ temporal and numerical reasoning capabilities.Patel et al. (2021) also showed that NLP math solvers rely on simple heuristics to answer math questions.We expect that the performance gap metric proposed in this work will be useful to better understand the impact of such schemes.6 Discussion and Future WorkIn this work, we consider how to conduct few-shot evaluations in light of the analysis with respect to the pretraining data. Prior work has attempted to control for overlap between training or pretraining data and the test instances, but as we have seen, those methods are insufficient. For example, Brown et al. (2020) measure the impact of removing instances from evaluation datasets that share 13-gram overlap with their pretraining data on GPT-3’s accuracy, and also argue that the low occurrence of exact phrases
5. [5]:  Passage ID 5: on Machine Learning (ICML), 2021.Razeghi et al. [2022a]Yasaman Razeghi, Robert L Logan IV, Matt Gardner, and Sameer Singh.Impact of pretraining term frequencies on few-shot numerical reasoning.In Findings of the Association for Computational Linguistics: EMNLP 2022, pages 840–854, 2022a.Razeghi et al. [2022b]Yasaman Razeghi, Raja Sekhar Reddy Mekala, Robert L Logan Iv, Matt Gardner, and Sameer Singh.Snoopy: An online interface for exploring the effect of pretraining term frequencies on few-shot lm performance.In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 389–395, 2022b.Rombach et al. [2022]Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer.High-resolution image synthesis with latent diffusion models.In Conference on Computer Vision and Pattern Recognition (CVPR), 2022.Saehoon et al. [2021]Kim Saehoon, Cho Sanghun, Kim Chiheon, Doyup Lee,