# Survey of Low-Resource Machine Translation

## Question

How are transliteration and alphabet mapping utilized in machine translation for languages with different scripts?

## URLs

1. https://ar5iv.org/html/2205.09578. [2205.09578] A machine transliteration tool between Uzbek alphabets
2. https://ar5iv.org/html/2402.16065. [2402.16065] Training a Bilingual Language Model by Mapping Tokens onto a Shared Character Space
3. https://ar5iv.org/html/2306.12693. [2306.12693] Multilingual Neural Machine Translation System for Indic to Indic Languages
4. https://ar5iv.org/html/2110.07804. [2110.07804] Alternative Input Signals Ease Transfer in Multilingual Machine Translation
5. https://ar5iv.org/html/2101.05162. [2101.05162] Uzbek Cyrillic-Latin-Cyrillic Machine Transliteration
6. https://ar5iv.org/html/2410.08974. [2410.08974] UniGlyph: A Seven-Segment Script for Universal Language Representation
7. https://ar5iv.org/html/2412.03877. [2412.03877] AyutthayaAlpha: A Thai-Latin Script Transliteration Transformer
8. https://ar5iv.org/html/2202.00794. [2202.00794] Learning to pronounce as measuring cross-lingual joint orthography-phonology complexity
9. https://ar5iv.org/html/2109.00486. [2109.00486] Survey of Low-Resource Machine Translation
10. https://ar5iv.org/html/2008.01391. [2008.01391] A Survey of Orthographic Information in Machine Translation

## Answer (I don't know?: ✗)

Transliteration and alphabet mapping are significant techniques in machine translation (MT), especially for languages utilizing different scripts. These methods facilitate the conversion of written text from one script to another, enabling better translation performance and accessibility.

Transliteration is the process of converting words from one alphabet to another. It plays an essential role in handling languages that use different writing systems, such as Hindi and Urdu, which utilize Devanagari and Perso-Arabic scripts, respectively. Bhat et al. (2016) developed machine transliteration models that allow for translation in both directions between these scripts, demonstrating improved performance by using a dependency parser trained on augmented resources, leading to reduced data sparsity [5]. This approach highlights how transliteration can bridge the gap between different orthographic systems to enhance communication and comprehension.

In addition to cross-language transliteration, there are intra-language transliteration efforts that convert words from one script to another within the same language. This aspect has been explored in early works, where methods were applied to Arabic-English and Japanese-English names transliteration, incorporating rule-based systems with neural networks [4]. Such transliteration efforts help maintain phonetic integrity while accommodating the syntactic structures of different languages.

Moreover, recent advancements have integrated deep-learning techniques, such as long short-term memory (LSTM) networks and recurrent neural networks (RNN), to improve transliteration accuracy. Studies show that combining traditional rule-based approaches with modern deep-learning methods enhances the transliteration quality significantly [4]. For example, combining older techniques with LSTMs has proven to be effective in achieving better performance in transliteration tasks.

Alphabet mapping is also crucial, particularly in the context of translating technical terms and acronyms, which often present challenges for MT systems. For instance, some systems struggle with acronyms, leading to significant translation inaccuracies—up to 50% in cases analyzed in the research [3]. By offering a new acronym corpus and innovating within the MT workflow, researchers focus on refining these aspects, further emphasizing the importance of careful script handling.

Additionally, the exploration of orthographic similarity has been mentioned in the context of transliteration for related languages with similar writing systems and phonetic properties, such as Indo-Aryan languages. Kunchukuttan et al. (2018b) highlight that leveraging multilingual transliteration can outperform traditional bilingual models by capitalizing on shared orthographic traits [5].

Ultimately, transliteration and alphabet mapping enhance the capabilities of machine translation systems by allowing for improved accuracy and understanding across diverse linguistic landscapes, facilitating greater access to information for speakers of different languages. These methods collectively bolster the framework of natural language processing by addressing the complexities associated with multilingual settings.

1. [1]:  https://ar5iv.org/html/2008.01391, [2008.01391] A Survey of Orthographic Information in Machine Translation
2. [2]:  https://ar5iv.org/html/2110.07804, [2110.07804] Alternative Input Signals Ease Transfer in Multilingual Machine Translation
3. [3]:  https://ar5iv.org/html/2409.17943, No Title
4. [4]:  https://ar5iv.org/html/2205.09578, [2205.09578] A machine transliteration tool between Uzbek alphabets
5. [5]:  https://ar5iv.org/html/2008.01391, [2008.01391] A Survey of Orthographic Information in Machine Translation
---
1. [1]:  Passage ID 1: orthographic information, focusing on multilingual settings and bilingual lexicon induction.Keywords: Orthography, Under-resourced languages, Machine translation, Rule-based machine translation, Statistical machine translation, Neural machine translation††journal: Machine Translation Journal1 IntroductionNatural Language Processing (NLP) plays a significant role in keeping languages alive and the development of languages in the digital device era (Karakanta et al., 2018). One of the sub-parts of NLP is Machine Translation (MT). MT has been the most promising application of Artificial Intelligence (AI) since the invention of computers, which has has been shown to increase access to information by the native language of the speakers in many cases. One of the such critical case is the spread of vital information during a crisis or emergency (Lewis et al., 2011; Neubig and Hu, 2018). Recently, translation accuracy has increased, and commercial systems have gained popularity.
2. [2]:  Passage ID 2: for translation system. Nakov and Ng (2009) use transliteration as a preprocessing step for their phrase-based SMT model to tackle systematic spelling variation. Both  Chakravarthi et al. (2019) and  Koneru et al. (2021) convert Dravidian languages to Latin script and train multilingual models with both source and target in Latin script; the latter identify code-switching to be a challenge during back-transliteration. Besides converting to Latin script,  Dabre et al. (2018) use another common script, Devanagari, for Indic languages.In addition to the natural written scripts, previous works also explored artificial script, such as IPA.  Liu et al. (2019) incorporate phonetic representations, specifically for Chinese Pinyin, to cope with homophone noise. Unlike our work,  Chakravarthi et al. (2019) adopt transliteration to IPA for both the source and target.Apart from transliterated input, other potential alternative signals we did not fully explored include orthographic syllable
3. [3]:  Passage ID 3: language processing (NLP) do – predict the next word in a series of words. While high-resource languages like English and French are reported to achieve near human parity using common metrics for measurement such as BLEU and COMET, we find that an important step is being missed: the translation of technical terms, specifically acronyms. Some state-of-the art machine translation systems like Google Translate which are publicly available can be erroneous when dealing with acronyms – as much as 50% in our findings. This article addresses acronym disambiguation for MT systems by proposing an additional step to the SL–TL (FR–EN) translation workflow where we first offer a new acronym corpus for public consumption and then experiment with a search-based thresholding algorithm that achieves nearly 10% increase when compared to Google Translate and OpusMT.1 IntroductionWith the myriad of artificial intelligence tools available for professional translators, it can be hard for translators
4. [4]:  Passage ID 4: alphabet of another language, as part of machine translation [1]. Later on, it also has been used for similar purposes, but with intra-language perspective, describing it as a conversion of words from one written script to another one within the same language [2, 4].Instances of early works on transliteration can be Arabic-English names transliteration using a combination of a rule-based system with neural networks [1], and Japanese-English using finite state transducers [5]. Both approaches dealt with phonetic representations of words, which were replaced by a spelling-based approach to achieve higher results, as in the case of the Arabic-English model of [6].Later modern approaches to transliteration include models with long short-term memories (LSTM) [4], and recurrent neural networks (RNN) [7], which perform equally well. Combination of old rule-based approaches with recent deep-learning methods improves the quality, according to a comparative study [8].Transliteration
5. [5]:  Passage ID 5: To remove the script barrier, Bhat et al. (2016) created machine transliteration models for the common orthographic representation of Hindi and Urdu text. The authors have transliterated text in both directions between Devanagari script (used to write the Hindi language) and Perso-Arabic script (used to write the Urdu language). The authors have demonstrated that a dependency parser trained on augmented resources performs better than individual resources. The authors have shown that there was a significant improvement in BLEU (Bilingual Evaluation Understudy) (Papineni et al., 2002) score and have shown that the problem of data sparsity is reduced.Recent work by Kunchukuttan et al. (2018b) has explored orthographic similarity for transliteration. In their work, they have used related languages which share similar writing systems and phonetic properties such as Indo-Aryan languages. They have shown that multilingual transliteration leveraging similar orthography outperforms bilingual