# Modeling Language Variation and Universals: A Survey on Typological Linguistics for Natural Language Processing

## Question

How can morphosyntactic annotation be effectively projected to resource-lean languages, and what techniques are employed for feature prediction?

## URLs

1. https://ar5iv.org/html/2406.05424. [2406.05424] Recent advancements in computational morphology : A comprehensive survey
2. https://ar5iv.org/html/2403.06399. [2403.06399] GlossLM: Multilingual Pretraining for Low-Resource Interlinear Glossing
3. https://ar5iv.org/html/2401.16078. [2401.16078] Understanding the effects of word-level linguistic annotations in under-resourced neural machine translation
4. https://ar5iv.org/html/2105.14214. [2105.14214] Predictive Representation Learning for Language Modeling
5. https://ar5iv.org/html/2404.05839. [2404.05839] ÚFAL LatinPipe at EvaLatin 2024: Morphosyntactic Analysis of Latin
6. https://ar5iv.org/html/2302.00407. [2302.00407] On the Role of Morphological Information for Contextual Lemmatization
7. https://ar5iv.org/html/2402.17608. [2402.17608] Linguistic Knowledge Can Enhance Encoder-Decoder Models (If You Let It)
8. https://ar5iv.org/html/2405.05966. [2405.05966] Natural Language Processing RELIES on Linguistics
9. https://ar5iv.org/html/2403.04507. [2403.04507] NLPre: a revised approach towards language-centric benchmarking of Natural Language Preprocessing systems

## Answer (I don't know?: ✗)

The effective projection of morphosyntactic annotation to resource-lean languages can leverage techniques such as annotation projection, as indicated in the context. This method involves the application of an unsupervised word alignment system on translations and then projecting annotated models from resource-rich languages onto low-resource languages. While this approach allows for the creation of models for various NLP tasks, it is important to note that the resulting projected annotations can be flawed due to errors in the projection process and the inherent differences in how languages convey meaning and features [1].

To address these errors, additional techniques can be employed. For instance, Hwa et al. (2005) utilized annotation projection for parsing tasks by first projecting syntactic trees from English onto Spanish and Chinese. They observed significant deficiencies in the projected trees and therefore implemented post-projection transformations, leveraging linguistic knowledge about the target languages to enhance the quality of the projections [1]. This indicates the value of combining automatic projection with linguistic expertise to improve the accuracy and relevance of the annotations.

Moreover, the projection process is particularly relevant in the context of various NLP tasks, encompassing not only parsing but also other tasks such as entity recognition (ER) and relation extraction. These tasks often require structured, annotated datasets to function effectively. For example, in ER, the task is to label sequences of words, which necessitates accurate supervised learning from annotated data. The challenges surrounding obtaining adequately annotated datasets in resource-lean settings can thus sometimes be mitigated through strategic projection techniques [3][5].

In addition to annotation projection, the context also hints at the importance of using specialized data for fine-tuning models. For instance, training models like BERT on carefully curated but smaller corpora has demonstrated that focusing on quality and specificity of data can yield superior performance, especially for domain-specific tasks [5]. This implies that morphosyntactic features, when annotated and projected effectively, can enrich models trained on smaller, focused datasets.

Furthermore, it is crucial to consider the empirical nature of NLP research as outlined in the context. This requires a robust understanding of linguistic principles and methodologies to ensure that the data and resources employed in annotation are reflective of the target languages’ characteristics [2]. Thus, projects aimed at morphosyntactic annotation projection must balance the need for structural representation with the nuances of linguistic variance across different languages.

In summary, effectively projecting morphosyntactic annotation to resource-lean languages can be achieved through annotation projection techniques that incorporate both algorithmic alignment processes and linguistic transformations. Employing these methods selectively, alongside high-quality data curation for fine-tuning, can significantly enhance feature prediction in NLP tasks related to less-resourced languages [1][2][5].

1. [1]:  https://ar5iv.org/html/2212.00138, No Title
2. [2]:  https://ar5iv.org/html/2405.05966, [2405.05966] Natural Language Processing RELIES on Linguistics
3. [3]:  https://ar5iv.org/html/2407.03895, No Title
4. [4]:  https://ar5iv.org/html/2407.03895, No Title
5. [5]:  https://ar5iv.org/html/2411.05503, No Title
---
1. [1]:  Passage ID 1: running a unsupervised word alignment system over these translations, we can use annotation projection to create models for any NLP task in the low-resource language. The projected annotations are imperfect, of course, given both a) errors in the projection processes, such as incorrect word alignments, and b) differences in how languages represent (or do not represent) meaning and features. But the technique remains a reasonable, effective start for addressing various tasks and domains in low-resource languages or domains.7.1.1 Annotation Projection for NLP TasksHwa et al. (2005) apply annotation projection to parsing, the task of predicting a tree relating the words of a sentence. They first directly project English trees to Spanish and Chinese, finding the projected trees are quite lacking. They then perform post-projection transformation of these trees based on linguistic knowledge of the target languages. Finally, they train target language syntactic parsers on these
2. [2]:  Passage ID 2: contemporary NLP as well as their relationship. In the sections that follow, we tackle each of the six facets of NLP research which make up the mnemonic “RELIES,” for which we argue that linguistics has enduring relevance.3 ResourcesThe field of NLP is committed to an empirical methodology wherein machine learning models are trained and evaluated on language data. This paradigm requires linguistic expertise on several fronts. Resources are supported by various degrees of linguistic knowledge—ranging from proficiency in a language to formal training in linguistics.Creation of resources for general NLP tasks.By “general NLP tasks” we mean tasks that closely relate to applications in widespread demand, such as machine translation (MT), entity linking, and sentiment classification. Studying these tasks in an empirical way requires corpus resources. Even if we can do without some of these resources in the training of NLP systems, they remain relevant for testing and studying
3. [3]:  Passage ID 3: years showed significant advancements [98, 7, 19] in natural language processing (NLP): Large language models (LLMs) emerged [8], facilitating new methodologies by describing tasks in natural language without a strong formalism. Because resource-intensive LLMs are not always superior [112], smaller, supervised learning-based models are still highly relevant for specialized domains or use cases that require rapid inference or are constrained by hardware limitations (such as mobile devices or offline scenarios) [34].One of these domains is entity recognition [73]. Entity recognition  (ER) describes the task of assigning a label to a sequence of words (e.g. to extract a person, a date or any other predefined label). To apply supervised learning to ER, data must be annotated. The manual annotation process, in which humans annotate data points with these predefined labels, is time-intensive and expensive [106]. Its output is an annotated dataset, which is also called corpus (pl. corpora)
4. [4]:  Passage ID 4: years showed significant advancements [98, 7, 19] in natural language processing (NLP): Large language models (LLMs) emerged [8], facilitating new methodologies by describing tasks in natural language without a strong formalism. Because resource-intensive LLMs are not always superior [112], smaller, supervised learning-based models are still highly relevant for specialized domains or use cases that require rapid inference or are constrained by hardware limitations (such as mobile devices or offline scenarios) [34].One of these domains is entity recognition [73]. Entity recognition  (ER) describes the task of assigning a label to a sequence of words (e.g. to extract a person, a date or any other predefined label). To apply supervised learning to ER, data must be annotated. The manual annotation process, in which humans annotate data points with these predefined labels, is time-intensive and expensive [106]. Its output is an annotated dataset, which is also called corpus (pl. corpora)
5. [5]:  Passage ID 5: general NLP models in domain-specific tasks like named entity recognition, relation extraction, and others [56, 76]. This demonstrated the importance of specialized data and triggered a trend in fine-tuning models on annotated, domain-specific datasets.A more recent study [77] showed that training BERT [16] on the British National Corpus [12] (i.e., a carefully curated yet much smaller text collection than that used to train the original model) achieved even better performance than the original BERT model.Thus, even in the age of powerful neural models, the quality and specificity of data remain critical factors in achieving high-performance NLP systems. Moreover, without datasets for training and validation, the field of Kyrgyz NLP simply cannot advance.2.2 Processing Methods for Less-Resourced LanguagesAddressing the challenges faced by LRLs requires innovative approaches that compensate for the lack of resources. Several common methods have been employed to process LRLs