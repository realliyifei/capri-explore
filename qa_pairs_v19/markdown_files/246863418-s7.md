# A Survey on Dynamic Neural Networks for Natural Language Processing

## Question

How are confidence-based early exit strategies implemented in BERT inference models?

## URLs

1. https://ar5iv.org/html/2107.00175. [2107.00175] ELBERT: FAST ALBERT WITH CONFIDENCE-WINDOW BASED EARLY EXIT
2. https://ar5iv.org/html/2402.05948. [2402.05948] DE3-BERT: Distance-Enhanced Early Exiting for BERT based on Prototypical Networks
3. https://ar5iv.org/html/2312.11882. [2312.11882] ConsistentEE: A Consistent and Hardness-Guided Early Exiting Method for Accelerating Language Models Inference
4. https://ar5iv.org/html/2405.15039. [2405.15039] CeeBERT: Cross-Domain Inference in Early Exit BERT
5. https://ar5iv.org/html/2006.04152. [2006.04152] BERT Loses Patience: Fast and Robust Inference with Early Exit
6. https://ar5iv.org/html/2204.06328. [2204.06328] HuBERT-EE: Early Exiting HuBERT for Efficient Speech Recognition

## Answer (I don't know?: ✗)

Confidence-based early exit strategies in BERT inference models are designed to accelerate the inference process by dynamically deciding when to stop processing based on the confidence level of predictions. These strategies utilize metrics such as entropy or the label score of the prediction probability distribution to evaluate the correctness of early predictions, fundamentally supporting the decision-making process for exiting [1] [2].

The implementation typically involves integrating an internal classifier at multiple intermediate layers of BERT. This architecture allows the model to assess the correctness of predictions at each layer, enabling an exit if an early prediction meets a certain confidence threshold. In this setup, the model does not always need to traverse all layers, allowing it to exit early for easier inputs while still processing more difficult ones through deeper layers [3].

Two prominent implementations of confidence-based strategies are exemplified by models like DeeBERT and RightTool. These models specifically focus on utilizing model confidence derived from early predictions to guide exit decisions effectively [2]. In addition, CascadeBERT enhances this approach by employing multiple cascaded classifiers, which collectively contribute to assessing prediction correctness and, subsequently, the exit decisions [4].

The effectiveness of these confidence-based early exit strategies is rooted in their ability to establish a reliable exit criterion. The challenge that arises in this context is the absence of ground-truth labels during inference, making it difficult to estimate the correctness of predictions accurately. To mitigate this issue, models like BERxiT are designed to learn and generate an indicator that quantifies the correctness of early predictions, contributing to more informed exit decisions [2] [4].

In summary, confidence-based early exit strategies in BERT models can be characterized by the integration of intermediate classifiers that evaluate prediction confidence, allowing for efficient inference by exiting early when confidence levels are sufficiently high. This approach combines innovative architectures and the strategic use of prediction metrics to optimize computational resources while maintaining model accuracy.

1. [1]:  https://ar5iv.org/html/2402.05948, [2402.05948] DE3-BERT: Distance-Enhanced Early Exiting for BERT based on Prototypical Networks
2. [2]:  https://ar5iv.org/html/2402.05948, [2402.05948] DE3-BERT: Distance-Enhanced Early Exiting for BERT based on Prototypical Networks
3. [3]:  https://ar5iv.org/html/2402.05948, [2402.05948] DE3-BERT: Distance-Enhanced Early Exiting for BERT based on Prototypical Networks
4. [4]:  https://ar5iv.org/html/2402.05948, [2402.05948] DE3-BERT: Distance-Enhanced Early Exiting for BERT based on Prototypical Networks
5. [5]:  https://ar5iv.org/html/2405.15039, [2405.15039] CeeBERT: Cross-Domain Inference in Early Exit BERT
---
1. [1]:  Passage ID 1: Dynamic Early ExitingEarly exiting, a parallel line of research for accelerating the inference of PLMs, is to dynamically stop inference for various input samples. DeeBERT [20], FastBERT [32], and RightTool [28] are pioneers in applying early exiting to accelerate the inference of BERT-style models. These studies employ the confidence level, such as entropy or label score of the prediction probability distribution, to estimate the correctness of early predictions for exit decision-making. On this basis, Lin et al. [33] extended confidence-based early exiting from classification tasks to sequence labeling tasks. To further improve the acceleration performance of early exiting models, one approach is to explore new exiting strategies for the inference stage. PABEE [21] uses the cross-layer consistency to determine early exiting. PCEE-BERT [23] employs a hybrid exiting strategy that combines confidence-based and patience-based strategies. BERxiT [22] learns to generate an exiting
2. [2]:  Passage ID 2: correctness) to establish the exiting criteria. According to the types of exiting indicators, there are mainly three early exiting strategies for the dynamic exiting of BERT models. The first strategy is confidence-based early exiting (e.g., Deebert [20], RightTool [28] and CascadeBERT [25]). It utilizes the model confidence, i.e., entropy or label score of the prediction probability distribution, to estimate the correctness of early predictions for exit decision-making. The second strategy is patience-based early exiting (e.g., PABEE [21] and LeeBERT [29]), relying on the cross-layer consistency to determine when to exit. Early exiting in the third type learns to generate an early exiting indicator that scores the prediction correctness (e.g., BERxiT [22]). However, a reliable exiting decision is to exit when the early predictions are sufficiently correct. Unfortunately, the absence of ground-truth labels during inference poses extreme challenges to estimating prediction correctness,
3. [3]:  Passage ID 3: the threshold, without incurring additional training costs. In Fig. 1, we illustrate early exiting based on BERT, where an internal classifier is added to each intermediate layer of BERT. This enables the early exiting of samples when the early predictions from these internal classifiers are deemed sufficiently correct, eliminating the need to traverse the entire model. This strategy employs adaptive inference to deal with easy samples with shallow layers of BERT and process difficult samples with deeper layers. This approach effectively mitigates the overthinking problem and accelerates model inference while maintaining high accuracy.A typical implementation for early exiting is to devise an early exiting indicator that reflects the correctness of early predictions (i.e., prediction correctness) to establish the exiting criteria. According to the types of exiting indicators, there are mainly three early exiting strategies for the dynamic exiting of BERT models. The first strategy
4. [4]:  Passage ID 4: consistency to determine early exiting. PCEE-BERT [23] employs a hybrid exiting strategy that combines confidence-based and patience-based strategies. BERxiT [22] learns to generate an exiting indicator that scores the correctness of early predictions. HASHEE [24] utilizes hash functions to assign each token to a fixed exiting layer, providing a novel static paradigm for early exiting. In addition, an alternative approach to improve acceleration performance is to strengthen the capability of internal classifiers through various techniques, such as model calibration, architecture refinement, and optimized training schemes. CascadeBERT [25] employs early exiting within multiple cascaded complete models, thus strengthening the representation capability of internal classifiers. Moreover, it formulates a difficulty-aware objective to calibrate the prediction probability distribution. LeeBERT [29] introduces a cross-layer distillation loss with learned weights to promote the training of
5. [5]:  Passage ID 5: the target task as used in the previous baselines (see Section 5.2), thus making Early Exit PLMs robust to domain changes and enhancing their efficiency.•In Section 4, we introduce CeeBERT, an upper confidence-based algorithm that relies solely on confidence scores for learning the optimal threshold to make exit decisions.•In Section 5, we evaluate CeeBERT on five different datasets drawn from diverse tasks to demonstrate its proficiency in improving inference latency compared to the state-of-the-art algorithms.2 Related workEarly exit methods are applied for various tasks such as image classification, image captioning and NLP tasks to reduce the computational resources and inference latency.Early exits in Image tasks:For image classification tasks, BranchyNet Teerapittayanon et al. (2016) uses classification entropy at each attached exit to decide whether to infer the sample at the side branch based on the entropy of prediction.Shallow-deepKaya et al. (2019)