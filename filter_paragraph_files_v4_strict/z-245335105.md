# A Comprehensive Analytical Survey on Unsupervised and Semi-Supervised Graph Representation Learning Methods

CorpusID: 245335105 - [https://www.semanticscholar.org/paper/b415ecb687941e1e9ef68e04a4a1c68c73483d51](https://www.semanticscholar.org/paper/b415ecb687941e1e9ef68e04a4a1c68c73483d51)

Fields: Computer Science, Mathematics

## (s34) Effect of Dimensions
(p34.0) Some previous studies have shown that the performance on the prediction task may vary if we choose different values for hyper-parameters [79,34,100,80]. For example, after reaching a certain value for dimensionality, the accuracy of prediction starts to drop when we increase it further. Most of the previous studies suggest using dimensional embedding. To summarize the results, we conduct experiments varying the dimensions of the output embedding for some shallow network-based methods. We set different parameters as described in Section 4.3 and take 20% of the dataset to train the logistic regression model while the rest of the samples in the dataset are used for the classification. We report the results of the F1-micro scores for the Pubmed dataset in Figs. 21 (a). We observe that Force2Vec, DeepWalk, and HARP perform better than other methods for various dimensional embedding. We also notice that, for lower dimensions, the F1-micro scores are not that much less compared to higher dimensions. In fact, the VERSE tool shows better performance for 16-dimensional embedding for the Pubmed dataset. RolX shows high sensitivity for different dimensions. It shows the lowest performance for 16-dimensional embedding. Then, with the increase of dimension, the F1-micro score also increases until 128-dimension. Then, it falls a little for 256-dimensional embedding. The LINE method shows similar sensitivity to the VERSE method though its F1-micro scores are lower than the VERSE.
