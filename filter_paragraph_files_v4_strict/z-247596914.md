# Visuo-Haptic Object Perception for Robots: An Overview

CorpusID: 247596914 - [https://www.semanticscholar.org/paper/49579115424853a2e479678023ef592fddaca003](https://www.semanticscholar.org/paper/49579115424853a2e479678023ef592fddaca003)

Fields: Computer Science, Engineering

## (s28) Transfer Learning
(p28.0) One of the challenges of transfer learning (colearning) is that machine learning models are based on the assumption that both training and test data are drawn from the same distribution. However, such an assumption does not hold when transferring knowledge between different robots or sensor modalities. A possible solution is domain adaptation, a.k.a. transfer learning, (e.g., Daum√© III and Marcu, 2006;Wang and Deng, 2018). Here, training samples from a source dataset are adapted to fit a target distribution.
## (s40) Multimodal Signal Processing and Applications
(p40.0) With regards to signal processing and applications, even though multimodal visuo-haptic approaches for grasping show better results and have the potential to handle use-cases where visual information alone is insufficient, vision-only grasping approaches (e.g., Levine et al, 2018;Mahler et al, 2017;Bousmalis et al, 2018;James et al, 2019) are still more popular. Some reasons for this popularity are that the availability, durability and understanding of vision sensors are better than tactile ones. Moreover, the simulation of vision sensors is easier and more realistic, and the collection, processing and interpretation of visual information are easier than tactile sensor readings. On the other side of the spectrum, there are also recent grasping approaches (e.g., Murali et al, 2020;Hogan et al, 2018) that only use tactile information, but such approaches are usually only suitable for limited scenarios or parts of the grasping process. Thus, future efforts should be concentrated on multimodal approaches. However, as discussed by Xia et al (2022), the main challenge is ensuring safety during the physical contact between the object and the robot necessary for tactile sensing. To avoid the hardware dependencies and the safety risks, simulations are a promising alternative to real-world training and data collection for learningbased grasping approaches. However, due to the inaccurate nature of simulations, they cannot completely replace, but they can significantly reduce, the amount of real-world data needed. Finally, finetuning on the real system or sim2real techniques (e.g., Ding et al, 2020;Narang et al, 2021) can help to bridge the simulation-to-reality gap.

(p40.1) Another major problem of data-driven and endto-end learning grasping approaches is that they require a vast amount of training data, in contrast to humans, who learn and generalize from very few examples. In this regard, future work should concentrate on improving the sample efficiency of the algorithms. One option is to include priors in the learning process, e.g., meaningful relations between tactile sensing regions can be incorporated into the model through graph-like structures, e.g., Garcia-Garcia et al (2019). Another option is combining model-based and model-free techniques for grasping or developing hierarchical and multi-stage approaches. An added benefit of such approaches is that they provide better control over the grasping process and increased interpretability of the model's behaviour, which is crucial for applications in industrial or collaborative environments alongside humans. Safety is of utmost importance in such environments, and integrating tactile sensors like robotic skin (Pang et al, 2021) can help improve tasks like grasping, prevent injuries, and enable compliant robot control.
