# Reinforcement Learning for Ridesharing: An Extended Survey *

CorpusID: 246017110 - [https://www.semanticscholar.org/paper/6099eeb3c4d8f8bae466e88075f83c5ee1d9c444](https://www.semanticscholar.org/paper/6099eeb3c4d8f8bae466e88075f83c5ee1d9c444)

Fields: Computer Science

## (s24) General RL
(p24.0) RL provides the necessary tools for the methods reviewed in this survey. Hence, the problems of RL for ridesharing tie closely to the development in RL in general. In the context of ridesharing, we have seen from the literature review above that it is difficult for RL to learn combinatorial actions, e.g., the system matching actions. In the era of deep RL, model interpretability is a long-standing challenge, which hampers investigation of customer experience corner cases. For experience-critical service like ridesharing, policy exploration adds further complication, especially for real-world deployment. In view of these challenges, the future is probably that RL-based and traditional optimization approaches will be complementing each other for a long time. We have seen such combinations in the current literature as  for matching, (Chaudhari et al. 2020a, Jiao et al. 2021 for repositioning, and (Delarue et al. 2020) for VRP, that combine RL with combinatorial optimization, mixed-integer programming, and tree search. The breakthroughs of RL that we are seeing in other domains and the continued development of RL methodology for ridesharing certainly make it exciting to anticipate the future landscape.
