# Evidence Based Library and Information Practice Evidence Summary Identifying Controlled Clinical Trials for Systematic Reviews Requires Searching Multiple Resources -and, Even Then, Comprehensiveness is Questionable A review of

CorpusID: 142741000
 
tags: #Psychology, #Education, #Computer_Science

URL: [https://www.semanticscholar.org/paper/859b40364034cd781e453e69a44f78c5bc8ae26e](https://www.semanticscholar.org/paper/859b40364034cd781e453e69a44f78c5bc8ae26e)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | False |
| By Annotator      | (Not Annotated) |

---

Evidence Based Library and Information Practice Evidence Summary Identifying Controlled Clinical Trials for Systematic Reviews Requires Searching Multiple Resources -and, Even Then, Comprehensiveness is Questionable A review of
2006

Ellen T Crumley 
Natasha Wiebe 
Kristie Cramer 
Terry P Klassen 
Lisa &quot; Hartling 
Which 
Evidence Based Library and Information Practice Evidence Summary Identifying Controlled Clinical Trials for Systematic Reviews Requires Searching Multiple Resources -and, Even Then, Comprehensiveness is Questionable A review of

Evidence Based Library and Information Practice
142006Resources Should be Used to Identify RCT/CCTs for Systematic Reviews: A Systematic Review." BMC Medical Research Methodology 5.24 (2005). 4 Nov. 2006 Received: 27 August 2006 Accepted: 23 October 200654 <http://www.biomedcentral.com/1471-2288/5/24>. Reviewed by: Gale G. Hannigan Professor, Texas A&M Medical Sciences Library College Station, Texas, United States of America Methods -Seven electronic databases MEDLINE, EMBASE, CINAHL, ERIC, PsycINFO, Web of Science, and Cochrane Library were searched to April 2004. Four journals, Health Information & Libraries Journal -(formerly Health Libraries Review), Hypothesis, Journal of the Medical Library Association-(formerly Bulletin of the Medical Library Association), and Medical Reference Services Quarterly were handsearched from 1990 to 2004. All abstracts of the Cochrane Colloquia (1993-2003) were handsearched, and key authors found from any portion of the searching process were contacted and relevant article references screened. Two reviewers independently screened results for studies that compared two or more resources to find RCTs or CCTs using defined inclusion and exclusion criteria. Two reviewers assessed studies for quality using four criteria: adequate descriptions of what the search was attempting to identify, the methods used to search, the reference standard, and evidence that bias was
Objective -To determine the value of searching different databases to identify relevant controlled clinical trial (CCT) and randomized controlled trial (RCT) reports for systematic reviews.Design -Systematic review.

Association-(formerly Bulletin of the Medical Library Association), and Medical Reference Services Quarterly were handsearched from 1990 to 2004. All abstracts of the Cochrane Colloquia (1993)(1994)(1995)(1996)(1997)(1998)(1999)(2000)(2001)(2002)(2003) were handsearched, and key authors found from any portion of the searching process were contacted and relevant article references screened. Two reviewers independently screened results for studies that compared two or more resources to find RCTs or CCTs using defined inclusion and exclusion criteria. Two reviewers assessed studies for quality using four criteria: adequate descriptions of what the search was attempting to identify, the methods used to search, the reference standard, and evidence that bias was avoided in selection of relevant studies. Screening and assessment differences between reviewers were resolved through discussion. Using a standard form, one investigator extracted data for each study, including study design and results (e.g., recall, precision), and a second investigator checked these data. Authors were contacted to provide missing data. Results were grouped by the compared resources and these comparisons were summarized using medians and ranges. Using a classification modified from Hopewell et al., search strategies were categorized as Complex (using a combination of types of search terms), Cochrane (the Cochrane Highly Sensitive Search Strategy or HSSS), Simple (using five or fewer search terms which may include a combination of MeSH, Publication Type, and keywords), and Index (using one or two terms to check/verify if the study is in the database) (2004).

Main results -Sixty-four studies met criteria for inclusion in the analysis. Four major comparisons were: MEDLINE vs. handsearch (n=22), MEDLINE vs. MEDLINE + handsearch (n=12), MEDLINE vs. other reference standard (n=18), and EMBASE vs. reference standard (n=13). Thirteen other comparisons had only one or two studies each. The most common comparison was MEDLINE vs. Handsearching. Data analyzed from 23 studies and 22 unique topic comparisons showed a 58% median for search recall (range 7-97%). Data for search precision based on 12 studies and 11 unique topic comparisons indicated a median of 31% (range 0.03-78%). Data based on more than four comparisons, shows no median recall more than 75% (range 18-90%) and no median precision more than 40% (range 13-83%). Recall was higher for Trial Registries vs. Reference Standard (89%, range 84-95%) but these numbers were based on two studies and four comparisons; one study with two comparisons measured precision at a range of 96-97% for Trial Registries vs.

Reference Standard. Subgroup analyses indicate that Complex and Cochrane searches each achieve better recall and precision compared to Simple searches. Forty-two studies reported reasons why searches miss relevant studies. The reason cited most often for electronic databases was inadequate or inappropriate indexing.

Conclusion -The results of this systematic review indicate that no single resource results in particularly high recall or precision when searchers look for RCTs and CCTs.


## Commentary

Well-performed, up-to-date systematic reviews of methodologically sound RCTs and CCTs currently represent the highest level of evidence. Therefore, it is critical that they are based on all appropriate and relevant RCTs and CCTs. Simply put, the question asked by the researchers is "Which resources and types of searches are most productive for locating clinical trials?" If their research answered this question, it might suggest an optimal, cost-effective approach in which systematic reviewers could be confident. To address the question, the authors analyze studies of the recall and precision of searches of the most common resources used to identify RCTs and CCTs, following the standard methodology of systematic reviews (e.g., they define their own search methods, inclusion/exclusion criteria, employ more than one person to evaluate studies, and describe their methodology in detail, to the point of providing a link for more information about the studies). As an aside, it is always helpful to include a figure that graphically describes the study process. Unfortunately, despite the rigor of this systematic review, the quality of the studies included varies and the numbers of truly comparable studies are quite small. These are inherent limitations to any conclusions the authors make. That said, if true, the reported results make one question the comprehensiveness of any systematic review literature search. Overall, medians for recall and precision are low and ranges are wide. In their conclusion, the authors recommend consultation with a librarian even though only one study provides direct comparison between librarian and non-librarian authored searches. Further, subgroup analyses do not consistently show that searches by librarians are better. This is the only hint of bias creeping into an otherwise well-executed study, and a reminder to us all not to take an article's abstract at face value. This research underscores the need to find a better way of identifying RCTs and CCTs and it suggests that registries and/or better indexing hold promise of making that possible. For the time being, though, systematic reviewers cannot rely on one resource in their effort to be complete and, until there are comprehensive clinical trial registries, even multiple-resource searching is most likely not all-inclusive.


## Works Cited## Commentary

Well-performed, up-to-date systematic reviews of methodologically sound RCTs and CCTs currently represent the highest level of evidence. Therefore, it is critical that they are based on all appropriate and relevant RCTs and CCTs. Simply put, the question asked by the researchers is "Which resources and types of searches are most productive for locating clinical trials?" If their research answered this question, it might suggest an optimal, cost-effective approach in which systematic reviewers could be confident. To address the question, the authors analyze studies of the recall and precision of searches of the most common resources used to identify RCTs and CCTs, following the standard methodology of systematic reviews (e.g., they define their own search methods, inclusion/exclusion criteria, employ more than one person to evaluate studies, and describe their methodology in detail, to the point of providing a link for more information about the studies). As an aside, it is always helpful to include a figure that graphically describes the study process. Unfortunately, despite the rigor of this systematic review, the quality of the studies included varies and the numbers of truly comparable studies are quite small. These are inherent limitations to any conclusions the authors make. That said, if true, the reported results make one question the comprehensiveness of any systematic review literature search. Overall, medians for recall and precision are low and ranges are wide. In their conclusion, the authors recommend consultation with a librarian even though only one study provides direct comparison between librarian and non-librarian authored searches. Further, subgroup analyses do not consistently show that searches by librarians are better. This is the only hint of bias creeping into an otherwise well-executed study, and a reminder to us all not to take an article's abstract at face value. This research underscores the need to find a better way of identifying RCTs and CCTs and it suggests that registries and/or better indexing hold promise of making that possible. For the time being, though, systematic reviewers cannot rely on one resource in their effort to be complete and, until there are comprehensive clinical trial registries, even multiple-resource searching is most likely not all-inclusive.


## Works Cited

Hopewell S, M. Clarke, C. Lefebvre, R.

Scherer. "Handsearching versus electronic searching to identify reports of randomized trials." Cochrane Database of Methodology Reviews 2002Reviews .4 (2002. 5 Nov. 2006 <http://www.mrw.interscience.wiley.co m/cochrane/clmethrev/articles/MR0000 01/frame.html>.