# A Survey on Explainability: Why should we believe the accuracy of a model?

CorpusID: 219057069 - [https://www.semanticscholar.org/paper/04483a3f197b3183309aaae20241e1d4bdf92aed](https://www.semanticscholar.org/paper/04483a3f197b3183309aaae20241e1d4bdf92aed)

Fields: Philosophy, Computer Science

## (s1) EXPLAINABILITY IN MACHINE LEARNING
Number of References: 6

(p1.0) The term eXplainable Artificial Intelligence is usually abbreviated as XAI. The term was first formulated by Lent and Mancuso in 2004 [53]. Before that it was addressed as "black-box". The main aim behind the development of such a technique is twofold -Firstly, it provides transparency against the working models and algorithms in a way to gain insights into the black-box. Secondly, it aids in converting an untrustworthy model into a trustworthy one. Digging deep into the matter, it is found that Explainability is not a recent topic that the researchers have been focusing upon. It has been discussed for many years and have recently gained more attention and importance due to their ability to explain the predictions made by the intelligent systems which is indeed a major concern for the study. Various researchers define Explainability in a number of ways -Ribeiro et al. [40] in 2016 defined explainability as "presenting textual or visual artifacts that provide a qualitative understanding of the relationship between the instance's components (e.g. words in text, patches in an image) and the model's prediction." According to Guidotti et al. [12] "an explanation is an Interface between humans and a decision maker that is at the same time both an accurate proxy of the decision maker and comprehensible to humans." Gilpin et al. defined it in terms of " models that are able to summarize the reasons for neural network behavior, gain the trust of users, or produce insights about the causes of their decisions. " [10]. According to Tim Miller [33], Explainable Artificial Intelligence (XAI) refers to "an explanatory agent revealing underlying causes to its or another agent's decision making. " Recently Arrieta et al. [4] have also defined it as "Given an audience an explainable Artificial Intelligence is one that produces details or reasons to make its functioning clear to understand. "
## (s8) Name
Number of References: 2

(p8.0) Year Author Description LIME 2016 Riberio et al. [40] Provide faithful explanation against the prediction made by a classifier. Addresses the "trusting a prediction" problem. SP-LIME 2016 Riberio et al. [40] Addresses the "trusting a model" problem.
