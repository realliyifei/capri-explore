# A SURVEY ON HUMAN ACTION RECOGNITION

CorpusID: 255942153 - [https://www.semanticscholar.org/paper/200a067b06bde6d5b684ed47edf17f9e67283539](https://www.semanticscholar.org/paper/200a067b06bde6d5b684ed47edf17f9e67283539)

Fields: Computer Science

## (s4) Early Fusion
Number of References: 3

(p4.0) Both feature-level and data-level fusion are referred to as early fusion. Data-level fusion is suitable for homogeneous multi-sensor data (e.g., two or more RGB cameras or depth cameras, etc.). When there are two or more heterogeneous sensors, feature-level fusion or decision-level fusion techniques are usually applied. The modalities are often highly correlated with each other, but it is difficult to extract this correlation in both feature layer and data layer. According to literature [54], correlation between information contained in different data streams can only be found at a higher level. Researchers usually use dimensionality reduction techniques to eliminate redundancy problems in the input space. For example, the Principal Component Analysis (PCA) method in literature [119] is widely used in dimensionality reduction processing in multimodal deep learning. In addition, the multimodal early fusion method also needs to solve the problem of time synchronization among different data sources, several methods were proposed to solve this problem in [101], such as Convolutional, Training and Pool Fusion, which can well integrate discrete event sequence and continuous signal to realize time synchronization between modalities.
