# IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING 1 A Survey on Multi-Behavior Sequential Recommendation

CorpusID: 261339556 - [https://www.semanticscholar.org/paper/ca9f41ad1c3f0ed51781eef6cfcd035bf4d01d1a](https://www.semanticscholar.org/paper/ca9f41ad1c3f0ed51781eef6cfcd035bf4d01d1a)

Fields: Computer Science

## (s14) Works
Number of References: 2

(p14.0) Data Perspective Model Perspective Features RLBL [14] A sequence of (item, behavior) pairs Local Capture the influence of heterogeneous behaviors by utilizing a behavior transition matrix. RIB [26] A sequence of (item, behavior) pairs Local Leverage GRU and attention mechanism simultaneously.
## (s18) C. Transformer-based Learning Architecture
Number of References: 8

(p18.0) The Transformer model [79], a deep learning architecture that utilizes a self-attention network to reduce the computational complexity and thus enhance the training speed, has gained wide recognition in recent years for its superior performance in sequence-to-sequence modeling. This model has been utilized in a wide range of research areas, including natural language processing [80], [81], computer vision [82], [83], and recommender systems [23], [84], [85].
## (s19) Works
Number of References: 4

(p19.0) Data Perspective Model Perspective Features DMT [23] Some behavior-specific subsequences of items Local + Global Use target item as query; Consider implicit feedback bias by a bias deep neural network. DFN [84] Some behavior-specific subsequences of items Local + Global Use target item as query; Consider implicit negative feedback noise by an attention network . DUMN [88] Some behavior-specific subsequences of items Local Consider implicit feedback noise; Use memory network to obtain the long-term user preference. FeedRec [25] Some behavior-specific subsequences of items and a sequence of (item, behavior) pairs Local + Global Consider implicit feedback noise by an attention network; Consider multiple patterns of the multi-behavior sequences.
