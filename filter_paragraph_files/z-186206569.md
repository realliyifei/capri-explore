# Deep Learning for Spatio-Temporal Data Mining: A Survey

CorpusID: 186206569 - [https://www.semanticscholar.org/paper/a54c647f6db73621ec496ea86355726161c0898d](https://www.semanticscholar.org/paper/a54c647f6db73621ec496ea86355726161c0898d)

Fields: Engineering, Mathematics, Computer Science, Environmental Science

## (s2) A. Data Types
(p2.0) There are various types of ST data that differs in the way of data collection and representation in different real-world applications. Different application scenarios and ST data types lead to different categories of data mining tasks and problem formulations. Different deep learning models usually have different preferences to the types of ST data and have different requirements for the input data format. For example, CNN model is designed to process image-like data, while RNN is usually used to process sequential data. Thus it is important to first summarize the general types of ST data and represent them properly. We follow and extend the categorization in [4], and classify the ST data into the following types: event data, trajectory data, point reference data, raster data, and videos.

(p2.1) Event data. Event data comprise of discrete events occurring at point locations and times (e.g., crime events in the city and traffic accident events in a transportation network). An event can generally be characterized by a point location and time, which denotes where and when the event occurred, respectively. For example, a crime event can be characterized as such a tuple (e i , l i , t i ), where e i is the crime type, l i is the location where the crime occurs and t i is the time when it occurs. Fig. 1(a) shows an illustration of the event data. It shows three types of events denoted by different shapes of the symbol. ST event data are common in realworld applications such as criminology (incidence of crime and related events), epidemiology (disease outbreak events), transportation (car accident), and social network (social event and trending topics).

(p2.2) Trajectory data. Trajectories denote the paths traced by bodies moving in space over time. (e.g., the moving route of a bike trip or taxi trip). Trajectory data are usually collected by the sensors deployed on the moving objects that can periodically transmit the location of the object over time, such as GPS on a taxi. Fig. 1(b) shows an illustration of two trajectories. Each trajectory can be usually characterized as such a sequence {(l 1 , t 1 ), (l 2 , t 2 )...(l n , t n )}, where l i is the location (e.g. latitude and longitude) and t i is the time when the moving object passes this location. Trajectory data such as human trajectory, urban traffic trajectory and location based social networks are becoming ubiquitous with the development of Mobile applications and IoT techniques.

(p2.3) Point reference data. Point reference data consist of measurements of a continuous ST field such as temperature, vegetation, or population over a set of moving reference points in space and time. For example, meteorological data such as temperature and humidity are commonly measured using weather balloons floating in space, which continuously record weather observations. Point reference data can be usually represented as a set of tuples as follows {(r 1 , l 1 , t 1 ), (r 2 , l 2 , t 2 )...(r n , l n , t n )}. Each tuple (r i , l i , t i ) denotes the measurement of a sensor r i at the location l i of the ST filed at time t i . Fig. 3 shows an example of the point reference data (e.g. sea surface temperature) in a continuous ST field at two time stamps. They are measured by the sensors at reference locations (shown as while circles) on the two time stamps. Note that the locations of the temperature sensors change over time.

(p2.4) Raster data. Raster data are the measurements of a continuous or discrete ST field that are recorded at fixed locations in space and at fixed time points. The major difference between point reference data and raster data is that the locations of the point reference data keep changing while the locations of the raster data are fixed. The locations and times for measuring the ST field can be regularly or irregularly distributed. Given m fixed locations S = {s 1 , s 2 , ...s m } and n time stamps T = {t 1 , t 2 , ...t n }, the raster data can be represented as a matrix R m√ón , where each entry r ij is the measurement at location s i at time stamp t j . Raster data are also quite common in realworld applications such as transportation, climate science, and neuroscience. For example, the air quality data (e.g. PM2.5) can be collected by the sensors deployed at fixed locations of a city, and the data collected in a continuous time period form the air quality raster data. In neuroscience, functional magnetic resonance imaging or functional MRI (fMRI) measures brain activity by detecting changes associated with blood flow. The scanned fMRI signals also form the raster data for analyzing the brain activity and identifying some diseases. Fig. 4 shows an example of the traffic flow raster data of a transportation network. Each road is deployed a traffic sensor to collect real time traffic flow data. The traffic flow data of all the road sensors in a whole day (24 hours) form a raster data.

(p2.5) Video. A video that consists of a sequence of images can be also considered as a type of ST data. In the spatial domain, the neighbor pixels usually have similar RGB values and thus present high spatial correlations. In the temporal domain, the images of consecutive frames usually change smoothly and present high temporal dependency. A video can be generally represented as a three dimensional tensor with one dimension representing time t and the other two representing an image. Actually, video data can be also considered as a special raster data if we assume that there is a "sensor" deployed at each pixel and at each frame the "sensors" will collect the RGB values. Deep learning based video data analysis is extremely hot and a large number of papers are published in recent years. Although we categorize videos as a type of ST data, we focus on reviewing related works from the perspective of data mining and video data analysis falls into the research areas of computer vision and pattern recognition. Thus in this survey we do not cover the ST data type of videos.
## (s10) B. Representation Learning
(p10.0) Representation learning aims to learn the abstract and useful representations of the input data to facilitate downstream data mining or machine learning tasks, and the representations are formed by composition of multiple linear or non-linear transformations of the input data. Most existing works on representation learning for ST data focused on studying the data types of trajectories and spatial maps.

(p10.1) Trajectories. Trajectories are ubiquitous in location-based social networks (LBSNs) and various mobility services, and RNN and CNN models are both widely used to learn the trajectory representations. [82] proposed a seq2seq-based model to learn trajectory representations, for the fundamental research problem of trajectory similarity computation. The trajectory similarity based on the learned representations is robust to non-uniform, low sampling rates and noisy sample points. Simiarly, [170], [171] proposed to transform a trajectory into a feature sequence to describe object movements, and then employed a sequencetosequence autoencoder to learn fixedlength deep representations for clustering. Location-based social network (LBSN) data usually contain two important aspects, i.e., the mobile trajectory data and the social network of users. To model the two aspects and mine their correlations, [164] proposed a neural network model to jointly learn the social network representation and the users' mobility trajectory representation. RNN and GRU models are used to capture the sequential relatedness in mobile trajectories at the short or long term levels. [10] proposed a content-aware POI embedding model named CAPE for POI recommendation. In CAPE, the embedding vectors of POIs in a user's check-in sequence are trained to be close to each other. [26] proposed a geographical convolutional neural tensor network named GeoCNTN to learn the embeddings of the locations in LBSNs. [41] proposed to use RNN and Autoencoder to learn the user check-in embedding and trajectory embedding, and used the embeddings for user social circle inference in LBSNs.
## (s11) C. Classification
(p11.0) The classification task is mostly studied in analyzing fMRI data. Recently, brain imaging technology has become a hot topic within the field of neuroscience, including functional Magnetic Resonance Imaging (fMRI), electroencephalography (EEG), and Magnetoencephalography (MEG) [120]. Particularly, fMRI combined with deep learning methods, has been widely used in the study of neuroscience for various classification tasks such as disease classification, brain function network classification and brain activation classification when watching words or images [158]. Various types of ST data can be extracted from the raw fMRI data depending on different classification tasks. [34] proposed the use of recurrent neural networks with long short-term memory (LSTMs) for classification of individuals with autism spectrum disorders (ASD) and typical controls directly from the resting-state fMRI time-series data generated from different brain regions. [48], [52], [54], [71], [113], [132] modeled the fMRI data as spatial maps, and then used them as the input of the classification models. Instead of using each individual restingstate fMRI time-series data directly, [48] and [52] calculated the whole-brain functional connectivity matrix based on the Pearson correlation coefficient between each pair of restingstate fMRI time-series data. Then the correlation matrix can be considered as a spatial map, and is input to a DNN model for ASD classification. [113] proposed a more general convolutional neural network architecture for functional connectome classification called connectome-convolutional neural network (CCNN). CCNN is able to combine information from diverse functional connectivity metrics, and thus can be easily adapted to a wide range of connectome based classification or regression tasks, by varying which connectivity descriptor combinations are used to train the network.

(p11.1) Some works also directly use the 3D structural MRI brain scanned images as the ST raster data, and then 3D-CNN model is usually applied to learn features from the ST raster for classification [63], [66], [78], [116], [128], [194]. [78] proposed two 3D convolutional network architectures for brain MRI classification, which are the modifications of a plain and residual convolutional neural networks. Their models can be applied to 3D MRI images without intermediate handcrafted feature extraction. [194] also designed a deep 3D-CNN framework for automatic, effective, and accurate classification and recognition of large number of functional brain networks reconstructed by sparse 3D representation of whole-brain fMRI signals.
## (s24) G. Neuroscience
(p24.0) In recent years, brain imaging technology has become a hot topic within the field of neuroscience. Such technology includes functional Magnetic Resonance Imaging (fMRI), electroencephalography (EEG), Magnetoencephalography (MEG), and functional Near Infrared Spectroscopy (fNIRS). The spatial and temporal resolutions of neural activity measured by these technologies is quite different from another. fMRI measures the neural activity from millions of locations, while it is only measured from tens of locations for EEG data. fMRI typically measures activity for every two seconds, while the temporal resolution of EEG data is is typically 1 millisecond. Because of its space resolving power, fMRI and EEG combined with deep learning methods, has been widely used in the study of neuroscience [34], [63], [113], [128]. As we discussed before, deep learning models are mostly used for the classification task in neuroscience by using the fMRI data or EEG data such as disease classification [34], brain function network classification [113] and brain activation classification [63]. For example, Long-Short Term Memory network (LSTM) was used to identify Autism Spectrum Disorder (ASD) [34], Convolutional Neural Networks (CNN) were used to diagnose amnestic Mild Cognitive Impairment (aMCI) [113] and Feedforward Neural Networks (FNN) were used to classify Schizophrenia [119].

(p24.1) VI. OPEN PROBLEMS Though many deep learning methods have been proposed and widely used for STDM in diverse application domains discussed above, challenges still exist due to the highly complex, large volume, and fast increasing ST data. In this section, we provide some open problems that have not been well addressed by current works and need further studies in the future.
