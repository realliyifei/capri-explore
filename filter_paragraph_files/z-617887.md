# Design of LDPC Codes: A Survey and New Results

CorpusID: 617887 - [https://www.semanticscholar.org/paper/c86374e2c091311860fd8f8616f50cb4f02fa3fa](https://www.semanticscholar.org/paper/c86374e2c091311860fd8f8616f50cb4f02fa3fa)

Fields: Engineering, Computer Science

## (s0) I. INTRODUCTION
(p0.0) The class of low-density parity-check (LDPC) codes represents the leading edge in modern channel coding. They have held the attention of coding theorists and practitioners in the past decade because of their near-capacity performance on a large variety of data transmission and storage channels and because their decoders can be implemented with manageable complexity. They were invented by Gallager in his 1960 doctoral dissertation [1] and were scarcely considered in the 35 years that followed. One notable exception is Tanner, who wrote an important paper in 1981 [2] which generalized LDPC codes and introduced a graphical representation of LDPC codes, now called Tanner graphs. Apparently independent of Gallager's work, LDPC codes were re-invented in the mid-1990's by MacKay, Luby, and others [3] [4][5] [6] who noticed the advantages of linear block codes which possess sparse (low-density) parity-check matrices.
## (s3) A. Definition and Problem Statement
(p3.0) A protograph [24][25] [26][27] is a relatively small bipartite graph from which a larger graph can be obtained by a copyand-permute procedure: the protograph is copied Q times, and then the edges of the individual replicas are permuted among the replicas (under restrictions described below) to obtain a single, large graph. An example is presented in Fig.  4. The permuted edge connections are specified by the paritycheck matrix H. Note that the edge permutations cannot be arbitrary. In particular, the nodes of the protograph are labeled so that if variable node V is connected to check node C in the protograph, then variable node V in a replica can only connect to one of the Q replicated C check nodes. Doing so preserves the decoding threshold properties of the protograph. A protograph can possess parallel edges, i.e., two nodes can be connected by more than one edge. For LDPC codes, the copy-and-permute procedure must eliminate such parallel connections in order to obtain a derived graph appropriate for a parity-check matrix.

(p3.1) It is convenient to choose the parity-check matrix H as an M × N array of Q × Q (weight-one) circulant permutation matrices (some of which may be the Q × Q zero matrix). When H is an array of circulants, the LDPC code will be quasi-cyclic. Such a structure has a favorable impact on both the encoder and the decoder. The encoder for QC codes can be implemented with shift-register circuits with complexity linearly proportional to m for serial encoding and to n for parallel encoding [13]. By contrast, encoders for unstructured LDPC codes require much more work. The decoder for QC LDPC codes can be implemented in a modular fashion by exploiting the circulant-array structure of H [28] [29].

(p3.2) Below we present an extension of the EXIT approach to codes defined by protographs. This extension is a multidimensional numerical technique and as such does not have a two-dimensional EXIT chart representation of the iterative decoding procedure. Still, the technique yields decoding thresholds for LDPC code ensembles specified by protographs. This multi-dimensional technique is facilitated by the relatively small size of protographs and permits the analysis of protograph code ensembles characterized by the presence of critical node types, i.e., node types which can lead to failed EXIT-based convergence of code ensembles. Examples of critical node types are degree-1 variable nodes and punctured variable nodes.

(p3.3) A code ensemble specified by a protograph is a refinement (sub-ensemble) of a code ensemble specified simply by the protograph's (hence, LDPC code's) degree distributions. To demonstrate this, we introduce the adjacency matrix B = [b ji ] for a protograph, also called a base matrix [25], where b ji is the number of edges between CN j and VN i. As an example, for the protograph at the top of Fig. 4,
## (s8) B. Irregular Repeat-Accumulate codes
(p8.0) The systematic irregular repeat-accumulate (IRA) codes generalize the systematic RA codes in that the repetition rate may differ across the k information bits and that a variable number of bits in the repeated word are combined (modulo 2) prior to sending them through the accumulator. Irregular repeat-accumulate [33] codes provide several advantages over RA codes. They allowing both flexibility in the choice of the repetition rate for each information bit so that high rate codes may be designed and capacity is more easily approached. 57.8317in;original-height 7.0188in;cropleft "0";croptop "1";cropright The Tanner graph for IRA codes is presented in Fig. 5(a) and the encoder structure (to be discussed further later) is depicted in Fig. 5(b). The variable repetition rate is accounted for in the graph by letting d b,i vary with i. The accumulator is represented by the right-most part of the graph, where the dashed edge is added to include the possibility of a tail-biting trellis. Also, we see that d c,j interleaver output bits are added (modulo 2) to produce the j-th accumulator input. Fig. 5 also includes the representation for RA codes. As indicated in the table in the figure, for an RA code, each information bit node connects to exactly q check nodes (d b,i = q) and each check node connects to exactly one information bit node (d c,j = 1). We remark that {d b,i } and {d c,j } can be related to our earlier notation, {d v (i)} and {d c (j)}, as follows:

(p8.1) To determine the code rate for an IRA code, define q to be the average repetition rate of the information bits andā as the average of the degrees {d c,j },
## (s9) C. Structured IRA and IRAA Codes
(p9.0) Given the code rate, length, and degree distributions, an IRA code is defined entirely by the matrix H u (equivalently, by A and Π). While a random-like H u would generally give good performance, it is problematic for both encoder and decoder implementations. For, in this case, a substantial amount of memory would be required to store the connection information implicit in H u . In addition, although standard message-passing decoding algorithms for LDPC codes are inherently parallel, the physical interconnections required to realize a code's bipartite graph becomes an implementation bottleneck and prohibits a fully parallel decoder [29]. Using a structured H u matrix mitigates these problems.

(p9.1) Tanner [24] was the first to consider structured RA codes, more specifically, quasi-cyclic RA codes, which require tailbiting in the accumulator. Simulation results in [24] demonstrate that the QC-RA codes compete well with random-like RA codes and surpass their performance at high SNR values. Similar ideas were applied to IRA codes in [29][44] [36]. In [36], IRA codes with quasi-cyclic structure are called structured IRA (S-IRA) codes.

(p9.2) Toward the goal of attaining structure in H, one cannot simply choose H u to be an array of circulant permutation matrices. For, it is easy to show that doing so will produce a poor LDPC code in the sense of minimum distance (consider weight-2 encoder inputs with adjacent ones). Instead, the following strategy is proposed in [36]. Let P be an L×J array of Q × Q circulant permutation matrices (for some convenient Q). (Conditions for designing P to avoid 4-cycles, etc., are described in [36].) Then set A T = P so that H u = Π T P and

(p9.3) where H p represents the tailbiting accumulator. Note that m = L × Q and k = J × Q. We now choose Π to be a standard deterministic "rowcolumn" interleaver so that row lQ + q in P becomes row qL + l in Π T P, for all 0 ≤ l < L and 0 ≤ q < Q. Next, we permute the rows of H a by Π −T to obtain where we have used the fact that Π −T = Π. Finally, we permute only the columns corresponding to the parity part of H b , which gives
## (s11) E. Accumulate-Repeat-Accumulate Codes
(p11.0) For accumulate-repeat-accumulate (ARA) codes, introduced in [45], an accumulator is added to precode a subset of the information bits of an IRA code. The primary role of this second accumulator is to improved the decoding threshold of a code, that is, to shift the BER waterfall region leftward. ARA codes are a subclass of LDPC codes and Fig. 12 presents a generic ARA Tanner graph in which punctured variable nodes are highlighted. The sparseness of the ARA graph is achieved at the price of these punctured variable nodes which act as auxiliary nodes that enlarge the H used by the decoder. The iterative graph-based ARA decoder thus has to deal with a redundant representation of the code, implying a larger H matrix than the nominal (n − k) × n. This issue, together with the presence of a large number of degree-1 and degree-2 variable nodes, results in slow decoding convergence.

(p11.1) The ARA codes presented in [45] relies on very simple protographs. Several modified ARA protographs have been introduced in [46] [47], leading to ARA and ARA-like code families with excellent performance in both the waterfall and floor regions of the codes' performance curves. The protograph of a rate-1/2 ARA code ensemble with repetition rate 4, denoted AR4A, is depicted in Fig. 13(a). The dark circle corresponds to a state-variable node, and it is associated with the precoded fraction of the information bits. As emphasized in the figure, such a protograph is the serial concatenation of an accumulator protograph and an IRA protograph.
## (s21) VIII. CONCLUSION AND OPEN PROBLEMS
(p21.0) This paper provided fundamentals in the design of LDPC codes. The EXIT chart technique for determining near-optimal degree distributions for LDPC code ensembles was first discussed to provide a target for the code designer. The utility of representing codes by protographs and how this naturally leads to quasi-cyclic LDPC codes was also discussed, after which the EXIT chart technique was extended to the special case of protograph-based LDPC codes. Discussed next was several design approaches for LDPC codes which incorporate one or more accumulators, including quasi-cyclic accumulatorbased codes. The second half the paper then switched to several algebraic LDPC code design techniques including codes based on finite geometries and codes whose designs are based on Reed-Solomon codes. The algebraic designs lead to cyclic, quasi-cyclic, and structured codes. Finally, the masking technique for converting regular quasi-cyclic LDPC codes to irregular codes was presented. While the paper focuses on the BI-AWGNC, as discussed in the paper, good BI-AWGNC codes tend to be universally good across many channels.

(p21.1) The ultimate goal in the LDPC code field is a situation that is analog of BCH or RS codes, that is, a straightforward design technique and a straightforward performance analysis. While this may be possible someday, in the short term, some of the open problems that are undergoing studies by researchers are as follows. It is well known that error-floors can be due to a small minimum distance or it can be the fault of the iterative decoder. Thus, there is a tremendous amount of research being undertaken to understand the floor phenomenon. Another issue is the design of short codes. As mentioned in Section II, decoding threshold prediction techniques assume an infinite codeword length and an infinite number of decoding iterations. This leads one to ask about threshold prediction for short codes with a finite number of iterations. Another problem being studied is generalized LDPC codes in which the single parity-check nodes and repetition nodes of Tanner graphs were replaced by more complex constraints. This was first considered by Tanner [2]. Other problems include lower bounding the minimum distance of an LDPC code and understanding the impact of cycle structure and distribution on an iterative decoder. After receiving the Ph.D. degree Prof. Ryan held positions in industry for five years, first at The Analytic Sciences Corporation, then at Ampex Corporation, and finally at Applied Signal Technology. From 1993 to 1998, he was an assistant professor and then associate professor in the Department of Electrical and Computer Engineering at New Mexico State University, Las Cruces, NM. From 1998 to present, he has been on the faculty in the Department of Electrical and Computer Engineering at the University of Arizona, Tucson, AZ, first as an associate professor and then as full professor.

(p21.2) Prof. Ryan has over 75 publications in the leading conferences and journals in the area of communication theory and channel coding. He is also preparing the textbook Iteratively Decodable Codes: Construction and Decoding (Shu Lin, co-author) to be published by Cambridge University Press. His research interests are in coding and signal processing with applications to magnetic data storage and wireless data communications. He was an associate editor for the IEEE Transactions on Communications from 1998 through 2005. He is a Senior Member of the IEEE.
