# CURRENTLY UNDER REVIEW 1 Ethics in AI through the Developer's Prism: A Socio-Technical Grounded Theory Literature Review and Guidelines

CorpusID: 249889131 - [https://www.semanticscholar.org/paper/950ed3ee3745d3060c2083d36eca5a491c5d3b91](https://www.semanticscholar.org/paper/950ed3ee3745d3060c2083d36eca5a491c5d3b91)

Fields: Sociology, Computer Science

## (s3) Socio-Technical Grounded Theory Literature Review
(p3.0) (ST-GTLR) is an iterative and responsive literature review method that applies the five-step framework of define, search, select, analyse and present described in the original GTLR guidelines by Wolfswinkel et al. [11] with concrete data analysis (and optional theory development) steps of socio-technical grounded theory [10]. A GTLR is particularly well suited to studying niche and emerging research areas to gain in-depth understanding, establish theoretical foundations, and make practical recommendations.

(p3.1) In this section, we present the guidelines for conducting an ST-GTLR, including a definition of ST-GTLR (see definition box), the context of use, the basic steps and procedures of the ST-GTLR method and a diagram of the ST-GTLR process with elaborated analysis stage ( Figure 1). We also include the details of the application of these guidelines and demonstrate how we conducted the ST-GTLR in the context of our review study.

(p3.2) (ST-GTLR) is an iterative and responsive literature review method that applies the five-step framework of define, search, select, analyse and present described in the original GTLR guidelines by Wolfswinkel et al. [11] with concrete data analysis (and optional theory development) steps of socio-technical grounded theory [10]. A GTLR is particularly well suited to studying niche and emerging research areas to gain in-depth understanding, establish theoretical foundations, and make practical recommendations.

(p3.3) In this section, we present the guidelines for conducting an ST-GTLR, including a definition of ST-GTLR (see definition box), the context of use, the basic steps and procedures of the ST-GTLR method and a diagram of the ST-GTLR process with elaborated analysis stage ( Figure 1). We also include the details of the application of these guidelines and demonstrate how we conducted the ST-GTLR in the context of our review study.
## (s5) Define
(p5.0) The first step is to formulate the initial review protocol, including determining the scope of the study by defining inclusion and/or exclusion criteria, publication period, and search items, followed by databases to search in, research questions, and search strings. Following this approach, we defined our inclusion and exclusion criteria, publication period, language of the articles to be included followed by the guiding research question (RQ), search string and appropriate sources and specific search items with the aim 1. The term 'developers' in our study include AI programmers, practitioners, engineers, specialists, experts, designers, and stakeholders. We use the terms 'AI developers' and 'developers' interchangeably throughout our study.   [10] of obtaining maximum relevant primary empirical studies. The RQ was formulated to gain an overall understanding of ethics in AI from the perspective of AI developers, as:

(p5.1) The first step is to formulate the initial review protocol, including determining the scope of the study by defining inclusion and/or exclusion criteria, publication period, and search items, followed by databases to search in, research questions, and search strings. Following this approach, we defined our inclusion and exclusion criteria, publication period, language of the articles to be included followed by the guiding research question (RQ), search string and appropriate sources and specific search items with the aim 1. The term 'developers' in our study include AI programmers, practitioners, engineers, specialists, experts, designers, and stakeholders. We use the terms 'AI developers' and 'developers' interchangeably throughout our study.   [10] of obtaining maximum relevant primary empirical studies. The RQ was formulated to gain an overall understanding of ethics in AI from the perspective of AI developers, as:
## (s6) What do we know from literature about how developers view ethics in AI?
(p6.0) Four popular digital databases, namely, ACM Digital Library (ACM DL), IEEE Xplore, SpringerLink and Wiley Online Library (Wiley OL) were used as sources to identify the relevant literature. These databases have been regularly used to conduct reviews on human aspects of software engineering, e.g., [35], [36]. Initially, we searched for relevant studies which were published in journals and conferences only and for which full texts were available.

(p6.1) Key terms were selected from the research title to develop search queries. The first key terms were 'ethics' + 'AI' + 'developers' as the aim of our study is to find AI developer's views about ethics in AI. Then, synonyms of the key search terms were used to retrieve more relevant primary studies. The search terms were linked with 'AND' and 'OR' Boolean operators when developing the final search string. The purpose of the 'AND' operator was to concatenate the key terms whereas the 'OR' operator linked the synonyms.  search string: ("ethics" OR "trust" OR "morals" OR "fairness" OR "responsib*") AND ("artificial intelligence" OR "AI" OR "machine learning") AND ("software developer" OR "software practitioner" OR "data scientist" OR "machine learning" OR "software engineer" OR "programmer") Final search string: ("ethic*" OR "moral*" OR "fairness") AND ("artificial intelligence" OR "AI" OR "machine learning" OR "data science") AND ("software developer" OR "software practitioner" OR "programmer") Six candidate search strings were developed and executed on the four online databases before one was finalised. Table 1 shows the initial and the final search strings created for this study. As the finalised search string returned an extremely large number of primary studies (N=9,806), we restricted the publication period from January 2010 to June 2021, in all four databases, as the topic of ethics in AI has been gaining rapid prominence in the last ten years. Table  2 shows the seed protocol of this study, including inclusion and exclusion criteria. For example, an inclusion criterion was that the study should be written in English, and be empirically based, presenting evidence of AI developers' views on ethics in AI. The exclusion criteria included: studies such as workshop articles, short papers which were less than four pages, books, gray literature, theses, unpublished and incomplete work. It also included studies written in language other than English and duplicate articles. Likewise, studies that presented only the concept of ethics in AI without empirical evidence, review papers, and studies discussing topics irrelevant to the RQ were also considered grounds for exclusion.

(p6.2) Four popular digital databases, namely, ACM Digital Library (ACM DL), IEEE Xplore, SpringerLink and Wiley Online Library (Wiley OL) were used as sources to identify the relevant literature. These databases have been regularly used to conduct reviews on human aspects of software engineering, e.g., [35], [36]. Initially, we searched for relevant studies which were published in journals and conferences only and for which full texts were available.

(p6.3) Key terms were selected from the research title to develop search queries. The first key terms were 'ethics' + 'AI' + 'developers' as the aim of our study is to find AI developer's views about ethics in AI. Then, synonyms of the key search terms were used to retrieve more relevant primary studies. The search terms were linked with 'AND' and 'OR' Boolean operators when developing the final search string. The purpose of the 'AND' operator was to concatenate the key terms whereas the 'OR' operator linked the synonyms.  search string: ("ethics" OR "trust" OR "morals" OR "fairness" OR "responsib*") AND ("artificial intelligence" OR "AI" OR "machine learning") AND ("software developer" OR "software practitioner" OR "data scientist" OR "machine learning" OR "software engineer" OR "programmer") Final search string: ("ethic*" OR "moral*" OR "fairness") AND ("artificial intelligence" OR "AI" OR "machine learning" OR "data science") AND ("software developer" OR "software practitioner" OR "programmer") Six candidate search strings were developed and executed on the four online databases before one was finalised. Table 1 shows the initial and the final search strings created for this study. As the finalised search string returned an extremely large number of primary studies (N=9,806), we restricted the publication period from January 2010 to June 2021, in all four databases, as the topic of ethics in AI has been gaining rapid prominence in the last ten years. Table  2 shows the seed protocol of this study, including inclusion and exclusion criteria. For example, an inclusion criterion was that the study should be written in English, and be empirically based, presenting evidence of AI developers' views on ethics in AI. The exclusion criteria included: studies such as workshop articles, short papers which were less than four pages, books, gray literature, theses, unpublished and incomplete work. It also included studies written in language other than English and duplicate articles. Likewise, studies that presented only the concept of ethics in AI without empirical evidence, review papers, and studies discussing topics irrelevant to the RQ were also considered grounds for exclusion.
## (s7) Search
(p7.0) The second stage involves performing the actual search using the review protocol defined in the first stage [11]. We performed the search using our seed review protocol presented in Table 2. The search process was iterative and time-consuming because some essential synonyms of the search terms were missing initially, and we had to revisit the define stage again and again before moving to the next stage (e.g. see the initial and final search strings developed for this study in Table 1).

(p7.1) The second stage involves performing the actual search using the review protocol defined in the first stage [11]. We performed the search using our seed review protocol presented in Table 2. The search process was iterative and time-consuming because some essential synonyms of the search terms were missing initially, and we had to revisit the define stage again and again before moving to the next stage (e.g. see the initial and final search strings developed for this study in Table 1).
## (s8) Select
(p8.0) The selection of sample texts is done in this stage. The steps include (i) filtering out doubles, (ii) refining sample based on title and abstract, (iii) refining sample based on full text, (iv) scanning forward and backward citations, and (v) checking if new articles come up in the last step as these steps are iterative [11]. If new articles come up in the last step, researchers should go to step (i) and follow other steps accordingly. If no new articles come up, then that will be the final sample to be included in the study.

(p8.1) Following these guidelines, we obtained a total of 1,244 primary articles (ACM DL: 273, IEEEX: 355, SpringerLink: 543 and Wiley OL: 73) using the seed review protocol as shown in Table 2 and the final search string. After filtering out the duplicates, we were left with 982 articles. As per the Wolfswinkel et al. guidelines, the next step was to refine the whole sample based on title and abstract. We tried this approach for the first 200 articles each that came up in ACM DL, IEEEX and SpringerLink and all 73 articles in Wiley OL to get a sense of the number of relevant articles to our research question. We read the abstract of the articles whose title seemed relevant to our research topic and tried to apply the inclusion and exclusion criteria (in Table 2) to select the relevant articles. We quickly realised that selection based on title and abstract was not working well. This is because the presence of the key search terms (e.g., ethics AND AI AND developer) was rather common and did not imply that the paper would include the developers' perspective on ethics in AI. We found ourselves having to scan through full texts to judge relevance to our RQ. Despite the effort involved, the return on investment was low, e.g. for every 100 papers read, we found only one or two relevant to our study, i.e., that presented the AI developers' views on ethics in AI.

(p8.2) From a quick reading of 673 papers, we obtained only 10 primary articles that were relevant to our research topic. Many articles, albeit interesting, did not present the AI developers' views on ethics in AI. So, we decided to find more relevant articles through snowballing of articles. Snowballing of those 10 articles via forward citations and backward citations was done until 31 December 2021 to find more relevant articles and enrich the quality. Snowballing seemed to work better for us than the traditional search approach. We modified the seed protocol accordingly, to include papers published in other databases and those published beyond journals and conferences, including students' theses, reports, and papers uploaded to ArXiv. The rest of the protocol remained the same. The final review protocol used in this study is presented in Table 2. In this way, we obtained 20 more relevant articles, taking the total number of primary articles to 30.

(p8.3) The select step of scanning through the full contents of 673 articles was very tedious with very low return on investment (e.g. only 10 relevant studies obtained). In hindsight, we would have done better to start with a set of seed papers that were collectively known to the research team or those obtained from some quick searches on Google Scholar. What we did next by proceeding from the seed papers to cycles of snowballing, was more practical, productive, and in line with the iterative GT approach as a form of applied theoretical sampling.

(p8.4) The selection of sample texts is done in this stage. The steps include (i) filtering out doubles, (ii) refining sample based on title and abstract, (iii) refining sample based on full text, (iv) scanning forward and backward citations, and (v) checking if new articles come up in the last step as these steps are iterative [11]. If new articles come up in the last step, researchers should go to step (i) and follow other steps accordingly. If no new articles come up, then that will be the final sample to be included in the study.

(p8.5) Following these guidelines, we obtained a total of 1,244 primary articles (ACM DL: 273, IEEEX: 355, SpringerLink: 543 and Wiley OL: 73) using the seed review protocol as shown in Table 2 and the final search string. After filtering out the duplicates, we were left with 982 articles. As per the Wolfswinkel et al. guidelines, the next step was to refine the whole sample based on title and abstract. We tried this approach for the first 200 articles each that came up in ACM DL, IEEEX and SpringerLink and all 73 articles in Wiley OL to get a sense of the number of relevant articles to our research question. We read the abstract of the articles whose title seemed relevant to our research topic and tried to apply the inclusion and exclusion criteria (in Table 2) to select the relevant articles. We quickly realised that selection based on title and abstract was not working well. This is because the presence of the key search terms (e.g., ethics AND AI AND developer) was rather common and did not imply that the paper would include the developers' perspective on ethics in AI. We found ourselves having to scan through full texts to judge relevance to our RQ. Despite the effort involved, the return on investment was low, e.g. for every 100 papers read, we found only one or two relevant to our study, i.e., that presented the AI developers' views on ethics in AI.

(p8.6) From a quick reading of 673 papers, we obtained only 10 primary articles that were relevant to our research topic. Many articles, albeit interesting, did not present the AI developers' views on ethics in AI. So, we decided to find more relevant articles through snowballing of articles. Snowballing of those 10 articles via forward citations and backward citations was done until 31 December 2021 to find more relevant articles and enrich the quality. Snowballing seemed to work better for us than the traditional search approach. We modified the seed protocol accordingly, to include papers published in other databases and those published beyond journals and conferences, including students' theses, reports, and papers uploaded to ArXiv. The rest of the protocol remained the same. The final review protocol used in this study is presented in Table 2. In this way, we obtained 20 more relevant articles, taking the total number of primary articles to 30.

(p8.7) The select step of scanning through the full contents of 673 articles was very tedious with very low return on investment (e.g. only 10 relevant studies obtained). In hindsight, we would have done better to start with a set of seed papers that were collectively known to the research team or those obtained from some quick searches on Google Scholar. What we did next by proceeding from the seed papers to cycles of snowballing, was more practical, productive, and in line with the iterative GT approach as a form of applied theoretical sampling.
## (s9) Analyse
(p9.0) We applied Socio-Technical Grounded Theory (STGT) to conduct our review because its socio-technical research framework is customised to fit the unique socio-technical contexts of domains such as software engineering and artificial intelligence [10].

(p9.1) • Socio-technical phenomenon: The topic of studying ethics in AI from the developers' viewpoint presents a distinctly socio-technical phenomenon, where "the social and technical aspects are interwoven in a way that studying one without due consideration of the other makes for an incomplete investigation and understanding" [10].

(p9.2) • Socio-technical domain and actors: Our domain of investigation was artificial intelligence, and we were ("ethic*" OR "moral*" OR "fairness") AND Snowballing applied in later iterations ("artificial intelligence" OR "AI" OR "machine learning" OR "data science") AND ("software developer" OR "software practitioner" OR "programmer")

(p9.3) We applied Socio-Technical Grounded Theory (STGT) to conduct our review because its socio-technical research framework is customised to fit the unique socio-technical contexts of domains such as software engineering and artificial intelligence [10].

(p9.4) • Socio-technical phenomenon: The topic of studying ethics in AI from the developers' viewpoint presents a distinctly socio-technical phenomenon, where "the social and technical aspects are interwoven in a way that studying one without due consideration of the other makes for an incomplete investigation and understanding" [10].

(p9.5) • Socio-technical domain and actors: Our domain of investigation was artificial intelligence, and we were ("ethic*" OR "moral*" OR "fairness") AND Snowballing applied in later iterations ("artificial intelligence" OR "AI" OR "machine learning" OR "data science") AND ("software developer" OR "software practitioner" OR "programmer")
## (s10) Inclusion Criteria
(p10.0) Each study must be a full text published journal article or Each study must be a full text published journal article, conference paper conference paper, students' thesis, report or paper on arXiv STGT includes basic data analysis procedures such as open coding, constant comparison, and memoing that are common to all GT variants and advanced data analysis procedures such as options of targeted data collection and analysis (DCA) and theoretical structuring or structured DCA and theoretical integration, depending on the researchers' choice of emergent or structured modes of theory development respectively [10]. In our ST-GTLR, we applied open coding, constant comparison, memoing in the basic stage and targeted DCA and theoretical structuring in the advanced stages using the emergent mode of theory development.

(p10.1) The qualitative data included primarily the context and findings covered in the primary studies, including excerpts of raw underlying empirical data included in the papers. Data was analysed iteratively in small batches. At first, we analysed the qualitative data of 10 articles that were obtained in the initial phase. We used the standard techniques of STGT data analysis such as open coding, constant comparison, and memoing for those 10 articles and advanced techniques of STGT data analysis such as targeted coding on the rest 20 articles, followed by theoretical structuring. The right-hand side of Figure 1 shows the details of the data analysis in the Analyse stage of the ST-GTLR process, as applied in this study. This approach of data analysis is rigorous and helped us to obtain multidimensional results that were original, relevant and dense, as evidenced by the depth of the categories and underlying concepts (presented in Section 4). The techniques of the STGT data analysis are explained in the following section. We also obtained layered understanding and reflections through reflective practices like memo writing, which are presented in Section 6.

(p10.2) Each study must be a full text published journal article or Each study must be a full text published journal article, conference paper conference paper, students' thesis, report or paper on arXiv STGT includes basic data analysis procedures such as open coding, constant comparison, and memoing that are common to all GT variants and advanced data analysis procedures such as options of targeted data collection and analysis (DCA) and theoretical structuring or structured DCA and theoretical integration, depending on the researchers' choice of emergent or structured modes of theory development respectively [10]. In our ST-GTLR, we applied open coding, constant comparison, memoing in the basic stage and targeted DCA and theoretical structuring in the advanced stages using the emergent mode of theory development.

(p10.3) The qualitative data included primarily the context and findings covered in the primary studies, including excerpts of raw underlying empirical data included in the papers. Data was analysed iteratively in small batches. At first, we analysed the qualitative data of 10 articles that were obtained in the initial phase. We used the standard techniques of STGT data analysis such as open coding, constant comparison, and memoing for those 10 articles and advanced techniques of STGT data analysis such as targeted coding on the rest 20 articles, followed by theoretical structuring. The right-hand side of Figure 1 shows the details of the data analysis in the Analyse stage of the ST-GTLR process, as applied in this study. This approach of data analysis is rigorous and helped us to obtain multidimensional results that were original, relevant and dense, as evidenced by the depth of the categories and underlying concepts (presented in Section 4). The techniques of the STGT data analysis are explained in the following section. We also obtained layered understanding and reflections through reflective practices like memo writing, which are presented in Section 6.
## (s11) The Basic Stage -Open Coding
(p11.0) We performed open coding to generate codes from the qualitative data of the initial set of 10 articles. Open coding was done for each line of the Findings section of the included articles to ensure we did not miss any information and insights related to our RQ. The length of the qualitative data varied from article to article. For example, some articles had an in-depth and long Findings section whereas some had short sections. Open coding for some articles consumed a lot of time and led to hundreds of codes whereas a limited number of codes were generated for some other articles.

(p11.1) Similar codes were grouped into concepts and similar concepts into categories using constant comparison. Examples of the application of STGT for Data Analysis [10] to generate codes, concepts and categories are exhibited in Figure 2 and a number of quotations from the original papers are included in the Findings section, providing strength of evidence [10]. The process of developing concepts and categories was iterative. As we read more papers, we refined the emerging concepts and categories based on the new insights obtained. The coding was performed by the first author in Google docs to begin with, followed by Google spreadsheet as the number of codes and concepts started growing. Both these formats enabled the ease of reviewing and providing feedback by the second author, and were accompanied by detailed discussions leading to refinements. Each code was numbered as C1,C2,C3 and labelled with the paper ID (e.g. G1, G2, G3) that it belonged to, to enable tracing and improve retrospective comprehension of the underlying contexts.

(p11.2) While the open coding led to valuable results in the form of codes, concepts, and categories, memoing helped us reflect on the insights related to the most prominent codes, concepts, and emerging categories. We also wrote reflective memos to document our reflections on the process of performing an ST-GTLR using an STGT approach. These insights and reflections are presented in Section 6. An example of a memo created for this study is presented in Figure 3.

(p11.3) We performed open coding to generate codes from the qualitative data of the initial set of 10 articles. Open coding was done for each line of the Findings section of the included articles to ensure we did not miss any information and insights related to our RQ. The length of the qualitative data varied from article to article. For example, some articles had an in-depth and long Findings section whereas some had short sections. Open coding for some articles consumed a lot of time and led to hundreds of codes whereas a limited number of codes were generated for some other articles.

(p11.4) Similar codes were grouped into concepts and similar concepts into categories using constant comparison. Examples of the application of STGT for Data Analysis [10] to generate codes, concepts and categories are exhibited in Figure 2 and a number of quotations from the original papers are included in the Findings section, providing strength of evidence [10]. The process of developing concepts and categories was iterative. As we read more papers, we refined the emerging concepts and categories based on the new insights obtained. The coding was performed by the first author in Google docs to begin with, followed by Google spreadsheet as the number of codes and concepts started growing. Both these formats enabled the ease of reviewing and providing feedback by the second author, and were accompanied by detailed discussions leading to refinements. Each code was numbered as C1,C2,C3 and labelled with the paper ID (e.g. G1, G2, G3) that it belonged to, to enable tracing and improve retrospective comprehension of the underlying contexts.

(p11.5) While the open coding led to valuable results in the form of codes, concepts, and categories, memoing helped us reflect on the insights related to the most prominent codes, concepts, and emerging categories. We also wrote reflective memos to document our reflections on the process of performing an ST-GTLR using an STGT approach. These insights and reflections are presented in Section 6. An example of a memo created for this study is presented in Figure 3.
## (s12) Advanced Stage -Theory Development
(p12.0) The codes and concepts generated from open coding in the basic stage led to the emergence of five categories: Developer Awareness, Developer Perception, Developer Needs, Developer Challenges and Developer Approach. Once these categories were generated, we proceeded to identify new papers using forward and backward snowballing in the advanced stage of theory development.

(p12.1) Since our topic under investigation was rather broad to begin with, an emergent mode of theory development seemed appropriate in the next, advanced stage of STGT [10]. This decision was further confirmed as the categories identified were distinct and well supported but the links between them, which define the shape or structure of a theory, were still unclear. We proceeded to iteratively perform targeted data collection and analysis on more papers. Reflections captured through memoing and snowballing served as an application of theoretical sampling when dealing with published literature, similar to how it is applied in primary STGT studies.

(p12.2) Targeted coding involves generating codes that are relevant to the preliminary but strong concepts and categories [10]. For example, see the emergence of a new code cultural norms realisation during targeting coding that supported the concept human limitations, which in turn led to the category Developer Awareness identified in the basic stage, in Figure   2. We performed targeted coding in chunks of two to three sentences or short paragraphs that seemed relevant to our emergent findings, instead of the line by line coding, and continued with constant comparison. This process was a lot faster than open coding. The codes developed using targeted coding were placed under relevant concepts, and new concepts were aligned with existing categories in the same Google spreadsheet.

(p12.3) In this stage, our memos became more advanced in the sense that they helped identify relationships between the categories and develop hypotheses. We continued with targeted data collection and analysis until we reached a point of diminishing results, described as theoretical saturation, where analysing new papers served to validate the emerging theory rather than lead to new insights or categories.

(p12.4) To structure the emergent theory, we made use of a developer's prism metaphor that the research team identified during one of the discussions and coding workshops. A triangular prism is useful for analysing and reflecting light. An ordinary triangular prism can separate white light into its constituent colours, called a spectrum. White light entering a prism is bent, or refracted, and the light separates into its constituent wavelengths, representing red, orange, yellow, green, blue, indigo, and violet. Using the prism metaphor, we see that the topic of ethics in AI looks like a single ray of white light. But, when it is viewed through a developer perspective, i.e., when it enters the developer's prism, the monochromatic ray of white light can be seen to separate into its constituent wavelengths. The wavelengths here refer to the spectrum of five distinct aspects -developer awareness, perception, needs, challenges and approach. In simple words, while the topic of 'ethics in AI' may look like a single phenomenon, seen from the developer's prism, it is rather a multi-faceted and complex phenomenon composed of a spectrum of distinct aspects, represented by each of the categories. Figure 4 shows a visual representation of the theory using the developer's prism metaphor.

(p12.5) The codes and concepts generated from open coding in the basic stage led to the emergence of five categories: Developer Awareness, Developer Perception, Developer Needs, Developer Challenges and Developer Approach. Once these categories were generated, we proceeded to identify new papers using forward and backward snowballing in the advanced stage of theory development.

(p12.6) Since our topic under investigation was rather broad to begin with, an emergent mode of theory development seemed appropriate in the next, advanced stage of STGT [10]. This decision was further confirmed as the categories identified were distinct and well supported but the links between them, which define the shape or structure of a theory, were still unclear. We proceeded to iteratively perform targeted data collection and analysis on more papers. Reflections captured through memoing and snowballing served as an application of theoretical sampling when dealing with published literature, similar to how it is applied in primary STGT studies.

(p12.7) Targeted coding involves generating codes that are relevant to the preliminary but strong concepts and categories [10]. For example, see the emergence of a new code cultural norms realisation during targeting coding that supported the concept human limitations, which in turn led to the category Developer Awareness identified in the basic stage, in Figure   2. We performed targeted coding in chunks of two to three sentences or short paragraphs that seemed relevant to our emergent findings, instead of the line by line coding, and continued with constant comparison. This process was a lot faster than open coding. The codes developed using targeted coding were placed under relevant concepts, and new concepts were aligned with existing categories in the same Google spreadsheet.

(p12.8) In this stage, our memos became more advanced in the sense that they helped identify relationships between the categories and develop hypotheses. We continued with targeted data collection and analysis until we reached a point of diminishing results, described as theoretical saturation, where analysing new papers served to validate the emerging theory rather than lead to new insights or categories.

(p12.9) To structure the emergent theory, we made use of a developer's prism metaphor that the research team identified during one of the discussions and coding workshops. A triangular prism is useful for analysing and reflecting light. An ordinary triangular prism can separate white light into its constituent colours, called a spectrum. White light entering a prism is bent, or refracted, and the light separates into its constituent wavelengths, representing red, orange, yellow, green, blue, indigo, and violet. Using the prism metaphor, we see that the topic of ethics in AI looks like a single ray of white light. But, when it is viewed through a developer perspective, i.e., when it enters the developer's prism, the monochromatic ray of white light can be seen to separate into its constituent wavelengths. The wavelengths here refer to the spectrum of five distinct aspects -developer awareness, perception, needs, challenges and approach. In simple words, while the topic of 'ethics in AI' may look like a single phenomenon, seen from the developer's prism, it is rather a multi-faceted and complex phenomenon composed of a spectrum of distinct aspects, represented by each of the categories. Figure 4 shows a visual representation of the theory using the developer's prism metaphor.
## (s13) Present
(p13.0) The last step of the ST-GTLR process is to present the findings. The key findings are presented through textual descriptions accompanied by original quotations from the included primary studies. Furthermore, Wolfswinkel et al. recommends, "presenting findings using visualisations such as diagrams can help reach a wider audience" [11]. To visualise the findings of the 30 primary empirical studies, we created model diagrams (Figures 4 and 5).

(p13.1) The last step of the ST-GTLR process is to present the findings. The key findings are presented through textual descriptions accompanied by original quotations from the included primary studies. Furthermore, Wolfswinkel et al. recommends, "presenting findings using visualisations such as diagrams can help reach a wider audience" [11]. To visualise the findings of the 30 primary empirical studies, we created model diagrams (Figures 4 and 5).
## (s56) THREATS AND LIMITATIONS
(p56.0) We now discuss some of the threats and limitations of our study. Unlike an SLR, an ST-GTLR study does not aim to achieve completeness. Rather, it focuses on capturing the 'lay of the land' through identifying the key aspects of the topic and presenting rich explanations and nuanced insights. As such, while the process of an ST-GTLR can be replicated, the results -the resulting descriptive findings and hypotheses -are not easily reproducible. Furthermore, our search and select steps for identifying the seed papers and subsequent snowballing may have resulted in missing some relevant papers. This threat is highly dependent on the list of keywords selected for the study and the limitations of the search engines. To minimise the risk of this threat, we used an iterative approach to develop the search strings for the study. Initially, we chose the key terms from our research title and added their synonyms to develop the final search strings which returned the most relevant studies. For example, we included 'fairness' in our final search string because when we used only the term 'ethics', we obtained zero articles in two databases (ACM DL and Wiley OL). It is one of the limitations of our study because using this term in our search string may have returned the studies focusing on developers' views on the fairness of AI systems.

(p56.1) Finding enough empirical articles related to our research topic was another challenge. Due to this, we relaxed the review protocol during snowballing of articles. This led us to include the articles that were published in venues other than journals and conferences. We also had to use studies uploaded on ArXiv as our seed papers due to the lack of enough peer-reviewed studies relevant to our research topic. Given the increasing trend of researchers sharing their manuscripts early on ArXiv while they are still under review, it is a useful resource to find the latest research on emerging topics. The ability to ascertain the authors and their affiliations lends credibility to the source. Direct citations to ArXiv has increased steadily from 2000 to 2013 in Scopus indexed scholarly publications. For example, ArXiv has been cited the most by mathematics [41].

(p56.2) When applying the STGT approach [10] to analyse the qualitative data of primary studies, we performed open coding and targeted coding only on the Findings sections of the studies that presented the empirical evidence we were interested in. We did not find examples of tools (software/framework/models) that AI developers use to implement ethics in AI. A study [G10] mentioned that there is an existence of various tools to enhance AI ethics implementation, however, no details about the tools were mentioned. Following a broad and inductive approach, we were not specifically looking for information on tools. However, it was still surprising that not a lot was mentioned by developers in this area. Future reviews and studies can be conducted to understand to what extent, why, and how tools are used in the context of implementing ethics in AI.

(p56.3) To minimise the threats associated with a single coder, the second author regularly reviewed the codes and discussed the coding process. All findings were reviewed and discussed by the four authors regularly who asked critical questions, helping develop nuanced concepts and categories. The hypotheses were derived by analysing the relationships between the five categories based on the empirical findings from 30 primary articles which limits the scope of our theory but it remains open to modification with more empirical evidence in future.

(p56.4) We now discuss some of the threats and limitations of our study. Unlike an SLR, an ST-GTLR study does not aim to achieve completeness. Rather, it focuses on capturing the 'lay of the land' through identifying the key aspects of the topic and presenting rich explanations and nuanced insights. As such, while the process of an ST-GTLR can be replicated, the results -the resulting descriptive findings and hypotheses -are not easily reproducible. Furthermore, our search and select steps for identifying the seed papers and subsequent snowballing may have resulted in missing some relevant papers. This threat is highly dependent on the list of keywords selected for the study and the limitations of the search engines. To minimise the risk of this threat, we used an iterative approach to develop the search strings for the study. Initially, we chose the key terms from our research title and added their synonyms to develop the final search strings which returned the most relevant studies. For example, we included 'fairness' in our final search string because when we used only the term 'ethics', we obtained zero articles in two databases (ACM DL and Wiley OL). It is one of the limitations of our study because using this term in our search string may have returned the studies focusing on developers' views on the fairness of AI systems.

(p56.5) Finding enough empirical articles related to our research topic was another challenge. Due to this, we relaxed the review protocol during snowballing of articles. This led us to include the articles that were published in venues other than journals and conferences. We also had to use studies uploaded on ArXiv as our seed papers due to the lack of enough peer-reviewed studies relevant to our research topic. Given the increasing trend of researchers sharing their manuscripts early on ArXiv while they are still under review, it is a useful resource to find the latest research on emerging topics. The ability to ascertain the authors and their affiliations lends credibility to the source. Direct citations to ArXiv has increased steadily from 2000 to 2013 in Scopus indexed scholarly publications. For example, ArXiv has been cited the most by mathematics [41].

(p56.6) When applying the STGT approach [10] to analyse the qualitative data of primary studies, we performed open coding and targeted coding only on the Findings sections of the studies that presented the empirical evidence we were interested in. We did not find examples of tools (software/framework/models) that AI developers use to implement ethics in AI. A study [G10] mentioned that there is an existence of various tools to enhance AI ethics implementation, however, no details about the tools were mentioned. Following a broad and inductive approach, we were not specifically looking for information on tools. However, it was still surprising that not a lot was mentioned by developers in this area. Future reviews and studies can be conducted to understand to what extent, why, and how tools are used in the context of implementing ethics in AI.

(p56.7) To minimise the threats associated with a single coder, the second author regularly reviewed the codes and discussed the coding process. All findings were reviewed and discussed by the four authors regularly who asked critical questions, helping develop nuanced concepts and categories. The hypotheses were derived by analysing the relationships between the five categories based on the empirical findings from 30 primary articles which limits the scope of our theory but it remains open to modification with more empirical evidence in future.
## (s57) CONCLUSION AND FUTURE WORK
(p57.0) AI systems are as ethical as the humans developing them. It is critical to understand how the humans in the trenches, the AI developers, view the topic of ethics in AI if we are to a lay firm theoretical foundation for future work in this area. With this in mind, we formulated the research question: What do we know from literature about how developers view ethics in AI? To address this, we conducted a sociotechnical grounded theory literature review (ST-GTLR) by applying the overarching framework of grounded theory literature review (GTLR) introduced by Wolfswinkel et al. [11] with the concrete steps of the socio-technical grounded theory (STGT) method for data analysis and theory development [10], on 30 primary empirical studies. Since there were not many empirical studies addressing our niche topic and RQ exclusively, a grounded theory-based iterative and responsive review approach worked well to identify and extract relevant content from across multiple studies (that mainly focused on related topics), while the application of STGT enabled rigour analysis and theory development. A contribution of this paper is the ST-GTLR guidelines for conducting review studies in software engineering, especially on niche and emerging topics.

(p57.1) Through applying STGT's basic stage, we identified five categories of developer awareness, developer perception, developer challenges, developer challenges, and developer needs. Through applying its emergent theory development mode, we identified five hypotheses that link the categories: H1: developer awareness is an antecedent to, but does not guarantee positive, developer perception; H2: developer awareness can lead to identifying developer needs; H3: developer challenges lead to identifying developer needs; H4: developer perception can generate developer approach; H5: developer challenges can be overcome by developer approach. Taken together, the categories and hypotheses form the theory of ethics in AI through the developer's prism that explains the seemingly single phenomenon of ethics in AI as a complex set of interrelated phenomena using the developer's prism metaphor. The theory explains that developers' awareness of AI ethics directly leads to their perception about AI ethics and its implementation as well as to identifying their needs, and indirectly leads to identifying their challenges and coming up with approaches (applied and potential strategies) to overcome them.

(p57.2) We also share practical recommendations for AI developers, managers, and organisations. The theory serves as a research agenda for the community, where future work can focus on investigating and explaining each of the phenomena of developer awareness, perception, challenges, needs, and approach. Future empirical studies can focus on improving the understanding and implementation of ethics in AI and recommend practical approaches to minimise ethical issues such as mitigating human biases in AI development through frameworks and tools development.

(p57.3) AI systems are as ethical as the humans developing them. It is critical to understand how the humans in the trenches, the AI developers, view the topic of ethics in AI if we are to a lay firm theoretical foundation for future work in this area. With this in mind, we formulated the research question: What do we know from literature about how developers view ethics in AI? To address this, we conducted a sociotechnical grounded theory literature review (ST-GTLR) by applying the overarching framework of grounded theory literature review (GTLR) introduced by Wolfswinkel et al. [11] with the concrete steps of the socio-technical grounded theory (STGT) method for data analysis and theory development [10], on 30 primary empirical studies. Since there were not many empirical studies addressing our niche topic and RQ exclusively, a grounded theory-based iterative and responsive review approach worked well to identify and extract relevant content from across multiple studies (that mainly focused on related topics), while the application of STGT enabled rigour analysis and theory development. A contribution of this paper is the ST-GTLR guidelines for conducting review studies in software engineering, especially on niche and emerging topics.

(p57.4) Through applying STGT's basic stage, we identified five categories of developer awareness, developer perception, developer challenges, developer challenges, and developer needs. Through applying its emergent theory development mode, we identified five hypotheses that link the categories: H1: developer awareness is an antecedent to, but does not guarantee positive, developer perception; H2: developer awareness can lead to identifying developer needs; H3: developer challenges lead to identifying developer needs; H4: developer perception can generate developer approach; H5: developer challenges can be overcome by developer approach. Taken together, the categories and hypotheses form the theory of ethics in AI through the developer's prism that explains the seemingly single phenomenon of ethics in AI as a complex set of interrelated phenomena using the developer's prism metaphor. The theory explains that developers' awareness of AI ethics directly leads to their perception about AI ethics and its implementation as well as to identifying their needs, and indirectly leads to identifying their challenges and coming up with approaches (applied and potential strategies) to overcome them.

(p57.5) We also share practical recommendations for AI developers, managers, and organisations. The theory serves as a research agenda for the community, where future work can focus on investigating and explaining each of the phenomena of developer awareness, perception, challenges, needs, and approach. Future empirical studies can focus on improving the understanding and implementation of ethics in AI and recommend practical approaches to minimise ethical issues such as mitigating human biases in AI development through frameworks and tools development.
## (s69) Socio-Technical Grounded Theory Literature Review
(p69.0) (ST-GTLR) is an iterative and responsive literature review method that applies the five-step framework of define, search, select, analyse and present described in the original GTLR guidelines by Wolfswinkel et al. [11] with concrete data analysis (and optional theory development) steps of socio-technical grounded theory [10]. A GTLR is particularly well suited to studying niche and emerging research areas to gain in-depth understanding, establish theoretical foundations, and make practical recommendations.

(p69.1) In this section, we present the guidelines for conducting an ST-GTLR, including a definition of ST-GTLR (see definition box), the context of use, the basic steps and procedures of the ST-GTLR method and a diagram of the ST-GTLR process with elaborated analysis stage ( Figure 1). We also include the details of the application of these guidelines and demonstrate how we conducted the ST-GTLR in the context of our review study.

(p69.2) (ST-GTLR) is an iterative and responsive literature review method that applies the five-step framework of define, search, select, analyse and present described in the original GTLR guidelines by Wolfswinkel et al. [11] with concrete data analysis (and optional theory development) steps of socio-technical grounded theory [10]. A GTLR is particularly well suited to studying niche and emerging research areas to gain in-depth understanding, establish theoretical foundations, and make practical recommendations.

(p69.3) In this section, we present the guidelines for conducting an ST-GTLR, including a definition of ST-GTLR (see definition box), the context of use, the basic steps and procedures of the ST-GTLR method and a diagram of the ST-GTLR process with elaborated analysis stage ( Figure 1). We also include the details of the application of these guidelines and demonstrate how we conducted the ST-GTLR in the context of our review study.
## (s71) Define
(p71.0) The first step is to formulate the initial review protocol, including determining the scope of the study by defining inclusion and/or exclusion criteria, publication period, and search items, followed by databases to search in, research questions, and search strings. Following this approach, we defined our inclusion and exclusion criteria, publication period, language of the articles to be included followed by the guiding research question (RQ), search string and appropriate sources and specific search items with the aim 1. The term 'developers' in our study include AI programmers, practitioners, engineers, specialists, experts, designers, and stakeholders. We use the terms 'AI developers' and 'developers' interchangeably throughout our study.   [10] of obtaining maximum relevant primary empirical studies. The RQ was formulated to gain an overall understanding of ethics in AI from the perspective of AI developers, as:

(p71.1) The first step is to formulate the initial review protocol, including determining the scope of the study by defining inclusion and/or exclusion criteria, publication period, and search items, followed by databases to search in, research questions, and search strings. Following this approach, we defined our inclusion and exclusion criteria, publication period, language of the articles to be included followed by the guiding research question (RQ), search string and appropriate sources and specific search items with the aim 1. The term 'developers' in our study include AI programmers, practitioners, engineers, specialists, experts, designers, and stakeholders. We use the terms 'AI developers' and 'developers' interchangeably throughout our study.   [10] of obtaining maximum relevant primary empirical studies. The RQ was formulated to gain an overall understanding of ethics in AI from the perspective of AI developers, as:
## (s72) What do we know from literature about how developers view ethics in AI?
(p72.0) Four popular digital databases, namely, ACM Digital Library (ACM DL), IEEE Xplore, SpringerLink and Wiley Online Library (Wiley OL) were used as sources to identify the relevant literature. These databases have been regularly used to conduct reviews on human aspects of software engineering, e.g., [35], [36]. Initially, we searched for relevant studies which were published in journals and conferences only and for which full texts were available.

(p72.1) Key terms were selected from the research title to develop search queries. The first key terms were 'ethics' + 'AI' + 'developers' as the aim of our study is to find AI developer's views about ethics in AI. Then, synonyms of the key search terms were used to retrieve more relevant primary studies. The search terms were linked with 'AND' and 'OR' Boolean operators when developing the final search string. The purpose of the 'AND' operator was to concatenate the key terms whereas the 'OR' operator linked the synonyms.  search string: ("ethics" OR "trust" OR "morals" OR "fairness" OR "responsib*") AND ("artificial intelligence" OR "AI" OR "machine learning") AND ("software developer" OR "software practitioner" OR "data scientist" OR "machine learning" OR "software engineer" OR "programmer") Final search string: ("ethic*" OR "moral*" OR "fairness") AND ("artificial intelligence" OR "AI" OR "machine learning" OR "data science") AND ("software developer" OR "software practitioner" OR "programmer") Six candidate search strings were developed and executed on the four online databases before one was finalised. Table 1 shows the initial and the final search strings created for this study. As the finalised search string returned an extremely large number of primary studies (N=9,806), we restricted the publication period from January 2010 to June 2021, in all four databases, as the topic of ethics in AI has been gaining rapid prominence in the last ten years. Table  2 shows the seed protocol of this study, including inclusion and exclusion criteria. For example, an inclusion criterion was that the study should be written in English, and be empirically based, presenting evidence of AI developers' views on ethics in AI. The exclusion criteria included: studies such as workshop articles, short papers which were less than four pages, books, gray literature, theses, unpublished and incomplete work. It also included studies written in language other than English and duplicate articles. Likewise, studies that presented only the concept of ethics in AI without empirical evidence, review papers, and studies discussing topics irrelevant to the RQ were also considered grounds for exclusion.

(p72.2) Four popular digital databases, namely, ACM Digital Library (ACM DL), IEEE Xplore, SpringerLink and Wiley Online Library (Wiley OL) were used as sources to identify the relevant literature. These databases have been regularly used to conduct reviews on human aspects of software engineering, e.g., [35], [36]. Initially, we searched for relevant studies which were published in journals and conferences only and for which full texts were available.

(p72.3) Key terms were selected from the research title to develop search queries. The first key terms were 'ethics' + 'AI' + 'developers' as the aim of our study is to find AI developer's views about ethics in AI. Then, synonyms of the key search terms were used to retrieve more relevant primary studies. The search terms were linked with 'AND' and 'OR' Boolean operators when developing the final search string. The purpose of the 'AND' operator was to concatenate the key terms whereas the 'OR' operator linked the synonyms.  search string: ("ethics" OR "trust" OR "morals" OR "fairness" OR "responsib*") AND ("artificial intelligence" OR "AI" OR "machine learning") AND ("software developer" OR "software practitioner" OR "data scientist" OR "machine learning" OR "software engineer" OR "programmer") Final search string: ("ethic*" OR "moral*" OR "fairness") AND ("artificial intelligence" OR "AI" OR "machine learning" OR "data science") AND ("software developer" OR "software practitioner" OR "programmer") Six candidate search strings were developed and executed on the four online databases before one was finalised. Table 1 shows the initial and the final search strings created for this study. As the finalised search string returned an extremely large number of primary studies (N=9,806), we restricted the publication period from January 2010 to June 2021, in all four databases, as the topic of ethics in AI has been gaining rapid prominence in the last ten years. Table  2 shows the seed protocol of this study, including inclusion and exclusion criteria. For example, an inclusion criterion was that the study should be written in English, and be empirically based, presenting evidence of AI developers' views on ethics in AI. The exclusion criteria included: studies such as workshop articles, short papers which were less than four pages, books, gray literature, theses, unpublished and incomplete work. It also included studies written in language other than English and duplicate articles. Likewise, studies that presented only the concept of ethics in AI without empirical evidence, review papers, and studies discussing topics irrelevant to the RQ were also considered grounds for exclusion.
## (s73) Search
(p73.0) The second stage involves performing the actual search using the review protocol defined in the first stage [11]. We performed the search using our seed review protocol presented in Table 2. The search process was iterative and time-consuming because some essential synonyms of the search terms were missing initially, and we had to revisit the define stage again and again before moving to the next stage (e.g. see the initial and final search strings developed for this study in Table 1).

(p73.1) The second stage involves performing the actual search using the review protocol defined in the first stage [11]. We performed the search using our seed review protocol presented in Table 2. The search process was iterative and time-consuming because some essential synonyms of the search terms were missing initially, and we had to revisit the define stage again and again before moving to the next stage (e.g. see the initial and final search strings developed for this study in Table 1).
## (s74) Select
(p74.0) The selection of sample texts is done in this stage. The steps include (i) filtering out doubles, (ii) refining sample based on title and abstract, (iii) refining sample based on full text, (iv) scanning forward and backward citations, and (v) checking if new articles come up in the last step as these steps are iterative [11]. If new articles come up in the last step, researchers should go to step (i) and follow other steps accordingly. If no new articles come up, then that will be the final sample to be included in the study.

(p74.1) Following these guidelines, we obtained a total of 1,244 primary articles (ACM DL: 273, IEEEX: 355, SpringerLink: 543 and Wiley OL: 73) using the seed review protocol as shown in Table 2 and the final search string. After filtering out the duplicates, we were left with 982 articles. As per the Wolfswinkel et al. guidelines, the next step was to refine the whole sample based on title and abstract. We tried this approach for the first 200 articles each that came up in ACM DL, IEEEX and SpringerLink and all 73 articles in Wiley OL to get a sense of the number of relevant articles to our research question. We read the abstract of the articles whose title seemed relevant to our research topic and tried to apply the inclusion and exclusion criteria (in Table 2) to select the relevant articles. We quickly realised that selection based on title and abstract was not working well. This is because the presence of the key search terms (e.g., ethics AND AI AND developer) was rather common and did not imply that the paper would include the developers' perspective on ethics in AI. We found ourselves having to scan through full texts to judge relevance to our RQ. Despite the effort involved, the return on investment was low, e.g. for every 100 papers read, we found only one or two relevant to our study, i.e., that presented the AI developers' views on ethics in AI.

(p74.2) From a quick reading of 673 papers, we obtained only 10 primary articles that were relevant to our research topic. Many articles, albeit interesting, did not present the AI developers' views on ethics in AI. So, we decided to find more relevant articles through snowballing of articles. Snowballing of those 10 articles via forward citations and backward citations was done until 31 December 2021 to find more relevant articles and enrich the quality. Snowballing seemed to work better for us than the traditional search approach. We modified the seed protocol accordingly, to include papers published in other databases and those published beyond journals and conferences, including students' theses, reports, and papers uploaded to ArXiv. The rest of the protocol remained the same. The final review protocol used in this study is presented in Table 2. In this way, we obtained 20 more relevant articles, taking the total number of primary articles to 30.

(p74.3) The select step of scanning through the full contents of 673 articles was very tedious with very low return on investment (e.g. only 10 relevant studies obtained). In hindsight, we would have done better to start with a set of seed papers that were collectively known to the research team or those obtained from some quick searches on Google Scholar. What we did next by proceeding from the seed papers to cycles of snowballing, was more practical, productive, and in line with the iterative GT approach as a form of applied theoretical sampling.

(p74.4) The selection of sample texts is done in this stage. The steps include (i) filtering out doubles, (ii) refining sample based on title and abstract, (iii) refining sample based on full text, (iv) scanning forward and backward citations, and (v) checking if new articles come up in the last step as these steps are iterative [11]. If new articles come up in the last step, researchers should go to step (i) and follow other steps accordingly. If no new articles come up, then that will be the final sample to be included in the study.

(p74.5) Following these guidelines, we obtained a total of 1,244 primary articles (ACM DL: 273, IEEEX: 355, SpringerLink: 543 and Wiley OL: 73) using the seed review protocol as shown in Table 2 and the final search string. After filtering out the duplicates, we were left with 982 articles. As per the Wolfswinkel et al. guidelines, the next step was to refine the whole sample based on title and abstract. We tried this approach for the first 200 articles each that came up in ACM DL, IEEEX and SpringerLink and all 73 articles in Wiley OL to get a sense of the number of relevant articles to our research question. We read the abstract of the articles whose title seemed relevant to our research topic and tried to apply the inclusion and exclusion criteria (in Table 2) to select the relevant articles. We quickly realised that selection based on title and abstract was not working well. This is because the presence of the key search terms (e.g., ethics AND AI AND developer) was rather common and did not imply that the paper would include the developers' perspective on ethics in AI. We found ourselves having to scan through full texts to judge relevance to our RQ. Despite the effort involved, the return on investment was low, e.g. for every 100 papers read, we found only one or two relevant to our study, i.e., that presented the AI developers' views on ethics in AI.

(p74.6) From a quick reading of 673 papers, we obtained only 10 primary articles that were relevant to our research topic. Many articles, albeit interesting, did not present the AI developers' views on ethics in AI. So, we decided to find more relevant articles through snowballing of articles. Snowballing of those 10 articles via forward citations and backward citations was done until 31 December 2021 to find more relevant articles and enrich the quality. Snowballing seemed to work better for us than the traditional search approach. We modified the seed protocol accordingly, to include papers published in other databases and those published beyond journals and conferences, including students' theses, reports, and papers uploaded to ArXiv. The rest of the protocol remained the same. The final review protocol used in this study is presented in Table 2. In this way, we obtained 20 more relevant articles, taking the total number of primary articles to 30.

(p74.7) The select step of scanning through the full contents of 673 articles was very tedious with very low return on investment (e.g. only 10 relevant studies obtained). In hindsight, we would have done better to start with a set of seed papers that were collectively known to the research team or those obtained from some quick searches on Google Scholar. What we did next by proceeding from the seed papers to cycles of snowballing, was more practical, productive, and in line with the iterative GT approach as a form of applied theoretical sampling.
## (s75) Analyse
(p75.0) We applied Socio-Technical Grounded Theory (STGT) to conduct our review because its socio-technical research framework is customised to fit the unique socio-technical contexts of domains such as software engineering and artificial intelligence [10].

(p75.1) • Socio-technical phenomenon: The topic of studying ethics in AI from the developers' viewpoint presents a distinctly socio-technical phenomenon, where "the social and technical aspects are interwoven in a way that studying one without due consideration of the other makes for an incomplete investigation and understanding" [10].

(p75.2) • Socio-technical domain and actors: Our domain of investigation was artificial intelligence, and we were ("ethic*" OR "moral*" OR "fairness") AND Snowballing applied in later iterations ("artificial intelligence" OR "AI" OR "machine learning" OR "data science") AND ("software developer" OR "software practitioner" OR "programmer")

(p75.3) We applied Socio-Technical Grounded Theory (STGT) to conduct our review because its socio-technical research framework is customised to fit the unique socio-technical contexts of domains such as software engineering and artificial intelligence [10].

(p75.4) • Socio-technical phenomenon: The topic of studying ethics in AI from the developers' viewpoint presents a distinctly socio-technical phenomenon, where "the social and technical aspects are interwoven in a way that studying one without due consideration of the other makes for an incomplete investigation and understanding" [10].

(p75.5) • Socio-technical domain and actors: Our domain of investigation was artificial intelligence, and we were ("ethic*" OR "moral*" OR "fairness") AND Snowballing applied in later iterations ("artificial intelligence" OR "AI" OR "machine learning" OR "data science") AND ("software developer" OR "software practitioner" OR "programmer")
## (s76) Inclusion Criteria
(p76.0) Each study must be a full text published journal article or Each study must be a full text published journal article, conference paper conference paper, students' thesis, report or paper on arXiv STGT includes basic data analysis procedures such as open coding, constant comparison, and memoing that are common to all GT variants and advanced data analysis procedures such as options of targeted data collection and analysis (DCA) and theoretical structuring or structured DCA and theoretical integration, depending on the researchers' choice of emergent or structured modes of theory development respectively [10]. In our ST-GTLR, we applied open coding, constant comparison, memoing in the basic stage and targeted DCA and theoretical structuring in the advanced stages using the emergent mode of theory development.

(p76.1) The qualitative data included primarily the context and findings covered in the primary studies, including excerpts of raw underlying empirical data included in the papers. Data was analysed iteratively in small batches. At first, we analysed the qualitative data of 10 articles that were obtained in the initial phase. We used the standard techniques of STGT data analysis such as open coding, constant comparison, and memoing for those 10 articles and advanced techniques of STGT data analysis such as targeted coding on the rest 20 articles, followed by theoretical structuring. The right-hand side of Figure 1 shows the details of the data analysis in the Analyse stage of the ST-GTLR process, as applied in this study. This approach of data analysis is rigorous and helped us to obtain multidimensional results that were original, relevant and dense, as evidenced by the depth of the categories and underlying concepts (presented in Section 4). The techniques of the STGT data analysis are explained in the following section. We also obtained layered understanding and reflections through reflective practices like memo writing, which are presented in Section 6.

(p76.2) Each study must be a full text published journal article or Each study must be a full text published journal article, conference paper conference paper, students' thesis, report or paper on arXiv STGT includes basic data analysis procedures such as open coding, constant comparison, and memoing that are common to all GT variants and advanced data analysis procedures such as options of targeted data collection and analysis (DCA) and theoretical structuring or structured DCA and theoretical integration, depending on the researchers' choice of emergent or structured modes of theory development respectively [10]. In our ST-GTLR, we applied open coding, constant comparison, memoing in the basic stage and targeted DCA and theoretical structuring in the advanced stages using the emergent mode of theory development.

(p76.3) The qualitative data included primarily the context and findings covered in the primary studies, including excerpts of raw underlying empirical data included in the papers. Data was analysed iteratively in small batches. At first, we analysed the qualitative data of 10 articles that were obtained in the initial phase. We used the standard techniques of STGT data analysis such as open coding, constant comparison, and memoing for those 10 articles and advanced techniques of STGT data analysis such as targeted coding on the rest 20 articles, followed by theoretical structuring. The right-hand side of Figure 1 shows the details of the data analysis in the Analyse stage of the ST-GTLR process, as applied in this study. This approach of data analysis is rigorous and helped us to obtain multidimensional results that were original, relevant and dense, as evidenced by the depth of the categories and underlying concepts (presented in Section 4). The techniques of the STGT data analysis are explained in the following section. We also obtained layered understanding and reflections through reflective practices like memo writing, which are presented in Section 6.
## (s77) The Basic Stage -Open Coding
(p77.0) We performed open coding to generate codes from the qualitative data of the initial set of 10 articles. Open coding was done for each line of the Findings section of the included articles to ensure we did not miss any information and insights related to our RQ. The length of the qualitative data varied from article to article. For example, some articles had an in-depth and long Findings section whereas some had short sections. Open coding for some articles consumed a lot of time and led to hundreds of codes whereas a limited number of codes were generated for some other articles.

(p77.1) Similar codes were grouped into concepts and similar concepts into categories using constant comparison. Examples of the application of STGT for Data Analysis [10] to generate codes, concepts and categories are exhibited in Figure 2 and a number of quotations from the original papers are included in the Findings section, providing strength of evidence [10]. The process of developing concepts and categories was iterative. As we read more papers, we refined the emerging concepts and categories based on the new insights obtained. The coding was performed by the first author in Google docs to begin with, followed by Google spreadsheet as the number of codes and concepts started growing. Both these formats enabled the ease of reviewing and providing feedback by the second author, and were accompanied by detailed discussions leading to refinements. Each code was numbered as C1,C2,C3 and labelled with the paper ID (e.g. G1, G2, G3) that it belonged to, to enable tracing and improve retrospective comprehension of the underlying contexts.

(p77.2) While the open coding led to valuable results in the form of codes, concepts, and categories, memoing helped us reflect on the insights related to the most prominent codes, concepts, and emerging categories. We also wrote reflective memos to document our reflections on the process of performing an ST-GTLR using an STGT approach. These insights and reflections are presented in Section 6. An example of a memo created for this study is presented in Figure 3.

(p77.3) We performed open coding to generate codes from the qualitative data of the initial set of 10 articles. Open coding was done for each line of the Findings section of the included articles to ensure we did not miss any information and insights related to our RQ. The length of the qualitative data varied from article to article. For example, some articles had an in-depth and long Findings section whereas some had short sections. Open coding for some articles consumed a lot of time and led to hundreds of codes whereas a limited number of codes were generated for some other articles.

(p77.4) Similar codes were grouped into concepts and similar concepts into categories using constant comparison. Examples of the application of STGT for Data Analysis [10] to generate codes, concepts and categories are exhibited in Figure 2 and a number of quotations from the original papers are included in the Findings section, providing strength of evidence [10]. The process of developing concepts and categories was iterative. As we read more papers, we refined the emerging concepts and categories based on the new insights obtained. The coding was performed by the first author in Google docs to begin with, followed by Google spreadsheet as the number of codes and concepts started growing. Both these formats enabled the ease of reviewing and providing feedback by the second author, and were accompanied by detailed discussions leading to refinements. Each code was numbered as C1,C2,C3 and labelled with the paper ID (e.g. G1, G2, G3) that it belonged to, to enable tracing and improve retrospective comprehension of the underlying contexts.

(p77.5) While the open coding led to valuable results in the form of codes, concepts, and categories, memoing helped us reflect on the insights related to the most prominent codes, concepts, and emerging categories. We also wrote reflective memos to document our reflections on the process of performing an ST-GTLR using an STGT approach. These insights and reflections are presented in Section 6. An example of a memo created for this study is presented in Figure 3.
## (s78) Advanced Stage -Theory Development
(p78.0) The codes and concepts generated from open coding in the basic stage led to the emergence of five categories: Developer Awareness, Developer Perception, Developer Needs, Developer Challenges and Developer Approach. Once these categories were generated, we proceeded to identify new papers using forward and backward snowballing in the advanced stage of theory development.

(p78.1) Since our topic under investigation was rather broad to begin with, an emergent mode of theory development seemed appropriate in the next, advanced stage of STGT [10]. This decision was further confirmed as the categories identified were distinct and well supported but the links between them, which define the shape or structure of a theory, were still unclear. We proceeded to iteratively perform targeted data collection and analysis on more papers. Reflections captured through memoing and snowballing served as an application of theoretical sampling when dealing with published literature, similar to how it is applied in primary STGT studies.

(p78.2) Targeted coding involves generating codes that are relevant to the preliminary but strong concepts and categories [10]. For example, see the emergence of a new code cultural norms realisation during targeting coding that supported the concept human limitations, which in turn led to the category Developer Awareness identified in the basic stage, in Figure   2. We performed targeted coding in chunks of two to three sentences or short paragraphs that seemed relevant to our emergent findings, instead of the line by line coding, and continued with constant comparison. This process was a lot faster than open coding. The codes developed using targeted coding were placed under relevant concepts, and new concepts were aligned with existing categories in the same Google spreadsheet.

(p78.3) In this stage, our memos became more advanced in the sense that they helped identify relationships between the categories and develop hypotheses. We continued with targeted data collection and analysis until we reached a point of diminishing results, described as theoretical saturation, where analysing new papers served to validate the emerging theory rather than lead to new insights or categories.

(p78.4) To structure the emergent theory, we made use of a developer's prism metaphor that the research team identified during one of the discussions and coding workshops. A triangular prism is useful for analysing and reflecting light. An ordinary triangular prism can separate white light into its constituent colours, called a spectrum. White light entering a prism is bent, or refracted, and the light separates into its constituent wavelengths, representing red, orange, yellow, green, blue, indigo, and violet. Using the prism metaphor, we see that the topic of ethics in AI looks like a single ray of white light. But, when it is viewed through a developer perspective, i.e., when it enters the developer's prism, the monochromatic ray of white light can be seen to separate into its constituent wavelengths. The wavelengths here refer to the spectrum of five distinct aspects -developer awareness, perception, needs, challenges and approach. In simple words, while the topic of 'ethics in AI' may look like a single phenomenon, seen from the developer's prism, it is rather a multi-faceted and complex phenomenon composed of a spectrum of distinct aspects, represented by each of the categories. Figure 4 shows a visual representation of the theory using the developer's prism metaphor.

(p78.5) The codes and concepts generated from open coding in the basic stage led to the emergence of five categories: Developer Awareness, Developer Perception, Developer Needs, Developer Challenges and Developer Approach. Once these categories were generated, we proceeded to identify new papers using forward and backward snowballing in the advanced stage of theory development.

(p78.6) Since our topic under investigation was rather broad to begin with, an emergent mode of theory development seemed appropriate in the next, advanced stage of STGT [10]. This decision was further confirmed as the categories identified were distinct and well supported but the links between them, which define the shape or structure of a theory, were still unclear. We proceeded to iteratively perform targeted data collection and analysis on more papers. Reflections captured through memoing and snowballing served as an application of theoretical sampling when dealing with published literature, similar to how it is applied in primary STGT studies.

(p78.7) Targeted coding involves generating codes that are relevant to the preliminary but strong concepts and categories [10]. For example, see the emergence of a new code cultural norms realisation during targeting coding that supported the concept human limitations, which in turn led to the category Developer Awareness identified in the basic stage, in Figure   2. We performed targeted coding in chunks of two to three sentences or short paragraphs that seemed relevant to our emergent findings, instead of the line by line coding, and continued with constant comparison. This process was a lot faster than open coding. The codes developed using targeted coding were placed under relevant concepts, and new concepts were aligned with existing categories in the same Google spreadsheet.

(p78.8) In this stage, our memos became more advanced in the sense that they helped identify relationships between the categories and develop hypotheses. We continued with targeted data collection and analysis until we reached a point of diminishing results, described as theoretical saturation, where analysing new papers served to validate the emerging theory rather than lead to new insights or categories.

(p78.9) To structure the emergent theory, we made use of a developer's prism metaphor that the research team identified during one of the discussions and coding workshops. A triangular prism is useful for analysing and reflecting light. An ordinary triangular prism can separate white light into its constituent colours, called a spectrum. White light entering a prism is bent, or refracted, and the light separates into its constituent wavelengths, representing red, orange, yellow, green, blue, indigo, and violet. Using the prism metaphor, we see that the topic of ethics in AI looks like a single ray of white light. But, when it is viewed through a developer perspective, i.e., when it enters the developer's prism, the monochromatic ray of white light can be seen to separate into its constituent wavelengths. The wavelengths here refer to the spectrum of five distinct aspects -developer awareness, perception, needs, challenges and approach. In simple words, while the topic of 'ethics in AI' may look like a single phenomenon, seen from the developer's prism, it is rather a multi-faceted and complex phenomenon composed of a spectrum of distinct aspects, represented by each of the categories. Figure 4 shows a visual representation of the theory using the developer's prism metaphor.
## (s79) Present
(p79.0) The last step of the ST-GTLR process is to present the findings. The key findings are presented through textual descriptions accompanied by original quotations from the included primary studies. Furthermore, Wolfswinkel et al. recommends, "presenting findings using visualisations such as diagrams can help reach a wider audience" [11]. To visualise the findings of the 30 primary empirical studies, we created model diagrams (Figures 4 and 5).

(p79.1) The last step of the ST-GTLR process is to present the findings. The key findings are presented through textual descriptions accompanied by original quotations from the included primary studies. Furthermore, Wolfswinkel et al. recommends, "presenting findings using visualisations such as diagrams can help reach a wider audience" [11]. To visualise the findings of the 30 primary empirical studies, we created model diagrams (Figures 4 and 5).
## (s122) THREATS AND LIMITATIONS
(p122.0) We now discuss some of the threats and limitations of our study. Unlike an SLR, an ST-GTLR study does not aim to achieve completeness. Rather, it focuses on capturing the 'lay of the land' through identifying the key aspects of the topic and presenting rich explanations and nuanced insights. As such, while the process of an ST-GTLR can be replicated, the results -the resulting descriptive findings and hypotheses -are not easily reproducible. Furthermore, our search and select steps for identifying the seed papers and subsequent snowballing may have resulted in missing some relevant papers. This threat is highly dependent on the list of keywords selected for the study and the limitations of the search engines. To minimise the risk of this threat, we used an iterative approach to develop the search strings for the study. Initially, we chose the key terms from our research title and added their synonyms to develop the final search strings which returned the most relevant studies. For example, we included 'fairness' in our final search string because when we used only the term 'ethics', we obtained zero articles in two databases (ACM DL and Wiley OL). It is one of the limitations of our study because using this term in our search string may have returned the studies focusing on developers' views on the fairness of AI systems.

(p122.1) Finding enough empirical articles related to our research topic was another challenge. Due to this, we relaxed the review protocol during snowballing of articles. This led us to include the articles that were published in venues other than journals and conferences. We also had to use studies uploaded on ArXiv as our seed papers due to the lack of enough peer-reviewed studies relevant to our research topic. Given the increasing trend of researchers sharing their manuscripts early on ArXiv while they are still under review, it is a useful resource to find the latest research on emerging topics. The ability to ascertain the authors and their affiliations lends credibility to the source. Direct citations to ArXiv has increased steadily from 2000 to 2013 in Scopus indexed scholarly publications. For example, ArXiv has been cited the most by mathematics [41].

(p122.2) When applying the STGT approach [10] to analyse the qualitative data of primary studies, we performed open coding and targeted coding only on the Findings sections of the studies that presented the empirical evidence we were interested in. We did not find examples of tools (software/framework/models) that AI developers use to implement ethics in AI. A study [G10] mentioned that there is an existence of various tools to enhance AI ethics implementation, however, no details about the tools were mentioned. Following a broad and inductive approach, we were not specifically looking for information on tools. However, it was still surprising that not a lot was mentioned by developers in this area. Future reviews and studies can be conducted to understand to what extent, why, and how tools are used in the context of implementing ethics in AI.

(p122.3) To minimise the threats associated with a single coder, the second author regularly reviewed the codes and discussed the coding process. All findings were reviewed and discussed by the four authors regularly who asked critical questions, helping develop nuanced concepts and categories. The hypotheses were derived by analysing the relationships between the five categories based on the empirical findings from 30 primary articles which limits the scope of our theory but it remains open to modification with more empirical evidence in future.

(p122.4) We now discuss some of the threats and limitations of our study. Unlike an SLR, an ST-GTLR study does not aim to achieve completeness. Rather, it focuses on capturing the 'lay of the land' through identifying the key aspects of the topic and presenting rich explanations and nuanced insights. As such, while the process of an ST-GTLR can be replicated, the results -the resulting descriptive findings and hypotheses -are not easily reproducible. Furthermore, our search and select steps for identifying the seed papers and subsequent snowballing may have resulted in missing some relevant papers. This threat is highly dependent on the list of keywords selected for the study and the limitations of the search engines. To minimise the risk of this threat, we used an iterative approach to develop the search strings for the study. Initially, we chose the key terms from our research title and added their synonyms to develop the final search strings which returned the most relevant studies. For example, we included 'fairness' in our final search string because when we used only the term 'ethics', we obtained zero articles in two databases (ACM DL and Wiley OL). It is one of the limitations of our study because using this term in our search string may have returned the studies focusing on developers' views on the fairness of AI systems.

(p122.5) Finding enough empirical articles related to our research topic was another challenge. Due to this, we relaxed the review protocol during snowballing of articles. This led us to include the articles that were published in venues other than journals and conferences. We also had to use studies uploaded on ArXiv as our seed papers due to the lack of enough peer-reviewed studies relevant to our research topic. Given the increasing trend of researchers sharing their manuscripts early on ArXiv while they are still under review, it is a useful resource to find the latest research on emerging topics. The ability to ascertain the authors and their affiliations lends credibility to the source. Direct citations to ArXiv has increased steadily from 2000 to 2013 in Scopus indexed scholarly publications. For example, ArXiv has been cited the most by mathematics [41].

(p122.6) When applying the STGT approach [10] to analyse the qualitative data of primary studies, we performed open coding and targeted coding only on the Findings sections of the studies that presented the empirical evidence we were interested in. We did not find examples of tools (software/framework/models) that AI developers use to implement ethics in AI. A study [G10] mentioned that there is an existence of various tools to enhance AI ethics implementation, however, no details about the tools were mentioned. Following a broad and inductive approach, we were not specifically looking for information on tools. However, it was still surprising that not a lot was mentioned by developers in this area. Future reviews and studies can be conducted to understand to what extent, why, and how tools are used in the context of implementing ethics in AI.

(p122.7) To minimise the threats associated with a single coder, the second author regularly reviewed the codes and discussed the coding process. All findings were reviewed and discussed by the four authors regularly who asked critical questions, helping develop nuanced concepts and categories. The hypotheses were derived by analysing the relationships between the five categories based on the empirical findings from 30 primary articles which limits the scope of our theory but it remains open to modification with more empirical evidence in future.
## (s123) CONCLUSION AND FUTURE WORK
(p123.0) AI systems are as ethical as the humans developing them. It is critical to understand how the humans in the trenches, the AI developers, view the topic of ethics in AI if we are to a lay firm theoretical foundation for future work in this area. With this in mind, we formulated the research question: What do we know from literature about how developers view ethics in AI? To address this, we conducted a sociotechnical grounded theory literature review (ST-GTLR) by applying the overarching framework of grounded theory literature review (GTLR) introduced by Wolfswinkel et al. [11] with the concrete steps of the socio-technical grounded theory (STGT) method for data analysis and theory development [10], on 30 primary empirical studies. Since there were not many empirical studies addressing our niche topic and RQ exclusively, a grounded theory-based iterative and responsive review approach worked well to identify and extract relevant content from across multiple studies (that mainly focused on related topics), while the application of STGT enabled rigour analysis and theory development. A contribution of this paper is the ST-GTLR guidelines for conducting review studies in software engineering, especially on niche and emerging topics.

(p123.1) Through applying STGT's basic stage, we identified five categories of developer awareness, developer perception, developer challenges, developer challenges, and developer needs. Through applying its emergent theory development mode, we identified five hypotheses that link the categories: H1: developer awareness is an antecedent to, but does not guarantee positive, developer perception; H2: developer awareness can lead to identifying developer needs; H3: developer challenges lead to identifying developer needs; H4: developer perception can generate developer approach; H5: developer challenges can be overcome by developer approach. Taken together, the categories and hypotheses form the theory of ethics in AI through the developer's prism that explains the seemingly single phenomenon of ethics in AI as a complex set of interrelated phenomena using the developer's prism metaphor. The theory explains that developers' awareness of AI ethics directly leads to their perception about AI ethics and its implementation as well as to identifying their needs, and indirectly leads to identifying their challenges and coming up with approaches (applied and potential strategies) to overcome them.

(p123.2) We also share practical recommendations for AI developers, managers, and organisations. The theory serves as a research agenda for the community, where future work can focus on investigating and explaining each of the phenomena of developer awareness, perception, challenges, needs, and approach. Future empirical studies can focus on improving the understanding and implementation of ethics in AI and recommend practical approaches to minimise ethical issues such as mitigating human biases in AI development through frameworks and tools development.

(p123.3) AI systems are as ethical as the humans developing them. It is critical to understand how the humans in the trenches, the AI developers, view the topic of ethics in AI if we are to a lay firm theoretical foundation for future work in this area. With this in mind, we formulated the research question: What do we know from literature about how developers view ethics in AI? To address this, we conducted a sociotechnical grounded theory literature review (ST-GTLR) by applying the overarching framework of grounded theory literature review (GTLR) introduced by Wolfswinkel et al. [11] with the concrete steps of the socio-technical grounded theory (STGT) method for data analysis and theory development [10], on 30 primary empirical studies. Since there were not many empirical studies addressing our niche topic and RQ exclusively, a grounded theory-based iterative and responsive review approach worked well to identify and extract relevant content from across multiple studies (that mainly focused on related topics), while the application of STGT enabled rigour analysis and theory development. A contribution of this paper is the ST-GTLR guidelines for conducting review studies in software engineering, especially on niche and emerging topics.

(p123.4) Through applying STGT's basic stage, we identified five categories of developer awareness, developer perception, developer challenges, developer challenges, and developer needs. Through applying its emergent theory development mode, we identified five hypotheses that link the categories: H1: developer awareness is an antecedent to, but does not guarantee positive, developer perception; H2: developer awareness can lead to identifying developer needs; H3: developer challenges lead to identifying developer needs; H4: developer perception can generate developer approach; H5: developer challenges can be overcome by developer approach. Taken together, the categories and hypotheses form the theory of ethics in AI through the developer's prism that explains the seemingly single phenomenon of ethics in AI as a complex set of interrelated phenomena using the developer's prism metaphor. The theory explains that developers' awareness of AI ethics directly leads to their perception about AI ethics and its implementation as well as to identifying their needs, and indirectly leads to identifying their challenges and coming up with approaches (applied and potential strategies) to overcome them.

(p123.5) We also share practical recommendations for AI developers, managers, and organisations. The theory serves as a research agenda for the community, where future work can focus on investigating and explaining each of the phenomena of developer awareness, perception, challenges, needs, and approach. Future empirical studies can focus on improving the understanding and implementation of ethics in AI and recommend practical approaches to minimise ethical issues such as mitigating human biases in AI development through frameworks and tools development.
