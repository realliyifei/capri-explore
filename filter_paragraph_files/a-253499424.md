# What's the Situation with Intelligent Mesh Generation: A Survey and Perspectives

CorpusID: 253499424 - [https://www.semanticscholar.org/paper/04d5891518052f83a7f240b821935ccef1ca051f](https://www.semanticscholar.org/paper/04d5891518052f83a7f240b821935ccef1ca051f)

Fields: Computer Science, Medicine, Engineering

## (s1) Motivation
(p1.0) I N this paper, we embark on a systematic review of publications centered on Intelligent Mesh Generation (IMG). Recognized as one of the six fundamental research directions in NASA's Vision 2030 [1], mesh generation holds a pivotal role in computational geometry and is integral to numerical simulations. IMG amalgamates machine learning with mesh generation, a blend whose significance is gaining recognition as a growing corpus of research that explores the use of neural networks to generate high-quality meshes across diverse application scenarios. Driven by various meshing objectives, IMG research has seen a surge in interest. Notably, recent years have seen the advent of many innovative algorithms. Despite the substantial research on IMG, there is a conspicuous absence of comprehensive reviews that adopt a standardized methodology to ensure significance, completeness, and impartiality. To advance research in the IMG field, an urgent need exists for a systematic overview of the current state-of-the-art IMG methods. Such an overview will aid in distilling the essential commonalities in these works, identifying current research trends, and pinpointing promising future directions.

LLM judge: YES

## (s9) Deformation-based Mesh Generation
(p9.0) A mesh consists of polygons and is essentially a discrete representation of a continuous surface. The combinatorial nature of the polygons prevents taking derivatives over the space of possible meshing of any given surface. Thus, it is difficult for mesh processing and optimization techniques to take advantage of modular gradient descent components of modern optimization frameworks. To circumvent this problem, deformation-based IMG has attracted more attention. As shown in Fig.4, a distinguishing feature of this technology is the need for an initial mesh such as spherical or ellipsoidal template mesh. Deformation-based IMG is applicable to different data types of inputs. A target mesh based on geometric information is usually generated from images [8]- [34], point clouds [35]- [39] or voxels [40], [41].

(p9.1) Due to the presence of an initial mesh, this type of method reduces the difficulty of mesh generation to some extent. The neural network only needs to predict the position of the vertex because the connection relationship already exists.

LLM judge: YES

## (s12) Delaunay triangulation-based Mesh Generation
(p12.0) Delaunay triangulation [133] is a widely employed mesh reconstruction technology that can connect point clouds into triangular meshes. Delaunay triangulation has many excellent properties, such as maximizing the minimum angle characteristic. Regardless of which region the Delaunay triangulation is constructed from, the final generated triangular mesh is unique. Inspired by Delaunay triangulation, some researchers have tried to integrate it into IMG to generate high-quality and manifold meshes [43]- [46], [49], [98], [104], [106]. Among these methods, early works [43]- [45],  [49] predict the position of vertices using neural networks and then generate high-quality meshes using Delaunay triangulation [133]. These methods generate 2D planar meshes with given boundaries or coarse meshes. However, in applications, a three-dimensional surface often needs to be addressed. Alfonzetti [46] utilized the 3D Delaunay algorithm to generate a tetrahedral mesh from a 3D point cloud. Song et al. [93] combined the classification model and adaptive Delaunay algorithm to realize the mesh reconstruction of large indoor and outdoor scenes. Rakotosaona et al. [104] projected a 3D point into the 2D parameter space by a neural network, triangulated the 2D plane point using the Delaunay algorithm, and then pulled the point cloud back to the 3D surface by inverse mapping. The algorithm pipeline is shown in Fig. 9. Furthermore, to realize end-to-end differentiable triangulation, Rakotosaona et al. [98] proposed a differentiable weighted Delaunay triangulation. As [134] remark, parameterization is a correspondence between a surface mesh embedded in 3D and a simple 2D domain referred to as the parameter space. Generally, parameterization is expected to be bijective, which is a classic problem in computer graphics and geometry processing with multifarious applications, such as mesh generation, texture mapping, and shape correspondence. Considering the convenience of mesh generation in parameter space, some researchers have tried to combine parametrization with machine learning modules and then invented a series of IMG methods based on parameterization. According to the different participation modes of parameterization, we broadly divide them into two categories. The first category is geometry image-based IMG. The authors map the surface to the parameter plane by the traditional parametric method [135] to obtain a geometry image, process the geometry image using the deep learning model, and then convert the geometry image to a mesh. The second category is parameterization learning-based IMG, which learns the mapping from the parameter space to the target space. Then, meshes are generated in the parameter space by the traditional or machine learning method.

LLM judge: YES

## (s18) Hybrid Polygon Mesh Generation
(p18.0) In practical applications, due to various nonideal conditions, it is often impossible to generate only a single basic facet. Therefore, some researchers have designed hybrid mesh generation algorithms out of active or passive intention. However, due to the limitation of their application, there are only a few types of IMG with hybrid meshes as the generation target. In the literature that we searched, only BP-ANN [114], AnalyticMesh [101] and PolyGen [70] belong to this category. BP-ANN generates anisotropic quadrilateral and isotropic triangular meshes by the advancing front method, which improves the level of automation and efficiency of hybrid mesh generation. AnalyticMesh marches among analytic cells to recover the exact mesh of the closed, piecewise planar surface captured by an implicit surface network. The algorithm is applicable to more advanced MLP architectures, including those with shortcut connections and max pooling operations, which support a richer set of architectural designs for learning and exactly meshing complex surface shapes. Polygen more compactly represents the surface of the object with different polygons.

LLM judge: YES

## (s19) Tetrahedral Mesh Generation
(p19.0) Tetrahedral mesh generation is an important branch of mesh generation. Unlike the surface mesh, tetrahedral mesh generation simultaneously divides the surface and the interior of the object. Tetrahedral mesh plays an irreplaceable role in numerical simulation, so it has received the attention of many researchers. However, due to the complexity of the problem and the incompleteness of the basic theory, intelligent tetrahedral mesh generation is still lacking. In the literature that we selected, the tetrahedral mesh generation process has been partially [46] or fully [81] replaced by deep learning modules. In [46], Alfonzetti et al. proposed a neural network generator for tetrahedral meshes. Starting from an initial moderately coarse mesh, the generator grows the mesh up to the user-specified number of nodes by a node probability density function. DefTet [81] is optimized for both vertex placement and occupancy and is differentiable with respect to standard 3D reconstruction loss functions. DefTet offers several advantages over prior work and can Fig. 12: DefTet [81]: an IMG method for tetrahedral mesh.

(p19.1) output shapes with arbitrary topology, using the occupancy of the tetrahedrons to differentiate the interior of the object from the exterior of the object. DefTet also represents local geometric details by deforming the triangular faces in these tetrahedrons to better align with the object surface, thus achieving high-fidelity reconstruction at a significantly lower memory footprint than existing volumetric approaches. DefTet accepts point clouds or images as input data to generate meshes. The algorithm flowchart of DefTet is shown in Fig. 12.

LLM judge: YES

## (s21) Point Cloud-based Mesh Generation
(p21.0) Point clouds, as a major representation of 3D data, have been widely employed in fields such as autonomous driving and AR. Point clouds naturally have depth information and are not affected by ambient lighting conditions compared to RGB images. Reconstructing a mesh from a point cloud is a long-standing problem in computer graphics. Recently, various approaches have been developed to reconstruct shapes for an array of applications [3]. These methods are divided into two categories: direct estimation of point locations and connection relationships, as shown in Fig. 13, and implicit surface reconstruction based on isosurfaces. This division is illustrated in section 4.1. Next, we introduce these methods in two aspects: (1) the challenges of point cloud-based mesh generation and (2) the learnable priors and related methods proposed to cope with these challenges.

LLM judge: YES

## (s23) Voxel-based Mesh Generation
(p23.0) A voxel is a data structure that uses a fixed-size cube as the minimum unit to represent a 3D object. A voxel is a traditional method for storing volume data, providing density, opacity, normals, and other information. The index of the voxel grid provides location information. The major drawback of voxel modeling is that the storage and calculation of voxels require a large memory resource.

(p23.1) Similar to point clouds, a class of voxel-based methods uses occupancy and isosurfaces to generate the mesh implicitly. Mescheder et al. [61] used occupancy networks for 3D resolution enhancement to better reconstruct objects. Voxel2Mesh [40] utilized a network to extract features from voxelized MRI brain images and CT liver scans and relied on deformation networks to obtain a triangular mesh of the target object. Peng et al. [77] combined convolutional encoders with implicit occupancy decoders and achieved detailed reconstruction of objects and 3D scenes. The authors encode the input into 2D or 3D Voxel grids which are processed using convolutional networks and then decoded into occupancy probabilities via a fully connected network. DMTet [92] is a deep 3D conditional generative model that can synthesize high-resolution, 3D shapes using simple user guides such as coarse voxels. The model marries the merits of implicit and explicit 3D representations by a differentiable marching tetrahedra layer. This combination allows joint optimization of the surface geometry and topology as well as the generation of the hierarchy of subdivisions by using reconstruction and adversarial losses. As an intermediate product of iso-surface extraction, the voxelized distance field is also often employed as input to generate meshes [66], [107], [117]. Scan2Mesh [66] took the voxelized truncated signed distance field (TSDF) as input. Its framework is visualized in Fig. 15. Scan2Mesh is composed of two main components: first, a 3D-convolutional and graph neural network to jointly predict vertex locations and edge connectivity; and second, a graph neural network to predict the final mesh face structure. NMC [107] used a signed distance field as input and was then trained to reconstruct the zero-isosurface of an implicit field while preserving geometric features such as sharp edges and smooth curves. The main limitations of NMC are that it is sensitive to rotation and cannot avoid self-intersection of meshes. NDC [117] is a data-driven approach to mesh reconstruction based on dual contouring. NDC can be trained to produce meshes from binary voxel grids, signed or unsigned distance fields, or point clouds and can produce open surfaces in cases where the input represents a sheet or partial surface.

LLM judge: YES

## (s33) 16.82
(p33.0) AtlasNet [56] Generate high-resolution, 3D shapes Generate shapes of arbitrary resolution; broad application Exist distortion or overlap 16.29 Li et al. [57] Modeling generic freeform 3D surfaces from sparse, expressive 2D sketches.

LLM judge: NO

Violates criteria 1: The content is incomplete and lacks context. It mentions two different methods (AtlasNet and Li et al.) for 3D shape generation without explaining them or providing additional insights. 
Additional issue: Lack of clarity on the specific applications or results of the mentioned methods.

## (s35) IM-Net [65]
(p35.0) Generate high visual quality mesh Efficient representation with coordinate information Many nonsurface points yield many invalid calculations 17.10 Scan2Mesh [66] Adaptation to incomplete scans Cleaner and more CAD-like meshes from noisy and partial range scans

LLM judge: NO

Violates: 5 (lack of explanation for Scan2Mesh and CAD) 

Other issues: Lack of context for how Scan2Mesh addresses the issue of incomplete scans and how it improves the quality of meshes.

## (s38) 2.15
(p38.0) BCNet [16] Accuracy of geometric representation Different topology garments can be generated Some details cannot be generated 2.48 PolyGen [70] Generate a wide variety of realistic geometries Is capable of generating coherent and diverse mesh samples It is suitable for the generation of artificial object surfaces but not for the generation of complex surfaces.

LLM judge: NO

Violations of criteria:
1. Not self-contained, lacks deeper context and explanation of BCNet and PolyGen.
2. Merely lists references without explaining their relevance or contribution to the paper.
3. Includes unclear symbols like "[16]" and "[70]".
4. Lack of clarity in the explanations given.

Other issues:
- Lack of explanation on how BCNet and PolyGen are relevant to the topic of garment generation, artificial object surfaces, and complex surfaces.

## (s44) Summary of open challenges
(p44.0) In this review, we have highlighted the limitations found across the selected articles. These limitations not only represent the challenges within the IMG field, but also help identify potential future research directions. The primary challenges we've recognized are as follows: (1) Generalization: Generalization means the ability for an algorithm to handle objects not observed during training -is a crucial aspect demonstrating the practical utility of the algorithm. The lack of generalization is a prevalent issue with current IMG methods, particularly those using deformationbased mesh generation techniques. These methods often produce meshes specific to a particular object type or topology, limiting their wider applicability.

(p44.1) (2) Interpretability: The interpretability of IMG is critically important, especially within the aerospace industry. It is our suggestion that melding IMG with fundamental mathematical and physical models, as evidenced by studies such as Zheng et al. [188] and Lei et al. [189], can not only effectively govern model optimization but also impart enhanced interpretability to the model. However, thus far, no research has directly addressed this particular issue.

LLM judge: YES

