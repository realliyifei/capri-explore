# A Review on Automated Brain Tumor Detection and Segmentation from MRI of Brain

CorpusID: 16988556 - [https://www.semanticscholar.org/paper/e888535c5b8ce61f50fa7ecc1979403c18d2bafb](https://www.semanticscholar.org/paper/e888535c5b8ce61f50fa7ecc1979403c18d2bafb)

Fields: Computer Science, Medicine

## (s12) Bayesian approach:
(p12.0) This is a supervised and parametric approach, where the data are assumed to follow a multivariate normal distribution, where mean and covariance are estimated from the training data set [57]. This method combines a graph-based algorithm and Bayesian model and segments the edema in addition. Also it can be extended to vectorial variables to operate on multi-modality images. A Bayesian network is a model of compound probability distribution function of a set of variable like directed acyclic graph with a probability table for each node. The nodes in a Bayesian network depends upon different variables in a domain, and the arcs between nodes represent the dependency relationships among the variables with probability [57]. First introduce some terms are very shortly written. Prior probability is the probability determined by the historic materials or the judgment of somebody. Since this kind of probability is not validated by experiment, it is called prior probability. Posterior probability is the probability which revised according to Bayesian equation and new features achieved by analysis thus the total probability theorem if A can be only influenced by factors B i . B j = Ø (i≠j), P(B i ) > 0, i = 1, 2,…then it have: P(A) = ∑ P(B i )P(A/B i ) Bayesian Equation is also called posterior probability equation because in this probability distribution some other investigations are needs. If the prior probability is P(B i ) and the additional information obtained by investigation is P(A|B i ), where i = 1,2,…, n, then the probability is:

(p12.1) The Bayesian Networks B = {G, Ѳ} is a directed graph with a probability to each node with i)each node of the network represents a variable which can be discrete or continuous, ii)A set of directed edges or arrows, if there exists an arrow from node X to node Y, then X is called the parents node of Y, iii) For each node X i , there is a conditional probability distribution P(X i /Pa i ), which indicate the influence by its parents, the graph must be directed acyclic graph. Then a Bayesian network defines a joint probability distribution written as follows
## (s14) Support Vector Machine (SVM):
(p14.0) The SVM approach is considered as a good candidate due to high generalization performance, especially when the dimension of the feature space is very high. The SVM uses the following idea: it maps the input vector x into a high-dimensional feature space Z through some non-linear mapping, chosen a priori [67]. SVM became famous when, using images as input, it gave accuracy comparable to neural-network with hand-designed features in a handwriting recognition task and
## (s15) Linear Discriminant Function g(x) is a linear function is given by
(p15.0) A hyper-plane in the feature space unit-length normal vector of the hyper-plane Nonlinear SVMs: The Kernel Trick with this mapping, our discriminant function is Thus no need to know this mapping explicitly, because it only use the dot product of feature vectors in both the training and test. A kernel function is defined as a function that corresponds to a dot product of two feature vectors in some expanded feature space is written below Support Vector Machines (SVMs) [68] are a popular tool for classification of data that is independent and identically distributed. SVMs try to maximize the margin between classes i.e. here using the simple linear feature space xi ·xj , by finding the optimal values in the following Quadratic Programming problem represented in dual Lagrangian form where C is a constant that bounds the misclassification error
## (s17) Fuzzy c-means algorithms:
(p17.0) The goal of a clustering analysis is to divide a given set of data or objects into a cluster, which represents subsets or a group. The partition should have two properties one of them is the homogeneity inside clusters data, which belongs to one cluster, should be as similar as possible and another one is heterogeneity between the clusters data, which belongs to different clusters, should be as different as possible [73]. The membership functions do not replicate the actual data distribution in the input and the output. They may not be suitable for fuzzy pattern recognition. To build membership functions from the data available, a clustering technique may be used to partition the data, and then produce membership functions from the resulting clustering [74]. The FCM algorithm is an improvement of earlier clustering methods. The objective function of FCM algorithm is defined as the sum of distances between the patterns and the cluster centers.

(p17.1) Where, C is the number of clusters that in this problem is equal to number of needed segmentation regions. The represents the center of cluster j; M is the number of brain MR image pixels; the parameter q is larger than 1, and adjusts the fuzzifier intensity; is the membership function of attribute to cluster j, which should satisfy these conditions:
## (s23) Fusion-based:
(p23.0) Fusion techniques are based on various theories such as probabilistic and Bayesian fusion, fuzzy set theory, possibility and belief functions theory. Since a tumor consists of different biological tissues, one type of MRI cannot give complete information about abnormal tissues. Therefore, different MRI modalities information of a patient is combined to take a decision on the location, extension, prognosis and diagnosis of the tumors discussed by  [132]. Data fusion is a growing research field, and the goal of data fusion is to obtain an information synthesis by combining different data [133]. Data coming from different sources and techniques are usually redundant but also complementary. A fuzzy fusion Dou et al. [134] using operators such as t-norm or average operators was performed to fuse the membership functions. Finally a fuzzy region growing is used to refine the final result. This method uses the fused information of several MRI types to segment the tumor automatically and is very fast to detect and segment the tumors.
## (s26) Watershed Methods:
(p26.0) It is one of the best methods to group pixels of an image on the basis of their intensities. Watershed algorithm is based on morphological process although it can be mixed up with edge based segmentation to yield a hybrid technique. Normally, images acquired by various techniques in the electromagnetic spectrum, possesses a large no of discontinuities in the intensity and these ultimately give rise to over segmentation when morphological segmentations like watersheds are carried out. Pixels falling under similar intensities are grouped together [150]. It is a good segmentation technique for dividing an image to separate a tumor from the image Watershed is a mathematical morphological operating tool.

(p26.1) Mathematically watershed segmentation shortly describes [150,151,153]; Suppose the lower point in the image (water shade and catchment basins ) are LP 1 , LP 2 …..LP Z to be coordinate of these points for the image I (i, j) and UB m refers to the points of catchment basins associated with minimum region LB z (x, y) represented by X[n] accordingly I(x, y) < n. Watershed Techniques have the ability to detect the continuous boundary of the region of interest, it can be best suited for those types of applications where high accuracy and precision is needed. Detection of tumor in the area of cancer research is best suited area of application where watershed segmentation can be applied efficiently. Watershed is a gradient-based segmentation technique where different gradient values are considered as different heights. A hole is made in each local minimum and immersed in water; the water will rise until local maximums. When two body of water meet, a dam is built between them. The water rises gradually until all points in the map are immersed. The image gets segmented by the dams. The dams are called watersheds and the segmented regions are called catchments basins [154]. The main problem of watershed transform is its sensitivity to intensity variations, resulting in over segmentation, which occurs when the image is segmented into an unnecessarily large number of regions. The over segmentation problem still exists in this method [154].
## (s27) Level Set Methods:
(p27.0) Level set methods use non parametric deformable models with active contour energy minimization techniques which solve computation of geodesics or minimal distance curves. Level set methods are governed by curvature defining speeds of moving curves or fronts.

(p27.1) There are large numbers of level set methods developed for segmentation of medical images and all most all these methods follow some common generic steps [155]. First placement of an initial contour arbitrarily, outside or inside the region of interest, level set φ = signed Euclidean distance function of the contour and Function φ allowed to evolving according to first or second derivative partial differential equation (PDE), then it is reinitialized after a number of iterations and go to second statement until the function φ converges or = 0.
## (s29) The Combination of Watershed and Level Set :
(p29.0) This approach combines the advantages of both methods: the watershed transform pre-segmentation is rough but quick and the level set needs only a few iterations to produce the final, fast, highly accurate, and smooth segmentation. The choice of watershed segmentation as the initialization of the level set method is made for two reasons [166]. The first reason is that because of watershed transform blindness of segmentation is reduced and the accuracy of segmentation is improved. The second reason is to do with improving the computation speed. After the initial segmentation based on watershed transform, the final segmentation is accomplished based on level set method [167]. By combining watershed transform and level sets, this method is able to produce highly accurate segmentations of topologically and geometrically complex structures in much less time than where level sets alone. 7.18 Self-organizing maps (SOM) : SOM consists of two layers: first is the input layer and the number of neurons in this layer is equal to dimension of input and second is the competitive layer and each neuron in this layer corresponds to one class or pattern [168]. The number of neurons in this layer depends on the number of clusters and is arranged in regular geometric mesh structure. Each connection from input layer to a neuron in competitive layer is assigned with a weight vector. The SOM functions in two steps, viz, [169] firstly finding the winning neuron i.e. the most similar neuron to input by a similarity factor like Euclidean distance, and secondly, updating the weight of winning neuron and its neighbour pixels based on input. The basic SOFM model consists of two layers. The first layer contains the input nodes and the second one contains the output nodes. The output nodes are arranged in a two dimensional grid as shown in Figure below  [170].

(p29.1) Where upper plane are 2D array of neurons, w ij are Weight, x 1 , x 2 ,.....,x n are Set of input signals , Every input is connected extensively to every output node via adjustable weights. The neighborhood is centered on the output node whose distance d ij is minimum. The measurement of d ij is an Euclidean distance, defined as:

(p29.2) The neighborhood decreases in size with time until only a single node is inside its bounds. A learning rate, , is also required which decreases monotonically in time. The weight updating rule is as follows :
## (s30) a) b)
(p30.0) Self-organizing maps (SOM) is an unsupervised clustering network that maps inputs which can be high dimensional to one or two dimensional discrete lattice of neuron units [169]. The input data is organized into several patterns according to a similarity factor like Euclidean distance and each pattern assigns to a neuron. Each neuron has a weight that depends on the pattern assigned to that neuron [169]. Input data is classified according to their grouping in input space and neighbouring neuron and moreover learns distribution and topology of input data [174,175]. For calculating that black and white similarity map, the more neighbors it use to calculate the distance the better similarity map we will get, but the number of distances the algorithm needs to compute increases exponentially.
## (s33) Fractal-based:
(p33.0) A fractal is an irregular geometric object with an infinite nesting of structures at all scales. Some of the most important properties of fractals are self-similarity, chaos, and non-integer fractal dimension (FD) [186,187,188]. Mathematically, a fractal structure is defined as a set that has a fractal dimension exceeding its topological one. FD serves as an index of the morph metric complexity and variability of the object being studied. The disadvantage is that the size of sub images is a problem, because different sub image sizes result in different FD. The second problem is the selection of reference images, because the MR images have different sizes and different parameters [189] and for tumor detection it is required to have a reference image similar to the patient image.
## (s34) Parametric deformable models (snakes):
(p34.0) Parametric models explicitly move predefined snake points based on an energy minimization scheme [190]. The following section reviews available segmentation algorithms on parametric methods. The deformation process has played a critical role in shape representation. The first class of deformable model is parametric deformable curves model, also known as snakes. Since then, there has been an extensive burst of publications in the area of parametric deformable models and their improvements, such as balloon force, topology snake, and distance snake.

(p34.1) In 2-D, a snake is defined as a curve C(s) =x(s), y(s) where x∈ (0, 1) in traditional snake, the energy usually formed by internal forces and external forces [191] as, E snake = E internal + E external Where E internal and E external are internal and external energies, respectively. The internal energy function determines the regularity, i.e., smooth shape of the contour. This energy is given by
## (s35) Edge-based segmentation methods:
(p35.0) In this method an algorithm searches for pixels with high gradient values that are usually edge pixels and then tries to connect them to produce a curve which represents a boundary of the object. The user determines an initial guess for the contour, which is then deformed by image driven forces to the boundaries of the desired objects. In these models, two types of forces are considered. The internal forces, defined within the curve, are designed to keep the model smooth during the deformation process. The external forces, which are computed from the image data, are defined to move the model toward an object boundary. The Canny edge detection algorithm [199] is known to many as the optimal edge detector. Canny's intentions were to enhance the many edge detectors already out at the time he started his work. Canny has shown that the first derivative of the Gaussian closely approximates the operator that optimizes the product of signal-to-noise ratio and localization. The algorithm then tracks along these regions and suppresses any pixel that is not at the maximum. The steps for canny edge detection is follows, Compute f x and f y G(x, y) is the Gaussian function;G x (x, y) is the derivate of G(x, y) with respect to x: G y (x, y) is the derivate of G(x, y) with respect to y:

(p35.1) The performance of the canny algorithm [199] depends heavily on the adjustable parameters, σ, which is the standard deviation for the Gaussian filter, and the threshold values, 'T1' and 'T2'. σ also controls the size of the Gaussian filter. The bigger the value for σ, the larger the size of the Gaussian filter becomes. This implies more blurring, necessary for noisy images, as well as detecting larger edges. Gradient-based algorithms such as the Prewitt filter have a major drawback of being very sensitive to noise. The gradient is a vector which has certain magnitude and direction is define as follows, the magnitude of gradient provides information about the strength of the edge and the direction of gradient is always perpendicular to the direction of the edge is the concept of sobel operator [25].

(p35.2) These kernels are designed to respond maximally to edges running vertically and horizontally relative to the pixel grid, one kernel for each of the two perpendicular orientations. The kernels can be applied separately to the input image, to produce separate measurements of the gradient component in each orientation. These can then be combined together to find the absolute magnitude of the gradient at each point and the orientation of that gradient. The gradient magnitude is given by:
