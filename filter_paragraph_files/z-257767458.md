# Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey

CorpusID: 257767458 - [https://www.semanticscholar.org/paper/d135ec27b06266dcc013431a7778fc37e5e79f70](https://www.semanticscholar.org/paper/d135ec27b06266dcc013431a7778fc37e5e79f70)

Fields: Computer Science, Medicine

## (s0) I. INTRODUCTION
(p0.0) In recent years, we have witnessed an accelerated growth of IoT devices in various domains such as healthcare [1], smart transportations [2], smart home and building [3], and smart cities [4]. In the healthcare domain, IoT technology has shown its capabilities and applications in collecting patients' data to enable healthcare professionals to analyze the data for better and more efficient treatment of various diseases. These devices are designed to automatically collect, send, receive, and store data over the networks in order to proactively detect, diagnose, monitor, and treat patients both in and out of the healthcare systems.

(p0.1) Internet of Healthcare Things (IoHT) is a sub-type of the Internet of Things (IoT) oriented to e-health by combining various smart devices such as smart watches, wearable trackers, and other smart connected devices to record various health measures such as heart rate, body temperature, and blood pressure [5]. A huge amount of information collected from those variety of IoHT devices and applications is later employed in data analytics where it is empowered with Artificial Intelligence (AI) and Machine Learning (ML) models to mine such information and improve the health decision making.

(p0.2) Traditionally, healthcare organizations use centralized MLbased models in clouds or data centers to train the data generated by IoHT devices aiming to take reliable decisions in the healthcare domain. However, such models usually suffer from performance and accuracy issues due to the unavailability of sufficient data to reside centrally on the server side for training due to direct access restrictions/regulations (HIPAA and GDPR) on such data, where all may lead to biased models that cannot be trustworthy [6] [7]. Additionally, even with sufficient data, the training procedure in a centralized setting is time-consuming and expensive tasks make them out of interest of hospitals and research centers [8].
## (s1) II. RELATED WORK
(p1.0) There are many review papers that cover a wide range of security and privacy challenges in FL environment that are either dedicated in other domains or covered security and privacy issues at the general level. In this section, we tried to discuss the most recent and similar to our work.

(p1.1) In [20], the focus is to provide an overview of FL, highlighting protocols, platforms, algorithms, market implications, and real-life use-cases, in terms of software and hardware. The advantage related to privacy, brought by FL, is presented in some parts of the work but this is not the main focus of the paper. Some use-cases related to health applications are presented but there are no comments about IoHT (In fact, authors state that IoT is not the focus of the paper).

(p1.2) The authors in [21] provide a formal definition of FL and review the existing works using FL. The works are evaluated in terms of five aspects and one of these aspects is privacy mechanisms. Three mechanisms are considered: model aggregation, homomorphic encryption, and differential privacy. In our survey, we focus on privacy and consider a different approach, classifying four techniques: anonymization, cryptography, perturbation method, and blockchain. Similar to [20], in [21] some use-cases related to health applications are presented but there are no comments about IoHT.

(p1.3) The authors in [22] review the FL method specifically in terms of both security and privacy. Different implementations of FL are considered and evaluated. Some of the FL threats in terms of security and privacy are similar to those considered in our paper. Some applications are oriented to IoT but there are no comments about IoHT.

(p1.4) In [23], the authors focused on the IoT domain only. Similar to [21], a formal definition of FL is presented. Healthcare applications are considered in the survey but the comparison and analysis of the works do not specify what privacy attacks the works are oriented to and neither the datasets used by them.

(p1.5) In another effort [24], a number of privacy-preserving mechanisms adopted for FL frameworks are evaluated by the authors, as well as their application to vehicle activity recognition. In this study, they examined the open-source FL frameworks FATE and PFL. The FATE framework uses homomorphic encryption to secure computations and input data, while PFL uses multi-party secure computations and differential privacy to protect the processing of vertically partitioned data and train neural networks for horizontally partitioned data. Similar to [21] and [20], there are no comments about IoHT in the survey.

(p1.6) Nguyen et al. [25] represent the summary of FL in the Internet of Medical Things (IoMT). In this study, a federated EHR management system, a federated remote monitoring system, a federated COVID-19 detection system, and a federated medical imaging system were discussed. Innovative FL designs for IoMT are investigated, including secure FL, resource-aware FL, and incentive-aware FL. Also, privacyenhanced FL to protect security is explored, but this is not the main focus of the paper. Similar to [24], in [25], among the privacy-enhancing mechanisms, differential privacy method is taken into consideration, while in our survey, we examine four different technologies that enhance privacy.

(p1.7) To the best of our knowledge, this work is the first survey specifically focused on reviewing Federated Learning applications in IoHT from the perspective of Privacy-Enhancing Technologies. A side-by-side comparison of recent efforts in this domain is shown in Table I.
## (s8) A. Benefits of FL in IoHT
(p8.0) Due to various characteristics of FL such as privacypreserving, and collaborative learning in a distributed data environment bring many advantages to the IoHT domain that will be discussed briefly in the next subsections.

(p8.1) 1) Improving the privacy of user data: With increasing the number of IoHT devices and publicly available medical datasets generated by IoHT devices, privacy concerns are also growing in the e-healthcare systems. Collected data by IoHT devices, such as heartbeat, blood pressure, and glucose level, is more sensitive compared to other types of data. According to data privacy protection legislation, private patient data is the most sensitive data and is restricted by government laws. To address data privacy challenges in the e-healthcare domain, FL offers a decentralized training mechanism where each client or institution can control private data and define a privacypreservation policy [37]. In the FL framework, the raw health data are stored at a medical devices or local site and do not leave the IoHT devices during the federated data training process. During model training, only the local updates like model gradients need to be sent to the central server, which reduces the risk of sensitive and personal data leakage and ensures a high level of patient data privacy [38].

(p8.2) 2) Less biased model: Because a centralized model can only be trained using limited data from a single hospital, the result may be biased in the predictions. Therefore, mitigation bias recently gains a lot of attention in modern machine learning techniques [39]. Thus, for models to be more generalizable, more data must be used, which can be achieved through data sharing between organizations. However, exchanging patients' electronic health data between hospitals is against their data security and privacy because healthcare data is sensitive [40]. Under these circumstances, to address the bias issue, federated learning has emerged as an option for building a collaborative learning model for healthcare data and producing models that yield unbiased results. The trained model is less biased and smarter as different datasets from various sources are integrated into the learning process [41].

(p8.3) 3) Improving the scalability: In the centralized model, uploading all of the healthcare data to the server leads to a waste of computing resources, breaches privacy, and puts more pressure on the wireless communication network, which declines the network's scalability. However, FL's distributed nature enables the scalability of IoHT networks [42]. In fact, FL has the ability to use the computational resources located at multiple IoHT devices across different hospitals located in different geographic regions in a parallel manner. For instance, when new hospitals or healthcare institutions participate, they add more computational resources in the federated learning process. Therefore, these more computational resources allow federated learning to enhance performance. Moreover, the FL architecture avoids sending the massive amounts of IoHT data gathered to the cloud, which can result in significant network bandwidth saving and drastically reduce communication costs [43] [44].
## (s10) A. Anonymization Techniques
(p10.0) Anonymization techniques are broadly used for privacy enhancing by changing the state of a data set and removing the identifier from dataset information in a way so that the dataset is usable and protects the privacy of individual's personal information [72]. Anonymity technology can better avoid the leakage of sensitive patient data and provide more secure environment for smart healthcare systems. There are several anonymization technologies that are appropriate for big medical data, which are based on three categories of widely used anonymity protection techniques: k-anonymity, ldiversity, and t-closeness models [73].
## (s12) C. Perturbation Techniques
(p12.0) A perturbation method is to protect private data and model privacy by adding random noise to the original data or training data during the training process. The differential privacy technique is a widely used perturbation method implemented in the FL frameworks in medical applications. It is one of the PETs methods and guarantees privacy [87] using probability statistical models to mask sensitive private data in a dataset [88] and protect healthcare data against inference attack on FL frameworks. By adding noise to the model parameters or data, data can be deferentially private [89] [90], and the parties cannot realize whether an individual record participates in the learning process or not. Differential privacy techniques include two categories: global differential and local differential privacy techniques. In the global differential privacy (GDP) setting, there is a trusted curator that applies carefully random noise to the real values returned for a particular query [91]. Different from GDP, a local differential privacy (LDP) technique does not need a trusted third-party. In fact, LDP allows users to locally perturb the input data, and it often produces too noisy data, as noise is applied to achieve individual record privacy [92]. As an advantage, the differential privacy technique by adding random noise makes data sets more secure because an attacker cannot distinguish which information is true. Therefore, more noises that are added to the sensitive data have a direct relationship to how the data is hard for an attacker to recognize true information about individuals in the dataset [93].
## (s13) D. Blockchain Techniques
(p13.0) Blockchain is beneficial in many non-financial industries such as healthcare due to its cryptographic security, immutability, and accountability [98]. Researchers have recently started implementing blockchain technology to decentralize traditional data management systems. For instance, blockchainbased data management prevents security breaches and assure GDPR compliance [99]. Therefore, blockchain-based PETs solutions can be used in Medical IoT to safeguard individuals' rights over their personal data [100]. Accordingly, Blockchain is a promising technique to improve the security and scalability of the FL system. This technique has provided a high level of security in the domain of healthcare by integrating blockchain into a federated learning to maintain the trained parameters [101]. The blockchain-based system is effective for decentralized federated learning training without the need for any central server which can mitigate risks of single-point failures [102]. To provide IoHT data provenance, blockchain has shown great promise, and also provides permission control of the participants to enhance the security and privacy of parameters in federated learning. Blockchain has gained popularity for managing the trust and provenance of trustworthy federated nodes, their datasets, the accuracy of the models, and the immutability of the global model [103]. A blockchain method consists of public (permissionless), private and consortium (permissioned). A public blockchain system allows any client to participate in the decentralized process without the need for authorized permission. In a private and consortium system, only the client with authorized permission can be involved in the block validation and confirmation process.
## (s17) C. Perturbation Methods
(p17.0) Similar to [109], in [116], the authors proposed a bandwidth-efficient FL framework in IoHT environment. The framework ensures privacy for FL based on Differential Privacy (DP). They discovered that exchanging the model update from a huge amount of IoHT devices needs a significant bandwidth. Therefore, they proposed the FL-SIGN-DP scheme to reduce communication costs and enhance privacy. Participants in FL-SIGN-DP only transmit the updated model's sign to the aggregation server. They used the electronic health records of roughly a million patients to assess the performance of the proposed scheme with regard to the in-hospital mortality rate. The proposed scheme is compared with centralized learning, FL-SIGN without using standard FL, differential privacy, and differential privacy with standard FL. The results showed that the FL-SIGN-DP consumes less bandwidth and can guarantee privacy protection.

(p17.1) Islam et al. [117] proposed a FL model to analyze patients' genomic data and identify the risk of heart failure. To enhance the privacy-preserving of the patient private data sharing among collaborating healthcare organizations in FL framework, they applied differential privacy mechanisms through feature selection based on statistical methods to increase scalability and accuracy in a federated setting where data are vertically partitioned. They evaluated the performance of the proposed FL framework using the IQVIA dataset and BC-TCGA dataset 11 for predicting the causes of certain heart failure and the BC-TCGA dataset for cancer prediction to compare their proposed FL method. The result demonstrated that their proposed model obtains better accuracy with the highest privacy for the IQVIA and BC-TCGA datasets in a federated training setting.

(p17.2) The authors in [118] proposed federated adversarial learning (FAL) on biomedical named entity recognition (BioNER). The differential privacy technology is also used to protect the security and privacy of the data, which adds Gaussian noise during the local training and model aggregation process to enhance privacy. More specifically, only the noised parameters with differential privacy are transferred among the server and the client. Therefore, the data leakage possibility has decreased on the local client's side. The dataset collected from 5 departments of a tumor hospital is used to examine the performance of the proposed scheme. The Result showed that the proposed FAL framework can connect data parties and prevent data leakage during data exchange inside medical institutions.

(p17.3) Similarly to [116], in [119], the authors proposed a costeffective and privacy-preserving FL framework which is IoHT Alzheimer's disease detection scheme. They presented an FL based privacy-preserving smart healthcare system, namely ADDetector, to detect Alzheimer's disease. Moreover, they implemented a differential privacy (DP) mechanism on the user data to avoid patient's data leakage during transferring data to the client and enhance the privacy level against the attacker. An ADReSS Challenge dataset from INTERSPEECH 2020 12 is used to evaluate the performance of the ADDetector FL-based scheme. The proposed FL-based framework and DP-based mechanism use the audio from smart devices to detect low-cost Alzheimer's disease. The experimental results showed that the ADDETECTOR FL-based framework achieves better accuracy and low average time overhead with a high level of privacy and security protection.

(p17.4) Dinh et al. [120] proposed an FL framework, called FedGAN, to facilitate COVID-19 detection by enhancing privacy among medical institutions in edge cloud computing. The aim of the framework is to create realistic COVID-19 X-ray data and detect it automatically without the need for sharing COVID-19 image with parties. Additionally, they integrated a differential privacy at each hospital site to increase and guarantee the data privacy in federated COVID-19 data training. To apply the differential privacy, they used both differentially private stochastic gradient descent and a gradient perturbation technique; they also added the Gaussian noises to the gradient during the training. Additionally, they use the FedGAN blockchain-based system for safe COVID-19 data analysis. To evaluate the performance of proposed FedGAN model, they used two popular COVID-19 X-ray data sets for simulations, including a DarkCOVID 13 and a ChestCOVID 14 dataset. The result demonstrated that FedGAN framework enhances the performance of COVID-19 detection and provides high level of privacy. Table IV presents a summary of the perturbation methods applied for FL in smart healthcare.
## (s19) VIII. KEY CHALLENGES FOR FUTURE RESEARCH
(p19.0) While PETs in FL have many advantages and have been growing rapidly in recent years, some challenges cannot be ignored. Existing frameworks are still at an early stage and need improving methods to enhance data privacy. 15 https://paperswithcode.com/dataset/cc-19 1) Computation cost: One of the main challenges of FL is represented by privacy-enhancing to prevent data leakage. FL needs multiple iterations to achieve the final global model. Therefore, the number of training iterations has a direct impact on increasing the cost of the training model. As shown in [111], multi-party computation is a way to protect data privacy in FL. Performing experiments with a different number of workers does not impact the computation cost, however, increasing the number of training rounds significantly boosts the computation cost. Therefore, the trade-off between privacy risk and computation time has been a promising topic for researchers.

(p19.1) 2) Privacy and security: In Section VII-D, some studies show that integration of the blockchain method and FL is a way to enhance privacy in IoHT. However, there is an open issue that may lead to privacy leakage. In the FL, only the central server has information about the sources of the local model updates, and the addresses of the clients are private. However, addresses in blockchain are public, and using blockchain in FL gives the ability to other clients to communicate with each other and obtain the training model based on the public information from the blockchain. Therefore, the risk of data leakage among clients cannot be ignored.

(p19.2) 3) Linkage attacks: The k-anonymity technique is a way to preserve the anonymity of individuals. The key idea is how to modify the attributes of the dataset in a way that each instance has at least k-1 other entities with identical quasi-identifiers. Therefore, an identifiable record would link to multiple records in the anonymous dataset. However, k-anonymity cannot avoid privacy leakage against linkage attacks where a sensitive attribute is shared among a group of individuals with the same quasi-identifier.
