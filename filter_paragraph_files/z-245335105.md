# A Comprehensive Analytical Survey on Unsupervised and Semi-Supervised Graph Representation Learning Methods

CorpusID: 245335105 - [https://www.semanticscholar.org/paper/b415ecb687941e1e9ef68e04a4a1c68c73483d51](https://www.semanticscholar.org/paper/b415ecb687941e1e9ef68e04a4a1c68c73483d51)

Fields: Mathematics, Computer Science

## (s3) Problem Definition
(p3.0) We can formally define the problem as follows: Given a graph G, we map it onto a d-dimensional space Z ∈ IR n×d such that the intrinsic properties of the original graph are preserved as much as possible. In other words, if we pick |N(u)| number of vertices for vertex u based on the similarity function σ in Figure 1: A conceptual figure to show that a mapping function preserves the notion of similarity of the original graph in embedding space. f is the mapping function and z i is the representation of i th vertex in the embedding space. the embedding space, then we should get all the neighbors of the original graph. Precisely, this represents the embedding of nodes in a network. In Fig. 1, we show pictorially that the embedding of vertices 3 and 5 preserves some notion of similarity in the embedding space as shown by z 3 and z 5 , respectively. So, if we find similarities among all other vertices with respect to vertex 3 in the embedding space, then the similarity between z 3 and z 5 will be higher than the similarity between z 3 and z 1 . A mapping or encoding function f is applied to generate such embedding of vertices.

(p3.1) Node embedding can be further extended to edge representation or even full representation of the graph. Simply, we can create an edge embedding of a graph by concatenating the embedding of two incident vertices of an edge. Similarly, a full representation of the graph can be deduced by taking the average contributions of all vertices for a given dimension. We describe several other kinds of edge embedding in Section 5.6.2. Most of the existing methods follow a general framework to generate and validate their graph embedding. We can summarize this precisely by Fig. 2. In the embedding generation step, a method is employed, and in the validation step, several prediction tasks are carried out using the learned embedding. Sometimes, embedding is pre-processed for performing latter tasks. For example, a portion of a dataset is used for training and the remaining portion of the dataset is used for testing. Generally, logistic regression is used for link prediction or node classification tasks, with the K-means algorithm being applied to cluster the graph, and the t-SNE [64] dimensionality reduction tool being used to visualize the embedding data.
## (s5) Feature Engineering
(p5.0) Early methods on graph mining tasks were mostly based on supervised (hand-crafted) feature engineering [41,3,28]. Those hand-crafted features are designed with respect to some common intuitions that are supposed to infer some meaningful information from graphs. For example, ReFeX by Henderson et al. (2011) extracts a predetermined set of features such as the degree of a vertex (in/out-degree in case of directed graph and weights in case of a weighted graph), number of edges in the egonet (number of incoming/outgoing edges in case of a directed graph) and recursive features by summing up or averaging two types of previous features. Gallagher and Eliassi-Rad (2008), on the other hand, focuses on extracting features such as the average degree of egonet, the number of incident links, betweenness centrality, and clustering coefficient. These extracted features are then arranged in a vector format with their corresponding label and fed to a standard machine learning classifier for making predictions. The prediction tasks based on the extracted features are conducted in the following way: First feature vectors with corresponding labels are partitioned into two sets, e.g., T % of the samples are used for training and the rest of the datasets are used for testing. Then, logistic regression or any other standard machine learning method can be trained to learn the parameters of the model using the training dataset. Finally, the prediction task is performed using the test dataset based on the trained model. These types of methods do not always perform well on graph mining tasks because a predefined set of features is not always enough to capture the latent characteristics of the graph. Sometimes, they are found to be difficult to generalize across different types of graphs due to the highly irregular structure. Thus, more advanced methods have been evolved over time which is briefly discussed in the following sections.
## (s6) Matrix Factorization
(p6.0) Matrix Factorization is an effective technique to decompose a matrix into two lower-dimensional rectangular matrices [53]. This technique has been successfully applied to recommender systems [53], data compression [113], and spectral clustering [22]. It was first applied to graph factorization in large scale by Ahmed et al. (2013). Matrix A of dimension M × N can be decomposed into two lower-dimensional rectangular matrices B and C having dimensions M × R and R × N, respectively. Generally, R is much less than M and N. In the case of factorizing an adjacency matrix, we have M = N and C = B , where B is a transpose matrix of B. The loss function for this problem is defined by the following Equation:
## (s19) Performance Metrics
(p19.0) A key focus of this survey is to understand the practical performance such as runtime, memory utilization, and scalability of various graph embedding and GNN methods on different graphs and hardware platforms. We also measure the accuracy of different methods when performing various machine learning tasks. We use F1-micro and F1-macro scores for the multilabel classification task, accuracy for the binary prediction task, and the modularity score to compare the results of clustering. We give a brief description of these measures below:

(p19.1) • Accuracy: When the predicted class is positive (negative) and the ground truth class is also positive (negative), it is termed as a true positive (negative). But when the predicted class is positive (negative) whereas ground truth class is negative (positive) then we term this as a false positive (negative). We represent an absolute number of true positive, false positive, true negative and false negative as TP, FP, TN and FN, respectively. In any type of binary classification or link prediction, we define accuracy as the following:

(p19.2) • F1-micro: For the multi-class classification task, the F1micro score aggregates the contributions of all classes to calculate the average value of final F1 score. In terms of precision-recall we can define this for a set of classes C as follows:

(p19.3) • F1-macro: Unlike the F1-micro score, the F1-macro score will compute the score independently for each class and finally take their average F1 score. In terms of 20 http://socialcomputing.asu.edu/pages/datasets precision-recall, we can define this for a set of classes C as follows:

(p19.4) • Modularity: The modularity score is a well-known measure to evaluate the effectiveness of any graph clustering technique. It computes the fraction of the edges that are within a given cluster minus the expected fraction, if edges are distributed randomly [74]. We can compute this score by using following Equation:

(p19.5) Here, A is the adjacency matrix of the graph, m is the number of edges, k i is the degree of the vertex v i . The membership of vertex v i belonging to a cluster is represented by c i , and δ(c i , c j ) = 1, if i and j are in the same cluster; otherwise, δ(c i , c j ) = 0.
## (s23) Training time for GNN methods
(p23.0) In the recent years, GNNs emerge as a popular option for graph representation learning, especially when nodes are partially labeled to facilitate semi-supervised predictions. In this section, we analyze the training time of some popular GNN methods. We measure the training time of GCN, GraphSAGE and FastGCN using their original source codes which are publicly available (Category 1). To measure the runtime of GAT, ClusterGCN and GraphSAINT, we use source codes available in the PyTorch Geometric (PyG) framework (Category 2) [27]. We ran all these methods on the Intel Skylake server and reported their training time in Table 10. We observe that GCN is the fastest GNN method for smaller graphs, but FastGCN runs faster than other methods for bigger graphs. The benefit of FastGCN stems from a sampling approach that is used to accelerate the training process while keeping the accuracy competitive to GCN and GraphSAGE. ClusterGCN and GraphSAINT apply a clustering technique and a sampling technique, respectively, as a pre-processing step before starting the training procedure. These expensive reprocessing steps make ClusterGCN and GraphSAINT slower than some of their peers.
## (s29) Operator
(p29.0) Notation Definition Hadamard We show notational definitions of three vector operators in Table 12. All these operators have been used previously for link prediction tasks [34]. We show the experimental results of unsupervised methods on this task in Figs. 17 (a), 17 (b), and 17 (c). As link prediction is a binary classification problem, we only report accuracy. We can see while using the Hadamard operator, Force2Vec and VERSE show competitive performance and outperform other methods. They achieve almost 99% accuracy in all datasets. For weighted L1 and L2 operators, DeepWalk performs better than other methods. For all cases, struc2vec is the worst performer as this tool is mainly designed to capture structural equivalence in the network. We also conducted experiments for link prediction task using HOPE and RolX. We observe that HOPE achieves accuracy of 79.8% and 80% for the Cora and the Pubmed datasets, respectively, using the Hadamard vector operator. On the other hand, RolX achieves accuracy of 79.7% and 74.8% for the Cora and the Pubmed datasets, respectively, using the Hadamard vector operator. These values of accuracy are lower than that of Force2Vec, VERSE and DeepWalk.
## (s30) Clustering
(p30.0) The clustering of vertices is an important task in graph mining where common/similar vertices tend to form a cluster. High quality embedding can be helpful to detect a community in large scale social networks. A good graph clustering has a higher number of intra-cluster edges and a lower number of inter-cluster edges. Generally, the Louvain algorithm [9] is widely used to find clusters in a graph which focuses on maximizing modularity. However, we can not apply it on embedding as we do not have any structural information about the graph. Instead, we apply the k-means 22 algorithm which can effectively detect clusters in the embedding space of the graph. The common practice is to set a value for k in a range and find the clusters that show the highest modularity score [100]. We report modularity scores of Force2Vec, DeepWalk, VERSE, HARP and LINE across different datasets in Fig. 18 (a). We consider Louvain algorithm as the baseline method. It has the modularity scores of 0.81, 0.88, 0.73, and 0.49 for Cora, Citeseer, Pubmed and Flickr datasets, respectively. We observe that Force2Vec achieves higher modulartiy scores for Cora, Citeseer, and Pubmed datasets. DeepWalk achieves higher modularity scores than other methods for Flickr dataset and VERSE shows better modularity score for the Youtube dataset. Notably these results are very competitive to the baseline method. For large graphs, such as Flickr and Youtube, the modularity scores of Force2Vec, VERSE and DeepWalk are comparative. As the LINE from authors' repository shows poor performance as usual, we run another implementation 23 . This version of LINE shows better performance compared to the previous version. In particular, this version of LINE achieves the modularity scores of 0.61, 0.51, and 0.51 for the Cora, Citeseer, and Pubmed datasets, respectively. Note that we do not show the results of other methods such as struc2vec or HOPE due to their poor performance in graph clustering task using the k-means algorithm.
## (s34) Effect of Dimensions
(p34.0) Some previous studies have shown that the performance on the prediction task may vary if we choose different values for hyper-parameters [79,34,100,80]. For example, after reaching a certain value for dimensionality, the accuracy of prediction starts to drop when we increase it further. Most of the previous studies suggest using dimensional embedding. To summarize the results, we conduct experiments varying the dimensions of the output embedding for some shallow network-based methods. We set different parameters as described in Section 4.3 and take 20% of the dataset to train the logistic regression model while the rest of the samples in the dataset are used for the classification. We report the results of the F1-micro scores for the Pubmed dataset in Figs. 21 (a). We observe that Force2Vec, DeepWalk, and HARP perform better than other methods for various dimensional embedding. We also notice that, for lower dimensions, the F1-micro scores are not that much less compared to higher dimensions. In fact, the VERSE tool shows better performance for 16-dimensional embedding for the Pubmed dataset. RolX shows high sensitivity for different dimensions. It shows the lowest performance for 16-dimensional embedding. Then, with the increase of dimension, the F1-micro score also increases until 128-dimension. Then, it falls a little for 256-dimensional embedding. The LINE method shows similar sensitivity to the VERSE method though its F1-micro scores are lower than the VERSE.
## (s35) Effect of Various Negative Samples
(p35.0) Noise-contrastive estimation [36] is a popular technique used by most of the shallow graph embedding models [100,117,90]. Using this technique, a subset of vertices are randomly selected from a uniform distribution as negative samples which are used alongside positive samples (i.e., k-hop neighbors) to optimize the objective function. However, randomly generated negative samples may hurt the optimization function due to the selection of false negative samples and this become vital if the number of negative samples is very large. Armandpour et al. (2019) have made efforts to analyze this issue theoretically and proposed robust negative sampling techniques for graph embedding problem. NSCaching [119] is another interesting work that generates efficient negative samples for knowledge graphs. In Fig. 21 (b), we empirically show the effect on performance measures varying the number of negative samples. To conduct experiment, we choose Force2Vec, VERSE and LINE methods as they support random negative sampling approach. We take 25% of the vertices in the training set and report the F1-micro score for the rest of the testing dataset. We observe that performance score drops when we use more than 5 negative samples for the Pubmed dataset and continues to decrease for more negative samples. VERSE method is more sensitive to higher negative samples than others as its performance score significantly drops after using more than 15 negative samples for the Pubmed dataset. Note that the size of this dataset is relatively small as it has only around 19K vertices. For smaller graphs than Pubmed, the number of randomly selected negative samples will show more sensitivity than bigger graphs than the Pubmed dataset. The reason is that for bigger graphs, the probability of selecting false negative is lower compared to the smaller graphs. Thus, care must be taken to choose an effective number of negative samples rather than random selection. 
## (s37) Discussions and Limitations
(p37.0) Graph representation learning is a challenging problem as it is hard to capture different latent characteristics of the original graph in the embedding space. If the output embedding can not capture the intrinsic properties well, then it performs poorly on several prediction tasks. A single tool can not generalize the embedding well for all prediction tasks. For example, struc2vec performs well for structural equivalence prediction whereas DeepWalk performs well for homophily prediction. In addition, we have shown in our experimental analyses that some methods may consume a high amount of memory but run fast, whereas some methods may take less memory but run slow. Some methods can generate a high quality embedding but have higher runtime and consume more memory. We have summarized the results of some embedding methods except GNN models in Table 13, based on several characteristics. We have evaluated all of the tested methods in this survey scoring from L, M, H, and VH denoting Low, Medium, High, and Very High values, respectively. Note that we want low values (L) for memory consumption, running time and number of hyper-parameters. On the other hand, we want very high values (VH) representing a better score for scalability, robustness and performance. We put 'M/H' for struc2vec in performance as it performs well for networks having structural equivalence properties, however shows moderate performance for networks having homophily characteristics. H* represents the variable running time for the LINE tool as it has a high running time for small networks but takes comparatively less time for large networks with respect to other methods. From our analyses, we can presume that an optimal embedding tool will have less runtime and memory consumption cost; furthermore, it will generate a high quality embedding that will show superior performance in various prediction tasks. In reality, there is always a trade-off between our expectation and available resources. From our analyses, we observe that the existing methods face the following challenges and limitations.

(p37.1) • Runtime, Memory Cost and Scalability: Runtime and memory requirement are two bottlenecks of random-walk based embedding methods, though they show superior performance, e.g., DeepWalk achieves superior performance for most of the prediction tasks, though it consumes significant amount of memory and runs very slow. Besides these, most of the real-world social networks are dynamic  Table 13: Summary of graph embedding methods except GNN methods based on different characteristics. We score each tool from L, M, H, and VH which represent Low, Medium, High, and Very High, respectively. Note that L represents better score for memory consumption, running time and number of hyperparameters whereas VH represents better score for scalability, robustness and performance.

(p37.2) in nature i.e., they are changing (in size) rapidly. For example., Facebook has around 2.5 billion users and this number is increasing day by day. This large graph makes matrix factorization methods obsolete. Thus, scalability is an import issue for future research in developing graph embedding methods.

(p37.3) • Bottleneck in Optimization: Some embedding methods support multi-core implementations in shared memory architecture and employ asynchronous SGD to optimize the objective function. It makes the output embedding nondeterministic which is not expected. It also incurs the false sharing problem, which is an unexpected phenomenon in shared memory programming due to poor optimization [11]. Thus, efforts can be made for new embedding methods so that the optimization process becomes deterministic and free of unexpected bottlenecks [83].

(p37.4) • Visualization: The current methods embed graphs in vector space. Thus, they need another dimensionality reduction tool (e.g., t-SNE or UMAP) to be embedded in euclidean space for visualization. We have seen that the embedding of shallow networks or matrix factorization based methods can be used for several prediction tasks. A future direction can be to explore whether we can generate an embedding which can be directly used for visualization. Another interesting idea for dynamic graph visualization might be to use graph convolutional neural networks. The current visualization techniques mostly visualize static graph. If new vertices or edges arrive in the network, then we need to run the visualization method again. So, if we can learn weights for a graph using an inductive approach, as of graph convolutional neural networks, we can easily generate coordinates for new nodes which will facilitate visualization of dynamic graphs.

(p37.5) • Interpretability of Representation: Considering the irregular connections and structures of graphs, it is often found hard to generalize a model so that it can characterize different types of graphs well. Most of the methods assume that neighboring vertices will have a similar representation. This strategy works well for link prediction or even multi-class classification problem. If we go beyond that e.g., multi-label classification, random-walk or graph convolutional networks based methods become viable approaches. However, there are a few works on the interpretability aspects of graph embedding. In this direction, there is scope to explore more on the applicability of different complex network motifs and their theoretical aspects.

(p37.6) In addition to the above challenges, the selection of effective negative samples from a graph can be a future work. We have seen that false negative in randomly selected negative sampling approach plays an important role in optimization. Thus, special care must be taken while selecting negative samples from a graph. An illustrative theoretical work can give new insight about effective negative sampling in graph embedding domain.
