# Deep Learning-based Spacecraft Relative Navigation Methods: A Survey

CorpusID: 237260001 - [https://www.semanticscholar.org/paper/80ea722a20c29c71696aa453a7d52fde6508808c](https://www.semanticscholar.org/paper/80ea722a20c29c71696aa453a7d52fde6508808c)

Fields: Engineering, Computer Science

## (s1) Thousand Million Quadrillion
(p1.0) Deep learning more accurate than humans on image classification   Previous studies have approached the topic of DL-based navigation for space. Kothari et al. [4] collated various applications of DL for space, briefly discussing the achieved and prospective goals of gap and provide a comprehensive reference for researchers and engineers aspiring to leverage deep learning for this subject, specifically for the three main applications identified in Fig. 2. Fig. 3 shows the set of research methods and application domains covered by our survey. In Fig. 3, direct DNN methods are end-to-end methods using DNNs, which constitute a direct, uninterrupted pipeline from inputs x to the desired quantity to estimate y. In contrast, indirect DNN methods are those in which the DNN is exclusively tasked with performing the image processing functions on the input, while the actual quantity to be estimated is achieved by combining this output with other methods, such as classical ML, geometry-based optimisation, and Kalman filtering.

(p1.1) This paper is organized as follows. Section 2 presents a review of DL-based pose estimation algorithms for spacecraft rendezvous. Section 3 contains a detailed review of crater and hazard detection of Terrain Relative Navigation (TRN) using DNNs. Section 4 provides a review of DL techniques with a focus on asteroid exploration. Finally, Section 5 lists the main conclusions and discussions.
## (s6) Direct Frameworks for Spacecraft Relative Pose Estimation
(p6.0) In this survey, direct DL-based frameworks are defined as those in which the estimation of the desired quantity is entirely relayed to the DNN, thus forming a continuous, uninterrupted pipeline from input to output. For spacecraft relative navigation, the problem is posited as estimating the 6-DoF pose of a target, F t , in the frame of reference of a chaser, F c (as shown in Fig. 2a).

(p6.1) The target may be non-cooperative, in which case it will not relay any explicit information to the chaser's onboard navigation system, and the relative pose is estimated from acquired images of the target only.

(p6.2) By partitioning the relative pose space into discrete hypotheses, a classification framework may be established if the target spacecraft has a known model. Sharma et al. [7] have proposed a deep CNN for relative pose classification of non-cooperative spacecraft. Taking advantage of transfer learning, AlexNet model [29] pre-trained on the large ImageNet dataset [30] is modified by replacing the last few layers to adapt to the space imagery of the Tango spacecraft flown in the Prisma mission [31]. Ten datasets with different added noises are created from synthetic images. The proposed approach demonstrated greater accuracy than a baseline method using classical pose estimation techniques from 2D-3D feature matching but is deemed not fine enough for any application other than a coarse initialisation.  of Interest (RoI) pooling technique, and then fed to the other two branches of the CNN containing three fully connected layers.

(p6.3) The second branch classifies the target attitude in terms of a probability distribution of discrete classes. It minimises a standard cross-entropy loss for the N closest attitude labels in the viewsphere. Lastly, the third branch takes the N candidates obtained from the previous branch and minimises another cross-entropy loss to yield the relative weighting of each. The final refined attitude is obtained via quaternion averaging with resort to the computed weights, which can be seen as a soft classification method.

(p6.4) Mathematically, the SPN utilises a Gauss-Newton algorithm to solve a minimisation problem for the estimate of relative position, for which the required initial guess is obtained from the bounding box (analogously to Kehl et al. [34]). The network is initially trained on the ImageNet dataset, and then the branch layers are further trained with an 80 %-20 % train-validation split on the SPEED dataset. As they report, the SPN method performs at degree-level and centimetre-level on relative attitude and position error, respectively. In Ref. [33], Sharma and D'Amico expand their conference paper [8] by discussing two features of the SPN, target-in-target pose estimation and uncertainty quantification. The capability of estimating the uncertainty associated with the estimated pose of the SPN emphasises that SPN can be integrated with conventional navigation filters. Additionally, the authors detail the proposed SPEED dataset, considering the solar illumination of the synthetic images and the ground truth  calibration of the relative pose by the real images. The SPN is also trained in three versions by using different datasets, including SPEED, "Apogee Motor", "Imitation-25", and "PRISMA-25".

(p6.5) Experiments are also carried out to demonstrate two key features of SPN method and compare it with their previous work, namely CNN-based [7] and image processing-based feature detection and correspondence [35] methods.

(p6.6) Instead of employing a bounding box feature detection, Proen√ßa and Gao [36] modify a pretrained ResNet architecture [37] with initial weights trained on the Common Objects in Context (COCO) dataset to keep spatial feature resolution. Similarly to Ref. [8], two branches are designed to estimate 3D location and orientation, respectively. The position estimation consists of a simple regression branch with two fully connected layers and the relative error is minimised for better generalisation in terms of loss weight magnitudes. The continuous attitude estimation is then realised via a soft classification method [38]. Additionally, the authors present their own synthetic Unreal Rendered Spacecraft On-Orbit (URSO) dataset for training featuring Soyuz. Experiments on renders of URSO and SPEED datasets are conducted to evaluate the proposed framework, with which their model achieved a third and a second place on the synthetic and real test set categories of SPEED in KPEC, respectively. Moreover, the experimental results show that estimating the orientation by soft classification performs better than direct regression methods.
## (s16) Previous Works Contributing to the Field
(p16.0) Ref. [28], where a DNN is used to match the observed patch with the corresponding patch in the codebook, which is annotated with the relative pose, but with the dataset of Lunar surface. The alternative approach is to have a single class per patch on the database and train the DNN to be robust to viewpoint distortion, and then rely on classical image processing techniques to infer the pose based on the different observed features between the observations and matched patches.
## (s17) Summary and Conclusion
(p17.0) This work surveyed recent trends in deep learning techniques for 6-DoF relative pose estimation in spaceborne applications. Contributions in the field of computer vision were presented, followed by concrete applications from the literature to autonomous spacecraft navigation, including spaceborne pose estimation, crater and hazard detection of terrain relative navigation, and DL-based asteroid navigation. This survey is motivated by the applicability of DL techniques in relative spacecraft navigation for future space missions, i.e. rendezvous, docking, formation flying, descent and landing on the lunar surface, orbiting and inspecting asteroids. The general DNN framework for the applications in this research area was reviewed in terms of network structure, type of network, training method, dataset topology and generation, and attained performance.

(p17.1) First, a review of DNN-based S/C relative pose estimation techniques was given, in which a top level distinction between supervised and unsupervised methods was made, whereby contributions in the space domain were found to belong exclusively to the former. Context in terms of preceding ground-based applications was established. Further lower level categorisations were made; in particular, it was found that many techniques favoured a direct approach (so called "end-to-end"),

(p17.2) where a DNN pipeline is trained directly on images to yield the relative state. Indeed, this is a very appealing property of deep learning, as not only is the feature extraction task relayed to a CNN, but so is the modelling task, eliminating the "middleman" and allowing the user to focus mainly on the architecture design and optimisation of learnable parameters. However, it was seen that more accurate solutions were obtained by combining them with classical methods. For these indirect methods, a CNN was tasked with regressing the locations of 2D keypoints on the target and estimating the relative pose from geometrical correspondences with their 3D counterparts, using techniques such as PnP or nonlinear optimisation. Furthermore, such solutions are easily incorporated into navigation filters to further refine the estimate with continuous, smooth consistency (also beyond pose estimation). The role of RNNs, particularly LSTMs, is highlighted in the processing of a continuous stream of images. Tables 1 and 2 summarises these findings in terms of relative pose estimation error for spacecraft rendezvous DL applications.

(p17.3) Second, the applications of DNNs to TRN were divided into three aspects for surveying, in which the DNN-based crater and hazard detection methods were recognised as contributors towards building a terrain navigation system. It was pointed out that public open data for training and testing of DNN-based TRN frameworks is limited. Furthermore, DL-based relative navigation methods focusing on asteroid missions were provided. The challenges and motivations were discussed before a detailed review of this field.

(p17.4) Lastly, regarding unsupervised learning methods (i.e. concerning cases in which the desired output for each input is not given during training), far too little attention has been paid to this kind of technique for space navigation. However, unsupervised techniques such as CNN-SLAM (Simultaneous Localisation and Mapping) or unsupervised VO are underlined as a potential novel approach for the space domain and may be investigated in future. Additionally, most publications study the application of DL in space in a theoretical way without being concerned with computational performance; indeed, only a few publications [19,22,81] focus on actual deployments on hardware, considering things like execution time, and size of the training dataset. Therefore, it can be concluded that these studies towards the actual engineering practice have been little discussed and require further development.
