# Trustworthy Federated Learning: A Survey

CorpusID: 258823036 - [https://www.semanticscholar.org/paper/a0e40d9a07fdc5848ef2f10d9b63f5c28e0cec03](https://www.semanticscholar.org/paper/a0e40d9a07fdc5848ef2f10d9b63f5c28e0cec03)

Fields: Computer Science

## (s1) arXiv:2305.11537v1 [cs.AI] 19 May 2023
(p1.0) 3) Streamlined model verification and auditability: Facilitate users to confirm a model update's accuracy and easily access verifiable data for specific update versions. 4) Unalterable model update history: Showcase a globally uniform record of global model updates without changes. Within this log, each update corresponds to a distinct entry that cannot be edited or deleted once created. 5) Dependable client and model identification: Select trustworthy clients and models to enhance the FL process. 6) Reliable contribution evaluation and incentive allocation: Implement a credible assessment of contributions and provide incentives to encourage FL clients' participation in future sessions. Investigators must concentrate on novel approaches to address the challenges in FL by creating equitable and dependable metrics for worker selection and evaluation. 7) Dynamic authoritative keys management: Allow updates for authoritative keys, even if some, but not most, keys are compromised. 8) Timely Monitoring: Timely monitoring methods for workers and model assessment schemes are necessary. Strengthening security and privacy features is crucial for Trustworthy FL.

(p1.1) By emphasizing these objectives, crucial areas and fostering cooperation among stakeholders, the creation of secure and dependable FL systems can facilitate more responsible and ethical AI applications. Within the current research landscape, there is a noticeable absence of studies investigating the crucial pillars of trustworthiness, specifically in relation to FL. To the best of our knowledge, this is the pioneering work encompassing all facets of Trustworthy FL. In an effort to bridge the gaps in existing literature, this study presents the following contributions: 1) We furnish an overview of the fundamental principles underlying trustworthy FL, accompanied by a comprehensive architecture of Trustworthy FL and trust assessment mechanisms. 2) We develop a taxonomy centered on the most pertinent trustworthiness pillars within FL contexts. In order to construct this taxonomy, we identify three primary pillars as the foundational elements: Interpretability, Fairness, and Security & Privacy. Each pillar embodies a dimension of trust, which is further delineated into distinct concepts for each pillar. Additionally, we explore the key challenges and future directions in the realm of Trustworthy FL. 3) In conclusion, we highlighted the essential research challenges associated with each facet of Trustworthy FL, as well as the direction for future investigations.

(p1.2) The remainder of this paper is organized as follows: The structure of this paper is as follows: We commence with an introduction to FL and its classification in Section 2, succeeded by a discussion on trust in FL, fundamental principles of trustworthiness, and the architecture of Trustworthy FL systems in Section 3. Section 4 presents a literature review, emphasizing existing research in the domain. Sections 5-8 delve into trust evaluation, trust-aware interpretability, fairness-aware trustworthiness, and trust-aware security & privacy-preserving FL systems, respectively. Throughout the paper, we examine topics such as data and feature selection, data sharing, model selection, explainability, client selection, contribution assessment, incentive mechanisms, accountability, auditability, secure and data aggregation, privacy preservation, and more. In conclusion, we explore open challenges and future research avenues in the field of Trustworthy FL, laying the foundation for the creation of secure and dependable FL systems that facilitate responsible and ethical AI applications.

(p1.3) 3) Streamlined model verification and auditability: Facilitate users to confirm a model update's accuracy and easily access verifiable data for specific update versions. 4) Unalterable model update history: Showcase a globally uniform record of global model updates without changes. Within this log, each update corresponds to a distinct entry that cannot be edited or deleted once created. 5) Dependable client and model identification: Select trustworthy clients and models to enhance the FL process. 6) Reliable contribution evaluation and incentive allocation: Implement a credible assessment of contributions and provide incentives to encourage FL clients' participation in future sessions. Investigators must concentrate on novel approaches to address the challenges in FL by creating equitable and dependable metrics for worker selection and evaluation. 7) Dynamic authoritative keys management: Allow updates for authoritative keys, even if some, but not most, keys are compromised. 8) Timely Monitoring: Timely monitoring methods for workers and model assessment schemes are necessary. Strengthening security and privacy features is crucial for Trustworthy FL.

(p1.4) By emphasizing these objectives, crucial areas and fostering cooperation among stakeholders, the creation of secure and dependable FL systems can facilitate more responsible and ethical AI applications. Within the current research landscape, there is a noticeable absence of studies investigating the crucial pillars of trustworthiness, specifically in relation to FL. To the best of our knowledge, this is the pioneering work encompassing all facets of Trustworthy FL. In an effort to bridge the gaps in existing literature, this study presents the following contributions: 1) We furnish an overview of the fundamental principles underlying trustworthy FL, accompanied by a comprehensive architecture of Trustworthy FL and trust assessment mechanisms. 2) We develop a taxonomy centered on the most pertinent trustworthiness pillars within FL contexts. In order to construct this taxonomy, we identify three primary pillars as the foundational elements: Interpretability, Fairness, and Security & Privacy. Each pillar embodies a dimension of trust, which is further delineated into distinct concepts for each pillar. Additionally, we explore the key challenges and future directions in the realm of Trustworthy FL. 3) In conclusion, we highlighted the essential research challenges associated with each facet of Trustworthy FL, as well as the direction for future investigations.

(p1.5) The remainder of this paper is organized as follows: The structure of this paper is as follows: We commence with an introduction to FL and its classification in Section 2, succeeded by a discussion on trust in FL, fundamental principles of trustworthiness, and the architecture of Trustworthy FL systems in Section 3. Section 4 presents a literature review, emphasizing existing research in the domain. Sections 5-8 delve into trust evaluation, trust-aware interpretability, fairness-aware trustworthiness, and trust-aware security & privacy-preserving FL systems, respectively. Throughout the paper, we examine topics such as data and feature selection, data sharing, model selection, explainability, client selection, contribution assessment, incentive mechanisms, accountability, auditability, secure and data aggregation, privacy preservation, and more. In conclusion, we explore open challenges and future research avenues in the field of Trustworthy FL, laying the foundation for the creation of secure and dependable FL systems that facilitate responsible and ethical AI applications.
## (s2) II. FEDRATED LEARNING AN OVERVIEW
(p2.0) FL is a transformative approach to distributed machine learning, enabling the collaborative training of models across multiple devices or clients while preserving data privacy [11]. Various FL architectures have been developed to address the diverse challenges and requirements in data distribution, communication patterns, and coordination methods. These architectures can be broadly classified into three main categories: data distribution-based architectures, such as Horizontal FL (HFL), Vertical FL (VFL), and Federated Transfer Learning (FTL); scale and communication-based architectures, including Cross-Silo FL (CSFL) and Cross-Device FL (CDFL); and coordination-based architectures, which encompass Centralized FL, Decentralized FL, and Hierarchical FL. Each of these architectures caters to specific needs and constraints, ensuring optimal model development across a wide range of applications while maintaining data privacy and security.

(p2.1) A. Data Distribution-Based FL Architectures 1) Vertical FL: VFL involves federated training of datasets that share the same sample space but differ in feature spaces. It is apt for scenarios in which data is divided vertically based on feature dimensions, with different parties holding homogeneous data that partially overlaps in sample IDs. Entity alignment and encryption methods can be employed to address data sample overlapping during local training. One instance of VFL in the healthcare sector is the collaboration between hospitals and insurance companies, jointly training an AI model using their respective datasets. Although VFL provides data privacy and joint training benefits, it presents more implementation challenges than HFL due to the requirement for entity resolution and the limitations of current techniques for complex machine learning models.

(p2.2) 2) Horizontal FL: In HFL, multiple participants possessing datasets with identical feature spaces but varying sample spaces collaborate in training a joint global model. The datasets are used locally, and a server merges the local updates received from the participants to develop a global update without accessing the local data directly. One example of HFL in the healthcare domain is speech disorder detection, where users with different voices speak identical sentences, and the local updates are combined to create a comprehensive speech recognition model. HFL is primarily utilized in smart devices and IoT applications. It allows leveraging data from numerous sources without sharing raw data, thus maintaining privacy.

(p2.3) However, HFL may encounter challenges when dealing with a limited number of labeled entities. 3) Federated Transfer Learning: FTL is tailored to handle datasets that differ in both sample spaces and feature spaces. Transfer learning techniques are used to compute feature values from distinct feature spaces into a uniform representation, which is then employed for local dataset training. Privacy protection mechanisms, such as random masks, can be implemented during the gradient exchange between clients and servers. FTL can support smart healthcare use cases like disease diagnosis by enabling collaboration among multiple hospitals with distinct patients and treatment plans. Although FTL has potential, it remains an evolving research area with challenges related to communication efficiency and flexibility in dealing with diverse data structures. Nevertheless, it provides a promising solution for ensuring data security and user privacy while addressing data island problems. An illustration of these data distribution-based FL architectures is presented in Fig. 1.

(p2.4) FL is a transformative approach to distributed machine learning, enabling the collaborative training of models across multiple devices or clients while preserving data privacy [11]. Various FL architectures have been developed to address the diverse challenges and requirements in data distribution, communication patterns, and coordination methods. These architectures can be broadly classified into three main categories: data distribution-based architectures, such as Horizontal FL (HFL), Vertical FL (VFL), and Federated Transfer Learning (FTL); scale and communication-based architectures, including Cross-Silo FL (CSFL) and Cross-Device FL (CDFL); and coordination-based architectures, which encompass Centralized FL, Decentralized FL, and Hierarchical FL. Each of these architectures caters to specific needs and constraints, ensuring optimal model development across a wide range of applications while maintaining data privacy and security.

(p2.5) A. Data Distribution-Based FL Architectures 1) Vertical FL: VFL involves federated training of datasets that share the same sample space but differ in feature spaces. It is apt for scenarios in which data is divided vertically based on feature dimensions, with different parties holding homogeneous data that partially overlaps in sample IDs. Entity alignment and encryption methods can be employed to address data sample overlapping during local training. One instance of VFL in the healthcare sector is the collaboration between hospitals and insurance companies, jointly training an AI model using their respective datasets. Although VFL provides data privacy and joint training benefits, it presents more implementation challenges than HFL due to the requirement for entity resolution and the limitations of current techniques for complex machine learning models.

(p2.6) 2) Horizontal FL: In HFL, multiple participants possessing datasets with identical feature spaces but varying sample spaces collaborate in training a joint global model. The datasets are used locally, and a server merges the local updates received from the participants to develop a global update without accessing the local data directly. One example of HFL in the healthcare domain is speech disorder detection, where users with different voices speak identical sentences, and the local updates are combined to create a comprehensive speech recognition model. HFL is primarily utilized in smart devices and IoT applications. It allows leveraging data from numerous sources without sharing raw data, thus maintaining privacy.

(p2.7) However, HFL may encounter challenges when dealing with a limited number of labeled entities. 3) Federated Transfer Learning: FTL is tailored to handle datasets that differ in both sample spaces and feature spaces. Transfer learning techniques are used to compute feature values from distinct feature spaces into a uniform representation, which is then employed for local dataset training. Privacy protection mechanisms, such as random masks, can be implemented during the gradient exchange between clients and servers. FTL can support smart healthcare use cases like disease diagnosis by enabling collaboration among multiple hospitals with distinct patients and treatment plans. Although FTL has potential, it remains an evolving research area with challenges related to communication efficiency and flexibility in dealing with diverse data structures. Nevertheless, it provides a promising solution for ensuring data security and user privacy while addressing data island problems. An illustration of these data distribution-based FL architectures is presented in Fig. 1.
## (s9) V. TRUST EVALUATION IN FL
(p9.0) In this section, we present a collection of criteria for assessing trust evaluation methods grounded in FL: 1) Effectiveness: A vital aspect of trust evaluation is the accurate determination of a trustee's trust value. Trustworthy methods must ensure precision, demonstrated by metrics like recall, precision, accuracy, and F-score.

(p9.1) 2) Data and Algorithm Selection: Trust evaluation relies on two critical components: training data and model-building algorithms. Optimal data and algorithm choices lead to accurate evaluations, and methods should consider their impact on trust assessment.

(p9.2) 3) Robustness: Trust evaluation is vulnerable to attacks. Addressing these attacks enhances resistance to disruptions, ensuring robust evaluation methods. 4) Privacy Protection: Trust evaluation data might include sensitive user information. It is crucial to protect this data from unauthorized disclosure, prioritizing user privacy and trust evidence protection in trust evaluation processes.

(p9.3) 5) Context-Awareness: Trust evaluation methods should be adaptable to changes in application scenarios, contexts, or environments, reflecting the fundamental characteristic of trust: context-awareness. 6) Subjectivity: Trust evaluation must capture trust's subjective nature for a more authentic representation, emphasizing the importance of subjectivity as a key trust characteristic. 7) Distributed Learning:: In FL, trust evaluation methods should account for distributed data storage and processing, ensuring that trust assessment is compatible with the decentralized nature of the learning process.

(p9.4) 8) Local Model Quality:: Trust evaluation should consider the quality of local models, as FL relies on combining local models to create a global model. Assessing the quality of local models can help identify unreliable participants. 9) Incentive Mechanisms:: Implementing incentive mechanisms can encourage honest participation and cooperation, elevating trust assessment in FL by ensuring that participants are motivated to contribute high-quality data and models.

(p9.5) 10) Contribution Evaluation:: Trust evaluation methods should incorporate mechanisms to measure the value of each client's contributions to the global model. These mechanisms should consider factors such as data quality, data diversity, and the impact of the local model on the global model's performance.

(p9.6) 11) Client Selection:: Incorporating client selection strategies in trust evaluation helps identify and select reliable clients that can contribute effectively to the global model. By selecting trustworthy clients, the overall quality and trustworthiness of the FL system can be improved.

(p9.7) 12) Verifiability and Auditibility:: Trust evaluation methods should provide a means of verifying the accuracy and reliability of both local models and the global model. This could involve techniques such as cryptographic proofs, secure aggregation, or trusted execution environments, ensuring transparency and trustworthiness in the FL system.

(p9.8) In the field of network security, trust is considered a crucial aspect for ensuring the secure transmission of data. In the context of the vehicle-road-cloud collaborative system, trust evaluation becomes increasingly complex due to the heterogeneity of the network and its openness to attacks. To address this challenge, the authors in [29] proposed a trust evaluation scheme based on FL. The scheme is designed as a hierarchical trust evaluation model that takes into account the different trust indices at various layers and factors affecting trust among nodes. The proposed model updates trust values in real-time, providing a personalized trust evaluation for each device in the network. This allows for a more thorough assessment of trust than traditional trust evaluation mechanisms, while also reducing the energy consumption and increasing accuracy compared to previous schemes. By combining FL with the hierarchical trust evaluation model, the system solves the problem of limited edge node resources and reduces the overhead of trust evaluation. This innovative approach to trust evaluation in the vehicle-road-cloud collaborative system shows promising results in improving network security and reliability.

(p9.9) The authors in [30] proposed a solution to the problem of trust in group decision-making for FL systems. The key contribution of their work is the introduction of a trust-based consensus method, called Trust X-BFT (TX-BFT), which utilizes a consortium chain to reach a consensus among participants. The TX-BFT method evaluates the trust levels of participants based on their historical behaviors in previous consensus processes and stores this information in a public ledger on the blockchain. This information is used to incentivize participants with higher trust levels by rewarding them and punishing those with lower trust levels. This, in turn, helps to improve the overall trust perception performance of the FL network. The proposed method has three stages -preliminary, prepare, and commit -and utilizes a parliament of consensus nodes to communicate and reach a consensus. In each round, a leader collects block generation proposals and broadcasts the pre-prepare information, while the verifiers wait for the pre-prepare message. Once the verifiers receive 2/3 commit messages, they begin inserting the proposed block into the chain and marking their status as final committed. The simulation results and security analysis demonstrate that the TX-BFT method can effectively defend against malicious users and data, and enhance the trust and stability of FL networks. The authors' contribution provides a valuable solution to the problem of trust in group decision-making for FL systems and has the potential to be widely adopted in various applications.

(p9.10) A clustering-based and distance-based trust evaluation methods are proposed in [31]. The clustering-based method groups FL agents based on their trust scores, while the distance-based method calculates the trust scores based on the similarity of FL agents' behaviors. The authors introduce the trusted decentralized FL algorithm, which incorporates the trust concept into the FL process to enhance its security. This paper addresses the challenge of enhancing the security of FL by introducing trust as a metric to measure the trustworthiness of FL agents. The authors propose a mathematical framework for trust computation and aggregation in a multi-agent system, which is the main contribution of the paper. This framework enables the calculation of trust scores for each FL agent based on their behavior, which can then be used to assess the risk of malicious attacks. Furthermore, the authors propose an attack-tolerant consensus-based FL algorithm, which takes into account the trust scores of FL agents during the consensus step. This helps to mitigate the risk of malicious attacks and ensures the security of the FL training.

(p9.11) PRTrust in [32], a trust model is proposed for a peer-topeer federated cloud system. The authors aim to address the challenge of trust establishment among participating cloud service providers (CSPs) to enable resource sharing in a secured manner. The trust model considers both reputation-based trust and performance-based risk in evaluating the trustworthiness of CSPs. PRTrust provides a two-tier weighted performance evaluation mechanism, a risk evaluation mechanism, and a personalized reputation-based trust evaluation mechanism. It also provides a CSP selection mechanism based on the evaluated trust and risk. The authors intend to reduce the risk of sub-standard service delivery and improve the selection of appropriate CSPs for resource and service sharing.

(p9.12) The security of the Internet of Vehicles (IoV) relies heavily on trust management between various connected devices and nodes. With the increasing number of connected vehicles, it becomes imperative to establish trust and identify dishonest nodes. To improve the security of IoV, a new approach for trust management is proposed in [33], which combines FL with blockchain technology (FBTM). This approach involves designing a vehicular trust evaluation to enhance the data acquired for the FL model and developing a blockchain-based reputation system to securely store and share the global FL models. The proof of reputation consensus is also proposed to evaluate the reliability of roadside units functioning as aggregators in the IoV network. Simulation results demonstrate the effectiveness of the proposed FBTM approach in ensuring the security of the IoV network.

(p9.13) The research work in [34] proposes a Federated Hierarchical Trust Interaction (FHTI) scheme for the Cross-Domain Industrial Internet of Things (IIoT) to address the challenge of multidomain trust interaction. To achieve this, the FHTI scheme integrates consortium blockchain and FL in a seamless manner. A blockchain-based trusted environment for the IIoT is established, followed by the development of a multidomain behavior detection mechanism using FL. The hierarchical trust system is then constructed by combining blockchain transaction performance, leading to unified trust management across multiple domains. Finally, a blockchain cross-chain interaction mechanism is proposed to ensure the credibility of trust values between parties. The main contributions of the article include a two-tier consortium blockchain security architecture and a hierarchical trust mechanism based on federated detection of blockchain nodes, which enables dynamic trust evaluation and hierarchical trust management, thereby improving trust between IIoT devices and breaking down trust barriers between domains.

(p9.14) The proposed system [35] combines FL with trust establishment mechanism and recommender selection strategy to address the challenge of cold-start items in recommendation systems. The cold-start problem occurs when a recommender system has limited or no information about a new user or item. To address this issue, the authors propose a trust establishment mechanism that enables the recommender system to build trust relationships with potential recommenders. The trust scores are derived from the devices' resource utilization data and the credibility scores of the recommenders. Additionally, the authors propose a recommender selection strategy based on double deep Q learning that considers the devices' trust scores and energy levels to choose the subset of IoT devices that will contribute to improving the accuracy of the recommendations. The authors demonstrate the value of FL for the cold-start item recommendation problem and provide insights into how to design intelligent algorithms that support the FL process while prioritizing trust management.

(p9.15) The authors presents a novel approach to address the challenges of trust management in cross-domain industrial IoT by introducing the FHTI architecture in [36]. It combines the power of consortium blockchain and FL to provide a safe and reliable network environment for users. The FHTI scheme is based on a behavior detection mechanism that uses FL to evaluate the trustworthiness of devices in a multidomain setting. The architecture also establishes a blockchain crosschain interaction mechanism that ensures the credibility of the trust value of both parties. The results of the simulation indicate that the proposed scheme can improve the accuracy of abnormal behavior recognition, increase resource utilization, and enhance the stability of the system compared to traditional methods. The FHTI scheme presents a promising solution for trust management in the cross-domain industrial IoT.

(p9.16) In this section, we present a collection of criteria for assessing trust evaluation methods grounded in FL: 1) Effectiveness: A vital aspect of trust evaluation is the accurate determination of a trustee's trust value. Trustworthy methods must ensure precision, demonstrated by metrics like recall, precision, accuracy, and F-score.

(p9.17) 2) Data and Algorithm Selection: Trust evaluation relies on two critical components: training data and model-building algorithms. Optimal data and algorithm choices lead to accurate evaluations, and methods should consider their impact on trust assessment.

(p9.18) 3) Robustness: Trust evaluation is vulnerable to attacks. Addressing these attacks enhances resistance to disruptions, ensuring robust evaluation methods. 4) Privacy Protection: Trust evaluation data might include sensitive user information. It is crucial to protect this data from unauthorized disclosure, prioritizing user privacy and trust evidence protection in trust evaluation processes.

(p9.19) 5) Context-Awareness: Trust evaluation methods should be adaptable to changes in application scenarios, contexts, or environments, reflecting the fundamental characteristic of trust: context-awareness. 6) Subjectivity: Trust evaluation must capture trust's subjective nature for a more authentic representation, emphasizing the importance of subjectivity as a key trust characteristic. 7) Distributed Learning:: In FL, trust evaluation methods should account for distributed data storage and processing, ensuring that trust assessment is compatible with the decentralized nature of the learning process.

(p9.20) 8) Local Model Quality:: Trust evaluation should consider the quality of local models, as FL relies on combining local models to create a global model. Assessing the quality of local models can help identify unreliable participants. 9) Incentive Mechanisms:: Implementing incentive mechanisms can encourage honest participation and cooperation, elevating trust assessment in FL by ensuring that participants are motivated to contribute high-quality data and models.

(p9.21) 10) Contribution Evaluation:: Trust evaluation methods should incorporate mechanisms to measure the value of each client's contributions to the global model. These mechanisms should consider factors such as data quality, data diversity, and the impact of the local model on the global model's performance.

(p9.22) 11) Client Selection:: Incorporating client selection strategies in trust evaluation helps identify and select reliable clients that can contribute effectively to the global model. By selecting trustworthy clients, the overall quality and trustworthiness of the FL system can be improved.

(p9.23) 12) Verifiability and Auditibility:: Trust evaluation methods should provide a means of verifying the accuracy and reliability of both local models and the global model. This could involve techniques such as cryptographic proofs, secure aggregation, or trusted execution environments, ensuring transparency and trustworthiness in the FL system.

(p9.24) In the field of network security, trust is considered a crucial aspect for ensuring the secure transmission of data. In the context of the vehicle-road-cloud collaborative system, trust evaluation becomes increasingly complex due to the heterogeneity of the network and its openness to attacks. To address this challenge, the authors in [29] proposed a trust evaluation scheme based on FL. The scheme is designed as a hierarchical trust evaluation model that takes into account the different trust indices at various layers and factors affecting trust among nodes. The proposed model updates trust values in real-time, providing a personalized trust evaluation for each device in the network. This allows for a more thorough assessment of trust than traditional trust evaluation mechanisms, while also reducing the energy consumption and increasing accuracy compared to previous schemes. By combining FL with the hierarchical trust evaluation model, the system solves the problem of limited edge node resources and reduces the overhead of trust evaluation. This innovative approach to trust evaluation in the vehicle-road-cloud collaborative system shows promising results in improving network security and reliability.

(p9.25) The authors in [30] proposed a solution to the problem of trust in group decision-making for FL systems. The key contribution of their work is the introduction of a trust-based consensus method, called Trust X-BFT (TX-BFT), which utilizes a consortium chain to reach a consensus among participants. The TX-BFT method evaluates the trust levels of participants based on their historical behaviors in previous consensus processes and stores this information in a public ledger on the blockchain. This information is used to incentivize participants with higher trust levels by rewarding them and punishing those with lower trust levels. This, in turn, helps to improve the overall trust perception performance of the FL network. The proposed method has three stages -preliminary, prepare, and commit -and utilizes a parliament of consensus nodes to communicate and reach a consensus. In each round, a leader collects block generation proposals and broadcasts the pre-prepare information, while the verifiers wait for the pre-prepare message. Once the verifiers receive 2/3 commit messages, they begin inserting the proposed block into the chain and marking their status as final committed. The simulation results and security analysis demonstrate that the TX-BFT method can effectively defend against malicious users and data, and enhance the trust and stability of FL networks. The authors' contribution provides a valuable solution to the problem of trust in group decision-making for FL systems and has the potential to be widely adopted in various applications.

(p9.26) A clustering-based and distance-based trust evaluation methods are proposed in [31]. The clustering-based method groups FL agents based on their trust scores, while the distance-based method calculates the trust scores based on the similarity of FL agents' behaviors. The authors introduce the trusted decentralized FL algorithm, which incorporates the trust concept into the FL process to enhance its security. This paper addresses the challenge of enhancing the security of FL by introducing trust as a metric to measure the trustworthiness of FL agents. The authors propose a mathematical framework for trust computation and aggregation in a multi-agent system, which is the main contribution of the paper. This framework enables the calculation of trust scores for each FL agent based on their behavior, which can then be used to assess the risk of malicious attacks. Furthermore, the authors propose an attack-tolerant consensus-based FL algorithm, which takes into account the trust scores of FL agents during the consensus step. This helps to mitigate the risk of malicious attacks and ensures the security of the FL training.

(p9.27) PRTrust in [32], a trust model is proposed for a peer-topeer federated cloud system. The authors aim to address the challenge of trust establishment among participating cloud service providers (CSPs) to enable resource sharing in a secured manner. The trust model considers both reputation-based trust and performance-based risk in evaluating the trustworthiness of CSPs. PRTrust provides a two-tier weighted performance evaluation mechanism, a risk evaluation mechanism, and a personalized reputation-based trust evaluation mechanism. It also provides a CSP selection mechanism based on the evaluated trust and risk. The authors intend to reduce the risk of sub-standard service delivery and improve the selection of appropriate CSPs for resource and service sharing.

(p9.28) The security of the Internet of Vehicles (IoV) relies heavily on trust management between various connected devices and nodes. With the increasing number of connected vehicles, it becomes imperative to establish trust and identify dishonest nodes. To improve the security of IoV, a new approach for trust management is proposed in [33], which combines FL with blockchain technology (FBTM). This approach involves designing a vehicular trust evaluation to enhance the data acquired for the FL model and developing a blockchain-based reputation system to securely store and share the global FL models. The proof of reputation consensus is also proposed to evaluate the reliability of roadside units functioning as aggregators in the IoV network. Simulation results demonstrate the effectiveness of the proposed FBTM approach in ensuring the security of the IoV network.

(p9.29) The research work in [34] proposes a Federated Hierarchical Trust Interaction (FHTI) scheme for the Cross-Domain Industrial Internet of Things (IIoT) to address the challenge of multidomain trust interaction. To achieve this, the FHTI scheme integrates consortium blockchain and FL in a seamless manner. A blockchain-based trusted environment for the IIoT is established, followed by the development of a multidomain behavior detection mechanism using FL. The hierarchical trust system is then constructed by combining blockchain transaction performance, leading to unified trust management across multiple domains. Finally, a blockchain cross-chain interaction mechanism is proposed to ensure the credibility of trust values between parties. The main contributions of the article include a two-tier consortium blockchain security architecture and a hierarchical trust mechanism based on federated detection of blockchain nodes, which enables dynamic trust evaluation and hierarchical trust management, thereby improving trust between IIoT devices and breaking down trust barriers between domains.

(p9.30) The proposed system [35] combines FL with trust establishment mechanism and recommender selection strategy to address the challenge of cold-start items in recommendation systems. The cold-start problem occurs when a recommender system has limited or no information about a new user or item. To address this issue, the authors propose a trust establishment mechanism that enables the recommender system to build trust relationships with potential recommenders. The trust scores are derived from the devices' resource utilization data and the credibility scores of the recommenders. Additionally, the authors propose a recommender selection strategy based on double deep Q learning that considers the devices' trust scores and energy levels to choose the subset of IoT devices that will contribute to improving the accuracy of the recommendations. The authors demonstrate the value of FL for the cold-start item recommendation problem and provide insights into how to design intelligent algorithms that support the FL process while prioritizing trust management.

(p9.31) The authors presents a novel approach to address the challenges of trust management in cross-domain industrial IoT by introducing the FHTI architecture in [36]. It combines the power of consortium blockchain and FL to provide a safe and reliable network environment for users. The FHTI scheme is based on a behavior detection mechanism that uses FL to evaluate the trustworthiness of devices in a multidomain setting. The architecture also establishes a blockchain crosschain interaction mechanism that ensures the credibility of the trust value of both parties. The results of the simulation indicate that the proposed scheme can improve the accuracy of abnormal behavior recognition, increase resource utilization, and enhance the stability of the system compared to traditional methods. The FHTI scheme presents a promising solution for trust management in the cross-domain industrial IoT.
## (s11) A. Trustworthy Feature and Sample Selection
(p11.0) The authors proposes a new approach called Federated Stochastic Dual-Gate based Feature Selection (FedSDG-FS) [37] for feature selection in Vertical FL (VFL). Existing FS works for VFL assume prior knowledge on the number of noisy features or the threshold of useful features to be selected, making them unsuitable for practical applications. FedSDG-FS uses a Gaussian stochastic dual-gate to approximate the probability of a feature being selected with privacy protection through Partially Homomorphic Encryption without a trusted third-party. It also proposes a feature importance initialization method based on Gini impurity to reduce overhead. Experiments show that FedSDG-FS outperforms existing approaches in selecting high-quality features and building global models with higher performance. The proposed method solves the problem of efficient feature selection in VF.

(p11.1) A trustworthiness evaluation framework, TrustE-VC, is proposed in [38] that combines criteria importance and performance rates to determine the service attributes of vertical FL that require more attention. It also suggests a three-level security feature to enhance effectiveness and trustworthiness in VC. The proposed framework comprises three interconnected components, including an aggregation of the security evaluation values, a fuzzy multicriteria decision-making algorithm, and a simple additive weight associated with importanceperformance analysis and performance rate to visualize the framework findings. The proposed framework provides a useful tool for designers and industrial CV practices to evaluate and select industrial CV trust requirements. The framework addresses the challenges of developing effective and trustworthy VFL models.

(p11.2) In [39], authors present an XAI Federated Deep Reinforcement Learning model aimed at improving decision-making for new Autonomous Vehicles (AVs) in trajectory and motion planning. This model tackles appropriate AV selection for FL and guarantees explainability and trustworthiness. Using XAI, it determines each feature's importance and AV's trust value. A trust-based deep reinforcement learning model is introduced for selections, showing superior performance in real-world data experiments. The study highlights trust's role in AV selection and proposes an innovative XAI-based trust computation method, providing a sophisticated mechanism for new AVs' decision-making.

(p11.3) The main contribution of [40] is a FL model named Fed-PARL, which aims to reduce the model size while performing sample-based pruning, avoiding misbehaved clients, and considering resource-availability for partial workloads. This is especially useful for resource-constrained IoT clients. FedPARL, a tri-level FL strategy, aids clients in conserving resources throughout training, eliminates unreliable or resource-deficient clients during selection, and allows for flexible local epochs based on client resource availability. An incentive-deterrent framework promotes effective clients and discourages poorperforming or malicious ones. This approach exhibits robustness in constrained FL-IoT environments, and results reveal that FedPARL outperforms existing methods, delivering an enhanced FL solution.

(p11.4) This authors proposes a new approach to optimize smart device sampling and data offloading in FL [41]. The authors propose a joint sampling and data offloading optimization problem where devices are selected based on their expected contribution to model training. The non-selected devices can transfer data to selected ones based on estimated data dissimilarities between nodes. The proposed approach aims to improve the efficiency and accuracy of FedL by reducing the communication and computational costs. The approach is evaluated using real-world data, and the results demonstrate its effectiveness in improving the performance of FedL.
## (s13) C. Trustworthy Model Selection
(p13.0) In FL, it is crucial to evaluate the contributions of participants to the performance of the final model while ensuring privacy. To achieve this, the widely adopted method is the use of Shapley Value (SV) techniques. However, existing SV-based approaches are computationally expensive and impractical for real-world applications. To tackle this issue, authors in [45] introduced the Guided Truncation Gradient Kapley (GTG-Shapley) approach, which reduces the computation cost of SVbased FL participant contribution evaluation. Unlike traditional methods, GTG-Shapley does not require extra learning tasks from participants, as it reconstructs FL sub-models using their previous gradient updates instead of training them from scratch. Additionally, GTG-Shapley employs guided Monte Carlo sampling to further reduce the number of required model reconstructions and evaluations, thereby enhancing the efficiency of SV computation. GTG-Shapley offers a more practical and scalable solution for fair FL participant contribution evaluation. GTG-Shapley enables FL to be more practical and widely adopted in real-world applications.

(p13.1) The aggregation of local models from participating clients is a critical component in generating the final global model in FL. However, traditional aggregation methods can be susceptible to adversarial attacks and client failures. To mitigate this issue, the authors of this paper propose a truth inference approach to FL that incorporates the reliability of each client's local model into the aggregation process. The proposed approach in [46] models the clients' reliability based on their submitted local model parameters and considers these parameters during the aggregation process to produce a robust estimate of the global model. The authors have further enhanced the method by considering the model parameters submitted by clients in previous rounds in addition to the current round, thus providing a more comprehensive evaluation of client reliability.The proposed truth inference approach provides a more robust estimate of the global model, protects against potential adversarial attacks, and considers client reliability in the aggregation process, thereby improving the robustness of FL.

(p13.2) In FL, the server aggregates the uploaded model parameters from participating clients to generate a global model. The common practice is to evenly weight the local models, assuming equal contribution from all nodes. However, the heterogeneous nature of devices and data leads to variations in contribution from users. To address this issue, authors in [47] introduces a reputation-enabled aggregation method that adjusts the aggregation weights based on the reputation scores of users. The reputation score is computed based on the performance metrics of the local models during each training round. The proposed method showed an improvement of 17.175% over the standard baseline in non-independent and identically distributed (non-IID) scenarios for a FL network of 100 participants. This work considers the mobile network of distributed computing nodes where the performance and reputation of individual nodes vary. The reputation-enabled weighted aggregation is hypothesized to lead to faster convergence and a higher accuracy level for FL in a mobile environment.
## (s17) B. Trustworthy Contribution Evaluation
(p17.0) The contribution measurement strategies used in FL systems can be classified into three main categories: self-report based evaluation, Shapley value based evaluation, and influence and reputation based evaluation. Self-report based evaluation involves the data owner directly reporting their level of contribution to the model owner. Metrics used to evaluate the contribution include computational resources and data size. The Shapley value based evaluation takes into account the participation order of the data owners and assesses their contributions in a fair manner, typically used in cooperative games. Influence and reputation based evaluation considers the client's impact on the FL model's loss function and their reliability, and may involve techniques like Fed-Influence and reputation mechanisms that can be combined with blockchain. A client's reputation is generally a combination of their internal reputation in a task and their accumulated reputation based on historical records. The authors in [89] focuses on the critical aspect of measuring the contributions of users in FL systems. The authors conduct a comprehensive analysis of the different strategies for evaluating user contributions, examining the factors that can impact the effectiveness of these methods. The paper emphasizes the need for fair and accurate evaluation techniques to assess the contributions of data owners in FL and provides valuable insights into the current state of research in this area. This study highlights the importance of considering user contributions in FL systems and provides a solid foundation for future research in this field. The categorization and most relevant research work are presented in following sub sections.

(p17.1) 1) Smart Contract based Trustworthy Contribution Evaluation: The authors in [91] proposes a solution to the issue of data validity and quality in FL systems by utilizing the EOS blockchain and IPFS. The system records uploaded updates in a scalable manner and rewards users based on the cost of their training data. To ensure that only valuable updates are validated and rewarded, the authors propose the Class-Sampled Validation Error Scheme (CSVES). This scheme tailors the validation set to a device's data breakdown and Reputation mechanism evaluates model quality and contribution, which encourages data owners to join the BFL and contribute high-quality data for local and weighted global model aggregation and reward allocation. checks the validity of the data cost claimed by the device. By implementing CSVES, the system can ensure that the data quality is maintained while incentivizing users to contribute high-quality updates to the FL model.

(p17.2) A BC-based FL scheme with a reputation mechanism to motivate data owners in high-quality data contribution has been proposed in [96]. By integrating smart contract technology and blockchain, the authors aim to create a decentralized and trustworthy environment for conducting FL tasks transparently and fairly. The proposed reputation mechanism evaluates model quality and contribution, which encourages data owners to join the BFL and contribute high-quality data for local and weighted global model aggregation and reward allocation. The noncooperative game theory with equilibrium point make sure the highest rewrard to the contributer with high quality data. Moreover, an optional grouping mechanism is proposed to address the high complexity of a large number of participants. The BFL mechanism is expected to improve the credibility and reliability of FL and guarantee the model quality.

(p17.3) 2) Shapely Value and Consensus based Trustworthy Contribution Evaluation: In [90], a blockchain-assisted FL framework is presented to encourage honest participation and reward fair contributions. The framework employs a new consensus mechanism known as "Proof of Interpretation and Selection" (PoIS), which evaluates the contributions of individual clients by analyzing model interpretation results. PoIS aggregates feature attributions to distinguish prominent contributors and outliers and uses a credit function that considers contribution, relevance, and past performance to determine incentives. The proposed framework has been tested against various types of adversaries, datasets, and attack strategies and found to be robust. This framework offers a promising solution for addressing the issues of traditional FL and ensuring fairness in contribution-based incentivization.

(p17.4) The authors propose a decentralized FL system named BESIFL (Blockchain Empowered Secure and Incentive FL) that leverages blockchain technology to remove the central FL server in [94]. Three essential components are there in system: an accuracy-based malicious node detection mechanism, a contribution-based incentive mechanism, and an algorithm that coordinates both mechanisms. The malicious node detection mechanism identifies and removes malicious nodes during the training process, while the contribution-based incentive mechanism motivates nodes to participate in FL and rewards them based on their contribution to model training. BESIFL is designed to address the security and incentive issues in FL while also stimulating credible nodes to contribute to the model training. The proposed system applies the consensus algorithm and identity authentication of blockchain to ensure the security of model training and employs mechanisms for accuracy-based malicious node detection, contribution-based node selection, and token-based node incentive.

(p17.5) The varying data quality and heterogeneous data distributions across multiple healthcare institutions pose significant challenges to existing FL frameworks. To address these issues, a Contribution-Aware FL (CAreFL) framework [95], has been proposed, which focuses on fair and efficient contribution evaluation of FL participants. The proposed GTG-Shapley approach allows for fast and accurate evaluation of participant contributions. Moreover, the framework introduces a novel FL model aggregation approach, which selects the best performing sub-model for the next round of local training instead of always aggregating all received local models. This approach addresses the heterogeneity issues of data distribution in the healthcare sector. The historical contribution evaluation records are further converted into reputation values for the FL participants, which can serve as a basis for stakeholder management decision support. The CAreFL framework offers a promising solution to the challenges faced by existing FL frameworks in the healthcare sector, improving FL model performance while ensuring privacy and fairness.

(p17.6) 3) Privacy Preserving Trustworthy Contribution Evaluation: Authors presents a novel architecture for healthcare institutions to collaborate in improving the performance of a global ML model in [92]. The proposed system utilizes a combination of blockchain and secure multi-party computation (SMPC) to ensure data integrity, model versioning and privacy preservation during model training and ensemble. Unlike traditional methods, proposed architecture prioritizes general model evaluation over incentivization for fair contribution assessment. This evaluation process is carried out by the blockchain nodes and recorded on tamper-proof storage. The final contribution of each participant's ML model is determined based on their performance on unforeseen data. Additionally, the architecture enables each participant to define their own model structure, taking into account the varying computing power among participants. The proposed hierarchical ensemble FL method promises to advance the field of collaborative ML in healthcare while maintaining the privacy and security of sensitive medical data.

(p17.7) The authors present a decentralized Fair and Privacy-Preserving Deep Learning (FPPDL) framework in [93], that aims to address the issue of fairness in FL models. Unlike traditional FL solutions that provide all parties with the same model regardless of their contribution, FPPDL aims to provide each participant with a final FL model that reflects their individual contributions. To achieve fairness, the authors propose a local credibility mutual evaluation mechanism, and for privacy preservation, a three-layer onion-style encryption scheme is proposed. The framework operates by recording all transactions, including uploading and downloading, through blockchain technology. This eliminates the need for participants to trust each other or a third party. The proposed framework is designed to create a healthy FL ecosystem where each participant's contribution is valued and accurately reflected in the final FL model. Table 3 provides an extensive overview of the research conducted on trustworthy contribution evaluation in FL.

(p17.8) The contribution measurement strategies used in FL systems can be classified into three main categories: self-report based evaluation, Shapley value based evaluation, and influence and reputation based evaluation. Self-report based evaluation involves the data owner directly reporting their level of contribution to the model owner. Metrics used to evaluate the contribution include computational resources and data size. The Shapley value based evaluation takes into account the participation order of the data owners and assesses their contributions in a fair manner, typically used in cooperative games. Influence and reputation based evaluation considers the client's impact on the FL model's loss function and their reliability, and may involve techniques like Fed-Influence and reputation mechanisms that can be combined with blockchain. A client's reputation is generally a combination of their internal reputation in a task and their accumulated reputation based on historical records. The authors in [89] focuses on the critical aspect of measuring the contributions of users in FL systems. The authors conduct a comprehensive analysis of the different strategies for evaluating user contributions, examining the factors that can impact the effectiveness of these methods. The paper emphasizes the need for fair and accurate evaluation techniques to assess the contributions of data owners in FL and provides valuable insights into the current state of research in this area. This study highlights the importance of considering user contributions in FL systems and provides a solid foundation for future research in this field. The categorization and most relevant research work are presented in following sub sections.

(p17.9) 1) Smart Contract based Trustworthy Contribution Evaluation: The authors in [91] proposes a solution to the issue of data validity and quality in FL systems by utilizing the EOS blockchain and IPFS. The system records uploaded updates in a scalable manner and rewards users based on the cost of their training data. To ensure that only valuable updates are validated and rewarded, the authors propose the Class-Sampled Validation Error Scheme (CSVES). This scheme tailors the validation set to a device's data breakdown and Reputation mechanism evaluates model quality and contribution, which encourages data owners to join the BFL and contribute high-quality data for local and weighted global model aggregation and reward allocation. checks the validity of the data cost claimed by the device. By implementing CSVES, the system can ensure that the data quality is maintained while incentivizing users to contribute high-quality updates to the FL model.

(p17.10) A BC-based FL scheme with a reputation mechanism to motivate data owners in high-quality data contribution has been proposed in [96]. By integrating smart contract technology and blockchain, the authors aim to create a decentralized and trustworthy environment for conducting FL tasks transparently and fairly. The proposed reputation mechanism evaluates model quality and contribution, which encourages data owners to join the BFL and contribute high-quality data for local and weighted global model aggregation and reward allocation. The noncooperative game theory with equilibrium point make sure the highest rewrard to the contributer with high quality data. Moreover, an optional grouping mechanism is proposed to address the high complexity of a large number of participants. The BFL mechanism is expected to improve the credibility and reliability of FL and guarantee the model quality.

(p17.11) 2) Shapely Value and Consensus based Trustworthy Contribution Evaluation: In [90], a blockchain-assisted FL framework is presented to encourage honest participation and reward fair contributions. The framework employs a new consensus mechanism known as "Proof of Interpretation and Selection" (PoIS), which evaluates the contributions of individual clients by analyzing model interpretation results. PoIS aggregates feature attributions to distinguish prominent contributors and outliers and uses a credit function that considers contribution, relevance, and past performance to determine incentives. The proposed framework has been tested against various types of adversaries, datasets, and attack strategies and found to be robust. This framework offers a promising solution for addressing the issues of traditional FL and ensuring fairness in contribution-based incentivization.

(p17.12) The authors propose a decentralized FL system named BESIFL (Blockchain Empowered Secure and Incentive FL) that leverages blockchain technology to remove the central FL server in [94]. Three essential components are there in system: an accuracy-based malicious node detection mechanism, a contribution-based incentive mechanism, and an algorithm that coordinates both mechanisms. The malicious node detection mechanism identifies and removes malicious nodes during the training process, while the contribution-based incentive mechanism motivates nodes to participate in FL and rewards them based on their contribution to model training. BESIFL is designed to address the security and incentive issues in FL while also stimulating credible nodes to contribute to the model training. The proposed system applies the consensus algorithm and identity authentication of blockchain to ensure the security of model training and employs mechanisms for accuracy-based malicious node detection, contribution-based node selection, and token-based node incentive.

(p17.13) The varying data quality and heterogeneous data distributions across multiple healthcare institutions pose significant challenges to existing FL frameworks. To address these issues, a Contribution-Aware FL (CAreFL) framework [95], has been proposed, which focuses on fair and efficient contribution evaluation of FL participants. The proposed GTG-Shapley approach allows for fast and accurate evaluation of participant contributions. Moreover, the framework introduces a novel FL model aggregation approach, which selects the best performing sub-model for the next round of local training instead of always aggregating all received local models. This approach addresses the heterogeneity issues of data distribution in the healthcare sector. The historical contribution evaluation records are further converted into reputation values for the FL participants, which can serve as a basis for stakeholder management decision support. The CAreFL framework offers a promising solution to the challenges faced by existing FL frameworks in the healthcare sector, improving FL model performance while ensuring privacy and fairness.

(p17.14) 3) Privacy Preserving Trustworthy Contribution Evaluation: Authors presents a novel architecture for healthcare institutions to collaborate in improving the performance of a global ML model in [92]. The proposed system utilizes a combination of blockchain and secure multi-party computation (SMPC) to ensure data integrity, model versioning and privacy preservation during model training and ensemble. Unlike traditional methods, proposed architecture prioritizes general model evaluation over incentivization for fair contribution assessment. This evaluation process is carried out by the blockchain nodes and recorded on tamper-proof storage. The final contribution of each participant's ML model is determined based on their performance on unforeseen data. Additionally, the architecture enables each participant to define their own model structure, taking into account the varying computing power among participants. The proposed hierarchical ensemble FL method promises to advance the field of collaborative ML in healthcare while maintaining the privacy and security of sensitive medical data.

(p17.15) The authors present a decentralized Fair and Privacy-Preserving Deep Learning (FPPDL) framework in [93], that aims to address the issue of fairness in FL models. Unlike traditional FL solutions that provide all parties with the same model regardless of their contribution, FPPDL aims to provide each participant with a final FL model that reflects their individual contributions. To achieve fairness, the authors propose a local credibility mutual evaluation mechanism, and for privacy preservation, a three-layer onion-style encryption scheme is proposed. The framework operates by recording all transactions, including uploading and downloading, through blockchain technology. This eliminates the need for participants to trust each other or a third party. The proposed framework is designed to create a healthy FL ecosystem where each participant's contribution is valued and accurately reflected in the final FL model. Table 3 provides an extensive overview of the research conducted on trustworthy contribution evaluation in FL.
## (s19) 1) Game Theory based Trustworthy Incentive Mechanism:
(p19.0) In [100], the authors propose a novel approach to designing incentives for a blockchain-enabled FL platform using mechanism design, an economic approach to realizing desired objectives in situations where participants act rationally. The main idea behind the incentive mechanism is to introduce a repeated competition for model updates, so that any rational worker follows the protocol and maximizes their profits. During each round, selected workers choose the best k model updates from previous round and update their own model based on them. The reward to workers in the previous round is decided by the vote of the next round workers. The model updates of the next round workers are also competed and voted by workers in the subsequent round, ensuring that they cannot sabotage the system. The authors provide a rigorous theoretical analysis of the incentive compatibility based on contest theory and clarify the optimal conditions for reward policy in a blockchain-enabled FL platform. The contribution of the paper includes a competitive incentive mechanism design, a fullfledged protocol that can be implemented on existing public blockchains, and a theoretical analysis to clarify incentive compatibility based on contest theory.
## (s48) arXiv:2305.11537v1 [cs.AI] 19 May 2023
(p48.0) 3) Streamlined model verification and auditability: Facilitate users to confirm a model update's accuracy and easily access verifiable data for specific update versions. 4) Unalterable model update history: Showcase a globally uniform record of global model updates without changes. Within this log, each update corresponds to a distinct entry that cannot be edited or deleted once created. 5) Dependable client and model identification: Select trustworthy clients and models to enhance the FL process. 6) Reliable contribution evaluation and incentive allocation: Implement a credible assessment of contributions and provide incentives to encourage FL clients' participation in future sessions. Investigators must concentrate on novel approaches to address the challenges in FL by creating equitable and dependable metrics for worker selection and evaluation. 7) Dynamic authoritative keys management: Allow updates for authoritative keys, even if some, but not most, keys are compromised. 8) Timely Monitoring: Timely monitoring methods for workers and model assessment schemes are necessary. Strengthening security and privacy features is crucial for Trustworthy FL.

(p48.1) By emphasizing these objectives, crucial areas and fostering cooperation among stakeholders, the creation of secure and dependable FL systems can facilitate more responsible and ethical AI applications. Within the current research landscape, there is a noticeable absence of studies investigating the crucial pillars of trustworthiness, specifically in relation to FL. To the best of our knowledge, this is the pioneering work encompassing all facets of Trustworthy FL. In an effort to bridge the gaps in existing literature, this study presents the following contributions: 1) We furnish an overview of the fundamental principles underlying trustworthy FL, accompanied by a comprehensive architecture of Trustworthy FL and trust assessment mechanisms. 2) We develop a taxonomy centered on the most pertinent trustworthiness pillars within FL contexts. In order to construct this taxonomy, we identify three primary pillars as the foundational elements: Interpretability, Fairness, and Security & Privacy. Each pillar embodies a dimension of trust, which is further delineated into distinct concepts for each pillar. Additionally, we explore the key challenges and future directions in the realm of Trustworthy FL. 3) In conclusion, we highlighted the essential research challenges associated with each facet of Trustworthy FL, as well as the direction for future investigations.

(p48.2) The remainder of this paper is organized as follows: The structure of this paper is as follows: We commence with an introduction to FL and its classification in Section 2, succeeded by a discussion on trust in FL, fundamental principles of trustworthiness, and the architecture of Trustworthy FL systems in Section 3. Section 4 presents a literature review, emphasizing existing research in the domain. Sections 5-8 delve into trust evaluation, trust-aware interpretability, fairness-aware trustworthiness, and trust-aware security & privacy-preserving FL systems, respectively. Throughout the paper, we examine topics such as data and feature selection, data sharing, model selection, explainability, client selection, contribution assessment, incentive mechanisms, accountability, auditability, secure and data aggregation, privacy preservation, and more. In conclusion, we explore open challenges and future research avenues in the field of Trustworthy FL, laying the foundation for the creation of secure and dependable FL systems that facilitate responsible and ethical AI applications.

(p48.3) 3) Streamlined model verification and auditability: Facilitate users to confirm a model update's accuracy and easily access verifiable data for specific update versions. 4) Unalterable model update history: Showcase a globally uniform record of global model updates without changes. Within this log, each update corresponds to a distinct entry that cannot be edited or deleted once created. 5) Dependable client and model identification: Select trustworthy clients and models to enhance the FL process. 6) Reliable contribution evaluation and incentive allocation: Implement a credible assessment of contributions and provide incentives to encourage FL clients' participation in future sessions. Investigators must concentrate on novel approaches to address the challenges in FL by creating equitable and dependable metrics for worker selection and evaluation. 7) Dynamic authoritative keys management: Allow updates for authoritative keys, even if some, but not most, keys are compromised. 8) Timely Monitoring: Timely monitoring methods for workers and model assessment schemes are necessary. Strengthening security and privacy features is crucial for Trustworthy FL.

(p48.4) By emphasizing these objectives, crucial areas and fostering cooperation among stakeholders, the creation of secure and dependable FL systems can facilitate more responsible and ethical AI applications. Within the current research landscape, there is a noticeable absence of studies investigating the crucial pillars of trustworthiness, specifically in relation to FL. To the best of our knowledge, this is the pioneering work encompassing all facets of Trustworthy FL. In an effort to bridge the gaps in existing literature, this study presents the following contributions: 1) We furnish an overview of the fundamental principles underlying trustworthy FL, accompanied by a comprehensive architecture of Trustworthy FL and trust assessment mechanisms. 2) We develop a taxonomy centered on the most pertinent trustworthiness pillars within FL contexts. In order to construct this taxonomy, we identify three primary pillars as the foundational elements: Interpretability, Fairness, and Security & Privacy. Each pillar embodies a dimension of trust, which is further delineated into distinct concepts for each pillar. Additionally, we explore the key challenges and future directions in the realm of Trustworthy FL. 3) In conclusion, we highlighted the essential research challenges associated with each facet of Trustworthy FL, as well as the direction for future investigations.

(p48.5) The remainder of this paper is organized as follows: The structure of this paper is as follows: We commence with an introduction to FL and its classification in Section 2, succeeded by a discussion on trust in FL, fundamental principles of trustworthiness, and the architecture of Trustworthy FL systems in Section 3. Section 4 presents a literature review, emphasizing existing research in the domain. Sections 5-8 delve into trust evaluation, trust-aware interpretability, fairness-aware trustworthiness, and trust-aware security & privacy-preserving FL systems, respectively. Throughout the paper, we examine topics such as data and feature selection, data sharing, model selection, explainability, client selection, contribution assessment, incentive mechanisms, accountability, auditability, secure and data aggregation, privacy preservation, and more. In conclusion, we explore open challenges and future research avenues in the field of Trustworthy FL, laying the foundation for the creation of secure and dependable FL systems that facilitate responsible and ethical AI applications.
## (s49) II. FEDRATED LEARNING AN OVERVIEW
(p49.0) FL is a transformative approach to distributed machine learning, enabling the collaborative training of models across multiple devices or clients while preserving data privacy [11]. Various FL architectures have been developed to address the diverse challenges and requirements in data distribution, communication patterns, and coordination methods. These architectures can be broadly classified into three main categories: data distribution-based architectures, such as Horizontal FL (HFL), Vertical FL (VFL), and Federated Transfer Learning (FTL); scale and communication-based architectures, including Cross-Silo FL (CSFL) and Cross-Device FL (CDFL); and coordination-based architectures, which encompass Centralized FL, Decentralized FL, and Hierarchical FL. Each of these architectures caters to specific needs and constraints, ensuring optimal model development across a wide range of applications while maintaining data privacy and security.

(p49.1) A. Data Distribution-Based FL Architectures 1) Vertical FL: VFL involves federated training of datasets that share the same sample space but differ in feature spaces. It is apt for scenarios in which data is divided vertically based on feature dimensions, with different parties holding homogeneous data that partially overlaps in sample IDs. Entity alignment and encryption methods can be employed to address data sample overlapping during local training. One instance of VFL in the healthcare sector is the collaboration between hospitals and insurance companies, jointly training an AI model using their respective datasets. Although VFL provides data privacy and joint training benefits, it presents more implementation challenges than HFL due to the requirement for entity resolution and the limitations of current techniques for complex machine learning models.

(p49.2) 2) Horizontal FL: In HFL, multiple participants possessing datasets with identical feature spaces but varying sample spaces collaborate in training a joint global model. The datasets are used locally, and a server merges the local updates received from the participants to develop a global update without accessing the local data directly. One example of HFL in the healthcare domain is speech disorder detection, where users with different voices speak identical sentences, and the local updates are combined to create a comprehensive speech recognition model. HFL is primarily utilized in smart devices and IoT applications. It allows leveraging data from numerous sources without sharing raw data, thus maintaining privacy.

(p49.3) However, HFL may encounter challenges when dealing with a limited number of labeled entities. 3) Federated Transfer Learning: FTL is tailored to handle datasets that differ in both sample spaces and feature spaces. Transfer learning techniques are used to compute feature values from distinct feature spaces into a uniform representation, which is then employed for local dataset training. Privacy protection mechanisms, such as random masks, can be implemented during the gradient exchange between clients and servers. FTL can support smart healthcare use cases like disease diagnosis by enabling collaboration among multiple hospitals with distinct patients and treatment plans. Although FTL has potential, it remains an evolving research area with challenges related to communication efficiency and flexibility in dealing with diverse data structures. Nevertheless, it provides a promising solution for ensuring data security and user privacy while addressing data island problems. An illustration of these data distribution-based FL architectures is presented in Fig. 1.

(p49.4) FL is a transformative approach to distributed machine learning, enabling the collaborative training of models across multiple devices or clients while preserving data privacy [11]. Various FL architectures have been developed to address the diverse challenges and requirements in data distribution, communication patterns, and coordination methods. These architectures can be broadly classified into three main categories: data distribution-based architectures, such as Horizontal FL (HFL), Vertical FL (VFL), and Federated Transfer Learning (FTL); scale and communication-based architectures, including Cross-Silo FL (CSFL) and Cross-Device FL (CDFL); and coordination-based architectures, which encompass Centralized FL, Decentralized FL, and Hierarchical FL. Each of these architectures caters to specific needs and constraints, ensuring optimal model development across a wide range of applications while maintaining data privacy and security.

(p49.5) A. Data Distribution-Based FL Architectures 1) Vertical FL: VFL involves federated training of datasets that share the same sample space but differ in feature spaces. It is apt for scenarios in which data is divided vertically based on feature dimensions, with different parties holding homogeneous data that partially overlaps in sample IDs. Entity alignment and encryption methods can be employed to address data sample overlapping during local training. One instance of VFL in the healthcare sector is the collaboration between hospitals and insurance companies, jointly training an AI model using their respective datasets. Although VFL provides data privacy and joint training benefits, it presents more implementation challenges than HFL due to the requirement for entity resolution and the limitations of current techniques for complex machine learning models.

(p49.6) 2) Horizontal FL: In HFL, multiple participants possessing datasets with identical feature spaces but varying sample spaces collaborate in training a joint global model. The datasets are used locally, and a server merges the local updates received from the participants to develop a global update without accessing the local data directly. One example of HFL in the healthcare domain is speech disorder detection, where users with different voices speak identical sentences, and the local updates are combined to create a comprehensive speech recognition model. HFL is primarily utilized in smart devices and IoT applications. It allows leveraging data from numerous sources without sharing raw data, thus maintaining privacy.

(p49.7) However, HFL may encounter challenges when dealing with a limited number of labeled entities. 3) Federated Transfer Learning: FTL is tailored to handle datasets that differ in both sample spaces and feature spaces. Transfer learning techniques are used to compute feature values from distinct feature spaces into a uniform representation, which is then employed for local dataset training. Privacy protection mechanisms, such as random masks, can be implemented during the gradient exchange between clients and servers. FTL can support smart healthcare use cases like disease diagnosis by enabling collaboration among multiple hospitals with distinct patients and treatment plans. Although FTL has potential, it remains an evolving research area with challenges related to communication efficiency and flexibility in dealing with diverse data structures. Nevertheless, it provides a promising solution for ensuring data security and user privacy while addressing data island problems. An illustration of these data distribution-based FL architectures is presented in Fig. 1.
## (s56) V. TRUST EVALUATION IN FL
(p56.0) In this section, we present a collection of criteria for assessing trust evaluation methods grounded in FL: 1) Effectiveness: A vital aspect of trust evaluation is the accurate determination of a trustee's trust value. Trustworthy methods must ensure precision, demonstrated by metrics like recall, precision, accuracy, and F-score.

(p56.1) 2) Data and Algorithm Selection: Trust evaluation relies on two critical components: training data and model-building algorithms. Optimal data and algorithm choices lead to accurate evaluations, and methods should consider their impact on trust assessment.

(p56.2) 3) Robustness: Trust evaluation is vulnerable to attacks. Addressing these attacks enhances resistance to disruptions, ensuring robust evaluation methods. 4) Privacy Protection: Trust evaluation data might include sensitive user information. It is crucial to protect this data from unauthorized disclosure, prioritizing user privacy and trust evidence protection in trust evaluation processes.

(p56.3) 5) Context-Awareness: Trust evaluation methods should be adaptable to changes in application scenarios, contexts, or environments, reflecting the fundamental characteristic of trust: context-awareness. 6) Subjectivity: Trust evaluation must capture trust's subjective nature for a more authentic representation, emphasizing the importance of subjectivity as a key trust characteristic. 7) Distributed Learning:: In FL, trust evaluation methods should account for distributed data storage and processing, ensuring that trust assessment is compatible with the decentralized nature of the learning process.

(p56.4) 8) Local Model Quality:: Trust evaluation should consider the quality of local models, as FL relies on combining local models to create a global model. Assessing the quality of local models can help identify unreliable participants. 9) Incentive Mechanisms:: Implementing incentive mechanisms can encourage honest participation and cooperation, elevating trust assessment in FL by ensuring that participants are motivated to contribute high-quality data and models.

(p56.5) 10) Contribution Evaluation:: Trust evaluation methods should incorporate mechanisms to measure the value of each client's contributions to the global model. These mechanisms should consider factors such as data quality, data diversity, and the impact of the local model on the global model's performance.

(p56.6) 11) Client Selection:: Incorporating client selection strategies in trust evaluation helps identify and select reliable clients that can contribute effectively to the global model. By selecting trustworthy clients, the overall quality and trustworthiness of the FL system can be improved.

(p56.7) 12) Verifiability and Auditibility:: Trust evaluation methods should provide a means of verifying the accuracy and reliability of both local models and the global model. This could involve techniques such as cryptographic proofs, secure aggregation, or trusted execution environments, ensuring transparency and trustworthiness in the FL system.

(p56.8) In the field of network security, trust is considered a crucial aspect for ensuring the secure transmission of data. In the context of the vehicle-road-cloud collaborative system, trust evaluation becomes increasingly complex due to the heterogeneity of the network and its openness to attacks. To address this challenge, the authors in [29] proposed a trust evaluation scheme based on FL. The scheme is designed as a hierarchical trust evaluation model that takes into account the different trust indices at various layers and factors affecting trust among nodes. The proposed model updates trust values in real-time, providing a personalized trust evaluation for each device in the network. This allows for a more thorough assessment of trust than traditional trust evaluation mechanisms, while also reducing the energy consumption and increasing accuracy compared to previous schemes. By combining FL with the hierarchical trust evaluation model, the system solves the problem of limited edge node resources and reduces the overhead of trust evaluation. This innovative approach to trust evaluation in the vehicle-road-cloud collaborative system shows promising results in improving network security and reliability.

(p56.9) The authors in [30] proposed a solution to the problem of trust in group decision-making for FL systems. The key contribution of their work is the introduction of a trust-based consensus method, called Trust X-BFT (TX-BFT), which utilizes a consortium chain to reach a consensus among participants. The TX-BFT method evaluates the trust levels of participants based on their historical behaviors in previous consensus processes and stores this information in a public ledger on the blockchain. This information is used to incentivize participants with higher trust levels by rewarding them and punishing those with lower trust levels. This, in turn, helps to improve the overall trust perception performance of the FL network. The proposed method has three stages -preliminary, prepare, and commit -and utilizes a parliament of consensus nodes to communicate and reach a consensus. In each round, a leader collects block generation proposals and broadcasts the pre-prepare information, while the verifiers wait for the pre-prepare message. Once the verifiers receive 2/3 commit messages, they begin inserting the proposed block into the chain and marking their status as final committed. The simulation results and security analysis demonstrate that the TX-BFT method can effectively defend against malicious users and data, and enhance the trust and stability of FL networks. The authors' contribution provides a valuable solution to the problem of trust in group decision-making for FL systems and has the potential to be widely adopted in various applications.

(p56.10) A clustering-based and distance-based trust evaluation methods are proposed in [31]. The clustering-based method groups FL agents based on their trust scores, while the distance-based method calculates the trust scores based on the similarity of FL agents' behaviors. The authors introduce the trusted decentralized FL algorithm, which incorporates the trust concept into the FL process to enhance its security. This paper addresses the challenge of enhancing the security of FL by introducing trust as a metric to measure the trustworthiness of FL agents. The authors propose a mathematical framework for trust computation and aggregation in a multi-agent system, which is the main contribution of the paper. This framework enables the calculation of trust scores for each FL agent based on their behavior, which can then be used to assess the risk of malicious attacks. Furthermore, the authors propose an attack-tolerant consensus-based FL algorithm, which takes into account the trust scores of FL agents during the consensus step. This helps to mitigate the risk of malicious attacks and ensures the security of the FL training.

(p56.11) PRTrust in [32], a trust model is proposed for a peer-topeer federated cloud system. The authors aim to address the challenge of trust establishment among participating cloud service providers (CSPs) to enable resource sharing in a secured manner. The trust model considers both reputation-based trust and performance-based risk in evaluating the trustworthiness of CSPs. PRTrust provides a two-tier weighted performance evaluation mechanism, a risk evaluation mechanism, and a personalized reputation-based trust evaluation mechanism. It also provides a CSP selection mechanism based on the evaluated trust and risk. The authors intend to reduce the risk of sub-standard service delivery and improve the selection of appropriate CSPs for resource and service sharing.

(p56.12) The security of the Internet of Vehicles (IoV) relies heavily on trust management between various connected devices and nodes. With the increasing number of connected vehicles, it becomes imperative to establish trust and identify dishonest nodes. To improve the security of IoV, a new approach for trust management is proposed in [33], which combines FL with blockchain technology (FBTM). This approach involves designing a vehicular trust evaluation to enhance the data acquired for the FL model and developing a blockchain-based reputation system to securely store and share the global FL models. The proof of reputation consensus is also proposed to evaluate the reliability of roadside units functioning as aggregators in the IoV network. Simulation results demonstrate the effectiveness of the proposed FBTM approach in ensuring the security of the IoV network.

(p56.13) The research work in [34] proposes a Federated Hierarchical Trust Interaction (FHTI) scheme for the Cross-Domain Industrial Internet of Things (IIoT) to address the challenge of multidomain trust interaction. To achieve this, the FHTI scheme integrates consortium blockchain and FL in a seamless manner. A blockchain-based trusted environment for the IIoT is established, followed by the development of a multidomain behavior detection mechanism using FL. The hierarchical trust system is then constructed by combining blockchain transaction performance, leading to unified trust management across multiple domains. Finally, a blockchain cross-chain interaction mechanism is proposed to ensure the credibility of trust values between parties. The main contributions of the article include a two-tier consortium blockchain security architecture and a hierarchical trust mechanism based on federated detection of blockchain nodes, which enables dynamic trust evaluation and hierarchical trust management, thereby improving trust between IIoT devices and breaking down trust barriers between domains.

(p56.14) The proposed system [35] combines FL with trust establishment mechanism and recommender selection strategy to address the challenge of cold-start items in recommendation systems. The cold-start problem occurs when a recommender system has limited or no information about a new user or item. To address this issue, the authors propose a trust establishment mechanism that enables the recommender system to build trust relationships with potential recommenders. The trust scores are derived from the devices' resource utilization data and the credibility scores of the recommenders. Additionally, the authors propose a recommender selection strategy based on double deep Q learning that considers the devices' trust scores and energy levels to choose the subset of IoT devices that will contribute to improving the accuracy of the recommendations. The authors demonstrate the value of FL for the cold-start item recommendation problem and provide insights into how to design intelligent algorithms that support the FL process while prioritizing trust management.

(p56.15) The authors presents a novel approach to address the challenges of trust management in cross-domain industrial IoT by introducing the FHTI architecture in [36]. It combines the power of consortium blockchain and FL to provide a safe and reliable network environment for users. The FHTI scheme is based on a behavior detection mechanism that uses FL to evaluate the trustworthiness of devices in a multidomain setting. The architecture also establishes a blockchain crosschain interaction mechanism that ensures the credibility of the trust value of both parties. The results of the simulation indicate that the proposed scheme can improve the accuracy of abnormal behavior recognition, increase resource utilization, and enhance the stability of the system compared to traditional methods. The FHTI scheme presents a promising solution for trust management in the cross-domain industrial IoT.

(p56.16) In this section, we present a collection of criteria for assessing trust evaluation methods grounded in FL: 1) Effectiveness: A vital aspect of trust evaluation is the accurate determination of a trustee's trust value. Trustworthy methods must ensure precision, demonstrated by metrics like recall, precision, accuracy, and F-score.

(p56.17) 2) Data and Algorithm Selection: Trust evaluation relies on two critical components: training data and model-building algorithms. Optimal data and algorithm choices lead to accurate evaluations, and methods should consider their impact on trust assessment.

(p56.18) 3) Robustness: Trust evaluation is vulnerable to attacks. Addressing these attacks enhances resistance to disruptions, ensuring robust evaluation methods. 4) Privacy Protection: Trust evaluation data might include sensitive user information. It is crucial to protect this data from unauthorized disclosure, prioritizing user privacy and trust evidence protection in trust evaluation processes.

(p56.19) 5) Context-Awareness: Trust evaluation methods should be adaptable to changes in application scenarios, contexts, or environments, reflecting the fundamental characteristic of trust: context-awareness. 6) Subjectivity: Trust evaluation must capture trust's subjective nature for a more authentic representation, emphasizing the importance of subjectivity as a key trust characteristic. 7) Distributed Learning:: In FL, trust evaluation methods should account for distributed data storage and processing, ensuring that trust assessment is compatible with the decentralized nature of the learning process.

(p56.20) 8) Local Model Quality:: Trust evaluation should consider the quality of local models, as FL relies on combining local models to create a global model. Assessing the quality of local models can help identify unreliable participants. 9) Incentive Mechanisms:: Implementing incentive mechanisms can encourage honest participation and cooperation, elevating trust assessment in FL by ensuring that participants are motivated to contribute high-quality data and models.

(p56.21) 10) Contribution Evaluation:: Trust evaluation methods should incorporate mechanisms to measure the value of each client's contributions to the global model. These mechanisms should consider factors such as data quality, data diversity, and the impact of the local model on the global model's performance.

(p56.22) 11) Client Selection:: Incorporating client selection strategies in trust evaluation helps identify and select reliable clients that can contribute effectively to the global model. By selecting trustworthy clients, the overall quality and trustworthiness of the FL system can be improved.

(p56.23) 12) Verifiability and Auditibility:: Trust evaluation methods should provide a means of verifying the accuracy and reliability of both local models and the global model. This could involve techniques such as cryptographic proofs, secure aggregation, or trusted execution environments, ensuring transparency and trustworthiness in the FL system.

(p56.24) In the field of network security, trust is considered a crucial aspect for ensuring the secure transmission of data. In the context of the vehicle-road-cloud collaborative system, trust evaluation becomes increasingly complex due to the heterogeneity of the network and its openness to attacks. To address this challenge, the authors in [29] proposed a trust evaluation scheme based on FL. The scheme is designed as a hierarchical trust evaluation model that takes into account the different trust indices at various layers and factors affecting trust among nodes. The proposed model updates trust values in real-time, providing a personalized trust evaluation for each device in the network. This allows for a more thorough assessment of trust than traditional trust evaluation mechanisms, while also reducing the energy consumption and increasing accuracy compared to previous schemes. By combining FL with the hierarchical trust evaluation model, the system solves the problem of limited edge node resources and reduces the overhead of trust evaluation. This innovative approach to trust evaluation in the vehicle-road-cloud collaborative system shows promising results in improving network security and reliability.

(p56.25) The authors in [30] proposed a solution to the problem of trust in group decision-making for FL systems. The key contribution of their work is the introduction of a trust-based consensus method, called Trust X-BFT (TX-BFT), which utilizes a consortium chain to reach a consensus among participants. The TX-BFT method evaluates the trust levels of participants based on their historical behaviors in previous consensus processes and stores this information in a public ledger on the blockchain. This information is used to incentivize participants with higher trust levels by rewarding them and punishing those with lower trust levels. This, in turn, helps to improve the overall trust perception performance of the FL network. The proposed method has three stages -preliminary, prepare, and commit -and utilizes a parliament of consensus nodes to communicate and reach a consensus. In each round, a leader collects block generation proposals and broadcasts the pre-prepare information, while the verifiers wait for the pre-prepare message. Once the verifiers receive 2/3 commit messages, they begin inserting the proposed block into the chain and marking their status as final committed. The simulation results and security analysis demonstrate that the TX-BFT method can effectively defend against malicious users and data, and enhance the trust and stability of FL networks. The authors' contribution provides a valuable solution to the problem of trust in group decision-making for FL systems and has the potential to be widely adopted in various applications.

(p56.26) A clustering-based and distance-based trust evaluation methods are proposed in [31]. The clustering-based method groups FL agents based on their trust scores, while the distance-based method calculates the trust scores based on the similarity of FL agents' behaviors. The authors introduce the trusted decentralized FL algorithm, which incorporates the trust concept into the FL process to enhance its security. This paper addresses the challenge of enhancing the security of FL by introducing trust as a metric to measure the trustworthiness of FL agents. The authors propose a mathematical framework for trust computation and aggregation in a multi-agent system, which is the main contribution of the paper. This framework enables the calculation of trust scores for each FL agent based on their behavior, which can then be used to assess the risk of malicious attacks. Furthermore, the authors propose an attack-tolerant consensus-based FL algorithm, which takes into account the trust scores of FL agents during the consensus step. This helps to mitigate the risk of malicious attacks and ensures the security of the FL training.

(p56.27) PRTrust in [32], a trust model is proposed for a peer-topeer federated cloud system. The authors aim to address the challenge of trust establishment among participating cloud service providers (CSPs) to enable resource sharing in a secured manner. The trust model considers both reputation-based trust and performance-based risk in evaluating the trustworthiness of CSPs. PRTrust provides a two-tier weighted performance evaluation mechanism, a risk evaluation mechanism, and a personalized reputation-based trust evaluation mechanism. It also provides a CSP selection mechanism based on the evaluated trust and risk. The authors intend to reduce the risk of sub-standard service delivery and improve the selection of appropriate CSPs for resource and service sharing.

(p56.28) The security of the Internet of Vehicles (IoV) relies heavily on trust management between various connected devices and nodes. With the increasing number of connected vehicles, it becomes imperative to establish trust and identify dishonest nodes. To improve the security of IoV, a new approach for trust management is proposed in [33], which combines FL with blockchain technology (FBTM). This approach involves designing a vehicular trust evaluation to enhance the data acquired for the FL model and developing a blockchain-based reputation system to securely store and share the global FL models. The proof of reputation consensus is also proposed to evaluate the reliability of roadside units functioning as aggregators in the IoV network. Simulation results demonstrate the effectiveness of the proposed FBTM approach in ensuring the security of the IoV network.

(p56.29) The research work in [34] proposes a Federated Hierarchical Trust Interaction (FHTI) scheme for the Cross-Domain Industrial Internet of Things (IIoT) to address the challenge of multidomain trust interaction. To achieve this, the FHTI scheme integrates consortium blockchain and FL in a seamless manner. A blockchain-based trusted environment for the IIoT is established, followed by the development of a multidomain behavior detection mechanism using FL. The hierarchical trust system is then constructed by combining blockchain transaction performance, leading to unified trust management across multiple domains. Finally, a blockchain cross-chain interaction mechanism is proposed to ensure the credibility of trust values between parties. The main contributions of the article include a two-tier consortium blockchain security architecture and a hierarchical trust mechanism based on federated detection of blockchain nodes, which enables dynamic trust evaluation and hierarchical trust management, thereby improving trust between IIoT devices and breaking down trust barriers between domains.

(p56.30) The proposed system [35] combines FL with trust establishment mechanism and recommender selection strategy to address the challenge of cold-start items in recommendation systems. The cold-start problem occurs when a recommender system has limited or no information about a new user or item. To address this issue, the authors propose a trust establishment mechanism that enables the recommender system to build trust relationships with potential recommenders. The trust scores are derived from the devices' resource utilization data and the credibility scores of the recommenders. Additionally, the authors propose a recommender selection strategy based on double deep Q learning that considers the devices' trust scores and energy levels to choose the subset of IoT devices that will contribute to improving the accuracy of the recommendations. The authors demonstrate the value of FL for the cold-start item recommendation problem and provide insights into how to design intelligent algorithms that support the FL process while prioritizing trust management.

(p56.31) The authors presents a novel approach to address the challenges of trust management in cross-domain industrial IoT by introducing the FHTI architecture in [36]. It combines the power of consortium blockchain and FL to provide a safe and reliable network environment for users. The FHTI scheme is based on a behavior detection mechanism that uses FL to evaluate the trustworthiness of devices in a multidomain setting. The architecture also establishes a blockchain crosschain interaction mechanism that ensures the credibility of the trust value of both parties. The results of the simulation indicate that the proposed scheme can improve the accuracy of abnormal behavior recognition, increase resource utilization, and enhance the stability of the system compared to traditional methods. The FHTI scheme presents a promising solution for trust management in the cross-domain industrial IoT.
## (s58) A. Trustworthy Feature and Sample Selection
(p58.0) The authors proposes a new approach called Federated Stochastic Dual-Gate based Feature Selection (FedSDG-FS) [37] for feature selection in Vertical FL (VFL). Existing FS works for VFL assume prior knowledge on the number of noisy features or the threshold of useful features to be selected, making them unsuitable for practical applications. FedSDG-FS uses a Gaussian stochastic dual-gate to approximate the probability of a feature being selected with privacy protection through Partially Homomorphic Encryption without a trusted third-party. It also proposes a feature importance initialization method based on Gini impurity to reduce overhead. Experiments show that FedSDG-FS outperforms existing approaches in selecting high-quality features and building global models with higher performance. The proposed method solves the problem of efficient feature selection in VF.

(p58.1) A trustworthiness evaluation framework, TrustE-VC, is proposed in [38] that combines criteria importance and performance rates to determine the service attributes of vertical FL that require more attention. It also suggests a three-level security feature to enhance effectiveness and trustworthiness in VC. The proposed framework comprises three interconnected components, including an aggregation of the security evaluation values, a fuzzy multicriteria decision-making algorithm, and a simple additive weight associated with importanceperformance analysis and performance rate to visualize the framework findings. The proposed framework provides a useful tool for designers and industrial CV practices to evaluate and select industrial CV trust requirements. The framework addresses the challenges of developing effective and trustworthy VFL models.

(p58.2) In [39], authors present an XAI Federated Deep Reinforcement Learning model aimed at improving decision-making for new Autonomous Vehicles (AVs) in trajectory and motion planning. This model tackles appropriate AV selection for FL and guarantees explainability and trustworthiness. Using XAI, it determines each feature's importance and AV's trust value. A trust-based deep reinforcement learning model is introduced for selections, showing superior performance in real-world data experiments. The study highlights trust's role in AV selection and proposes an innovative XAI-based trust computation method, providing a sophisticated mechanism for new AVs' decision-making.

(p58.3) The main contribution of [40] is a FL model named Fed-PARL, which aims to reduce the model size while performing sample-based pruning, avoiding misbehaved clients, and considering resource-availability for partial workloads. This is especially useful for resource-constrained IoT clients. FedPARL, a tri-level FL strategy, aids clients in conserving resources throughout training, eliminates unreliable or resource-deficient clients during selection, and allows for flexible local epochs based on client resource availability. An incentive-deterrent framework promotes effective clients and discourages poorperforming or malicious ones. This approach exhibits robustness in constrained FL-IoT environments, and results reveal that FedPARL outperforms existing methods, delivering an enhanced FL solution.

(p58.4) This authors proposes a new approach to optimize smart device sampling and data offloading in FL [41]. The authors propose a joint sampling and data offloading optimization problem where devices are selected based on their expected contribution to model training. The non-selected devices can transfer data to selected ones based on estimated data dissimilarities between nodes. The proposed approach aims to improve the efficiency and accuracy of FedL by reducing the communication and computational costs. The approach is evaluated using real-world data, and the results demonstrate its effectiveness in improving the performance of FedL.
## (s60) C. Trustworthy Model Selection
(p60.0) In FL, it is crucial to evaluate the contributions of participants to the performance of the final model while ensuring privacy. To achieve this, the widely adopted method is the use of Shapley Value (SV) techniques. However, existing SV-based approaches are computationally expensive and impractical for real-world applications. To tackle this issue, authors in [45] introduced the Guided Truncation Gradient Kapley (GTG-Shapley) approach, which reduces the computation cost of SVbased FL participant contribution evaluation. Unlike traditional methods, GTG-Shapley does not require extra learning tasks from participants, as it reconstructs FL sub-models using their previous gradient updates instead of training them from scratch. Additionally, GTG-Shapley employs guided Monte Carlo sampling to further reduce the number of required model reconstructions and evaluations, thereby enhancing the efficiency of SV computation. GTG-Shapley offers a more practical and scalable solution for fair FL participant contribution evaluation. GTG-Shapley enables FL to be more practical and widely adopted in real-world applications.

(p60.1) The aggregation of local models from participating clients is a critical component in generating the final global model in FL. However, traditional aggregation methods can be susceptible to adversarial attacks and client failures. To mitigate this issue, the authors of this paper propose a truth inference approach to FL that incorporates the reliability of each client's local model into the aggregation process. The proposed approach in [46] models the clients' reliability based on their submitted local model parameters and considers these parameters during the aggregation process to produce a robust estimate of the global model. The authors have further enhanced the method by considering the model parameters submitted by clients in previous rounds in addition to the current round, thus providing a more comprehensive evaluation of client reliability.The proposed truth inference approach provides a more robust estimate of the global model, protects against potential adversarial attacks, and considers client reliability in the aggregation process, thereby improving the robustness of FL.

(p60.2) In FL, the server aggregates the uploaded model parameters from participating clients to generate a global model. The common practice is to evenly weight the local models, assuming equal contribution from all nodes. However, the heterogeneous nature of devices and data leads to variations in contribution from users. To address this issue, authors in [47] introduces a reputation-enabled aggregation method that adjusts the aggregation weights based on the reputation scores of users. The reputation score is computed based on the performance metrics of the local models during each training round. The proposed method showed an improvement of 17.175% over the standard baseline in non-independent and identically distributed (non-IID) scenarios for a FL network of 100 participants. This work considers the mobile network of distributed computing nodes where the performance and reputation of individual nodes vary. The reputation-enabled weighted aggregation is hypothesized to lead to faster convergence and a higher accuracy level for FL in a mobile environment.
## (s64) B. Trustworthy Contribution Evaluation
(p64.0) The contribution measurement strategies used in FL systems can be classified into three main categories: self-report based evaluation, Shapley value based evaluation, and influence and reputation based evaluation. Self-report based evaluation involves the data owner directly reporting their level of contribution to the model owner. Metrics used to evaluate the contribution include computational resources and data size. The Shapley value based evaluation takes into account the participation order of the data owners and assesses their contributions in a fair manner, typically used in cooperative games. Influence and reputation based evaluation considers the client's impact on the FL model's loss function and their reliability, and may involve techniques like Fed-Influence and reputation mechanisms that can be combined with blockchain. A client's reputation is generally a combination of their internal reputation in a task and their accumulated reputation based on historical records. The authors in [89] focuses on the critical aspect of measuring the contributions of users in FL systems. The authors conduct a comprehensive analysis of the different strategies for evaluating user contributions, examining the factors that can impact the effectiveness of these methods. The paper emphasizes the need for fair and accurate evaluation techniques to assess the contributions of data owners in FL and provides valuable insights into the current state of research in this area. This study highlights the importance of considering user contributions in FL systems and provides a solid foundation for future research in this field. The categorization and most relevant research work are presented in following sub sections.

(p64.1) 1) Smart Contract based Trustworthy Contribution Evaluation: The authors in [91] proposes a solution to the issue of data validity and quality in FL systems by utilizing the EOS blockchain and IPFS. The system records uploaded updates in a scalable manner and rewards users based on the cost of their training data. To ensure that only valuable updates are validated and rewarded, the authors propose the Class-Sampled Validation Error Scheme (CSVES). This scheme tailors the validation set to a device's data breakdown and Reputation mechanism evaluates model quality and contribution, which encourages data owners to join the BFL and contribute high-quality data for local and weighted global model aggregation and reward allocation. checks the validity of the data cost claimed by the device. By implementing CSVES, the system can ensure that the data quality is maintained while incentivizing users to contribute high-quality updates to the FL model.

(p64.2) A BC-based FL scheme with a reputation mechanism to motivate data owners in high-quality data contribution has been proposed in [96]. By integrating smart contract technology and blockchain, the authors aim to create a decentralized and trustworthy environment for conducting FL tasks transparently and fairly. The proposed reputation mechanism evaluates model quality and contribution, which encourages data owners to join the BFL and contribute high-quality data for local and weighted global model aggregation and reward allocation. The noncooperative game theory with equilibrium point make sure the highest rewrard to the contributer with high quality data. Moreover, an optional grouping mechanism is proposed to address the high complexity of a large number of participants. The BFL mechanism is expected to improve the credibility and reliability of FL and guarantee the model quality.

(p64.3) 2) Shapely Value and Consensus based Trustworthy Contribution Evaluation: In [90], a blockchain-assisted FL framework is presented to encourage honest participation and reward fair contributions. The framework employs a new consensus mechanism known as "Proof of Interpretation and Selection" (PoIS), which evaluates the contributions of individual clients by analyzing model interpretation results. PoIS aggregates feature attributions to distinguish prominent contributors and outliers and uses a credit function that considers contribution, relevance, and past performance to determine incentives. The proposed framework has been tested against various types of adversaries, datasets, and attack strategies and found to be robust. This framework offers a promising solution for addressing the issues of traditional FL and ensuring fairness in contribution-based incentivization.

(p64.4) The authors propose a decentralized FL system named BESIFL (Blockchain Empowered Secure and Incentive FL) that leverages blockchain technology to remove the central FL server in [94]. Three essential components are there in system: an accuracy-based malicious node detection mechanism, a contribution-based incentive mechanism, and an algorithm that coordinates both mechanisms. The malicious node detection mechanism identifies and removes malicious nodes during the training process, while the contribution-based incentive mechanism motivates nodes to participate in FL and rewards them based on their contribution to model training. BESIFL is designed to address the security and incentive issues in FL while also stimulating credible nodes to contribute to the model training. The proposed system applies the consensus algorithm and identity authentication of blockchain to ensure the security of model training and employs mechanisms for accuracy-based malicious node detection, contribution-based node selection, and token-based node incentive.

(p64.5) The varying data quality and heterogeneous data distributions across multiple healthcare institutions pose significant challenges to existing FL frameworks. To address these issues, a Contribution-Aware FL (CAreFL) framework [95], has been proposed, which focuses on fair and efficient contribution evaluation of FL participants. The proposed GTG-Shapley approach allows for fast and accurate evaluation of participant contributions. Moreover, the framework introduces a novel FL model aggregation approach, which selects the best performing sub-model for the next round of local training instead of always aggregating all received local models. This approach addresses the heterogeneity issues of data distribution in the healthcare sector. The historical contribution evaluation records are further converted into reputation values for the FL participants, which can serve as a basis for stakeholder management decision support. The CAreFL framework offers a promising solution to the challenges faced by existing FL frameworks in the healthcare sector, improving FL model performance while ensuring privacy and fairness.

(p64.6) 3) Privacy Preserving Trustworthy Contribution Evaluation: Authors presents a novel architecture for healthcare institutions to collaborate in improving the performance of a global ML model in [92]. The proposed system utilizes a combination of blockchain and secure multi-party computation (SMPC) to ensure data integrity, model versioning and privacy preservation during model training and ensemble. Unlike traditional methods, proposed architecture prioritizes general model evaluation over incentivization for fair contribution assessment. This evaluation process is carried out by the blockchain nodes and recorded on tamper-proof storage. The final contribution of each participant's ML model is determined based on their performance on unforeseen data. Additionally, the architecture enables each participant to define their own model structure, taking into account the varying computing power among participants. The proposed hierarchical ensemble FL method promises to advance the field of collaborative ML in healthcare while maintaining the privacy and security of sensitive medical data.

(p64.7) The authors present a decentralized Fair and Privacy-Preserving Deep Learning (FPPDL) framework in [93], that aims to address the issue of fairness in FL models. Unlike traditional FL solutions that provide all parties with the same model regardless of their contribution, FPPDL aims to provide each participant with a final FL model that reflects their individual contributions. To achieve fairness, the authors propose a local credibility mutual evaluation mechanism, and for privacy preservation, a three-layer onion-style encryption scheme is proposed. The framework operates by recording all transactions, including uploading and downloading, through blockchain technology. This eliminates the need for participants to trust each other or a third party. The proposed framework is designed to create a healthy FL ecosystem where each participant's contribution is valued and accurately reflected in the final FL model. Table 3 provides an extensive overview of the research conducted on trustworthy contribution evaluation in FL.

(p64.8) The contribution measurement strategies used in FL systems can be classified into three main categories: self-report based evaluation, Shapley value based evaluation, and influence and reputation based evaluation. Self-report based evaluation involves the data owner directly reporting their level of contribution to the model owner. Metrics used to evaluate the contribution include computational resources and data size. The Shapley value based evaluation takes into account the participation order of the data owners and assesses their contributions in a fair manner, typically used in cooperative games. Influence and reputation based evaluation considers the client's impact on the FL model's loss function and their reliability, and may involve techniques like Fed-Influence and reputation mechanisms that can be combined with blockchain. A client's reputation is generally a combination of their internal reputation in a task and their accumulated reputation based on historical records. The authors in [89] focuses on the critical aspect of measuring the contributions of users in FL systems. The authors conduct a comprehensive analysis of the different strategies for evaluating user contributions, examining the factors that can impact the effectiveness of these methods. The paper emphasizes the need for fair and accurate evaluation techniques to assess the contributions of data owners in FL and provides valuable insights into the current state of research in this area. This study highlights the importance of considering user contributions in FL systems and provides a solid foundation for future research in this field. The categorization and most relevant research work are presented in following sub sections.

(p64.9) 1) Smart Contract based Trustworthy Contribution Evaluation: The authors in [91] proposes a solution to the issue of data validity and quality in FL systems by utilizing the EOS blockchain and IPFS. The system records uploaded updates in a scalable manner and rewards users based on the cost of their training data. To ensure that only valuable updates are validated and rewarded, the authors propose the Class-Sampled Validation Error Scheme (CSVES). This scheme tailors the validation set to a device's data breakdown and Reputation mechanism evaluates model quality and contribution, which encourages data owners to join the BFL and contribute high-quality data for local and weighted global model aggregation and reward allocation. checks the validity of the data cost claimed by the device. By implementing CSVES, the system can ensure that the data quality is maintained while incentivizing users to contribute high-quality updates to the FL model.

(p64.10) A BC-based FL scheme with a reputation mechanism to motivate data owners in high-quality data contribution has been proposed in [96]. By integrating smart contract technology and blockchain, the authors aim to create a decentralized and trustworthy environment for conducting FL tasks transparently and fairly. The proposed reputation mechanism evaluates model quality and contribution, which encourages data owners to join the BFL and contribute high-quality data for local and weighted global model aggregation and reward allocation. The noncooperative game theory with equilibrium point make sure the highest rewrard to the contributer with high quality data. Moreover, an optional grouping mechanism is proposed to address the high complexity of a large number of participants. The BFL mechanism is expected to improve the credibility and reliability of FL and guarantee the model quality.

(p64.11) 2) Shapely Value and Consensus based Trustworthy Contribution Evaluation: In [90], a blockchain-assisted FL framework is presented to encourage honest participation and reward fair contributions. The framework employs a new consensus mechanism known as "Proof of Interpretation and Selection" (PoIS), which evaluates the contributions of individual clients by analyzing model interpretation results. PoIS aggregates feature attributions to distinguish prominent contributors and outliers and uses a credit function that considers contribution, relevance, and past performance to determine incentives. The proposed framework has been tested against various types of adversaries, datasets, and attack strategies and found to be robust. This framework offers a promising solution for addressing the issues of traditional FL and ensuring fairness in contribution-based incentivization.

(p64.12) The authors propose a decentralized FL system named BESIFL (Blockchain Empowered Secure and Incentive FL) that leverages blockchain technology to remove the central FL server in [94]. Three essential components are there in system: an accuracy-based malicious node detection mechanism, a contribution-based incentive mechanism, and an algorithm that coordinates both mechanisms. The malicious node detection mechanism identifies and removes malicious nodes during the training process, while the contribution-based incentive mechanism motivates nodes to participate in FL and rewards them based on their contribution to model training. BESIFL is designed to address the security and incentive issues in FL while also stimulating credible nodes to contribute to the model training. The proposed system applies the consensus algorithm and identity authentication of blockchain to ensure the security of model training and employs mechanisms for accuracy-based malicious node detection, contribution-based node selection, and token-based node incentive.

(p64.13) The varying data quality and heterogeneous data distributions across multiple healthcare institutions pose significant challenges to existing FL frameworks. To address these issues, a Contribution-Aware FL (CAreFL) framework [95], has been proposed, which focuses on fair and efficient contribution evaluation of FL participants. The proposed GTG-Shapley approach allows for fast and accurate evaluation of participant contributions. Moreover, the framework introduces a novel FL model aggregation approach, which selects the best performing sub-model for the next round of local training instead of always aggregating all received local models. This approach addresses the heterogeneity issues of data distribution in the healthcare sector. The historical contribution evaluation records are further converted into reputation values for the FL participants, which can serve as a basis for stakeholder management decision support. The CAreFL framework offers a promising solution to the challenges faced by existing FL frameworks in the healthcare sector, improving FL model performance while ensuring privacy and fairness.

(p64.14) 3) Privacy Preserving Trustworthy Contribution Evaluation: Authors presents a novel architecture for healthcare institutions to collaborate in improving the performance of a global ML model in [92]. The proposed system utilizes a combination of blockchain and secure multi-party computation (SMPC) to ensure data integrity, model versioning and privacy preservation during model training and ensemble. Unlike traditional methods, proposed architecture prioritizes general model evaluation over incentivization for fair contribution assessment. This evaluation process is carried out by the blockchain nodes and recorded on tamper-proof storage. The final contribution of each participant's ML model is determined based on their performance on unforeseen data. Additionally, the architecture enables each participant to define their own model structure, taking into account the varying computing power among participants. The proposed hierarchical ensemble FL method promises to advance the field of collaborative ML in healthcare while maintaining the privacy and security of sensitive medical data.

(p64.15) The authors present a decentralized Fair and Privacy-Preserving Deep Learning (FPPDL) framework in [93], that aims to address the issue of fairness in FL models. Unlike traditional FL solutions that provide all parties with the same model regardless of their contribution, FPPDL aims to provide each participant with a final FL model that reflects their individual contributions. To achieve fairness, the authors propose a local credibility mutual evaluation mechanism, and for privacy preservation, a three-layer onion-style encryption scheme is proposed. The framework operates by recording all transactions, including uploading and downloading, through blockchain technology. This eliminates the need for participants to trust each other or a third party. The proposed framework is designed to create a healthy FL ecosystem where each participant's contribution is valued and accurately reflected in the final FL model. Table 3 provides an extensive overview of the research conducted on trustworthy contribution evaluation in FL.
## (s66) 1) Game Theory based Trustworthy Incentive Mechanism:
(p66.0) In [100], the authors propose a novel approach to designing incentives for a blockchain-enabled FL platform using mechanism design, an economic approach to realizing desired objectives in situations where participants act rationally. The main idea behind the incentive mechanism is to introduce a repeated competition for model updates, so that any rational worker follows the protocol and maximizes their profits. During each round, selected workers choose the best k model updates from previous round and update their own model based on them. The reward to workers in the previous round is decided by the vote of the next round workers. The model updates of the next round workers are also competed and voted by workers in the subsequent round, ensuring that they cannot sabotage the system. The authors provide a rigorous theoretical analysis of the incentive compatibility based on contest theory and clarify the optimal conditions for reward policy in a blockchain-enabled FL platform. The contribution of the paper includes a competitive incentive mechanism design, a fullfledged protocol that can be implemented on existing public blockchains, and a theoretical analysis to clarify incentive compatibility based on contest theory.
