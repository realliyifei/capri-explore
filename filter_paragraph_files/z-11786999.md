# Siamese Learning Visual Tracking: A Survey

CorpusID: 11786999 - [https://www.semanticscholar.org/paper/754fa133a250d824c50b4c3b9c73975059954f41](https://www.semanticscholar.org/paper/754fa133a250d824c50b4c3b9c73975059954f41)

Fields: Mathematics, Computer Science

## (s11) Disucssion
(p11.0) The literature shows the enormous success of using machine learning to improve the robustness of tracking. While recent work and initiatives try to establish community platforms, evaluation protocols and allow new insights into tracking, only a few works consider the problem of initialisation. Vagueness, complexity and computability of tracking are strongly intertwined and suggest a common machine learning approach as principled solution. However, it is important to point out that although machine learning is very promising to control vagueness by fully exploiting video information, learning will fail in the most general case of uncertainty, as learning assume priors of the underlying random processes, a constraining assumption in case of real disjuncture between known random processes and new unknown processes with unknown statistics. [33] emphasised recently this an other problems as robustness to distributional shift.
## (s12) SIAMESE TRACKING
(p12.0) Learning with a Siamese network [34], [35] is a promising approach to tackle some of these difficult tracking challenges. A Siamese network is a Y-shaped neural network that joins two network branches in final layers to produce a single output. The idea originated 1993 in fingerprint recognition [34] and signature verification [35], where the task is to compare two imaged fingerprints or two hand-written signatures and infer identity. A Siamese network captures the comparison of the preprocessed input as a function 3 of similarity with the advantageous ability to learn similarity and the features jointly and directly from the data 4 . Despite their generality and usefulness in various applications, relatively less is known about statistical foundation and properties [37], [38]. Siamese networks have also been applied to face verification and recognition [39], [40], [41], [42], areal-to-ground image matching [43], stereo matching [44], patch matching [45], [46], [47], optical flow [48], largescale video classification [49] and one-shot character recognition [50].
## (s13) Overview
(p13.0) Motivated by these successful applications, some research groups studied very recently the Siamese networks for tracking [13], [51], [52], [53], [54]. These proposed methods consider similarity as a priori given except for [51], [52] who learn similarity and features jointly. Joint learning utilises the Yshaped network architecture to its full extent, while assumptions, such as a given similarity, restrict parts of the network. Joint learning is currently little understood, while feature learning for the aim of compression has been extensively studied over decades by the signal processing community [38]. Learning similarity with given features as last case is rigorously studied in statistical decision theory and machine learning.

(p13.1) All methods assume an initial given bounding box in the first frame and the presence of a search region in the next frame where the object template is matched. Object template and search region are input to the network except for [13].
## (s15) YCNN
(p15.0) [51] propose as possibly first but unpublished attempt two identical branches similar to VGGNet [55] with three conv and max-pooling layers, both linked to three fc layers. The conv layers share the same parameters. Each layer finishes with a ReLU except for the output which finishes with a sigmoid function. The network output is a 0-1 bounded prediction map with high values at pixels indicating object presence. The branches work as feature hierarchies aggregating fine-to-coarse spatial details, while the fc layers design spatiotemporal features as well as a general similarity function. Thus, YCNN learns discriminating features of growing complexity while simultaneously learning similarity between template and search region with corresponding prediction maps. Training is done in two stages on augmented images of objects from ImageNet and for fine-tuning with videos from VOT-15 [56] and TB-100 [57]. Training minimises a weighted L 2 loss by using Adam [58], mini-batches and dropout. Weighting is important as nearly 95 % of pixels in the prediction map have very low to zero values. During tracking, the feed forward pass infers then position as maximum in the prediction map. By averaging the prediction map over the five most confident maintained templates avoids drift. Repeating inference with scaled templates estimates additionally overall scale.
## (s16) SINT
(p16.0) [13] propose two identical query and search networks inherited from AlexNet [59] and VGGNet with five conv and two max-pooling layers, three region pooling layers, an fc layer and a final L 2 normalisation layer. ReLUs follow each conv layer. Max-pooling is done after the first two conv layers. Both networks are unconnected but share the same weights. Instead of object and search region templates, the whole two subsequent frames are input, hence bounding boxes locating the object in the query frame and bounding boxes locating candidates in the search frame are additionally fed to the networks. The networks' outputs are normalised features lying on the same manifold. Again, the networks work as feature hierarchies aggregating fine-to-coarse spatial details, however in this work similarity is a priori defined by the training loss function. So SINT learns discriminating solely features of growing complexity with bounding boxes in query and search frame and an additional binary variable indicating correct and incorrect pairs measured by the Jaccard index. Training is done on images of objects from ALOV [32]. Training minimises a margin contrastive loss and uses pretraining on ImageNet. During tracking, the query is fed with the initial bounding box in the first frame resulting in a query feature vector. Inference samples candidates at radial positions and different scales and feeds the search at once resulting in feature vectors for each candidate. An offline learned ridge regressor refines finally position and scale of the winning candidate with maximal inner product to the query.
## (s17) SiamFC
(p17.0) [53] propose two identical branches inherited from AlexNet with five conv layers, max-pooling following the first two conv layers and ReLUs after every conv layer except for conv5. A novel cross-correlation layer links the two conv5 layers. By waiving padding the whole network is fullyconvolutional. The output is an unbounded correlation map with high values at pixels indicating object presence. As for YCNN and SINT, the branches can be seen as spatial description of increasing complexity which is embedded in a metric space where cross-correlation is used as similarity function. Like SINT, SiamFC learns discriminating solely the features with triplets of template, search region and corresponding prediction map. Values isotropically within a radius of the centre count correctly to the object's position, hence are labeled positively whereas all other values are labeled negatively. Training is done on videos of objects from ImageNet [2]. Augmentation considers scale but not translation, because of the fully-convolutional network property. Training minimises a discriminative mean logistic loss by using SGD, mini-batches, Xavier initialisation and annealing of the learning rate. Tracking computes the position via the up-sampled prediction map for a given template. The tracker handles scale by searching over five different scale variations and updates scale by linear interpolation.
## (s18) CFNet
(p18.0) [54] adds a correlation filter and crop layers to the branch that concerns the template. These layers follow directly the convolutional network. The input is a larger region of the frame including the template, hence resolution of feature maps in the branches and prediction map is larger. Feature maps are further multiplied by a cosine window and cropped after correlation to remove the effect of circular boundaries. CFNet inherits the basic ability from SiamFC to discriminate spatial features with triplets of template region, search region and corresponding prediction map. Instead of unconstrained features, CFNet learns features that especially discriminate and solve the underlying ridge regression of the correlation layer by exploiting background samples in the surrounding region of the template. The learnt parameters of the correlation layer remain fixed during tracking, no online learning happens as shown by [60]. Training is done as with SiamFC by using the same algorithms on videos of objects from ImageNet. To make training end-to-end, emphasis has been on a differential correlation layer and on back-propagation of the parameters. Correlation is formulated in the Fourier space to preserve efficiency of computation. Tracking is similar simple as in SiamFC and computes position and scale by a single feed forward pass. The prediction map is multiplied by a spatial cosine window to penalise larger displacements. Instead of handling five different scale variations, scale is handled as by [61]. To fully exploit the correlation filter, the initial template is updated in each frame by a moving average. [52] proposes two convolutional branches inherited from AlexNet up to pool5. Both branches share the same parameters. These pool5 features of both branches are connected to a single vector and fed to three fc layers. ReLUs are used after each fc layer. The final fc layer links to an output layer with four nodes describing the bounding box. The output is scaled by a validated constant factor. GOTURN learns simultaneously the hierarchy of spatial features in the branches as well as spatiotemporal features and the similarity function in the fc layers to discriminate between template and search region with corresponding bounding boxes. Training is done in two stages on augmented images of objects from ImageNet and on videos from ALOV by using standard back-propagation of CaffeNet. Augmentation assumes linear translation and constant scale with parameters sampled from a Laplace distribution, hence small motion is assumed to occurs more frequently than larger displacements. Training minimises a L 1 loss between predicted and ground truth bounding box by using mini-batches, dropout and pre-training of the branches on ImageNet without fine-tuning these parameters to prevent overfitting. Tracking initialises the template in the first frame and updates the template with the predicted bounding box for each frame. Crops of the current and next frame yield template and search region. These crops are not exact but padded to add context.
## (s21) Network Branches
(p21.0) All proposed methods suggest convolutional branches inherited either from AlexNet or VGGNet with five conv layers except for YCNN that complements three layers by two fc layers and CFNet that studies one to five layers. The inheritance from AlexNet and VGGNet allows transfer learning from ImageNet and ALOV. The methods consider equal branches by effectively sharing the parameters which avoids during the fine-tuning overfitting to the small datasets currently available [13]. The first two conv layers capture very local visual detail, for example edges, contributing to the accuracy of the tracker, while conv layers three to five aggregate this detail to an object specific description, for example category specific details, which is important for the robustness of the tracker [60]. Max-pooling as it is part of AlexNet and VGGNet introduces invariance to deformations of the object but it also reduces significantly image resolution and by that hinders improvements to the tracker's accuracy. All authors except [51] recognise this limitation and use two max-pooling layers to trade-off accuracy and deformation invariance. [54] also show important insights into the number of layers. They report saturation of tracking performance with increasing network depth and that more than five conv layers yield minor performance gains. CFNet implements the object specific description on higher layers with a correlation filter which allows an effective object specific description and fast computation in the Fourier domain. This significantly improves computational performance and shows that the branches are representable in various ways by combining layers of heterogeneous features.
## (s22) Connection of Branches
(p22.0) All proposed methods except SINT connect the branches, SiamFC and CFNet with a single crosscorrelation layer, YCNN and GOTURN with three fc layers. SINT omits the concatenating layer by using normalisation layers at the end of both branches. Fig. 2 illustrates these three variations of network architecture. This Siamese network architecture of SiamFC, CFNet and SINT in combination with parameter sharing limit the feature selection to the spatial image domain. Instead, YCNN and GO-TURN enable additional learning of spatiotemporal features in the concatenating layers, as argued by [52] such as "relationships between an object's appearance change and its motion" which seems very general for different categories of objects. Parameter sharing has the consequence that all methods require appearance constancy between template and search region, hence [51]'s argument that YCNN's deep features show "superiority of recognising an object with varying appearance" is questionable. SiamFC, Theoretically, the network of GOTURN generalises over the network of SiamFC which allows capturing features beyond sole visual features of the exemplar image and which allows regression of the bounding box instead of convoluting a final score map capturing potential positions of the exemplar image within the search image. The author's argue that GOTURN learns a generic relationship between arbitrary motion and visual features, however this is not clear yet. Due to the more general Y-shaped architecture it might learn features beyond pure visual such as motion and their relationship in the fully-connected layers, however the network might also be able to learn context features as well.

(p22.1) CFNet and SINT assume a specific function of similarity and the idea is to solely learn visual features to best match the given similarity. SINT even expresses similarity by the training loss which might have advantages in generalisation as particular different functions of similarity and training loss might derive adversary optimisation problems. This is not a problem for YCNN and GOTURN, as similarity and features are jointly learned, however, the interference with the particular training loss is unclear.
## (s23) Network Training
(p23.0) Training is a crucial for sufficient performance. All methods describe basically two training phases, (i) a pre-training phase to transfer-learn generic features of objects from labeled datasets and (ii) a fine-tuning phase to adapt features to given video sets. The cross-correlation layer has here advantages as crosscorrelation preserves the convolutional property of the whole network which introduces invariance to object translation. Therefore training samples must not contain translated versions which reduces significantly the effort for training. Less augmentation of training data is needed. The training loss and its choice has significant influence on the training result. [52] argue that L 1 is superior to L 2 as it penalises more harshly small errors near zero which increases substantially accuracy of the predicted bounding box. This argument is an exception, as none of the other studies show some insights into this important problem. [52] chose also different inputs for training and studied their influence on the mean error derived from VOT accuracy and robustness measures. They show that feeding the network with whole frames instead of template and search region pairs, the frames' contexts are exploited which reduces significantly the mean error, especially in cases of occlusion. SINT is the only method following this insight but without any hints of their awareness. The reason is that their motivation comes from image retrieval where processing of frames is common.
## (s24) Tracker Inference
(p24.0) All proposed networks return in a single feed forward pass information about the bounding box in the search region. YCNN, SiamFC and CFNet return position and in a post-processing step then scale. SINT needs prior sampling of candidates in the search region and returns similarities to the template all at once thanks to the region proposal layer. The best candidate with maximum similarity defines the bounding box in the new frame. GOTURN is different as it regresses directly the bounding box. The idea of inferring direct position seems elegant and superior to the idea of candidate sampling as it allows e.g. in case of SiamFC and CFNet dense cross-correlation at pixel level. GOTURN regresses directly the bounding box and is the simplest recurrent network as it can be seen as unrolled recurrent network with Markov property. Although [53] recognises this relationship, none of the works [13], [51], [53], [54] follow this fully sequential approach, as the intention is to learn a matching function. A significant advantage of YCNN, SINT, SiamFC and CFNet over GOTURN is that the predictions allows solutions for tracking in clutter, SINT however limited by the candidate samples. SiamFC and SINT consider a single initial template, while YCNN maintains the k-best templates, GOTURN keeps the last and CFNet a moving average template. [52] show that updating the template improves accuracy and robustness of the tracker.
## (s26) CONCLUSION
(p26.0) The various combinations of possible inputs, outputs and features and their implementation as layers in the network need definitely future research work. There are strong pros for a fixed similarity function, nevertheless learning similarity with fixed features or learning similarity and features jointly might conceal success as shown in the fields of re-identification [62] and sensor networks [63]. All methods keep for a good reason the tracking framework simple, namely to be able to better study the network's properties. There is much room for improvement concerning the tracking, for example by combining the network with filtering methods. Seeing the Siamese network as matching function or seeing the network as simplest recurrent network poses important questions about the integration of the network into the tracking framework which have not been answered yet. More training data is needed as well as new ideas for combining supervised and unsupervised training approaches as labelled data will always be limited. There is currently little knowledge about the influence of training loss on the overall performance. Insights into these topics by in-depth ablative analysis such as done by [52], [54] are further needed. There are currently three lines of research: There is tracking research that assumes an initial label of the unknown object e.g. a bounding box and investigates tracking in the subsequent frames. These methods are combined with detection which on the one hand allows integrated perception but on the other hand the use of detectors unnecessarily restricts the tracker to certain object categories. The third line of research studies tracking jointly with attentional mechanism that does not assume any knowledge of the object.
## (s27) ACKNOWLEDGMENTS
(p27.0) I thank all reviewers for reading the article and for their valuable comments which improved substan- 6. SINT performs best with IoU/prec. 62.5/84.8 % on OTB-2013 and OPE [13]. tially the work. This research has received funding from the EU ARTEMIS Joint Undertaking under grant agreements no. 621429 (EMÅ¡) and from the FFG (Austrian Research Promotion Agency) on behalf of BMVIT, The Federal Ministry of Transport, Innovation and Technology. This work was supported by the AIT strategic research programme 2017 Visual Surveillance and Insight.
