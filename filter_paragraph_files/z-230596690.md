# IET Image Processing Deep learning for occluded and multi-scale pedestrian detection: A review

CorpusID: 230596690 - [https://www.semanticscholar.org/paper/abf4b0aa85edafc82886365bf473ac157509629e](https://www.semanticscholar.org/paper/abf4b0aa85edafc82886365bf473ac157509629e)

Fields: Engineering, Computer Science

## (s0) INTRODUCTION
(p0.0) Pedestrian detection, as an important research topic in the field of computer vision for a long time, has many applications such as autonomous driving, video surveillance, robotics and so on.

(p0.1) In addition, pedestrian detection as a special case of object detection, its research achievements play an important role in promoting the development of other object detection methods. The process of pedestrian detection is to predict, locate and mark the position of pedestrian to obtain information such as the position and action of the pedestrian [1], as shown in Figure 1. However, due to the random distribution and dynamic characteristics of pedestrian, many detection algorithms cannot detect pedestrians accurately in real time. There will be false positives and false negatives in the process of pedestrian detection since the influence by weather, similar objects, occlusion and other factors results in poor robustness of current pedestrian detection algorithms in more complex scenes. Therefore, a lot of research is still devoted every year to establish a state-of-theart method. Figure 2 shows the amount of researches from 2000 to 2018 in pedestrian detection, the data from Google scholar advanced search the pedestrian detection as allintitle.

(p0.2) Pedestrian detection is a special task of object detection. Its technological progress is closely related to the development of general object detection. This connection can be described as follows: The general object detection algorithm can be used for pedestrian detection after appropriate improvement. Pedestrian detection is a kind of object detection, and the problems it studies can promote the development of general object detection from another view.

(p0.3) In 2003, Viola and Jones [2] first used image intensity information and motion information combined with Adaboost classifier to realise pedestrian detection and tracking, which attracted the attention of researchers to the issue. Then, Dalal and Triggs [3] proposed pedestrian detection methods based on histogram of oriented gradient (HOG) and support vector machine (SVM) classifiers, which achieved nearly 100% detection effect on MIT pedestrian dataset [4] and greatly promoted the development of pedestrian detection technology due to its ability to accurately represent objects. Later, pedestrian detection methods based on artificial feature extraction combined with machine learning classifier have become the mainstream [5][6][7][8][9], and most of the researchers have improved or innovated on this paradigm. The design of an artificially extracted feature is critical to the performance of the detector. The development of this kind of method is restricted by the artificial feature extraction since the artificial feature cannot adapt to the change of image background, which may lead to the poor effect of the proposed detection method. Krizhevsky [10] proposed AlexNet model based on deep convolution neural network in 2012, which won the first prize in ImageNet [11] large-scale image recognition contest with absolute superiority, and its performance is far superior to traditional machine learning algorithm. The excellent classification performance of AlexNet model has led researchers to focus on deep learning. Based on the research of artificial features, Girshick [12] used sliding window to extract pedestrian proposals in 2014, and convolutional neural network (CNN) was used to extract pedestrian deep feature in the proposals, which was trained by SVM. Thereafter, the detection performance has improved by the new generation of pedestrian detection methods based on CNN significantly.

(p0.4) Pedestrian detection, as a hotspot and difficult problem in the field of computer vision, has attracted widespread attention due to its great application prospect in many directions. This study presents a comprehensive survey of the existing achievements in pedestrian detection. The main work of this study is as follows: Section 1briefly summarises the current research results from traditional machine learning detection methods to deep learning detection methods. Section 2 focuses on the principles, performances, advantages of several deep learning pedestrian detection models, and discusses its corresponding improvement methods. Section 3 analyses and explores the occlusion and multi-scale problems and solutions of pedestrian detection. Section 5 summarises the pedestrian detection datasets and evaluation methods, and prospects the development trend of deep learning methods in pedestrian detection.
## (s2) Two-stage detection framework
(p2.0) Two-stage network framework detection method is usually called region-based detection method. First, it obtains the proposals of the object by sliding window or selective search, then extracts the convolution feature in the region by using CNN, and finally classifies and recognises the feature by using classifier. Girshick et al. [13] combined traditional machine learning methods with CNN and proposed a detection framework based on RCNN as shown in Figure 3, of which the selective search is used to obtain as many object proposals as possible; CNN is used to extract the features of the proposals instead of manual extraction and SVM is used to classify the feature vectors. The results showed that the RCNN method owns the powerful processing ability of CNN in the field of computer vision. Later, spatial pyramid pooling (SPP) Net [14] and Fast RCNN [15] have been improved by introducing SPP layer and region of interest (ROI) pooling layer, respectively. However, the number of the proposals is too large, which is accompanied by a large amount of computational consumption in the proposals generation process, and limits its application scenarios. In response
## (s4) Features extraction
(p4.0) The accuracy of pedestrian detection depends on the accuracy of its feature description and the classification ability of the classifier. Pedestrian detection method based on deep learning is to extract pedestrian features through CNN. However, the convolution neural network has a strong expansibility, so most researchers change the structure of convolution neural network to extract more accurate pedestrian features. Network architecture plays an important role in feature extraction. It is the most basic and effective process to improve the performance of detectors by improving the network architecture in the feature extraction process. The continuous evolution of RCNN algorithm series is the continuous improvement of its network architecture. By changing the number, distribution structure and function of each convolution layer in the network, the convolution network can achieve higher detection performance [17][18].
## (s5) Training and classification
(p5.0) Detector performance is greatly affected by network training process and classifier. The classifier plays a decisive role in the performance of pedestrian detection. Different training strategies will affect the classification ability of the classifier. For the algorithm based on two-stage detection framework, feature extraction and classifier training are independent. In this process, some researchers focus on feature extraction, while some researchers try to explore more effective training strategies to improve the performance of classifier. Because of the complexity of pedestrian samples, it is necessary to design appropriate classification strategies according to pedestrian characteristics in the process of network training. Table 1 lists several different training methods and pedestrian detectors of classifiers. Among them, miss rate (MR) [22] is the evaluation result in the reasonable subset of Caltech [23], which is the meaning of all MR in this study. The content of dataset and pedestrian detector performance evaluation will be detailed in Section 4. Zhang et al. [24] used the Faster RCNN detection framework to detect pedestrians, they found that the Softmax classifier used by Faster RCNN cannot effectively used the features provided by the fully connect layer, resulting in the classifier unable to adapt to low pixel pedestrians. They combined RPN network with Boosted Forests (BFs) on the basis of Faster RCNN. Meanwhile, BF classification strategy was introduced on the basis of RPN detector, the ability of classifier to mine difficult cases was strengthened, and the problem of weak generalisation ability of Faster R-CNN in pedestrian detection was improved. According to the different features extracted, the corresponding classification strategy was set up to avoid the miscalculation of multiple features by the classifier. The detection accuracy is improved by balancing the ability of feature extraction and classification training. Cai et al. [25] deduced a complexity-aware cascade training algorithm (Comp ACT) to optimise the classification risk under the constraint of feature complexity, so that the highcomplexity features can be trained in the later stage which can better combine feature extraction and classifier functions. It is very effective to train the classification sub network for detecting pedestrians of different scales to improve the ability of the detector to deal with low pixel pedestrians, and achieves a high-precision pedestrian detection. Scale-aware fast regionconvolutional neural networks (SAF RCNN) [26] proposed a weighting mechanism based on scale perception for pedestrian features at different scales. It used sub-networks to train pedestrian images at different scales separately, which improved the performance of private sub-networks at different input scales and ensured the detection performance in a certain scale range.

(p5.1) To sum up, in the improved algorithm based on the two-stage detection framework, researchers balance the ability of classifier and feature extraction to improve the detection accuracy. This process needs to refer to the detailed feature types for effective classification strategy design. At the same time, the designed classification strategy should meet the adaptability of the detector to pedestrians in various scenes.
## (s7) Single-stage detection framework
(p7.0) Although the two-stage network framework has made great breakthroughs in accuracy, the performance of end-to-end learning cannot be reflected due to the hierarchical method of region extraction combined with training. To solve this issue, a single-stage network framework is proposed to speed up detection by removing the regional proposals generation stage. By setting anchors in advance, the input image is convoluted directly, and then the anchors in the convolution map are regressed and classified. In practical testing, it has more efficient detection speed and is easily transplanted to embedded system. However, its direct detection on the original image means that the training process is very complex and the trained model is difficult to guarantee better robustness, so the accuracy cannot replace the two-stage framework. You only look once (YOLO) [35], Single Shot MultiBox Detector (SSD) [36] are representative single-stage network frameworks. YOLO divides the input image into S × S units, each unit is responsible for the centre of the unit's object detection, using a one-time prediction of the object boundaries, positioning confidence and all kinds of probability vectors. At present, several versions have been updated according to their performance, such as YOLOv2 [37], YOLOv3 [38]. Different from YOLO, SSD detects multi-scale objects directly in the convolution layer by setting anchors of different scales on the image, calculating and regressing all the anchors and confidence in the detection process, and detecting multi-scale objects by setting convolution maps of different scales. SSD has advantages over YOLO in solving small-scale and location problems. The network structure of SSD and YOLO is shown in Figure 6.

(p7.1) The proposer of SSD algorithm used the original SSD in pedestrian detection and found that the results were worse than those of RCNN framework pedestrian detection algorithm. The reason is that SSD has poor ability in reducing false positives when dealing with pedestrians in complex scenarios. Inspired  [40] proposed an improved method based on asymptotic localisation fitting (ALF). By setting different IOU thresholds on the feature map for multiple regression, the regression boxes of the upper layer is used as the anchor boxes of the next layer. The results show that the detection accuracy reaches the most advanced level under the condition of guaranteeing high detection speed. Based on the SSD framework, Du et al. [41] proposed a deep neural network fusion structure FPGA-Deep Neural Networks (F-DNN) for fast and robust pedestrian detection. It used a single convolution network to generate pedestrian proposals, and used several deep neural networks to optimise the results in parallel. At the same time, it integrated the pixel-level semantic segmentation network into the detection architecture to enhance the pedestrian detector.

(p7.2) The outstanding advantage of single-stage network is its excellent detection speed, but the accuracy is slightly inadequate. In order to increase the detection accuracy of YOLOv3 in automatic driving applications, by constructing the boundary frame model with Gauss parameters, [42] proposed a new predictive localisation algorithm to improve the reliability of the border. This method guaranteed the excellent detection speed of YOLOv3 and greatly improves the accuracy. The authors of [43] proposed a hybrid attention mechanism HARNet for singlestage object detection. First, spatial, channel and focused attentions are used for single-stage object detection. Then, the consistent attention mechanism was constructed into a deformable filter, and the hybrid attention mechanism is embedded in Retina-Net to complete single-stage object detection. Through the combination of multiple attention mechanisms and singlestage network, HARNet improves the single-stage network to locate the pedestrian area quickly and accurately, and solves the problem of missing detection caused by too many anchors in the single-stage network.

(p7.3) YOLO and SSD play an important role in promoting the realtime application of pedestrian detection algorithm, but so far pedestrian detection methods still focus on the improvement of two-stage network framework, and there are still few pedestrian detection algorithms based on single-stage network framework. The reason is that the most suitable method is still not found to balance the high speed and high precision of single-stage network framework in dealing with complex scenarios.
## (s10) Multi-scale proposals or feature maps
(p10.0) The initial RCNN focused on the sampling of multi-scale object in the process of generating proposals, but the excessive number of proposals led to the inefficiency of its calculation. Although the proposals of RPN solve this problem to some extent, the proposals for small-scale pedestrians are not fully covered. SAF RCNN [26] and MS-CNN [20] extended Fast RCNN and Faster RCNN to deal with scale change, respectively. F-DNN [41] used multiple deep classifiers combined with soft filters to further validate each proposal. SSD [36] divided the output feature map into a set of template boxes by using boundary boxes with different aspect ratios and proportions, and then constructed multi-scale target detector using complementary detection method in different output layers. Recent studies have different views on multi-scale pedestrian detection. But they have similarities, that is, they all consider the impact of the region proposals generation on multi-scale pedestrians.

(p10.1) In Figure 8, we briefly describe the details of the relevant methods to deal with multi-scale detection problems. Zhang et al. [52] proposed a new multi-scale pedestrian detection method (Active Detection method, ADM). Based on the characteristics of ResNet and RCNN, the multi-layer convolution feature of the input image and the initial pedestrian proposals were taken as input, and the coordinate transformation action sequence was carried out to realise the accurate prediction of boundary frames of different scales. GDFL [33] proposed a scale-aware pedestrian attention module to guide the detector to focus on pedestrian regions. It calculated the probability of pedestrian presence at each pixel by generating pedestrian attention masks and integrated the masks with the convolution feature map after coding, which not only highlights the pedestrian but also significantly eliminated the background interference, and improved the recognition ability of small-scale pedestrian and occluded pedestrian. SSA CNN [31] proposed a multi-scale and multi task learning framework. By learning pedestrian detection and semantic segmentation from the multi-scale network layer, the semantic information with different granularity is integrated with the shared feature maps. It connects two semantic segmentation branches to different scale network layer to obtain multi-scale semantic feature map. Then, the multiscale semantic feature map is used as the semantic clue and connected with the corresponding convolution feature map to provide the pixel level classification information, improve the classification ability of pedestrians, and reduce the difficulty of pedestrian bounding box regression.

(p10.2) By comparing the above literature, the key point of dealing with multi-scale pedestrian detection is whether the low pixel pedestrian features can be accurately extracted in the feature extraction stage. In this process, it plays a decisive role in the generation of the proposed area and the operation of the feature map. Therefore, in order to solve the problem of multi-scale pedestrian detection, it is necessary to eliminate the background interference accurately without increasing the calculation cost, and at the same time to ensure that the deep convolution feature map does not lose the low-pixel pedestrian information.
## (s11) Different training and classification strategy
(p11.0) Another way to deal with multi-scale detection problem is to use different stages of classification strategy. In Comp ACT [25] and RPN+BF [24], cascade boosting and BF classifiers are used to classify images with different resolution under deep feature maps, the characteristics of small-scale image are fully mined, and are not limited by the structure of pre-training network. Similar methods are used in [48] to classify multi-scale deep convolution feature maps by using the booted decision forests. It trained a group of enhanced boosted decision forests through multi-layer convolution feature map, and effectively improved the detection ability of the detector for multi-scale pedestrians by using the enhanced boosted decision forests of different scales trained. SAF RCNN [26] classifies multi-scale proposals by training sub networks of different sizes. And ALF [40] refines the classification results by cascading regression on multi-scale feature maps. In addition, [58] adopted an unsupervised training deep network, which combines multi-step global feature and local feature classification. It used multi-stage features and connections that skip layers to integrate global shape information with local distinctive motif information, especially the unsupervised method based on convolutional sparse coding to pre-train the filters at each stage. The method of unsupervised training and fusion of various feature maps ensures that the detector can adapt to the changes of pedestrians with different pixel sizes, so as to enhance the detection ability of pedestrians with small pixels.

(p11.1) It is proved to be very effective to improve the detector's ability to detect small-scale pedestrians based on improved training and classification methods. The core of these methods is to train classifiers for different scale feature maps and enhance the sensitivity of classifiers to low pixel features. In addition, combining the feature map of CNN with classifier training at different depths also has a better performance.
## (s12) Annotation method
(p12.0) The pedestrian detection method based on deep learning needs to input a certain number of labelled images to train the CNN. The quality of the input image determines the detection ability of the trained detector. Among them, the size, resolution and label position of the image affect the accuracy of the detector after training. Therefore, some researchers explore how to label pedestrian images with different scales to guide the feature extraction ability of CNN for small-scale pedestrians. In order to better realise the ability of the detector to learn small-scale pedestrians, Song et al. [53] analysed the bias of image boundary frames in the training stage, and a multi-scale pedestrian detection method (TLL) was proposed based on the topological line localisation and temporal feature aggregation. By establishing the topological information of human body model in different scales, the topological information is used as the annotated training detector in the training stage as shown in Figure 9. Pedestrians over different scales could be modelled as a group of 2D Gaussian kernels. And a post-processing scheme based on Markov random field is proposed to improve the positioning accuracy under crowd occlusion. Zhang et al. [47] verified that the initial annotation information plays a decisive role in detector training. Through more detailed post annotation training in Caltech dataset, MR is 3% lower than before. In addition, CMFs [48] used additional pixel annotation to improve the perfor-

(p12.1) The annotation method of TLL [53] FIGURE 10 The examples of pedestrian occlusion mance of the detector. They proposed a combination of sliding window detectors and semantic pixel labelling, and used the weighted sum of pixel labelling scores within a proposal region to represent the score of the proposal. This method can ensure that the pixel information can be retained in the training process and achieve the purpose of identifying low pixel pedestrians. On the other hand, the annotation method can also improve the detector's ability to deal with occlusion problems, and the typical ones are JL-TopS [49]. The human body parts are labelled in different levels during training, which promotes the detector's perception of occlusion. The multi-scale detection capability is only part of the performance of pedestrian detector. Its development is from the initial single-scale detection method to the feature pyramid, then to the multi-detection model and advanced semantics assistant detection. Its inherent purpose is to enable the detector to deeply mine the feature differences of different scale images in the training process, so as to obtain more general purpose detection performance.
## (s18) Pedestrian detection dataset
(p18.0) Dataset is one of the foundations and decisive factors in the process of pedestrian detection research. It is not only the common basis for measuring and comparing the performance of competitive algorithms, but also a powerful assistant to promote the development and progress of research in this field. The number of datasets and the quality of annotated information are critical for training detectors. Detectors need more data to enrich their ability to adapt to multiple scenarios, and accurate annotation information can better guide the detector to learn what it needs. So far, the published pedestrian datasets include MIT [4], INRIA [3], Daimler [7], Caltech [23], KITTI [30], TUD [44], NICTA [68], ETH [8], CVC [69], USC [70], and Citypersons [27] pedestrian datasets. According to the different content of each dataset, each dataset has its own characteristics. Among them, Caltech, KITTI and Citypersons pedestrian datasets have more complete annotation information and better annotation for occluded and multi-scale scenes, hence, they are most widely used. We summarise these three common pedestrian detection datasets in detail as shown in Table 4. Caltech dataset is the largest pedestrian dataset at present, which is photographed by car camera with about 250,000 frames (about 137 min), 350,000 bounding boxes and 2300 pedestrian annotations. In addition, the time correspondence between rectangular frames and their occlusion are also labelled.
## (s20) Evaluation method
(p20.0) The detection ability of pedestrian detector is reflected by the corresponding evaluation index and the correct evaluation method plays a decisive role in the process of detection performance evaluation. At present, the evaluation of detector performance is based on the test set of dataset. In this section, taking the results of various detection algorithms in Caltech dataset as examples, the measurement standards of different evaluation methods for detector performance are described in detail. Figure 14 shows the comparison of the results of several deep learning based pedestrian detection algorithms in Caltech dataset. The precision-recall curve [22] is used to evaluate the performance of each algorithm. The more convex the curve is FIGURE 15 MR-FPPI curve comparison of several advanced algorithms in Caltech dataset on the right, the better the performance is. The optimal algorithm GDFL obtains 85% detection accuracy. Precision and recall are common evaluation indexes in general object detection. Precision refers to the correct proportion of the object predicted by the detector, and recall rate is the proportion of the object correctly positioned to the total number of objects.

(p20.1) Scholars in the analysis of detector error cases found that only use precision-recall curve cannot be refined to prove the effectiveness of the detector for a variety of scenarios, that is, false positives and false negatives cannot be better displayed. Based on the general object evaluation method, Piotr Dollar puts forward the curve of the number of false positive per image (or false positive per window) of each image with the log average miss rate referred to as MR-FPPI/FPPW curve [22]. Figure 15 shows the evaluation results of several advanced algorithms in Caltech dataset. Take the average miss rate of FPPI under 10 −2 , the lower the curve, the better the performance. Figures 15 (a), (b) and (c), respectively, show the detection results of three different types of pedestrians: Reasonable, smallscale and occlusion, in Caltech dataset. Among them, for reasonable pedestrians, SDS-RCNN achieves an average miss rate of 7% of the optimal performance energy. In the detection of small-scale pedestrians, ADM achieves the best 31% average miss rate. At the same time, ADM has a better detection ability for pedestrians under occlusion.
