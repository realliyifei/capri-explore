# Logic Bugs in IoT Platforms and Systems: A Review

CorpusID: 209516328 - [https://www.semanticscholar.org/paper/18311137888a74119a38efde68a5c9eaa0e56a2c](https://www.semanticscholar.org/paper/18311137888a74119a38efde68a5c9eaa0e56a2c)

Fields: Engineering, Computer Science

## (s3) A TENTATIVE CLASSIFICATION
(p3.0) We classify the collected logic bugs into seven categories based on their root causes. In Table 1, we list the categories, the corresponding logic bugs, a brief description for each bug, and the corresponding references. Note that this classification is tentative, because with the development of IoT technologies, we expect the emergence of previously-unseen new vulnerabilities.

(p3.1) Authentication Problems. Authentication is a classic issue in systems security. IoT systems are no exception [18,19,26]. More specifically, there are logic bugs in which the IoT devices are mistakenly recognized as other devices (bug 1 and bug 3).

(p3.2) Over-privileged Capabilities. Similar to Android applications, IoT platforms also use capabilities to define and manage the privileges of the automation apps in the cloud. However, recent research [8] disclosed that the automation apps are often granted more privileges than necessary and the privileges were abused by attackers (bug 4 and bug 5). Meanwhile, IoT devices also lack necessary privilege separation (bug 6).

(p3.3) Working State Out of Synchronization. The IoT devices, mobile apps and the IoT cloud interact with each other closely in IoT platforms. A critical event will cause a working state change in either of the three entities. Formally, the working state changes can be modelled as a state machine. However, the state machine transitions are often not properly safeguarded in popular IoT platforms.
## (s5) D. Identifying Method & Defense. Shoshitaishvili et al. have
(p5.0) presented Firmalice [19], a binary firmware analysis framework to discover the authentication bypass bug. First, Firmalice converts the firmware binary to an intermediate language called VEX, discovers the entry point and identifies privileged program points. Then, Firmalice uses code slicing techniques to extract code snippets associated with the privileged program point, relieving symbolic execution path explosion problems. Finally, Firmalice performs symbolic execution on the sliced code and attempts to solve the path constraints at the privileged point to concretize the user input. If the user input can be uniquely concretized, then it represents that the input required to reach the privileged program point can be uniquely determined by the attacker, and the associated path is labeled as an authentication bypass. Since most authentication bypass bugs in IoT devices are backdoors that deliberately left by firmware developers, we think the best defense is to patch and upgrade the firmware by discovering authentication bypass early through program analysis techniques (e.g., Firmalice).
## (s6) Bug 3: Weak Owner Authentication
(p6.0) A. System model. Some IoT device manufacturers do not deploy their devices with IoT platform, so that they have to adopt other protocols like Nimble out-of-band authentication for Extensible Authentication Protocol (EAP-NOOB) to implement bootstrapping of new devices.

(p6.1) For EAP-NOOB protocol, a human-assisted-out-of-bind (OOB) channel is added to achieve device binding process. Specifically, When a user wants to bind the device, he first needs to deliver his user authentication message to the device in an OOB channel. The form of user authentication message could be QR code, audio signal, NFC data, etc. Then the device transmits user authentication message to the cloud with its identity information, finally the cloud can bind this device with the user's account. For example, when the user binds the camera, the IoT cloud will generate a QR code associated with his account and send it to user's mobile app. Then user should let the camera scan the QR code to complete the device binding process.

(p6.2) B. Attack Scenario. We show a specific attack scenario in Figure 3. The user first resets the device to activate the device registration. At the same time, the attacker also activates the registration of device B. After that, the user logs in his account and choose the camera A, and the QR code encoding as authentication message are generated from the cloud. Then, the user shows the QR code to the camera A (in the OOB channel indicated by the dashed line in Figure 3). Since the device A is compromised and controlled, the attacker would deliver the message received by the device A to another device B. With the authentication message, the attacker successfully binds the cameras B to the user's account. As a result, the devices B owns authentication message and would be successfully associated with the user's account on the IoT cloud which is against the user's intention. The researchers [18] call this attack as misbinding attack.

(p6.3) C. Cause Analysis. In the IoT device bootstrapping process, the IoT cloud lacks adequate authentication of target IoT device which causes this logic bug. Specifically, the IoT cloud associates the user's account with the IoT device which provides the user's authentication message generated by the mobile app. Once the target IoT device is compromised, the information could be stole by the attacker and used for another device binding. In addition, IoT devices take user's physical access to devices as their identities instead of cryptographically verifiable identities such as serial number, public keys, which makes it hard for the IoT cloud to authenticate the IoT device.

(p6.4) D. Identifying Method. To analysis a authentication protocol whether this logic bug exists or not in it, Sethi et al. [18] have proposed a formal model analysis approach based on an automatic cryptographic protocol verifier named Proverif. This analysis approach finally finds two forms of misbinding. One is shown in the attack scenario, and another is that both devices are compromised and the bug could be exploited similarly.

(p6.5) E. Defense. Approaches such as identifier communication and presence checking have been proposed by Sethi et al. [18] to partially defense the attacks. In the identifier communication approach, the IoT cloud utilizes some printable information such as model, serial numbers and even public-key fingerprint attached to the device for enhancing device authentication. Thus, it would be more difficult for attackers to launch the misbinding attack. In the presence checking approach, the user always communicates with the dynamic root of trust for measurement (DRTM) inside the device and generates authentication approaches based on trust computing base (TCB), which could check the presence of the device correctly even with untrusted software in the IoT device.
## (s7) OVER-PRIVILEGED CAPABILITIES MANAGEMENT 5.1 System Model
(p7.0) Recently, many IoT platform providers open their automation application programming frameworks to support third party IoT apps development. These programming frameworks usually define a set of capabilities to manage the permissions of IoT apps. A capability in the IoT platform consists of a set of commands (i.e., method calls) and attributes (i.e., properties) [8]. Commands represent ways in which a device can be controlled. Attributes represent the state information of a device. When installing an automation application in the IoT platform, the user would be asked to authorize to this application what kind of capabilities. Once it is installed, the application can send commands and obtain attributes to/from the related devices, bound with these capabilities.
## (s8) Bug 4: Over-granted Capabilities in Automation Apps
(p8.0) A. Attack Scenario. A malicious automation application advertises itself as a battery status monitor application. However, it requests a set of capabilities which is beyond the requirements of a battery status monitor application, including capability.lock and capability.unlock. When being installed into the system, this application is authorized the capabilities of monitoring the battery status of the front door lock as well as locking and unlocking it. SmartAuth, identifying the automation application which requests more capabilities and has more functionalities than its advertising [21]. It collects security-relevant information from the automation application's description, code and annotations, and identifies discrepancies between what is claimed in the description and what the app actually does. Then the information is used to inform the user how the specific application has the inconsistency between its description and its code. Therefore, the users have the knowledge to determine whether the automation application can abuse certain capabilities and enforce whether the automation application can utilize certain capabilities with SmartAuth through different security policies. Because most IoT platforms are closed-source, SmartAuth patches the automation application to implement the proof-of-concept system. In the end, each automation application can only access what the user allows.
## (s9) Bug 5: Coarse-grained Capabilities in Automation Apps
(p9.0) A. Attack Scenario. When being installed into the IoT platform, a benign-but-buggy or malicious automation application requests to use only one command lock of capability.lock. Because of the coarsegrained capabilities in the platform, this capability also includes command unlock. This results in that automation application has the ability to automatically send unlock command. If this capability is bound to a front door lock, this automation application can lock and unlock the front door. Hence, when this benign-but-buggy or malicious automation application is exploited by an attacker, she can unlock the front door, which results in break-ins or theft.

(p9.1) B. Cause Analysis. The root cause of this bug is the coarse-grained capabilities classification in the automation application programming frameworks. One capability may include one or more commands and attributes. Once an automation application requests one command, a set of other commands or attributes included in one capability are also authorized to this app automatically.

(p9.2) C. Identifying Method. The method of identifying whether an automation application has been authorized more commands or attributes than it requires is to verify the result of requested commands and attributesused commands and attributes. If it is empty, automation application is not over-privileged. The requested commands and attributes can be directly obtained from the capabilities requested by the automation application. To get the used commands and attributes, Fernandes et al. utilizes static analysis to determine a list of all methods and properties accessed in an automation application [8]. Then this list is filtered using the completed capability documentation to obtain the set of used commands and attributes in this app. In the end, the set of over-authorized commands or attributes can be computed.

(p9.3) D. Defense. The root cause is essentially the design flaw of the IoT platform. Therefore, to defend the attacks caused by the coarsegrained capabilities, the design of this system should be re-constructed. However, most IoT platforms are closed-source. Moreover, the cost of using a new design may be huge because of deployed devices and applications. Taking this into consideration, patching the automation application could be the only solution to defend this kind of attack. Jia et al. propose ContextIoT, which can automatically patch unmodified commodity automation application, to provide finegrained capabilities in the IoT platform [11]. ContextIoT consists of two major steps at two stages, e.g., installation time and runtime. At the installation time, ContextIoT collects context information from the automation application and patches it to separate security sensitive behaviors (e.g., unlock) which request permissions from the user, if the context is not logical. At runtime, ContextIoT prompts the request to the user to ask for permission if the behavior does not conform with a certain security logic. Essentially, Contex-tIoT prevents the usage of capabilities authorized to an automation application for malicious behaviors.
## (s10) Bug 6: Privilege Separation Logic Bugs in IoT Firmware
(p10.0) A.System Model. IoT devices continuously interact with different entities including mobile automation application, cloud or physical access (e.g., pushing a button) and perform the tasks corresponding to the user commands. As shown in Figure 4, because different communication channels usually use different protocols, ports and servers, the IoT firmware images are implemented with different functions to receive and decode the message from different interactive entities. We name the first function used to receive the message from interactive entities as caller functions. After decoding the message, IoT firmware images invoke other functions to extract the commands and finally trigger the corresponding functions to accomplish the specific tasks. We name the first function used to perform tasks for individual command as task function. In addition, since different entities play distinct roles in an IoT platform, the command sets from these diverse interactive entities are differential. That means some commands could only be invoked by specific interactive entities in normal operations. For instance, remote commands sent by the cloud are usually responsible for device management services like assigning device identification. Thus, most functions in IoT firmware can be divided into separated collections for dealing with commands invoked by different entities. Each collection should have distinct privilege, so that one entity can only invoke its own commands. For example, according to the privilege separation rules in Figure 4, Task function B should only be invoked by command B sent by mobile app and Task function C should only be invoked by command C sent by cloud and so on. B.Attack Scenario. As shown in Figure 5, a legitimate user is the ownership of a smart lock with the device ID A, and an attacker owns another IoT device with the device ID B. At this point, if the attacker has access to the same local network with the user's device, he is able to send a set_device_id command to the smart lock, changing the device ID of the smart lock from A to B which has been bound with the attacker's account as revealed in recent research [24].

(p10.1) Since the device ID is used to uniquely identify the device and the IoT platform maintains the binding relationship through the device ID. Once the device ID of the device has changed, the ownership of this device will be shifted with it. Thus, in the above attack scenario, after the device ID of the smart lock had been changed as B, the attacker can illegally occupy this device forever.

(p10.2) C.Cause Analysis. In the above attack example, the command set_device_id which should only be sent by the remote IoT cloud has been accidentally carried out by a local attacker. The root cause of that is the developers use common functions to deal with command sets belong to various interactive entities in real-world IoT firmware.

(p10.3) Due to these common functions, IoT firmware images often contain various execution paths from caller functions of different interactive entities but finally to the same task function. As shown in Figure 4, if IoT firmware uses the same function to extract commands from mobile app and cloud, except for the normal execution path from caller function 2 to function, there also exists an unexpected execution path from caller function 1 to task function C. That violates the privilege separation rules. Thus, the local attackers are able to perform some remote sensitive command C (e.g., setting device ID or unbinding the devices) which should only be sent by cloud. Such unexpected execution paths are called privilege separation vulnerabilities in paper [24].

(p10.4) D.Identifying Method. Based on the root cause of the attack, the key to identify privilege separation vulnerabilities is to identify the over-privileged common functions which will be used for performing one command but could be invoked by different interactive entities. Yao et al. [24] developed a useful tool to identify the over-privileged common function according to the path constraints generated by symbolic execution.

(p10.5) E.Defense. The strict privilege separation model should be implemented in IoT firmware to make the control flow and data flow of handling commands sent by different interactive entities strictly separated.
## (s12) Attack Scenario
(p12.0) Bug 7: Insufficient State Guard. As shown in Figure 6, an automation app has a home automation rule that connects a fire alarm and a smart lock, so that in case of a fire, the alarm can detect thick smoke and send a command to the smart lock to open the door. However, Zhou et al. [26] found the attacker is able to log in a phantom device the has the same device identity as the smoke alarm. Then the attacker can send fake smoke alarms via phantom device to the IoT cloud. As a result, the cloud will also unlock the door allowing the attacker to enter the room.

(p12.1) Bug 8: Illegal States Combination. If a user only unbinds the device but forgets to reset the device, the IoT cloud will also revoke the ownership with the user, but the device is still in its original state and keeps a connection with the IoT cloud. This allows a remote attacker to forge and send a binding request with his account to cloud at that moment as shown in Figure 7. Since the connection between cloud and device is still maintained, after the cloud accepts the binding request, the victim's device will be directly under the control of the remote attacker without finishing other setup steps including device discovery or logging in the cloud.
## (s19) Attack Scenario
(p19.0) An attacker can exploit the out-sync of sensor data to cause sensor blinding or state confusion [15]. Sensor blinding attack could destroy the availability of sensor devices by preventing the delivery of sensory measurements to the IoT cloud. State confusion attacks the integrity of actuator state of devices reported to IoT cloud, and causes the state displayed in the companion mobile app to be inconsistent with the actual state of the actuator. We assume that the attackers can fingerprint the IoT devices being used and learn the telemetry channel model for a specific device, they can also selectively suppress a particular channel in the following attack scenarios. Attackers can achieve this by physical layer suppression (e.g. jamming) and local network layer suppression (e.g. controlling over the wireless router).

(p19.1) Bug 9: Sensor Blinding. As a concrete example mentioned in research [15], the Merkury Security Camera is a connected surveillance camera that is able to record abnormal motions such as home invasion, and uploads motion notification to AWS servers using a plain-text MQTT connection. Meanwhile, the device separately sends heartbeats (connectivity health and video content) to the AWS servers over SSL. Attackers can easily identify the alwaysresponsive and on-demand messages by correlating the packet timings and blind the sensor from delivering abnormal messages. The server regards the device as online because it receives the periodic heartbeats, but it will not be aware the device fails to report on-demand messages. Thus, the companion mobile app will not alert the user for the abnormal event even though the device upload videos over the SSL connection. Because the device does not buffer undelivered events if it is not disconnected, users will not get a notification even after connection reconstruction. Attackers can utilize this logic bug to eliminate forensic evidence to gain physical access to areas. 
## (s21) Defenses
(p21.0) There are three main methods to defend against telemetry channel suppression attacks in IoT [15]. The first method to defend against the attack is to obscure messages sent from the devices by manipulating traffic. Another method is to establish pre-IoT virtual private networks to prevent attackers from inferring traffic activities and selectively suppressing the on-demand sub-channels. Besides, unifying the on-demand and always responsive sub-channels, redesigning priority buffer scheme, and reducing timeout length to achieve a secure IoT design are great solutions for this logic bug.
## (s22) UNEXPECTED TRIGGER ACTION IN AUTOMATION APPLICATION 8.1 System Model
(p22.0) The automation app developments are based on a software stack provided by IoT platforms to realize monitoring and controlling on IoT devices * . Under the hood, as shown in Figure 10, the triggeraction model of the IoT platform consists of events, event-handler methods of automation app, actions, and the attributes which represent the state information of devices. To realize the trigger-action services, the automation app needs to register an event-handler with a device event or pre-defined event. The handlers are triggered to take action when these events occur. Actions represent the commands to control device states, which cause modifications on attributes, e.g., device state changes.

(p22.1) By exploiting the logic flows of the trigger-action rules, several critical bugs have been disclosed by Celik et al. [5], In what follows, we introduce four representative bugs in this category.
## (s23) Bug 11: Race Conditions of Events
(p23.0) A. Attack Scenario. As is defined in [5], an attribute of a device can not be modified to conflicting values by two or more noncomplementary event handlers of multiple apps working in concert, which may lead to a potential race condition. For example, "When motion is detected, turn on the switch" and "Every day at midnight, turn off the switch" will conflict if motion is detected at 12 pm. It is notable that the authors [5] do not investigate what attacks the adversary may realize by utilizing these bugs. Thus, the consequences caused by this bug are limited to leading devices trapped into insecure or unsafe states. * All the unexpected trigger-action bugs covered in this section lie in Samsung's Smart-Things Platform B. Cause Analysis. Upon its subscribed events' occurrence which is different from each other, two or more independent event-handlers of multiple apps are invoked to take actions possibly at the same time to manipulate the same attribute of one device to conflicting values. The sequence and timing of actions of these event-handlers usually make the final states of devices unpredictable.
## (s30) Identifying Method & Defense
(p30.0) Bastys et al. propose two solutions to defense the attacks caused by the URL-based information flow in IFTTT service, breaking the flow and tracking the flow [3]. Breaking the flow means to classify the trigger and action service providers, and restrict the sources and sinks to either exclusively private or exclusively public data. In this way, there is no flow from private to public, thus preventing privacy leakage. Specifically, the access to public URLs in the filter code is disabled or delegating the choice to the users at the time of the applet's installation. However, both methods for breaking the flow may over-kill the benign applets and is not flexible for future service features. On the other hand, tracking the flow ensures the only way to include links or markup on the action-based APIs is through using API constructors provided by IFTTT service. By monitoring the information flow in the applet, this method can prevent privacy leakage and eliminate the defects in breaking the flow method.   Table, which holds a set of address pointers pointing to particular memory management functions in MMS, is used by the TMS to index the "services" provided by the MMS. The Mbed task sandboxing mechanism ensures that the data of every sandboxed task will be stored in memory and only accessible in the privileged mode, and that the memory access permission can only be switched by the MMS. As an example of TMS, the task scheduler is finding the ready-to-start task shown in Figure 11. Were it to be a sandboxed task, the task scheduler uses pre-defined SVC calls to trigger SVC dispatcher to run in the privileged mode. The dispatcher then searches the context table to call MMS, which configures the MPU to set the memory region of the task's data with readable/writable permissions in the unprivileged mode. Finally, the dispatcher uses specific instructions (e.g., load EXC_RETURN into the PC register in Cortex-M processors) to return to the unprivileged mode and gives control to the sandboxed task.
## (s32) Weakness 1: Inadequate Task Memory Isolation
(p32.0) A. System Model. In x86 processors, every task could run in an isolated virtual memory address space offered by the virtual-tophysical address translation of MMU. Through mechanisms such as Inter-Process Communication (IPC) and shared memory, tasks can exchange information but still be restricted to their own address spaces. Since the MPU does not support virtual memory, the RTOSs deployed on IoT devices simply layout (the code and data of) tasks into a (shared) physical memory address space, which makes the memory address space a large attack surface for attackers who are exploiting a memory corruption vulnerability.

(p32.1) B. Attack Scenario. As shown in Figure 13, it is obvious that an attacker can compromise function 1 in task Y through a buffer overflow to redirect the control flow to function 2 in task X.

(p32.2) C. Cause Analysis. First, traditional OSs use MMU to abstract physical memory in the form of virtual memory for restricting tasks' access accessibility, while RTOSs deployed on IoT devices do not support this feature. Second, MPU roughly divides the physical memory into MPU regions of a fixed number, each assigned with different access permissions under both privileged and unprivileged modes. But this lightweight access control design cannot provide such isolation of the same level as that by MMU.

(p32.3) D. Identifying Method. To identify this vulnerability, the attacker needs to determine the target task X who contains a function 2, whose entry address is known to the attacker. Then, the attacker finds or designs a intermediary task Y who contains a trampolinefunction (e.g., function 1) with the potential ability to jump to the target address of the attack and cannot resist the memory corruption attack (e.g., buffer overflow). Finally, if the attacker can compromise the function 1 to call function 2, it is considered that there actually is an inadequate task isolation vulnerability.

(p32.4) E. Defences. Kim et al. [12] designed a security architecture that virtually partitions the memory space and enforces memory access control of a RTOS. Through off-line analysis on identifying the reachable memory regions of a task, they used MPU to conduct run-time memory access control for each task and finally reduces the memory spaces which are open to attackers.
