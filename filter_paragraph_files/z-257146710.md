# Usability Evaluation of Dashboards: A Systematic Literature Review of Tools

CorpusID: 257146710 - [https://www.semanticscholar.org/paper/3442c410623f5963d3fa7110f59837278ed33c4f](https://www.semanticscholar.org/paper/3442c410623f5963d3fa7110f59837278ed33c4f)

Fields: Computer Science, Medicine

## (s0) Introduction
(p0.0) Nowadays, healthcare organizations encounter various forms of information chaos, such as information overload, erroneous information, scattered information, and incompatibility of information with job requirements [1]. Meanwhile, effective and efficient use of data in managerial and clinical decision-making can be complicated because of the massive amount of data, data collection from various sources, and lack of data organization, which can lead to increased errors [2], delayed service delivery [3], and patient safety risks [4]. Agile healthcare organizations use relevant data in their daily operational decisions, ranging from supply chain management and staff planning to care delivery planning and community health management [5].

(p0.1) Healthcare systems are increasingly using business intelligence systems for monitoring performance indicators [5]. According to Loewen and Roudsari, these systems are used for collecting, analyzing, and presenting organizational data to intended users in their required format in line with meeting organizational objectives [6]. Dashboards are one of these systems widely used in the healthcare settings. Through data visualization, dashboards provide practical feedback to improve performance, promote the use of evidence-based methods, and enhance workflow and resource management [7,8]. These tools also use visual representations, such as charts and color coding, to facilitate the interpretation of information [8,9].
## (s2) Data Sources and Search
(p2.0) Strategy. The search and data extraction stages were performed based on the PRISMA checklist [23]. Articles were extracted by searching the PubMed, Web of Science, and Scopus databases. A combination of MeSH terms and keywords related to dashboards, usability, and questionnaires was used for the search strategy ( Table 1). The final search of articles was carried out without any time restrictions. Two researchers (SA and SS) searched and retrieved articles independently, and any disagreement was discussed with the senior author (RR).
## (s5) Study Selection, Article Evaluation, and Data Extraction.
(p5.0) In the study selection phase, two authors (SS and SA) performed screening, selection, and full-text review and two authors (KB and HA) performed qualitative evaluations of papers; any disagreement was checked and eliminated through discussing with the senior author (RR). The quality of each study was checked by using the Joanna Briggs Institute (JBI) critical appraisal tools. The JBI-MAStARI instrument was used for RCT and quasiexperimental studies (nonrandomized experimental studies) [24]. For RCT studies, there is a checklist containing 13 questions with four options ("yes," "no," "unclear," and "not/applicable"). For quasiexperimental studies, there is a checklist covering 9 questions with four options ("yes," "no," "unclear," and "not/applicable").

(p5.1) One score was assigned for each "yes" answer, and in case 70 of the questions led to "yes" answer, the risk of bias was considered as low. The risk of bias was regarded as "moderate" in the event of obtaining 50-60% of "yes" answers. Ultimately, a "high-risk" bias was assigned to "yes" responses below 50% (Appendix A Table A1 and Appendix A Table A2).

(p5.2) For data extraction, the features of questionnaires, including the number and scoring of questions, criteria, and reliability, were first investigated (Table 2). Next, the year of the study, country of the study, evaluation criteria for dashboards, and questionnaires used for the evaluation of dashboards were extracted for each article and entered into Microsoft Excel for analysis (Appendix B Table A3). Moreover, for data extraction, the questionnaires were assessed, and the evaluation criteria for dashboards were extracted ( Table 3). The reasons for selecting or removing each criterion for dashboard evaluation in the questionnaires are presented (Appendix C Table A4).
## (s12) Discussion
(p12.0) In the present study, questionnaires used in previous research were reviewed to suggest criteria for dashboard evaluation. Generally, questionnaires are the most commonly used tools for usability evaluation because of the simplicity of data analysis [53,54]. According to the findings, although SUS does not cover the efficiency, memorability, or error criteria and consists of a series of general questions for usability evaluation [55], it was the most widely used tool for dashboard evaluation. In four studies, SUS was used along with other questionnaires for dashboard evaluation [32][33][34][35].
