# Interpretability in Activation Space Analysis of Transformers: A Focused Survey

CorpusID: 255547504 - [https://www.semanticscholar.org/paper/58c8b76e5090de43f753be3284b628ec3c8285ac](https://www.semanticscholar.org/paper/58c8b76e5090de43f753be3284b628ec3c8285ac)

Fields: Computer Science

## (s4) Activation Space Analysis Methods
(p4.0) There are two types of interpretability analysis that are carried out in the related research work: 1) Analyze individual neurons and 2) Analyze the entire set of neurons of the feed-forward layer. We look into both approaches from four perspectives: categorization, linguistic knowledge sought for, methodology, and evaluations, and conduct a comparative analysis of these methods. Linguistic Phenomena: Investigating the linguistic phenomena that occurs within the activations of pretrained models, when trained for a specific task set, using various interpretability analysis methods, is a common way to interpret the features learned by these models. The linguistic phenomenon refers to the presence of various linguistic features such as word morphology, lexical semantics, syntax or linguistic knowledge such as parts-of-speech, grammar, coreference, lemmas. Linguistic Correlation Analysis (LCA) is one such method that focuses on understanding what the model learned about linguistic features and determining those neurons that explicitly focus on such phenomena. A toolkit with three major methods, Individual Model Analysis, Cross-model Analysis and LCA, to identify salient neurons within the model or related to a task under consideration, is presented by Dalvi et al. [13].
## (s5) Evaluations
(p5.0) Linguistic Phenomena: A layer-wise probing is conducted to understand the redistribution of linguistic knowledge (syntactic chunking, POS, and semantic tagging) when fine-tuned for downstream tasks [14]. Using this probing across three fine-tuned models BERT, RoBERTa, and XLnet, on GLUE tasks and architectures reveal the following observations: The morpho-syntactic linguistic phenomenon that is preserved, post fine-tuning, in the higher layers is dependent on the task; Different architectures preserve linguistic information differently post fine-tuning. The neuron-wise probing further refines to the fine-grained neuron level, where the most salient neurons are extracted and their distribution across architecture and variations in downstream tasks are studied. An alignment of findings is found with Merchant et al. [38], where the fine-tuning affects only the top layer. In comparison with Mosbach et al. [39], which is focused on sentence level probing, Durrani et al. [14] studies corelinguistic phenomena. Additionally, their findings from fine-grained neuron analysis extend the core-linguistic task layer-wise analysis, along with fine-tuning effects on these neurons. Another interesting observation made is the different patterns that are entailed when these networks are pruned from top or bottom.
