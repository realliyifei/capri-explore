# A Survey of Malware Detection Techniques based on Machine Learning

CorpusID: 86679729 - [https://www.semanticscholar.org/paper/2fb8c4d2a203bc918f5d936036428579ecb09d92](https://www.semanticscholar.org/paper/2fb8c4d2a203bc918f5d936036428579ecb09d92)

Fields: Computer Science

## (s13) C. Principal Component Analysis (PCA)
(p13.0) The principal component analysis is a procedure for reducing the number of variables and making the information less redundant.It uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of uncorrelated variables.It is at the same time a geometric approach (the variables are represented in a new space, according to maximum inertia directions) and a statistical approach (the research focuses on independent axes that best explain the variability or variance of the data).Siddiqui et al. [4] used this technique in their process of reducing the initial set of data.They started with 877 variables.After the application of PCA, they retained solely the variables that explained 95% of the full variance of the data set.As a result, they obtained 146 variables, a considerable reduction of the number of features.

(p13.1) After using the information gain as a first feature selection technique, Zhang et al. [20] utilized the PCA as a second feature selection technique in their research in 2018.They finally retained 50 features to train their classification model.They didn"t specify the initial number of features.
## (s14) D. Random Forest
(p14.0) The random forest technique is a prominent technique for classification and regression.Nevertheless, it is a notable feature selection technique as well.For feature selection, it calculates the importance of an attribute by removing it from the model, then calculating the decrease in either accuracy or Gini index.These two metrics are used to evaluate the classification models and to explain their performance.The chosen attributes are the ones that imply a significant decrease in the chosen evaluation metric when removed.

(p14.1) For the selection of features, Siddiqui et al. [4] used both PCA and random forest techniques, in two different approaches.Using the random forest, they rejected the variables where the average decrease in accuracy was less than 10%.Thereby, they retained only 84 variables from 877.Pablo et al. [12] took advantage of this technique as well.They combined it with another technique called Chi-Squared.They used the Chi-Squared method first, which allowed them to retain 68,800 features from a total number of 682,936 initial features, which is 10% of the entire set.Then, they applied the random forest technique.They chose the ranking made by accuracy decrease.The reduction passed by successive stages.They went from 68,800 features, to 10,000 features, then to 5000, 1000, 300, 100, 30, 10, and finally to 9 features uniquely.
## (s16) F. Self-Organizing Feature Map (SOFM)
(p16.0) Self-organizing feature maps (SOFMs) form a class of neural networks.They can be used for either classification or dimensionality reduction.Burnap et al. [12] used SOFMs to reduce the features dimensionality.Once a sample is received, it runs through a virtual environment for 5 minutes.The chosen nine machine activity metrics, mentioned in section II.F, are taken every second, producing 300 vectors of nine values for each sample, in the 5-minute time window.Then, SOFMs are used to transform each 9-dimensional vector to a 2-dimensional vector.Therefore, 300 vectors of x-y coordinates are used as features for the training of the model.
## (s17) G. Wavelet Transform
(p17.0) Various researches use the Wavelet Transforms for dimensionality reduction [9,21].Wojnowicz et al. [9] applied the wavelet transform to the entropy signals at different levels of resolution.For each level of resolution, each training file was divided into chunks of code, then the average entropy of each chunk was calculated, resulting in a discrete entropy signal.This signal was then multiplied by appropriate wavelet functions to get values called wavelet coefficients.After that the spectral energy was calculated as the sum of the wavelet coefficients squares.The spectral energies gathered from each www.ijacsa.thesai.orglevel of resolution were used as input features for the machine learning classifier.For the highest level of resolution, the files were divided into code chunks of 256 bytes each.For example, if a file size is 32 * 256 bytes, since 32 = 2 5 , the file will be decomposed 5 times; to 2 1 , 2 2 , 2 3 , 2 4 , and 2 5 pieces, giving 5 levels of resolution.It subsequently generates 5 features which are the spectral energies E 1 , E 2 , E 3 , E 4 and E 5 .In addition to these spectral energies, Wojnowicz et al. integrated additional string features and entropy statistics for the training of their model.
## (s20) B. Random Forest
(p20.0) A random forest is an ensemble learning method used for classification and regression.It is constructed from a collection of decision trees.Each tree determines the class label of an unlabeled instance and then gets its classification.Each tree is divided at each node taking into account random features.Therefore, the model selects the most chosen class among all trees.The larger the number of trees, the more accurate is the result.Siddiqui et al. [4] built their model with 100 classification trees.The number of variables tested at each division was ranged from 6 to 43, depending on the number of selected variables in the data set.They formed several combinations presenting several experiments, such as:  Random forest for classification using all the 877 initially extracted features  Random forest for classification using 146 features retained by PCA feature selection technique  Random forest for classification using 84 features retained by random forest feature selection technique

(p20.1) The best results were obtained using random forests for both feature selection and classification.Bai et al. [7] also obtained the best results using random forests as classification model, they compared it to other decision tree models.
## (s22) V. CLASSIFICATION OF THE STUDIED RESEARCHES
(p22.0) There are several indicators to measure the performance of a given classifier.For the classification of the different studied researches, this paper was interested in the accuracy rate of each one of them.Accuracy is defined as the number of malicious files classified as malicious, plus the number of benign files classified as benign, divided by the total number of files.Table 3 shows our results taking into account the most important researches.

(p22.1) We should mention that Burnap et al. [12] didn"t calculate the accuracy in their experiments.They used instead the precision rate.It is the number of malicious files classified as malicious, divided by the number of all the files classified as malicious.

(p22.2) Several researches investigated in this paper use the k-fold cross-validation.It is a resampling procedure used to evaluate machine learning models on a limited data sample.The technique partitions the existing dataset into iterative learning and test subsets.It is applied to estimate the efficiency of a machine learning model on unseen data.However, since it does not use a completely new subset for the final test of the model, this can lead to an overfitting of the training data, the model subsequently would fail to perfectly generalize to previously unseen data.Therefore, an important factor is to check whether a classification model could generalize from previously seen data in the model training, to new data exclusively used for the last test phase.

(p22.3) Burnap et al. [12] performed their first experiment using 10-fold cross validation.In a second experiment, they used a new unseen set of data for the final test.By comparing the two experiments, we remark that the results of the random forest model decreased by more than 12% from the first experiment to the second one, whereas those of the ANN model decreased by 2.45% only.That shows that a model based on an ANN provides more stability between training and test datasets.Pablo et al. [8] also made such a comparison.In the first experiment they obtained an accuracy of 99.60%, and after the application of their model to new malicious files, whose date of appearance was located after the date of the files used for training, the new accuracy was 98.40%.The results of the ANN model decreased in this case by just 1.20%.

(p22.4) As for Abdelsalam et al. [18], their best model considered performance metrics collected over a time interval as inputs to a convolutional neural network.They obtained an accuracy of 97% with the validation dataset, this result dropped to 90% while testing with the new test dataset.Here we see that the accuracy rate of the results of the convolutional neural network model decreased by 7%.The references [8], [9], [10], [12] and [18] are the only malware detection researches in this paper that used unseen data for the final tests, yet they are the ones that have frequently achieved the best results.

(p22.5) In Table 3, the results of [3] and [4] were taken into account for comparison reasons, knowing that it is very likely that their accuracy rates will decrease while using unseen data for the final performance tests.
