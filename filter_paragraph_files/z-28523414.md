# Edinburgh Research Explorer a review of the tools used for marine monitoring in the UK Citation for published version

CorpusID: 28523414 - [https://www.semanticscholar.org/paper/71965057c5aa9e83d7700cf1ec734f29f0a22c31](https://www.semanticscholar.org/paper/71965057c5aa9e83d7700cf1ec734f29f0a22c31)

Fields: Engineering, Political Science, Environmental Science

## (s5) Fixed Point Marine Observation Systems
(p5.0) Fixed-point marine observation systems have been deployed globally, including in UK waters, to make in situ sustained Eulerian observations of a variety of biogeochemical and physical variables. Various platforms have been deployed, including fixeddepth or profiling moorings, fixed piles, towers and seabed landers that employ instrumentation capable of long term, autonomous operation. European programmes (e.g., FixO3 (Table S1; 3, Cristini et al., 2016), Jerico (Table S1; 4, Sparnocchia et al., 2016) have been successful at linking data streams from many of these platforms, greatly increasing the geographical spread and availability of monitoring data across Europe (Table  S1; 5). Current sustained fixed point-observation systems include open ocean sites such as those under the global OceanSITES programme (Table S1; 6) (Hartman et al., 2015); and coastal seas locations such as the German COSYNA project (Table S1; 7), the SmartBuoy and WaveNet programmes within the UK (Mills et al., 2005, Table S1; 8) and the moorings at stations L4 and E1 in the Western Channel Observatory (Table S1; 9). Such platforms can resolve processes that are episodic and/or have high temporal variability, which traditional platforms such as research vessels are less able to resolve. Parameters determined on such platforms include inorganic nutrients, sea surface salinity and temperature, chlorophyll, dissolved oxygen, phytoplankton species, turbidity and the underwater light climate. These data are used within the OSPAR eutrophication assessment (Foden et al., 2011). In addition, these data have enabled better design of robust monitoring programmes (Heffernan et al., 2010), validation of models (Große et al., 2016;van der Molen et al., 2016) and satellite marine products (Neukermans et al., 2012), and for studying ecosystem behavior (Devlin et al., 2009;Blauw et al., 2012;Capuzzo et al., 2013Capuzzo et al., , 2015Johnson et al., 2013;Hull et al., 2016). Fixed-point moorings are also used for making measurements of the wave climate. WaveNet is the UK strategic operational wave monitoring network. It provides near real-time data on the wave climate to the UK Coastal Flood Forecasting Service (Table  S1; 10) to help improve coastal flood forecasting models and the assessments of flood risk in the UK. In addition, WaveNet maintains the primary UK archive for wave data, which is used by engineers to design coastal sea defenses and offshore structures. Additional example programmes within the UK include Marine Automatic Weather Stations (MAWS) on moored buoys (Table  S1; 11) and the Channel Coastal Observatory (Table S1; 12).

(p5.1) In CP2, data from fixed point platforms were used for assessment of marine air temperature, salinity, sea surface temperature, wave climate, ocean circulation, suspended particulate matter and eutrophication (UKMMAS, 2010).
## (s7) Subsurface Floats
(p7.0) Subsurface floats are autonomous Lagrangian platforms, which make observations of the ocean by moving with it (Swallow, 1955). A float is designed to be neutrally buoyant at the depth of interest and parameters can be monitored as it moves. Tracking its location can be done either at depth by acoustics or by making floats that can vary their buoyancy and return to the surface to be tracked by satellite. Initially, floats were designed to measure the ocean flow field but modern floats provide a platform for other hydrographic measurements (e.g., temperature, salinity, oxygen) and data is sent back via satellite. Advantages of float-based monitoring are the potential for global coverage, continual direct data supply, ease of deployment, cost efficiency, power of analysis for large groups of floats, horizontal resolution at target depth and vertical resolution during surfacing and sinking. Disadvantages are that they can be lost and that the geographical location of measurements is dependent on arbitrary movement. As such, targeting the observations to spatially limited processes or systems can be difficult. Strong quality control and calibration protocols are needed for instruments that are not recovered regularly. Full water column sampling by this method is limited by the depth of buoyancy control by the float (Davis et al., 2001;Roemmich et al., 2009).

(p7.1) The defining subsurface float design is the Argo float, which has revolutionized the way the internal workings of the oceans are monitored (Gould et al., 2004). The global Argo programme (Table S1; 16) has been operational since 1999, with a peak deployment of over 5,000 profiling drifting floats measuring depth, temperature and salinity in the upper 2,000 m of the world's oceans (Riser et al., 2016). The capacity to make biogeochemical measurements from Argo floats is also developing (Emerson et al., 2002;Johnson et al., 2009;Claustre et al., 2010). Argo data have been used to study topics including: water mass properties and formation, air-sea interaction, ocean circulation, mesoscale eddies, ocean dynamics and seasonal-todecadal variability. In the UK, Argo float data are utilized in real time by the Met Office for ocean forecasting (National Partnership of Ocean Prediction), where information is required to integrate models of deep ocean behavior for 7-day forecasts of global sea temperature (GloSea5/FOAM).
## (s11) Satellite
(p11.0) Earth observation (EO) data have the potential to provide considerable support to in situ and/or field-based marine monitoring; offering synoptic observations of systems at relatively high temporal frequencies. Indeed, ocean color EO data are becoming widely used to provide information on indicators of water quality at increasingly relevant spatiotemporal scales (Tyler et al., 2016). The uncertainties associated with EO products have raised concerns about their applicability to monitoring activities under official directives, such as MSFD. However, in the UK's optically-complex coastal and shelf sea waters, satellite retrievals of chlorophyll-a (Chl-a), suspended particulate matter (SPM), turbidity (Kd) and colored dissolved organic matter (CDOM) have benefited substantially from the recent development and validation of tailored algorithms (Mitchell et al., 2016;Tilstone et al., 2017). Integration of EO data with in situ data from research vessels, AUVs and ROVs, fixed point marine observing systems, SOO and subsurface floats is essential for validation of EO products. Recent validation studies of MERIS chlorophyll (Cristina et al., 2015) support the feasibility of integrating EO data for marine monitoring, specifically for MSFD Descriptor 5 (minimizing eutrophication).

(p11.1) In continuity of MERIS, the ESA has launched the Sentinel-3 OLCI instrument for improved and complete coverage of oceans at 300 m full resolution every 1-4 days. EO measurements from next-generation satellites have the potential to improve data collection for a range of current and future monitoring requirements, including identification and differentiation of phytoplankton functional types for harmful algal bloom detection, measuring of total suspended particulate materials, pigmented fraction of dissolved organic matter, and changes to systems in response to changes in climate (Cristina et al., 2015;Tyler et al., 2016).

(p11.2) Satellite data collected from the above system are generally used to produce and overlay maps (e.g., GeoTIFF, GeoJSON, and netcdf formats) by measuring variables in space and time. Satellites are collecting petabytes of data annually but these are held by the satellite owner (usually NASA or ESA) and only the relevant data, orders of magnitude smaller, are analyzed locally using relevant software (e.g., Matlab, Python or R).
## (s13) Sensors
(p13.0) There is a wide range of sensors available for marine monitoring including chemical, biogeochemical, physical and biological parameters (Kröger et al., 2009;Mills and Fones, 2012) some of these are employed within the UK programmes described in this paper. These include CTD systems routinely deployed from research vessels and sensors for measuring salinity, temperature, oxygen, turbidity, chlorophyll fluorescence, light and nutrients on fixed point moorings (Section Fixed Point Marine Observation Systems) and FerryBox systems (Section Voluntary Observing Ships and Ships of Opportunity). Whilst autonomous surface and underwater vehicles are not currently deployed within statutory monitoring programmes in the UK, many of the sensors described can also be integrated with these vehicles. Considerations of power requirements, size, weight and degree of autonomy typically determine which platforms the sensors may be deployed on. Recent developments in smaller and cheaper electronic components has enabled low-cost sensors to be developed, including for the marine environment, to measure parameters such as chlorophyll fluorescence, turbidity, pH, temperature and salinity (Radu et al., 2010;Leeuw et al., 2013;Murphy et al., 2015;Sendra et al., 2015). Given sufficient stability and sensitivity, these have the potential to be incorporated into monitoring programmes where appropriate.
## (s16) Satellite Sensors
(p16.0) Ocean color sensors aboard different satellites can measure the small proportion of incident radiation (reflected sunlight) not absorbed by the ocean and its constituent components. This is an average derived from the surface to "one optical depth"the depth to which satellites can "see" (McClain, 2009). In the most optically non-complex (clear) waters, this depth averages to around 20-25 m (Kemp and Villareal, 2013). Today, the marine environment is simultaneously monitored by the NASA MODIS (National Aeronautics and Space Administration's Moderate Resolution Imaging Spectroradiometer), NOAA VIIRS (Visible Infrared Imaging Radiometer Suite) and the ESA OLCI (Ocean and Land Color Instrument) sensors. As with all ocean color sensors through time, these are carried on polar-orbiting satellites in sun-synchronous, low-Earth orbit. Coverage is global, measured in the visible and rear-infrared spectral range (400-900 nm), reaches up to 300 m at full resolution, and revisit times range from daily to once every 4 days. Importantly, these data are also freely available through their respective NASA and ESA portals.
## (s19) Visual Taxonomy-Plankton
(p19.0) Full-community microscopic analysis of fresh-and brackishwater phytoplankton is currently undertaken for compliance with the EU Water Framework Directive and contributes to water-body characterizations in the UK. Cell density and the suspended sediment load will often dictate the methods of phytoplankton examination chosen. In the case of zooplankton, general community data is used for biodiversity, ecosystem, and impact assessment. Fish eggs and larvae are also used for both ecosystem and fish stock assessment. Quantitative sampling is usually done aboard ship: zooplankton is traditionally collected using the deployment of nets, vertically in the water column or towed behind the vessel (e.g., Gulf VII, Nash et al., 1998), and the sample must be preserved prior to organism enumeration and identification.

(p19.1) Microscopic analysis of both zooplankton and phytoplankton is time-consuming and requires a considerable amount of taxonomic expertise. It is possible to combine microscopy with more rapid assessments such as flow cytometry as a qualifying enhancement to the analysis. Furthermore, FlowCam TM , Zooscan and other semi-automated analysis methodologies exist, although still require a taxonomist to validate identification performed by the instrument. Continuous automated surface water sampling on a research vessel can describe broad geographic patterns in zooplankton biodiversity and taxonomic composition (Pitois et al., 2016). It can be integrated within existing multidisciplinary surveys at little extra cost and without requiring additional survey time making it a particularly useful tool as part of integrated monitoring to underpin policy areas such as the MSFD. More recent advances in image recognition algorithms allow for in-flow instruments for imaging and identifying zooplankton in near real time as a ship is transiting (Culverhouse et al., 2015(Culverhouse et al., , 2016. The use of in-flow plankton image analysis will potentially produce tens of terabytes of data per survey which can be processed on-board, but needs to be stored on servers until then. Image recognition algorithms are used to identify the zooplankton species and/or taxonomic groups; these require intensive computational processing power to output a list of species or taxonomic groups, their density and size distribution.
## (s20) Biosensors
(p20.0) While the use of physical and chemical sensors is widespread and well understood in marine science and monitoring, biosensors have not yet realized their full potential. The term biosensor refers to a large array of sensor types and complex analytical instruments, ranging in their biological sensing element from entire cells to individual molecules such as antibodies, enzymes or nucleic acids, and in their detection element from optical to electrochemical, acoustic and beyond. Several papers and book chapters have reviewed existing technology (e.g., Kröger et al., 2002;Justino et al., 2015). These publications highlight potential applications and combinations with many of the platforms discussed above, although pitfalls including limited sensor stability, availability of the biological sensing element and lack of commercialization for marine applications (the most successful biosensors have been developed for other fields such as medical point-of-care diagnostic, biosecurity and food analysis). With rapid advances in the field of molecular biology, the use of molecular diagnostics and molecular-probebased sensors for many marine applications, such as the detection of harmful algal blooms, invasive species, or studies into population dynamics, are becoming more affordable and routine, thus creating opportunities for their inclusion in marine monitoring.

(p20.1) Examples of current commercially available marine biosensors are a nitrate and nitrite sensor based on immobilized whole microorganisms (Unisense, Denmark, Table S1; 22) and the Environmental Sample Processor capable of collecting and analysing marine water samples for a wide range of parameters such as chemicals, biologicals (microbes, larvae) and particulate matter (Table S1; 23). Biosensors can produce a range of data types, depending on the combination of biological sensing element and transducer employed. In general, the data volume produced is low, and if necessary for analysis can be reduced to qualitative yes/no answer or a relatively simple quantitative response.
## (s21) Molecular Biology Techniques
(p21.0) Molecular biology is the analysis of DNA, RNA or proteins and is perhaps most commonly exploited in the fields of disease diagnostics, forensic science, and taxonomic analyses. There are many molecular tools (e.g., PCR, high-throughput sequencing and allozyme markers) that can be utilized for the analysis of marine samples (for review, see Bourlat et al., 2013). However, it is perhaps more appropriate here to focus on the end aims of downstream analyses and what can now be achieved with new technology. The most common application for using molecular tools is species identification, whereby a cryptic individual, pathogen, or a partly processed fish sample (Miller and Mariani, 2010) can be identified by a specific DNA-based assay. Species ID techniques can also be used in a quantitative manner; in marine systems example uses include quantification of fecal contamination at swimming beaches (Griffith and Weisberg, 2011) or for direct quantification of zooplankton that are otherwise difficult to identify (Vadopalas et al., 2006). The identification of species within a sample can now be taken a level further. Analysis of DNA from environmental samples (often known as eDNA) in combination with high throughput DNA sequencing methods, can be used without prior knowledge to assess the species diversity present in, for example, a stomach content sample (Leray et al., 2015), a benthic macrofaunal sample , or a water sample as a surrogate in fish stock analysis (Thomsen et al., 2016). This approach can potentially reduce the need for expensive and time consuming taxonomic identification by experts, opening the possibility of automation, although these techniques still require a large amount of validation and are not yet capable of replacing traditional methods for marine monitoring. In addition to high levels of specificity, molecular techniques can often provide an exceptional level of sensitivity, providing enough data to inform questions about the presence, absence and movement of species through an ecosystem, without actually catching the species in question. e.g., non-indigenous species (Zaiko et al., 2015;Davison et al., 2017), large pelagic fishes (Thomsen et al., 2012), or microscopic indicators of water quality (Pochon et al., 2015). There are additional molecular tools for data collection during monitoring. For example: population genetics can be used to assess genetic introgression between fish stocks (Tysklind et al., 2013); gene expression analyses to diagnose where animals may be impacted by novel, or emerging contaminants (Hutchinson et al., 2013); and ecosystem function can be inferred either through metagenomic (Langille et al., 2013), or metatranscriptomic (Durkin et al., 2012) analyses of the species present. However, these techniques are likely to inform decision making on how to monitor, rather than being part of a monitoring programme per se. Generally, the biggest advance in molecular tool capability has been (and will continue to be for the foreseeable future) the development of high throughput sequencing systems, which have made large scale sequencing exponentially quicker and cheaper. These tools are becoming cheaper and smaller and it is likely they will be used on vessel based, or unmanned platforms for rapid identification of single species, or for large scale studies of biodiversity. It is worth noting that DNA sequencing for species identification will produce tens of terabytes of data per annum. This data will need storing, either on accessible online databases (For example EMBL, Table S1; 24) or on servers with the relevant responsible authority. Raw data analysis requires intensive computational processing power, via Linux cluster, to reduce information to a species list or indicator index, as in Aylagas et al. (2014).
## (s22) Passive Samplers
(p22.0) New technology to aid assessment of chemicals in the water has developed in the form of passive samplers (Booij et al., 2016). Passive samplers offer the opportunity to derive a single extract from a sampler which can be used to analyse for a wide range of compounds. Passive samplers do not currently encompass the full suite of contaminants that require monitoring, although methods are constantly being investigated and improved. Inter-laboratory comparisons have also begun as part of QA/QC requirements for inclusion in the CEMP (Section Contaminants Monitoring). The results obtained from a passive sampler can be calculated back to a dissolved water concentration or bioavailable sediment concentration, which are more environmentally relevant in terms of exposure to an organism that the total concentrations traditionally measured. The samplers have been deployed on fixed point systems (Section Fixed Point Marine Observation Systems) and have also been incorporated into a FerryBox system on a research vessel (Sections Research Vessels and Voluntary Observing Ships and Ships of Opportunity), allowing continuous sampling of water and exposure of the samplers when the research vessel is at sea. If a vessel is operating within a welldefined spatial area, then this has the potential to provide valuable monitoring data. Passive sampling has the potential to offer lower cost sampling, if current policy can adapt to accept the calculated results obtained over traditional water, sediment and biota analysis.
## (s25) Fisheries Stock Assessment
(p25.0) The primary objective of fisheries monitoring is to underpin management to achieve maximum sustainable yields (MSYs) for all commercial fish and shellfish species. This has been an integral part of the EU's Common Fisheries Policy (CFP), which was first implemented in 1983. It has been gradually acknowledged that commercial fisheries have dramatically changed the structure of marine ecosystems and that fish stocks should be managed as part of the ecosystem. Currently, a policy framework to support the integration of European environmental and fishery management is largely in place (Jennings and Le Quesne, 2012). The main policies driving this integration are the Habitats Directive (Council Directive 92/43/EEC), the CFP (Council Regulation (EC) No, 2371/2002) and more recently the MSFD (Council Directive, 2008/56/EC). The CFP aims to fulfill its objectives by defining regional fisheries multi-annual management plans that take account of species and fishery interactions in establishing conservation and technical measures to achieve the targets (Lynam and Mackinson, 2015).
## (s33) Marine Non-indigenous Species
(p33.0) Non-Indigenous Species (NIS), also known as non-native or alien species, are organisms that have been moved into new areas outside their natural range by human activities e.g., shipping, recreational boating, and aquaculture. Some NIS become invasive and can exert pressures on the marine environment with possible social, economic, or environmental impacts (Copp et al., 2005). The Convention on Biological Diversity (CBD) has identified a three-tiered hierarchal approach for managing invasive species: (i) preventing the introduction of invasive species, between and within states, is generally more costeffective and environmentally desirable than measures taken following introduction and establishment of an invasive species; (ii) early detection and rapid action to prevent the establishment of invasive species; and (iii) containment and long-term control measures should be implemented, to prevent further spread of an introduced species. To achieve these goals, several international measures have been put in place and are currently being enhanced: The Regional Seas Conventions (e.g., OSPAR in relation to the UK); the EC Regulation on the use of Alien Species in Aquaculture (Council Regulation (EC) No, 708/2007); the MSFD descriptor two (Council Directive, 2008/56/EC); the WFD; the EC Regulation on Invasive Alien Species of EC Concern (Council Regulation (EU) No, 1143/2014); and the IMOs International Ballast Water Convention (e.g., Olenin et al., 2016). For all these drivers, it is key to assess the level of risk of entry (introduction), of establishment, of secondary dispersal and of impacts.
## (s36) Modeling in Current Monitoring Programmes
(p36.0) Holistic assessments of the marine environment are required to support Ecosystem Based Management, therefore integrative modeling is key to turn monitoring data into assessment products (de Jonge et al., 2006). The EU has implemented this through the MSFD (Council Directive, 2008/56/EC), which aims to maintain biodiversity and protect ecosystem function with modeling being required at each step of the assessment cycle (Lynam et al., 2016). Beyond improving our assessments of state, models are an integral part of the decision-making process, since they allow assessment of the performance of policies and potential management measures alongside quantification of the risk and uncertainty (Hyder et al., 2015a;Lynam et al., 2016). Models can also be used to assess the value of different configurations of monitoring networks, although further development is required in this area (Kupschus et al., 2016).

(p36.1) Models have the potential to provide consistent products that pull together monitoring from different sources (e.g., vessel, AUV, remote sensing) and account for uncertainty in the data. Models of the ocean and shelf seas are commonly used to develop reanalysis products, where monitoring data are assimilated into the model and used to produce consistent gridded products that are provided to the scientific community (Table S1; 28). For example, the Atlantic-European North West Shelf-Ocean Physics Reanalysis uses the Forecasting Ocean Assimilation Model 7 km Atlantic Margin Model (FOAM AMM7). Similarly, the European data-portal EMODnet provides interpolated maps derived from monitoring data (Table S1: 29).

(p36.2) To support decision making and management of the marine environment, models are commonly used for fisheries stock assessments, but multi-species modeling approaches have had much less acceptance. There are some significant challenges surrounding the uptake and use of complex models by decision makers (Hyder et al., 2015a;Lynam et al., 2016) relating to understanding of models in the following ways; production of functional outputs, quantifying uncertainty, and availability of quality standards. The availability of products and decision making timescales are often at odds with model development (Hyder et al., 2015a;Queirós et al., 2016). Communicating the outcomes and limitations of complex models to stakeholders is one of the main challenges when it comes to uptake and should be dealt with as part of the model building process (Cartwright et al., 2016).

(p36.3) Despite these challenges, there are still good examples of the integration of modeling and monitoring to develop solutions. Models have been used to provide advance-warning of algal blooms in support of the EU Bathing Waters Directive (Shutler et al., 2015), assessment of eutrophication OSPAR (Lenhart et al., 2010) and the identification of areas at high risk from the introduction of non-indigenous species . Model information has also been used to estimate the physical loss of potential habitat supporting common eelgrass, Zostera marina beds and northern horsemussel, Modiolus modiolus, reefs that are important in European waters (ICES, 2016a). The STRIKER v.4.0 model (fully described in Appendix 9.4 of the Tidal lagoon Swansea Bay Plc Environmental Statement; TLSB, 2016) models risk of injury to salmon by turbine strikes. Fisheries management within the ICES area depends greatly on stock assessment models to integrate survey data with commercial catch information (ICES, 2016b) and population modeling is used similarly to evaluate the abundance of gray seals in UK waters using count data on the production of pup at colonies (Table S1; 30). The distribution of cetaceans has been modeled from line-transect survey data to develop an indicator assessment for OSPAR (Table S1; 31). However, the pressing need is for multi-species modeling to support advice on ecosystem status for fisheries and food webs in general.

(p36.4) There is a broad marine ecosystem modeling capability within the UK and there is potential to increase the use of models to support marine environmental management (Hyder et al., 2015a). Further development of models integrating monitoring data is needed to better assess changes over time, predict future trends and develop more efficient monitoring programmes (Carstensen, 2014;Hyder et al., 2015a). Discussed further in Section Total Ecosystem Approach.
## (s37) Modeling to Understand Data Gaps
(p37.0) Within an ecosystem approach to management, monitoring programmes should be adaptive to ensure that data are collected to support those assessment areas that are most uncertain, and/or showing the strongest degradation (Shephard et al., 2015). Risk analysis is required to draw attention to activities that pose a risk to biodiversity and ecosystem function (e.g., Pinnegar et al., 2014;Katsanevakis et al., 2016). Adaptive monitoring to tackle uncertainties and risks should be cost-effective and lead to information being generated where it is most needed (de Jonge et al., 2006). Modeling can help to understand "the value of information, " "reduce uncertainty" and how best to integrate new technology appropriately in our monitoring programmes. As a result, we can build a more thorough understanding of the way we collect data and generate a quantitative weighting of any gaps that exist in the programme.
## (s39) THE FUTURE OF MONITORING Total Ecosystem Approach
(p39.0) The "total ecosystem approach" to monitoring is a coherent evidence-to-advice package, supported by a fully-integrated ecosystem monitoring programme, and potentially a way to implement many of the new approaches identified above (Borja et al., 2016;Kupschus et al., 2016). At the center of this package is a dynamic model of the ecosystem function and its responses to pressures based on process relationships. Monitoring data help to parameterize the relationships with individual states that contribute to one or more parameter estimates (Kupschus et al., 2016). Ideally, legislative assessments of ecosystem state are produced from results of this model, and future states are predicted for different sets of pressure and environmental trajectories. Such an idealized system offers several benefits and improvements over the current monitoring approach: 1) Ecosystem processes are fixed over evolutionary timescales;

(p39.1) what differs are the rates of the processes based on current conditions, and the interactions. One data point influences multiple output states, and one output state is influenced by multiple data points. The rigidity/redundancy this creates means that data collection can be more flexible. In contrast to current, status-based monitoring, which lacks the stabilizing effects, it is possible to alter or improve monitoring design and to implement modern technology as it becomes relevant. 2) Quantitative assessments of ecosystem information provide the opportunity to evaluate the efficiency of the monitoring programme and assess the efficacy of alternative monitoring options allowing for a feedback loop to data collection. Thus, data collection can be targeted specifically at the model uncertainty to increase precision of key outputs or to reduce model error through thorough hypothesis testing. 3) Modeled quantities are in absolute terms, which means they can be compared across different sampling methodologies appropriate for different regions such as catchmentcoast-marine provided that the biological components are interacting sufficiently between the sampled regions in order to support a coherent model. 4) Predictions from the model provide an internally-consistent ecological view of the system under different management actions. Such outputs provide the opportunity to evaluate the societal view of management options through socio-economic simulations. Such analysis of key risks and concerns for society can be used to weight ecosystem model uncertainties and provide an opportunity for further feedback on data collection to ensure monitoring meets societal needs.
## (s40) Integration of New Technology and Associated Challenges
(p40.0) The challenge of introducing new technologies is to ensure that (as appropriate) they are validated. Integration and validation can be a simple process, e.g., replacing and upgrading a camera system, or can require a complete reworking of equipment, sampling methodology, data analysis and finally interpretation of that data to meet policy requirements. The recent overview by Danovaro et al. (2016) demonstrates some of the ways this could be done, with specific emphasis on molecular and automated solutions. Incorporating new technology into long-running monitoring programme clearly has different implications to when doing so within a new or contemporary programme due to the interruption of well managed practices and loss of timeseries data i.e., preventing comparison between new and old data sets. Implementation of the total ecosystem model, as discussed above in Section Total Ecosystem Approach, would mitigate this challenge, allowing new sources of data to be directly integrated into a model of ecosystem health. However, where a status based monitoring approach is used then it is normal to validate new equipment by running old and new systems side-by-side until some form of comparison or calibration can be made-a time consuming and expensive endeavor, which should only be completed where long-term efficiency gains are probable. In a new monitoring programme, there is less issue with data continuity and greater potential to use innovative technology. However, this should not absolve responsibility to design and deploy a programme that will allow continuity when future changes become possible i.e., it is crucial to realize that although we are currently seeing a lot of change in automation, molecular capability, and large-scale data gathering, this is not the end of technological development. The implementation of any new objective should therefore be accompanied by a strategy for continual updating of our monitoring programme to take advantage of new technology, such as using modeling practices discussed earlier. However, translating data from models into policy-relevant information is possibly the biggest issue. This lies in understanding the true objective of what is trying to be achieved, i.e., is it the collection of data or is it, for example, to understand the function of an ecosystem. If the latter then, it should be possible to use any technology to answer the question.
