# Reinforcement Learning for Ridesharing: An Extended Survey *

CorpusID: 246017110 - [https://www.semanticscholar.org/paper/6099eeb3c4d8f8bae466e88075f83c5ee1d9c444](https://www.semanticscholar.org/paper/6099eeb3c4d8f8bae466e88075f83c5ee1d9c444)

Fields: Computer Science

## (s3) Problem Scopes
(p3.0) First, we start from the pricing module. Since the trip fare is both the price that the passenger has to pay for the trip and the major factor for the income of the driver, pricing decisions influence both demand and supply distributions through price sensitivities of users, e.g., the use of surge pricing during peak hours. This is illustrated by the solid arrows pointing from the pricing module to orders and idle vehicles respectively in Figure 1. The pricing problem in the ridesharing literature is in most cases dynamic pricing, which adjusts trip prices in real-time in view of the changing demand and supply. The pricing modules sits at the upstream position with respect to the other modules and is a macro-level lever to achieve supply-demand (SD) balance. Although technically, driver pay can be determined by a separate module from pricing and has its own implication on supply elasticity and driver behavior, this paper follows the common setting where driver pay is closely associated (approximately proportional) to the trip fare so that pricing has the dual effect on demand and supply.

(p3.1) The ridesharing matching problem (Yan et al. 2020, Özkan & Ward 2020) may appear under different names in the literature, e.g., order dispatching , trip-vehicle assignment (Bei & Zhang 2018), and on-demand taxi dispatching . It is an online bipartite matching problem where both supply and demand are dynamic, with the uncertainty coming from demand arrivals, travel times, and the entrance-exit behavior of the drivers. Matching can be done continuously in a streaming manner or at fixed review windows (i.e., batching). Sophisticated matching algorithms often leverage demand prediction in some form beyond the actual requests, e.g., the value function in RL. Online request matching is not entirely unique to ridesharing. Indeed, ridesharing matching falls into the family of more general dynamic matching problems for on-demand markets (Hu & Zhou 2022). A distinctive feature of the ridesharing problem is its spatiotemporal nature. A driver's eligibility to match and serve a trip request depends in part on her spatial proximity to the request. Trip requests generally take different amount of time to finish, and they change the spatial states of the drivers, affecting the supply distribution for future matching. The drivers and passengers generally exhibit asymmetric exit behaviors in that drivers usually stay in the system for an extended period of time, whereas passenger requests are lost after a much shorter waiting period in general.

(p3.2) Single-vehicle repositioning may refer to as taxi routing or passenger seeking in the literature. Taxi routing slightly differs in the setting from repositioning a rideshare vehicle in that a taxi typically has to be at a visual distance from the potential passenger to take the request whereas the matching radius of a mobile rideshare request is considerably longer, sometimes more than a mile. System-level vehicle repositioning, also known as driver dispatching, vehicle rebalancing/reallocation, or fleet management, aims to rebalance the global SD distributions by proactively dispatching idle vehicles to different locations. Repositioning and matching are similar to each other in that both relocate a vehicle to a different place as a consequence. In theory, one can treat repositioning as matching a vehicle to a virtual trip request, the destination of which is that of the reposition action, so that both matching and repositioning can be solved in a single problem instance. Typically in practice, these two problems are solved separately because they are separate system modules on most ridesharing platforms with different review intervals and objective metrics among other details. Figure 1: The process flow of ridesharing operations. The solid orange rectangular boxes represent the modules described in Section 2, and the literature on the optimization problems associated with the modules are reviewed in the paper. The blue text and arrow apply exclusively to ride-pooling to account for the fact that order combinations and in-service vehicles are also eligible to participate in matching.
## (s10) Online Matching
(p10.0) The rideshare matching problem and its generalized forms have been investigated extensively in the field of operations research (see e.g., (Özkan & Ward 2020, Hu & Zhou 2022, Lowalekar et al. 2018 and the references therein). Typically, both the open trip requests and available drivers are batched within time windows of fixed length as they arrive at the system, and they are matched at predefined discrete review times. See Figure 2 for an illustration. Hence, ridesharing matching is an online stochastic problem . Outside the RL literature, Lowalekar et al. (2018) approach the problem through stochastic optimization and use Bender's decomposition to solve it efficiently. To account for the temporal dependency of the decisions, Hu & Zhou (2022) formulate the problem as a stochastic DP and propose heuristic policies to compute the optimal matching decisions. For a related problem, the truckload carriers assignment problem, Simao et al. (2009) also formulate a dynamic DP but with post-decision states so that they are able to solve the problem using ADP. In each iteration, a demand path is sampled, and the value function is approximated in a linear form and updated using the dual variables from the LP solution to the resulting optimization problem.

(p10.1) The RL literature for rideshare matching (see Table 2) typically aims to optimize the total driver income and the service quality over an extended period of time. Service quality can be quantified by response rate and fulfillment rate. Response rate is the ratio of the matched requests to all trip requests. Since the probability of pre-match cancellation is primarily a function of response time (pre-match waiting time), the total response time is an alternative metric to response rate. Fulfillment rate is the ratio of completed requests to all requests and is no higher than the response rate. The gap is due to post-match cancellation, usually because of the waiting for pick-up. Hence, the average pick-up distance is also a relevant quantity to observe. Figure 3 shows the detailed flow of matching a single trip request together with the quantities discussed above.

(p10.2) In terms of the MDP formulation, driver agent is a convenient modeling choice for its straightforward definition of state, action, and reward, in contrast to system-level modeling where the action space is exponential. In this case, the rideshare platform is naturally a multi-agent system with a global objective. A common approach is to crowdsource all drivers' experience trajectories to train a single agent and apply it to all the drivers to generate their matching policies ). Since the system reward is the sum of the drivers' rewards, the system value function does decompose into the individual drivers' value functions computed by each driver's own trajectories. The approximation here is using a single value function learned from all drivers' data. See    This type of single-agent approach avoids dealing explicitly with the multi-agent aspect of the problem and the interaction among the agents during training. Besides simplicity, this strategy has the additional advantage of being able to easily handle a dynamic set of agents (and hence, a changing action space) ). On the other hand, order matching requires strong system-level coordination in that a feasible solution has to satisfy the one-to-one constraints. To address this issue, Xu et al.  2019) take a different approach treating each spatial grid cell as a worker agent and a region of a set of grid cells as a manager agent, and they adopt hierarchical RL to jointly optimize order matching and vehicle repositioning.
## (s12) Route Guidance (Navigation)
(p12.0) Routing in this paper refers to low-level navigation decisions on a road network, typically with output of matching and repositioning algorithms as input. The road network, combined with traffic conditions on the links (exhibited as link costs), forms the traffic network which is a non-stationary stochastic network (Mao & Shen 2018). It is known that standard static shortest-path algorithms do not find the path with minimum expected cost in this case, and the optimal route is not a simple route but a policy (Hall 1986, Kim et al. 2005). There are two types of set-up for the routing problem, depending on the decision review time. In the first type of set-up, each vehicle on the road network selects a route for a given OD pair from a set of feasible routes. The decision is only reviewed and revised after a trip is completed. Hence, it is called route planning or route choice. When the routes for all the vehicles are planned together, it is equivalent to assigning the vehicles to each link in the network, and hence, the problem is called traffic assignment problem (TAP), which is typically for transportation planning purposes. In the second type of set-up, the routing decision is made at each intersection to select the next outbound road (link) to enter. These are real-time    adaptive navigation decisions for vehicles to react to the changing traffic state of the road network.
## (s13) Ride-pooling (Carpool)
(p13.0) Ride-pooling optimization typically concerns with matching, repositioning, routing (see e.g.,   Tong et al. 2018)). The RL literature has primarily focused on the first two problems. The ride-pooling matching problem differs from that in Section 4.2 in that a combination of multiple passengers, and hence their combined trip, can be matched to a vehicle that may or may not be empty. See stages B and C in Figure 6 from (Alonso-Mora, Samaranayake, Wallar, Frazzoli & Rus 2017) for an illustration. The repositioning problem is similar to the ride-hailing case, except that the objective is to optimize some pooling-specific metrics that we define next. The routing problem solves for the sequence of pick-ups and drop-offs given the assigned passengers for a vehicle. The routing problem could also concern with route guidance on the road network. See stage D in Figure 6.

(p13.1) Many works have multiple objectives and define the reward as a weighted combination of several quantities, with hand-tuned weight parameters. Passenger wait time is the duration between the request time and the pick-up time. Detour delay is the extra time a passenger spends on the vehicle due to the participation in the ride-pooling. In some cases, these two quantities define the feasibility of a potential pooled trip instead of appearing in the reward (Shah et al. 2020). Effective trip distance is the travel distance between the origin and destination of a trip request, should it be fulfilled without ride-pooling. Yu & Shen (2019) consider minimizing passenger wait time, detour delay, and lost demand. Guériau & Dusparic (2018) maximize the number of passengers served. Jindal et al. (2018) maximize the total effective trip distance within an episode, which is just the number of served requests weighted by individual trip distance. Considering a fixed number of requests within an episode (hence fixed maximum effective distance), this metric reflects the efficiency of ride-pooling.   The state of an agent usually consists of global SD information, similar to that for matching and reposition, but the vehicle status contains key additional information of occupancy and OD's of the passengers on board.
## (s18) Joint Optimization
(p18.0) The rideshare platform is an integrated system, so joint optimization of multiple decision modules leads to better solutions that otherwise unable to realize under separate optimizations, ensuring that different decisions work towards the same goal. RL for joint optimization across multiple modules calls for research on reward function design, state-action representation that facilitates intermodule communication, and the training algorithms. Models and algorithms that allow decentralized execution by the different modules are highly preferred in practice. We have already seen development on RL for joint matching-reposition (Holler et al. 2019) and with ride-pooling (Guériau & Dusparic 2018), pricing-matching (Chen, Jiao, Qin, Tang, Li, An, Zhu & Ye 2019), and pricing-reposition (Turan et al. 2020). An RL-based method for fully joint optimization of all major modules is highly expected. Meanwhile, this also requires readiness from the rideshare platforms in terms of system architecture and organizational structure.
## (s19) Heterogeneous Fleet
(p19.0) With the wide adoption of electric vehicles and the emergence of autonomous vehicles, we are facing an increasingly heterogeneous fleet on rideshare platforms. Electric vehicles have limited operational range per their battery capacities. They have to be routed to a charging station when the battery level is low (but sufficiently high to be able to travel to the station). Autonomous vehicles may run within a predefined service geo-fence due to their limited ability (compared to human drivers) to handle complex road situations. For an RL-based approach, a heterogeneous fleet means multiple types of agents with different state and action spaces. The adoption of autonomous vehicles also opens new operational paradigms. Dynamic fleet size inflation (Beirigo et al. 2022), for example, hires idle autonomous vehicles on demand to guarantee service quality contracts in a ridesharing marketplace. Specific studies are required to investigate how to make such a heterogeneous fleet cooperate well to complement each other and maximize the advantage of each type of vehicles to improve overall system efficiency.
## (s22) Non-stationarity
(p22.0) We have seen in Sections 4.2 and 4.3 that RL algorithms deployed to real-world systems generally adopt offline training -once the value function or the policy is deployed, it is not updated until the next deployment. Value functions trained offline using a large amount of historical data are only able to capture recurring patterns resulted from day-on-day SD changes. However, the SD dynamics can be highly non-stationary in that one-time abrupt changes can easily occur due to various events and incidents, e.g., concerts, matches, and even road blocks by traffic accidents. To fully unleash the power of RL, practical mechanisms for real-time on-policy updates of the value function (e.g., , Eshkevari et al. 2022) is required. In view of the low risk tolerance of production systems in general, sample complexity, computational complexity, and robustness are the key challenges that such methods have to address.
## (s24) General RL
(p24.0) RL provides the necessary tools for the methods reviewed in this survey. Hence, the problems of RL for ridesharing tie closely to the development in RL in general. In the context of ridesharing, we have seen from the literature review above that it is difficult for RL to learn combinatorial actions, e.g., the system matching actions. In the era of deep RL, model interpretability is a long-standing challenge, which hampers investigation of customer experience corner cases. For experience-critical service like ridesharing, policy exploration adds further complication, especially for real-world deployment. In view of these challenges, the future is probably that RL-based and traditional optimization approaches will be complementing each other for a long time. We have seen such combinations in the current literature as  for matching, (Chaudhari et al. 2020a, Jiao et al. 2021 for repositioning, and (Delarue et al. 2020) for VRP, that combine RL with combinatorial optimization, mixed-integer programming, and tree search. The breakthroughs of RL that we are seeing in other domains and the continued development of RL methodology for ridesharing certainly make it exciting to anticipate the future landscape.
