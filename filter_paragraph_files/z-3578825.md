# A review of human sensory dynamics for application to models of driver steering and speed control

CorpusID: 3578825 - [https://www.semanticscholar.org/paper/954c95c6af0a9ab215755667c7f9f0c424b1cb98](https://www.semanticscholar.org/paper/954c95c6af0a9ab215755667c7f9f0c424b1cb98)

Fields: Engineering, Psychology, Computer Science, Medicine

## (s6) Vestibular system
(p6.0) There is some disagreement in the literature as to the relative importance of the vestibular system in nonvisual motion perception. Studies measuring thresholds of human motion perception in the dark often assume that the influence of the vestibular system is much larger than that of the somatosensors (Benson et al. 1986(Benson et al. , 1989Grabherr et al. 2008;Soyka et al. 2012Soyka et al. , 2009Soyka et al. , 2011Kingma 2005). However, Gianna et al. (1996) found that perception thresholds for subjects with vestibular deficiencies were not significantly higher than for normal subjects, and Bronstein and Hood (1986) found that neck proprioception largely replaced vestibular function in vestibular deficient subjects for head rotations relative to the body. In contrast, Mallery et al. (2010) found that a subject with vestibular deficiencies had rotational velocity thresholds an order of magnitude higher than those of normal subjects and Valko et al. (2012) found that vestibular deficient subjects had significantly higher perception thresholds in four different motion axes. The relative importance of the vestibular and somatosensory systems may depend on the precise nature of the stimuli; however, it does appear that the vestibular system is an important source of information for drivers.

(p6.1) The vestibular system consists of two sets of organs located in the inner ear: the semicircular canals (SCCs) which sense rotational motion and the otoliths which sense translational motion (Kandel et al. 2000). Many studies have investigated the function of the vestibular system in primates and humans, either directly by measuring electrical signals in the brain or indirectly by measuring the vestibulo-ocular reflex (VOR), a reflexive eye movement which uses vestibular information to compensate for head movements.

(p6.2) There is some disagreement in the literature as to the relative importance of the vestibular system in nonvisual motion perception. Studies measuring thresholds of human motion perception in the dark often assume that the influence of the vestibular system is much larger than that of the somatosensors (Benson et al. 1986(Benson et al. , 1989Grabherr et al. 2008;Soyka et al. 2012Soyka et al. , 2009Soyka et al. , 2011Kingma 2005). However, Gianna et al. (1996) found that perception thresholds for subjects with vestibular deficiencies were not significantly higher than for normal subjects, and Bronstein and Hood (1986) found that neck proprioception largely replaced vestibular function in vestibular deficient subjects for head rotations relative to the body. In contrast, Mallery et al. (2010) found that a subject with vestibular deficiencies had rotational velocity thresholds an order of magnitude higher than those of normal subjects and Valko et al. (2012) found that vestibular deficient subjects had significantly higher perception thresholds in four different motion axes. The relative importance of the vestibular and somatosensory systems may depend on the precise nature of the stimuli; however, it does appear that the vestibular system is an important source of information for drivers.

(p6.3) The vestibular system consists of two sets of organs located in the inner ear: the semicircular canals (SCCs) which sense rotational motion and the otoliths which sense translational motion (Kandel et al. 2000). Many studies have investigated the function of the vestibular system in primates and humans, either directly by measuring electrical signals in the brain or indirectly by measuring the vestibulo-ocular reflex (VOR), a reflexive eye movement which uses vestibular information to compensate for head movements.
## (s7) Otoliths
(p7.0) The otoliths are formed from small granular particles contained in a gelatinous membrane which is in turn connected to sensory cells via hairs called cilia. When subjected to translational acceleration, the inertia forces on the otoliths deflect the cilia and excite the sensory cells (Kandel et al. 2000). Most mathematical models are based on empirical data from experiments carried out on humans and animals.

(p7.1) It is a natural extension of Einstein's equivalence principal (Einstein 1907) that humans cannot tell the difference between a translational acceleration and a change in orientation of the gravity vector. Young and Meiry (1968) developed a model for the otoliths relating the perceived specific force (combination of inertial and gravitational accelerations) to the actual specific force. They proposed the transfer function:
## (s11) Somatosensors
(p11.0) During driving, the information provided by the visual and vestibular systems is complemented by the response of various receptors of the somatosensory system (Kandel et al. 2000). A particular group of receptors provide proprioception, which is the sensing of joint angles and movements and muscle displacements and forces. These receptors are particularly important in allowing the driver to sense the angle and torque of the steering wheel, which can be used by experienced drivers to sense the characteristics of the contact between the tyre and the road. Proprioceptors are also used to sense the displacements and forces of the foot pedals. The following subsections discuss the properties of the muscle spindles, which measure muscle displacement, and the Golgi tendon organs, which measure muscle force. Other somatosensors which may play a role are skin receptors and joint receptors which give information on touch and joint angle (Collins et al. 2005;Proske and Gandevia 2009), and graviceptors which respond to the motion of fluid within the body (Vaitl et al. 2002). While these somatosensors may give the driver useful information, such as the contact forces between the body and the seat, the nature of these stimuli means they are difficult to measure and quantify, and as such the existing literature does not lend itself to application within driver models.

(p11.1) During driving, the information provided by the visual and vestibular systems is complemented by the response of various receptors of the somatosensory system (Kandel et al. 2000). A particular group of receptors provide proprioception, which is the sensing of joint angles and movements and muscle displacements and forces. These receptors are particularly important in allowing the driver to sense the angle and torque of the steering wheel, which can be used by experienced drivers to sense the characteristics of the contact between the tyre and the road. Proprioceptors are also used to sense the displacements and forces of the foot pedals. The following subsections discuss the properties of the muscle spindles, which measure muscle displacement, and the Golgi tendon organs, which measure muscle force. Other somatosensors which may play a role are skin receptors and joint receptors which give information on touch and joint angle (Collins et al. 2005;Proske and Gandevia 2009), and graviceptors which respond to the motion of fluid within the body (Vaitl et al. 2002). While these somatosensors may give the driver useful information, such as the contact forces between the body and the seat, the nature of these stimuli means they are difficult to measure and quantify, and as such the existing literature does not lend itself to application within driver models.
## (s12) Muscle spindles
(p12.0) Muscle spindles are sensors which detect the length and rate of change of length of the muscles. They produce two separate signals, one dependent on muscle velocity and length (type Ia afferent) and one dependent on muscle length only (type II afferent) (Kandel et al. 2000). An empirical linear model of the muscle spindle response, based on measurements taken in cats, was formulated by Poppele and Bowman (1970), with the Ia and II afferent responses to muscle displacements given by:
## (s13) Golgi tendon organs
(p13.0) Golgi tendon organs (GTOs) respond to the forces in the muscles. They share a nerve with the Ia afferent response of the muscle spindles, giving a response known as a type Ib afferent (Kandel et al. 2000). A linear model of the GTOs was first proposed by Houck and Simon (1967), again based on measurements in cats. Their model was stated as a transfer function between muscle force and Ib afferent response by Prochazka (1999):
## (s14) Time delays
(p14.0) As shown in Fig. 3, there are various ways in which delays are introduced between sensory stimuli being applied to a driver and the driver's control response being measured. Delay sources include receptor dynamics, nerve conduction, neural processing and neuromuscular dynamics. Various techniques have been used in the literature to measure delays in human response to sensory stimulation. The simplest of these is to apply a stimulus and measure the time taken for a physical response (such as pressing a button) to be recorded. Some studies have used more sophisticated methods of applying stimuli, such as galvanic vestibular stimulation (GVS) which bypasses the vestibular organs by applying an electrical stimulus directly to the nerves (Fitzpatrick and Day 2004). Other methods have been used to detect responses at other points in the process, such as measuring the VOR to identify the reflexive delay, using magnetoencephalography (MEG, Hämäläinen et al. 1993) or electroencephalography (EEG) to measure electrical impulses within the brain or using electromyography (EMG) to record electrical activity in the muscles. When interpreting sensory time delays measured in different studies using different techniques, it is important to consider which of the delay components shown in Fig. 3 are included in the measurement in each case. The aim of this section is to use results from the literature to estimate the total delay between stimulus and response for each sensory system. However, it can be difficult to separate the effects of pure time delays from lags due to the dynamics of the sensors and muscles and the time taken for signals to rise above noise levels . Nevertheless, results from the literature can be used to find an approximate estimate of the order of magnitude of time delays in human sensory systems.

(p14.1) EMG has been used to measure the response of the muscle spindles to applied muscle stretches, finding delays of 25-30 ms for the Ia afferent and 40 ms for the II afferent (Matthews 1984). Bigler (2013) combined these with measured nerve conduction delays (Trojaborg and Sindrup 1969;Kandel et al. 2000) to give delays of 34 ms and 48 ms for the Ia and II afferents. As the Ib afferent response of the GTOs shares the same nerve as the Ia muscle spindle response, the time delay for the Ib afferent may be the same as the Ia muscle spindle response. However, these values do not include any neural processing time, so the actual sensor delays are likely to be larger.

(p14.2) Reaction times for drivers' responses to simulated wind gusts have been measured in a driving simulator (Wierwille et al. 1983). Mean delays of 0.56 s without motion feedback and 0.44 s with motion feedback were found. These measurements encompass the complete process between stimulus application and physical response shown in Fig. 3, including all delays, lags and noise. Therefore, they can be considered as upper bounds for the delays in the visual system and combined visual-vestibular systems during driving. MEG has been used to record neural responses to visual stimuli and delays of 140-190 ms have been found (Kawakami et al. 2002;Lam et al. 2000), although it is unclear how much neural processing is carried out before and after this response is measured. Vestibular reflex delays have been measured by actively stimulating vestibular nerves using GVS and measuring the latency to the onset of the VOR (Aw et al. 2006;Tabak et al. 1997). Delays of 5-9 ms have been found, showing that the conduction of vestibular reflex signals is very fast.

(p14.3) There is a growing body of evidence, reviewed by Barnett-Cowan (2013) that despite the very fast conduction of vestibular reflex signals, vestibular processing can take much longer than the processing of other sensory signals. Vestibular delays have been found to be significantly longer than visual delays when measuring brain responses using EEG (Barnett-Cowan et al. 2010) and when measuring overall reaction times (Barnett-Cowan and Harris 2009). Barnett-Cowan et al. (2010) measured impulses in the brain 100 ms and 200 ms after visual and vestibular stimuli, respectively, with a further 135 ms until a button was pressed in both cases. This gives visual and vestibular delays of 235 ms and 335 ms; however, Barnett-Cowan (2013) suggested that these delays may include the time taken for the stimuli to rise above threshold levels (as modelled by Soyka et al. 2013) so they may be overestimates.
## (s16) Threshold models
(p16.0) The simplest model of sensory thresholds is a 'dead zone' where the perceived amplitude is zero. There are two possible methods for modelling this, as shown in Fig. 8. Method 2 is the most applicable of these, as method 1 implies that the perceived amplitude would be smaller than the actual amplitude, even above the perception threshold. The dead zone model is useful for simplicity; however, it assumes that the psychometric function is a step function, and it cannot be used directly to model JNDs.

(p16.1) Recent studies have suggested that sensory thresholds arise primarily as a result of noise in the sensory channels and the brain. Soyka et al. (2011Soyka et al. ( , 2012 Fig. 9 Sensor model incorporating additive and signal dependent noise (Bigler 2013). Noise is added after the sensor transfer function to represent spontaneous neuron firing in the brain. This is similar to the model of Soyka et al. (2011Soyka et al. ( , 2012, who modelled thresholds using a constant noise addition after the sensory transfer function based on additive noise (AN) applied to the outputs of the otolith and SCC transfer functions. The perception thresholds were found as the minimum stimulus amplitude required for the output to exceed the noise level. Both studies found good fits to experimental results, although the transfer functions had to be adjusted slightly from those found in the literature (see Sect. 2). This model predicts the frequency dependence of perception thresholds and is valid for arbitrary motion inputs rather than solely sinusoidal motion. A similar principle was used by Bigler (2013) to model JNDs as well as perception thresholds, by adding signal-dependent noise (SDN) as well as AN to the output of the sensor transfer function (Todorov 2005). This sensor model is shown in Fig. 9.

(p16.2) The simplest model of sensory thresholds is a 'dead zone' where the perceived amplitude is zero. There are two possible methods for modelling this, as shown in Fig. 8. Method 2 is the most applicable of these, as method 1 implies that the perceived amplitude would be smaller than the actual amplitude, even above the perception threshold. The dead zone model is useful for simplicity; however, it assumes that the psychometric function is a step function, and it cannot be used directly to model JNDs.

(p16.3) Recent studies have suggested that sensory thresholds arise primarily as a result of noise in the sensory channels and the brain. Soyka et al. (2011Soyka et al. ( , 2012 Fig. 9 Sensor model incorporating additive and signal dependent noise (Bigler 2013). Noise is added after the sensor transfer function to represent spontaneous neuron firing in the brain. This is similar to the model of Soyka et al. (2011Soyka et al. ( , 2012, who modelled thresholds using a constant noise addition after the sensory transfer function based on additive noise (AN) applied to the outputs of the otolith and SCC transfer functions. The perception thresholds were found as the minimum stimulus amplitude required for the output to exceed the noise level. Both studies found good fits to experimental results, although the transfer functions had to be adjusted slightly from those found in the literature (see Sect. 2). This model predicts the frequency dependence of perception thresholds and is valid for arbitrary motion inputs rather than solely sinusoidal motion. A similar principle was used by Bigler (2013) to model JNDs as well as perception thresholds, by adding signal-dependent noise (SDN) as well as AN to the output of the sensor transfer function (Todorov 2005). This sensor model is shown in Fig. 9.
## (s18) Visual thresholds
(p18.0) Various studies have measured perception thresholds and JNDs for the visual perception of self-motion. A difficulty in interpreting these results with any certainty is that they may well be dependent on the characteristics of the visual scene, such as the relative motion of stationary reference objects in the visual field, so it is not clear how generally applicable the results are. However, it may still be possible to find some useful information about the performance limits of the visual system. A driving simulator display was used by Bigler (2013) to measure yaw angle and lateral displacement thresholds. The display was not calibrated to give full-scale visual feedback so the absolute values of the measured thresholds may not be at the correct scale; however, the frequency response should not depend on the display scaling. The results are shown in Fig. 10. The visual transfer function given in Eq. 1 was used with the model of Soyka et al. (2011Soyka et al. ( , 2012 to give predicted thresholds, shown by the solid lines in Fig. 10. The model fits the thresholds very well, which is not surprising considering that the visual transfer function was found by fitting parameters to these results. The additive noise levels found are 0.0011 rad/s* for the yaw angular velocity and 0.032 m/s* for the lateral velocity.

(p18.1) A fit to the data was also found for a simple model of the visual system dynamics, with unity transfer functions between actual and perceived yaw and sway velocities. The fit using this model is shown by the dotted lines in Fig. 10, and the noise values found were 0.0013 rad/s* for the yaw angular velocity and 0.035 m/s* for the sway velocity. Visual JNDs have been measured for a range of yaw velocities, and Weber fractions of 7 % (de Bruyn and Orban 1988), 10 % A few studies have investigated the limits of visual perception of motion in the longitudinal direction. Reinterpretation of the data collected by Bremmer and Lappe (1999) gives a JND in displacement in the longitudinal direction of 450 mm, with a reference displacement of 4 m. This gives a Weber fraction of 10 %; however, extrapolating from measurements taken for this relatively short displacement of 4 m may be inaccurate. Monen and Brenner (1994) determined the smallest step increase in forward velocity necessary for the difference to be perceived within half a second and found a large Weber fraction of around 50 %.

(p18.2) Thresholds of visual perception involved in feedforward control have not been measured explicitly. Authié and Mestre (2012) measured JNDs in path curvature, finding a Weber fraction of approximately 11 %. Bigler (2013) used the results of Legge and Campbell (1981), who found the angular resolution of the retina to be around 1.5 arc min, to calculate additive and multiplicative noise variances for visual perception of road path geometry ahead of the vehicle. However, these results were found by asking subjects to indicate when they could detect a change in position of a small dot, which is likely to be significantly easier than picking out the full road geometry from a complicated visual scene.

(p18.3) Various studies have measured perception thresholds and JNDs for the visual perception of self-motion. A difficulty in interpreting these results with any certainty is that they may well be dependent on the characteristics of the visual scene, such as the relative motion of stationary reference objects in the visual field, so it is not clear how generally applicable the results are. However, it may still be possible to find some useful information about the performance limits of the visual system. A driving simulator display was used by Bigler (2013) to measure yaw angle and lateral displacement thresholds. The display was not calibrated to give full-scale visual feedback so the absolute values of the measured thresholds may not be at the correct scale; however, the frequency response should not depend on the display scaling. The results are shown in Fig. 10. The visual transfer function given in Eq. 1 was used with the model of Soyka et al. (2011Soyka et al. ( , 2012 to give predicted thresholds, shown by the solid lines in Fig. 10. The model fits the thresholds very well, which is not surprising considering that the visual transfer function was found by fitting parameters to these results. The additive noise levels found are 0.0011 rad/s* for the yaw angular velocity and 0.032 m/s* for the lateral velocity.

(p18.4) A fit to the data was also found for a simple model of the visual system dynamics, with unity transfer functions between actual and perceived yaw and sway velocities. The fit using this model is shown by the dotted lines in Fig. 10, and the noise values found were 0.0013 rad/s* for the yaw angular velocity and 0.035 m/s* for the sway velocity. Visual JNDs have been measured for a range of yaw velocities, and Weber fractions of 7 % (de Bruyn and Orban 1988), 10 % A few studies have investigated the limits of visual perception of motion in the longitudinal direction. Reinterpretation of the data collected by Bremmer and Lappe (1999) gives a JND in displacement in the longitudinal direction of 450 mm, with a reference displacement of 4 m. This gives a Weber fraction of 10 %; however, extrapolating from measurements taken for this relatively short displacement of 4 m may be inaccurate. Monen and Brenner (1994) determined the smallest step increase in forward velocity necessary for the difference to be perceived within half a second and found a large Weber fraction of around 50 %.

(p18.5) Thresholds of visual perception involved in feedforward control have not been measured explicitly. Authié and Mestre (2012) measured JNDs in path curvature, finding a Weber fraction of approximately 11 %. Bigler (2013) used the results of Legge and Campbell (1981), who found the angular resolution of the retina to be around 1.5 arc min, to calculate additive and multiplicative noise variances for visual perception of road path geometry ahead of the vehicle. However, these results were found by asking subjects to indicate when they could detect a change in position of a small dot, which is likely to be significantly easier than picking out the full road geometry from a complicated visual scene.
## (s19) Otolith thresholds
(p19.0) Perception thresholds have been measured extensively for translational accelerations in the horizontal plane. Measurements have been carried out in the longitudinal (X) and lateral (Y) directions, and the thresholds have been seen to be simi-lar in both directions (Benson et al. 1986); therefore, they are considered together. Thresholds have also been measured in the vertical (Z) direction (Nesti et al. 2014a); however, this is not so relevant for the car driver's control task.
## (s24) Coherence zones
(p24.0) The term 'coherence zone' was coined by van der Steen (1998) to describe the range of amplitudes of inputs to two sensory systems (such as visual and vestibular systems) which are perceived as consistent with each other, as shown in Fig. 14 Fig. 14 Coherence zone between visual and vestibular stimuli. For a given visual stimulus, there will be an upper and lower limit of vestibular stimulus amplitude which is perceived as coherent with the visual stimulus. The coherence zone width (CZW) is the difference between these two limits, and the point of mean coherence (PMC) is defined as the point halfway between the limits. The gain of mean coherence (GMC) is defined as the ratio of the vestibular amplitude to the visual amplitude at the PMC and represents the preferred gain between the visual and vestibular cues the point of mean coherence (PMC), coherence zone width (CZW) and gain of mean coherence (GMC) as shown.
## (s25) Sensory integration
(p25.0) The sensory systems described in Sect. 2 provide the central nervous system (CNS) with measurements (or sensory 'cues') which can be used to estimate vehicle states while driving. However, these measurements are shaped by the sensor dynamics and also contain additive and signal-dependent noise (as described in Sect. 4). The CNS must therefore carry out sensory integration to give a single estimate of the vehicle states from the noisy, filtered information received from each of the sensors.

(p25.1) In a real-world driving scenario, the driver will be presented with coherent sensory information. Any discrepancies between information from the different sensors are due to sensory noise, or incomplete information available to a particular sensor. However, in some situations the information presented to the different senses may be incoherent or biased, in which case the driver may use a different integration strategy. This is particularly relevant for motion in virtual environments, where the visual, vestibular and somatosensory information presented to the driver may not all accurately reflect the real-world stimuli. An overview of methods and results from investigations of sensory integration in a variety of virtual environments (not specific to driving) is given by Campos and Bülthoff (2012). The following subsections build on this, focusing in more depth on results which suggest how information from the sensory systems summarised in Sect. 2 may be integrated during driving.

(p25.2) The sensory systems described in Sect. 2 provide the central nervous system (CNS) with measurements (or sensory 'cues') which can be used to estimate vehicle states while driving. However, these measurements are shaped by the sensor dynamics and also contain additive and signal-dependent noise (as described in Sect. 4). The CNS must therefore carry out sensory integration to give a single estimate of the vehicle states from the noisy, filtered information received from each of the sensors.

(p25.3) In a real-world driving scenario, the driver will be presented with coherent sensory information. Any discrepancies between information from the different sensors are due to sensory noise, or incomplete information available to a particular sensor. However, in some situations the information presented to the different senses may be incoherent or biased, in which case the driver may use a different integration strategy. This is particularly relevant for motion in virtual environments, where the visual, vestibular and somatosensory information presented to the driver may not all accurately reflect the real-world stimuli. An overview of methods and results from investigations of sensory integration in a variety of virtual environments (not specific to driving) is given by Campos and Bülthoff (2012). The following subsections build on this, focusing in more depth on results which suggest how information from the sensory systems summarised in Sect. 2 may be integrated during driving.
## (s43) Vestibular system
(p43.0) There is some disagreement in the literature as to the relative importance of the vestibular system in nonvisual motion perception. Studies measuring thresholds of human motion perception in the dark often assume that the influence of the vestibular system is much larger than that of the somatosensors (Benson et al. 1986(Benson et al. , 1989Grabherr et al. 2008;Soyka et al. 2012Soyka et al. , 2009Soyka et al. , 2011Kingma 2005). However, Gianna et al. (1996) found that perception thresholds for subjects with vestibular deficiencies were not significantly higher than for normal subjects, and Bronstein and Hood (1986) found that neck proprioception largely replaced vestibular function in vestibular deficient subjects for head rotations relative to the body. In contrast, Mallery et al. (2010) found that a subject with vestibular deficiencies had rotational velocity thresholds an order of magnitude higher than those of normal subjects and Valko et al. (2012) found that vestibular deficient subjects had significantly higher perception thresholds in four different motion axes. The relative importance of the vestibular and somatosensory systems may depend on the precise nature of the stimuli; however, it does appear that the vestibular system is an important source of information for drivers.

(p43.1) The vestibular system consists of two sets of organs located in the inner ear: the semicircular canals (SCCs) which sense rotational motion and the otoliths which sense translational motion (Kandel et al. 2000). Many studies have investigated the function of the vestibular system in primates and humans, either directly by measuring electrical signals in the brain or indirectly by measuring the vestibulo-ocular reflex (VOR), a reflexive eye movement which uses vestibular information to compensate for head movements.

(p43.2) There is some disagreement in the literature as to the relative importance of the vestibular system in nonvisual motion perception. Studies measuring thresholds of human motion perception in the dark often assume that the influence of the vestibular system is much larger than that of the somatosensors (Benson et al. 1986(Benson et al. , 1989Grabherr et al. 2008;Soyka et al. 2012Soyka et al. , 2009Soyka et al. , 2011Kingma 2005). However, Gianna et al. (1996) found that perception thresholds for subjects with vestibular deficiencies were not significantly higher than for normal subjects, and Bronstein and Hood (1986) found that neck proprioception largely replaced vestibular function in vestibular deficient subjects for head rotations relative to the body. In contrast, Mallery et al. (2010) found that a subject with vestibular deficiencies had rotational velocity thresholds an order of magnitude higher than those of normal subjects and Valko et al. (2012) found that vestibular deficient subjects had significantly higher perception thresholds in four different motion axes. The relative importance of the vestibular and somatosensory systems may depend on the precise nature of the stimuli; however, it does appear that the vestibular system is an important source of information for drivers.

(p43.3) The vestibular system consists of two sets of organs located in the inner ear: the semicircular canals (SCCs) which sense rotational motion and the otoliths which sense translational motion (Kandel et al. 2000). Many studies have investigated the function of the vestibular system in primates and humans, either directly by measuring electrical signals in the brain or indirectly by measuring the vestibulo-ocular reflex (VOR), a reflexive eye movement which uses vestibular information to compensate for head movements.
## (s44) Otoliths
(p44.0) The otoliths are formed from small granular particles contained in a gelatinous membrane which is in turn connected to sensory cells via hairs called cilia. When subjected to translational acceleration, the inertia forces on the otoliths deflect the cilia and excite the sensory cells (Kandel et al. 2000). Most mathematical models are based on empirical data from experiments carried out on humans and animals.

(p44.1) It is a natural extension of Einstein's equivalence principal (Einstein 1907) that humans cannot tell the difference between a translational acceleration and a change in orientation of the gravity vector. Young and Meiry (1968) developed a model for the otoliths relating the perceived specific force (combination of inertial and gravitational accelerations) to the actual specific force. They proposed the transfer function:
## (s48) Somatosensors
(p48.0) During driving, the information provided by the visual and vestibular systems is complemented by the response of various receptors of the somatosensory system (Kandel et al. 2000). A particular group of receptors provide proprioception, which is the sensing of joint angles and movements and muscle displacements and forces. These receptors are particularly important in allowing the driver to sense the angle and torque of the steering wheel, which can be used by experienced drivers to sense the characteristics of the contact between the tyre and the road. Proprioceptors are also used to sense the displacements and forces of the foot pedals. The following subsections discuss the properties of the muscle spindles, which measure muscle displacement, and the Golgi tendon organs, which measure muscle force. Other somatosensors which may play a role are skin receptors and joint receptors which give information on touch and joint angle (Collins et al. 2005;Proske and Gandevia 2009), and graviceptors which respond to the motion of fluid within the body (Vaitl et al. 2002). While these somatosensors may give the driver useful information, such as the contact forces between the body and the seat, the nature of these stimuli means they are difficult to measure and quantify, and as such the existing literature does not lend itself to application within driver models.

(p48.1) During driving, the information provided by the visual and vestibular systems is complemented by the response of various receptors of the somatosensory system (Kandel et al. 2000). A particular group of receptors provide proprioception, which is the sensing of joint angles and movements and muscle displacements and forces. These receptors are particularly important in allowing the driver to sense the angle and torque of the steering wheel, which can be used by experienced drivers to sense the characteristics of the contact between the tyre and the road. Proprioceptors are also used to sense the displacements and forces of the foot pedals. The following subsections discuss the properties of the muscle spindles, which measure muscle displacement, and the Golgi tendon organs, which measure muscle force. Other somatosensors which may play a role are skin receptors and joint receptors which give information on touch and joint angle (Collins et al. 2005;Proske and Gandevia 2009), and graviceptors which respond to the motion of fluid within the body (Vaitl et al. 2002). While these somatosensors may give the driver useful information, such as the contact forces between the body and the seat, the nature of these stimuli means they are difficult to measure and quantify, and as such the existing literature does not lend itself to application within driver models.
## (s49) Muscle spindles
(p49.0) Muscle spindles are sensors which detect the length and rate of change of length of the muscles. They produce two separate signals, one dependent on muscle velocity and length (type Ia afferent) and one dependent on muscle length only (type II afferent) (Kandel et al. 2000). An empirical linear model of the muscle spindle response, based on measurements taken in cats, was formulated by Poppele and Bowman (1970), with the Ia and II afferent responses to muscle displacements given by:
## (s50) Golgi tendon organs
(p50.0) Golgi tendon organs (GTOs) respond to the forces in the muscles. They share a nerve with the Ia afferent response of the muscle spindles, giving a response known as a type Ib afferent (Kandel et al. 2000). A linear model of the GTOs was first proposed by Houck and Simon (1967), again based on measurements in cats. Their model was stated as a transfer function between muscle force and Ib afferent response by Prochazka (1999):
## (s51) Time delays
(p51.0) As shown in Fig. 3, there are various ways in which delays are introduced between sensory stimuli being applied to a driver and the driver's control response being measured. Delay sources include receptor dynamics, nerve conduction, neural processing and neuromuscular dynamics. Various techniques have been used in the literature to measure delays in human response to sensory stimulation. The simplest of these is to apply a stimulus and measure the time taken for a physical response (such as pressing a button) to be recorded. Some studies have used more sophisticated methods of applying stimuli, such as galvanic vestibular stimulation (GVS) which bypasses the vestibular organs by applying an electrical stimulus directly to the nerves (Fitzpatrick and Day 2004). Other methods have been used to detect responses at other points in the process, such as measuring the VOR to identify the reflexive delay, using magnetoencephalography (MEG, Hämäläinen et al. 1993) or electroencephalography (EEG) to measure electrical impulses within the brain or using electromyography (EMG) to record electrical activity in the muscles. When interpreting sensory time delays measured in different studies using different techniques, it is important to consider which of the delay components shown in Fig. 3 are included in the measurement in each case. The aim of this section is to use results from the literature to estimate the total delay between stimulus and response for each sensory system. However, it can be difficult to separate the effects of pure time delays from lags due to the dynamics of the sensors and muscles and the time taken for signals to rise above noise levels . Nevertheless, results from the literature can be used to find an approximate estimate of the order of magnitude of time delays in human sensory systems.

(p51.1) EMG has been used to measure the response of the muscle spindles to applied muscle stretches, finding delays of 25-30 ms for the Ia afferent and 40 ms for the II afferent (Matthews 1984). Bigler (2013) combined these with measured nerve conduction delays (Trojaborg and Sindrup 1969;Kandel et al. 2000) to give delays of 34 ms and 48 ms for the Ia and II afferents. As the Ib afferent response of the GTOs shares the same nerve as the Ia muscle spindle response, the time delay for the Ib afferent may be the same as the Ia muscle spindle response. However, these values do not include any neural processing time, so the actual sensor delays are likely to be larger.

(p51.2) Reaction times for drivers' responses to simulated wind gusts have been measured in a driving simulator (Wierwille et al. 1983). Mean delays of 0.56 s without motion feedback and 0.44 s with motion feedback were found. These measurements encompass the complete process between stimulus application and physical response shown in Fig. 3, including all delays, lags and noise. Therefore, they can be considered as upper bounds for the delays in the visual system and combined visual-vestibular systems during driving. MEG has been used to record neural responses to visual stimuli and delays of 140-190 ms have been found (Kawakami et al. 2002;Lam et al. 2000), although it is unclear how much neural processing is carried out before and after this response is measured. Vestibular reflex delays have been measured by actively stimulating vestibular nerves using GVS and measuring the latency to the onset of the VOR (Aw et al. 2006;Tabak et al. 1997). Delays of 5-9 ms have been found, showing that the conduction of vestibular reflex signals is very fast.

(p51.3) There is a growing body of evidence, reviewed by Barnett-Cowan (2013) that despite the very fast conduction of vestibular reflex signals, vestibular processing can take much longer than the processing of other sensory signals. Vestibular delays have been found to be significantly longer than visual delays when measuring brain responses using EEG (Barnett-Cowan et al. 2010) and when measuring overall reaction times (Barnett-Cowan and Harris 2009). Barnett-Cowan et al. (2010) measured impulses in the brain 100 ms and 200 ms after visual and vestibular stimuli, respectively, with a further 135 ms until a button was pressed in both cases. This gives visual and vestibular delays of 235 ms and 335 ms; however, Barnett-Cowan (2013) suggested that these delays may include the time taken for the stimuli to rise above threshold levels (as modelled by Soyka et al. 2013) so they may be overestimates.
## (s53) Threshold models
(p53.0) The simplest model of sensory thresholds is a 'dead zone' where the perceived amplitude is zero. There are two possible methods for modelling this, as shown in Fig. 8. Method 2 is the most applicable of these, as method 1 implies that the perceived amplitude would be smaller than the actual amplitude, even above the perception threshold. The dead zone model is useful for simplicity; however, it assumes that the psychometric function is a step function, and it cannot be used directly to model JNDs.

(p53.1) Recent studies have suggested that sensory thresholds arise primarily as a result of noise in the sensory channels and the brain. Soyka et al. (2011Soyka et al. ( , 2012 Fig. 9 Sensor model incorporating additive and signal dependent noise (Bigler 2013). Noise is added after the sensor transfer function to represent spontaneous neuron firing in the brain. This is similar to the model of Soyka et al. (2011Soyka et al. ( , 2012, who modelled thresholds using a constant noise addition after the sensory transfer function based on additive noise (AN) applied to the outputs of the otolith and SCC transfer functions. The perception thresholds were found as the minimum stimulus amplitude required for the output to exceed the noise level. Both studies found good fits to experimental results, although the transfer functions had to be adjusted slightly from those found in the literature (see Sect. 2). This model predicts the frequency dependence of perception thresholds and is valid for arbitrary motion inputs rather than solely sinusoidal motion. A similar principle was used by Bigler (2013) to model JNDs as well as perception thresholds, by adding signal-dependent noise (SDN) as well as AN to the output of the sensor transfer function (Todorov 2005). This sensor model is shown in Fig. 9.

(p53.2) The simplest model of sensory thresholds is a 'dead zone' where the perceived amplitude is zero. There are two possible methods for modelling this, as shown in Fig. 8. Method 2 is the most applicable of these, as method 1 implies that the perceived amplitude would be smaller than the actual amplitude, even above the perception threshold. The dead zone model is useful for simplicity; however, it assumes that the psychometric function is a step function, and it cannot be used directly to model JNDs.

(p53.3) Recent studies have suggested that sensory thresholds arise primarily as a result of noise in the sensory channels and the brain. Soyka et al. (2011Soyka et al. ( , 2012 Fig. 9 Sensor model incorporating additive and signal dependent noise (Bigler 2013). Noise is added after the sensor transfer function to represent spontaneous neuron firing in the brain. This is similar to the model of Soyka et al. (2011Soyka et al. ( , 2012, who modelled thresholds using a constant noise addition after the sensory transfer function based on additive noise (AN) applied to the outputs of the otolith and SCC transfer functions. The perception thresholds were found as the minimum stimulus amplitude required for the output to exceed the noise level. Both studies found good fits to experimental results, although the transfer functions had to be adjusted slightly from those found in the literature (see Sect. 2). This model predicts the frequency dependence of perception thresholds and is valid for arbitrary motion inputs rather than solely sinusoidal motion. A similar principle was used by Bigler (2013) to model JNDs as well as perception thresholds, by adding signal-dependent noise (SDN) as well as AN to the output of the sensor transfer function (Todorov 2005). This sensor model is shown in Fig. 9.
## (s55) Visual thresholds
(p55.0) Various studies have measured perception thresholds and JNDs for the visual perception of self-motion. A difficulty in interpreting these results with any certainty is that they may well be dependent on the characteristics of the visual scene, such as the relative motion of stationary reference objects in the visual field, so it is not clear how generally applicable the results are. However, it may still be possible to find some useful information about the performance limits of the visual system. A driving simulator display was used by Bigler (2013) to measure yaw angle and lateral displacement thresholds. The display was not calibrated to give full-scale visual feedback so the absolute values of the measured thresholds may not be at the correct scale; however, the frequency response should not depend on the display scaling. The results are shown in Fig. 10. The visual transfer function given in Eq. 1 was used with the model of Soyka et al. (2011Soyka et al. ( , 2012 to give predicted thresholds, shown by the solid lines in Fig. 10. The model fits the thresholds very well, which is not surprising considering that the visual transfer function was found by fitting parameters to these results. The additive noise levels found are 0.0011 rad/s* for the yaw angular velocity and 0.032 m/s* for the lateral velocity.

(p55.1) A fit to the data was also found for a simple model of the visual system dynamics, with unity transfer functions between actual and perceived yaw and sway velocities. The fit using this model is shown by the dotted lines in Fig. 10, and the noise values found were 0.0013 rad/s* for the yaw angular velocity and 0.035 m/s* for the sway velocity. Visual JNDs have been measured for a range of yaw velocities, and Weber fractions of 7 % (de Bruyn and Orban 1988), 10 % A few studies have investigated the limits of visual perception of motion in the longitudinal direction. Reinterpretation of the data collected by Bremmer and Lappe (1999) gives a JND in displacement in the longitudinal direction of 450 mm, with a reference displacement of 4 m. This gives a Weber fraction of 10 %; however, extrapolating from measurements taken for this relatively short displacement of 4 m may be inaccurate. Monen and Brenner (1994) determined the smallest step increase in forward velocity necessary for the difference to be perceived within half a second and found a large Weber fraction of around 50 %.

(p55.2) Thresholds of visual perception involved in feedforward control have not been measured explicitly. Authié and Mestre (2012) measured JNDs in path curvature, finding a Weber fraction of approximately 11 %. Bigler (2013) used the results of Legge and Campbell (1981), who found the angular resolution of the retina to be around 1.5 arc min, to calculate additive and multiplicative noise variances for visual perception of road path geometry ahead of the vehicle. However, these results were found by asking subjects to indicate when they could detect a change in position of a small dot, which is likely to be significantly easier than picking out the full road geometry from a complicated visual scene.

(p55.3) Various studies have measured perception thresholds and JNDs for the visual perception of self-motion. A difficulty in interpreting these results with any certainty is that they may well be dependent on the characteristics of the visual scene, such as the relative motion of stationary reference objects in the visual field, so it is not clear how generally applicable the results are. However, it may still be possible to find some useful information about the performance limits of the visual system. A driving simulator display was used by Bigler (2013) to measure yaw angle and lateral displacement thresholds. The display was not calibrated to give full-scale visual feedback so the absolute values of the measured thresholds may not be at the correct scale; however, the frequency response should not depend on the display scaling. The results are shown in Fig. 10. The visual transfer function given in Eq. 1 was used with the model of Soyka et al. (2011Soyka et al. ( , 2012 to give predicted thresholds, shown by the solid lines in Fig. 10. The model fits the thresholds very well, which is not surprising considering that the visual transfer function was found by fitting parameters to these results. The additive noise levels found are 0.0011 rad/s* for the yaw angular velocity and 0.032 m/s* for the lateral velocity.

(p55.4) A fit to the data was also found for a simple model of the visual system dynamics, with unity transfer functions between actual and perceived yaw and sway velocities. The fit using this model is shown by the dotted lines in Fig. 10, and the noise values found were 0.0013 rad/s* for the yaw angular velocity and 0.035 m/s* for the sway velocity. Visual JNDs have been measured for a range of yaw velocities, and Weber fractions of 7 % (de Bruyn and Orban 1988), 10 % A few studies have investigated the limits of visual perception of motion in the longitudinal direction. Reinterpretation of the data collected by Bremmer and Lappe (1999) gives a JND in displacement in the longitudinal direction of 450 mm, with a reference displacement of 4 m. This gives a Weber fraction of 10 %; however, extrapolating from measurements taken for this relatively short displacement of 4 m may be inaccurate. Monen and Brenner (1994) determined the smallest step increase in forward velocity necessary for the difference to be perceived within half a second and found a large Weber fraction of around 50 %.

(p55.5) Thresholds of visual perception involved in feedforward control have not been measured explicitly. Authié and Mestre (2012) measured JNDs in path curvature, finding a Weber fraction of approximately 11 %. Bigler (2013) used the results of Legge and Campbell (1981), who found the angular resolution of the retina to be around 1.5 arc min, to calculate additive and multiplicative noise variances for visual perception of road path geometry ahead of the vehicle. However, these results were found by asking subjects to indicate when they could detect a change in position of a small dot, which is likely to be significantly easier than picking out the full road geometry from a complicated visual scene.
## (s56) Otolith thresholds
(p56.0) Perception thresholds have been measured extensively for translational accelerations in the horizontal plane. Measurements have been carried out in the longitudinal (X) and lateral (Y) directions, and the thresholds have been seen to be simi-lar in both directions (Benson et al. 1986); therefore, they are considered together. Thresholds have also been measured in the vertical (Z) direction (Nesti et al. 2014a); however, this is not so relevant for the car driver's control task.
## (s61) Coherence zones
(p61.0) The term 'coherence zone' was coined by van der Steen (1998) to describe the range of amplitudes of inputs to two sensory systems (such as visual and vestibular systems) which are perceived as consistent with each other, as shown in Fig. 14 Fig. 14 Coherence zone between visual and vestibular stimuli. For a given visual stimulus, there will be an upper and lower limit of vestibular stimulus amplitude which is perceived as coherent with the visual stimulus. The coherence zone width (CZW) is the difference between these two limits, and the point of mean coherence (PMC) is defined as the point halfway between the limits. The gain of mean coherence (GMC) is defined as the ratio of the vestibular amplitude to the visual amplitude at the PMC and represents the preferred gain between the visual and vestibular cues the point of mean coherence (PMC), coherence zone width (CZW) and gain of mean coherence (GMC) as shown.
## (s62) Sensory integration
(p62.0) The sensory systems described in Sect. 2 provide the central nervous system (CNS) with measurements (or sensory 'cues') which can be used to estimate vehicle states while driving. However, these measurements are shaped by the sensor dynamics and also contain additive and signal-dependent noise (as described in Sect. 4). The CNS must therefore carry out sensory integration to give a single estimate of the vehicle states from the noisy, filtered information received from each of the sensors.

(p62.1) In a real-world driving scenario, the driver will be presented with coherent sensory information. Any discrepancies between information from the different sensors are due to sensory noise, or incomplete information available to a particular sensor. However, in some situations the information presented to the different senses may be incoherent or biased, in which case the driver may use a different integration strategy. This is particularly relevant for motion in virtual environments, where the visual, vestibular and somatosensory information presented to the driver may not all accurately reflect the real-world stimuli. An overview of methods and results from investigations of sensory integration in a variety of virtual environments (not specific to driving) is given by Campos and Bülthoff (2012). The following subsections build on this, focusing in more depth on results which suggest how information from the sensory systems summarised in Sect. 2 may be integrated during driving.

(p62.2) The sensory systems described in Sect. 2 provide the central nervous system (CNS) with measurements (or sensory 'cues') which can be used to estimate vehicle states while driving. However, these measurements are shaped by the sensor dynamics and also contain additive and signal-dependent noise (as described in Sect. 4). The CNS must therefore carry out sensory integration to give a single estimate of the vehicle states from the noisy, filtered information received from each of the sensors.

(p62.3) In a real-world driving scenario, the driver will be presented with coherent sensory information. Any discrepancies between information from the different sensors are due to sensory noise, or incomplete information available to a particular sensor. However, in some situations the information presented to the different senses may be incoherent or biased, in which case the driver may use a different integration strategy. This is particularly relevant for motion in virtual environments, where the visual, vestibular and somatosensory information presented to the driver may not all accurately reflect the real-world stimuli. An overview of methods and results from investigations of sensory integration in a variety of virtual environments (not specific to driving) is given by Campos and Bülthoff (2012). The following subsections build on this, focusing in more depth on results which suggest how information from the sensory systems summarised in Sect. 2 may be integrated during driving.
