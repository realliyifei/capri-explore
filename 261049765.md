# LARGE LANGUAGE MODELS ON WIKIPEDIA-STYLE SURVEY GENERATION: AN EVALUATION IN NLP CONCEPTS

CorpusID: 261049765
 
tags: #Linguistics, #Computer_Science

URL: [https://www.semanticscholar.org/paper/d8cb4c151aabdd04ded60c23dd2182060d6d522f](https://www.semanticscholar.org/paper/d8cb4c151aabdd04ded60c23dd2182060d6d522f)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | False |
| By Annotator      | (Not Annotated) |

---

LARGE LANGUAGE MODELS ON WIKIPEDIA-STYLE SURVEY GENERATION: AN EVALUATION IN NLP CONCEPTS


Fan Gao 
Tokyo Institute of Technology
Japan

Hang Jiang 
Massachusetts Institute of Technology
USA

Moritz Blum 
Bielefeld University
Germany

Jinghui Lu 
Dairui Liu 
Sensetime Research
China

University College Dublin
Ireland

Yuang Jiang 
Yale University
USA

Irene Li 
University of Tokyo
Japan

LARGE LANGUAGE MODELS ON WIKIPEDIA-STYLE SURVEY GENERATION: AN EVALUATION IN NLP CONCEPTS
Preprint
Large Language Models (LLMs) have achieved significant success across various natural language processing (NLP) tasks, encompassing question-answering, summarization, and machine translation, among others. While LLMs excel in general tasks, their efficacy in domain-specific applications remains under exploration. Additionally, LLM-generated text sometimes exhibits issues like hallucination and disinformation. In this study, we assess LLMs' capability of producing concise survey articles within the computer science-NLP domain, focusing on 20 chosen topics. Automated evaluations indicate that GPT-4 outperforms GPT-3.5 when benchmarked against the ground truth. Furthermore, four human evaluators provide insights from six perspectives across four model configurations. Through case studies, we demonstrate that while GPT often yields commendable results, there are instances of shortcomings, such as incomplete information and the exhibition of lapses in factual accuracy.Existing work has shown that LLMs have great potential in an educational scenario, such as code generation and providing explanations, and so onAmer-Yahia et al. (2023). In this work, however, our focus is the task of survey generationLi et al. (2022). We are particularly interested in exploring how LLMs could help in explaining concepts in a structured way. Specifically, we aim to understand 1

# INTRODUCTION

Recently, Large language models (LLMs) have attracted a lot of attention due to their strong performance on general natural language processing (NLP) tasks Shaib et al. (2023). The GPT Brown et al. (2020) family, as a representative, also shows great ability in various applications. While it has been demonstrated that they perform well in some general tasks, their effectiveness in domain-specific tasks continues to be under scrutiny Tian et al. (2023). Furthermore, the text produced by LLMs can sometimes exhibit problems like the creation of false information and hallucination Zhao et al. (2023).

The goal of automatic survey generation is to employ machine learning or NLP techniques to create a structured overview of a concept Sun & Zhuge (2022). Such surveys are particularly valuable in the scientific domain, serving both educational and research purposes. Automating this process not only alleviates the manual effort but also ensures timely updates at a reduced cost. A common approach involves an initial information retrieval phase to select pertinent documents or sentences based on the query topic. This is followed by a summarization or simplification phase to produce the final survey Jha et al. (2013); Li et al. (2022). In this study, we explore the potential of LLMs in this task, with a focus domain to be NLP.


## Introduction

A-star, also referred to as A*, is one of the most successful search algorithms to find the shortest path between nodes of graphs. It is an informed search algorithm, as it uses information about path cost and also uses heuristics to find the solution. A* search achieves optimality and completeness, two valuable properties of search algorithms.


## History

The A* search algorithm was made as a part of the Shakey project. The goal of the project was to build a mobile robot that could plan its own actions. It yielded in the making of Shakey the Robot, the first general-purpose robot made in 1966. The A* search algorithm was developed to help Shakey solve pathfinding problems so it could move around.


## Key Ideas

The A* algorithm has 3 parameters. The first, g, is the cost of moving from the initial cell to the current cell, i.e. it is the sum of all the cells that have been visited since leaving the first cell. h, also known as the heuristic value, is the estimated cost of moving from the current cell to the final cell. The actual cost cannot be calculated until the final cell is reached, therefore, it is an estimated value. We must make sure that there is never an overestimation of this cost. f is the sum of g and h, i.e. f = g + h. The algorithm selects the smallest f-valued cell and moves to that cell. This process continues until the algorithm reaches its goal cell.


## Uses/Applications

The A* algorithm has found applications in many software systems, from machine learning and search optimization to game development where characters navigate through complex terrain and obstacles to reach the player. It is also used in maps, where the A* algorithm is used to calculate the shortest distance between the source (initial state) and the destination (final state).


## Variations

The A* search algorithm is like Dijkstra's algorithm in that it can be used to find a shortest path. The A* algorithm is like the Greedy Best-First-Search algorithm in that it can use a heuristic to guide itself, and in the simple case, it is as fast as Greedy Best-First-Search. Unlike other traversal techniques, A* search algorithm has "brains". It is a smart algorithm that uses heuristic methods to guide itself. the potential of LLMs in generating Wikipedia-style survey articles that effectively explain given concepts.

In our work, we specifically select the realm of Compute Science -NLP to investigate the effectiveness and limitations of LLMs in specialized domains. We empirically conduct experiments on two models, GPT-3.5 and GPT-4 concerning NLP survey generation. The evaluation process involves a variety of prompts, designed to study the capabilities of the GPT models in a thorough and systematic way. Concretely, we evaluate prompts including (i) zero-shot; (ii) one-shot; (iii) description prompts. We examine how these respective prompts influence the generated content. We release the GPTsgenerated surveys of all these works 1 .

We evaluate the performance of different models and prompts with expert-generated annotations, which serve as the benchmark for automated evaluations. Furthermore, we employ human evaluators to provide a qualitative dimension to ensure the results reflect technical performance and subjective human perspectives.


# EXPERIMENTS

We adopt the Surfer100 dataset Li et al. (2022)   We conduct experiments on 20 concepts, listed in Tab. 2. Specifically, we compare GPT-3.5 and GPT-4 with three different settings: zero-shot, one-shot and with prompt. The example prompts for these settings are shown in Tab. 4. In zero-shot setting, we simply give the basic template; in one-shot setting, we add a ground truth survey article; in the prompt setting, we give a detailed description for each section as the instruction. Besides, we also compare a special setting, GPT-4 in zero-shot, but with a search engine plugin enabled 2 .

We first show the ROUGE score Lin (2004) in Tab. 3. In the first group, we compare GPT-3.5 and 4 in zero-and one-shot settings. One may notice that GPT-4 is, in general, better than GPT-3.5. But with the one-shot setting, GPT-3.5 is improved significantly and has comparable results with GPT-4. In the second group, we add the description prompt and compare the effect of the one-shot instruction. With these descriptions, GPT-4 is not sensitive to the one-shot setting. More discussions are provided later.

We also report human evaluation on understanding the outputs. We invite experts in NLP to evaluate the surveys generated on the 20 selected topics from six dimensions. Initially, they are introduced to the experiment, evaluation perspectives, and corresponding guidelines as defined below.

1. Readability:

• 1 (bad): The text is highly difficult to read, full of grammatical errors, and lacks coherence and clarity. • 5 (good): The text is easy to read, well-structured, and flows naturally.


## Relevancy:

• 1 (bad): The generated text is completely irrelevant to the given context or prompt.

• 5 (good): The generated text is highly relevant and directly addresses the given context or prompt.

3. Redundancy:

• 1 (bad): The text is excessively repetitive, containing unnecessary repetitions of the same information. For example, each section should have 50-150 tokens. If it is too long, we should give a low rating. • 5 (good): The text is concise and free from redundancy, providing only essential information.


## Zero-Shot

Generate a survey about <Topic>. There should be five sub-sections: Introduction, History, Key Ideas, Variations and Applications. Each sub-section should contain 50-150 words.  The three main prompt types we compared. We eliminated some text in the one-shot setting, which is the ground truth from the survey of Word2Vec.


## One-Shot


## Hallucination:

• 1 (bad): The generated text includes false or misleading information that does not align with the context or is factually incorrect. • 5 (good): The generated text is free from hallucinations and provides accurate and contextually appropriate information. 5. Completeness/Accuracy:

• 1 (bad): The generated text is incomplete (missing key information), leaving out crucial details or providing inaccurate information. • 5 (good): The generated text is comprehensive, accurate, and includes all relevant information. 6. Factuality:

• 1 (bad): The text contains a significant number of factual inaccuracies or false statements, especially in History and Main Idea. For example, Year or people are wrong. • 5 (good): The text is factually accurate, supported by evidence, and free from misinformation.

Particuilarly, we opt for four representative models including GPT-3.5 zero-shot, GPT-4 zero-shot, GPT-4 zero-shot with prompt, GPT-4 one-shot with prompt to conduct the human evaluation. When assessing the criteria of Readability, Relevancy, Redundancy and Hallucination, experts are asked to concentrate on the generated surveys. However, when considering the aspects of Completeness and Factuality, they are required to compare the generated surveys with the given ones and cross-verify the included information against available, verifiable ground truth. A total of four experts complete the evaluation and assign scores to all the generated surveys. The review of each survey typically takes around 2 to 3 minutes, but when it comes to verifying the completeness and information, this extends to approximately 5 to 6 minutes. On average, the collection of evaluation scores requires 7 to 8 hours of effort per participant labor to rate 80 surveys.

We calculate the average and standard deviation scores concerning different dimensions, which can be found in Tab. 5 and 6. Furthermore, the mean scores are graphically visualized using a radar chart in Fig. 1. We can observe that the GPT-3.5 with zero-shot setting demonstrates the weakest performance across all criteria. In contrast, the GPT-4 model, in both zero-shot and one-shot with prompts, significantly outperforms others and shows comparable performance across different dimensions. Particularly, GPT models demonstrate strong performance in "Readability", consistently scoring above 4, while they fall short in "Completeness" and "Factuality". When employed with the description prompt setting, GPT models have substantial improvements in the performance of "Relevancy", "Redundancy", and "Hallucination".

We also visualize the score data in the box plot, providing more details of distribution. From Fig. 2, we can discover a high level of consensus among experts about the performance of GPT-4 models in terms of "Readability", "Relevancy", "Redundancy", and "Hallucination", with scores ranging from 3 to 5. Besides, the "Completeness" metrics also demonstrate a substantial agreement across the four models, with lower scores compared to other dimensions. Furthermore, while the "Factuality" scores vary amongst the models, the larger range of variation suggests that GPT models may occasionally generate information that is not entirely accurate.   


# CASE STUDY AND OBSERVATIONS


## UNDERSTANDING OF "SURVEY"

When we give the prompt to GPT models by asking them to write a "survey", they sometimes generate survey articles as desired, but they will write other types of content. For example, as indicated in Tab. 7, it appears that GPT would understand the term "Survey" as the questionnaire. Moreover, even if they are able to generate a survey article in the format, there is still the situation that the generated content is not a typical survey. As shown in Tab. 8, there are inconsequential sentences in an attempt to extend and explain the provided text. For example, it repeats saying this section and participants. But this is mostly observed in the GPT-3.5 zero-shot setting.


## INCOMPLETE INFORMATION

In the "History" section, GPT models occasionally produce incomplete evolutionary history, and thus, potentially result in misleading information. For instance, in Tab. 9, when discussing the Knowledge Graph topic, GPT-4 model simply asserts that the term was invented by Google, while the reality is that the concept of Knowledge Graph has a long history, and it is Google that popularized the term. Similarly, in the case of the topic on Decision Trees, although the GPT model yields accurate context, it ignores landmark events and consequently causes misunderstandings.


## NEBULOUS SENTENCE STRUCTURE

We observe that GPT models frequently construct sentences, especially within the "Application" Section, that employ a rather vague sentence structure, which lacks specificity and can be used in different NLP topics. As shown in Tab. 10, it is evident that GPT models tend to generate similar sentences, such as "The Topic has a wide spectrum of applications" and "The Topic plays a vital role in Natural Language Processing and Natural Language Understanding"; These statements hold significant meaning when "The Topic" is substituted with any NLP topics.


## HIGH-QUALITY SURVEY

We also present a high-quality generated survey in Tab 11. It is designed to read and understand easily, providing readers with comprehensive and detailed information. The example survey on LSTM is well-structured, with a summary provided in the first sentence and followed by the detailed explanation in each section. Specially, when discussing applications, it demonstrates a high level of domain specificity. Most importantly, the generated information is both accurate and concise.  Table 7: An example of generated questionnaire as qurvey (part).


## GOING BEYOND THE GROUND TRUTH

GPT-4 based methods maintain an overall high-quality response regarding all aspects. We show two examples by comparing the GPT-4 one-shot with prompt setting result with the ground truth in Tab. 12. In the first topic, multilingual BERT (mBERT), GPT successfully points out that the


## Introduction

This section aims to introduce the concept of Hidden Markov Models (HMMs) to the participants. HMMs are powerful statistical models used to represent systems that undergo successive probabilistic transitions. This section will briefly explain the basics of HMMs and provide the necessary background information for the subsequent sections.


## History

In this section, participants will explore the historical development of Hidden Markov Models. Starting from its early roots in the 1960s, the section will highlight key contributions and milestones in the field. Participants will gain an understanding of how HMMs have evolved over time and their relevance in various disciplines.


## Key Ideas

This section will delve into the fundamental concepts and principles behind Hidden Markov Models. Participants will learn about the core elements of HMMs, such as states, transitions, and observations. They will also be introduced to the notion of hidden states and the probabilistic framework that characterizes HMMs.


## Uses/Applications

The final section will focus on the diverse range of applications of Hidden Markov Models. Participants will discover how HMMs have been successfully applied in various fields, including speech recognition, bioinformatics, natural language processing, and finance. Real-world examples will be provided, showcasing the practical significance of HMMs and their potential for solving complex problems.


## Variations

In this section, participants will explore the different variations and extensions of Hidden Markov Models. The section will cover topics such as continuous HMMs, time-inhomogeneous HMMs, and higher-order HMMs. Participants will gain insights into the modifications made to basic HMMs, enabling them to handle more complex real-world scenarios. key idea behind mBERT is mapping words from distinct languages into a shared embedding space. However, the ground truth only mentions shared vocabulary, which is superficial. In the second example, Hidden Markov Models (HMMs), the GPT response is more precise and more complete than the ground truth. One can find that the content flow is present as algorithm category → features → applications → motivation (highlighted in bold and italicized words). In contrast, the ground truth texts spend a lot of words to which category HMM belongs, including many terminologies which is less informative.


## Limitations of Ground Truth

We refer to this previous work Li et al. (2022) on how the ground truth was generated. In general, the human writer was asked to rely on web data when writing the survey article; while these data were collected in the year 2021, it may be hard to say if it is a fair ROUGE score comparison with GPT models in Tab. 3. One may find that when applying the plugin, it reaches the best results, and the reason might be that it searches the web data, which may be close to how ground truth was created. While the ground truth may not be a perfect reference, in this work, we focus more on human evaluation and case studies.


## GPT-4 zero-shot with prompt Ground Truth

Topic: Knowledge Graph; Section: History Debuted by Google in 2012, Knowledge Graph is a synthesis of graph theory and semantic searching that targets more precise search results by understanding intent and meaning of search queries. Google introduced it to refine their search engine, understanding user queries' context and delivering relevant results. The Knowledge Graph evolution saw ontology and machine learning playing significant roles, with schema verification, information extraction and data alignment offering more precise data interpretations and integration.

In 1960, Semantic Networks were invented as a knowledge representation framework. The main idea of Semantic Networks was to capture a wide range of entities including real-world objects, events, situations or abstract concepts. In 2001, Tim Berners-Lee coined the term Semantic Web which is an application of Semantic Network combined with the Web. In 2012, Google popularized the term knowledge graph with the announcement of Knowledge Graph. there are very few technical details about its organization, coverage and size, but it is said that it contained 70 billion connected facts by 2016. Today, knowledge graphs are used by companies from a wide range of industries.


## GPT-4 one-shot with prompt Ground Truth

Topic: Decision Trees; Section: History Decision Trees were first introduced by Ross Quinlan, a researcher in machine learning, who developed an algorithm known as ID3 (Iterative Dichotomiser 3) dating back to the 1980s. The algorithm was developed in order to create a Decision Tree that predicts the value of a target variable based on several input variables. This was a significant development in the field of Machine Learning as it addressed the problem of handling categorical data and missing values while predicting multi-output concepts.  Model: GPT-4 zero-shot; Topic: Decision Trees; Section: Application Knowledge Graphs have a broad spectrum of applications. They significantly improve the efficiency of search engines, personalized recommendations, innovations in AI, and semantic searches. They also play a vital role in Natural Language Processing tasks such as machine reading and language understanding. Other potential applications include healthcare for an accurate analysis of patient data, e-commerce for efficient product recommendation, social media analytics, and cultural heritage preservation. With tech giants continually enhancing their proprietary knowledge graphs, the use of Knowledge Graphs in various sectors is anticipated to grow exponentially in the future.

Model: GPT-4 one-shot with prompt; Topic: Meta-learning; Section: Application

Meta-learning has a wide spectrum of applications. Aside from its notable use in deep learning where neural networks are used, it's also used in reinforcement learning. These tasks include but aren't limited to, robotic control, game playing, and autonomous navigation. Additionally, meta-learning can be used for rapid adaptation in natural language processing and, in particular, natural language understanding. Several companies use meta-learning algorithms for designing personalized recommendations and adaptive chatbots. 


## Introduction

Long Short-Term Memory Networks (LSTM) are an innovative type of Recurrent Neural Networks (RNNs) that have been specifically designed to effectively manage and maintain the essential elements extracted from time-varying or sequence data. LSTMs have been a remarkable advancement in the field of artificial intelligence because they address the shortcomings of traditional RNNs such as the undesirable effects of gradient vanishing and exploding, which impede RNNs' learning ability for long time-lag tasks.


## History

Introduced by Sepp Hochreiter and Jürgen Schmidhuber in 1997, the LSTM addresses the vanishing gradient problem experienced by traditional RNNs. The main novelty of LSTM was the incorporation of gating units. These units permit or restrict information from flowing through the sequence chain, thereby effectively containing the exploding or vanishing gradient problem. Since its inception, LSTM has served as a prerequisite for various network designs addressing further issues and limitations.


## Key Ideas

The core concept behind LSTM networks is the cell state, a controllable information pipeline that carries the required details from early input sequences to later ones, making provision for long-term dependencies.(Accurate and easy-to-understand) LSTM adjusts the cell state through carefully designed structures called gates, which are capable of removing or adding information to the cell state. There are three main types of gates: forget gate deciding what information should be discarded, input gate deciding what new information should be stored in the cell state, and output gate deciding what information should be utilized.


## Uses/Applications

LSTM found a myriad of applications in fields where sequence or time series data are crucial.(demonstrate domain-specificity) In natural language processing, LSTM has proven effective in machine translation, sentiment analysis, named entity recognition, and text generation due to its ability to capture context dependencies. In computer vision, LSTM has been utilized for video processing and in action recognition tasks. Also, in time series analysis and forecasting including stock market prediction or weather forecasting, LSTM exhibits prime performance.


## Variations

Over the years, several variations of LSTMs have been introduced to maximize efficiency and minimize computational resources. The Gated Recurrent Unit (GRU) is a popular variation, which merges the cell state and hidden state, and uses two gates. Another important variation is the Peephole LSTM, which lets the gate layers peep into the cell state. The Convolutional LSTM replaces simple multiplication operations with convolutional operations, making it especially effective for spatial temporal data. GPT-4 one-shot with prompt Ground Truth Topic: multilingual BERT; Section: Main Idea

This specific type of training allows it to create shared representations for syntactically or semantically similar words across different languages. One core concept behind mBERT is that it does not require distinct models for each language; it works on the idea of shared multilingual embeddings, leading to representation where different languages' embeddings should be close to each other if they are translations.

One important point to note is that while training on many languages, we keep a shared vocabulary for all languages rather than keeping distinct vocab for every language. This saves space and most importantly our model learns the root structure of language and learn the underlying structure rather than just learning of the vocab.

Topic: Hidden Markov Models; Section: Introduction

Hidden Markov Models (HMMs) are a statistical model used primarily in the field of machine learning and data analysis. Part of the broader category of Markov chain models (present the category), HMMs offer a way to describe the evolution of observable events that are driven by an internal state which is not directly accessible (present the features). The model's effectiveness has found it a important role in numerous applications, ranging from image recognition, speech recognition, genomics to finance (present the applications). The primary motivation behind HMMs is to provide a framework to infer the missing information from observable data, where every state from the hidden sequence generates an output according to a certain probability distribution related to that state (present the motivation).

Hidden Markov models (HMMs) are a way of relating a sequence of observations to a sequence of hidden classes or hidden states that explain the observations. They are a class of a full probabilistic model-the model parameters and the overall sequence 'scores' are all probabilities. They form the foundation for creating probabilistic models of linear sequence 'labeling' problems. From just drawing an intuitive picture, HMMs offer fundamental concepts for building a complex model and are the core of many algorithms in computational sequence analysis, including genefinding, profile searches, multiple sequence alignment, and regulatory site identification. 

## Figure 1 :
1Human Evaluation (Mean Scores).

## Figure 2 :
2Human Evaluation Scores. Topic: Generative Adversarial Network Section: Introduction 1. How would you rate your existing knowledge about Generative Adversarial Network (GAN)? a) No knowledge b) Basic understanding c) Intermediary knowledge d) Proficient e) Expert 2. What sources do you usually refer to gain information about AI technologies such as GAN? Section: History 3. Are you aware of the person who originally proposed the concept of GAN? If yes, could you please provide the name? 4. When was the GAN model first introduced? a) 2005 b) 2010 c) 2014 d) 2018

## Table 1 :
1An example from Surfer100: the survey of A star Search.


, which contains 100 manually written short survey articles on NLP concepts. Each survey contains five sections: Introduction, History, Key Ideas, Uses/Applications, and Variations. Each section includes 50-150 tokens. An example is shown in Tab. 1.BERT 
Autoencoders 
Clustering 
Decision Trees 
Ensemble Learning Gaussian Mixture Model 
Generative Adversarial Network Gradient Boosting 
Hidden Markov Models 
Knowledge Graphs 
Language Modeling Long Short-Term Memory Network 
Maximum Marginal Relevance 
Meta Learning 
Multilingual BERT 
Perceptron 
Relation Extraction Residual Neural Network 
RMSprop Optimizer 
Sentiment Analysis 



## Table 2 :
2The 20 selected concepts.Model 
R-1 
R-2 
R-L 

GPT-3.5 zero-shot 
26.19 
5.68 24.27 
GPT-3.5 one-shot 
30.18 
7.57 27.87 
GPT-4 zero-shot 
26.42 
6.04 24.01 
GPT-4 one-shot 
30.41 
9.43 27.74 

GPT-4 zero-shot with prompt 31.06 
9.11 28.65 
GPT-4 one-shot with prompt 
31.46 
8.21 28.78 

GPT-4 zero-shot with plugin* 31.91 10.46 29.52 



## Table 3 :
3ROUGE scores: comparison of variations on different settings.

## Table 4 :
4

## Table 5 :
5Mean scores of human evaluation.Model 
Readability Relevancy Redundancy Hallucination Completeness Factuality 

GPT-3.5 zero-shot 
0.98 
1.61 
1.04 
1.18 
0.94 
0.83 
GPT-4 zero-shot 
0.65 
0.76 
0.69 
0.79 
0.71 
0.92 
GPT-4 zero-shot with prompt 
0.72 
0.75 
0.81 
0.64 
0.69 
0.93 
GPT-4 one-shot with prompt 
0.60 
0.79 
0.64 
0.78 
0.70 
1.07 



## Table 6 :
6Standard deviation scores of human evaluation.

## Table 8 :
8An example of an invalid generated survey.

## Table 9 :
9Two example surveys with incomplete information.

## Table 10 :
10Example surveys with nebulous sentence structure.

## Table 11 :
11An example of the high-quality survey.

## Table 12 :
12Two examples showing that the generated output is better than the ground truth.
https://github.com/astridesa/EDUEval
https://www.keymate.ai/

From large language models to databases and back: A discussion on research and education. Sihem Amer-Yahia, Angela Bonifati, Lei Chen, Guoliang Li, Kyuseok Shim, Jianliang Xu, Xiaochun Yang, Sihem Amer-Yahia, Angela Bonifati, Lei Chen, Guoliang Li, Kyuseok Shim, Jianliang Xu, and Xiaochun Yang. From large language models to databases and back: A discussion on research and education, 2023.

. Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskeverand Dario Amodei. Language models are few-shot learnersTom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners, 2020.

A system for summarizing scientific topics starting from keywords. Rahul Jha, Amjad Abu-Jbara, Dragomir R Radev, Annual Meeting of the Association for Computational Linguistics. Rahul Jha, Amjad Abu-Jbara, and Dragomir R. Radev. A system for summarizing scientific topics starting from keywords. In Annual Meeting of the Association for Computational Linguistics, 2013. URL https://api.semanticscholar.org/CorpusID:1842821.

Surfer100: Generating surveys from web resources, Wikipedia-style. Irene Li, Alex Fabbri, Rina Kawamura, Yixin Liu, Xiangru Tang, Jaesung Tae, Chang Shen, Sally Ma, Tomoe Mizutani, Dragomir Radev, Proceedings of the Thirteenth Language Resources and Evaluation Conference. the Thirteenth Language Resources and Evaluation ConferenceMarseille, FranceEuropean Language Resources AssociationIrene Li, Alex Fabbri, Rina Kawamura, Yixin Liu, Xiangru Tang, Jaesung Tae, Chang Shen, Sally Ma, Tomoe Mizutani, and Dragomir Radev. Surfer100: Generating surveys from web resources, Wikipedia-style. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pp. 5388-5392, Marseille, France, June 2022. European Language Resources Association. URL https://aclanthology.org/2022.lrec-1.576.

ROUGE: A package for automatic evaluation of summaries. Chin-Yew Lin, Text Summarization Branches Out. Barcelona, SpainAssociation for Computational LinguisticsChin-Yew Lin. ROUGE: A package for automatic evaluation of summaries. In Text Summarization Branches Out, pp. 74-81, Barcelona, Spain, July 2004. Association for Computational Linguistics. URL https://aclanthology.org/W04-1013.

Summarizing, simplifying, and synthesizing medical evidence using gpt-3 (with varying success. Chantal Shaib, Millicent L Li, Sebastian Joseph, Iain J Marshall, Junyi Jessy Li, Byron C Wallace, 2023Chantal Shaib, Millicent L. Li, Sebastian Joseph, Iain J. Marshall, Junyi Jessy Li, and Byron C. Wallace. Summarizing, simplifying, and synthesizing medical evidence using gpt-3 (with varying success), 2023.

Automatic survey generation based onposition closeness of key words. Xiaoping Sun, Hai Zhuge, SSRN Electronic Journal. Xiaoping Sun and Hai Zhuge. Automatic survey generation based onposition closeness of key words. SSRN Electronic Journal, 2022. URL https://api.semanticscholar.org/ CorpusID:252731063.

Opportunities and challenges for chatgpt and large language models in biomedicine and health. Qiao Shubo Tian, Lana Jin, Po-Ting Yeganova, Qingqing Lai, Xiuying Zhu, Yifan Chen, Qingyu Yang, Won Chen, Donald C Kim, Rezarta Comeau, Aadit Islamaj, Xin Kapoor, Zhiyong Gao, Lu, Shubo Tian, Qiao Jin, Lana Yeganova, Po-Ting Lai, Qingqing Zhu, Xiuying Chen, Yifan Yang, Qingyu Chen, Won Kim, Donald C. Comeau, Rezarta Islamaj, Aadit Kapoor, Xin Gao, and Zhiyong Lu. Opportunities and challenges for chatgpt and large language models in biomedicine and health, 2023.

Llm calibration and automatic hallucination detection via pareto optimal self-supervision. Theodore Zhao, Mu Wei, J Samuel Preston, Hoifung Poon, Theodore Zhao, Mu Wei, J. Samuel Preston, and Hoifung Poon. Llm calibration and automatic hallucination detection via pareto optimal self-supervision, 2023.