# A Survey on Stance Detection for Mis-and Disinformation Identification

CorpusID: 232075945 - [https://www.semanticscholar.org/paper/14ba97c7e4c7d370965333ecf3835e514c664106](https://www.semanticscholar.org/paper/14ba97c7e4c7d370965333ecf3835e514c664106)

Fields: Computer Science

## (s2) Source(s) Target
Number of References: 5

(p2.0) Context Evidence #Instances Task English Datasets Rumour Has It (Qazvinian et al., 2011) Topic Tweet 10K Rumours PHEME (Zubiaga et al., 2016b) Claim Tweet 4.5K Rumours Emergent (Ferreira and Vlachos, 2016) ǌ Headline Article * 2.6K Rumours FNC-1 (Pomerleau and Rao, 2017) ǌ Headline Article 75K Fake news RumourEval '17 (Derczynski et al., 2017) Implicit 1 Tweet 7.1K Rumours FEVER  ɀ  Table 1: Key characteristics of stance detection datasets for mis-and disinformation detection. #Instances denotes dataset size as a whole; the numbers are in thousands (K) and are rounded to the hundreds. * the article's body is summarised. Sources: Twitter, ǌ News, ɀikipedia, Reddit. Evidence: Single, Multiple, Thread.
## (s9) Shades of Truth
Number of References: 4

(p9.0) The notion of shades of truth is important in mis-and disinformation detection. For example, fact-checking often goes beyond binary true/false labels, e.g., Nakov et al. (2018) used a third category half-true, Rashkin et al. (2017) included mixed and no factual evidence, and Wang (2017); Santia and Williams (2018) adopted an even finer-grained schema with six labels, including barely true and utterly false. We believe that such shades could be applied to stance and used in a larger pipeline. In fact, fine-grained labels are common for the related task of Sentiment Analysis (Pang and Lee, 2005;Rosenthal et al., 2017).
