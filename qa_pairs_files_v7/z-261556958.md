# Robust Recommender System: A Survey and Future Directions

CorpusID: 261556958 - [https://www.semanticscholar.org/paper/73d4a4e39eafc5884247f6cacf42228476ae3b54](https://www.semanticscholar.org/paper/73d4a4e39eafc5884247f6cacf42228476ae3b54)

Fields: Computer Science

## (s20) Adjustment of Training Process
Number of References: 2

(p20.0) Orthogonal Mapping where , is the ground truth rating andˆ, is predicted rating computing by Θ. The 1 -norm offers enhanced robustness against outliers or anomalous data in comparison to the Euclidean distance (i.e., 2 -norm). By integrating the 1 -norm regularization, the model prioritizes essential features over noise, leading to more refined recommendations. In recent times, researchers continue to innovate regularization strategies to improve the robustness of recommender systems in the presence of natural noise. As an illustration, Chen et al. [23] meld Jacobian regularization [68] with the transformer block in sequential recommender systems. This regularization enables a significant reduction in the model's susceptibility to noisy sequences, consequently delivering more consistent and trustworthy recommendations amidst noise.
## (s33) From Perspective of Applications
Number of References: 6

(p33.0) E-commerce Recommender Systems: E-commerce recommender systems, a crucial feature on platforms like Amazon and eBay, are designed to simplify product discovery for customers [116]. They function based on the historical browsing or purchasing patterns of customers, leaning heavily on user-item interaction data and item-side information. Despite their effectiveness, these systems confront several robustness concerns. One significant issue is the natural noise in user data through unintentional clicks or purchases, which may not necessarily represent the user's genuine preferences [151]. Furthermore, the system's integrity can be compromised by attackers manipulating item side information to push certain products or fabricate user profiles to manipulate a product's exposure [33]. In an e-commerce context, considerations of recommender systems' robustness are comprehensive. Beyond the strategies delineated in Sections 3 and 4, real-world applications necessitate these systems to adapt to the dynamic nature of product trends, cope with extensive product catalogs, and manage the persistent relevance of products over time. Collectively, these requisites pose new challenges in upholding robustness.

(p33.1) Media Recommender Systems: Media recommender systems, used prominently on streaming platforms like Netflix and TikTok, curate media suggestions-ranging from movies to songs-based on a user's historical consumption patterns and explicit preferences [49]. Similar to e-commerce systems, short-media recommendations also grapple with robustness issues, including unintentional likes, misleading video tags, and orchestrated efforts to inflate likes or views (Section 4 and Sections 3). These issues are amplified by the rapid shift in trends and the shorter lifespan of the content. On the other hand, long-media recommendations, such as for movies and music, provide a better reflection of user preferences through indicators like viewing or listening duration, thereby reducing the impact of natural noise. However, these systems also face potential challenges from fake user interactions [120] and the manipulation of item side information, such as fake video tags, for promotion is more likely due to the nature of the content [33] (Section 3).
## (s35) Robustness v.s. Accuracy
Number of References: 4

(p35.0) Several works have observed pursuing greater model robustness often comes with a compromise in accuracy, especially on clean data [109,131]. This trade-off has also been proved in some specific scenarios [128,153]. The trade-off often arises due to the limitations of defense methods, such as the challenges in identifying adversarial examples that alter the original semantics of a label. Additionally, it can stem from the model's inability to establish a suitable classification boundary after the introduction of such adversarial perturbations.
## (s38) Robustness v.s. Fairness
Number of References: 6

(p38.0) Fairness in machine learning typically signifies that an algorithm or model provides impartial and unbiased predictions across different groups or individuals [97,134]. Many methods interpret fairness as a model's invariant prediction to alterations in sensitive attributes (e.g., gender) within the input data [69,97]. This objective shares a resemblance with adversarial training where small perturbations in input data shouldn't alter predictions [157]. Nonetheless, a distinction persists: fairness concentrates explicitly on modifications to select attributes without imposing constraints on the extent of these changes. In contrast, robustness isn't tied to specific attributes but stipulates that the magnitude of changes should remain moderate to avoid distorting the ground truth label. Recent studies suggest that enhancing a model's robustness can indirectly improve its fairness [99].
## (s40) Mitigating Gap between Defense Assumption and Attack Goal
Number of References: 2

(p40.0) A significant challenge that arises in the realm of recommender systems is the gap between defense assumptions and the actual objectives of attacks. Attacks, especially shilling attacks, often aim to promote or diminish product exposure, rather than merely undermining recommendation performance. However, many prevailing defense strategies are predicated on the notion that attackers principally aim to degrade the functionality of recommender systems. This is particularly evident in adversarial training scenarios. For instance, He et al. [56] incorporate adversarial perturbations to model parameters during its training phase. Yet, these perturbations often don't align with real-world attack patterns, meaning certain adversarial examples optimized during training might be ineffective for defense. In another approach, Wu et al. [137] positively introduce empirical risk minimizing users to counterbalance the impacts of malicious users, who are often perceived as threats to recommendation quality.
