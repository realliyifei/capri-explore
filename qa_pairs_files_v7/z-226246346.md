# Video Generative Adversarial Networks: A Review

CorpusID: 226246346 - [https://www.semanticscholar.org/paper/5c1b1ab734ebc6ba56ea5d8af9d01a9fe8e0ba8b](https://www.semanticscholar.org/paper/5c1b1ab734ebc6ba56ea5d8af9d01a9fe8e0ba8b)

Fields: Engineering, Computer Science

## (s41) VIDEO GANS
Number of References: 6

(p41.0) Video GANs models vary depending on the condition settings. While at one end, there are video GANs frameworks that are not supplied with conditional signals, discussed in section 4.1, other models are conditioned on audios, texts, semantic maps, images and videos, as discussed in sections 4.2.1, 4.2.2, 4.2.3, and 4.2.4 respectively. In all these categories, the overall architecture can be divided roughly into three subcategories. First are the GANs frameworks that use RNN architectures to address the time-series nature of video data [39,40]. The second are progressive video GANs models [41,42] in which initial frames are first generated, and the generated data is fed into another generator to produce an enhanced result. The third are the two-stream architecture video GANs [6,43], where each stream considers a different aspect of the video. The following sections review the video GANs models based on the presence or absence of input condition and the variations within each category.
## (s42) Unconditional video generation
Number of References: 3

(p42.0) This section is a review of unsupervised GANs frameworks in the video domain, and a summary of these frameworks, the datasets and evaluation metrics used can be found in Table S4. So far, the output videos produced by these frameworks are short and have low-quality frames due to the lack of any information provided as a condition with the videos during the training phase. Although such models produce low-quality videos, the unconditional models have become the foundation for conditional frameworks. For instance, MoCoGAN [40] architecture, which is an unconditional model, is used in Text-Filter conditioning Generative Adversarial Network (TFGAN) [44] and storyGAN [39], both of which are conditional models.
