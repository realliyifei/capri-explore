# National survey of evaluation practices and performance-guided resource allocation at German medical schools Medical Faculties aimed to analyse current practices at German medical schools

CorpusID: 170078057
 
tags: #Psychology, #Medicine

URL: [https://www.semanticscholar.org/paper/50f5d7825e6c840ad1ad2e9ddbe385c49a6fca6f](https://www.semanticscholar.org/paper/50f5d7825e6c840ad1ad2e9ddbe385c49a6fca6f)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | False |
| By Annotator      | (Not Annotated) |

---

National survey of evaluation practices and performance-guided resource allocation at German medical schools Medical Faculties aimed to analyse current practices at German medical schools


Sarah Schiekirka-Schwake 
Janina Barth 
Reinhard Hickel 

Scientific Medical Societies
Universität München
Germany, Germany


Klinik für Kardiologie und Pneumologie
Universitätsmedizin Göttingen
Germany


Health Behaviour Research Centre
University College London
United Kingdom


Klinik für Psychosomatische Medizin und Psychotherapie
Universitätsmedizin Göttingen
Germany


Arbeitsgemeinschaft der Wissenschaftlichen Medizinischen Fachgesellschaften e.V
Universitätsmedizin Göttingen
Humboldtallee 3837073Berlin, GöttingenGermany, Germany


Universität München
Deutschland


Health Behaviour Research Centre
University College London
Großbritannien


Klinik für Psychosomatische Medizin und Psychotherapie
Universitätsmedizin Göttingen
Deutschland


Arbeitsgemeinschaft der Wissenschaftlichen Medizinischen Fachgesellschaften e.V
Berlin, Deutschland 7/13 GMS German

National survey of evaluation practices and performance-guided resource allocation at German medical schools Medical Faculties aimed to analyse current practices at German medical schools
23at German medical schools. For this reason, the Association of the
Background: Little is known about evaluation practices as well as performance-oriented allocation of resources according to teaching quality

## Background

There are currently around 92,000 undergraduate medical students in Germany, dispersed among 37 medical schools. Teaching quality must meet high standards, both in terms of content [1] and the coverage of interprofessionalism and scientificity [2]. Owing to the purpose of national rankings, "teaching outcome" at individual medical schools is sometimes used as a surrogate marker of "teaching quality". The second state examination only represents factual knowledge, and the aggregate exams provide but few clues to the specific strengths and weaknesses of individual curricula. Thus medical schools need other data sources to assess their teaching quality. One popular source are student evaluations of teaching. Depending on the survey instrument that is used, up to four dimensions of teaching quality can be mapped. According to Gibson et al., the structural and procedural characteristics of teaching as well as the didactic skills of the teachers and the student learning outcome are differentiated [3]. However, many evaluation tools focus on structural and process-related parameters [4] and only ask for student satisfaction with teaching. It is known that, particularly, global assessments by students are subject to a variety of confounding factors (e.g., individual characteristics such as gender, interest in subject, level of performance) [5]. Such a bias of the evaluation is problematic because at some medical schools the results are discussed as the basis of a performance-based allocation of resources (Leistungsorientierte Mittelvergabe, LOM) for teaching (teaching-LOM). In research, a defined benefit allocation has become well established. Although the parameters and algorithms used in research evaluation are criticized heavily [6], there has been a mismatch between incentives for good research and those for good teaching. Although a large amount of money flows into the basic equipment for teaching, the quality of teaching is often not sufficiently considered in resource allocation. Therefore, the perception of many scientists is that commitment to teaching pays off less than involvement in research. So far, there is a lack of comprehensive data for German medical schools regarding their evaluation practices and the design of LOM algorithms in teaching. Against this background, the Working Group on Evaluation of Performance in Medical Research and Teaching of the Association of Scientific Medical Societies in Germany (AWMF) and the Medical School Association (MFT) have set the common goal of analyzing current evaluation practices at medical schools in Germany. This paper shows the results of a survey conducted at these schools.


## Methods

A standardized questionnaire was developed in a multistage procedure and piloted.

The questionnaire covered the following aspects of teaching evaluation and LOM awarding practice in eleven parts:

1. grounding of evaluation, 2. objects of evaluation, 3. persons involved in the evaluation, 4. regularity and frequency of evaluation of the curriculum, 5. format of evaluation by students, 6. format of the evaluation by academic teachers, 7. content of the evaluation by students, 8. use of objective data for quality assurance and evaluation, 9. processing and distribution of the evaluation results, 10. consequences of the evaluation, 11. allocation of funds for teaching.

The questionnaire mainly included yes/no questions, sometimes with the possibility of supplementing free text information. Occasionally, numbers were requested, especially for the range of the evaluations, the response rates of student evaluations, and the allocation of funds by the faculties. The questionnaire was sent in July 2013 via the office of the Medical School Association to all medical schools in Germany. Medical schools were asked for written answers from the responsible staff and for sending relevant materials. In case of non-response, a reminder was issued at the end of August, further missing data were requested by phone in November and December. The (German) questionnaire is available from the authors upon request.


## Results

30 German medical schools participated in the survey with 33 study programs (23 standard curricula, 6 model curricula, 3 reformed standard curricula, and 1 degree program in molecular medicine) (response rate 83%). The results are presented below according to the abovementioned sections of the questionnaire.


## Grounding of evaluation

Only 21% of all study programs had a dedicated evaluation system. The majority relied on evaluation regulations of the respective university or on corresponding decisions of the departmental council. The majority (85%) cited their evaluation practice as "grown by experience", and 75% think that it is scientifically justified. Regarding the data source, 40% referred to external and 36% to internal survey instruments. In addition, points such as relevant knowledge in methodology research or evaluation standards as defined by various groups (e.g., the German Evaluation Society (DeGEVal), the working group on evaluation, and the training committee) were mentioned.


## Objects of the evaluation and involved groups of people

Most frequently, subjects (70%), individual courses (67%), and study sections (64%) are evaluated. In particular, the internship (PJ) is relevant to evaluation for 85% of the programs. Also, teachers are evaluated in three out of four medical schools. About half of the medical schools evaluate examinations (quality and results) and graduates. All degree programs use student evaluations, 45% involved teachers and 20-25% internal panels, but also external reviewers.

Regularity and frequency of evaluation in the core curriculum

In less than 50% of the study programs, a comprehensive evaluation of all types of events and groups of persons takes place. Only courses in special medical disciplines or cross-sectional areas are consistently evaluated by about two thirds of medical schools; individual segments of the curriculum (e.g., preclinical, clinical, practical internship) in 42%; and teachers (27% to 36%) as well as examinations (33%) in about one third.


## Format of evaluations by students and academic teachers

Nearly all study programs (97%) use online formats for student evaluations, and about 50% (additionally) utilize paper-based formats for evaluations. The majority (94%) are evaluated outside of course times, mainly before or after the final exam. However during ongoing courses, evaluations take place in about 46%. The number of questions in the questionnaire varies greatly (1 to 140 items). Ordinal or interval-scaled items (e.g., grades, percentages) and free-text comments are most commonly used, as well as dichotomous, open and multiple choice questions. The reported response rates of student evaluations average approximately 60%. Incentives for increased returns, such as transparency (18%) and student bonus schemes (33%), as well as coercion and negative consequences, are only sporadically described as helpful. Other forms of evaluation include debriefing (54%) and reports from semester spokespersons (48%). Interviews (15%) and focus groups (21%) are less frequently used. In the course evaluation by academic teachers, the majority (80%) choose a structured approach. In 40% of the cases all teachers are evaluated; in 20% a selection of teachers are evaluated by committees.


## Content of the evaluation by students

Using student evaluations, structural and process parameters as well as the overall impression of the teaching is captured. The subjective relevance of the educational content for examinations and practice, the content structure and overall satisfaction with educational events or overall grades are most frequently rated by students (>80%). For further details see Table 1.

Use of objective data for quality assurance and evaluation 94% of medical schools use objective data for internal or external quality assurance of teaching. Particularly frequently (>80%) the second state examination (pass rate in the reference cohort, failure rate) was named, followed by average study duration, average score in the second state examination and number of graduates (79% each), passing of the first state examination, and further qualifications of the teachers (76% each). Ratio of support, number and quality of doctorates, research projects or publications on teaching, as well as average scores and subject-specific evaluations in the first state examination are less relevant parameters for quality assurance (50-70%).


## Processing and distribution of the evaluation results

The results of the evaluation are mostly written as reports and regularly stored electronically in a protected area. Usually, deans' offices (79%) and professors responsible for issuing certificates (76%) are actively informed about the results, often also teaching coordinators (67%), individual academic teachers (61%), and students (64%). An active communication of results takes place in more than 40%; and in almost 10% of all cases, the (external) public is actively informed.


## Consequences of the evaluation

In two out of three faculties, teaching quality is rated according to fixed criteria/categories; in 82%, courses and academic teachers are also assessed in relation to each other. Mostly (82%) there are feedback talks with academic teachers, less frequently feedback on teaching content in cross-sectional areas (73%), medical subjects (61%), and modules (55%). In addition, just under 80% (79%) of the degree programs have provided consequences for particularly positive but also particularly negative evaluation results. For positive results, the main reported consequence (54%) is reward by teaching-LOM. Only occasionally, awards for the best lecturer or a bonus for promotions were mentioned. In contrast, 73% of study programs provide training and support for teachers with particularly negative outcomes, followed by face-to-face interviews (45%) and negative effects on teaching-LOM (21%).


## Allocation of funds for teaching

Seventeen medical schools answered the questions about their internal distribution of resources. These data are   Figure 1. It becomes clear here that the three most important items represent the general basic supply of the Chairs as well as the curricular basic equipment and the evaluation-based research LOM. In contrast, evaluation-based funds for teaching play a minor role, as well as application-based research and teaching support. With an average of 1.6% (minimum 0%, medi-an 3%, maximum 6%), the evaluation-based teaching-LOM tends to account for a small part of the state funds. In 60%, the teaching-LOM follows a fixed algorithm. With just under 70%, it benefits clinics and institutes in particular, much less complete modules (15%) or individuals (21%).


## Discussion

The results of the survey are in agreement with the current literature [4], in so far as evaluation instruments used in Germany primarily assess structural and procedural aspects as well as students' overall impression of teaching quality. Teaching outcome -mostly defined as students' learning success -is either assessed by student ratings of their own perceived learning outcome, or it is inferred from student performance in high-stakes examinations. A systematic evaluation of teachers is rare. For the dimensions "process" and "teacher", the literature review by Schiekirka et al. [4] already identified numerous survey instruments for medical education with good to very good reliability. About one third of faculties use such instruments or use their scientific base for the development of own instruments. However, it is unclear whether the used instruments are equivalent to those already identified. Furthermore, it is uncertain how the instruments were developed, whether they were psychometrically tested and to what extent they meet established quality criteria. In 88% of medical schools, global grades are used to assess teaching quality. Although these evaluations provide a rough idea of student satisfaction with teaching, they are not considered valid measures of teaching quality due to the strong bias introduced by various construct-irrelevant confounders [5]. Data show for example that students with a high initial interest in a course generally tend to rate it more positively than those with a low interest [7], [8]. Further studies found a positive correlation between exam performance and student ratings for an anatomy course [9], [10]. In this context, the importance of a clear definition of the construct of good teaching underlying the evaluation should be emphasized: Only after it has been clearly defined what is meant by "good teaching" can one identify and use an instrument that measures precisely this construct. Conversely, the interpretation of existing evaluation data should only refer to that particular construct (e.g., structural conditions) and should not be generalized to other aspects of the quality of teaching (e.g., didactic skills of academic teachers). However, the psychometric examination of the evaluation tools used, minimization of distorting effects, as well as the coverage of all four dimensions suggested by Gibson [3] are urgently needed in order to be able to validly assess and optimize teaching quality. Even when the result of teaching is inferred from seemingly objective exam data, some difficulties need to be kept in mind. In order to provide valid data, examinations need to be aligned to learning objectives and instructional methods [11] and thereby free of construct-irrelevant variance [12], [13]. They must also meet international quality standards [14], which cannot be taken for granted [15]. These requirements become even more important when the distribution of teaching-LOM is based on evaluation results and examinations. So far, the financial remuneration of teaching has mainly been part of the basic equipment of Chairs or has been based on teaching quantity.

Quality-based funding for teaching, unlike research, plays only a minor role. Also other gratifications for high quality teaching are only occasionally given. Due to the current heterogeneity of the evaluations, it is not possible or at least of limited value to compare the results of teaching evaluations across medical schools. Although a certain degree of comparability can be established by comparing students' results in central written exams, the validity of the data must be discussed against the background of the construct of good teaching chosen in each case. In terms of rewarding good teaching, initial data show that teachers are currently more motivated by student feedback, but they also have a positive attitude towards financial incentives [16], [17]. Thus, it seems to be unrewarding to exclusively emphasize financial incentives; instead, other aspects of appreciation and specific support (for example by improving the organizational conditions for teaching and career opportunities) can help to increase and sustain motivation of academic teachers [18]. Just as good research performance leads to both immaterial or career-related and direct material appreciation, an incentive system for good teaching should be based on a broad range of rewards in order to overcome the existing imbalance.


## Conclusions

This first systematic survey of German medical schools on the practices used for evaluating medical teaching has shown that the evaluation instruments used have similar content and methodology, and above all record structural and procedural aspects as well as students' overall impression of teaching. Yet, there is considerable heterogeneity regarding the instruments actually used. A nationwide consensus on a general construct of good medical teaching as well as the identification or development of valid and reliable evaluation instruments in a nation-wide cooperation appears sensible.


## Notes


## Competing interests

The authors declare that they have no competing interests.


## Authorship

The authors Raupach T and Herrmann-Lingen C contributed equally to this work.  


## Grundlagen der Evaluation

Lediglich 21% der Studiengänge verfügten über eine fakultätseigene Evaluationsordnung. Die Mehrzahl berief sich auf die Evaluationsordnung der jeweiligen Universität bzw. auf entsprechende Fachbereichsratsbeschlüsse. Der Großteil (85%) gibt seine Evaluationspraxis als "durch Erfahrung gewachsen" an, bei 75% ist diese auch wissenschaftlich begründet. Als Quelle verweisen 40% auf externe und 36% auf interne Erhebungsinstrumente. Des Weiteren werden vereinzelt Punkte wie einschlägige Kenntnisse in der Methodenforschung oder Standards für Evaluation der Gesellschaft für Evaluation e.V. (DeGEVal), der AG Evaluation und der Ausbildungskommission genannt.


## Gegenstände der Evaluation und beteiligte Personengruppen

Hauptsächlich werden Fächer (70%), Einzelveranstaltungen (67%) und Studienabschnitte (64%) evaluiert. Insbesondere das Praktische Jahr (PJ) ist für 85% der Studiengänge evaluationsrelevant. Auch Lehrende werden an drei Vierteln der Fakultäten evaluiert. Für Prüfungen (Qualität und Ergebnisse) und AbsolventInnen erfolgt in etwa der Hälfte der Fakultäten eine Evaluation. Alle Studiengänge nutzen studentische Evaluationen, 45% beziehen Lehrende mit ein und 20-25% interne Gremien jedoch auch externe GutachterInnen.


## Regelmäßigkeit und Häufigkeit der Evaluation im Kerncurriculum

In weniger als 50% der Studiengänge erfolgt eine flächendeckende Evaluation aller Veranstaltungstypen und Personengruppen. Lediglich Fächer bzw. Querschnittsbereiche werden von etwa zwei Dritteln der Fakultäten durchgängig evaluiert, einzelne Studienabschnitte von 42%, und Lehrende (27% bis 36%) sowie Prüfungen (33%) von ca. einem Drittel.


## Format der Evaluationen

Nahezu alle Studiengänge (97%) nutzen bei studentischen Evaluationen Online-Formate, etwa 50% evaluieren (zusätzlich) papierbasiert. Mehrheitlich (94%) wird außerhalb von Lehrveranstaltungen, vorwiegend vor oder nach der Abschlussklausur, evaluiert. Aber auch während laufender Veranstaltungen finden in ca. 46% der Studiengänge Evaluationen statt. Die Fragenanzahl im Fragebogen variiert stark (1 bis 140 Items). Am häufigsten kommen ordinal-bzw. intervallskalierte Items (z.B. Schulnoten, %-Angaben) sowie Freitextkommentare zum Einsatz. Auch werden dichotome, offene und Mehrfachantwort-Fragen verwendet. Die Rücklaufquoten studentischer Evaluationen wurden im Mittel mit ungefähr 60% angegeben. Anreize für einen erhöhten Rücklauf wie Transparenz (18%) und Bonussysteme für Studierende (33%) werden ebenso wie Zwang und negative Konsequenzen nur vereinzelt als hilfreich beschrieben. Als weitere Evaluationsformen wurden Nachbesprechungen (54%) und Berichte von Semester-sprecherInnen (48%) genannt. Interviews (15%) und Fokusgruppen (21%) kommen seltener zum Einsatz. Bei der Lehrveranstaltungsevaluation durch Dozierende wird in der Mehrzahl (80%) ein strukturiertes Vorgehen gewählt. In 40% der Fälle evaluieren alle Lehrenden, in 20% eine Auswahl von Lehrenden in Kommissionen.


## Inhaltliche Aspekte der Evaluation durch Studierende

Mittels studentischer Evaluationen werden vor allem Struktur-und Prozessparameter sowie der Gesamteindruck der Lehre erfasst. Besonders hoch (>80%) schätzen Studierende subjektiv die Prüfungs-und Praxisrelevanz der Inhalte ein, bewerten den inhaltlichen Aufbau und geben ihre globale Zufriedenheit mit der Veranstaltung an bzw. eine Gesamtnote ab. Für weitere Details siehe Tabelle 1.


## Nutzung objektiver Daten zur Qualitätssicherung und Evaluation

Von 94% der Fakultäten werden objektive Daten zur internen oder externen Qualitätssicherung der Lehre genutzt. Besonders häufig (>80%) wurde das Zweite Staatsexamen (Bestehensquote in der Referenzkohorte, Durchfallquote) genannt, gefolgt von durchschnittlicher Studiendauer, durchschnittlicher Punktzahl im Zweiten Staatsexamen und Absolventenzahlen (je 79%), Bestehen des Ersten Staatsexamens und Weiterqualifikationen der Lehrenden (je 76%). Betreuungsrelation, Zahl und Qualität von Promotionen sowie Forschungsprojekte bzw. Publikationen zur Lehre, aber auch durchschnittliche Punktzahlen und fächerspezifische Auswertungen im Ersten Staatsexamen sind weniger relevante Parameter für die Qualitätssicherung (50-70%)


## Aufbereitung und Verbreitung der Evaluationsergebnisse

Die Evaluationsergebnisse werden überwiegend als schriftliche Berichte verfasst und meist elektronisch in einem geschützten Bereich abgelegt. In der Regel werden Dekanat (79%) und Scheinverantwortliche (76%) aktiv über die Ergebnisse informiert, häufig auch Lehrkoordi-natorInnen (67%), einzelne Dozierende (61%) und Studierende (64%). Eine aktive Ergebnis-Kommunikation erfolgt in gut 40%, und in knapp 10% der Fälle wird aktiv die (externe) Öffentlichkeit informiert.


## Konsequenzen der Evaluation

Die Bewertung der Lehrqualität erfolgt in zwei von drei Fakultäten anhand fester Kriterien/Kategorien, bei 82% werden Veranstaltungen und Dozierende auch relativ zueinander bewertet. Mehrheitlich (82%) werden Feedbackgespräche mit Dozierenden geführt, seltener wird Feedback zu Lehrinhalten an Querschnittsbereiche (73%), Fächer (61%) und Module (55%) gegeben. Zudem haben knapp 80% (79%) der Studiengänge Konsequenzen für besonders positive aber auch für besonders negative Evaluationsergebnisse vorgesehen. Für positive Ergebnisse wird vorwiegend (54%) die Berücksichtigung in der LOM-Lehre genannt und nur vereinzelt 


## Diskussion

Die Ergebnisse der Fakultätenbefragung decken sich insofern mit der aktuellen Literatur [4], als die in Deutschland eingesetzten Erhebungsinstrumente vorrangig strukturelle und prozedurale Aspekte sowie einen Gesamteindruck der Lehre erfassen. Das Ergebnis der Lehre -i.d.R. als Lernerfolg der Studierenden definiert -wird entweder anhand punktueller studentischer Angaben zum wahrgenommenen eigenen Lernerfolg oder anhand der Leistungen in den Staatsexamina beurteilt. Eine systematische Bewertung der Lehrenden erfolgt kaum. Für die Dimensionen "Prozess" und "Lehrende" wurden in der Literaturrecherche von Schiekirka et al. [4] bereits zahlreiche Erhebungsinstrumente für die medizinische Lehre mit guter bis sehr guter Reliabilität identifiziert. Etwas mehr als ein Drittel der Fakultäten geben an, externe Instrumente für die Evaluation heranzuziehen bzw. diese als wissenschaftliche Grundlage für fakultätseigene Instrumente zu nutzen. Es bleibt jedoch unklar, ob die genutzten Instrumente sich mit den bereits identifizierten Instrumenten decken. Auch bleibt offen, ob die Instrumente spezifisch zur Erfassung der Lehre in der Medizin entwickelt wurden, ob ihnen psychometrische Testungen zugrunde liegen und inwiefern sie den gängigen Gütekriterien genügen. Bei 88% der Fakultäten werden Globalnoten zur Bewertung der Lehrqualität herangezogen. Wenngleich diese Bewertungen einen groben Eindruck von der studentischen Zufriedenheit mit der Lehre vermitteln, sind sie aufgrund der starken Verzerrung durch verschiedene konstrukt-irrelevante Störfaktoren nicht als valide Messgrößen der Lehrqualität anzusehen [5]. So zeigen Daten, dass Studierende mit einem großen initialen Interesse an einer Lehrveranstaltung in der Evaluation positivere Einschätzungen angeben als Personen mit einem geringen Interesse [7], [8]. Weitere Studien fanden eine positive Korrelation zwischen Leistungen in der Abschlussprüfung und der Bewertung eines Anatomiekurses [9], [10]. In diesem Zusammenhang sei auf die Bedeutung einer klaren Definition des in der Evaluation abgebildeten Konstrukts von guter Lehre hingewiesen: Nur wenn eindeutig definiert ist, was unter "guter Lehre" verstanden wird, kann ein Instrument identifiziert und eingesetzt werden, das genau dieses Konstrukt misst. Umgekehrt darf sich die Interpretation vorliegender Evaluationsdaten nur auf genau dieses Konstrukt (z.B. strukturelle Gegebenheiten) beziehen, und nicht auf andere Aspekte der Lehrqualität (z.B. didaktisches Geschick der Dozenten) ausgeweitet werden. Die psychometrische Untersuchung eingesetzter Evaluationsinstrumente, Minimierung verzerrender Effekte sowie die Erfassung aller vier Dimensionen nach Gibson [3] sind jedoch dringend erforderlich, um die Lehrqualität valide erfassen und entsprechend optimieren zu können. Auch die Erfassung des Lehrergebnisses durch scheinbar objektive Daten wie Prüfungen unterliegt Schwierigkeiten. Um valide Daten liefern zu können, müssen Prüfungen kongruent mit dem Lehrinhalt und der Lehrform [11] und somit frei von konstrukt-irrelevanter Varianz sein [12], [13] sowie internationalen Qualitätsstandards genügen [14]. Nicht immer ist dies gegeben [15]. Noch mehr Gewicht bekommen diese Voraussetzungen, wenn die Verteilung von LOM-Lehre auf Basis von Evaluationsergebnissen und Prüfungen erfolgen soll. Die finanzielle Honorierung der Lehre erfolgt bislang überwiegend im Rahmen der Grundausstattung bzw. nach Kriterien der Lehr-Quantität. Qualitätsbasierte Mittelzuweisung für die Lehre spielt anders als im Bereich der Forschung nur eine untergeordnete Rolle. Auch weitere Gratifikationen für hohe Lehrqualität kommen lediglich vereinzelt zum Einsatz. Durch die derzeitige Heterogenität der Evaluation ist die Vergleichbarkeit der Ergebnisse zwischen Fakultäten nicht oder nur sehr eingeschränkt möglich. Durch eine Betrachtung schriftlicher Examensergebnisse kann zwar eine gewisse Vergleichbarkeit hergestellt werden -hier bleibt jedoch jeweils die Validität der Daten vor dem Hintergrund des jeweils gewählten Konstruktes guter Lehre zu diskutieren. Hinsichtlich einer Honorierung guter Lehre zeigen erste Daten, dass Lehrende derzeit ihre Motivation vorranging aus studentischem Feedback ziehen, jedoch möglichen finanziellen Anreizen positiv gegenüber stehen [16], [17]. So scheint es nicht zielführend zu sein, ausschließlich finanzielle Anreize in den Vordergrund zu stellen, vielmehr können auch weitere Aspekte der Wertschätzung und konkrete Unterstützung (durch z.B. Verbesserung von Rahmenbedingungen und Karrierechancen) motivationsfördernd und -erhaltend wirken [18]. Ebenso wie gute Forschungsleistung sowohl immaterielle und karrierebezogene als auch direkte materielle Wertschätzung erfährt, sollte ein Anreizsystem für gute Lehre auf breiter Basis ansetzen, um das bislang bestehende Ungleichgewicht auszugleichen.


## Fazit

Diese erste systematische Erhebung zu den Evaluationspraktiken in der Lehre an deutschen medizinischen Fakultäten hat gezeigt, dass die Evaluationsinstrumente inhaltlich und methodisch ähnlich ausgelegt sind und vor allem strukturelle und prozedurale Aspekte sowie einen Gesamteindruck der Lehre erfassen. Bezüglich der tatsächlich eingesetzten Instrumente herrscht eine erhebliche Heterogenität. Eine möglichst bundesweite Konsentierung eines Leitbilds guter medizinischer Lehre sowie die Identifikation bzw. Entwicklung valider und reliabler Erhebungsinstrumente in deutschlandweiter Zusammenarbeit scheint sinnvoll.


## Anmerkungen

Interessenkonflikte Die Autoren erklären, dass sie keine Interessenkonflikte in Zusammenhang mit diesem Artikel haben.


## Autorenschaft

Die Autoren Raupach T und Herrmann-Lingen C haben gleichermaßen zu der Arbeit beigetragen.


## Danksagungen

Wir danken der AWMF für finanzielle Unterstützung, der MFT-Geschäftsstelle (Dr. Corinne Dölling) für logistische Unterstützung, Frau Sabine Gluth für die Komplettierung und Auswertung der Befragungsdaten, den Mitarbeiterinnen und Mitarbeitern der Studiendekanate für die Beantwortung der Fragebögen sowie den Mitgliedern der AWMF-Kommission für Leistungsevaluation in Forschung und Lehre und der MFT-AG Lehre für ihre Unterstützung bei der Durchführung und Interpretation der Befragung.

## Figure 1 :
1Relative distribution of state funds at medical school shown in


the staff of the Deans of Studies for answering the questionnaires, and the members of the AWMF Committee for Performance Evaluation in Research and Teaching and the MFT Working Group on Teaching for their support in implementation and interpretation of the survey. Fachgesellschaften e.V. (AWMF) und der Medizinische Fakultätentag (MFT) das gemeinsame Ziel gesetzt, die Praxis der Evaluationen und Reinhard Hickel 2,4 LOM in der Lehre (LOM-Lehre) an den medizinischen Fakultäten in Deutschland zu analysieren.

## Table 1 :
1Aspects that are captured by educational event evaluations by students


Methoden: Die Datenerhebung erfolgte mittels Fragebogen, der an alle medizinischen Fakultäten in Deutschland gesandt wurde. Ergebnisse: An der Befragung nahmen 30 Fakultäten mit insgesamt 33 Studiengängen teil (Rücklauf: 83%). Die an den Fakultäten eingerecht hohe Heterogenität. Teilweise bleibt unklar, inwiefern die Erhebungsinstrumente internationalen Qualitätsstandards genügen. Die finanzielle Honorierung der Lehre erfolgt überwiegend im Rahmen der Grundausstattung bzw. nach Kriterien der Lehr-Quantität. Qualitätsbasierte Mittelzuweisung spielt eine eher untergeordnete Rolle. Im Studium der Humanmedizin werden an den 37 deutschen Fakultäten aktuell rund 92.000 Menschen zu künftigen Ärztinnen und Ärzten ausgebildet. Die Qualität des Studiums muss hohen Ansprüchen genügen: Neben der inhaltlichen Ebene [1] sind hierbei u.a. auch Aspekte der Interprofessionalität und der Wissenschaftlichkeit abzudecken [2]. Das "Ergebnis" der Lehre an den medizinischen Fakultäten wird -auch zum Zweck eines nationalen Rankings -zuweilen an den studentischen Leistungen im schriftlichen Teil des Zweiten Staatsexamens abgeschätzt. Diese Prüfung bildet lediglich Faktenwissen ab und die aggregierten Examensleistungen bieten nur wenige Anhaltspunkte für konkrete Stärken und Schwächen einzelner Curricula. Somit benötigen die Fakultäten andere Datenquellen zur Beurteilung ihrer Lehrqualität. Hierzu werden in der Regel studentische Evaluationen durchgeführt. Hier können -je nach dem eingesetzten Erhebungsinstrument -bis zu vier Dimensionen der Lehrqualität abgebildet werden. Nach Gibson et al. werden diesbezüglich strukturelle und prozedurale Charakteristika der Lehre sowie die didaktischen Fertigkeiten der Lehrenden und der studentische Lernerfolg unterschieden [3]. Viele Evaluationsinstrumente legen ihren Fokus allerdings auf strukturelle und prozessbezogene Parameter [4] und erfragen in erster Linie die studentische Zufriedenheit mit der Lehre. Dabei ist bekannt, dass insbesondere Global-Bewertungen durch Studierende mannigfachen Störfaktoren (z.B. individuelle Charakteristika wie Geschlecht, Interesse am Thema, Leistungsniveau) unterliegen [5]. Eine solche Verzerrung der Evaluation ist problematisch, da die Ergebnisse an einigen Fakultäten als Grundlage einer Leistungsorientierten Mittelvergabe (LOM) für Lehre (LOM-Lehre) diskutiert werden. In der Forschung ist eine Leistungsorientierte Mittelzuweisung mittlerweile allgemein etabliert. Obwohl die Parameter und Algorithmen der Forschungsevaluation intensiv kritisiert werden [6], ist ein Ungleichgewicht zwischen Anreizen für gute Forschung und solchen für gute Lehre entstanden. Zwar fließen große Summen in die Grundausstattung der Lehre, die Lehrqualität wird bei der Ressourcen-Allokation jedoch häufig nicht ausreichend einbezogen. Dies hat zu Folge, dass sich in der Wahrnehmung vieler WissenschaftlerInnen Engagement in der Lehre weniger auszahlt als Engagement in der Forschung. Bislang fehlen umfassende Daten zu den Evaluationspraktiken und zur Gestaltung von LOM-Algorithmen in der Lehre für die deutschen medizinischen Fakultäten. Vor diesem Hintergrund haben sich die Arbeitsgemeinschaft der Wissenschaftlichen Medizinischen Fachgesellschaften e.V. (AWMF) und der Medizinische Fakultätentag (MFT) das gemeinsame Ziel gesetzt, die an den medizinischen Fakultäten in Deutschland gängigen Evaluationspraktiken zu analysieren. In dieser Arbeit werden die Ergebnisse einer an allen medizinischen Fakultäten Deutschlands durchgeführten Befragung vorgestellt. Es wurde ein standardisierter und im Vorfeld in einem mehrstufigen Verfahren pilotierter Fragebogen entwickelt. Der Fragebogen bildete in elf Abschnitten die folgenden Aspekte der Lehrevaluation und LOM-Vergabepraxis ab: Der Fragebogen enthielt vor allem Ja/Nein-Fragen, teilweise mit der Möglichkeit zu ergänzenden Freitextangaben. Vereinzelt wurden Zahlenangaben, etwa zum Umfang der Evaluationen, den Rücklaufquoten studentischer Evaluationen sowie zur Aufteilung der fakultären Landesmittel erbeten. Der Fragebogen wurde im Juli 2013 über die Geschäftsstelle des Medizinischen Fakultätentages allen medizinischen Fakultäten in Deutschland zugesandt. Die Fakultäten wurden um schriftliche Beantwortung durch die zuständigen Mitarbeiter sowie die Zusendung relevanter Materialien gebeten. Bei Nichtbeantwortung erfolgte eine Erinnerung Ende August, weitere fehlende Daten wurden im November und Dezember telefonisch erfragt. Der Fragebogen kann bei den Autoren angefordert werden.Tobias Raupach 1,5,6 
Christoph 
Herrmann-Lingen 7,8 

Einleitung 

Methoden 

1. Grundlagen der Evaluation, 
2. Gegenstände der Evaluation, 
3. an der Evaluation beteiligte Personengruppen, 
4. Regelmäßigkeit und Häufigkeit der Evaluation des 
Kerncurriculums, 
5. Format der Evaluation durch Studierende, 
6. Format der Evaluation durch Dozenten, 
7. inhaltliche Aspekte der Evaluation durch Studie-
rende, 
8. Nutzung objektiver Daten zu Qualitätssicherung und 
Evaluation, 
9. Aufbereitung und Verbreitung der Evaluationsergeb-
nisse, 
10. Konsequenzen der Evaluation, 
11. Mittelvergabe für die Lehre. 

Ergebnisse 

An der Befragung nahmen 30 deutsche medizinische 
Fakultäten mit insgesamt 33 Studiengängen (23 Regel-
studiengänge, 6 Modellstudiengänge, 3 reformierte Re-
gelstudiengänge, und 1 Studiengang für Molekulare Me-
dizin) teil (Rücklaufquote 83%). 
Die Ergebnisse werden im Folgenden orientiert an den 
Abschnitten des Fragebogens dargestellt. 



## Tabelle 1 :
1Aspekte, die mittels Lehrveranstaltungsevaluation durch Studierenden erfasst werden Abbildung 1: Prozentuale Verteilung der Landeszuführungsbeiträge an den Fakultäten Für die Verteilung der Landes-Zuführungsbeiträge liegen Antworten von 17 Fakultäten vor. Diese Daten sind in Abbildung 1 dargestellt. Deutlich wird hier, dass die drei wichtigsten Posten die allgemeine Grundausstattung der Lehrstühle sowie die curriculare Basisausstattung und die evaluationsbasierte Forschungs-LOM darstellen. Demgegenüber spielen diese Mittel für die Lehre ebenso eine untergeordnete Rolle wie antragsbasierte Forschungs-und Lehrförderung. Die evaluationsbasierte LOM-Lehre bildet mit durchschnittlich 1,6% (Minimum 0%, Median 3%, Maximum 6%) eher einen kleinen Teil der Landesmittel ab. Die LOM-Lehre folgt in gut 60% einem festen Algorithmus. Sie kommt mit knapp 70% insbesondere den Kliniken bzw. Instituten zugute, deutlich seltener kompletten Modulen (15%) oder Einzelpersonen (21%).Auszeichnungen als beste Dozentin bzw. bester Dozent 
oder ein Bonus bei Beförderungen erwähnt. Dagegen 
stehen bei 73% der Studiengänge Schulungs-und 
Unterstützungsangebote für Lehrende mit besonders 
negativen Ergebnissen zur Verfügung, gefolgt von per-
sönlichen Gesprächen (45%) und Effekten auf die LOM-
Lehre (21%). 

Mittelvergabe für Lehre 


/13 GMS German Medical Science 2019, Vol. 17, ISSN 1612-3174 Schiekirka-Schwake et al.: National survey of evaluation practices and performance-guided ...
Schiekirka-Schwake et al.: National survey of evaluation practices and performance-guided ...
Studiendekanat, Universitätsmedizin Göttingen, Deutschland setzten Erhebungsinstrumente erfassen vorrangig strukturelle und prozedurale Aspekte sowie einen Gesamteindruck der Lehre. Zwischen den Fakultäten herrscht bezüglich der verwendeten Instrumente eine 2 Präsidium, Medizinischer Fakultätentag, Berlin, Deutschland
Dekanat des Fachbereichs Medizin, Goethe-Universität Frankfurt, Deutschland
Dekanat der Medizinischen Fakultät, Ludwig-Maximilians-und reliabler Erhebungsinstrumente in deutschlandweiter Zusammenarbeit scheint erstrebenswert und würde eine Weiterentwicklung der gültigen LOM-Lehre darstellen.
AcknowledgementsWe thank the AWMF for financial support, the MFT office (Dr. Corinne Dölling) for logistical support, Mrs. Sabine Gluth for the completion and reporting of the survey data, 5Schlussfolgerung: Eine möglichst bundesweite Konsentierung eines Leitbilds guter Lehre sowie die Identifikation bzw. Entwicklung valider
E G Hahn, M R Fischer, Doc35. DOI: 10.3205/zma000627 2. Wissenschaftsrat. Empfehlungen zur Weiterentwicklung des Medizinstudiums in Deutschland auf Grundlage einer Bestandsaufnahme der humanmedizinischen Modellstudiengänge. DresdenWissenschaftsrat26Nationaler Kompetenzbasierter Lernzielkatalog Medizin (NKLM) für Deutschland: Zusammenarbeit der Gesellschaft für Medizinische Ausbildung (GMA) und des Medizinischen Fakultätentages (MFT)Hahn EG, Fischer MR. Nationaler Kompetenzbasierter Lernzielkatalog Medizin (NKLM) für Deutschland: Zusammenarbeit der Gesellschaft für Medizinische Ausbildung (GMA) und des Medizinischen Fakultätentages (MFT). GMS Z Med Ausbild. 2009;26(3):Doc35. DOI: 10.3205/zma000627 2. Wissenschaftsrat. Empfehlungen zur Weiterentwicklung des Medizinstudiums in Deutschland auf Grundlage einer Bestandsaufnahme der humanmedizinischen Modellstudiengänge. Dresden: Wissenschaftsrat; 2014.

Enhancing Evaluation in an Undergraduate Medical Education Program. K A Gibson, P Boyle, D A Black, M Cunningham, M C Grimm, H P Mcneil, 10.1097/ACM.0b013e31817eb8abAcad Med. 838Gibson KA, Boyle P, Black DA, Cunningham M, Grimm MC, McNeil HP. Enhancing Evaluation in an Undergraduate Medical Education Program. Acad Med. 2008;83(8):787-93. DOI: 10.1097/ACM.0b013e31817eb8ab

Evaluation in medical education: A topical review of target parameters, data collection tools and confounding factors. S Schiekirka, M A Feufel, C Herrmann-Lingen, T Raupach, 10.3205/000219GMS Ger Med Sci. 13Schiekirka S, Feufel MA, Herrmann-Lingen C, Raupach T. Evaluation in medical education: A topical review of target parameters, data collection tools and confounding factors. GMS Ger Med Sci. 2015 Sep 16;13:Doc15. DOI: 10.3205/000219

Evaluation of medical research performance -position paper of the Association of the Scientific Medical Societies in Germany (AWMF). C Herrmann-Lingen, E Brunner, S Hildenbrand, T H Loew, T Raupach, C Spies, R D Treede, C F Vahl, H J Wenz, 10.3205/000196GMS Ger Med Sci. 12Herrmann-Lingen C, Brunner E, Hildenbrand S, Loew TH, Raupach T, Spies C, Treede RD, Vahl CF, Wenz HJ. Evaluation of medical research performance -position paper of the Association of the Scientific Medical Societies in Germany (AWMF). GMS Ger Med Sci. 2014;12:Doc11. DOI: 10.3205/000196

A systematic review of factors influencing student ratings in undergraduate medical education course evaluations. S Schiekirka, T Raupach, 10.1186/s12909-015-0311-8BMC Med Educ. 1530Schiekirka S, Raupach T. A systematic review of factors influencing student ratings in undergraduate medical education course evaluations. BMC Med Educ. 2015 Mar 5;15:30. DOI: 10.1186/s12909-015-0311-8

Comprehensive evaluation of medical teaching --a task for the psychosocial disciplines?. U Berger, C Schleussner, B Strauss, Berger U, Schleussner C, Strauss B. [Comprehensive evaluation of medical teaching --a task for the psychosocial disciplines?].

. 10.1055/s-2003-36966Psychother Psychosom Med Psychol. 532Psychother Psychosom Med Psychol. 2003 Feb;53(2):71-8. DOI: 10.1055/s-2003-36966

Piloting an outcome-based programme evaluation tool in undergraduate medical education. T Raupach, S Schiekirka, C Münscher, T Beißbarth, W Himmel, G Burckhardt, T Pukrop, 10.3205/zma000814GMS Z Med Ausbild. 293Raupach T, Schiekirka S, Münscher C, Beißbarth T, Himmel W, Burckhardt G, Pukrop T. Piloting an outcome-based programme evaluation tool in undergraduate medical education. GMS Z Med Ausbild. 2012;29(3):Doc44. DOI: 10.3205/zma000814

The effect of timing on the validity of student ratings. S D Canaday, M A Mendelson, J H Hardin, 10.1097/00001888-197812000-00002J Med Educ. 5312Canaday SD, Mendelson MA, Hardin JH. The effect of timing on the validity of student ratings. J Med Educ. 1978 Dec;53(12):958- 64. DOI: 10.1097/00001888-197812000-00002

The relationship between student ratings of course effectiveness and student achievement. M A Mendelson, S D Canaday, J H Hardin, 10.1111/j.1365-2923.1978.tb00337.xMed Educ. 123Mendelson MA, Canaday SD, Hardin JH. The relationship between student ratings of course effectiveness and student achievement. Med Educ. 1978 May;12(3):199-204. DOI: 10.1111/j.1365- 2923.1978.tb00337.x

Curriculum development for medical education -A six-step approach. D E Kern, P A Thomas, D M Howard, E B Bass, Kern DE, Thomas PA, Howard DM, Bass EB. Curriculum development for medical education -A six-step approach.

. London Baltimore, The John Hopkins University PressBaltimore, London: The John Hopkins University Press; 1998.

Construct-irrelevant variance and flawed test questions: Do multiple-choice item-writing principles make any difference? Acad Med. S M Downing, 10.1097/00001888-200210001-0003277SupplDowning SM. Construct-irrelevant variance and flawed test questions: Do multiple-choice item-writing principles make any difference? Acad Med. 2002 Oct;77(10 Suppl):S103-4. DOI: 10.1097/00001888-200210001-00032

Construct-Irrelevant Variance in High-Stakes Testing. T M Haladyna, S M Downing, 10.1111/j.1745-3992.2004.tb00149.xEduc Meas. 231Haladyna TM, Downing SM. Construct-Irrelevant Variance in High- Stakes Testing. Educ Meas. 2005;23(1):17-27. DOI: 10.1111/j.1745-3992.2004.tb00149.x

Basic quantitative analyses of medical examinations. A Möltner, D Schellberg, J Jünger, GMS Z Med Ausbild. 23353Möltner A, Schellberg D, Jünger J. Basic quantitative analyses of medical examinations. GMS Z Med Ausbild. 2006;23(3):Doc53.

School-specific assessment in German medical schools. A Möltner, R Duelli, F Resch, J Schultz, J Jünger, 10.3205/zma000681GMS Z Med Ausbild. 273Möltner A, Duelli R, Resch F, Schultz J, Jünger J. School-specific assessment in German medical schools. GMS Z Med Ausbild. 2010;27(3):Doc44. DOI: 10.3205/zma000681

A qualitative study to investigate the acceptance of performance-based allocation of resources for the improvement of education at German medical schools. B Müller-Hilke, 10.3205/zma000680GMS Z Med Ausbild. 273Müller-Hilke B. A qualitative study to investigate the acceptance of performance-based allocation of resources for the improvement of education at German medical schools. GMS Z Med Ausbild. 2010;27(3):Doc43. DOI: 10.3205/zma000680

Performancerelated middle management in medical teaching. Attractiveness of incentive tools from the perspective of the teachers. M Hofer, M Pieper, M Sadlo, J Reipen, N Heussen, 10.1055/s-2008-1081141Dtsch Med Wochenschr. 133Hofer M, Pieper M, Sadlo M, Reipen J, Heussen N. [Performance- related middle management in medical teaching. Attractiveness of incentive tools from the perspective of the teachers]. Dtsch Med Wochenschr. 2008 Aug;133(31-32):1615-20. DOI: 10.1055/s-2008-1081141

Mehr Geld zur Lehre lenken. B Müller-Hilke, Leistungsorientierte Mittelvergabe, Dtsch Arztebl. 11050Müller-Hilke B. Leistungsorientierte Mittelvergabe: Mehr Geld zur Lehre lenken. Dtsch Arztebl. 2013;110(50):A 2418-20.

E G Hahn, M R Fischer, Doc35. DOI: 10.3205/zma000627 2. Wissenschaftsrat. Empfehlungen zur Weiterentwicklung des Medizinstudiums in Deutschland auf Grundlage einer Bestandsaufnahme der humanmedizinischen Modellstudiengänge. DresdenWissenschaftsrat26Nationaler Kompetenzbasierter Lernzielkatalog Medizin (NKLM) für Deutschland: Zusammenarbeit der Gesellschaft für Medizinische Ausbildung (GMA) und des Medizinischen Fakultätentages (MFT)Hahn EG, Fischer MR. Nationaler Kompetenzbasierter Lernzielkatalog Medizin (NKLM) für Deutschland: Zusammenarbeit der Gesellschaft für Medizinische Ausbildung (GMA) und des Medizinischen Fakultätentages (MFT). GMS Z Med Ausbild. 2009;26(3):Doc35. DOI: 10.3205/zma000627 2. Wissenschaftsrat. Empfehlungen zur Weiterentwicklung des Medizinstudiums in Deutschland auf Grundlage einer Bestandsaufnahme der humanmedizinischen Modellstudiengänge. Dresden: Wissenschaftsrat; 2014.

Enhancing Evaluation in an Undergraduate Medical Education Program. K A Gibson, P Boyle, D A Black, M Cunningham, M C Grimm, H P Mcneil, 10.1097/ACM.0b013e31817eb8abAcad Med. 838Gibson KA, Boyle P, Black DA, Cunningham M, Grimm MC, McNeil HP. Enhancing Evaluation in an Undergraduate Medical Education Program. Acad Med. 2008;83(8):787-93. DOI: 10.1097/ACM.0b013e31817eb8ab

Evaluation in medical education: A topical review of target parameters, data collection tools and confounding factors. S Schiekirka, M A Feufel, C Herrmann-Lingen, T Raupach, 10.3205/000219GMS Ger Med Sci. 13Schiekirka S, Feufel MA, Herrmann-Lingen C, Raupach T. Evaluation in medical education: A topical review of target parameters, data collection tools and confounding factors. GMS Ger Med Sci. 2015 Sep 16;13:Doc15. DOI: 10.3205/000219

Evaluation of medical research performance -position paper of the Association of the Scientific Medical Societies in Germany (AWMF). C Herrmann-Lingen, E Brunner, S Hildenbrand, T H Loew, T Raupach, C Spies, R D Treede, C F Vahl, H J Wenz, 10.3205/000196GMS Ger Med Sci. 12Herrmann-Lingen C, Brunner E, Hildenbrand S, Loew TH, Raupach T, Spies C, Treede RD, Vahl CF, Wenz HJ. Evaluation of medical research performance -position paper of the Association of the Scientific Medical Societies in Germany (AWMF). GMS Ger Med Sci. 2014;12:Doc11. DOI: 10.3205/000196

A systematic review of factors influencing student ratings in undergraduate medical education course evaluations. S Schiekirka, T Raupach, 10.1186/s12909-015-0311-8BMC Med Educ. 1530Schiekirka S, Raupach T. A systematic review of factors influencing student ratings in undergraduate medical education course evaluations. BMC Med Educ. 2015 Mar 5;15:30. DOI: 10.1186/s12909-015-0311-8

Comprehensive evaluation of medical teaching --a task for the psychosocial disciplines?. U Berger, C Schleussner, B Strauss, Berger U, Schleussner C, Strauss B. [Comprehensive evaluation of medical teaching --a task for the psychosocial disciplines?].

. 10.1055/s-2003-36966Psychother Psychosom Med Psychol. 532Psychother Psychosom Med Psychol. 2003 Feb;53(2):71-8. DOI: 10.1055/s-2003-36966

Piloting an outcome-based programme evaluation tool in undergraduate medical education. T Raupach, S Schiekirka, C Münscher, T Beißbarth, W Himmel, G Burckhardt, T Pukrop, 10.3205/zma000814GMS Z Med Ausbild. 293Raupach T, Schiekirka S, Münscher C, Beißbarth T, Himmel W, Burckhardt G, Pukrop T. Piloting an outcome-based programme evaluation tool in undergraduate medical education. GMS Z Med Ausbild. 2012;29(3):Doc44. DOI: 10.3205/zma000814

The effect of timing on the validity of student ratings. S D Canaday, M A Mendelson, J H Hardin, 10.1097/00001888-197812000-00002J Med Educ. 5312Canaday SD, Mendelson MA, Hardin JH. The effect of timing on the validity of student ratings. J Med Educ. 1978 Dec;53(12):958- 64. DOI: 10.1097/00001888-197812000-00002

The relationship between student ratings of course effectiveness and student achievement. M A Mendelson, S D Canaday, J H Hardin, 10.1111/j.1365-2923.1978.tb00337.xMed Educ. 123Mendelson MA, Canaday SD, Hardin JH. The relationship between student ratings of course effectiveness and student achievement. Med Educ. 1978 May;12(3):199-204. DOI: 10.1111/j.1365- 2923.1978.tb00337.x

Curriculum development for medical education -A six-step approach. D E Kern, P A Thomas, D M Howard, E B Bass, Kern DE, Thomas PA, Howard DM, Bass EB. Curriculum development for medical education -A six-step approach.

. London Baltimore, The John Hopkins University PressBaltimore, London: The John Hopkins University Press; 1998.

Construct-irrelevant variance and flawed test questions: Do multiple-choice item-writing principles make any difference? Acad Med. S M Downing, 10.1097/00001888-200210001-0003277SupplDowning SM. Construct-irrelevant variance and flawed test questions: Do multiple-choice item-writing principles make any difference? Acad Med. 2002 Oct;77(10 Suppl):S103-4. DOI: 10.1097/00001888-200210001-00032

Construct-Irrelevant Variance in High-Stakes Testing. T M Haladyna, S M Downing, 10.1111/j.1745-3992.2004.tb00149.xEduc Meas. 231Haladyna TM, Downing SM. Construct-Irrelevant Variance in High- Stakes Testing. Educ Meas. 2005;23(1):17-27. DOI: 10.1111/j.1745-3992.2004.tb00149.x

Basic quantitative analyses of medical examinations. A Möltner, D Schellberg, J Jünger, GMS Z Med Ausbild. 23353Möltner A, Schellberg D, Jünger J. Basic quantitative analyses of medical examinations. GMS Z Med Ausbild. 2006;23(3):Doc53.

School-specific assessment in German medical schools. A Möltner, R Duelli, F Resch, J Schultz, J Jünger, 10.3205/zma000681GMS Z Med Ausbild. 273Möltner A, Duelli R, Resch F, Schultz J, Jünger J. School-specific assessment in German medical schools. GMS Z Med Ausbild. 2010;27(3):Doc44. DOI: 10.3205/zma000681

A qualitative study to investigate the acceptance of performance-based allocation of resources for the improvement of education at German medical schools. B Müller-Hilke, 10.3205/zma000680GMS Z Med Ausbild. 273Müller-Hilke B. A qualitative study to investigate the acceptance of performance-based allocation of resources for the improvement of education at German medical schools. GMS Z Med Ausbild. 2010;27(3):Doc43. DOI: 10.3205/zma000680

Performancerelated middle management in medical teaching. Attractiveness of incentive tools from the perspective of the teachers. M Hofer, M Pieper, M Sadlo, J Reipen, N Heussen, 10.1055/s-2008-1081141Dtsch Med Wochenschr. 133Hofer M, Pieper M, Sadlo M, Reipen J, Heussen N. [Performance- related middle management in medical teaching. Attractiveness of incentive tools from the perspective of the teachers]. Dtsch Med Wochenschr. 2008 Aug;133(31-32):1615-20. DOI: 10.1055/s-2008-1081141

Mehr Geld zur Lehre lenken. B Müller-Hilke, Leistungsorientierte Mittelvergabe, Dtsch Arztebl. 11050Müller-Hilke B. Leistungsorientierte Mittelvergabe: Mehr Geld zur Lehre lenken. Dtsch Arztebl. 2013;110(50):A 2418-20.

. Humboldtallee. Korrespondenzadresse: Sarah Schiekirka-Schwake Studiendekanat38Universitätsmedizin GöttingenKorrespondenzadresse: Sarah Schiekirka-Schwake Studiendekanat, Universitätsmedizin Göttingen, Humboldtallee 38, 37073 Göttingen, Deutschland sarah.schiekirka-schwake@med.uni-goettingen.de

National survey of evaluation practices and performance-guided resource allocation at German medical schools. S Bitte Zitieren Als Schiekirka-Schwake, J Barth, J Pfeilschifter, R Hickel, T Raupach, C Herrmann-Lingen, 10.3205/000270URN: urn:nbn:de:0183-0002708GMS Ger Med Sci. 17Bitte zitieren als Schiekirka-Schwake S, Barth J, Pfeilschifter J, Hickel R, Raupach T, Herrmann-Lingen C. National survey of evaluation practices and performance-guided resource allocation at German medical schools. GMS Ger Med Sci. 2019;17:Doc04. DOI: 10.3205/000270, URN: urn:nbn:de:0183-0002708

. Artikel Online Frei Zugänglich, Unter, shtml Eingereicht: 02.08Artikel online frei zugänglich unter http://www.egms.de/en/journals/gms/2019-17/000270.shtml Eingereicht: 02.08.2018

. Veröffentlicht, 18.04.2019Veröffentlicht: 18.04.2019

. Copyright, Schiekirka-Schwake, Dieser Artikel ist ein Open-Access-Artikel. steht unter den Lizenzbedingungen der Creative Commons Attribution 4.0 License (NamensnennungCopyright ©2019 Schiekirka-Schwake et al. Dieser Artikel ist ein Open-Access-Artikel und steht unter den Lizenzbedingungen der Creative Commons Attribution 4.0 License (Namensnennung).

. 1612-3174GMS German Medical Science. 17GMS German Medical Science 2019, Vol. 17, ISSN 1612-3174

. Schiekirka-Schwake, Bundesweite Erhebung zur Lehrevaluation und Leistungsorientierten. Schiekirka-Schwake et al.: Bundesweite Erhebung zur Lehrevaluation und Leistungsorientierten ...