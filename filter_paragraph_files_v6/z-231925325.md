# Thank you for Attention: A survey on Attention-based Artificial Neural Networks for Automatic Speech Recognition

CorpusID: 231925325 - [https://www.semanticscholar.org/paper/274c50e6819d8654a6cdc918d2d6d3ad02ce6c23](https://www.semanticscholar.org/paper/274c50e6819d8654a6cdc918d2d6d3ad02ce6c23)

Fields: Engineering, Computer Science

## (s11) B. RNN-free Transformer-based models
Number of References: 3

(p11.0) In this section, we will discuss the literature where RNNfree self-attention models are used for streaming speech recognition. Self-attention aligner [60] which is designed based on the Transformer model proposes a chunk hoping mechanism to provide support to online speech recognition. Transformerbased network requires the entire sequence to be obtained before the prediction starts and hence, not suitable for online speech recognition. In [60], the entire sequence is partitioned into several overlapped chunks, each of which contains three parts belonging to current, past and future. Speech frames or encoder states of the current part are attended to provide the output predictions belonging to the corresponding chunk. The past and future parts provide contexts to the identification of the current part. After attending a chunk, the mechanism hops to a new chunk to attend. The number of speech frames or encoder states hopped between two chunks is same as the current part of each chunk. A similar method was proposed in augmented memory Transformer [61] where an augmented memory bank is included apart from partitioning the input speech sequence. The augmented memory bank is used for carrying the information over the chunks, specifically by extracting key-value pairs from the projection of concatenated augmented memory bank and the relevant chunk (including past, current and future parts).
