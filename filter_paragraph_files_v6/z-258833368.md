# Deep Learning Approaches to Lexical Simplification: A Survey

CorpusID: 258833368 - [https://www.semanticscholar.org/paper/a9429423352c9b15531d32a43b5cd560519a3214](https://www.semanticscholar.org/paper/a9429423352c9b15531d32a43b5cd560519a3214)

Fields: Computer Science, Linguistics

## (s3) Deep Learning Approaches
Number of References: 3

(p3.0) Prior to deep learning approaches, lexicon, rulebased, statistical, n-gram, and word embedding models were state-of-the-art for SG, SS, and SR. As previously mentioned, Paetzold and Specia (2017b) have provided a comprehensive survey detailing these approaches, their performances, as well as their impact on LS literature. The following sections provide an extension of the work carried out by Paetzold and Specia (2017b). We introduce new deep learning approaches for LS and begin our survey of the LS pipeline at the SG phase. The recent developments in the CWI step of the pipeline have been extensively surveyed by North et al. (2022b).
## (s6) Neural Regression Maddela and Xu
Number of References: 4

(p6.0) Word Embeddings + LLMs One of the most common approaches to SS and SR involves the use of word embeddings and LLMs. Seneviratne et al. (2022) filtered and ranked top-k=20 candidate substitutions based on the same combined score that they used for SG. It consisted of their MLM model's prediction score of the generated candidate together with the inner product of the target word's embedding and the embedding of the potential candidate substitution. These top-k=20 candidate substitutions were then subject to one of three additional ranking metrics. The first ranking metric (CILex_1) ranked candidate substitutions on their cosine similarity between the original sentence and a copy of the original sentence with the candidate substitution in place of its complex word. The second and third ranking metrics made use of dictionary definitions of the target complex word and its candidate substitutions. They calculated the cosine similarity between each embedding of each definition and the embedding of the sentence of the target complex word. Those with the highest cosine similarities between a). the definition of the target complex word and the definition of the candidate substitution (CILex_2), or b). the definition of the target complex word and the word embedding of the original sentence with the candidate substitution in place of its complex word (CILex_3), were used to determine the rank of each candidate substitution. They discovered that all three metrics produced similar performances on the TSAR-2022 dataset with CILex 1, 2, and 3 achieving acc@1 scores of 0.375, 0.380, and 0.386, respectively. Li et al. (2022) used a set of features taken from LSBert combined with what they referred to as an equivalence score. Equivalence score was created to gauge semantic similarity between candidate substitution and complex word to an extent that was more expressive than the cosine similarity between word embeddings. To obtain this equivalence score, they used a pre-trained RoBERTa LLM trained for natural language inference (NLI) which predicts the likelihood of one sentence entailing another. The model was trained on a multi-genre corpus with a MLM objective. The product of the returned likelihood of the original sentence with the candidate substitution preceding the original sentence and vice-versa equated to the equivalence score. Since Li et al. (2022) used the same method of SG as LSBert, having only changed their LLM to RoBERTa, they concluded that their system's superior performance was a consequence of its unique SR. They achieved an acc@1 of 0.659, whereas LSBert attained an acc@1 of 0.598 on the English TSAR-2022 dataset (Saggion et al., 2022).
## (s12) Discussion and Conclusion
Number of References: 2

(p12.0) Since the 2017 survey on LS (Paetzold and Specia, 2017b), deep learning approaches have provided new headway within the field. MLM is now the go to method for SG, with the majority of recent LS studies having employed a MLM objective. The casual language model: GPT-3, surpasses the performance of all other approaches when subjected to prompt learning, especially when an ensemble of prompts are taken into consideration (Table 3). The prediction scores of MLM or casual language modeling have replaced various SS and SR techniques. LS systems that employ minimal SS and no SR apart from ranking their LLM's prediction scores, have outperformed more technical, featureoriented, and unsupervised ranking methods (Table  3). However, an exception is made with regards to equivalence score (Li et al., 2022), which has been shown to be effective at SR.
