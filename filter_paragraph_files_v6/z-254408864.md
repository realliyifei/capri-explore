# A Comprehensive Survey on Multi-hop Machine Reading Comprehension Approaches

CorpusID: 254408864 - [https://www.semanticscholar.org/paper/bad1ea60373fc77c1ff82c5ff99f1fd38c972ae8](https://www.semanticscholar.org/paper/bad1ea60373fc77c1ff82c5ff99f1fd38c972ae8)

Fields: Computer Science, Linguistics

## (s0) INTRODUCTION
Number of References: 5

(p0.0) Machine reading comprehension (MRC) is one of the most important and long-standing topics in the Natural Language Machine reading comprehension (MRC) is one of the most important and long-standing topics in Natural Language Processing (NLP). MRC provides a way to evaluate an NLP system's capability for natural language understanding. An MRC task, in brief, refers to the ability of a computer to read and understand natural language context and then find the answer to questions about that context. The emergence of large-scale single-document MRC datasets, such as SQuAD [1], CNN/Daily mail [2], has led to increased attention to this topic and different models have been proposed to address the MRC problem, such as (Chen, Bolton, and Manning, 2016) Adriana Trigiani is an Italian American best-selling author of sixteen books, television writer, film director, and entrepreneur based in Greenwich Village, New York City. (2) Based on Trigiani's 2000 best-selling novel of the same name, the story is set in the actual Virginia town of Big Stone Gap circa 1970s. The first attempt to improve the simple single-hop MRC task happened with emerging of some datasets like TriviaQA [15] and NarrativeQA [16]. These datasets addressed more challenges by introducing multiple passages per each question and also presenting a more complex kind of questions that couldn't be answered with one single sentence. Although this kind of question was more complex than single-hop questions, they still could be answered by a few nearby sentences within one passage, which means they mostly do not need multi-hop reasoning. They are generally known as the multi-passage or multi-document dataset that
## (s10) â€¢
Number of References: 4

(p10.0) The NoOp module can be seen as a skip command. It is used to reduce computations when the controller decides no action is required. However, this system approaches question decomposition by having a decomposer model trained via human labels (Cao and Liu, 2021a). Figure 5: Architecture of Self-assembling MNM [18] ONUS: Perez et al. [27] proposed an algorithm for One-to-N Unsupervised Sequence transduction (ONUS) that map a complicate multi-hop question to some simpler single-hop sub-questions. Unlike other decomposition studies use a combination of hand-crafted heuristics, rule-based algorithms, and learning from supervised decompositions to decompose multi-hop question which require significant human effort, this model automatically learns to decompose different kinds of questions. The main idea has been shown in Figure 6. To decompose multi-hop question to simpler corpus , First some candidate sub-question from a simple corpus will be created by mining 10M possible sub-questions from Common Crawl with a classifier. It then trains a decomposition model on the mined data using Q and D with unsupervised sequence-to-sequence learning to map multi-hop questions to sub-question. With this idea, the model is able to train a large transformer model to generate decompositions and avoid heuristic/extractive decompositions.   RERC: Fu et al. [26] also handled multi-hop MRC with a focus on decomposing complicated questions into simpler ones. They proposed a three-stage Relation Extractor-Reader and Comparator (RERC) model. RERC is consist of 1) Relation Extractor to decompose the complex questions into simple sub-questions by automatically extracting the subject and key relations of the complex question, 2) Reader to find the answers to the sub-questions in turn by an advanced ALBERT model, and finally, 3) Comparator to perform the numerical comparison and summarizes all the answers to get the final answer ( Figure 9)
## (s13) Commonsense Algorithm consists of Commonsense Selection Representation to select useful relational knowledge paths and
Number of References: 5

(p13.0) Commonsense Model Incorporation to fill the gaps of reasoning between hops of inference using Necessary and Optional Information Cell (NOIC).  [29] QFE: Nishida et al. [30] proposed a model for explainable multi-hop QA named Query Focused Extractor (QFE) which is based on a summarization idea. They use the multi-task learning of the QA model for answer selection and QFE for evidence extraction.

(p13.1) QFE as the main part of this model adaptively determines the number of evidence sentences by considering the dependency among the evidence sentences and the coverage of the question. Unlike other approaches that extract each evidence sentence separately, QFE uses an RNN and attention mechanism to consider important information in the question and the relationships between sentences. This query-aware recurrent structure enables QFE to consider the dependency among the evidence sentences and cover the important information in the question sentence. In brief, the main goal of QFE is to summarize the context according to the question. Query-focused summarization is the task of summarizing the source document with regard to the given query. The multitask learning with QFE is general in the sense that it can be combined with any QA model. The overview of QFE is shown in Figure 11. is the current summarization vector, is the query vector considering the current summarization, is the extracted sentence, updates the RNN state. Figure 11: Overview of Query Focused Extractor at step t [30] TAP: Bhargav et al. [31] proposed a deep neural architecture, called TAP (Translucent Answer Prediction) cover of two main ideas: (1) Local Interaction: Each sentence should be understood in the context of its neighboring sentences and the question, (2) Global Interaction: A global (inter-passage) interaction among sentences must be identified and used for supporting facts. TAP is a hierarchical architecture that tries to capture the local and global interactions between the sentences and consists of two main parts: (Figure 12)
## (s28) Models Performance:
Number of References: 2

(p28.0) In this section we will show the performance of the models. This investigation is helpful in several ways; it will determine the stat-of-the-result, and also shows which models and techniques has achieved the best result. On the other hand, it can show the overall performance and effectiveness of each technique in multi-hop MRC To evaluate the results of the models we need to use the evaluation metrics of the datasets. HotpotQA [11] and Wikihop [55], are two populare datasets among the reviewed studies as it has been clear in Figure 46 in which shows the percentage of use of two datasets among the reviewed models from 2018 to 2022. Then they provide a proper situation for evaluating the model's performance. 
