# Prevention and Resolution of Conflicts in Social Navigation -a Survey

CorpusID: 235606440
 
tags: #Engineering, #Computer_Science

URL: [https://www.semanticscholar.org/paper/a768b58dbfe3d92399e8075863577f6fdf51ba11](https://www.semanticscholar.org/paper/a768b58dbfe3d92399e8075863577f6fdf51ba11)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | True |
| By Annotator      | (Not Annotated) |

---

Prevention and Resolution of Conflicts in Social Navigation -a Survey
ACMCopyright ACM2021. June 03-05. 2018

Reuth Mirsky 
Xuesu Xiao 
Justin Hart 
Peter Stone 
Reuth Mirsky 
Xuesu Xiao 
Justin Hart 
Peter Stone 
Prevention and Resolution of Conflicts in Social Navigation -a Survey

Woodstock '18: ACM Symposium on Neural Gaze Detection
Woodstock, NY; New York, NY, USAACM332021. June 03-05. 201810.1145/1122445.1122456ACM Reference Format:CCS Concepts: • Human-centered computing → Interaction design theory, concepts and paradigmsHCI theory, concepts and models• General and reference → Surveys and overviews• Computing methodologies → Mobile agentsCooperation and coordinationMulti-agent systems Additional Key Words and Phrases: Social Navigation, Mobile Robots, Human-Robot Interactions
One of the main goals of contemporary roboticists is to enable intelligent mobile robots to operate smoothly in shared human-robot environments. One of the most fundamental necessary capabilities in service of this goal is competent navigation in this "social"context. As a result, there has a been a recent surge of research on social navigation in general, and especially on how to handle conflicts between agents in social navigation. These contributions introduce a variety of models, algorithms, and evaluation metrics, however as this research area is inherently interdisciplinary, many of the relevant papers are not comparable and there is no shared standard vocabulary. The main goal of this survey is to bridge this gap by introducing such a common language, using it to survey existing work, and highlighting open problems. It starts by defining a conflict in social navigation, and offers a detailed taxonomy of its components. This survey then maps existing work into this taxonomy, while discussing papers using its framing. Finally, this paper propose some future research directions and open problems that are currently on the frontier of social navigation to help focus ongoing and future research.

# INTRODUCTION

Enabling autonomous robots to navigate in the presence of people and/or other robots has been studied for the past 70 years. Grey Walter built robotic "turtles" that could navigate on their own [161]. These robots, named Elmer and Elsie, were an exercise in minimalism and an attempt to demonstrate that a small number of brain cells could give rise to complex behaviors. They each consisted of "two miniature radio tubes, two sense organs, one for light and the other for touch, and two effectors or motors, one for crawling and the other for steering". Their power supply was a hearing-aid battery. Nevertheless, these robots could navigate freely in an enclosed space and change their trajectory in response to light and touch.

Modern mobile robots are much more sophisticated and complex. Most feature a variety of sensors, intricate steering systems, and several layers of hardware and software to control their movement. Despite these improvements, mobile robots are still not prevalent in our homes and offices. One of the main reasons for this deficit is that comprehensive autonomy is still achievable only in controlled environments and is usually constructed from hard-coded rules or learned from a relatively clean dataset [14,61,135]. Solving the problem of navigating in such a setting -in the presence of other robots or humans -is a complex, cross-disciplinary challenge with facets of robotics, artificial intelligence, engineering, psychology, biology, and other areas of study. As such, each of these communities has defined social navigation differently. In the multi-robot community [159] 1 social navigation usually refers to robot navigation in the presence of additional robots. In human-robot interaction (HRI), social navigation refers strictly to the task of navigating in a shared space with people. Rios-Martinez et al. [126] gave a compact description of socially-aware navigation: Socially-aware navigation is the strategy exhibited by a social robot which identifies and follows social conventions (in terms of management of space) in order to preserve a comfortable interaction with humans. The resulting behavior is predictable, adaptable, and easily understood by humans. This definition implies, from the robot's point of view, that humans are no longer perceived only as dynamic obstacles but also as social entities.

In the fully general social navigation setting, a social agent is an agent (either human or robot) that is aware of the objectives of others (human or robot) and considers them in its behavior, either by adjusting its policy or by indicating why it chose a potentially "anti-social" behavior. However, this general definition is quite broad, encompassing a wide variety of multi-agent navigation scenarios, including those that involve only robots. In practice, the term "social navigation" usually refers to a more human-centric perspective. Thus, this survey focuses on three requirements that separate "Human-centric Social Navigation" from more general social navigation. These requirements are:

(1) There exists an autonomously navigating agent. The agent has a specific, reachable navigational goal that it needs to reach.

(2) There exists one (or more) human or animals in the environment.

(3) The interaction takes place in a physical environment, either "in the wild", or in a specifically designed environment or lab.

Many papers have discussed challenges that occur when only one or two of these requirements are met. Teleoperation of robots is widely investigated within HRI, but it is not consistent with (1). The multi-agent systems (MAS) and distributed planning communities focus on constructing algorithms for multi-robot navigation, which do not meet requirement (2). Even within the HRI community, many works describe progress in social navigation in artificial settings or simulations rather than in real world environments, such that requirement (3) does not hold. Significant work has been done in the graphics community to model crowds and swarms, but these works also do not meet requirement (3).

Our main focus is on papers that meet all three requirements, but this survey also cites some papers in which not all of the above requirements hold, due to their contributions to our understanding of social navigation. In cases that the underlying scope of a paper is not fully aligned with this survey, we indicate in the first reference to that paper the requirements that do hold. For example, Walter [161] 1, 3 is a work in which there is an autonomous agent (R1) -a "turtle" that navigates in the wild (R3) but no human pedestrians are present (R2).

Even within the context of the three requirements discussed above, there are many behaviors by a robot that could be considered "social": following, giving navigational instructions, waiting in line, and more, as discussed later in this section. To limit the scope of this survey, we focus on one specific type of social interaction with people which requires the robot to reason about an encounter, specifically conflicts. When a robot is designed to carry a person's luggage and follow them, the task is a social navigation task in which the robot needs to detect the person, reason about the proper distance from them, and drive at a safe and comfortable speed. These challenges, however, are orthogonal to the challenge of avoiding conflicts with other pedestrians. A better understanding of conflicts in social navigation requires a definition of what a conflict is in this context: Definition 1. A conflict between a robot and other mobile robots or pedestrians is a situation in which if there is no change of direction and change in speed by at least one of the parties, they will collide.

By this definition not all conflicts end in a physical collision, but every collision is preceded by a conflict. In this survey, we define collision avoidance as "conflict resolution. " (See more on the meaning of resolution of conflicts in the next section.) Based on these definitions, the contributions of this survey are as follows.

(1) It surveys work in which the authors include conflicts in their models, and makes the distinction between research toward avoiding such conflicts altogether (prevention) and research that models response to such conflicts (resolution).

(2) It introduces a taxonomy of the attributes that vary between models and algorithms for conflict resolution and conflict prevention.

(3) Based on this taxonomy, it identifies the attribute values used in existing work and consolidates them into tables.

(4) It summarizes the current state of the art in conflict resolution and prevention in social navigation, including a practical checklist to follow when introducing a new contribution to social navigation research.

Previous papers have presented ideas that overlap those in this survey, but from different perspectives. There are numerous surveys on topics general to social interactive robots [37] 1,2 and to all sorts of navigation like path planning [11] 1 , vision for navigation [8,27] 1 , perception and semantics [41] and localization and mapping [24,39,132] 1,3 . There are also many surveys on social navigation that focus on elements such as joint or group navigation [67,99,121,165], giving navigational instructions [149,166] 1 , detecting dynamic objects [31,71] 1 , acting in human-like manner in social contexts such as waiting in line [104] 1, 2 or distributing flyers [131] 1, 2 , and other factors which are not discussed in this survey [119]; except in cases that are specifically in service to the purpose of assisting in detecting or avoiding conflicts. Here, we provide details on the major related surveys, both to provide a reference for readers who are interested in those different points of view and to define the scope of this survey.

Kruse et al. [78] 1, 2 highlight the rising interest in the topic of social navigation since 2000, and identify specific tasks and challenges that social navigation encompasses. Interest is still on the rise, which requires this survey to narrow focus somewhat as we update their coverage of the topic. Our focus is on the narrower topic of conflicts that arise between a robot and pedestrians. Hoogendoorn and Bovy [56] 2, 3 introduced a three-tiered model of navigation utility, decomposing it into strategic (high-level decision making), tactical (global navigation), and operational (local navigation and event handling) levels. This survey focuses mostly on the operational level: setting local goals and re-planning as needed. Recently, Gao and Huang [40] provided a review of scenarios, datasets, and methods used in social navigation. They discussed the main use-cases as being passing, crossing, overtaking, approaching, following, leading, accompanying, and combinations thereof. This survey's perspective is different in that it does not categorize papers according to the aim of the navigating parties, but rather according to situations in which these parties are (or will be) in conflict.

Charalampous et al. [18] present a survey in which they aim "to systemize the recent literature by describing the required levels of robot perception, focusing on methods related to a robot's social awareness, the availability of datasets these methods can be compared with, as well as issues that remain open and need to be confronted when robots operate in close proximity with humans." This survey extends their initial discussion on robot design for operating in close proximity with humans, or as we refer to it, robots in conflict situations. Specifically, we aim to provide basic definitions that will be used to standardize future works on the problem of robots that navigate in environments in close proximity with humans. López et al. [83] 1, 3 provide a survey on turn prediction, and how upper body kinematics can signal upcoming turns. In their survey, they identified that Gaze Yaw is the earliest predictor of walking turns, but that existing data does not support quantifying how much, and how reliably, timing and distance can be anticipated. In addition, Head Yaw was the most reliable kinematic variable for predicting walking turns from about 200ms away.

Their survey can inform the design of conflict resolution by enabling the robot to predict upcoming turns using these signals. Another recent survey focuses on the algorithmic requirements and methodologies of the navigating robot in a general social navigation context [97]. The survey by Xiao et al. [163] reviews methods that use machine learning techniques for the mobile robot navigation problem in general. It focuses on the comparison between machine learning and classical approaches in terms of their scope and performance on real-world navigation problems. In contrast, this survey is on social navigation, with the focus especially on prevention and resolution of conflicts, with any (learning or non-learning) methods. For a more general perspective on the current state of social navigation, Mavrogiannis et al. [91] identified the three broad categories of challenges that are being investigated: planning, behavior design, and evaluation. This survey is more specific to the context of conflicts in social navigation, and it drills down to provide an elaborate taxonomy of models and algorithms in such scenarios.

The remainder of this survey is organized as follows: Section 2 proposes a taxonomy for social navigation, identifying important factors of the social navigation problem. Sections 3 and 4 present a selection of relevant works that have contributed models and algorithms respectively. Section 5 focuses on the evaluation measurements used in social navigation and refers to some existing benchmarks. Finally, Section 6 highlights open problems in social navigation with respect to the proposed taxonomy and provides a checklist for researchers to consult when investigating a new social navigation problem.


# TAXONOMY

This section systematically lays out the taxonomy with which we survey each of the central elements of social navigation: models (Section 3) and algorithms (Section 4). We now detail the methodology of collecting papers for this survey. We started with existing surveys on social navigation [17,78] and we collected all of their references, as well as papers that cite these references using Google Scholar. To choose which papers to include, we used the scope specified in Section 1.

Overall, this survey contains 54 (out of 166) citations that do not share all three requirements, but that nonetheless provide some fundamental contribution to social navigation, or are surveys on topics relevant to social navigation. We iterated through this process of collecting papers that cite, and that are cited by, our current bibliography until doing so led to no new papers that meet all of our requirements. The only exceptions to this process were papers from the same group as other included papers, since they often publish more than one paper on the same project. In such cases, we survey both papers if they have some difference in their taxonomy values. Otherwise, we only report on the newest paper.

For each paper we discuss, we identify eight attributes as listed in Table 1. Below we discuss this list of attributes (in bold) and the values (in italics) they can take (we write in parentheses the shorthand version of the values as they appear in the tables in Sections 3 and 4). We acknowledge that not all papers can be situated precisely within this taxonomy. In these cases, or if the value is not stated in the relevant paper, we label the corresponding attribute with the value "None" or "Neither" (e.g., some of the papers do not provide any empirical analysis, and thus the experiment type attribute is None). This taxonomy is constructed with the goal of encompassing as much work as possible, such that any new contribution can be easily placed in a clear context. 


## Taxonomy Attributes and Values

Prevention vs. Resolution Prevention (P) / Resolution (R) / Both (B) / Neither (N). This attribute identifies work on planning ahead to avoid conflicts (Prevention) vs. work on solving conflicts when they are imminent (Resolution). Robot Role Reactor (R) / Initiator (I) / Both (B) / Neither (N). The robot can infer and react to the human's plan (Reactor) or it can actively influence the human's plan (Initiator). Some works try to compromise between the two (Both) and a few papers, such as human-only experiments, do not discuss a robot strategy (Neither). Number of Agents Absolute Number (Abs) / Density (D). Several papers deal with a one-on-one interaction and some deal with multiple agents in a shared space. We mention, when known, how crowded the environment is. Most works report either an Absolute Number of participants or a Density (measured as # / 2 ). When presenting an absolute number of pedestrians, we include the navigating robot in the count, so it can be compared with multi-robot research where the number of agents includes multiple robots that are running the same algorithm. Observability Full / Partial / Depth / RGB. If the work is set up in simulation, the robot can have either full or partial observability. Work that involves experiments or evaluations with real robots usually reports specific type(s) of sensors that were used, such as depth sensors (e.g. LIDAR), or cameras (e.g., RGB, or RGBD). If more than one type of sensor is used, we mention all of them. Motion Control SFM / ORCA / ROS / Human / Other. Most papers rely on an existing motion controller, and a robot is augmented with a new component for social navigation. This survey classifies the main types of motion control used in these papers: the Social Force Model (SFM), Optimal Reciprocal Collision Avoidance (ORCA), the ROS move_base navigation stack 1 (ROS), evaluation of human behavior without any existing robot (Human), and Other. The "other" category includes both papers in which the motion control is not significant or relevant (such as research projects that use cellular automata, point-based navigation, Dijkstra's algorithm, or other types of search for motion planning) or in which the motion control is novel and is a major part of the paper's contribution (such as Social Momentum [93] or LM-SARL [19]). We mark these cases as "other", but mention the specific motion control that is used when possible. Communication None (N) / Indirect (I) / Direct (D). This attribute refers to communication that is conveyed by the robot, and not to communication that is conveyed by the other agents. None means that the robot is not doing anything specifically to convey its navigational goal. Indirect communication refers to situations where the robot uses whatever mechanisms it already possesses to signal its intentions, such as legibility [30] 1 and stigmergy [7] 2 . Direct communication means that there is some mechanism that was added to the robot to allow communication. See Figure 1 for examples. Experiment Type Simulation (Sim) / In the Lab (Lab) / In the Wild (ItW) / Survey (Sur). Many researchers run experiments in Simulation as part of their evaluation, either as the only type of evaluation or in addition to real-world experiments. In the Lab experiments are defined as experiments in the real world in a controlled environment such as a lab or using a scripted scenario. In the Wild are real world experiments in an unstructured environment or with no predefined script for the pedestrians. All types of experiments can be accompanied by post-interaction Surveys. When a paper reports on more than one type of experiment, we include the details of one experiment, ordered in this prioritized order: In the Wild, In the Lab, simulation, survey (when it is the only methodology used). There are two exceptions to this policy: the first exception regards surveys, which are often used as an additional measuring technique for an experiment in the wild or in the lab. Hence, surveys can be mentioned together with another experiment type.The second exception regards papers that report two or more experiment types, where one of them is a small-scale in the wild, but do not report significant results for it. In such cases, we report the paper according to the experiment with reported results, but we add an uppercase + sign next to it (e.g., Lab + ). all (Human-Human) or that do not involve humans (Robot-Robot). Such papers are cited with the requirements notation presented earlier (e.g. citation 1 ) to highlight that one of our requirements for including a paper in this survey does not hold.

Some of the attributes and the values chosen to be presented here are not intuitive. Developing these ideas requires careful reasoning. Here, we discuss these ideas and explain their rationale. First, Prevention vs. Resolution is an important attribute, but it is non-trivial to classify a robot's behavior as being either "prevention" or "resolution."

On the one hand, it is clear that prevention and resolution are different tasks that can direct the robot's behavior.

With the definition of conflicts, the intuitive difference between resolution and prevention can be viewed as "how imminent the conflict is". On the other hand, formally defining the difference between these tasks can be elusive. Several papers identify a specific behavior that is unique to resolution of conflicts. Reynolds [124] defined "unaligned collision avoidance" as a scenario in which the agent "will steer laterally to turn away from the potential collision. It will also accelerate forward or decelerate backwards to get to the indicated site before or after the predicted collision". Park et al. [116] referred to a similar scenario: "The combination of speed reduction and the change of the heading direction is only used as a last resort when the pedestrians are too close to each other or when the pedestrian has winded far off the original path, and the angle to the destination is large enough such that side stepping is unnatural." This description is consistent with our definition of a conflict. However, there are some cases where the acting agent tries to cause the other party to change its behavior, so we extend this definition slightly: Resolution papers involve an action by the (2) virtual gaze [50]; (3) sensor rotation [35]; (4) arrow signaling [133] controlled party, with the intention to cause itself or the other party (1) a reduction in speed as well as (2) a change in heading. Papers on prevention, on the other hand, discuss navigational techniques that can be implemented from farther away which inform the local navigation process, such as a trajectory change that do not involve change in speed.

This description forms three different categories:

• If one of the parties uses both change of heading and change of speed, it is already in conflict.

• If one of the parties acts in a way that is meant to avoid the conflict, (which might be a change of heading, or a verbal cue for example) then this interaction is a resolution. • If one party acts in a way that no conflict emerges, then its behavior is considered prevention.

By way of example, consider a person walking in a crowded environment, looking at a phone. Without watching the crowds, two people might collide -which means they have reached a conflict. If the person looks up early enough, is might side-step abruptly without a change of speed -which means that a conflict was resolved. If the person decides to step away to a less crowded area, this behavior is considered prevention.

Observability is an important factor to consider, especially when discussing simulations, which will explicitly model the observations that can be made by agents acting in the scene. Many simulations assume that the robot (or pedestrians around it) has full (ground truth) observability. Other simulations restrict observability in an artificial way, to suit what a robot would realistically be able to sense (partial observability). In the discussion of these papers, it is important to keep in mind that these observation modalities may not be realistic to implement on real robots thus impacting how these contributions must be interpreted in the context of real-world embodied social navigation.

With respect to the Communication attribute, we make the distinction between communication that is indirect or direct and communication that is implicit or explicit. Implicit communication is often used to describe any non-verbal communication that is conveyed by people (the interpretation of eye gaze is implicit), and explicit communication is a verbal or written communication that is intended to influence others (e.g. speech is explicit) [25] 2, 3 . Because robots do not tend to naturally communicate implicitly (for example, not all robots have "eyes" and those that do do not necessarily need to turn them to "look" at something, and do not naturally turn them to where they are about to walk), we make the distinction between direct and indirect communication as defined above, and keep the implicit/explicit distinction as one reflective of mimicking human behavior. Using these definitions, the possible combinations for robot communication are: implicit-indirect (e.g., velocity change [157] 1 ), implicit-direct (e.g., gaze change on a virtual head [1]), and explicit-direct (e.g., arrow projections on the floor [162]).

Some papers present more than one set of experiments, for example, both Human-Robot in a lab study and Heterogenous agents in simulation. As this survey focuses on social navigation, we choose to highlight Human-Robot experiments.

Thus, in papers that present more than one set of experiments, for our Experiment Type and Agent Type attributes we choose the values that are relevant to the set of experiments which are the most similar to a Human-Robot interaction:

In the Wild > In the Lab > Simulation > Survey.

We would also like to highlight that some of the taxonomy attributes are very concrete and define low-level components used in the interaction (e.g. the motion control used), while other attributes are more abstract (e.g., prevention vs. resolution). Usually, the abstract attributes and their values depend on the concrete attributes. Figure 2 presents the hierarchical structure of these attributes, in work that is consistent with the three requirements outlined in Section 1. The bottom part represents the attributes that are independent of other attributes. The values assigned to the attribute at the end of an edge affect the values that can be assigned at the beginning. For example, the values of the Communication attribute will be directly affected by the Number of Agents in the environment and the robot's Observability. In turn, the choice of value for the Communication attribute directly affects whether the interaction will be Prevention vs. Resolution and the Agent Type which can perceive the communication channel chosen.


## Additional Concepts

There are some additional concepts that are worth mentioning, but which we decided to exclude from explicit inclusion in our taxonomy. As research and discussion on social navigation progresses, this taxonomy could be extended to include these attributes.

First, one seemingly-important factor to consider in the taxonomy is collision type. When referring to collisions, the majority of work mention head-on collisions or side collisions, while rear-end collisions are the least commonly investigated type. In the papers presented in this survey, there is not a single work that explicitly discusses only one type of collision; rather there are several papers that propose ways to categorize collisions according to the required response from pedestrians and / or the robot. Reynolds [124] defines two types of collisions: unaligned collision avoidance and separation. Unaligned collision avoidance is a behavior that "tries to keep characters which are moving in arbitrary directions from running into each other." Separation is similar to rear-end collision and refers to a simpler form of movement: "Separation steering behavior gives a character the ability to maintain a certain separation distance from others nearby." Mavrogiannis et al. [93] discuss the point in space and time where agents collide and call this point "entanglement. " This concept raises an additional question about the concrete implementation of this collision point - what's considered close enough to be an entanglement in a social context (e.g., Mavrogiannis et al. [92] segmented their experiments with ≤ 1 meter between the robot and the human). Thus, while it is simple to classify the direction of a collision, it is more challenging to define properly the minimal requirements of an encounter to be considered a collision. Is entering a person's personal space a collision? Is brushing against a leg? Overall, the definition for collision varies between researchers and may be a parameter that can be adjusted.

Another common discussion point is context awareness and semantic mapping. Many papers discuss the need for mobile social robots to be aware of their context [18]. A leading approach to enable this is semantic mapping, where the robot constructs maps that represent not only a metric occupancy grid but also other properties of the environment [74] 1, 3 . This survey does not focus on the mental model of the navigating robot (or of the other agents) in the environment, so this is not included in the taxonomy. It is, however, an important factor to consider when designing a robot for social navigation, as context awareness could greatly influence a robot's behavior.

Another thing to consider when designing the interaction between a mobile robot and pedestrians is how people react to humans vs. robotic counterparts. Will a human interaction with another human produce a similar or different response from an interaction with a robot? The assumption that people will behave in the same way when encountering a robot as they would another human is common in HRI and other research communities, although it is not unanimously agreed upon. In their survey on proxemics for social navigation, Rios-Martinez et al. [126] stated that "This article starts from the idea that people will keep the same conventions of social space management when they interact with robots than when they interact with humans. Researchers in social robotics that believe in that hypothesis can rely on the rich sociological literature to propose innovative models of social robots." As a counter opinion, Butler and Agah [10] have identified that people feel comfortable when a robot moves in speeds that are between 0.254 / and 0.381 / , while a normal walking speed for young human is about 1 / . This difference in speed suggests that people prefer a robot that moves more slowly than people do. Until there is a clear theory regarding the reactions of people to other people vs. robots in social navigation -and until that theory is tested -it is reasonable to exclude assumptions regarding whether people react to robots similarly or differently from how they react to other people from this taxonomy.

The distinction between social cues and social signals is useful and will be used in our discussions in the next sections, but is not included as an attribute in the taxonomy. How a robot can best communicate with humans is a rich and versatile research area; and is taken into consideration through observability and communication in the taxonomy. To discuss such communication more accurately, we make the distinction between cues and signals [160] 2,3 . Cues are the low-level inputs that the robot can receive or send, such as gaze, position, language, etc. Signals, on the other hand, are emotions, personality, and other traits that are more high-level. Signals discussed in the context of social navigation usually serve a purpose in conflict resolution, and the way to implement them in a robot (or detect them in a human) is through social cues.

One attribute that is relevant in a broader context than social navigation is focused vs. unfocused interaction.

Goffman [45] 2, 3 defines these terms to categorize scenarios in which the robot and the human share their focus (shared attention) vs. scenarios in which the robot and the human share an environment, but not attention. Rios-Martinez et al. [126] use this attribute to identify different types of navigational behaviors in robots: minimizing probability of encounter, avoiding collisions, passing people, staying in line, approaching humans, following people, and walking side-by-side. Because the papers in this survey revolve around conflicts, the robot and the human do not share focus, and hence all included papers involve strictly unfocused interactions. Focused vs. unfocused interaction are not considered as part of the taxonomy.

Lastly, the topic of differences in navigation with independent pedestrians vs. groups vs. crowds has enjoyed recent popularity [47,101,165]. Most social navigation papers either consider interactions with a single individual or with a crowd of individuals (as defined as Number of Agents in our taxonomy). An early sociological study showed that people tend to move in small groups rather than alone, but that the group size distribution highly depends on context (a casual Saturday afternoon stroll vs. a workday morning commute) [23] 2,3 . Recent research has demonstrated that in many contexts, more than 50% of pedestrians are not travelling alone, but in groups [99] 2, 3 . Thus, the context in which navigation takes place determines whether it is necessary to consider a surrounding crowd.


# MODELS

This section details various models used for social navigation. The discussion is grouped according to three main underlying models: Multiagent systems, human-inspired models, and physics-based models (specifically, the social force model and other force modelling). Each of these categories represents a different set of assumptions -as well as a different research community -that each model stems from. Navigation in multiagent systems is usually designed with the premise that agents navigating in an environment are homogeneous. These papers include multi-robot navigation models and crowd modelling. Thus, a social navigation model that aims to build on this work would be required to reason about agents with different, sometimes unknown, behaviors. Other models are inspired from insights about human navigation. These papers provide measurements and rules that explain how people navigate amongst themselves, and a social navigation model is required to translate these rules into robot motion and perception. We specify papers leveraging the social force model as a separate category that is inspired from the physical modelling of forces. Many models have been proposed which build upon the seminal work by Helbing and Molnar [53] 2, 3 with additional types of forces. Finally, some of the papers sit at an intersection between two categories. In these cases, the work is categorized according to the type of motion control associated with the chosen model, such that it is grouped with work that uses similar motion control.   


## Psychology and Human-Inspired Models

The contributions discussed so far have focused on multiagent or multi-robot navigation systems that have been adapted to accommodate human pedestrians. A different approach starts with the modelling of human behavior, which then leverages these models for improving robot navigation. Cutting et al. the angle between one's gaze and one's direction of movement -which can be used to estimate where a collision might occur. As a different way to estimate the expected collision point, Carel [12] defined to be the time to bypass a dynamic obstacle (human or not). Moussaïd et al. [98] use to heuristically plan how to navigate in a way that avoids collisions. Park et al. [116] claim that GMA-based collision prediction has several advantages over the time-to-contact ( ) approach. It is more robust to variations in the speed and the path of the other pedestrian. It also does not assume either constant speed or a linear path, so the accuracy of the prediction is not affected by these variations. Kitazawa and Fujiyama [73] investigate the Information Process Space (IPS) of a navigating person when walking in a hallway in the presence of static objects and other pedestrians. In this work, they identify the area that the observing pedestrian considers as the one in which a collision with another pedestrian could occur in a short time (see Figure 3). For example, Park et al. [116] propose a collision avoidance behavior model that is based on their empirical results about IPS to generate more human-like collision avoidance behaviors.

Another concept from psychology that has had a significant impact on social navigation is that of personal space [42,49,57]. While the original formulation of personal space is depicted by Hall [49] 2, 3 as a concentric circle, later work extends that to an egg shape [51] 2, 3 , ellipse [53], or as asymetrical (smaller on the dominant side) [42] 2, 3 .

Closely related to personal space is the concept of density in crowds. The average density of people in a non-crowded environment has been evaluated to be 0.03 pedestrians per 2 ; whereas in a moderately crowded environment, there are 0.25 pedestrians per 2 [99]. Rios-Martinez et al. [125] incorporate both personal space and IPS-based constraints into an adaptive optimization algorithm to enable more human-like navigation. Truong and Ngo [154] propose a comprehensive framework that reasons about pedestrians' extended personal space and the social interaction space to identify a Dynamic Social Zone (DSZ); a concept which is incorporated into their motion planner.  


## Physics-based Model

Researchers have also used models inspired by physics to represent the dynamics and interactions among different moving agents. Helbing and Molnar [53] were the first to propose the Social Force Model (SFM), a model inspired by fluid dynamics that describes an agent's motion using a set of repelling and attracting forces. They evaluate this model in a simulation of homogeneous SFM-based agents. Many contributions extend the SFM models to handle additional forces: Karamouzas et al. [64] add an evasive force that uses collision prediction and avoidance, which makes agents more proactive and anticipatory than the classical SFM. Moussaïd et al. [99] propose several group-related forces that help model pedestrians that walk in a group, and Swofford et al. [144] 2, 3 use a Deep Affinity Network (DANTE) to predict the likelihood that two individuals in a scene are part of the same conversational group, with consideration for Fig. 3. Information Process Space -the visual processing coverage of pedestrians, as measured by [73] and depicted by Rios-Martinez et al. [126].  [143]. This model has been leveraged in a modified Rapidly-exploring Random Tree (RRT) for navigation in human environments, though it assumes access to full state information. Table 4 summarizes the taxonomy values for models inspired by physics and mechanical engineering research.


# ALGORITHMS

This section discusses contributions in the form of algorithms and hardware augmentations that enhance social navigation. Most of the work presented here fits our basic definition of social navigation, however several are included which have not been evaluated in the context of navigating around people. These papers are included if their contribution can be applied in the context of social navigation. Broadly speaking, this section is divided into three main approaches:

Approaches that infer the human's trajectory and adapt to it; Approaches that convey the goal or trajectory of the robot to the person it is interacting with before reaching a conflict; and mixed approaches which mediate between the inferred trajectory of the human and the desired goal of the robot.


## Inferring Human Trajectories

Many social navigation contributions have been inspired by the way the humans navigate in social contexts. The majority of these papers can be split into two categories: online and offline inference. Online inference means that a robot observes the behavior of a person during deployment and incorporates its inference about the person's planned trajectory into its execution. Offline inference happens prior to the execution stage, usually on more than a single trajectory. The robot learns to predict human trajectories or imitate them from a set of observed trajectories. Offline inference does not happen in real-time and usually reasons about more than one trajectory during the learning phase. where the robot follows the current location of the person; and path-following, where the robot tries to follow the exact path that the person took. They show that while no significant difference was found between the two approaches in terms of the distance or time between tracking errors, participants rated the robot's behavior as significantly more natural and human-like in the direction-following condition. In addition, participants felt that the direction-following robot's behavior is more similar to the participants' expectations.

Others have leveraged human gaze to infer the trajectory of pedestrians. Gaze is a very strong communicative cue used by human, in the context of collaborative settings in general [15] 2, 3 and for navigation in particular [2]. It has been shown that not only people can partially understand gaze cues from very young age, but also chimpanzees and dogs [120,140]  [139] 2, 3 extend their work to a varying number of moving pedestrians. Of course, this gaze behavior extends beyond walking and bicycling. Recent work has studied the use of gaze as a modality for plan recognition in games [137] and as a cue for interacting with copilot systems in cars [58,59], also with the aim of inferring the driver's intended trajectory.

Gaze is also often fixated on objects being manipulated, which can be leveraged to improve algorithms which learn from human demonstrations [128]  with the robot reacting to human gaze. Ratsamee et al. [122] propose to avoid collisions with humans by considering a social model that takes into consideration body pose and face orientation.


### Offline Inference and Learning .

While the previous subsection focused on the recognition of human's trajectories during execution, some leverage these trajectories to learn and infer how a human would react in a social navigation interaction. Pacchierotti et al. [113] design a rule-based strategy for people passing that was inspired by spatial behavior studies. This strategy intends to mimic the way people avoid collisions once inside a person's personal space.

One such successful approach uses Inverse Reinforcement Learning (IRL) to elicit the explicit cost representation to imitate human's social navigation behavior. Instead of hand-crafted functions, these papers use IRL to leverage data-driven approaches. IRL was extensively used to infer reward (cost) functions from human demonstrations. The most straight forward application of IRL is by Kim and Pineau [69], to learn a cost function that respects social variables over features extracted from a RGB-D sensor. This work used IRL to infer cost functions in a social navigation context: navigational features were firstly extracted from an RGB-D sensor, then represented as a local cost function learned from a set of demonstration trajectories by an expert using IRL. The system still operated under the classical navigation pipeline, with a global path planned using a shortest-path algorithm, and local path using the learned cost function to respect social variables. Obstacle avoidance was still handled by a low-level controller. Okal and Arras [112] tackle cost function representation at a global level in social context: they developed a graph structure and used Bayesian IRL to learn the cost for this representation. With the learned global representation, traditional global planner (A*) planned a global path over this graph, and POSQ steer function for differential-drive mobile robots served as a local planner.

Henry et al. [54] use Inverse Reinforcement Learning to learn motion patterns of humans in simulation that can later be used for planning in social navigation.

An alternative approach to IRL with a similar objective is to model social navigation trajectories using a Maximum Entropy Probability Distribution, where cost is also implicitly defined by identifying an underlying model from demonstrated data. Maximum entropy probability distribution has been used by Pfeiffer et al. [118] to model agents' trajectories for planning and by Kretzschmar et al. [75] to infer the parameters of the navigation model that matches the observed behavior in expectation. Kuderer et al. [79] also use human demonstrations, but instead of using a Markov Decision Process, they elicit features from the human trajectories, and then use Entropy maximization for choosing the robot's behavior. Luber et al. [87] use unsupervised learning from surveillance data to learn motion patterns and augment this knowledge to a motion planner.

Sisbot et al. [138] create a human aware motion planner (HAMP) that is explicitly given a cost model for safety and for legibility, and the robot reasons about the joint cost of these two properties in its planning process. Cost were also implicitly defined by identifying an underlying model from demonstrated data. Kirby et al. [70] model human social conventions at the global planning stage. This trait enables it to mediate between different, sometimes conflicting objectives. For example, consider a goal that is down an intersecting hallway to the robot's left. While the social norm in many places is to pass a pedestrian from the right side, the robot may choose to walk across the hallway in front of a oncoming person, effectively passing them on the left of the corridor. This behavior is the result of mediating between two objectives: complying with the right-alignment social norm, and minimizing the time to the goal.

Many algorithms use hand-crafted behaviors to resolve and prevent conflicts, i.e. to realize collision avoidance. As a continuation of previous Collision Avoidance Deep Reinforcement Learning (CADRL) work [21], Chen et al. [20] further propose a hand-crafted reward function to incorporate the social norm of left or right-handed passing in a DRL approach and enabled a physical robot to move at human walking speed in an environment with many pedestrians, called Socially Aware CADRL (SA-CADRL). Within the same line of research, but to relax the assumption of other agents' dynamics, Everett et al. [32] propose GA3C-CADRL to use LSTM to allow reasoning about an arbitrary number of nearby agents and GPU to maximize the number of training experiences. Similarly, the reward function by Jin et al. [60] contain ego-safety to measure collision from the robot's perspective and social-safety to measure the impact of the robot's actions on surrounding pedestrians. Other options that utilize DRL include using a Hidden Markov Model (HMM) in a higher hierarchy to learn to choose between target pursuing and collision avoidance trained by RL [29]. Tai et al. [147] use Generative Adversarial Imitation Learning (GAIL) to learn continuous actions from depth image and desired force toward the target. This improved safety and efficiency upon pure BC. Li et al. [80] propose a new problem, Socially Concomitant Navigation (SCN), in addition to collision avoidance in traditional social navigation: the robot also needs to consider the motion of its companion so as to maintain a sense of affinity when they are traveling together towards a certain goal. Taking features extracted from a LiDAR sensor along with the goal as input, a navigation policy is trained by Trust Region Policy Optimization (TRPO) to output continuous velocity commands for navigation. Bera et al. [6] create SocioSense, a social navigation algorithm that categorize pedestrians according to psychological traits (e.g. shy, tense) and adjusts the robot's velocity according the the pedestrians around it. Lu et al. [86] incorporated a dynamic measure into their reward to reason about the density of the crowd when deciding on the distance from other pedestrians. They then extended the deep neural network architecture from SARL [19] to choose the optimal action with the shaped reward that reasons about the "uncomfortable distance" between the robot and a pedestrian.

To observe social rules when navigating in densely populated environments, Yao et al. [165] propose to utilize information about social groups to address the naturalness aspect from the perspective of collective formation behaviors in the complex real world. They used a deep neural network, called Group-Navi GAN, to track social groups and navigate the robot to join the flow of a social group through providing a local goal to the local planner. Other components of the existing navigation pipeline, e.g. state estimation, collision avoidance, etc., were still functioning as is. The classical navigation pipeline, with the assistance of a learned local goal, was capable of navigating safely in a densely populated area following crowd flows to reach the goal. Liang et al. [81] develop CrowdSteer, a RL-based collision-avoidance algorithm that navigates in dense and crowded environments. The algorithm is trained using PPO in simulation with simulated human agents, and was deployed in the real-world. Martins et al. [90] propose ClusterNav, an algorithm that gets human demonstrations using teleoperation, then uses Expectation Maximization to learn how to navigate in an unsupervised manner. Their approach cannot reason about dynamic obstacles, hence it is unable to reason about interactions with people during navigation so it does not appear in our tables. Table 5 summarizes the taxonomy values for the inference algorithms for social navigation discussed in this subsection. Dragan et al. [30] formally define the concepts of legibility (motion that allows the observer to confidently infer the correct goal) and predictability (motion that conforms with the observer's expectations) in robot navigation. They


## Conveying the Robot's Goal to the Human

show that human-robot collaboration is affected by the way the robot plans its motion, and to perform better, the robot design should switch from a focus on predictability to a focus on legibility. This section presents several approaches to increase the robot's legibility and explicability, with an emphasis on interaction points where there is a conflict between the human pedestrian and the robot. More details about the specific mechanisms that are activated in humans when interacting with a robot can be found by the work by Sciutti et al. [129], who survey the concept of "motor resonance" between an acting robot and an observing human. Kitagawa et al. [72] recently presented a motion planning algorithm for omni-directional robots to resemble human movements in a time-efficient manner.

Many contributions use verbal signals for guidance [149]. Jeffrey and Mark [57] investigate human navigational behavior in the context of two simulated environments. In these simulations, people could communicate using either text messages or audio. Yedidsion et al. [166] investigate how verbal instructions given by more than one robot can assist humans in navigation in a new environment. However, for the social navigation task, verbal communication is considered less useful, as the navigation is expected to take place seamlessly without demanding the high awareness level that verbal communication requires [16]. To deal with this challenge, many contributions take inspiration from the theory of proxemics [49] as a non-verbal way to convey intent or restriction. Rios-Martinez et al. [126] investigate the comfort zone of people when a robot approaches them and Torta et al. [151] identify specific values for this comfort zone (182 cm from a sitting person and 173 cm from a standing person) or imitate them from a set of observed trajectories, and uses the learned model for online planning. LED and Artificial Signals Baraka and Veloso [4] use an LED configuration on their CoBot to indicate a number of robot states -including turning -focusing on the design of LED animations to address legibility. Their study shows that the use of these signals increases participants' willingness to aid the robot. Shrestha et al. [133] augment their robot with projection indicators to signal the robot's intented path. Szafir et al. [146] equip quad-rotor drones with LEDs mounted in a ring at the base, providing four different signal designs along this strip. They found that their LEDs improve participants' ability to quickly infer the intended motion of the drone. Shrestha et al. [134] perform a study in which a robot crosses a humans' path, indicating its intended path with an arrow projected onto the floor. They demonstrate their method to be effective in expressing the robot's intended trajectory. Fernandez et al. [33] introduce the concept of a "passive demonstration, " in order to disambiguate the intention of a robot's LED turn signal. Watanabe et al. [162] evaluate a robotic wheelchair that autonomously navigates the environment with and without intention communication.  [156] found that head pose is a significant predictor of the direction that a person intends to walk.

Following a similar line of thought, Khambhaita et al. [68] propose a motion planner which coordinates head motion to the path a robot will take 4 seconds in the future. In a video survey in which their robot approaches a T-intersection in a hallway, they found that study participants are significantly more able to determine the intended path of the robot in terms of the left or right branch of the intersection when the robot uses the gaze cue as opposed to when it does not. Using a different gaze cue, Lynch et al. [88] 1, 2 perform a study in a virtual environment in which virtual agents establish mutual gaze with participants during path-crossing events in a virtual hallway, finding no significant effect in helping participants to disambiguate their paths from those of the virtual agents.

Fiore et al. [35] propose an analysis of human interpretation of social cues in hallway navigation. Their study design included different proxemic and gaze cues that were implemented by rotating the sensors of the robot. Their results

show that cues associated with the robot's proxemic behavior were found to significantly affect participant perceptions of the robot's social presence while cues associated with the robot's gaze behavior were not found to be significant.

However, Fernandez et al. [33] show that people are able to adapt to LED-based cues after watching a demonstration of its use, and May et al. [94] present a robot that was able to convey their intention using a mechanical signal but not using a gaze cue. Hart et al. [50] challenge these previous results by providing a different naturalistic gaze cue using a virtual agent head which is added to a mobile robot platform, and compared its performance against a similar robot with an LED turn signal. The results of this work suggest that people are able to perceive the naturalistic gaze cue and react to it. These conflicting results can be attributed to the vast differences in signal implementation between the different experiments. Table 6 summarizes the taxonomy values for algorithms that focus on conveying the robot's intention to a human.


## Mediating Conflicts in Navigational Intentions

Karamouzas et al. [65] identify a power-law interaction that is based not on the physical separation between pedestrians but on their projected time to a potential future collision, and is therefore fundamentally anticipatory in nature. This finding highlights that there is a value in understanding and mediating between the human's navigational goal and the robot's. Murakami et al. [102] propose to smooth a wheelchair's trajectory to avoid colliding with pedestrians. Kruse et al. [76,77] investigate classic navigation algorithms that create erratic trajectories near obstacles that make a robot look confused. To address this challenge, they use context-dependent cost functions and directional cost functions that help a robot to solve spatial conflicts. One result, for example, is adjusting the robot's velocity instead of its path. Silva and

Fraichard [136] tackle the mediation problem using the notion of motion effort and how it should be shared between the robot and the person in order to avoid collisions. To that end their approach learns a robot behavior using Reinforcement

Learning that enables it to mutually solve the collision avoidance problem during our simulated trials. Svenstrup et al. [143] propose a modified RRT for navigation in human environments assuming access to full state information. The proposed RRT planner plans with a potential field representation of the world, with a potential model designed for moving humans. Alternatively, recent work by Truc et al. [153] focused on drone navigation around people. This work introduced a human-aware 3D reactive planner for drone navigation. This planner is based on stochastic optimization of two criteria: discomfort due to the proximity of the drone to pedestrians, and visibility of the drone.

A different line of research combines social navigation and person following. This combination can work in several directions: both Müller et al. [100], Topp and Christensen [150] present collision avoidance algorithms that are utilized in the context of following one particular person through a populated environment. Alternatively, in Yao et al. [165], the robot leverages the planning of other pedestrians and follows them instead of searching for a solution on its own. Table 7 summarizes the taxonomy values for mediation algorithms for social navigation discussed in this subsection.


# EVALUATING AN INTERACTION

The numerous different metrics and evaluation methods used in social navigation make apparent the need to standardize them. This section is meant to provide tools and metrics to evaluate new research in social navigation with respect to the existing literature and with our proposed taxonomy to provide context for evaluation. As we are surveying an interdisciplinary area, many of the metrics used so far for evaluation were adapted from other research areas (e.g.,

Human-Computer Interfaces, psychology, physics, mechanical engineering, and more). To pinpoint the most common and useful metrics, we discuss only the metrics that were used in the papers that were presented in the tables in Sections 3 and 4. For each metric we present, we mention the taxonomy attributes that are the most relevant and can directly affect the values of the metric. For example, measuring group formation directly depends on the Number of Agents in the environment, since if there is only one pedestrian it cannot form a group. Table 8 summarizes this evaluation according to the different aspects of the interaction: Properties of the interaction itself, actions taken by the human or the robot, emergent behaviors, algorithmic properties, and other. This last aspect includes both qualitative evaluation and prediction accuracy, which is a very common metric to estimate the proficiency of obstacle detection, a preliminary step before the actual interaction.


## Interaction Properties

This subsection discusses measurements that are related to the nature of the interaction itself, and are meant to evaluate how successful and efficient an interaction is. These metrics are objective, and external to the robot and the human.

Conflicts Count is one of the most common approaches to estimate the success of an interaction. This measurement is quantified in several ways: by counting desirable outcomes vs. undesirable outcomes, by counting accidents, or by counting interactions that ended without the robot reaching its goal. In this category we also consider experiments that counted how many times the robot was required to replan [100] and how many targets it was able to reach in total [48].

What consists of a desirable outcome varies between researchers. For example, whether the goal of an algorithm is conflict Prevention vs. Resolution will determine whether a situation where the robot slowed down and changed its heading direction is a successful interaction. For prevention, reaching such a conflict is a failure; for resolution it is just the beginning of the interaction. This measure is also affected by the Number of Agents, the Experiment Type, and the evaluated Agent Type. textit is another very common metric used to evaluate an interaction. In general, faster velocities imply that the robot was able to navigate confidently without slowing down. Many researchers used this metric as a complementary one for conflicts count, to account for cases such as a robot that can reach its goal quickly, but will collide walls most of the times. As a reference point, the robot's speed is usually compared to the average speed of pedestrians (1.3 ± 0.2 m/s), but this value depends on whether they walk alone or in a group, as group size affects speed more than density level [99]. Gérin-Lajoie et al. [42] measured similar results for natural walking around dynamic obstacles (1.44 ± 0.17 m/s).

Accordingly, this measurement is greatly affected by the Robot's Role in the interaction, the Number of Agents, the Experiment Type, and the Agent Type. Path Time is a way to measure the velocity of the robot throughout a full interaction. As the robot might accelerate or decelerate, recording the total time that it took the robot to reach its goal is a simple way to measure its performance.

One unique metric that is also relevant to throughput is "Social work", defined by Ferrer et al. [34]. This metric measures the total work done by the robot, and the summation of the work done by each person in the scene. Kanazawa et al. [62] looked at the total waiting time that the robot had experienced during the interaction. This measure depends on the Robot's Role, the Number of Agents in the environment, and the Experiment Type.

Path Length provides another perspective about the interaction, and is correlated with speed and path time: by counting any two of these three metrics (Speed, Path Time, and Path Length) you can get a reasonable estimation of the third. As such, this metric is also affected by the same attributes as the other two metrics: the Robot's Role, the Number of Agents, and the Experiment Type.

Acceleration is a way to measure the changes in the robot's behavior throughout the interaction. A robot that accelerates or decelerates several times in an interaction is an indication that it had to replan or adjust to avoid a conflict. This metric is highly affected by whether the task is Prevention vs. Resolution of conflicts, and also by the Robot's Role, and the Number of Agents.

Smoothness is a generalization for several metrics that measure the total energy that was put into the interaction by the robot or the human. Successful interactions are expected to require less energy than unsuccessful interactions, which force the robot to replan. Smoothness can be evaluated in several ways, including acceleration/deceleration over time, total kinetic energy used [116], path irregularity (how many unnecessary turns were taken) [48], cumulative heading change [112], and the integral of the square of the curvature to measure the smoothness of a pedestrian's path [64].

This measure is influenced by whether the task is Prevention vs. Resolution, the Robot's Role, the Observability that can enable the robot to plan better ahead, and the Motion Control used. Avoidance Distance is a way to measure how close the robot came to a conflict or a full collision with a human. Usually, a robot that is able to avoid pedestrians from afar is considered more successful than a robot that almost reaches collision [143]. However, this success sometimes creates a tradeoff with the total length of the path the robot needs to take and the smoothness of the path. This metric is highly affected by whether the task is Prevention vs. Resolution, the Robot's Role, the Number of Agents, and the Motion Control used that might have its own predefined distance-keeping restrictions.


## Robot/Human Actions

While the previous subsection considered measurements of the interaction as a whole, in this subsection we discuss measures that evaluate the actions taken by the robot or the human. Degrees Turned As part of an interaction, either the robot or the human (or both) turn to avoid collision. Evaluation which consists of this measurement usually tracks the degrees of the lane change of either party. This measure will be highly affected by the Robot's Role which will determine who will turn, the Number of Agents in the environment, and the Motion Control used.

Gaze is a general measurement, in which several different aspects can be evaluated, including fixation count and length [108], and the Gaze-Movement Angle (GMA) [26]. Kitazawa and Fujiyama [73] investigated gaze patterns in a collision avoidance scenario with multiple pedestrians moving in a wide hallway shape area. They show that pedestrians pay much more attention to ground surface to detect potential immediate environmental hazards than fixating on obstacles, that most their fixations fall within a cone-shape area rather than semicircle, and that the attention paid to approaching pedestrians is not as high as that to static obstacles. 


## Emergent Behaviors

Several experiments have been designed to identify specific movement patterns and flow patterns that emerge during execution of social navigation algorithms, or to mimic human movement patterns that emerge in these contexts [5,84].

In many cases, these patterns are in the form of lanes [53] 2, 3 or group clusters. .

Lane Emergence is a phenomenon that exists in human crowds -whenever an environment becomes crowded enough, it is likely that people will follow the path of others who are going in the same direction [43,165]. For several algorithms deployed in crowded environments, the researchers were able to detect the emergence of lanes in robotic navigation context, and considered this behavior as a sign of success, since lanes are usually an efficient way to navigate in crowds. This measure is affected by the Number of Agents, the Experiment Type, and the evaluated Agent Type. Group Formation is another phenomenon whose appearance implies the success of the interaction. However, unlike lane emergence, group formation is usually an explicit objective of a work that discusses these types of interactions: such work focuses on understanding how groups of pedestrians move together [99], and are investigating whether a robot can seamlessly join such a group [103], bypass it [144], or disperse it [22]. This measure is affected by the Number of Agents and the Agent Type.

Maximal Density is a metric used a lot in simulations to stress-test an agent's ability to navigate in an environment with multiple other agents. When shifting to the real world, Fruin [38] 2, 3 proposed to identify 6 levels of crowdness, which they refer to as Level of Service, as depicted in Figure 4. When comparing to human-only navigation, the average density of people in a non-crowded environment was evaluated to 0.03 pedestrians per 2 , and in a moderately crowded environment, there are 0.25 pedestrians per 2 [99]. Notice that density, or the Number of Agents is an attribute in this survey's taxonomy -in this specific section, we only refer to evaluation that uses density as a metric, rather than as a controlled variable.


## Algorithmic Properties

The previous subsections focused on measuring physical quantities, either about the interaction as a whole or about one of the parties. In this subsection, we focus on more algorithmic aspects of the interaction. The metrics presented here can often be measured internally by the robot. Computation Time in social navigation refers to the robot's processing time. As the robot should perform in real-time, there is a need to evaluate whether the robot can process the required information, plan, and execute its plan on time. Two different components that are measured by computation time are: interaction processing, which is usually measured in milliseconds [157], and learning (in data-driven approaches), which is usually measured in learning episodes for achieving a desired behavior [29]. Computation time is highly influenced by whether the task is Prevention vs. Resolution as resolution usually requires shorter timescales, Number of Agents, Experiment Type and Agent

Type.

Model Prediction is a crucial part of every social navigation interaction: in order to properly act, the robot should first be able to predict accurately the behavior of other agents in the environment. Some contributions focus solely on improving the part of the interaction that involves understanding the environment given sensor information, and accurately predicting trajectories [79,96] 2, 3 , while others evaluate the prediction of pedestrian trajectories interleaved with robot execution [6,106]. This metric is influenced by the Robot's Role in the interaction, Observability, and Agent Type.


## Other Evaluations

So far, all evaluation metrics were objective and could usually be quantitatively evaluated. Some contributions focus on analyzing an interaction and identifying theoretical concepts, thus have no empirical evaluation, while others test subjective quantities (e.g. comfort level) or provide a qualitative evaluation of an interaction. Survey Questions is the most common approach to elicit information from users about how they perceive an interaction with an agent or a robot. These metrics consist of comfort levels during the interaction [57,94,158], social presence [68,113], expectation matching [43,75], and more. With respect to comfort, Torta et al. [151] identify specific values for this comfort zone (182 cm from a sitting person and 173 cm from a standing person). Syrdal et al. [145] present an empirical evaluation of the role of video prototyping and evocation as a good way to evaluate non-functional aspects of HRI. Another type of subjective evaluation is of proxemics [112,143], which is related to avoidance distance that was discussed earlier, but can encompass additional information about the interaction. For example, Hall [49] identifies different interaction ranges: Intimate space (up to 0.45m), personal space (1.2m), social space (3.6m), and public space (7.6m). When mapping these distances to human-robot interactions, the comfortable distance from a robot is 0.2m, and arrival tolerance 0.5m [19,78]. A survey is also referred in this survey as an Experiment Type, hence this is the most related attribute.

No Evaluation is a category designated for papers that make only a theoretical contribution, such as classifying different abstract types of interactions [124] or ones that provide only a qualitative analysis of an interaction [150]. Accordingly, research with no empirical evaluation might be affected by all attributes of the taxonomy, depending on the subject of the analysis.


## Simulations and Resources

So far, this section discussed specific metrics and evaluation methods that have been used in social navigation. One of the goals of this discussion is to promote better comparisons between different contributions in the field. Another way to promote this goal is by using existing simulations or resources that can have a similar baseline. In this subsection, we identify some of the recent efforts to create social navigation benchmarks and evaluation frameworks.

Carton et al. [13] propose a framework for the analysis of human trajectories, and show that human plan their navigation trajectory in a similar fashion when walking past a robot or a human.

Simulations are commonly used for the evaluation of a social navigation algorithm or model (39 of the 75 surveyed papers used simulations) either as a preliminary step to physical navigation or as a completely independent task. Next we point out several simulations that are available to use and can provide comparative evaluation for new contributions.

Loscos et al. [84] created a rule-based simulation that can handle up to 10, 000 pedestrians in an urban environment. [155] presents a testing platform that combines ROS and Unity into a social navigation testbed. In this platform's Table 8. An overview of the different metrics used in the surveyed papers to evaluate a social interaction.


## Evaluation Type Metric Evaluated Relevant Works

Interaction Properties


## Conflicts Count


## No Interaction Evaluation

Reynolds [124], Strassner and Langer [142], Topp and Christensen [150], Ohki et al. [110], Pandey and Alami [114], O'Callaghan et al. [109], Gómez et al. [46], Papadakis et al. [115], Charalampous et al. [17] current version, it can measure whether or not the robot reaches its goal, time to goal, collisions with static objects, final distance to goal, collisions with pedestrians, and closest distance to pedestrians.

Pertaining to real world interactions, there are not many contributions that can generalize due to several reasons:

First, robots can only be tested under similar conditions, meaning that an evaluation platform for large mobile robots will be different from one for smaller robots. Explicitly identifying how accurate a robotic design is (e.g. 2D vs. 3D

representation, joint movement, 3rd person vs. 1st person evaluation, etc.) is a key component in the design of any real-world robot experiment [145]. In addition, real human-robot interactions require human presence, which introduces a lot of variability and cannot be just compiled into an algorithm that can be used repeatedly.

Mavrogiannis et al. [92] recently published a testbed where people and robots navigated in a shared space. The robots used three distinct navigation strategies, executed by a telepresence robot (two autonomous, one teleoperated). The first is Optimal Reciprocal Collision Avoidance (ORCA), a local collision-free motion planner for a large number of robots as proposed by Van Den Berg et al. [157] and the second is the social momentum (SM) planning framework, which estimates the most likely intended avoidance protocols of others based on their past behaviors, superimposes them, and generates an expressive and socially compliant robot action that reinforces the expectations of others regarding these avoidance protocols [93]. These two chosen navigational strategies are agnostic to the fact that the other agent is a human. This assumption leaves an opportunity to investigate this problem further.


# DISCUSSION

In this survey, we identified specific components that comprise a social navigation interaction, and introduced a detailed taxonomy to provide researchers with a framework and a language for comparing and contrasting research in social navigation (Section 2). We then surveyed a comprehensive list of papers that contribute to social navigation and discussed them according to their values given our taxonomy (Sections 3 and 4). We then surveyed the different measurements used to evaluate an interaction in this context, and highlighted the relations between these measurements and the taxonomy attributes (Section 5).

Social navigation is a growing research area and we expect that while the attributes we chose for the taxonomy will remain relevant in the years to come, additional attributes will be added and the focus of specific work might shift to deal with new settings. However, any progress to the field must be rooted in the fundamental components of social navigation as they are presented in this survey. In addition, the proposed taxonomy can serve as a framework that enables researchers to properly place their contributions with respect to other work and to provide better benchmarks, which we hope will lead to an additional growth in this research area.

To conclude this survey and to consolidate its contributions into a coherent guide, we offer the readers the following checklist to assist with the design of social navigation interaction between a human and a robot. When introducing a new contribution to social navigation, potential aspects to consider include the following.

(1) Taxonomy Identify the values your work has with respect to the taxonomy's attributes in this survey: Prevention vs. Resolution, Robot's Role, Number of Agents, Observability, Motion Control, Communication, Experiment Type, and Agent type. As shown in this survey, the values of these attributes differ greatly among different papers; thus using this taxonomy is expected to help place new contributions within useful contexts and scopes.

(2) Reliability Provide as many details as possible about the choices made in the design of the robot, and about the implementation details. For example, when reporting an absolute number of pedestrians, also report the size of the area in which the experiment was conducted. While the presented taxonomy and the above checklist can be useful resources, in Section 2 we mentioned some additional concepts that are not yet mature enough to be included in the taxonomy, but might become more significant as the field grows. These concepts include: an analysis of different collision types, context awareness and semantic mapping, reactions to a robot vs. to a human, social cues and social signals, focused interaction, and navigating with groups of pedestrians. We see a surge of work that breaks traditional assumptions about pedestrian behavior in the context of social navigation [22,101,123], and these new settings may not be reflected using the existing attributes of the social navigation taxonomy. These papers are part of a fast evolving field, in which we predict an immense growth in the next decade. It is hence a good time to gather and map the knowledge that was already acquired, so it will also be easier to identify the differences when charging into new problem domains.

There are numerous open problems related to social navigation, in which there are specific potential advances that are within reach, given our current understanding and technological abilities: standardization of evaluation metrics and domains, context-aware navigation (e.g., workday vs. weekend), group understanding (avoid collision with a group participant), and adaptive navigation via machine learning (lifelong learning). Each of these problems offers many opportunities that leverage recent advances in machine learning, robotics, and human-robot interactions and implement them in a social navigation context. For those interested in contributing to this research area, the above problems ought to serve as a promising starting point. More information about these problems can be found in Subsection 2.2.

To conclude, we expect the field of social navigation to gain increased popularity and lead to more real-world applications during the next decade. This survey aims to help lay the groundwork for these exciting developments by mapping existing approaches into a novel taxonomy, and providing a context into which to place new contributions to social navigation.


Agent Type Human-Robot (H-R), Human-Agent (H-A), Human-Human (H-H), Robot-Robot (R-R), Homogeneous Agents (Hom), Heterogeneous Agents (Het). This survey focuses on social navigation between a person and a robot (Human-Robot). Due to the difficulty of evaluating such interactions, many models and algorithms are evaluated on a different set of agents. The most common approaches are running a simulation in which the human counterparts are controlled by a real human (Human-Agent) or by some other set of predefined or learned behaviors (either Homogeneous Agents or Heterogeneous Agents). Several papers are included which provide a fundamental understanding of purely-human navigation and present evaluations that do not involve robots at

## Fig. 1 .
1Various direct communication behaviors: (1) mechanical gaze[94];

## Fig. 2 .
2The hierarchical structure of the taxonomy's attributes


[26] 2, 3 empirically evaluates human behavior in situations of obstacle avoidance. Their work investigates the relation between object avoidance and finding one's aimpoint in a series of human studies. Their results are summarized in a decision-tree to facilitate reasoning about collision detection with other objects (static or moving) and defined the concept of Gaze-Movement Angle (GMA) -


Others have analyzed how gait and posture are affected by a sudden trajectory change as one expects to see in conflict resolution. Patla et al.[117] 2, 3 analyzed head yaw, trunk yaw and foot position when turning due to an expected obstacle vs. turning abruptly due to an unexpected obstacle. To analyze the relationship between head pose and predicted walking trajectory, Unhelkar et al.[156] 2, 3 discretized walking trajectories as a decision problem regarding which target a person would walk toward. They incorporated this information into an anytime path planner[105] 1 and evaluated this enhanced planner in simulation. Holman et al.[55] 2,3 extend this predictive model to incorporate gaze.Senft et al.[130] identify and implement a navigational pattern for making space in a hallway. Their model involves controlling the robot's rotation and sliding motion, and consists of three steps: step, slide, and rotate.All of the contributions mentioned above leverage insights from empirical studies on humans and robots to manually construct models for social navigation. However, together with the increasing abilities of machine learning, different learning techniques have been used to automatically learn models of navigation in social contexts. Lu et al.[85] propose a planning model that can be tuned to match different social navigation contexts. Bennewitz et al.[5] learn motion patterns of people that can be used for trajectory prediction in social robots. Henry et al.[54] extend this approach by modeling partial trajectories. More recently, Vasquez et al.[158] used Inverse Reinforcement Learning (IRL) to infer a reward function for social navigation. They introduce a new software framework to systematically investigate the effect of features and learning algorithms used in the literature. They also present results for the task of socially-compliant robot navigation in crowds, evaluating two different IRL approaches and several feature sets in large-scale simulations.Karnan et al.[66] collected a large scale dataset with human demonstrated socially compliant navigation behaviors in natural indoor and outdoor spaces on a university campus. They used behavior cloning to learn a global and local planner to mimic human navigation behaviors.

## 2, 3 .
3Gaze and head pose have both been shown to be significant indicators of a person's attention, which can be used to infer navigational goals. Stiefelhagen et al. [141] 2, 3 show that the visual focus of a person's attention can be deduced from head pose when the visual resolution is insufficient to determine eye gaze. Smith et al.

## Fig. 4 .
4Levels of Service from A to F: How crowded is the environment (taken from Fruin[38])

## ( 3 )
3Human Presence If your work consists of an interaction with pedestrians, what is their level of familiarity with the robot prior to the interaction? As presented in this survey, often experiments with human subjects are conducted in the lab rather than in the wild, where the subjects are often the roboticists who designed the robot.(4) Context Identify what is exactly the context in which the interaction takes place. As with other decisions, the context in which the chosen design is utilized can affect the behavior of pedestrians. (5) Success If your work consists of empirical evaluation, identify in advance what is considered a success in an interaction. For example, if your work introduces a new indirect communication method, the success of the evaluation should properly isolate the effect of that method. (6) Evaluation Detail which metrics will be used to evaluate this success, and what values are these metrics expected to have. Based on the presented taxonomy and surveyed papers, evaluation can be placed in comparison to other existing work.

## Table 1 .
1The Social Navigation TaxonomyAttributes 
Values 

Prevention vs. Resolution 
Prevention (P) / Resolution (R) / Both (B) / Neither (N) 
Robot Role 
Reactor (R) / Initiator (I) / Both (B) / Neither (N) 
Number of Agents 
Absolute Number ( 
= # of agents) / Density ( = #/ 2 ) 
Observability 
Full / Partial / Depth / RGB 
Motion Control 
SFM / ORCA / ROS / Human / Other 
Communication 
None (N) / Indirect (I) / Direct (D) 
Experiment Type 
Simulation (Sim) / In the Lab (Lab) / In the Wild (ItW) / Survey (Sur) 

Agent Type 
Human-Robot (H-R) / Human-Agent (H-A) / Human-Human (H-H) / 
Robot-Robot (R-R) / Homogeneous Agents (Hom) / Heterogeneous Agents (Het) 



## Table 2 .
2An overview of the different multiagent based models used in social navigation. P. vs. R. is Prevention vs. Resolution, Role refers to the robot role, Obs. is observability, Com. refers to communication, and Exp. type is the experiment type.Two research communities that have contributed significantly to the study of the problem of social navigation are the multi-robot navigation and graphics communities. Both of these communities have proposed different approaches to model the behavior of a crowd. The multi-robot community focuses more on safety and feasibility in the real-world, while the graphics community focuses on robustness. Due to these different goals, multi-robot work usually comes from the perspective of a single interaction (or only a few) in mind under realistic constraints; while the challenge of crowd modelling is to model interactions between hundreds and thousands of agents simultaneously, though the perception and movement restrictions on those agents tends to not be grounded in the physical constraints that both robots and real people must contend with.Many have considered the challenge of multi-robot navigation[164] 1,3 . As this is a fertile and active research area that deserves its own survey, we discuss only a few selected publications that have had a significant influence on social navigation. Van Den Berg et al.[157] present the principle of optimal reciprocal collision avoidance (ORCA) that provides a sufficient condition for multiple robots to avoid collisions among one another, and thus can guarantee collision-free navigation. Chen et al.[19] model human-robot and human-human interactions, then infer relative importance through a pooling module via a self-attention mechanism, finally planning motions.A branch of multi-robot research was inspired by planning under uncertainty, using Markov Decision Processes (MDPs). Foka and Trahanias[36] model hot points of human navigation, a probabilistic prediction of the person's destination. In their work, they use a Partially Observable MDP (POMDP) solved online at each time step to determine which actions the robot actually performs. Gupta et al.[47] recently presented an additional POMDP model for intentionaware navigation in crowds, where the model can address decisions related both to the robot's speed and its heading.Bandyopadhyay et al.[3] specifically model human intention with Mixed Observability MDP (MOMDP) and then plan the motion of a robot in this setting.The graphics community has contributed several important models to social navigation, as well as simulation environments that can be utilized to evaluate other models and algorithms (see more about these simulation environments in Section 5). Musse and Thalmann[103] propose a model of crowd behavior where agent behavior is determined using a predefined set of rules. Strassner and Langer[142] use behavioral rules for modelling each person's behavior in a crowd. Such behaviors include perceiving, storing, and forgetting knowledge. Bonneaud and Warren [9] model pedestrian behavior using an empirically-grounded emergent approach, where the local control laws for locomotor behavior are derived experimentally and the global crowd behavior is emergent. Okal and Arras[111] present a modelYear 
Paper 
P vs. R 
Role 
# Agents 
Obs. 
Motion Control 
Com. 
Exp. 
Type 

Agent 
Type 

1997 
Musse and Thalmann [103] 
R 
R 
Abs=10 
Full 

Other 
(Hand Coded) 

N 
Sim 
Hom 

2005 
Strassner and Langer [142] 
N 
N 
Abs=2 
Partial 

Other 
(Hand Coded) 

N 
Sim 
Hom 

2010 
Foka and Trahanias [36] 
R 
R 
Abs=6 
Depth 

Other 
(POMDP) 

I 
ItW 
H-R 

2011 
Van Den Berg et al. [157] 
P 
R 
Abs=1000 
Full 
ORCA 
I 
Sim 
Hom 

2013 
Bandyopadhyay et al. [3] 
P 
R 
Abs=4 

RGB + 
Depth 

SFM 
N 
Lab 
H-R 

2014 
Bonneaud and Warren [9] 
R 
R 
Abs=20 
Full 
Other 
N 
Sim 
Hom 
2014 
Okal and Arras [111] 
R 
R 
Abs=176 
Partial 
SFM 
N 
Sim 
Hom 
2016 
Godoy et al. [44] 
P 
B 
Abs=100 
Full 
Other 
N 
Lab 
R-R 

2019 
Chen et al. [19] 
P 
R 
Abs=6 
Full 

Other 
(LM-SARL) 

N 

Sim + 

Hom 

2022 
Gupta et al. [47] 
R 
R 
Abs=401 
Partial 

Other 
(POMDP) 

N 
Sim 
Hom 

3.1 Multiagent Systems 



## Table 3 .
3An overview of the different human-inspired and psychology-based models used in social navigation. P. vs. R. is Prevention vs. Resolution, Role refers to the robot role, Obs. is observability, Com. refers to communication, and Exp. type is the experiment type.for crowd behavior in which groups are formed. Their representation gives each individual an internal state, and under a set of predefined conditions pedestrians can choose to walk together.Year 
Paper 
P vs. R 
Role 
# Agents 
Obs. 
Motion Control 
Com. 
Exp. 
Type 

Agent 
Type 

1995 
Cutting et al. [26] 
R 
R 
Abs=2 
Partial 

Other 
(Hand Coded) 

I 
Sim + Sur 
H-H 

1998 
Jeffrey and Mark [57] 
R 
R 
Abs=4+ 
Partial 
Human 
N 
Sim 
H-H 
1999 
Patla et al. [117] 
B 
R 
Abs=2 
Partial 
Human 
N 
Lab 
H-H 
1999 
Reynolds [124] 
R 
R 
Abs=2 
Full 
None 
N 
None 
Hom 

2002 
Bennewitz et al. [5] 
P 
R 
Abs=2 
Depth 

Other 
(Learned) 

N 
Lab 
H-R 

2008 
Gérin-Lajoie et al. [42] 
R 
R 
Abs=2 
None 
Human 
N 
Lab 
H-H 
2010 
Henry et al. [54] 
P 
R 
None 
Depth 
Other (A*) 
N 
Sim 
Hom 
2010 
Kitazawa and Fujiyama [73] 
R 
R 
Abs=4 
Partial 
Human 
N 
Lab 
H-H 

2011 
Moussaïd et al. [98] 
R 
R 
Abs=96 
Partial 

Other 
(Hand Coded) 

N 
Lab 
Hom 

2011 
O'Callaghan et al. [109] 
P 
R 
Abs=2 
Depth 

Other 
(Planner) 

N 
ItW 
H-R 

2012 
Rios-Martinez et al. [125] 
P 
R 
Abs = 6 
RGB+Depth 
ROS 
N 
Sim 
Hom 
2013 
Lu et al. [85] 
P 
R 
Abs = 2 
Partial 
ROS 
N 
Sim 
Het 

2013 
Park et al. [116] 
R 
R 
D=0.1-1 
Partial 

Other 
(Hand Coded) 

I 
Sim 
Hom 

2014 
Charalampous et al. [17] 
P 
R 
Abs=2 
RGB+Depth 
Other 
N 
ItW 
H-R 
2014 
Papadakis et al. [115] 
N 
I 
Abs=2 
RGB+Depth 
None 
I 
Lab 
H-R 

2014 
Vasquez et al. [158] 
P 
R 
Abs=6+ 
Full 

Other 
(Dijkstra) 

I 
Sim 
H-A 

2015 
Unhelkar et al. [156] 
R 
R 
Abs=2 
Full 

Other 
(SIPP) 

N 
Lab 
H-A 

2016 
Mead and Matarić [95] 
N 
I 
Abs=2 
RGB 
None 
D 
Lab 
H-R 
2016 
Truong and Ngo [154] 
P 
R 
Abs = 4 
RGB+Depth 
Other (D*) 
N 
Lab 
H-R 

2020 
Senft et al. [130] 
R 
R 
Abs = 2 
Depth 

Other 
(Hand Coded) 

I 
Lab 
H-R 

2022 
Karnan et al. [66] 
P 
I 
Abs = 2 
RGB+Depth 

Other 
(Teleoperation) 

I 
ItW 
H-R 



## Table 2
2summarizes the taxonomy values for models inspired by multiagent systems research.

## Table 3
3summarizes the taxonomy values for models inspired by human behavior, physiology, and psychology research.

## Table 4 .
4An overview of the different physics-inspired models used in social navigation. P. vs. R. is Prevention vs. Resolution, Role refers to the robot role, Obs. is observability, Com. refers to communication, and Exp. type is the experiment type.the social context in which these interactions take place. A different type of force inspired work uses potential fields attached to moving pedestriansYear 
Paper 
P vs. R 
Role 
# Agents 
Obs. 
Motion Control 
Com. 
Exp. 
Type 

Agent 
Type 
1995 
Helbing and Molnar [53] 
P 
R 
D=0.3 
Full 
SFM 
N 
Sim 
H-A 

2003 
Loscos et al. [84] 
R 
R 
Abs=6000 
Partial 

Other 
(Hand Coded) 

N 
Sim 
Hom 

2009 
Karamouzas et al. [64] 
R 
R 
Abs=1000 
Full 
SFM 
N 
Sim 
Hom 
2010 
Moussaïd et al. [99] 
N 
N 
D=0.03-0.25 
Full 
SFM 
N 
ItW 
H-H 

2010 
Svenstrup et al. [143] 
P 
R 
Abs=40 
Full 

Other 
(Modified 
RRT) 

I 
Sim 
Hom 

2020 
Swofford et al. [144] 
N 
I 
Abs=18 
RGB 
ROS 
N 
Lab 
H-R 



## Table 5 .
5An overview of the different inference algorithms used in social navigation. P. vs. R. is Prevention vs. Resolution, Role refers to the robot role, Obs. is observability, Com. refers to communication, and Exp. type is the experiment type. Online Inference. Cutting et al.[26] offer an early attempt to evaluate the trajectory of a passerby by calculating their GMA and reacting to it. The robot designed by Tamura et al.[148] detects pedestrians by using a laser range finder and tracks using a Kalman filter. They apply a social force model to the observed trajectory to determine whether the pedestrian intends to avoid a collision with the robot or not, and select an appropriate behavior based on the estimation result. Gockley et al.[43] discuss how to avoid rear-end collisions in the context of person following. They propose a laser-based person-tracking method and evaluate two different approaches to person-following: direction-following,Year 
Paper 
P vs. R 
Role 
# Agents 
Obs. 
Motion Control 
Com. 
Exp. 
Type 

Agent 
Type 

2006 
Pacchierotti et al. [113] 
R 
R 
Abs=3 
Depth 

Other 
(Hand Coded) 

N 
Sim 
Hom 

2007 
Gockley et al. [43] 
P 
R 
Abs=2 
Depth 

Other 
(CVM) 

D 
Lab 
H-R 

2007 
Sisbot et al. [138] 
P 
R 
Abs=2 

RGB + 
Depth 

Other 
(HAMP) 

I 
Lab 
H-R 

2009 
Kirby et al. [70] 
P 
R 
Abs=4 
Depth 
Other (A*) 
N 
Sim 
Hom 

2010 
Ohki et al. [110] 
P 
R 
Abs=5 
Full 

Other 
(Hand Coded) 

N 
Sim 
Hom 

2010 
Pandey and Alami [114] 
P 
R 
Abs=2 
Full 

Other 
(Hand Coded) 

N 
Lab 
H-R 

2010 
Tamura et al. [148] 
R 
R 
Abs=2 
Depth 
SFM 
N 
Lab 
H-R 

2011 
Diego and Arras [28] 
P 
R 
Abs=5 
None 

Other 
(Modified TSP) 

N 
Sim 
Het 

2012 
Kuderer et al. [79] 
P 
R 
Abs=3 
Full 
Other (learned) 
N 
Lab 
H-R 
2012 
Luber et al. [87] 
P 
R 
Abs=2 
Full 
Other (RMP) 
N 
Sim 
H-A 

2013 
Ratsamee et al. [122] 
P 
R 
Abs=2 

RGB + 
Depth 

SFM 
N 
Lab 
H-R 

2014 
Gómez et al. [46] 
P 
R 
Abs=5 
Full 

Other 
(Planning) 

N 
Sim 
R-R 

2016 
Kim and Pineau [69] 
R 
R 
Crowd 

RGB + 
Depth 

Other 
(Costmap Search) 

I 
ItW 
H-R 

2016 
Kretzschmar et al. [75] 
P 
R 
Abs=3 
Depth 

Other 
(RPROP) 

I 
Lab 
H-R 

2016 
Okal and Arras [112] 
P 
R 
Abs=4 
Depth 
ROS 
I 

Sim + 

Hom 

2016 
Pfeiffer et al. [118] 
P 
R 
Abs=891 
RGB 

Other 
(Max Entropy) 

I 
ItW 
Hom 

2017 
Bera et al. [6] 
P 
R 
D<=2 
Full 

Other 
(SocioSense) 

N 
Sim 
Het 

2017 
Chen et al. [20] 
P 
R 
Abs=10+ 
RGB 

Other 
(Learned) 

N 
ItW 
H-R 

2017 
Chen et al. [21] 
P 
R 
Abs=6 
Full 

Other 
(Learned) 

N 
Sim 
R-R 

2018 
Ding et al. [29] 
P 
R 
Abs=20 
Depth 
None 
N 
Sim 
R-R 

2018 
Everett et al. [32] 
P 
R 
Abs=10+ 

RGB + 
Depth 

Crowd 
N 

Sim + 

H-A 

2018 
Jiang et al. [58] 
R 
B 
Abs=2 
RGB 

Other 
(Hand Coded) 

N 
Sim 
H-A 

2018 
Li et al. [80] 
P 
R 
Abs=3+ 
Depth 

Other 
(Learned) 

N 
Lab 
H-R 

2018 
Long et al. [82] 
P 
R 
Abs=100 
Depth 

Other 
(Learned) 

N 
Sim 
R-R 

2018 
Tai et al. [147] 
P 
R 
Abs=3 
Depth 

Other 
(Learned) 

N 

Sim + 

H-A 

2019 
Jin et al. [60] 
P 
R 
Abs=4 
Depth 

Other 
(Learned) 

N 
Lab 
H-R 

2019 
Meng et al. [96] 
N 
N 
Abs=1 
RGB 
None 
N 
Sim 
Hom 

2019 
Nardi and Stachniss [106] 
N 
N 
Abs=1 
Full 

Other 
(Hand Coded) 

N 
Sim 
R-R 

2020 
Liang et al. [81] 
P 
R 
Abs=10+ 

RGB + 
Depth 

Other 
(Learned) 

N 
Lab 
H-R 

2022 
Lu et al. [86] 
P 
R 
Abs=5 
Depth 

Other 
(Learned) 

N 
Sim 
Hom 

4.1.1 


1,2 . Though the use of instrumentation such as head-mounted gaze trackers or static gaze tracking cameras is limiting for mobile robots, recent work in the development of gaze trackers which work without such equipment[127] 1, 2 may soon allow us to perform the inverse of the robot experiments presented here,

## Table 6 .
6An overview of the different intention-conveying algorithms used in social navigation. P. vs. R. is Prevention vs. Resolution, Role refers to the robot role, Obs. is observability, Com. refers to communication, and Exp. type is the experiment type.Year 
Paper 
P vs. R 
Role 
# Agents 
Obs. 
Motion Control 
Com. 
Exp. 
Type 

Agent 
Type 

2009 
Nummenmaa et al. [108] 
R 
I 
Abs=2 
Partial 

Other 
(Hand Coded) 

D 
Sim 
H-A 

2013 
Fiore et al. [35] 
R 
I 
Abs=2 
Depth 

Other 
(Hand Coded) 

I + D 
Sim 
H-A 

2015 
May et al. [94] 
R 
I 
Abs=2 

RGB + 
Depth 

Other 
(A*) 

D 
Lab 
H-R 

2015 
Szafir et al. [146] 
P 
I 
Abs=2 

RGB + 
Depth 

Other 
(Hand Coded) 

D 
Lab + Sur 
H-R 

2015 
Unhelkar et al. [156] 
P 
N 
Abs=1 
Full 

Other 
(SIPP) 

N 
Sim 
Hom 

2015 
Watanabe et al. [162] 
R 
I 
Abs=2 
Depth 
ROS 
D 
Lab 
H-R 

2016 
Khambhaita et al. [68] 
R 
I 
Abs=2 

RGB + 
Depth 

ROS 
D 
Lab + Sur 
H-R 

2018 
Baraka and Veloso [4] 
P 
I 
Abs=2 

RGB + 
Depth 

ROS 
D 
Lab + Sur 
H-R 

2018 
Fernandez et al. [33] 
R 
I 
Abs=2 
Depth 

Other 
(Hand Coded) 

D 
Lab 
H-R 

2018 
Lynch et al. [88] 
R 
I 
Abs=2 
Full 

Other 
(Hand Coded) 

D 
Sim 
H-A 

2018 
Shrestha et al. [133] 
R 
I 
Abs=2 
Full 

Other 
(Hand Coded) 

D 
Lab + Sur 
H-R 

2020 
Hart et al. [50] 
R 
I 
Abs=2 
Depth 

Other 
(Hand Coded) 

D 
Lab 
H-R 



## Table 7 .
7An overview of the different mediation algorithms used in social navigation. P. vs. R. is Prevention vs. Resolution, Role refers to the robot role, Obs. is observability, Com. refers to communication, and Exp. type is the experiment type.Year 
Paper 
P vs. R 
Role 
# Agents 
Obs. 
Motion 
Control 
Com. 
Exp. 
Type 

Agent 
Type 

2002 
Murakami et al. [102] 
R 
B 
Abs=2 

RGB + 
Depth 

Other 
(Hand Coded) 

I 
Lab 
H-R 

2005 
Topp and Christensen [150] 
R 
R 
Abs=4 
Depth 

Other 
(Person 
Tracking) 

N 
Lab 
H-R 

2008 
Müller et al. [100] 
R 
R 
Abs=7 
Depth 

Other 
(A* + 
Person 
Tracking) 

N 
Lab 
H-R 

2010 
Svenstrup et al. [143] 
P 
R 
Abs=39 
Full 

Other 
(Modified 
RRT) 

N 
Sim 
H-R 

2013 
Ferrer et al. [34] 
P 
R 
Abs=10 
Depth 
SFM 
N 
ItW 
H-R 

2013 
Guzzi et al. [48] 
P 
B 
Abs=6 
RGB 

Other 
(Hand Coded) 

N 
R 
R-R 

2014 
Karamouzas et al. [65] 
P 
R 
D=0.27-2.5 
Full 

Other 
(Hand Coded) 

N 
Sim 
Hom 

2014 
Kruse et al. [77] 
P 
B 
Abs=2 
Full 

Other 
(Hand Coded) 

I 
Lab + Sur 
H-R 

2017 
Silva and Fraichard [136] 
P 
B 
Abs=2 
Full 
ROS 
N 
Sim 
Hom 

2019 
Yao et al. [165] 
P 
R 
Abs=6 

RGB + 
Depth 

Other 
(Geometry 
based) 

N 
Lab 
H-R 

2022 
Truc et al. [153] 
R 
R 
Abs=2 
Full 

Other 
(Hand Coded) 

N 
Sim 
Het 




Metrics that involve gaze are affected by the Robot's Role, Observability, Communication protocols that the human should be aware of, the Experiment Type, and Agent Type which can all have great effects on gaze patterns. Head Orientation and Body Positions are ways to capture some intermediate value between the degrees turned in practice, and the changes in GMA. Recently, Kitagawa et al. [72] leveraged people's reliance on such cues and incorporated similar body rotations into an omni-directional robot to improve the way pedestrians perceive its performance. These metrics are highly affected by the Robot's Role in the interaction, the Communication channel used, and the Agent Type.


Treuille et al.[152] offered a real-time crowd model based on continuum dynamics, which can facilitate large-scale simulations for navigation. Heïgeas et al.[52] presented a simulation platform where pedestrians act according to a physics-based particle force interaction model. Recently, Khambhaita et al.[68] created a simulated benchmark for social navigation tasks instead of physical experiments. This simulation is implemented with openAI Gym. Tsoi et al.
https://www.ros.org/
Prevention and Resolution of Conflicts in Social Navigation -a SurveyWoodstock '18, June 03-05, 2018, Woodstock, NY

Murakami, Diego and Arras. 102Okal and Arras. Everett et al. [32],Ding et al. [29], Long et al. [82], Lynch et al. [88. Liang et al. [81], Lu et al. [86], Gupta et al. [47Murakami et al. [102], Pacchierotti et al. [113], Müller et al. [100], Kirby et al. [70],Svenstrup et al. [143], Tamura et al. [148], Diego and Arras [28],Bandyopadhyay et al. [3], Park et al. [116], Ma et al. [89],Guzzi et al. [48], Unhelkar et al. [156], Godoy et al. [44],Okal and Arras [112], Kretzschmar et al. [75], Khambhaita et al. [68], Fernandez et al. [33], Li et al. [80], Everett et al. [32],Ding et al. [29], Long et al. [82], Lynch et al. [88], Jiang et al. [58], Yao et al. [165], Jin et al. [60], Meng et al. [96], Chen et al. [19], Hart et al. [50], Liang et al. [81], Lu et al. [86], Gupta et al. [47]

. Speed Helbing, Molnar ; Gérin-Lajoie, 53Unhelkar et al. [156], Kretzschmar et al. [75], Long et al. [82], Liang et al. [81Speed Helbing and Molnar [53], Gérin-Lajoie et al. [42], Karamouzas et al. [64], Moussaïd et al. [98], Kruse et al. [77], Unhelkar et al. [156], Kretzschmar et al. [75], Long et al. [82], Liang et al. [81]

Pacchierotti , Path Time Helbing and Molnar. 53Foka and Trahanias. Ding et al. [29], Long et al. [82. Liang et al. [81], Lu et al. [86], Gupta et al. [47Path Time Helbing and Molnar [53], Pacchierotti et al. [113], Karamouzas et al. [64], Foka and Trahanias [36], Bandyopadhyay et al. [3], Ferrer et al. [34], Godoy et al. [44], Chen et al. [20], Chen et al. [21], Tai et al. [147], Everett et al. [32], Ding et al. [29], Long et al. [82], Jiang et al. [58], Jin et al. [60], Kanazawa et al. [62], Chen et al. [19], Liang et al. [81], Lu et al. [86], Gupta et al. [47]

. Pacchierotti , 113Path Length Helbing and Molnar [53. Okal and Arras [112], Ding et al. [29], Jiang et al. [58], Long et al. [82], Nardi and Stachniss [106], Liang et al. [81Path Length Helbing and Molnar [53], Pacchierotti et al. [113], Karamouzas et al. [64] , Henry et al. [54], Luber et al. [87], Rios-Martinez et al. [125], Lu et al. [85], Vasquez et al. [158], Okal and Arras [112], Ding et al. [29], Jiang et al. [58], Long et al. [82], Nardi and Stachniss [106], Liang et al. [81]

Acceleration Helbing and Molnar. 53Bonneaud and Warren [9Acceleration Helbing and Molnar [53], Bonneaud and Warren [9]

. Avoidance Distance Luber, 87Kim and Pineau [69. Lynch et al. [88], Jin et al. [60], Kanazawa et al. [62], Lu et al. [86Avoidance Distance Luber et al. [87], Kruse et al. [77], May et al. [94], Kim and Pineau [69], Kretzschmar et al. [75], Chen et al. [20], Tai et al. [147], Lynch et al. [88], Jin et al. [60], Kanazawa et al. [62], Lu et al. [86]

. Smoothness Helbing, ; Molnar, Gockley, 53Vasquez et al. [158], Karamouzas et al. [65], Okal and Arras [112], Truc et al. [153Smoothness Helbing and Molnar [53], Gockley et al. [43], Karamouzas et al. [64], Park et al. [116], Guzzi et al. [48], Vasquez et al. [158], Karamouzas et al. [65], Okal and Arras [112], Truc et al. [153]

Karamouzas, Truong and Ngo [154Robot / Human Actions Degrees Turned Helbing and Molnar. 53Bonneaud and WarrenRobot / Human Actions Degrees Turned Helbing and Molnar [53], Karamouzas et al. [64], Bonneaud and Warren [9], Truong and Ngo [154]

Gaze Fixations Nummenmaa, Kitazawa and Fujiyama. 108Gaze Fixations Nummenmaa et al. [108], Kitazawa and Fujiyama [73]

-Movement Angle Gaze, Murakami, Diego and Arras. 102Okal and Arras. Fernandez et al. [33], Li et al. [80], Everett et al. [32],Ding et al. [29. Jin et al. [60], Meng et al. [96], Chen et al. [19],Hart et al. [50], Liang et al. [81Gaze-Movement Angle Murakami et al. [102], Pacchierotti et al. [113], Müller et al. [100], Kirby et al. [70],Svenstrup et al. [143], Diego and Arras [28], Bandyopadhyay et al. [3], Ratsamee et al. [122], Park et al. [116], Ma et al. [89],Guzzi et al. [48], Unhelkar et al. [156], Godoy et al. [44],Okal and Arras [112], Kretzschmar et al. [75], Khambhaita et al. [68],Fernandez et al. [33], Li et al. [80], Everett et al. [32],Ding et al. [29], Long et al. [82], Lynch et al. [88], Yao et al. [165],Jin et al. [60], Meng et al. [96], Chen et al. [19],Hart et al. [50], Liang et al. [81]

. Head Orientation Patla, 117Unhelkar et al. [156] Body Position Patla et al. [117], Unhelkar et al. [156Head Orientation Patla et al. [117], Ratsamee et al. [122], Unhelkar et al. [156] Body Position Patla et al. [117], Unhelkar et al. [156]

Emergent Behaviors Lane Emergence Helbing and Molnar. Bennewitz, 53Van Den Berg et al. [157], Karamouzas et al. [65Emergent Behaviors Lane Emergence Helbing and Molnar [53], Bennewitz et al. [5], Loscos et al. [84], Van Den Berg et al. [157], Karamouzas et al. [65]

Group Formation Musse and Thalmann. 103Moussaïd et al. [99], Swofford et al. [144Group Formation Musse and Thalmann [103], Moussaïd et al. [99], Swofford et al. [144]

. Maximal, Bandyopadhyay, 3Mead and Matarić [95Maximal density Bandyopadhyay et al. [3], Ma et al. [89], Mead and Matarić [95]

Sisbot, Algorithmic Properties Computation Time. 138Silva and Fraichard [136], Ding et al. [29Algorithmic Properties Computation Time Sisbot et al. [138], Moussaïd et al. [99], Van Den Berg et al. [157], Silva and Fraichard [136], Ding et al. [29]

Model Prediction Kuderer, Okal and Arras. 79Kim and Pineau [69. Silva and Fraichard [136], Yao et al. [165], Nardi and Stachniss [106], Meng et al. [96Model Prediction Kuderer et al. [79], Okal and Arras [111], Kim and Pineau [69], Kretzschmar et al. [75], Bera et al. [6], Silva and Fraichard [136], Yao et al. [165], Nardi and Stachniss [106], Meng et al. [96]

. Murakami , Other Survey Questions Jeffrey and Mark57Szafir et al. [146], Okal and Arras [112], Kretzschmar et al. [75. Shrestha et al. [133], Senft et al. [130Other Survey Questions Jeffrey and Mark [57], Murakami et al. [102], Pacchierotti et al. [113], Gockley et al. [43], Svenstrup et al. [143], Vasquez et al. [158], Kruse et al. [77], May et al. [94], Watanabe et al. [162], Szafir et al. [146], Okal and Arras [112], Kretzschmar et al. [75], Khambhaita et al. [68], Chen et al. [20], Baraka and Veloso [4], Shrestha et al. [133], Senft et al. [130]

Robot gaze does not reflexively cue human attention. Henny Admoni, Caroline Bank, Joshua Tan, Mariya Toneva, Brian Scassellati, Proceedings of the Annual Meeting of the Cognitive Science Society. the Annual Meeting of the Cognitive Science Society33Henny Admoni, Caroline Bank, Joshua Tan, Mariya Toneva, and Brian Scassellati. 2011. Robot gaze does not reflexively cue human attention. In Proceedings of the Annual Meeting of the Cognitive Science Society, Vol. 33.

Social eye gaze in human-robot interaction: a review. Henny Admoni, Brian Scassellati, Journal of Human-Robot Interaction. 6Henny Admoni and Brian Scassellati. 2017. Social eye gaze in human-robot interaction: a review. Journal of Human-Robot Interaction 6, 1 (2017), 25-63.

Intention-aware motion planning. Tirthankar Bandyopadhyay, Emilio Kok Sung Won, David Frazzoli, Hsu, Algorithmic foundations of robotics X. SpringerWee Sun Lee, and Daniela RusTirthankar Bandyopadhyay, Kok Sung Won, Emilio Frazzoli, David Hsu, Wee Sun Lee, and Daniela Rus. 2013. Intention-aware motion planning. In Algorithmic foundations of robotics X. Springer, 475-491.

Mobile Service Robot State Revealing Through Expressive Lights: Formalism, Design, and Evaluation. Kim Baraka, Manuela M Veloso, 10.1007/s12369-017-0431-xInternational Journal of Social Robotics. 10Kim Baraka and Manuela M. Veloso. 2018. Mobile Service Robot State Revealing Through Expressive Lights: Formalism, Design, and Evaluation. International Journal of Social Robotics 10, 1 (01 Jan 2018), 65-92. https://doi.org/10.1007/s12369-017-0431-x

Learning motion patterns of persons for mobile service robots. Maren Bennewitz, Wolfram Burgard, Sebastian Thrun, Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No. 02CH37292). 2002 IEEE International Conference on Robotics and Automation (Cat. No. 02CH37292)IEEE4Maren Bennewitz, Wolfram Burgard, and Sebastian Thrun. 2002. Learning motion patterns of persons for mobile service robots. In Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No. 02CH37292), Vol. 4. IEEE, 3601-3606.

Sociosense: Robot navigation amongst pedestrians with social and psychological constraints. Aniket Bera, Tanmay Randhavane, Rohan Prinja, Dinesh Manocha, 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEEAniket Bera, Tanmay Randhavane, Rohan Prinja, and Dinesh Manocha. 2017. Sociosense: Robot navigation amongst pedestrians with social and psychological constraints. In 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 7018-7025.

Swarm intelligence: from natural to artificial systems. Eric Bonabeau, Marco Dorigo, Directeur De Recherches Du Fnrs, Guy Marco, Guy Theraulaz, Théraulaz, Number. 1Oxford university pressEric Bonabeau, Marco Dorigo, Directeur de Recherches Du Fnrs Marco, Guy Theraulaz, Guy Théraulaz, et al. 1999. Swarm intelligence: from natural to artificial systems. Number 1. Oxford university press.

Visual navigation for mobile robots: A survey. Francisco Bonin-Font, Alberto Ortiz, Gabriel Oliver, Journal of intelligent and robotic systems. 53Francisco Bonin-Font, Alberto Ortiz, and Gabriel Oliver. 2008. Visual navigation for mobile robots: A survey. Journal of intelligent and robotic systems 53, 3 (2008), 263-296.

An empirically-grounded emergent approach to modeling pedestrian behavior. Stephane Bonneaud, H William, Warren, Pedestrian and evacuation dynamics. SpringerStephane Bonneaud and William H Warren. 2014. An empirically-grounded emergent approach to modeling pedestrian behavior. In Pedestrian and evacuation dynamics 2012. Springer, 625-638.

Psychological effects of behavior patterns of a mobile personal robot. John Travis Butler, Arvin Agah, Autonomous Robots. 10John Travis Butler and Arvin Agah. 2001. Psychological effects of behavior patterns of a mobile personal robot. Autonomous Robots 10, 2 (2001), 185-202.

Kuanqi Cai, Chaoqun Wang, Jiyu Cheng, Clarence W De Silva, Max Q-H Meng, arXiv:2006.14195Mobile robot path planning in dynamic environments: a survey. arXiv preprintKuanqi Cai, Chaoqun Wang, Jiyu Cheng, Clarence W De Silva, and Max Q-H Meng. 2020. Mobile robot path planning in dynamic environments: a survey. arXiv preprint arXiv:2006.14195 (2020).

Visual factors in the contact analog (Publication R61ELC60). Wl Carel, General Electric Company Advanced Electronics CenterIthaca, NYWL Carel. 1961. Visual factors in the contact analog (Publication R61ELC60). Ithaca, NY: General Electric Company Advanced Electronics Center (1961).

Measuring the effectiveness of readability for mobile robot locomotion. Daniel Carton, Wiktor Olszowy, Dirk Wollherr, International Journal of Social Robotics. 8Daniel Carton, Wiktor Olszowy, and Dirk Wollherr. 2016. Measuring the effectiveness of readability for mobile robot locomotion. International Journal of Social Robotics 8, 5 (2016), 721-741.

Acting under uncertainty: Discrete Bayesian models for mobile-robot navigation. Leslie Pack Anthony R Cassandra, James A Kaelbling, Kurien, Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems. IROS'96. IEEE/RSJ International Conference on Intelligent Robots and Systems. IROS'96IEEE2Anthony R Cassandra, Leslie Pack Kaelbling, and James A Kurien. 1996. Acting under uncertainty: Discrete Bayesian models for mobile-robot navigation. In Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems. IROS'96, Vol. 2. IEEE, 963-972.

Understanding other people's actions: Intention and attention. Umberto Castiello, Journal of Experimental Psychology: Human Perception and Performance. 29416Umberto Castiello. 2003. Understanding other people's actions: Intention and attention. Journal of Experimental Psychology: Human Perception and Performance 29, 2 (2003), 416.

A survey of nonverbal signaling methods for non-humanoid robots. Elizabeth Cha, Yunkyung Kim, Terrence Fong, J Maja, Mataric, Foundations and Trends® in Robotics. 6Elizabeth Cha, Yunkyung Kim, Terrence Fong, Maja J Mataric, et al. 2018. A survey of nonverbal signaling methods for non-humanoid robots. Foundations and Trends® in Robotics 6, 4 (2018), 211-323.

Social mapping on RGB-D scenes. Konstantinos Charalampous, Christos Emmanouilidis, Antonios Gasteratos, 2014 IEEE International Conference on Imaging Systems and Techniques (IST) Proceedings. IEEE. Konstantinos Charalampous, Christos Emmanouilidis, and Antonios Gasteratos. 2014. Social mapping on RGB-D scenes. In 2014 IEEE International Conference on Imaging Systems and Techniques (IST) Proceedings. IEEE, 398-403.

Recent trends in social aware robot navigation: A survey. Konstantinos Charalampous, Ioannis Kostavelis, and Antonios Gasteratos. 93Konstantinos Charalampous, Ioannis Kostavelis, and Antonios Gasteratos. 2017. Recent trends in social aware robot navigation: A survey. Robotics and Autonomous Systems 93 (2017), 85-104.

Crowd-robot interaction: Crowd-aware robot navigation with attention-based deep reinforcement learning. Changan Chen, Yuejiang Liu, Sven Kreiss, Alexandre Alahi, 2019 International Conference on Robotics and Automation (ICRA). IEEEChangan Chen, Yuejiang Liu, Sven Kreiss, and Alexandre Alahi. 2019. Crowd-robot interaction: Crowd-aware robot navigation with attention-based deep reinforcement learning. In 2019 International Conference on Robotics and Automation (ICRA). IEEE, 6015-6022.

Socially aware motion planning with deep reinforcement learning. Michael Yu Fan Chen, Miao Everett, Jonathan P Liu, How, 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEEYu Fan Chen, Michael Everett, Miao Liu, and Jonathan P How. 2017. Socially aware motion planning with deep reinforcement learning. In 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 1343-1350.

Decentralized non-communicating multiagent collision avoidance with deep reinforcement learning. Miao Yu Fan Chen, Michael Liu, Jonathan P Everett, How, 2017 IEEE international conference on robotics and automation (ICRA). IEEEYu Fan Chen, Miao Liu, Michael Everett, and Jonathan P How. 2017. Decentralized non-communicating multiagent collision avoidance with deep reinforcement learning. In 2017 IEEE international conference on robotics and automation (ICRA). IEEE, 285-292.

Autonomous Social Distancing in Urban Environments Using a Quadruped Robot. Zhiming Chen, Tingxiang Fan, Xuan Zhao, Jing Liang, Cong Shen, Hua Chen, Dinesh Manocha, Jia Pan, Wei Zhang, IEEE Access. 9Zhiming Chen, Tingxiang Fan, Xuan Zhao, Jing Liang, Cong Shen, Hua Chen, Dinesh Manocha, Jia Pan, and Wei Zhang. 2021. Autonomous Social Distancing in Urban Environments Using a Quadruped Robot. IEEE Access 9 (2021), 8392-8403.

The equilibrium size distribution of freely-forming groups. S James, John Coleman, James, Sociometry. 24James S Coleman and John James. 1961. The equilibrium size distribution of freely-forming groups. Sociometry 24, 1 (1961), 36-45.

Semantic information for robot navigation: A survey. Jonathan Crespo, Jose Carlos Castillo, Oscar Martinez Mozos, Ramon Barber, Applied Sciences. 102497Jonathan Crespo, Jose Carlos Castillo, Oscar Martinez Mozos, and Ramon Barber. 2020. Semantic information for robot navigation: A survey. Applied Sciences 10, 2 (2020), 497.

Yuchen Cui, Qiping Zhang, Alessandro Allievi, Peter Stone, Scott Niekum, W Bradley Knox, arXiv:2009.13649The EMPATHIC Framework for Task Learning from Implicit Human Feedback. arXiv preprintYuchen Cui, Qiping Zhang, Alessandro Allievi, Peter Stone, Scott Niekum, and W Bradley Knox. 2020. The EMPATHIC Framework for Task Learning from Implicit Human Feedback. arXiv preprint arXiv:2009.13649 (2020).

How we avoid collisions with stationary and moving objects. E James, Cutting, M Peter, Paul A Vishton, Braren, Psychological review. 102627James E Cutting, Peter M Vishton, and Paul A Braren. 1995. How we avoid collisions with stationary and moving objects. Psychological review 102, 4 (1995), 627.

Vision for mobile robot navigation: A survey. N Guilherme, Desouza, C Avinash, Kak, 24Guilherme N DeSouza and Avinash C Kak. 2002. Vision for mobile robot navigation: A survey. IEEE transactions on pattern analysis and machine intelligence 24, 2 (2002), 237-267.

Please do not disturb! minimum interference coverage for social robots. Gian Diego, Tipaldi Kai, O Arras, IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE. Gian Diego and Tipaldi Kai O Arras. 2011. Please do not disturb! minimum interference coverage for social robots. In 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 1968-1973.

Hierarchical reinforcement learning framework towards multi-agent navigation. Wenhao Ding, Shuaijun Li, Huihuan Qian, Yongquan Chen, 2018 IEEE International Conference on Robotics and Biomimetics (ROBIO). IEEEWenhao Ding, Shuaijun Li, Huihuan Qian, and Yongquan Chen. 2018. Hierarchical reinforcement learning framework towards multi-agent navigation. In 2018 IEEE International Conference on Robotics and Biomimetics (ROBIO). IEEE, 237-242.

Legibility and predictability of robot motion. Anca D Dragan, C T Kenton, Siddhartha S Lee, Srinivasa, 8th ACM/IEEE International Conference on Human-Robot Interaction (HRI). IEEEAnca D Dragan, Kenton CT Lee, and Siddhartha S Srinivasa. 2013. Legibility and predictability of robot motion. In 2013 8th ACM/IEEE International Conference on Human-Robot Interaction (HRI). IEEE, 301-308.

Moving obstacle detection in highly dynamic scenes. Andreas Ess, Bastian Leibe, Konrad Schindler, Luc Van Gool, 2009 IEEE International Conference on Robotics and Automation. IEEEAndreas Ess, Bastian Leibe, Konrad Schindler, and Luc Van Gool. 2009. Moving obstacle detection in highly dynamic scenes. In 2009 IEEE International Conference on Robotics and Automation. IEEE, 56-63.

Motion planning among dynamic, decision-making agents with deep reinforcement learning. Michael Everett, Yu Fan Chen, Jonathan P How, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEEMichael Everett, Yu Fan Chen, and Jonathan P How. 2018. Motion planning among dynamic, decision-making agents with deep reinforcement learning. In 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 3052-3059.

Passive Demonstrations of Light-Based Robot Signals for Improved Human Interpretability. Rolando Fernandez, Nathan John, Sean Kirmani, Justin Hart, Jivko Sinapov, Peter Stone, 27th IEEE International Symposium on Robot and Human Interactive Communication. RO-MANIEEERolando Fernandez, Nathan John, Sean Kirmani, Justin Hart, Jivko Sinapov, and Peter Stone. 2018. Passive Demonstrations of Light-Based Robot Signals for Improved Human Interpretability. In 2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN). IEEE, 234-239.

Social-aware robot navigation in urban environments. Gonzalo Ferrer, Anais Garrell, Alberto Sanfeliu, 2013 European Conference on Mobile Robots. IEEE. Gonzalo Ferrer, Anais Garrell, and Alberto Sanfeliu. 2013. Social-aware robot navigation in urban environments. In 2013 European Conference on Mobile Robots. IEEE, 331-336.

Toward understanding social cues and signals in human-robot interaction: effects of robot gaze and proxemic behavior. M Stephen, Travis J Fiore, Wiltshire, J C Emilio, Florian G Lobato, Jentsch, H Wesley, Benjamin Huang, Axelrod, Frontiers in psychology. 4859Stephen M Fiore, Travis J Wiltshire, Emilio JC Lobato, Florian G Jentsch, Wesley H Huang, and Benjamin Axelrod. 2013. Toward understanding social cues and signals in human-robot interaction: effects of robot gaze and proxemic behavior. Frontiers in psychology 4 (2013), 859.

Probabilistic autonomous robot navigation in dynamic environments with human motion prediction. F Amalia, Panos E Foka, Trahanias, International Journal of Social Robotics. 2Amalia F Foka and Panos E Trahanias. 2010. Probabilistic autonomous robot navigation in dynamic environments with human motion prediction. International Journal of Social Robotics 2, 1 (2010), 79-94.

A survey of socially interactive robots. Terrence Fong, Illah Nourbakhsh, Kerstin Dautenhahn, Robotics and autonomous systems. 42Terrence Fong, Illah Nourbakhsh, and Kerstin Dautenhahn. 2003. A survey of socially interactive robots. Robotics and autonomous systems 42, 3-4 (2003), 143-166.

Designing for pedestrians: A level-of-service concept. J John, Fruin, HS-011 999John J Fruin. 1971. Designing for pedestrians: A level-of-service concept. Number HS-011 999.

Localization and Mapping for Indoor Navigation: Survey. Handbook of Research on. Heba Gaber, Mohamed Marey, Safaa Amin, Mohamed F Tolba, Machine Learning Innovations and Trends. Heba Gaber, Mohamed Marey, Safaa Amin, and Mohamed F Tolba. 2017. Localization and Mapping for Indoor Navigation: Survey. Handbook of Research on Machine Learning Innovations and Trends (2017), 136-160.

Evaluation of socially-aware robot navigation. Yuxiang Gao, Chien-Ming Huang, Frontiers in Robotics and AI. 420Yuxiang Gao and Chien-Ming Huang. 2021. Evaluation of socially-aware robot navigation. Frontiers in Robotics and AI (2021), 420.

Semantics for robotic mapping, perception and interaction: A survey. Sourav Garg, Niko Sünderhauf, Feras Dayoub, Douglas Morrison, Akansel Cosgun, Gustavo Carneiro, Qi Wu, Tat-Jun Chin, Ian Reid, Stephen Gould, Foundations and Trends® in Robotics. 8Sourav Garg, Niko Sünderhauf, Feras Dayoub, Douglas Morrison, Akansel Cosgun, Gustavo Carneiro, Qi Wu, Tat-Jun Chin, Ian Reid, Stephen Gould, et al. 2020. Semantics for robotic mapping, perception and interaction: A survey. Foundations and Trends® in Robotics 8, 1-2 (2020), 1-224.

Characteristics of personal space during obstacle circumvention in physical and virtual environments. Martin Gérin-Lajoie, Carol L Richards, Joyce Fung, Bradford J Mcfadyen, Gait & posture. 27Martin Gérin-Lajoie, Carol L Richards, Joyce Fung, and Bradford J McFadyen. 2008. Characteristics of personal space during obstacle circumvention in physical and virtual environments. Gait & posture 27, 2 (2008), 239-247.

Natural person-following behavior for social robots. Rachel Gockley, Jodi Forlizzi, Reid Simmons, Proceedings of the ACM/IEEE international conference on Human-robot interaction. the ACM/IEEE international conference on Human-robot interactionRachel Gockley, Jodi Forlizzi, and Reid Simmons. 2007. Natural person-following behavior for social robots. In Proceedings of the ACM/IEEE international conference on Human-robot interaction. 17-24.

Moving in a Crowd: Safe and Efficient Navigation among Heterogeneous Agents. Julio Godoy, Ioannis Karamouzas, J Stephen, Maria L Guy, Gini, IJCAI. Julio Godoy, Ioannis Karamouzas, Stephen J Guy, and Maria L Gini. 2016. Moving in a Crowd: Safe and Efficient Navigation among Heterogeneous Agents.. In IJCAI. 294-300.

Behavior in public places. Erving Goffman, Simon and SchusterErving Goffman. 2008. Behavior in public places. Simon and Schuster.

Fast marching solution for the social path planning problem. Nikolaos Javier V Gómez, Santiago Mavridis, Garrido, 2014 IEEE International Conference on Robotics and Automation (ICRA). IEEEJavier V Gómez, Nikolaos Mavridis, and Santiago Garrido. 2014. Fast marching solution for the social path planning problem. In 2014 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 1871-1876.

Intention-Aware Navigation in Crowds with Extended-Space POMDP Planning. Himanshu Gupta, Bradley Hayes, Zachary Sunberg, Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems. the 21st International Conference on Autonomous Agents and Multiagent SystemsHimanshu Gupta, Bradley Hayes, and Zachary Sunberg. 2022. Intention-Aware Navigation in Crowds with Extended-Space POMDP Planning. In Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems. 562-570.

Human-friendly robot navigation in dynamic environments. Jérôme Guzzi, Alessandro Giusti, M Luca, Guy Gambardella, Gianni A Di Theraulaz, Caro, 2013 IEEE International Conference on Robotics and Automation. IEEEJérôme Guzzi, Alessandro Giusti, Luca M Gambardella, Guy Theraulaz, and Gianni A Di Caro. 2013. Human-friendly robot navigation in dynamic environments. In 2013 IEEE International Conference on Robotics and Automation. IEEE, 423-430.

The hidden dimension. Edward Twitchell Hall, 609Garden City, NY: DoubledayEdward Twitchell Hall. 1966. The hidden dimension. Vol. 609. Garden City, NY: Doubleday.

Using Human-Inspired Signals to Disambiguate Navigational Intentions. Justin Hart, Reuth Mirsky, Xuesu Xiao, Stone Tejeda, Bonny Mahajan, Jamin Goo, Kathryn Baldauf, Sydney Owen, Peter Stone, International Conference on Social Robotics. SpringerJustin Hart, Reuth Mirsky, Xuesu Xiao, Stone Tejeda, Bonny Mahajan, Jamin Goo, Kathryn Baldauf, Sydney Owen, and Peter Stone. 2020. Using Human-Inspired Signals to Disambiguate Navigational Intentions. In International Conference on Social Robotics. Springer, 320-331.

The shape of personal space: An experimental investigation. A Leslie, Hayduk, Canadian Journal of Behavioural Science/Revue canadienne des sciences du comportement. 1387Leslie A Hayduk. 1981. The shape of personal space: An experimental investigation. Canadian Journal of Behavioural Science/Revue canadienne des sciences du comportement 13, 1 (1981), 87.

A physically-based particle model of emergent crowd behaviors. Laure Heïgeas, Annie Luciani, Joelle Thollot, Nicolas Castagné, arXiv:1005.4405arXiv preprintLaure Heïgeas, Annie Luciani, Joelle Thollot, and Nicolas Castagné. 2010. A physically-based particle model of emergent crowd behaviors. arXiv preprint arXiv:1005.4405 (2010).

Social force model for pedestrian dynamics. Dirk Helbing, Peter Molnar, Physical review E. 514282Dirk Helbing and Peter Molnar. 1995. Social force model for pedestrian dynamics. Physical review E 51, 5 (1995), 4282.

Learning to navigate through crowded environments. Peter Henry, Christian Vollmer, Brian Ferris, Dieter Fox, 2010 IEEE International Conference on Robotics and Automation. IEEEPeter Henry, Christian Vollmer, Brian Ferris, and Dieter Fox. 2010. Learning to navigate through crowded environments. In 2010 IEEE International Conference on Robotics and Automation. IEEE, 981-986.

Watch Where You're Going! Gaze and Head Orientation as Predictors for Social Robot Navigation. Blake Holman, Abrar Anwar, Akash Singh, Mauricio Tec, Justin Hart, Peter Stone, Proceedings of the IEEE International Conference on Robotics and Automation (ICRA). the IEEE International Conference on Robotics and Automation (ICRA)IEEEBlake Holman, Abrar Anwar, Akash Singh, Mauricio Tec, Justin Hart, and Peter Stone. 2021. Watch Where You're Going! Gaze and Head Orientation as Predictors for Social Robot Navigation. In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA). IEEE, 6183-6190.

Simulation of pedestrian flows by optimal control and differential games. Serge Hoogendoorn, Piet Bovy, Optimal control applications and methods. 24Serge Hoogendoorn and Piet Bovy. 2003. Simulation of pedestrian flows by optimal control and differential games. Optimal control applications and methods 24, 3 (2003), 153-172.

Constructing social spaces in virtual environments: A study of navigation and interaction. Phillip Jeffrey, Gloria Mark, Workshop on personalised and social navigation in information space. StockholmSwedish Institute of Computer SciencePhillip Jeffrey and Gloria Mark. 1998. Constructing social spaces in virtual environments: A study of navigation and interaction. In Workshop on personalised and social navigation in information space. Stockholm: Swedish Institute of Computer Science, 24-38.

A Study of Human-Robot Copilot Systems for En-Route Destination Changing. Yu-Sian Jiang, Garrett Warnell, Eduardo Munera, Peter Stone, Proceedings of the 27th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN2018). the 27th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN2018)Nanjing, ChinaYu-Sian Jiang, Garrett Warnell, Eduardo Munera, and Peter Stone. 2018. A Study of Human-Robot Copilot Systems for En-Route Destination Changing. In Proceedings of the 27th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN2018). Nanjing, China. http://www.cs.utexas.edu/users/ai-lab/?ROMAN18-Jiang

Inferring User Intention using Gaze in Vehicles. Yu-Sian Jiang, Garrett Warnell, Peter Stone, The 20th ACM International Conference on Multimodal Interaction (ICMI). Boulder, ColoradoYu-Sian Jiang, Garrett Warnell, and Peter Stone. 2018. Inferring User Intention using Gaze in Vehicles. In The 20th ACM International Conference on Multimodal Interaction (ICMI). Boulder, Colorado. http://www.cs.utexas.edu/users/ai-lab/?ICMI18-Jiang

Mapless Navigation among Dynamics with Social-safety-awareness: a reinforcement learning approach from 2D laser scans. Jun Jin, M Nhat, Nazmus Nguyen, Daniel Sakib, Hengshuai Graves, Martin Yao, Jagersand, arXiv:1911.03074arXiv preprintJun Jin, Nhat M Nguyen, Nazmus Sakib, Daniel Graves, Hengshuai Yao, and Martin Jagersand. 2019. Mapless Navigation among Dynamics with Social-safety-awareness: a reinforcement learning approach from 2D laser scans. arXiv preprint arXiv:1911.03074 (2019).

The foundation of efficient robot learning. Leslie Pack, Kaelbling , Science. 369Leslie Pack Kaelbling. 2020. The foundation of efficient robot learning. Science 369, 6506 (2020), 915-916.

Adaptive motion planning for a collaborative robot based on prediction uncertainty to enhance human safety and work efficiency. Akira Kanazawa, Jun Kinugawa, Kazuhiro Kosuge, IEEE Transactions on Robotics. 35Akira Kanazawa, Jun Kinugawa, and Kazuhiro Kosuge. 2019. Adaptive motion planning for a collaborative robot based on prediction uncertainty to enhance human safety and work efficiency. IEEE Transactions on Robotics 35, 4 (2019), 817-832.

A review and analysis of eye-gaze estimation systems, algorithms and performance evaluation methods in consumer platforms. Anuradha Kar, Peter Corcoran, IEEE Access. 5Anuradha Kar and Peter Corcoran. 2017. A review and analysis of eye-gaze estimation systems, algorithms and performance evaluation methods in consumer platforms. IEEE Access 5 (2017), 16495-16519.

A predictive collision avoidance model for pedestrian simulation. Ioannis Karamouzas, Peter Heil, Pascal Van Beek, H Mark, Overmars, International workshop on motion in games. SpringerIoannis Karamouzas, Peter Heil, Pascal Van Beek, and Mark H Overmars. 2009. A predictive collision avoidance model for pedestrian simulation. In International workshop on motion in games. Springer, 41-52.

Universal power law governing pedestrian interactions. Ioannis Karamouzas, Brian Skinner, Stephen J Guy, Physical review letters. 113238701Ioannis Karamouzas, Brian Skinner, and Stephen J Guy. 2014. Universal power law governing pedestrian interactions. Physical review letters 113, 23 (2014), 238701.

Socially Compliant Navigation Dataset (SCAND): A Large-Scale Dataset of Demonstrations for Social Navigation. Anirudh Haresh Karnan, Xuesu Nair, Garrett Xiao, Soeren Warnell, Alexander Pirk, Justin Toshev, Joydeep Hart, Peter Biswas, Stone, IEEE Robotics and Automation Letters. Haresh Karnan, Anirudh Nair, Xuesu Xiao, Garrett Warnell, Soeren Pirk, Alexander Toshev, Justin Hart, Joydeep Biswas, and Peter Stone. 2022. Socially Compliant Navigation Dataset (SCAND): A Large-Scale Dataset of Demonstrations for Social Navigation. IEEE Robotics and Automation Letters (2022).

Model of side-by-side walking without the robot knowing the goal. Deneth Karunarathne, Yoichi Morales, Takayuki Kanda, Hiroshi Ishiguro, International Journal of Social Robotics. 10Deneth Karunarathne, Yoichi Morales, Takayuki Kanda, and Hiroshi Ishiguro. 2018. Model of side-by-side walking without the robot knowing the goal. International Journal of Social Robotics 10, 4 (2018), 401-420.

Head-Body Motion Coordination for Human Aware Robot Navigation. Harmish Khambhaita, Jorge Rios-Martinez, Rachid Alami, 9th International workshop on Human-Friendly Robotics. 8Harmish Khambhaita, Jorge Rios-Martinez, and Rachid Alami. 2016. Head-Body Motion Coordination for Human Aware Robot Navigation. In 9th International workshop on Human-Friendly Robotics (HFR 2016). 8p.

Socially adaptive path planning in human environments using inverse reinforcement learning. Beomjoon Kim, Joelle Pineau, International Journal of Social Robotics. 8Beomjoon Kim and Joelle Pineau. 2016. Socially adaptive path planning in human environments using inverse reinforcement learning. International Journal of Social Robotics 8, 1 (2016), 51-66.

Companion: A constraint-optimizing method for person-acceptable navigation. Rachel Kirby, Reid Simmons, Jodi Forlizzi, RO-MAN 2009-The 18th IEEE International Symposium on Robot and Human Interactive Communication. IEEERachel Kirby, Reid Simmons, and Jodi Forlizzi. 2009. Companion: A constraint-optimizing method for person-acceptable navigation. In RO-MAN 2009-The 18th IEEE International Symposium on Robot and Human Interactive Communication. IEEE, 607-612.

Change detection models for mobile cameras. Dmitry Mark, Kit , Ph.D. DissertationDmitry Mark Kit. 2012. Change detection models for mobile cameras. Ph.D. Dissertation.

Human-Inspired Motion Planning for Omni-Directional Social Robots. Ryo Kitagawa, Yuyi Liu, Takayuki Kanda, 10.1145/3434073.3444679Proceedings of the 2021 ACM/IEEE International Conference on Human-Robot Interaction (HRI '21). the 2021 ACM/IEEE International Conference on Human-Robot Interaction (HRI '21)New York, NY, USAAssociation for Computing MachineryRyo Kitagawa, Yuyi Liu, and Takayuki Kanda. 2021. Human-Inspired Motion Planning for Omni-Directional Social Robots. In Proceedings of the 2021 ACM/IEEE International Conference on Human-Robot Interaction (HRI '21). Association for Computing Machinery, New York, NY, USA, 34-42. https://doi.org/10.1145/3434073.3444679

Pedestrian vision and collision avoidance behavior: Investigation of the information process space of pedestrians using an eye tracker. Kay Kitazawa, Taku Fujiyama, Pedestrian and evacuation dynamics. SpringerKay Kitazawa and Taku Fujiyama. 2010. Pedestrian vision and collision avoidance behavior: Investigation of the information process space of pedestrians using an eye tracker. In Pedestrian and evacuation dynamics 2008. Springer, 95-108.

Semantic mapping for mobile robotics tasks: A survey. Ioannis Kostavelis, Antonios Gasteratos, Robotics and Autonomous Systems. 66Ioannis Kostavelis and Antonios Gasteratos. 2015. Semantic mapping for mobile robotics tasks: A survey. Robotics and Autonomous Systems 66 (2015), 86-103.

Socially compliant mobile robot navigation via inverse reinforcement learning. Henrik Kretzschmar, Markus Spies, Christoph Sprunk, Wolfram Burgard, The International Journal of Robotics Research. 35Henrik Kretzschmar, Markus Spies, Christoph Sprunk, and Wolfram Burgard. 2016. Socially compliant mobile robot navigation via inverse reinforcement learning. The International Journal of Robotics Research 35, 11 (2016), 1289-1307.

Legible robot navigation in the proximity of moving humans. Thibault Kruse, Patrizia Basili, Stefan Glasauer, Alexandra Kirsch, IEEE Workshop on Advanced Robotics and its Social Impacts (ARSO). IEEEThibault Kruse, Patrizia Basili, Stefan Glasauer, and Alexandra Kirsch. 2012. Legible robot navigation in the proximity of moving humans. In 2012 IEEE Workshop on Advanced Robotics and its Social Impacts (ARSO). IEEE, 83-88.

Evaluating directional cost models in navigation. Thibault Kruse, Alexandra Kirsch, Harmish Khambhaita, Rachid Alami, Proceedings of the 2014 ACM/IEEE international conference on Human-robot interaction. the 2014 ACM/IEEE international conference on Human-robot interactionThibault Kruse, Alexandra Kirsch, Harmish Khambhaita, and Rachid Alami. 2014. Evaluating directional cost models in navigation. In Proceedings of the 2014 ACM/IEEE international conference on Human-robot interaction. 350-357.

Human-aware robot navigation: A survey. Thibault Kruse, Amit Kumar Pandey, Rachid Alami, Alexandra Kirsch, Robotics and Autonomous Systems. 61Thibault Kruse, Amit Kumar Pandey, Rachid Alami, and Alexandra Kirsch. 2013. Human-aware robot navigation: A survey. Robotics and Autonomous Systems 61, 12 (2013), 1726-1743.

Feature-based prediction of trajectories for socially compliant navigation. Markus Kuderer, Henrik Kretzschmar, Christoph Sprunk, Wolfram Burgard, Robotics: science and systems. Markus Kuderer, Henrik Kretzschmar, Christoph Sprunk, and Wolfram Burgard. 2012. Feature-based prediction of trajectories for socially compliant navigation.. In Robotics: science and systems.

Role playing learning for socially concomitant mobile robot navigation. Mingming Li, Rui Jiang, Shuzhi Sam Ge, Tong Heng Lee, CAAI Transactions on Intelligence Technology. 3Mingming Li, Rui Jiang, Shuzhi Sam Ge, and Tong Heng Lee. 2018. Role playing learning for socially concomitant mobile robot navigation. CAAI Transactions on Intelligence Technology 3, 1 (2018), 49-58.

CrowdSteer: Realtime Smooth and Collision-Free Robot Navigation in Dense Crowd Scenarios Trained using High-Fidelity Simulation. Jing Liang, Utsav Patel, International Joint Conference on AI. Adarsh Jagan Sathyamoorthy, and Dinesh ManochaJing Liang, Utsav Patel, Adarsh Jagan Sathyamoorthy, and Dinesh Manocha. 2020. CrowdSteer: Realtime Smooth and Collision-Free Robot Navigation in Dense Crowd Scenarios Trained using High-Fidelity Simulation. International Joint Conference on AI (2020).

Towards optimally decentralized multi-robot collision avoidance via deep reinforcement learning. Pinxin Long, Tingxiang Fanl, Xinyi Liao, Wenxi Liu, Hao Zhang, Jia Pan, 2018 IEEE International Conference on Robotics and Automation (ICRA). IEEEPinxin Long, Tingxiang Fanl, Xinyi Liao, Wenxi Liu, Hao Zhang, and Jia Pan. 2018. Towards optimally decentralized multi-robot collision avoidance via deep reinforcement learning. In 2018 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 6252-6259.

Walking turn prediction from upper body kinematics: A systematic review with implications for human-robot interaction. M Antonio, López, C Juan, Diego Alvarez, Álvarez, Applied Sciences. 93361Antonio M López, Juan C Alvarez, and Diego Álvarez. 2019. Walking turn prediction from upper body kinematics: A systematic review with implications for human-robot interaction. Applied Sciences 9, 3 (2019), 361.

Intuitive crowd behavior in dense urban environments using local laws. Celine Loscos, David Marchal, Alexandre Meyer, Proceedings of Theory and Practice of Computer Graphics. Theory and Practice of Computer GraphicsIEEECeline Loscos, David Marchal, and Alexandre Meyer. 2003. Intuitive crowd behavior in dense urban environments using local laws. In Proceedings of Theory and Practice of Computer Graphics, 2003. IEEE, 122-129.

Tuning cost functions for social navigation. V David, Lu, William D Daniel B Allan, Smart, International Conference on Social Robotics. SpringerDavid V Lu, Daniel B Allan, and William D Smart. 2013. Tuning cost functions for social navigation. In International Conference on Social Robotics. Springer, 442-451.

Socially aware robot navigation in crowds via deep reinforcement learning with resilient reward functions. Xiaojun Lu, Hanwool Woo, Angela Faragasso, Atsushi Yamashita, Hajime Asama, Advanced Robotics. 36Xiaojun Lu, Hanwool Woo, Angela Faragasso, Atsushi Yamashita, and Hajime Asama. 2022. Socially aware robot navigation in crowds via deep reinforcement learning with resilient reward functions. Advanced Robotics 36, 8 (2022), 388-403.

Socially-aware robot navigation: A learning approach. Matthias Luber, Luciano Spinello, Jens Silva, Kai O Arras, 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE. Matthias Luber, Luciano Spinello, Jens Silva, and Kai O Arras. 2012. Socially-aware robot navigation: A learning approach. In 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 902-907.

Effect of virtual human gaze behaviour during an orthogonal collision avoidance walking task. D Sean, Julien Lynch, Julien Pettré, Richard Bruneau, Armel Kulpa, Anne-Hélène Crétual, Olivier, 2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR). IEEESean D Lynch, Julien Pettré, Julien Bruneau, Richard Kulpa, Armel Crétual, and Anne-Hélène Olivier. 2018. Effect of virtual human gaze behaviour during an orthogonal collision avoidance walking task. In 2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR). IEEE, 136-142.

Modeling pedestrian space in complex building for efficient pedestrian traffic simulation. J Ma, Siu Ming Lo, Song, Wang, G X Zhang, Liao, Automation in Construction. 30J Ma, Siu Ming Lo, WG Song, WL Wang, J Zhang, and GX Liao. 2013. Modeling pedestrian space in complex building for efficient pedestrian traffic simulation. Automation in Construction 30 (2013), 25-36.

Clusternav: Learning-based robust navigation operating in cluttered environments. S Gonçalo, Martins, P Rui, Fernando J Rocha, Paulo Pais, Menezes, 2019 International Conference on Robotics and Automation (ICRA). IEEEGonçalo S Martins, Rui P Rocha, Fernando J Pais, and Paulo Menezes. 2019. Clusternav: Learning-based robust navigation operating in cluttered environments. In 2019 International Conference on Robotics and Automation (ICRA). IEEE, 9624-9630.

Christoforos Mavrogiannis, Francesca Baldini, Allan Wang, Dapeng Zhao, Pete Trautman, Aaron Steinfeld, Jean Oh, arXiv:2103.05668Core challenges of social robot navigation: A survey. arXiv preprintChristoforos Mavrogiannis, Francesca Baldini, Allan Wang, Dapeng Zhao, Pete Trautman, Aaron Steinfeld, and Jean Oh. 2021. Core challenges of social robot navigation: A survey. arXiv preprint arXiv:2103.05668 (2021).

Effects of distinct robot navigation strategies on human behavior in a crowded environment. Christoforos Mavrogiannis, Alena M Hutchinson, John Macdonald, Patrícia Alves-Oliveira, Ross A Knepper, 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI). IEEEChristoforos Mavrogiannis, Alena M Hutchinson, John Macdonald, Patrícia Alves-Oliveira, and Ross A Knepper. 2019. Effects of distinct robot navigation strategies on human behavior in a crowded environment. In 2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI). IEEE, 421-430.

Social momentum: A framework for legible navigation in dynamic multi-agent environments. Christoforos I Mavrogiannis, B Wil, Ross A Thomason, Knepper, Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction. the 2018 ACM/IEEE International Conference on Human-Robot InteractionChristoforos I Mavrogiannis, Wil B Thomason, and Ross A Knepper. 2018. Social momentum: A framework for legible navigation in dynamic multi-agent environments. In Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction. 361-369.

Show me your moves! Conveying navigation intention of a mobile robot to humans. Alyxander David May, Christian Dondrup, Marc Hanheide, 2015 European Conference on Mobile Robots (ECMR). IEEEAlyxander David May, Christian Dondrup, and Marc Hanheide. 2015. Show me your moves! Conveying navigation intention of a mobile robot to humans. In 2015 European Conference on Mobile Robots (ECMR). IEEE, 1-6.

Perceptual models of human-robot proxemics. Ross Mead, J Maja, Matarić, Experimental Robotics. SpringerRoss Mead and Maja J Matarić. 2016. Perceptual models of human-robot proxemics. In Experimental Robotics. Springer, 261-276.

Scaling Local Control to Large-Scale Topological Navigation. Xiangyun Meng, Nathan Ratliff, Yu Xiang, Dieter Fox, IEEE International Conference on Robotics and Automation (ICRA. Xiangyun Meng, Nathan Ratliff, Yu Xiang, and Dieter Fox. 2020. Scaling Local Control to Large-Scale Topological Navigation. IEEE International Conference on Robotics and Automation (ICRA) (2020).

A survey on human-aware robot navigation. Ronja Möller, Antonino Furnari, Sebastiano Battiato, Aki Härmä, Giovanni Maria Farinella, Robotics and Autonomous Systems. 145103837Ronja Möller, Antonino Furnari, Sebastiano Battiato, Aki Härmä, and Giovanni Maria Farinella. 2021. A survey on human-aware robot navigation. Robotics and Autonomous Systems 145 (2021), 103837.

How simple rules determine pedestrian behavior and crowd disasters. Mehdi Moussaïd, Dirk Helbing, Guy Theraulaz, Proceedings of the National Academy of Sciences. 108Mehdi Moussaïd, Dirk Helbing, and Guy Theraulaz. 2011. How simple rules determine pedestrian behavior and crowd disasters. Proceedings of the National Academy of Sciences 108, 17 (2011), 6884-6888.

The walking behaviour of pedestrian social groups and its impact on crowd dynamics. Mehdi Moussaïd, Niriaska Perozo, Simon Garnier, Dirk Helbing, Guy Theraulaz, PloS one. 510047Mehdi Moussaïd, Niriaska Perozo, Simon Garnier, Dirk Helbing, and Guy Theraulaz. 2010. The walking behaviour of pedestrian social groups and its impact on crowd dynamics. PloS one 5, 4 (2010), e10047.

Socially inspired motion planning for mobile robots in populated environments. Jörg Müller, Cyrill Stachniss, Kai O Arras, Wolfram Burgard, Proc. of International Conference on Cognitive Systems. of International Conference on Cognitive SystemsJörg Müller, Cyrill Stachniss, Kai O Arras, and Wolfram Burgard. 2008. Socially inspired motion planning for mobile robots in populated environments. In Proc. of International Conference on Cognitive Systems.

Mutual anticipation can contribute to self-organization in human crowds. Hisashi Murakami, Claudio Feliciani, Yuta Nishiyama, Katsuhiro Nishinari, Science Advances. 77758Hisashi Murakami, Claudio Feliciani, Yuta Nishiyama, and Katsuhiro Nishinari. 2021. Mutual anticipation can contribute to self-organization in human crowds. Science Advances 7, 12 (2021), eabe7758.

Collision avoidance by observing pedestrians' faces for intelligent wheelchairs. Yoshifumi Murakami, Yoshinori Kuno, Nobutaka Shimada, Yoshiaki Shirai, Journal of the Robotics Society of Japan. 20Yoshifumi Murakami, Yoshinori Kuno, Nobutaka Shimada, and Yoshiaki Shirai. 2002. Collision avoidance by observing pedestrians' faces for intelligent wheelchairs. Journal of the Robotics Society of Japan 20, 2 (2002), 206-213.

A model of human crowd behavior: Group inter-relationship and collision detection analysis. Daniel Soraia Raupp Musse, Thalmann, Computer Animation and Simulation'97. SpringerSoraia Raupp Musse and Daniel Thalmann. 1997. A model of human crowd behavior: Group inter-relationship and collision detection analysis. In Computer Animation and Simulation'97. Springer, 39-51.

A social robot that stands in line. Yasushi Nakauchi, Reid Simmons, Autonomous Robots. 12Yasushi Nakauchi and Reid Simmons. 2002. A social robot that stands in line. Autonomous Robots 12, 3 (2002), 313-324.

Anytime safe interval path planning for dynamic environments. Venkatraman Narayanan, Mike Phillips, Maxim Likhachev, 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE. Venkatraman Narayanan, Mike Phillips, and Maxim Likhachev. 2012. Anytime safe interval path planning for dynamic environments. In 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 4708-4715.

Long-term robot navigation in indoor environments estimating patterns in traversability changes. Lorenzo Nardi, Cyrill Stachniss, ICRA. Lorenzo Nardi and Cyrill Stachniss. 2020. Long-term robot navigation in indoor environments estimating patterns in traversability changes. ICRA (2020).

The design of future things. Don Norman, Basic booksDon Norman. 2009. The design of future things. Basic books.

I'll walk this way: Eyes reveal the direction of locomotion and make passersby look and go the other way. Lauri Nummenmaa, Jukka Hyönä, Jari K Hietanen, Psychological Science. 20Lauri Nummenmaa, Jukka Hyönä, and Jari K Hietanen. 2009. I'll walk this way: Eyes reveal the direction of locomotion and make passersby look and go the other way. Psychological Science 20, 12 (2009), 1454-1458.

Learning navigational maps by observing human motion patterns. T Simon, O&apos;callaghan, P N Surya, Alen Singh, Fabio T Alempijevic, Ramos, 2011 IEEE International Conference on Robotics and Automation. IEEESimon T O'Callaghan, Surya PN Singh, Alen Alempijevic, and Fabio T Ramos. 2011. Learning navigational maps by observing human motion patterns. In 2011 IEEE International Conference on Robotics and Automation. IEEE, 4333-4340.

Collision avoidance method for mobile robot considering motion and personal spaces of evacuees. Takeshi Ohki, Keiji Nagatani, Kazuya Yoshida, IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE. Takeshi Ohki, Keiji Nagatani, and Kazuya Yoshida. 2010. Collision avoidance method for mobile robot considering motion and personal spaces of evacuees. In 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 1819-1824.

Towards group-level social activity recognition for mobile robots. Billy Okal, Kai O Arras, IROS Assistance and Service Robotics in a Human Environments Workshop. Billy Okal and Kai O Arras. 2014. Towards group-level social activity recognition for mobile robots. In IROS Assistance and Service Robotics in a Human Environments Workshop.

Learning socially normative robot navigation behaviors with bayesian inverse reinforcement learning. Billy Okal, Kai O Arras, 2016 IEEE International Conference on Robotics and Automation (ICRA). IEEEBilly Okal and Kai O Arras. 2016. Learning socially normative robot navigation behaviors with bayesian inverse reinforcement learning. In 2016 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2889-2895.

Design of an office-guide robot for social interaction studies. Elena Pacchierotti, Patric Henrik I Christensen, Jensfelt, IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE. Elena Pacchierotti, Henrik I Christensen, and Patric Jensfelt. 2006. Design of an office-guide robot for social interaction studies. In 2006 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 4965-4970.

A framework towards a socially aware mobile robot motion in human-centered dynamic environment. Amit Kumar Pandey, Rachid Alami, IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE. Amit Kumar Pandey and Rachid Alami. 2010. A framework towards a socially aware mobile robot motion in human-centered dynamic environment. In 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 5855-5860.

Adaptive spacing in human-robot interactions. Panagiotis Papadakis, Patrick Rives, Anne Spalanzani, IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE. Panagiotis Papadakis, Patrick Rives, and Anne Spalanzani. 2014. Adaptive spacing in human-robot interactions. In 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 2627-2632.

A collision avoidance behavior model for crowd simulation based on psychological findings. Jin Hyoung Park, Francisco Arturo Rojas, Hyun Seung Yang, Computer Animation and Virtual Worlds. 24Jin Hyoung Park, Francisco Arturo Rojas, and Hyun Seung Yang. 2013. A collision avoidance behavior model for crowd simulation based on psychological findings. Computer Animation and Virtual Worlds 24, 3-4 (2013), 173-183.

Online steering: coordination and control of body center of mass, head and body reorientation. A E Patla, A Adkin, T Ballard, 10.1007/s002210050932Experimental Brain Research. 129A. E. Patla, A. Adkin, and T. Ballard. 1999. Online steering: coordination and control of body center of mass, head and body reorientation. Experimental Brain Research 129, 4 (01 Dec 1999), 629-634. https://doi.org/10.1007/s002210050932

Predicting actions to act predictably: Cooperative partial motion planning with maximum entropy models. Mark Pfeiffer, Ulrich Schwesinger, Hannes Sommer, Enric Galceran, Roland Siegwart, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEEMark Pfeiffer, Ulrich Schwesinger, Hannes Sommer, Enric Galceran, and Roland Siegwart. 2016. Predicting actions to act predictably: Cooperative partial motion planning with maximum entropy models. In 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2096-2101.

. Sören Pirk, Edward Lee, Xuesu Xiao, Leila Takayama, Anthony Francis, Alexander Toshev, arXiv:2204.054432022. A Protocol for Validating Social Navigation Policies. arXiv preprintSören Pirk, Edward Lee, Xuesu Xiao, Leila Takayama, Anthony Francis, and Alexander Toshev. 2022. A Protocol for Validating Social Navigation Policies. arXiv preprint arXiv:2204.05443 (2022).

Comprehension of seeing as a referential act in young children, but not juvenile chimpanzees. J Daniel, Donna T Povinelli, Claude G Bierschwale, Cech, British Journal of Developmental Psychology. 17Daniel J Povinelli, Donna T Bierschwale, and Claude G Cech. 1999. Comprehension of seeing as a referential act in young children, but not juvenile chimpanzees. British Journal of Developmental Psychology 17, 1 (1999), 37-60.

Key technologies in robot assistants: Motion coordination between a human and a mobile robot. Erwin Prassler, Dirk Bank, Boris Kluge, M Hagele, Transactions on Control, Automation and Systems Engineering. 4Erwin Prassler, Dirk Bank, Boris Kluge, and M Hagele. 2002. Key technologies in robot assistants: Motion coordination between a human and a mobile robot. Transactions on Control, Automation and Systems Engineering 4, 1 (2002), 56-61.

Human-robot collision avoidance using a modified social force model with body pose and face orientation. Photchara Ratsamee, Yasushi Mae, Kenichi Ohara, Tomohito Takubo, Tatsuo Arai, International Journal of Humanoid Robotics. 101350008Photchara Ratsamee, Yasushi Mae, Kenichi Ohara, Tomohito Takubo, and Tatsuo Arai. 2013. Human-robot collision avoidance using a modified social force model with body pose and face orientation. International Journal of Humanoid Robotics 10, 01 (2013), 1350008.

Not Some Random Agent: Multi-person interaction with a personalizing service robot. Samantha Reig, Michal Luria, Janet Z Wang, Danielle Oltman, Elizabeth Jeanne Carter, Aaron Steinfeld, Jodi Forlizzi, John Zimmerman, Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction. the 2020 ACM/IEEE International Conference on Human-Robot InteractionSamantha Reig, Michal Luria, Janet Z Wang, Danielle Oltman, Elizabeth Jeanne Carter, Aaron Steinfeld, Jodi Forlizzi, and John Zimmerman. 2020. Not Some Random Agent: Multi-person interaction with a personalizing service robot. In Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction. 289-297.

Steering behaviors for autonomous characters. W Craig, Reynolds, Game developers conference. Craig W Reynolds. 1999. Steering behaviors for autonomous characters. In Game developers conference, Vol. 1999. Citeseer, 763-782.

Navigating between people: A stochastic optimization approach. Jorge Rios-Martinez, Alessandro Renzaglia, Anne Spalanzani, Agostino Martinelli, Christian Laugier, 2012 IEEE International Conference on Robotics and Automation. IEEEJorge Rios-Martinez, Alessandro Renzaglia, Anne Spalanzani, Agostino Martinelli, and Christian Laugier. 2012. Navigating between people: A stochastic optimization approach. In 2012 IEEE International Conference on Robotics and Automation. IEEE, 2880-2885.

From proxemics theory to socially-aware navigation: A survey. Jorge Rios-Martinez, Anne Spalanzani, Christian Laugier, International Journal of Social Robotics. 72Jorge Rios-Martinez, Anne Spalanzani, and Christian Laugier. 2015. From proxemics theory to socially-aware navigation: A survey. International Journal of Social Robotics 7, 2 (2015), 137-153.

Human gaze following for human-robot interaction. Akanksha Saran, Srinjoy Majumdar, Elaine Schaertl Short, Andrea Thomaz, Scott Niekum, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEEAkanksha Saran, Srinjoy Majumdar, Elaine Schaertl Short, Andrea Thomaz, and Scott Niekum. 2018. Human gaze following for human-robot interaction. In 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 8615-8621.

Understanding teacher gaze patterns for robot learning. Akanksha Saran, Elaine Schaertl Short, Andrea Thomaz, Scott Niekum, Conference on Robot Learning. PMLR. Akanksha Saran, Elaine Schaertl Short, Andrea Thomaz, and Scott Niekum. 2020. Understanding teacher gaze patterns for robot learning. In Conference on Robot Learning. PMLR, 1247-1258.

Measuring human-robot interaction through motor resonance. Alessandra Sciutti, Ambra Bisio, Francesco Nori, Giorgio Metta, Luciano Fadiga, Thierry Pozzo, Giulio Sandini, International Journal of Social Robotics. 4Alessandra Sciutti, Ambra Bisio, Francesco Nori, Giorgio Metta, Luciano Fadiga, Thierry Pozzo, and Giulio Sandini. 2012. Measuring human-robot interaction through motor resonance. International Journal of Social Robotics 4, 3 (2012), 223-234.

Would You Mind Me if I Pass by You? Socially-Appropriate Behaviour for an Omni-based Social Robot in Narrow Environment. Emmanuel Senft, Satoru Satake, Takayuki Kanda, Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction. the 2020 ACM/IEEE International Conference on Human-Robot InteractionEmmanuel Senft, Satoru Satake, and Takayuki Kanda. 2020. Would You Mind Me if I Pass by You? Socially-Appropriate Behaviour for an Omni-based Social Robot in Narrow Environment. In Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction. 539-547.

A robot that distributes flyers to pedestrians in a shopping mall. Chao Shi, Satoru Satake, Takayuki Kanda, Hiroshi Ishiguro, International Journal of Social Robotics. 10Chao Shi, Satoru Satake, Takayuki Kanda, and Hiroshi Ishiguro. 2018. A robot that distributes flyers to pedestrians in a shopping mall. International Journal of Social Robotics 10, 4 (2018), 421-437.

Precise localization for achieving next-generation autonomous navigation: State-of-the-art, taxonomy and future prospects. Chandra Rathin, Shit, Computer Communications. 160Rathin Chandra Shit. 2020. Precise localization for achieving next-generation autonomous navigation: State-of-the-art, taxonomy and future prospects. Computer Communications 160 (2020), 351-374.

Communicating directional intent in robot navigation using projection indicators. C Moondeep, Tomoya Shrestha, Ayano Onishi, Mitsuhiro Kobayashi, Shigeki Kamezaki, Sugano, 27th IEEE International Symposium on Robot and Human Interactive Communication. RO-MANIEEEMoondeep C Shrestha, Tomoya Onishi, Ayano Kobayashi, Mitsuhiro Kamezaki, and Shigeki Sugano. 2018. Communicating directional intent in robot navigation using projection indicators. In 2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN). IEEE, 746-751.

Communicating Directional Intent in Robot Navigation using Projection Indicators. M C Shrestha, T Onishi, A Kobayashi, M Kamezaki, S Sugano, 10.1109/ROMAN.2018.852552827th IEEE International Symposium on Robot and Human Interactive Communication. RO-MANM. C. Shrestha, T. Onishi, A. Kobayashi, M. Kamezaki, and S. Sugano. 2018. Communicating Directional Intent in Robot Navigation using Projection Indicators. In 2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN). 746-751. https: //doi.org/10.1109/ROMAN.2018.8525528

Illah Reza Nourbakhsh, and Davide Scaramuzza. Roland Siegwart, MIT pressIntroduction to autonomous mobile robotsRoland Siegwart, Illah Reza Nourbakhsh, and Davide Scaramuzza. 2011. Introduction to autonomous mobile robots. MIT press.

Human robot motion: A shared effort approach. Grimaldo Silva, Thierry Fraichard, European Conference on Mobile Robots (ECMR). IEEE. Grimaldo Silva and Thierry Fraichard. 2017. Human robot motion: A shared effort approach. In 2017 European Conference on Mobile Robots (ECMR). IEEE, 1-6.

Eduardo Velloso, Frank Vetere, and Liz Sonenberg. 2020. Combining gaze and AI planning for online human intention recognition. Ronal Singh, Tim Miller, Joshua Newn, Artificial Intelligence. 103275Ronal Singh, Tim Miller, Joshua Newn, Eduardo Velloso, Frank Vetere, and Liz Sonenberg. 2020. Combining gaze and AI planning for online human intention recognition. Artificial Intelligence (2020), 103275.

A human aware mobile robot motion planner. Emrah Akin, Luis F Sisbot, Rachid Marin-Urias, Thierry Alami, Simeon, IEEE Transactions on Robotics. 23Emrah Akin Sisbot, Luis F Marin-Urias, Rachid Alami, and Thierry Simeon. 2007. A human aware mobile robot motion planner. IEEE Transactions on Robotics 23, 5 (2007), 874-883.

Tracking the Visual Focus of Attention for a Varying Number of Wandering People. K Smith, S O Ba, J Odobez, D Gatica-Perez, 10.1109/TPAMI.2007.70773IEEE Transactions on Pattern Analysis and Machine Intelligence. 307K. Smith, S. O. Ba, J. Odobez, and D. Gatica-Perez. 2008. Tracking the Visual Focus of Attention for a Varying Number of Wandering People. IEEE Transactions on Pattern Analysis and Machine Intelligence 30, 7 (July 2008), 1212-1229. https://doi.org/10.1109/TPAMI.2007.70773

Comprehension of human communicative signs in pet dogs (Canis familiaris). Krisztina Soproni, Ádám Miklósi, József Topál, Vilmos Csányi, Journal of comparative psychology. 115122Krisztina Soproni, Ádám Miklósi, József Topál, and Vilmos Csányi. 2001. Comprehension of human communicative signs in pet dogs (Canis familiaris). Journal of comparative psychology 115, 2 (2001), 122.

From gaze to focus of attention. Rainer Stiefelhagen, Michael Finke, Jie Yang, Alex Waibel, International Conference on Advances in Visual Information Systems. SpringerRainer Stiefelhagen, Michael Finke, Jie Yang, and Alex Waibel. 1999. From gaze to focus of attention. In International Conference on Advances in Visual Information Systems. Springer, 765-772.

Virtual humans with personalized perception and dynamic levels of knowledge. Johannes Strassner, Marion Langer, Computer Animation and Virtual Worlds. 16Johannes Strassner and Marion Langer. 2005. Virtual humans with personalized perception and dynamic levels of knowledge. Computer Animation and Virtual Worlds 16, 3-4 (2005), 331-342.

Trajectory planning for robots in dynamic human environments. Mikael Svenstrup, Thomas Bak, Hans Jørgen Andersen, IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE. Mikael Svenstrup, Thomas Bak, and Hans Jørgen Andersen. 2010. Trajectory planning for robots in dynamic human environments. In 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 4293-4298.

Improving Social Awareness Through DANTE: Deep Affinity Network for Clustering Conversational Interactants. Mason Swofford, John Peruzzi, Nathan Tsoi, Sydney Thompson, Roberto Martín-Martín, Silvio Savarese, Marynel Vázquez, Proceedings of the ACM on Human-Computer Interaction. 4Mason Swofford, John Peruzzi, Nathan Tsoi, Sydney Thompson, Roberto Martín-Martín, Silvio Savarese, and Marynel Vázquez. 2020. Improving Social Awareness Through DANTE: Deep Affinity Network for Clustering Conversational Interactants. Proceedings of the ACM on Human-Computer Interaction 4, CSCW1 (2020), 1-23.

Video prototyping in human-robot interaction: Results from a qualitative study. Nuno Dag Sverre Syrdal, Kerstin Otero, Dautenhahn, Proceedings of the 15th European conference on Cognitive ergonomics: the ergonomics of cool interaction. the 15th European conference on Cognitive ergonomics: the ergonomics of cool interactionDag Sverre Syrdal, Nuno Otero, and Kerstin Dautenhahn. 2008. Video prototyping in human-robot interaction: Results from a qualitative study. In Proceedings of the 15th European conference on Cognitive ergonomics: the ergonomics of cool interaction. 1-8.

Communicating Directionality in Flying Robots. Daniel Szafir, Bilge Mutlu, Terry Fong, 10.1145/2696454.2696475Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI '15). the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI '15)New York, NY, USAACMDaniel Szafir, Bilge Mutlu, and Terry Fong. 2015. Communicating Directionality in Flying Robots. In Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI '15). ACM, New York, NY, USA, 19-26. https://doi.org/10.1145/2696454.2696475

Socially compliant navigation through raw depth inputs with generative adversarial imitation learning. Lei Tai, Jingwei Zhang, Ming Liu, Wolfram Burgard, 2018 IEEE International Conference on Robotics and Automation (ICRA). IEEELei Tai, Jingwei Zhang, Ming Liu, and Wolfram Burgard. 2018. Socially compliant navigation through raw depth inputs with generative adversarial imitation learning. In 2018 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 1111-1117.

Smooth collision avoidance in human-robot coexisting environment. Yusuke Tamura, Tomohiro Fukuzawa, Hajime Asama, IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE. Yusuke Tamura, Tomohiro Fukuzawa, and Hajime Asama. 2010. Smooth collision avoidance in human-robot coexisting environment. In 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 3887-3892.

Probabilistic algorithms and the interactive museum tour-guide robot minerva. Sebastian Thrun, Michael Beetz, Maren Bennewitz, Wolfram Burgard, B Armin, Frank Cremers, Dieter Dellaert, Dirk Fox, Chuck Haehnel, Nicholas Rosenberg, Roy, The International Journal of Robotics Research. 19Sebastian Thrun, Michael Beetz, Maren Bennewitz, Wolfram Burgard, Armin B Cremers, Frank Dellaert, Dieter Fox, Dirk Haehnel, Chuck Rosenberg, Nicholas Roy, et al. 2000. Probabilistic algorithms and the interactive museum tour-guide robot minerva. The International Journal of Robotics Research 19, 11 (2000), 972-999.

Tracking for following and passing persons. Anna Elin, Henrik I Topp, Christensen, IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE. Elin Anna Topp and Henrik I Christensen. 2005. Tracking for following and passing persons. In 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 2321-2327.

Design of a parametric model of personal space for robotic social navigation. Elena Torta, H Raymond, James F Cuijpers, Juola, International Journal of Social Robotics. 5Elena Torta, Raymond H Cuijpers, and James F Juola. 2013. Design of a parametric model of personal space for robotic social navigation. International Journal of Social Robotics 5, 3 (2013), 357-365.

Continuum crowds. Adrien Treuille, Seth Cooper, Zoran Popović, ACM Transactions on Graphics (TOG). 25Adrien Treuille, Seth Cooper, and Zoran Popović. 2006. Continuum crowds. ACM Transactions on Graphics (TOG) 25, 3 (2006), 1160-1168. https://howtorts.github.io/2014/01/09/continuum-crowds.html.

KHAOS: a Kinematic Human Aware Optimizationbased System for Reactive Planning of Flying-Coworker. Jérôme Truc, Phani-Teja Singamaneni, Daniel Sidobre, Serena Ivaldi, Rachid Alami, ICRA 2022. Jérôme Truc, Phani-Teja Singamaneni, Daniel Sidobre, Serena Ivaldi, and Rachid Alami. 2022. KHAOS: a Kinematic Human Aware Optimization- based System for Reactive Planning of Flying-Coworker. In ICRA 2022.

Dynamic social zone based mobile robot navigation for human comfortable safety in social environments. Xuan-Tung Truong, Trung-Dung Ngo, International Journal of Social Robotics. 8Xuan-Tung Truong and Trung-Dung Ngo. 2016. Dynamic social zone based mobile robot navigation for human comfortable safety in social environments. International Journal of Social Robotics 8, 5 (2016), 663-684.

SEAN: Social Environment for Autonomous Navigation. Nathan Tsoi, Mohamed Hussein, Jeacy Espinoza, Xavier Ruiz, Marynel Vázquez, Proceedings of the 8th International Conference on Human-Agent Interaction. the 8th International Conference on Human-Agent InteractionNathan Tsoi, Mohamed Hussein, Jeacy Espinoza, Xavier Ruiz, and Marynel Vázquez. 2020. SEAN: Social Environment for Autonomous Navigation. In Proceedings of the 8th International Conference on Human-Agent Interaction. 281-283.

Human-robot co-navigation using anticipatory indicators of human walking motion. Claudia Vaibhav V Unhelkar, Leia Pérez-D&apos;arpino, Julie A Stirling, Shah, 2015 IEEE International Conference on Robotics and Automation (ICRA). IEEEVaibhav V Unhelkar, Claudia Pérez-D'Arpino, Leia Stirling, and Julie A Shah. 2015. Human-robot co-navigation using anticipatory indicators of human walking motion. In 2015 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 6183-6190.

Reciprocal n-body collision avoidance. Jur Van Den, Berg, J Stephen, Ming Guy, Dinesh Lin, Manocha, Robotics research. SpringerJur Van Den Berg, Stephen J Guy, Ming Lin, and Dinesh Manocha. 2011. Reciprocal n-body collision avoidance. In Robotics research. Springer, 3-19.

Inverse reinforcement learning algorithms and features for robot navigation in crowds: an experimental comparison. Dizan Vasquez, Billy Okal, Kai O Arras, IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE. Dizan Vasquez, Billy Okal, and Kai O Arras. 2014. Inverse reinforcement learning algorithms and features for robot navigation in crowds: an experimental comparison. In 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 1341-1346.

Multi-robot coordination analysis, taxonomy, challenges and future scope. Janardan Kumar Verma, Virender Ranga, Journal of Intelligent & Robotic Systems. 102Janardan Kumar Verma and Virender Ranga. 2021. Multi-robot coordination analysis, taxonomy, challenges and future scope. Journal of Intelligent & Robotic Systems 102, 1 (2021), 1-36.

Social signal processing: Survey of an emerging domain. Alessandro Vinciarelli, Maja Pantic, Hervé Bourlard, Image and vision computing. 27Alessandro Vinciarelli, Maja Pantic, and Hervé Bourlard. 2009. Social signal processing: Survey of an emerging domain. Image and vision computing 27, 12 (2009), 1743-1759.

An imitation of life. W Grey Walter, Scientific american. 182W Grey Walter. 1950. An imitation of life. Scientific american 182, 5 (1950), 42-45.

Communicating robotic navigational intentions. Atsushi Watanabe, Tetsushi Ikeda, Yoichi Morales, Kazuhiko Shinozawa, Takahiro Miyashita, Norihiro Hagita, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEEAtsushi Watanabe, Tetsushi Ikeda, Yoichi Morales, Kazuhiko Shinozawa, Takahiro Miyashita, and Norihiro Hagita. 2015. Communicating robotic navigational intentions. In 2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 5763-5769.

Motion planning and control for mobile robot navigation using machine learning: a survey. Xuesu Xiao, Bo Liu, Garrett Warnell, Peter Stone, Autonomous Robots. Xuesu Xiao, Bo Liu, Garrett Warnell, and Peter Stone. 2022. Motion planning and control for mobile robot navigation using machine learning: a survey. Autonomous Robots (2022), 1-29.

A survey and analysis of multi-robot coordination. Zhi Yan, Nicolas Jouandeau, Arab Ali Cherif, International Journal of Advanced Robotic Systems. 10399Zhi Yan, Nicolas Jouandeau, and Arab Ali Cherif. 2013. A survey and analysis of multi-robot coordination. International Journal of Advanced Robotic Systems 10, 12 (2013), 399.

Following Social Groups: Socially Compliant Autonomous Navigation in Dense Crowds. Xinjie Yao, Ji Zhang, Jean Oh, arXiv:1911.12063arXiv preprintXinjie Yao, Ji Zhang, and Jean Oh. 2019. Following Social Groups: Socially Compliant Autonomous Navigation in Dense Crowds. arXiv preprint arXiv:1911.12063 (2019).

Optimal Use of Verbal Instructions for Multi-robot Human Navigation Guidance. Jacqueline Harel Yedidsion, Connor Deans, Mahathi Sheehan, Justin Chillara, Peter Hart, Raymond J Stone, Mooney, International Conference on Social Robotics. SpringerHarel Yedidsion, Jacqueline Deans, Connor Sheehan, Mahathi Chillara, Justin Hart, Peter Stone, and Raymond J Mooney. 2019. Optimal Use of Verbal Instructions for Multi-robot Human Navigation Guidance. In International Conference on Social Robotics. Springer, 133-143.