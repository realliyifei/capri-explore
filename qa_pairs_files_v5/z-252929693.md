# A Survey of Automatic Text Classification Based on Thai Social Media Data

CorpusID: 252929693 - [https://www.semanticscholar.org/paper/ccd7a3a39a0d649f196aeb94a72533310f7b64e4](https://www.semanticscholar.org/paper/ccd7a3a39a0d649f196aeb94a72533310f7b64e4)

Fields: Computer Science

## (s18) Lexicon-Based Approach (LB Approach)
Number of References: 2

(p18.0) The LB classification method establishes rules or requirements for classifying text. The algorithm searches for polarity words like "bad," "nasty," "tasty," or "good." Expressions in the text are calculated by algorithm and scored from -1 to +1. After combining the scores of all the words, it uses the mathematical and statistical methods to determine the final scores to identify the sentiment of the text (Taboada et al., 2011), as shown in Figure 3. The scores and classifications of texts depend on the vocabulary in the dictionary for the analysis and classification of English sentiments (Suwanpipob, 2019).
## (s36) Sentiment Analysis and Classification
Number of References: 4

(p36.0) Sentiment classification research is the classification of messages according to the feelings or intentions of the writer. Its purpose is to explore and develop businesses and services. The research can be divided into two categories. First, the text classification uses feelings toward a product, service, person, place, or event (positive, negative, and neutral). The second is the classification of messages based on the emotion or feeling that the writers want to communicate and express (happy, sad, lonely, shocked, and fear). Messages can be classified based one's feelings about a product, service, person, place, or event. Pugsee and Niyomvanich (2015) developed a system to determine the choice of recipes using comments. A total of 7,222 texts from blogging sites about food were analyzed and categorized based on users' feelings about a recipe. It consisted of 6,620 positive texts, 54 negative texts, and 548 neutral texts. The researchers developed an automatic text classification based on the SentiWordNet dictionary comparison, with an accuracy of 93.08%. Masdisornchote (2016) collected 1,090 texts expressing opinions about mobile phones via the Siamphone Website. The texts were segmented by the LexTo word tokenization and compared with the sentiment dictionary to classify into positive and negative statements. An overall efficiency (F-Measure) was 86.1%. Songram (2016) used a Graph API tool to collect 467 texts from Facebook during the Coup d'Ã©tat in Thailand. Three experts classified the texts, which can be divided into 259 positive texts and 208 negative texts. A classification based association (CBA) was used to create rules to classify the texts. The result showed an accuracy of 77.75%. Vateekul and Koomsubha (2016) collected 3,813,173 texts from Twitter. They brought them into the word segmentation process via Kucut to consider the emoticons. A positive emoticon was identified as a positive emotion and feeling. A negative emoticon indicated a negative emotion and feeling. A random sample of 22,000 texts were used to create a model for classification by extracting the embedded feature using the word2vec. This study used CNN, NB, and SVM. The accuracy was 75.35%, 74.05%, and 74.71%, respectively. Sanguansa (2016) used 55,539 texts to express customer opinions in the field of business (positive, negative, and neutral texts). The researchers extracted TF, TF-IDF, and word-embedding attributes. They used NB, LR, and SVM to create a text classification model. It was found that the embedding attribute classification using the LR model yielded the highest accuracy at 85.12%.   Kuhamanee et al. (2017) collected 10,000 opinion texts about traveling in Thailand. Twitter data was analyzed to formulate guidelines for promoting the tourism industry of Bangkok. The researchers used the obtained data to divide the text into positive and negative feelings, as well as a sense of neutrality. TF-IDF attributes were then extracted. The performance of the text classification models by NB, DT, SVM, and artificial NN was compared. It found that the accuracy of each was 55.06%, 79.83%, 80.11%, and 80.33%, respectively.
