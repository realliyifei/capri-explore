# Rank-based Decomposable Losses in Machine Learning: A Survey

CorpusID: 250627000 - [https://www.semanticscholar.org/paper/59ceacd001ee4a0e7984207040275e5e9e657d9b](https://www.semanticscholar.org/paper/59ceacd001ee4a0e7984207040275e5e9e657d9b)

Fields: Mathematics, Medicine, Computer Science

## (s1) Related Works
Number of References: 10

(p1.0) There exist several surveys [1], [22]- [29] on loss functions. Specifically, [22]- [24] focus on loss functions that are used in specific learning tasks or domains such as face recognition, semantic segmentation, computer vision, etc. [28] investigates the commonly used loss functions in general machine learning, such as classification and regression. [29] revisits many existing loss functions in machine learning from two aspects: traditional machine learning (classification, regression, and unsupervised learning) and deep learning (object detection and face recognition). However, the loss functions discussed in these surveys are only focused on the individual loss level. They assume the loss functions use the average operator in the sample level. On the other hand, [1], [25]- [27] discuss the losses from the information retrieval area. However, they only view the losses from the perspective of evaluation metrics. There is no system survey about rank-based decomposable Losses, especially view losses from the aggregator that aggregates a set of values to a single value.
## (s46) Hyperparameter Tuning
Number of References: 3

(p46.0) Rank-based losses rely heavily on important hyperparameters that can greatly affect the performance of the final model. For instance, in the case of AoRR aggregate loss, the hyperparameter m determines the number of possible outliers that are ignored during training. If m is set lower than the actual number of outliers, the model will be adversely affected by the outliers. Conversely, if m is set too high, some essential samples will be removed during training, resulting in a suboptimal final model. Several works have attempted to develop new learning strategies to determine the hyperparameters in model training. For example, Kawaguchi et al. used the AT k aggregator to design ordered SGD optimization methods in [96]. They employed an adaptive setting to decrease k when the model performance achieved preset-specific criteria. In [13], a similar method was applied for learning the AoRR aggregate loss. They used greedy search to determine the hyperparameter m. However, these methods may not be efficient for large-scale datasets. Therefore, in [14], Hu et al. proposed an auxiliary learning framework to determine the hyperparameters using a clean dataset, which is extracted from the original dataset that may contain outliers. However, this method may not work when a clean dataset is unavailable. Therefore, exploring methods for determining hyperparameters in rank-based decomposable losses may be a promising future direction.
