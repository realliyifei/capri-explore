# Survey of Attacks and Defenses on Edge-Deployed Neural Networks

CorpusID: 208309878 - [https://www.semanticscholar.org/paper/0171abaa8e11ab531a2a0eba4c14fa972f1fe9e8](https://www.semanticscholar.org/paper/0171abaa8e11ab531a2a0eba4c14fa972f1fe9e8)

Fields: Mathematics, Computer Science, Engineering

## (s5) III. ATTACKS ON DEPLOYED NEURAL NETWORKS
Number of References: 3

(p5.0) We present a short survey of published attacks on neural network accelerators. We focus primarily on test-time attacks (attacks on already trained models), as we assume that training-time attacks such as data poisoning [28] or Neural Trojans [29] must happen before the model is deployed. API attacks: API attacks interact with the victim device only through the sensors, the interface, or the network. Here we assume that the attack is independent of the hardware platform running the neural network and does not rely on any sidechannel information. The majority of the API attacks present in the literature either attempt to (1) exfiltrate the model or the model metaparameters, (2) find adversarial examples, or (3) infer some property of the model's training data.
