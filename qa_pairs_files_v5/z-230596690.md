# IET Image Processing Deep learning for occluded and multi-scale pedestrian detection: A review

CorpusID: 230596690 - [https://www.semanticscholar.org/paper/abf4b0aa85edafc82886365bf473ac157509629e](https://www.semanticscholar.org/paper/abf4b0aa85edafc82886365bf473ac157509629e)

Fields: Computer Science, Engineering

## (s2) Two-stage detection framework
Number of References: 3

(p2.0) Two-stage network framework detection method is usually called region-based detection method. First, it obtains the proposals of the object by sliding window or selective search, then extracts the convolution feature in the region by using CNN, and finally classifies and recognises the feature by using classifier. Girshick et al. [13] combined traditional machine learning methods with CNN and proposed a detection framework based on RCNN as shown in Figure 3, of which the selective search is used to obtain as many object proposals as possible; CNN is used to extract the features of the proposals instead of manual extraction and SVM is used to classify the feature vectors. The results showed that the RCNN method owns the powerful processing ability of CNN in the field of computer vision. Later, spatial pyramid pooling (SPP) Net [14] and Fast RCNN [15] have been improved by introducing SPP layer and region of interest (ROI) pooling layer, respectively. However, the number of the proposals is too large, which is accompanied by a large amount of computational consumption in the proposals generation process, and limits its application scenarios. In response
## (s4) Features extraction
Number of References: 2

(p4.0) The accuracy of pedestrian detection depends on the accuracy of its feature description and the classification ability of the classifier. Pedestrian detection method based on deep learning is to extract pedestrian features through CNN. However, the convolution neural network has a strong expansibility, so most researchers change the structure of convolution neural network to extract more accurate pedestrian features. Network architecture plays an important role in feature extraction. It is the most basic and effective process to improve the performance of detectors by improving the network architecture in the feature extraction process. The continuous evolution of RCNN algorithm series is the continuous improvement of its network architecture. By changing the number, distribution structure and function of each convolution layer in the network, the convolution network can achieve higher detection performance [17][18].
## (s5) Training and classification
Number of References: 5

(p5.0) Detector performance is greatly affected by network training process and classifier. The classifier plays a decisive role in the performance of pedestrian detection. Different training strategies will affect the classification ability of the classifier. For the algorithm based on two-stage detection framework, feature extraction and classifier training are independent. In this process, some researchers focus on feature extraction, while some researchers try to explore more effective training strategies to improve the performance of classifier. Because of the complexity of pedestrian samples, it is necessary to design appropriate classification strategies according to pedestrian characteristics in the process of network training. Table 1 lists several different training methods and pedestrian detectors of classifiers. Among them, miss rate (MR) [22] is the evaluation result in the reasonable subset of Caltech [23], which is the meaning of all MR in this study. The content of dataset and pedestrian detector performance evaluation will be detailed in Section 4. Zhang et al. [24] used the Faster RCNN detection framework to detect pedestrians, they found that the Softmax classifier used by Faster RCNN cannot effectively used the features provided by the fully connect layer, resulting in the classifier unable to adapt to low pixel pedestrians. They combined RPN network with Boosted Forests (BFs) on the basis of Faster RCNN. Meanwhile, BF classification strategy was introduced on the basis of RPN detector, the ability of classifier to mine difficult cases was strengthened, and the problem of weak generalisation ability of Faster R-CNN in pedestrian detection was improved. According to the different features extracted, the corresponding classification strategy was set up to avoid the miscalculation of multiple features by the classifier. The detection accuracy is improved by balancing the ability of feature extraction and classification training. Cai et al. [25] deduced a complexity-aware cascade training algorithm (Comp ACT) to optimise the classification risk under the constraint of feature complexity, so that the highcomplexity features can be trained in the later stage which can better combine feature extraction and classifier functions. It is very effective to train the classification sub network for detecting pedestrians of different scales to improve the ability of the detector to deal with low pixel pedestrians, and achieves a high-precision pedestrian detection. Scale-aware fast regionconvolutional neural networks (SAF RCNN) [26] proposed a weighting mechanism based on scale perception for pedestrian features at different scales. It used sub-networks to train pedestrian images at different scales separately, which improved the performance of private sub-networks at different input scales and ensured the detection performance in a certain scale range.
## (s7) Single-stage detection framework
Number of References: 8

(p7.0) Although the two-stage network framework has made great breakthroughs in accuracy, the performance of end-to-end learning cannot be reflected due to the hierarchical method of region extraction combined with training. To solve this issue, a single-stage network framework is proposed to speed up detection by removing the regional proposals generation stage. By setting anchors in advance, the input image is convoluted directly, and then the anchors in the convolution map are regressed and classified. In practical testing, it has more efficient detection speed and is easily transplanted to embedded system. However, its direct detection on the original image means that the training process is very complex and the trained model is difficult to guarantee better robustness, so the accuracy cannot replace the two-stage framework. You only look once (YOLO) [35], Single Shot MultiBox Detector (SSD) [36] are representative single-stage network frameworks. YOLO divides the input image into S Ã— S units, each unit is responsible for the centre of the unit's object detection, using a one-time prediction of the object boundaries, positioning confidence and all kinds of probability vectors. At present, several versions have been updated according to their performance, such as YOLOv2 [37], YOLOv3 [38]. Different from YOLO, SSD detects multi-scale objects directly in the convolution layer by setting anchors of different scales on the image, calculating and regressing all the anchors and confidence in the detection process, and detecting multi-scale objects by setting convolution maps of different scales. SSD has advantages over YOLO in solving small-scale and location problems. The network structure of SSD and YOLO is shown in Figure 6.

(p7.1) The proposer of SSD algorithm used the original SSD in pedestrian detection and found that the results were worse than those of RCNN framework pedestrian detection algorithm. The reason is that SSD has poor ability in reducing false positives when dealing with pedestrians in complex scenarios. Inspired  [40] proposed an improved method based on asymptotic localisation fitting (ALF). By setting different IOU thresholds on the feature map for multiple regression, the regression boxes of the upper layer is used as the anchor boxes of the next layer. The results show that the detection accuracy reaches the most advanced level under the condition of guaranteeing high detection speed. Based on the SSD framework, Du et al. [41] proposed a deep neural network fusion structure FPGA-Deep Neural Networks (F-DNN) for fast and robust pedestrian detection. It used a single convolution network to generate pedestrian proposals, and used several deep neural networks to optimise the results in parallel. At the same time, it integrated the pixel-level semantic segmentation network into the detection architecture to enhance the pedestrian detector.

(p7.2) The outstanding advantage of single-stage network is its excellent detection speed, but the accuracy is slightly inadequate. In order to increase the detection accuracy of YOLOv3 in automatic driving applications, by constructing the boundary frame model with Gauss parameters, [42] proposed a new predictive localisation algorithm to improve the reliability of the border. This method guaranteed the excellent detection speed of YOLOv3 and greatly improves the accuracy. The authors of [43] proposed a hybrid attention mechanism HARNet for singlestage object detection. First, spatial, channel and focused attentions are used for single-stage object detection. Then, the consistent attention mechanism was constructed into a deformable filter, and the hybrid attention mechanism is embedded in Retina-Net to complete single-stage object detection. Through the combination of multiple attention mechanisms and singlestage network, HARNet improves the single-stage network to locate the pedestrian area quickly and accurately, and solves the problem of missing detection caused by too many anchors in the single-stage network.
## (s10) Multi-scale proposals or feature maps
Number of References: 7

(p10.0) The initial RCNN focused on the sampling of multi-scale object in the process of generating proposals, but the excessive number of proposals led to the inefficiency of its calculation. Although the proposals of RPN solve this problem to some extent, the proposals for small-scale pedestrians are not fully covered. SAF RCNN [26] and MS-CNN [20] extended Fast RCNN and Faster RCNN to deal with scale change, respectively. F-DNN [41] used multiple deep classifiers combined with soft filters to further validate each proposal. SSD [36] divided the output feature map into a set of template boxes by using boundary boxes with different aspect ratios and proportions, and then constructed multi-scale target detector using complementary detection method in different output layers. Recent studies have different views on multi-scale pedestrian detection. But they have similarities, that is, they all consider the impact of the region proposals generation on multi-scale pedestrians.

(p10.1) In Figure 8, we briefly describe the details of the relevant methods to deal with multi-scale detection problems. Zhang et al. [52] proposed a new multi-scale pedestrian detection method (Active Detection method, ADM). Based on the characteristics of ResNet and RCNN, the multi-layer convolution feature of the input image and the initial pedestrian proposals were taken as input, and the coordinate transformation action sequence was carried out to realise the accurate prediction of boundary frames of different scales. GDFL [33] proposed a scale-aware pedestrian attention module to guide the detector to focus on pedestrian regions. It calculated the probability of pedestrian presence at each pixel by generating pedestrian attention masks and integrated the masks with the convolution feature map after coding, which not only highlights the pedestrian but also significantly eliminated the background interference, and improved the recognition ability of small-scale pedestrian and occluded pedestrian. SSA CNN [31] proposed a multi-scale and multi task learning framework. By learning pedestrian detection and semantic segmentation from the multi-scale network layer, the semantic information with different granularity is integrated with the shared feature maps. It connects two semantic segmentation branches to different scale network layer to obtain multi-scale semantic feature map. Then, the multiscale semantic feature map is used as the semantic clue and connected with the corresponding convolution feature map to provide the pixel level classification information, improve the classification ability of pedestrians, and reduce the difficulty of pedestrian bounding box regression.
## (s11) Different training and classification strategy
Number of References: 6

(p11.0) Another way to deal with multi-scale detection problem is to use different stages of classification strategy. In Comp ACT [25] and RPN+BF [24], cascade boosting and BF classifiers are used to classify images with different resolution under deep feature maps, the characteristics of small-scale image are fully mined, and are not limited by the structure of pre-training network. Similar methods are used in [48] to classify multi-scale deep convolution feature maps by using the booted decision forests. It trained a group of enhanced boosted decision forests through multi-layer convolution feature map, and effectively improved the detection ability of the detector for multi-scale pedestrians by using the enhanced boosted decision forests of different scales trained. SAF RCNN [26] classifies multi-scale proposals by training sub networks of different sizes. And ALF [40] refines the classification results by cascading regression on multi-scale feature maps. In addition, [58] adopted an unsupervised training deep network, which combines multi-step global feature and local feature classification. It used multi-stage features and connections that skip layers to integrate global shape information with local distinctive motif information, especially the unsupervised method based on convolutional sparse coding to pre-train the filters at each stage. The method of unsupervised training and fusion of various feature maps ensures that the detector can adapt to the changes of pedestrians with different pixel sizes, so as to enhance the detection ability of pedestrians with small pixels.
## (s12) Annotation method
Number of References: 6

(p12.0) The pedestrian detection method based on deep learning needs to input a certain number of labelled images to train the CNN. The quality of the input image determines the detection ability of the trained detector. Among them, the size, resolution and label position of the image affect the accuracy of the detector after training. Therefore, some researchers explore how to label pedestrian images with different scales to guide the feature extraction ability of CNN for small-scale pedestrians. In order to better realise the ability of the detector to learn small-scale pedestrians, Song et al. [53] analysed the bias of image boundary frames in the training stage, and a multi-scale pedestrian detection method (TLL) was proposed based on the topological line localisation and temporal feature aggregation. By establishing the topological information of human body model in different scales, the topological information is used as the annotated training detector in the training stage as shown in Figure 9. Pedestrians over different scales could be modelled as a group of 2D Gaussian kernels. And a post-processing scheme based on Markov random field is proposed to improve the positioning accuracy under crowd occlusion. Zhang et al. [47] verified that the initial annotation information plays a decisive role in detector training. Through more detailed post annotation training in Caltech dataset, MR is 3% lower than before. In addition, CMFs [48] used additional pixel annotation to improve the perfor-

(p12.1) The annotation method of TLL [53] FIGURE 10 The examples of pedestrian occlusion mance of the detector. They proposed a combination of sliding window detectors and semantic pixel labelling, and used the weighted sum of pixel labelling scores within a proposal region to represent the score of the proposal. This method can ensure that the pixel information can be retained in the training process and achieve the purpose of identifying low pixel pedestrians. On the other hand, the annotation method can also improve the detector's ability to deal with occlusion problems, and the typical ones are JL-TopS [49]. The human body parts are labelled in different levels during training, which promotes the detector's perception of occlusion. The multi-scale detection capability is only part of the performance of pedestrian detector. Its development is from the initial single-scale detection method to the feature pyramid, then to the multi-detection model and advanced semantics assistant detection. Its inherent purpose is to enable the detector to deeply mine the feature differences of different scale images in the training process, so as to obtain more general purpose detection performance.
## (s18) Pedestrian detection dataset
Number of References: 11

(p18.0) Dataset is one of the foundations and decisive factors in the process of pedestrian detection research. It is not only the common basis for measuring and comparing the performance of competitive algorithms, but also a powerful assistant to promote the development and progress of research in this field. The number of datasets and the quality of annotated information are critical for training detectors. Detectors need more data to enrich their ability to adapt to multiple scenarios, and accurate annotation information can better guide the detector to learn what it needs. So far, the published pedestrian datasets include MIT [4], INRIA [3], Daimler [7], Caltech [23], KITTI [30], TUD [44], NICTA [68], ETH [8], CVC [69], USC [70], and Citypersons [27] pedestrian datasets. According to the different content of each dataset, each dataset has its own characteristics. Among them, Caltech, KITTI and Citypersons pedestrian datasets have more complete annotation information and better annotation for occluded and multi-scale scenes, hence, they are most widely used. We summarise these three common pedestrian detection datasets in detail as shown in Table 4. Caltech dataset is the largest pedestrian dataset at present, which is photographed by car camera with about 250,000 frames (about 137 min), 350,000 bounding boxes and 2300 pedestrian annotations. In addition, the time correspondence between rectangular frames and their occlusion are also labelled.
