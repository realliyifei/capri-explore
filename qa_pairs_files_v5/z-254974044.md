# How can we combat online misinformation? A systematic overview of current interventions and their efficacy

CorpusID: 254974044 - [https://www.semanticscholar.org/paper/6ce5e6fc425306bbd3d9ca659dbf7c78f42c6c33](https://www.semanticscholar.org/paper/6ce5e6fc425306bbd3d9ca659dbf7c78f42c6c33)

Fields: Sociology, Computer Science, Political Science

## (s20) Inoculation games
Number of References: 2

(p20.0) Inoculation games are designed to reduce people's susceptibility to misinformation through 'prebunking'. In these games, players typically navigate a simulated social media environment while also learning about common methods that purveyors of misinformation rely on. Players may also be exposed to common cues which signal content as misinformation, such as emotionally manipulative language, incoherence, false dichotomies, scapegoating, and ad hominem attacks. The process of psychological 'inoculation' is rooted in the idea that just as injections containing a weakened strain of a virus trigger antibodies in the immune system to help confer resistance against future infection, the same can be achieved in building protection against misinformation. By preemptively warning people against misleading tactics and by exposing people to a weakened version, it is claimed that cognitive resistance can be developed against a range of misinformation types and contexts (Lewandowsky & van der Linden, 2021;Traberg et al., 2022). While the games currently rely on voluntary participation, it is possible that they could be implemented in educational settings, or be routinely offered by platforms and websites as users are browsing.
## (s21) Public awareness campaigns
Number of References: 7

(p21.0) Public awareness campaigns are broadly aimed at increasing awareness of the prevalence of online misinformation across society. These campaigns are typically implemented by governments and platforms and take short, advert-like formats. Public awareness campaigns are broadly feasible to implement and have the potential for a wide reach given they can take the form of paper leaflets and posters (e.g., distributed in libraries), television and radio ads, and social media campaigns. As the campaigns are designed to increase alertness to possible misinformation before exposure, they avoid ethical concerns surrounding content moderation. However, one concern that public awareness campaigns have in common with generalised warnings is that in promoting scepticism, audiences may also experience decreased trust in legitimate news stories (Clayton et al., 2020;Pantazi et al., 2021). Additionally, the efficacy of public awareness campaigns relies on trust in whichever authority implements the campaign, which may differ heavily between individuals (J. D. West & Bergstrom, 2021).

(p21.1) Further research should focus on discrimination between true and false content as an outcome measure to ensure that the kinds of messages found in public awareness campaigns do not simply enhance scepticism overall. Such campaigns may be best used in conjunction with deeper educational approaches, serving as important reminders for people to draw on the media literacy skills they previously learned. There is overall support for the efficacy of fact-check labels in reducing susceptibility to misinformation and reducing misinformation sharing intentions (for a review, see Nieminen & Rapeli, 2019). One research study showed that adding a 'disputed' or 'rated false' tag to a headline significantly lowered its perceived accuracy relative to a control condition and that these overlays were more effective at reducing susceptibility to misinformation than general warnings (Clayton et al., 2020). Additionally, in the same study, fact-check labels did not affect the perceived accuracy of unlabeled false or true headlines (unlike general warnings mentioned above). Other studies similarly find that exposure to a fact-check tag improves accuracy judgments about the specific content (Ecker et al., 2010;Nyhan et al., 2020).
## (s23) Prompts
Number of References: 3

(p23.0) Prompts that appear when a user is about to post content (also referred to as 'accuracy nudges' or 'friction') are designed to draw a user's attention to the accuracy of a headline prior to them sharing it, or otherwise slow down human interaction with a platform (Kirchner & Roesner, 2022). These prompts are typically found on social media platforms. The shift in focus intends to induce extra caution or to make users think twice prior to sharing. The intervention targets the act of sharing misinformation, shown to substantially reduce its reach (AndÄ± & Akesson, 2021;Pennycook et al., 2021). The appeal of posting prompts are that they are proactive, as well as that they allow full freedom for users to decide for themselves what content to publish and remove technology companies from the position of having to decide what is true or false.
