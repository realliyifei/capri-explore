# Generative Adversarial Networks: A Literature Review

CorpusID: 232895648 - [https://www.semanticscholar.org/paper/c7db4378b9a677a301e25f7340e5ee1db904d571](https://www.semanticscholar.org/paper/c7db4378b9a677a301e25f7340e5ee1db904d571)

Fields: Computer Science

## (s0) Introduction
Number of References: 21

(p0.0) With the emergence of autonomous driving, machine translation and other technologies [1][2][3], Artificial intelligence (AI) gradually entered public life [4][5][6]. All the time researchers were trying to improve the learning and optimization ability of computers, machine learning (ML) has officially entered the stage of AI. Machine learning is a method of learning with data or previous experience to optimize the objective model's performance [7]. According to the way of learning, it can be divided into supervised learning, semi-supervised learning, unsupervised learning, transfer learning and reinforcement learning (RL) [8]. Transfer learning is a learning method that transfers the trained model parameters to a new model for training [9][10][11]. Reinforcement learning is used to describe and solve the problem that agents use learning strategies to maximize returns or achieve specific goals in their interaction with the environment [12,13]. It contains the value-based algorithm and the policy-based algorithm. Supervised learning is a method to use the existing data and their relationship to train the optimal model [14]. The classical algorithms are Naive Bayesian Classifier [15], Decision Tree [16], k-Nearest Neighbor (KNN) [17], Support Vector Machine (SVM) [18] and so on. However, once there is a lack of prior knowledge in real life, it is difficult for machines to serve humans due to the increased difficulty in manual labeling of categories and the high cost of categories.

(p0.1) Fortunately, unsupervised learning represented by clustering algorithm provides ideas for solving such problems [19,20]. In 2014, Ian Goodfellow et al. [21] proposed a generative model named Generative Adversarial Networks (GAN). It is composed of a generator and a discriminator. The generator is responsible for producing samples, and the discriminator is responsible for distinguishing the authenticity of samples. Since the goal of each side is to defeat the other, the model that optimizes itself is continuously modified, and the generator after the final training can generate a nearly real sample through any input.
## (s2) Game Theory
Number of References: 3

(p2.0) The inspiration of GAN comes from the zero-sum game in game theory [23]. The zero-sum game, a non-cooperative game, is defined as a game in which two parties are strictly opposed to each other, where the gains of one party are bound to bring losses of the other party, and the gains and losses of both parties add up to zero [24]. In GAN, the discriminator judges the samples generated by the generator. The more real the images generated by the generator, the more difficult it is for the discriminator to judge the authenticity and falsity. Similarly, in the early training period, the samples with poor quality generated can be easily identified as false samples. Eventually they will reach an equilibrium point in the game named the Nash equilibrium. Nash equilibrium refers to the strategy adopted by both sides of the game to maximize their own interests [25]. In continuous training, the generator seeks to generate enough samples to fool the discriminator, which tries to recognize the authenticity of all the samples. The process of mutual game is also a characteristic and highlight of generative adversarial networks.
## (s5) Variational Autoencoders (VAE)
Number of References: 5

(p5.0) Autoencoder is a data compression algorithm, in which the data compression and decompression are realized by neural network self-learning [34]. The encoder maps the input data to the low-latitude features we need, and then reconstructs the original input data through the decoder. Variational Autoencoder [35] is a method that adds "Gaussian noise" to the result of the encoder in Autoencoder to make the result of decoder robust to noise.

(p5.1) In the formula above, X is training data, and Z is the hidden feature that cannot be observed in X data. The characteristic of VAE is that every one-dimensional distribution of Z conforms to a normal distribution, and the learning of characteristics is introduced to make the decoding effect better [36,37]. However, VAE adopted the Variational Inference [38] for approximation. Compared with GAN, the fitting of the real data is not as good as GAN. From the result of the generated picture, the picture clarity of GAN is also better than that of VAE.
## (s19) Natural Language Processing (NLP)
Number of References: 4

(p19.0) Natural language processing is the study of normal communication between humans and computers using natural language [78]. At present, NLP is mostly based on statistical machine learning and applied in emotional processing, machine translation, text extraction and other directions [79][80][81]. However, NLP did not make great progress in the early days of GAN. The reason is that GAN is mainly applied to continuous data, while text is mainly discrete data. According to the discriminant result, the discriminator will give feedback to the generator after the sequence generated by the generator is inputted. With the efforts of researchers, GAN has made some achievements on NLP in recent years.
## (s21) Audio Generated
Number of References: 3

(p21.0) With the development of advanced learning, the ability of computer natural language processing is gradually improved, but it is seldom applied in audio processing. Previous audio generation methods are generally based on text. This approach requires humans to record a large number of voice databases, which is inefficient and produces unnatural audio [85]. In 2016, Google DeepMind proposed a deep generation model of raw audio waveforms called WaveNet [86], which chose to directly model the original waveform of audio signals, expanding the variety of audio and increasing the authenticity of audio generation. However, since the audio has a sequence, WaveNet, which belongs to the autoregressive model, needs a long time to conduct continuous sampling, and researchers have been trying more generation methods, such as MelodyRNN, DeepBach and so on [87].
## (s26) Domain Transformation
Number of References: 3

(p26.0) Text to image is an input sentence to generate an image. Due to GAN's excellent performance in graphic image processing, many new models have been created on the result of this kind of domain transformation. Scott et al. proposed GAN-INT-CLS [99], which generates a network that inputs text features to obtain images. Then, GAWWN [100] was proposed by this team to improve the accuracy of the generated images. In terms of image to text, Liu et al. proposed the method of generating poetry through images, which for the first-time incorporated image processing and poetry generation into a framework, making the cognition of machines have the ability to approach human beings [101].
## (s29) Cyber Security
Number of References: 5

(p29.0) Nowadays, Cyber Security has attracted more and more attention from researchers because of the progress of big data, Internet of things (IoT), blockchain and other hot spots [108]. At the same time, the gradually increasing numbers of network anomalies threaten the normal operation of the network, such as Challenge Collapsar (CC) attack, distributed denial of service (DDoS) attack, malware, worm [109]. However, network abnormal behavior is not a simple image or text, and it is difficult to process with GAN. Meanwhile, as the detection technology of abnormal network behaviors, the researchers turn to the source of the attack and plan to use the method of generating abnormal behavior samples to simulate the attack, so as to improve the detection ability of the existing detection technology.

(p29.1) Hu et al. proposed MalGAN [110], a generation model of malware. This model used a neural network-based alternative detector to match the black box detection to generate samples that could fool the detector so as to by passing the black box detection. The DeepDGA [111] algorithm can generate a large number of pseudo-random domain names through the training of GAN. Kim et al. proposed tDCGAN [112], which turned the malicious software into pictures, adopted self-encoder as the generator of GAN, and finally trained discriminator that adopted transfer learning method to detect zero-day malicious software.
