# Scheduling in cloud manufacturing systems: Recent systematic literature review

CorpusID: 228969851 - [https://www.semanticscholar.org/paper/452df82a18974297a9595b6c0c6045bdbfe79e54](https://www.semanticscholar.org/paper/452df82a18974297a9595b6c0c6045bdbfe79e54)

Fields: Computer Science, Medicine, Engineering

## (s6) Game Theory based approach
Number of References: 6

(p6.0) A widely used approach for decision-making problems in CMfg is Game Theory. The main advantage of this approach is that it allows the decision-making process to be decentralized so that customers and suppliers of production resources directly coordinate their activity. In Liu et al. [36] the system under study is modeled as a multi-agent system, in which the different agents negotiate and resolve the decision problems involved in CMfg. To do this, first, customer orders must be broken down into subtasks in order to be able to make the corresponding matching between subtasks and productive resources. In Xiao et al. [37], also a decentralized problem is analyzed but considering the customer's perspective. The customer establishes his payments in order to minimize total production times, total production costs, and improving reliability. To find Nash equilibria, a Biogeography-based optimization algorithm is used. Chen et al. [38] suggest a cooperative game approach, in which customers seek to obtain resources to produce their orders. Initially, the allocation of clients to resources is done centrally, and then, in a second stage, collaborative games are proposed with the aim to improve the initial allocation. The authors demonstrate that this problem is NP-hard. Finally, the authors propose dynamic programming algorithms to solve some of the problems proposed.

(p6.1) Another type of problem that can be addressed with game theory is the case of incomplete information, as in Liu et al. [39]. In this work, the authors propose a decision mechanism based on a double auction. These auctions are held between the service applicant (customer) and the service provider (producer). The mechanism ensures that the services finally assigned meet the quality, time, and cost preferences defined by the clients. Another approach to address the problem is to consider a non-cooperative public goods game model as in Bai et al. [40]. This approach allows us to converge towards an optimal schedule more efficiently than other methods, such as Genetic Algorithm (GA). Another strategy is to consider biddings as in Liu et al. [41]. The objective of this work is to maximize the overall benefit of all participants. In the case of decomposing the production tasks into sub-tasks, the bidding method is also applied. The authors' results make it possible to ensure that the proposed approach efficiently solves the problem, as well as to ensure trust and fairness among the participants.
## (s8) Machine learning and Artificial intelligence
Number of References: 8

(p8.0) This subsection analyzes the articles that have used methods based on Machine Learning or Artificial Intelligence. This subsection clearly shows the speed of growth in the study of scheduling problems in CMfg. Until the review of [11] there are practically no papers based on these approaches, while from that review to the moment, there have been several publications in this field. As the first contribution in this line is Liu et al. [25], where the same authors as in [11], propose an exploratory study on the subject. In [25], a deep reinforcement learning (DRL) based approach is proposed, which combines the benefits of deep learning with reinforcement learning. The work develops a framework where the different scheduling problems in CMfg environments can be solved from DRL. This approach would automatically extract high-level characteristics of tasks and resources, as well as the learning inherent in scheduling patterns, rules, and approaches. In Chen et al. [64], the objective is to minimize the makespan and the total traveled distance. To obtain non-dominated solutions, the authors develop an agent system that makes decisions using the method of Reinforcement Learning based Assigning Policy (RLAP). Under the RLAP approach, tasks are assigned to each agent, which allows to solve problems with dynamic features. Dong et al. [65] suggests a Deep-Q-Network (DQN) method for the task assignment problem, which includes a classification of the tasks and the current status of the process. The proposed method is compared against other classical resolution heuristics proposed to minimize the makespan. The numerical experiments show the benefits of DQN when surpassing the other methods. An application based on Artificial Neural Networks (ANN) can be found in Zhu et al. [27]. A multi-user demand problem and the resource allocation problem are presented as a multi-objective optimization problem. This multi-objective problem seeks to minimize operating time, maximizing the use of resources, and minimizing general expenses. The authors transform the multi-objective problem into a reinforcement learning (RL) problem and solve using ANN. In Morariu et al. [66] , recurrent neural networks (RNN) are applied. In this case, the authors use the RNN to generate a predictor of future scenarios and thus obtain the schedule. To do this, the providers of productive resources provide information in real-time, about the current state of the production process. This information is then filtered and processed by RNN, to estimate the near-future scenario, and this feeds the optimizer that determines the schedule.
