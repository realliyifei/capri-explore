# A Review on Video-Based Human Activity Recognition

CorpusID: 5664472 - [https://www.semanticscholar.org/paper/f2985c9c03e0113e27a473d5f2b064de10804110](https://www.semanticscholar.org/paper/f2985c9c03e0113e27a473d5f2b064de10804110)

Fields: Computer Science

## (s11) Space-Time Volumes (STV)
Number of References: 6

(p11.0) The space-time volume (STV) is formed by temporally stacking frames over a video sequence as a 3D cuboid of spatial-temporal shape.Blank et al. [2] propose a method, by stacking segmented silhouette frame-by-frame, to form a 3D spatial-temporal shape, from which the space-time features such as local space-time saliency, action dynamics, shape structure and orientation can be extracted [2].Ke et al. [3] further uses the spatial-temporal shapes for shaped-based matching, including spatial-temporal region extraction and region matching.For region matching, an unsupervised clustering technique is applied to group the video into classes of 3D volumes of consistent appearance.In order to overcome the limitation of shape-based approaches, such as changes in camera view and variability in the speed of actions, Ke et al. [3] also incorporate Shechtman and Irani's flow-based features [51] into the classifier to improve the performance.Moreover, Dollar et al. [11] applies a spatio-temporal interest point detector to find local region of interest in the cuboids of space and time for activity recognition.First, cuboids of spatio-temporally windowed data surrounding a feature point extracted from sample behaviors are clustered to form a dictionary of cuboid prototypes.The histogram of the cuboid types is then used as an activity descriptor for object recognition.Generally, the STV features provide a proper way to combine spatial and temporal information; however, STV features normally require good segmented silhouette and are sensitive to viewpoint and occlusion.
## (s47) Entertainment Environments
Number of References: 23

(p47.0) Human activity recognition can also be used to recognize entertainment activities, such as sport [3][4][5]7], dance [2,51] and gaming [10,15,39], in order to enrich lifestyles.Various video-based entertainment activity recognition systems have been proposed.

(p47.1) For the purpose of recognizing sportive activities, Yamato et al. [4] might well be pioneers in applying HMMs to recognize the time-sequential images of tennis scenes, including six tennis strokes such as forehand stroke, backhand stroke, forehand volley, backhand volley, smash and serving.In [7], Luo et al. developed an object-based method for video analysis and interpretation of sports video sequences.The sport behaviors are effectively recognized by using DBNs, which can generate a hierarchical description for video events, including bowling, downhill skiing, golf swing, pitching, and ski jumps recorded from real scenarios, with cluttered background and moving cameras.Ke et al. [3] exploit the use of volumetric features for the recognition of actions such as serve, run right and return serve actions in the tennis sequences when combined with flow-based correlation techniques.By using an extended behavior-based similarity measure, Shechtman and Irani [51] were successful in detecting dives into a pool during a swimming relay match.Despite the numerous simultaneous activities and despite the severe noise, this method is able to separate most dives from other activities.

(p47.2) The 3D shapes induced by the 2D silhouettes in the space-time volume are used by Blank et al. [2] for action detection in a ballet movie.The method utilizes properties of the solution to the Poisson equation to extract space-time features, such as local space-time salience, action dynamics, shape structure and orientation.The effectiveness and robustness of the method is demonstrated via an example of finding all the locations in the movie where an action called "cabriole" (beating feet together at an angle in the air) is performed by either a male or a female dancer.Besides the ability of detecting diving in a pool, the method developed by Shechtman and Irani [51] is also successful in detecting the single turn of a dancer in a very fast moving ballet video sequence.

(p47.3) One of the most popular leisure activities is playing video games.A number of methods are developed for this purpose [10,15,39].Richard et al. [39] developed Pfinder as a real-time system for tracking people and interpreting their actions by using a multi-class statistical model of color and shape to obtain the head, hands and feet positions in different viewing conditions.Pfinder has been successfully used in several different human interface applications, e.g., to navigate a 3D virtual game environment or to place the player at a particular place in a virtual room, which is populated by virtual occupants from real-time 3D computer graphics based on live video.In [15], Huo et al. present a method for human motion capture and pose recognition.The human torso and the hands are segmented from the whole body and tracked over time.A 2D model is used for the torso detection and tracking, while a skin color model is utilized for the hands tracking.Moreover, 3D location of these body parts are calculated and further used for pose recognition.The implementation of the proposed approach is simple, easy to realize, and suitable for real gaming applications.Ke et al. [69] also perform a similar 3D human pose estimation task, but they only use one camera rather than multiple cameras as in [15].Moreover, their system can estimate 3D poses not only the upper body part as in [15] but also the lower body part including knees and feet.A simple video game is implemented, i.e., a 3D avatar, generated by real-time, based on the derived 3D poses of the proposed system, to hit balls so as to get scores or to avoid attacks from flying balls.
