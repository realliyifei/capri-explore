# A Survey on Causal Inference for Recommendation

CorpusID: 257637133 - [https://www.semanticscholar.org/paper/301b07ecba0864c5bad4039d6a0bc93687417443](https://www.semanticscholar.org/paper/301b07ecba0864c5bad4039d6a0bc93687417443)

Fields: Computer Science

## (s12) Causal Recommendation
Number of References: 10

(p12.0) To address this issue, early approaches tend to predict the missing data directly [130] but have accentuated the problem of high bias [112,143]. Recently, many researchers have resorted to the propensity score ( ) in causality to recover the data distribution. For example, ExpoMF [74] first predicts the exposure matrix and then uses the exposures (i.e., propensity scores) to guide the model of the interaction matrix, which is inspired by the separation between propensity scores and potential outcomes in the PO framework. Similarly, Wang et al. [138] propose SERec to integrate social exposure into collaborative filtering. A refreshing work is that Wang et al. [144] aim to overcome the confounder issue with propensity score. They regard correlations among the interacted items as bringing indirect evidence for confounders and propose the deconfounded recommenders. They first build an exposure model to estimate the propensity score and then use this exposure model to estimate a substitute for the unobserved confounders, conditional on which the final outcome model (specifically in [144], a rating model based on matrix factorization) is trained. In addition, inspired by [24,59], Chen et al. [13] propose IOBM (Interactional Observation-Based Model)to estimate propensity score in interaction settings, which learns low-dimensional embeddings as a substitute for unobservable confounders . Specifically, it learns individual embeddings to capture the potential outcome information from specific exposure events. Based on individual embeddings, the interactional embeddings, which uncovers the hidden relationship among single exposure events and utilizes query context information to apply attention, are learned through the bidirectional LSTM model.
## (s22) Doubly Robust.
Number of References: 23

(p22.0) Doubly Robust (DR) [22,26,56,143] is another powerful and effective causal method account for the MNAR issue. To understand DR, let us consider the two common-used approaches to mitigate against MNAR: direct method (DM) [7] and IPS [114]. The former designs a model (linear regression, deep neural network, etc.) to directly learn the missing outcomes based on the observed data, which has low variance due to the advantage of supervised learning but suffers from high bias caused by unmet IID assumptions, denoted as [114]: where^( , ) is the estimated outcomes. The latter, though unbiased theoretically, often causes training losses to oscillate stemming from the inverse of propensity with high variance [134]. What DR does is to combine the direct method and IPS, which takes advantage of both and overcomes their limitations:

(p22.1) DR uses the estimated outcomes to decrease the variance of IPS. It is also doubly robust in that it is consistent with the policy reward value if either the propensity scores or the imputed outcomes are accurate for all user-item pairs [114,143].

(p22.2) By the way, advanced versions like Switch-DR [145] and DRos (Doubly Robust with Optimistic Shrinkage) [131] are proposed to further control the variance.

(p22.3) Based on the above advantages, DR has found an increasingly wide utilization in RS [41,64,87,155,166,172]. Yuan et al. [166] propose a propensity-free doubly robust method to address the issue that samples with low propensity scores are absent in the observed dataset. Zhang et al. [172] propose Multi-DR based on a multi-task learning framework to address selection bias and data sparsity issues in CVR estimation. Gun et al. [41] propose the MRDR (more robust doubly robust) estimator to further reduce the variance caused by inaccurate imputed outcomes in DR while retaining its double robustness. In addition, Kiyohara et al. [64] expand previous RIPS to Cascade Doubly Robust estimator, which has the same user interaction assumption as RIPS. Xiao et al. [155] propose an information bottleneck-based approach to effectively learn the DR estimator for the estimation of recommendation uplift, with the hope of a better trade-off between the bias and variance of propensity scores.
## (s38) DICE [WWW'21]
Number of References: 9

(p38.0) Counterfactual inference with separate structures Fig. 15. Separate-learning-counterfactual-inference, a common pattern of SCM-based causal inference for recommender systems, learns causal effect with a separate structure or multi-task framework and performs counterfactual inference during testing. Though a popular tool, instrumental variable seems to find little application in recommender systems because of the difficulty of finding variables that satisfy the conditions of instrumental variables. As already cited above, Sharma et al. [124] utilize an instantaneous shock in direct traffic as an instrumental variable to evaluate the recommendation effect. Si et al. [126] propose a model-agnostic framework named IV4Rec that effectively decomposes the embedding vectors into two parts: the causal part indicating a user's personal preference for an item, and the non-causal part merely reflects the statistical dependencies between users and items such as exposure mechanism and display position,  [162] Intervention on the treatment MF, LightGCN, etc. Data insufficiency 2021 CauSeR [42].

(p38.1) Intervention on the treatment SR-GNN [153] Popularity bias in SBRSs 2021 MCT [135] Back-door criterion, CATE (self-designed) Disability employment 2021 DecRS [140] Intervention on the treatment FM, NFM [44] Bias amplification 2021 PDA [176] Intervention with users' search behaviors as the instrumental variable. More specifically, it modifies the traditional IV method, using the residual of the least square regression as the causal embedding instead of discarding it. The causal graph is illustrated in Fig. 17.
