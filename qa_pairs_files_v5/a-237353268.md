# Neuron-level Interpretation of Deep NLP Models: A Survey

CorpusID: 237353268 - [https://www.semanticscholar.org/paper/ff56dfdbc8b86decbc6119d96c1097c0fef56ecd](https://www.semanticscholar.org/paper/ff56dfdbc8b86decbc6119d96c1097c0fef56ecd)

Fields: Computer Science

## (s7) Linear Classifiers
Number of References: 4

(p7.0) The idea is to train a linear classifier towards the concept of interest, using the activation vectors generated by the model being analyzed. The weights assigned to neurons (features to the classifier) serve as their importance score with respect to the concept. The regularization of the classifier directly effects the weights and therefore the ranking of neurons. Radford et al. (2019) used L1 regularization which forces the classifier to learn spiky weights, indicating the selection of very few specialized neurons learning a concept, while setting the majority of neurons' weights to zero. Lakretz et al. (2019) on the other hand used L2 regularization to encourage grouping of features. This translates to discovering group neurons that are jointly responsible for a concept. Dalvi et al. (2019) used ElasticNet regularization which combines the benefits of L1 and L2, accounting for both highly correlated group neurons and specific focused neurons with respect to a concept.

(p7.1) Limitation A pitfall to probing classifiers is whether a probe faithfully reflects the concept learned within the representation or just memorizes the task (Hewitt and Liang, 2019;Zhang and Bowman, 2018). Researchers have mitigated this pitfall for some analyses by using random initialization of neurons (Dalvi et al., 2019) and control tasks  to demonstrate that the knowledge is possessed within the neurons and not due to the probe's capacity for memorization. Another discrepancy in the neuron probing framework, that especially affects the linear classifiers, is that variance patterns in neurons differ strikingly across the layers.  suggested to apply z-normalization as a pre-processing step to any neuron probing method to alleviate this issue.

LLM judge: NO

The analysis reveals that the content potentially fails to meet several of the criteria necessary for inclusion in a scientific question-answering dataset. To be specific:

1. The text is logically coherent and contains no non-text elements, which meets criteria 1, 3, and 4. However, it encompasses various detailed pieces of information that require a broader context to fully understand, such as the distinctions between L1, L2, and ElasticNet regularization and their specific impacts on neuron importance ranking within the context of probing classifiers.

2. The limitation section (p7.1) introduces a new discussion about the challenges associated with probing classifiers, namely the issue of whether these classifiers actually reflect learned concepts or simply memorize tasks. This introduces a shift that, while connected to the main topic, starts to cover a different aspect that requires its understanding along with the initial explanation, potentially affecting the self-contained and comprehensive criteria (criteria 5 and 2, respectively).

3. Although both paragraphs are related to the overarching topic of neuron importance and classifier regularization, the transition from discussing regularization techniques to probing limitations introduces multiple complex concepts that cannot be summarized effectively in a single question without losing significant context or oversimplifying.

Additionally, the content might be too specialized and necessitate background knowledge beyond what is provided in the text to form a self-contained and comprehensive question suitable for a general scientific question-answering dataset.

