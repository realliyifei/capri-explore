# fermentation A Review Unveiling Various Machine Learning Algorithms Adopted for Biohydrogen Productions from Microalgae

CorpusID: 257346609 - [https://www.semanticscholar.org/paper/0a49520fd4e23ff95a1e2e7cb443caba45e4568e](https://www.semanticscholar.org/paper/0a49520fd4e23ff95a1e2e7cb443caba45e4568e)

Fields: Environmental Science, Biology, Computer Science, Engineering

## (s0) Introduction
Number of References: 4

(p0.0) Hydrogen that is produced from microalgae, either through photo-fermentation or dark fermentation, is known as microalgal hydrogen. It is a subset of biohydrogen, defined as hydrogen that is produced biologically from microorganisms using renewable biomass materials [1,2]. Microalgal hydrogen production has garnered considerable interest from academia as well as industry due to its potential as an alternative energy source. However, the nature of the complex biological processes and factors involved have made studies and process modelling very arduous. Researchers have recently employed machine learning (ML) to overcome this concern. ML is defined as building algorithms that can predict an outcome based on a statistical analysis of input data. The application of ML to studies can generate regression models that describe the relationship between independent variables and dependent variables [3,4]. These algorithms come in various forms, depending on their purposes and effectiveness.
## (s4) Support Vector Machines
Number of References: 8

(p4.0) Support vector machines (SVM) are designed for binary classification in a multidimensional space. The working principle of SVM involves the identification of a hyperplane, a boundary that separates outcome categories to their full extent [18]. SVM applies a data transformation to the sample data and projects it to a desired dimensional space that is higher via a kernel function. A kernel function is defined as a function that returns the inner product (dot product) between the images of two data points (x, x') in the higherdimensional space. ML then takes place in this space [24]. An example of a dot product between x ij and x ij ' can be mathematically shown below:

(p4.1) There are multiple kernel functions available depending on the data set, as it needs to have its dimensionality increased to obtain the hyperplane (Table 1) [25]. These kernel functions of two data points all aim to reach the target space T. Among these equations, Karatzoglou and Meyer (2006) stated that the Gaussian radial basis function (RBF) is the most suitable when there is no pre-existing knowledge available regarding a data set [24]. They also stated that the linear kernel function is beneficial for large and inadequate data points. The performance of SVM is based on the established regularization parameter C (box constraint) and the kernel parameter (scaling factor), which make up the hyperplane parameter. Having a high value of C will cause the SVM to create a complex prediction function to greatly reduce the misclassification of data points. In contrast, a low value of C will lead to a simple prediction function [24]. Training an SVM algorithm involves mapping the decision boundary for each outcome category and specifying the hyperplane that separates the categories. The algorithm will then attempt to find the optimal hyperplane that has the highest margin between classes, which is proportional to the classification accuracy [14]. Figure 3 shows a simple 2-D illustration of the SVM algorithm. Any SVM algorithm aims to find the maximum margin hyperplane, situated at the maximum margin between all possible positive and negative hyperplanes that can be defined, which will separate the support vectors into two distinct categories. Misclassifications occur when a data set is mapped onto the wrong side of the hyperplane, which is affected by the box constraint.  [25].
