# A Survey on Deep Learning and Explainability for Automatic Report Generation from Medical Images

CorpusID: 245837979 - [https://www.semanticscholar.org/paper/c47611ecff497c01e8bebc1da2ffba4e9b4d9de9](https://www.semanticscholar.org/paper/c47611ecff497c01e8bebc1da2ffba4e9b4d9de9)

Fields: Medicine, Computer Science

## (s4) RESEARCH QUESTIONS
(p4.0) This survey aims to answer the following research questions regarding the task of natural language report generation from medical images:

(p4.1) (1) What datasets are used in this area? What diseases and imaging techniques are considered?

(p4.2) (2) What deep learning methods are the most commonly employed?

(p4.3) (3) What explainability or interpretability techniques are used?

(p4.4) (4) How are the proposed models evaluated? What metrics are used? (5) How is the performance of the automatic methods? Which method can be considered state of the art or showing the best performance? (6) What are the main unsolved challenges? What are the potential avenues for future work?

(p4.5) This survey aims to answer the following research questions regarding the task of natural language report generation from medical images:

(p4.6) (1) What datasets are used in this area? What diseases and imaging techniques are considered?

(p4.7) (2) What deep learning methods are the most commonly employed?

(p4.8) (3) What explainability or interpretability techniques are used?

(p4.9) (4) How are the proposed models evaluated? What metrics are used? (5) How is the performance of the automatic methods? Which method can be considered state of the art or showing the best performance? (6) What are the main unsolved challenges? What are the potential avenues for future work?
## (s12) Domain knowledge.
(p12.0) Although all works used datasets from the medical domain to train their models, which can be considered a form of domain knowledge transfer, some works took special steps to explicitly incorporate additional knowledge from experts into their design. Concretely, we identify two incipient trends in the application of domain knowledge: 1) the use of graph neural networks right after the CNN, providing an architectural bias to guide the model to identify medical concepts and their relations from the images; and 2) enhancing the model's report generation with access to an external template database curated by experts.

(p12.1) KERP [86] incorporates knowledge at the architectural level using graph neural networks. The authors manually designed an abnormality graph and a disease graph, where each node represents an abnormality or disease, and the edges are built based on their co-occurrences in the training set. Some example abnormalities are "low lung volumes" and "enlarged heart size", whereas diseases represent a higher level of abstraction, for example "emphysema" or "consolidation". The information flows from image features (encoded by a CNN) to the abnormality graph, and then to the disease graph, via inter-node message passing. This biases the network to encode the visual information in terms of abnormalities, diseases and their relations. Similarly, Zhang et al. [162] created an observations graph, containing 20 nodes of chest abnormalities or body parts, where conditions related to the same organ or tissue are connected by edges. Their ablation analysis showed some performance gains, thanks to the graph neural network.
## (s44) RESEARCH QUESTIONS
(p44.0) This survey aims to answer the following research questions regarding the task of natural language report generation from medical images:

(p44.1) (1) What datasets are used in this area? What diseases and imaging techniques are considered?

(p44.2) (2) What deep learning methods are the most commonly employed?

(p44.3) (3) What explainability or interpretability techniques are used?

(p44.4) (4) How are the proposed models evaluated? What metrics are used? (5) How is the performance of the automatic methods? Which method can be considered state of the art or showing the best performance? (6) What are the main unsolved challenges? What are the potential avenues for future work?

(p44.5) This survey aims to answer the following research questions regarding the task of natural language report generation from medical images:

(p44.6) (1) What datasets are used in this area? What diseases and imaging techniques are considered?

(p44.7) (2) What deep learning methods are the most commonly employed?

(p44.8) (3) What explainability or interpretability techniques are used?

(p44.9) (4) How are the proposed models evaluated? What metrics are used? (5) How is the performance of the automatic methods? Which method can be considered state of the art or showing the best performance? (6) What are the main unsolved challenges? What are the potential avenues for future work?
## (s52) Domain knowledge.
(p52.0) Although all works used datasets from the medical domain to train their models, which can be considered a form of domain knowledge transfer, some works took special steps to explicitly incorporate additional knowledge from experts into their design. Concretely, we identify two incipient trends in the application of domain knowledge: 1) the use of graph neural networks right after the CNN, providing an architectural bias to guide the model to identify medical concepts and their relations from the images; and 2) enhancing the model's report generation with access to an external template database curated by experts.

(p52.1) KERP [86] incorporates knowledge at the architectural level using graph neural networks. The authors manually designed an abnormality graph and a disease graph, where each node represents an abnormality or disease, and the edges are built based on their co-occurrences in the training set. Some example abnormalities are "low lung volumes" and "enlarged heart size", whereas diseases represent a higher level of abstraction, for example "emphysema" or "consolidation". The information flows from image features (encoded by a CNN) to the abnormality graph, and then to the disease graph, via inter-node message passing. This biases the network to encode the visual information in terms of abnormalities, diseases and their relations. Similarly, Zhang et al. [162] created an observations graph, containing 20 nodes of chest abnormalities or body parts, where conditions related to the same organ or tissue are connected by edges. Their ablation analysis showed some performance gains, thanks to the graph neural network.
