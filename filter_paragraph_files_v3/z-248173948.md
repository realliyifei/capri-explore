# A Comprehensive Review of Various Diabetic Prediction Models: A Literature Survey

CorpusID: 248173948 - [https://www.semanticscholar.org/paper/bf1a3b9a295dc31c9d71cad4ab29ca115415f037](https://www.semanticscholar.org/paper/bf1a3b9a295dc31c9d71cad4ab29ca115415f037)

Fields: Computer Science, Medicine

## (s16) Conclusion
(p16.0) Based upon the comparative analysis and the above discussion, it can be concluded that Kamrul Hasan et al.'s [36] method is by far the best approach for diabetes prediction, as it is ranking features, selecting predominant features, filling missing values by median, and then tuning the hyperparameters as well. All the experiments were conducted using python. Although the accuracy achieved is only 78.9% by ensembling of AdaBoost and gradient boost, the AUC achieved is approximately 95%. A comparison of the threefeature selection technique and six machine learning classifiers has been made, and the ensembling of AdaBoost and gradient boost gave the best results.

(p16.1) Based upon the comparative analysis and the above discussion, it can be concluded that Kamrul Hasan et al.'s [36] method is by far the best approach for diabetes prediction, as it is ranking features, selecting predominant features, filling missing values by median, and then tuning the hyperparameters as well. All the experiments were conducted using python. Although the accuracy achieved is only 78.9% by ensembling of AdaBoost and gradient boost, the AUC achieved is approximately 95%. A comparison of the threefeature selection technique and six machine learning classifiers has been made, and the ensembling of AdaBoost and gradient boost gave the best results.

(p16.2) Based upon the comparative analysis and the above discussion, it can be concluded that Kamrul Hasan et al.'s [36] method is by far the best approach for diabetes prediction, as it is ranking features, selecting predominant features, filling missing values by median, and then tuning the hyperparameters as well. All the experiments were conducted using python. Although the accuracy achieved is only 78.9% by ensembling of AdaBoost and gradient boost, the AUC achieved is approximately 95%. A comparison of the threefeature selection technique and six machine learning classifiers has been made, and the ensembling of AdaBoost and gradient boost gave the best results.
## (s35) Conclusion
(p35.0) Based upon the comparative analysis and the above discussion, it can be concluded that Kamrul Hasan et al.'s [36] method is by far the best approach for diabetes prediction, as it is ranking features, selecting predominant features, filling missing values by median, and then tuning the hyperparameters as well. All the experiments were conducted using python. Although the accuracy achieved is only 78.9% by ensembling of AdaBoost and gradient boost, the AUC achieved is approximately 95%. A comparison of the threefeature selection technique and six machine learning classifiers has been made, and the ensembling of AdaBoost and gradient boost gave the best results.

(p35.1) Based upon the comparative analysis and the above discussion, it can be concluded that Kamrul Hasan et al.'s [36] method is by far the best approach for diabetes prediction, as it is ranking features, selecting predominant features, filling missing values by median, and then tuning the hyperparameters as well. All the experiments were conducted using python. Although the accuracy achieved is only 78.9% by ensembling of AdaBoost and gradient boost, the AUC achieved is approximately 95%. A comparison of the threefeature selection technique and six machine learning classifiers has been made, and the ensembling of AdaBoost and gradient boost gave the best results.

(p35.2) Based upon the comparative analysis and the above discussion, it can be concluded that Kamrul Hasan et al.'s [36] method is by far the best approach for diabetes prediction, as it is ranking features, selecting predominant features, filling missing values by median, and then tuning the hyperparameters as well. All the experiments were conducted using python. Although the accuracy achieved is only 78.9% by ensembling of AdaBoost and gradient boost, the AUC achieved is approximately 95%. A comparison of the threefeature selection technique and six machine learning classifiers has been made, and the ensembling of AdaBoost and gradient boost gave the best results.
## (s54) Conclusion
(p54.0) Based upon the comparative analysis and the above discussion, it can be concluded that Kamrul Hasan et al.'s [36] method is by far the best approach for diabetes prediction, as it is ranking features, selecting predominant features, filling missing values by median, and then tuning the hyperparameters as well. All the experiments were conducted using python. Although the accuracy achieved is only 78.9% by ensembling of AdaBoost and gradient boost, the AUC achieved is approximately 95%. A comparison of the threefeature selection technique and six machine learning classifiers has been made, and the ensembling of AdaBoost and gradient boost gave the best results.

(p54.1) Based upon the comparative analysis and the above discussion, it can be concluded that Kamrul Hasan et al.'s [36] method is by far the best approach for diabetes prediction, as it is ranking features, selecting predominant features, filling missing values by median, and then tuning the hyperparameters as well. All the experiments were conducted using python. Although the accuracy achieved is only 78.9% by ensembling of AdaBoost and gradient boost, the AUC achieved is approximately 95%. A comparison of the threefeature selection technique and six machine learning classifiers has been made, and the ensembling of AdaBoost and gradient boost gave the best results.

(p54.2) Based upon the comparative analysis and the above discussion, it can be concluded that Kamrul Hasan et al.'s [36] method is by far the best approach for diabetes prediction, as it is ranking features, selecting predominant features, filling missing values by median, and then tuning the hyperparameters as well. All the experiments were conducted using python. Although the accuracy achieved is only 78.9% by ensembling of AdaBoost and gradient boost, the AUC achieved is approximately 95%. A comparison of the threefeature selection technique and six machine learning classifiers has been made, and the ensembling of AdaBoost and gradient boost gave the best results.
