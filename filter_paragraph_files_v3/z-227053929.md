# Challenges in Deploying Machine Learning: a Survey of Case Studies

CorpusID: 227053929 - [https://www.semanticscholar.org/paper/a178a0bdee7549d87402b6c6128c569109128458](https://www.semanticscholar.org/paper/a178a0bdee7549d87402b6c6128c569109128458)

Fields: Business, Computer Science

## (s10) Hyper-parameter selection
(p10.0) In addition to parameters that are learned during the training process, many ML models also require hyper-parameters. Examples of such hyper-parameters are the depth of a decision tree, the number of hidden layers in a neural network or the number of neighbors in k-Nearest Neighbors classifier. Hyper-parameter optimization (HPO) is the process of choosing the optimal setting of these hyper-parameters. Most HPO techniques involve multiple training cycles of the ML model. This is computationally challenging because in the worst case the size of the HPO task grows exponentially: each new hyper-parameter adds a new dimension to the search space. As discussed by Yang and Shami [57], these considerations make HPO techniques very expensive and resourceheavy in practice, especially for applications of deep learning. Even approaches like Hyperband [58] or Bayesian optimization [59], that are specifically designed to minimize the number of training cycles needed, are not yet able to deal with the high dimensional searches that emerge when many hyper-parameters are involved. Large datasets complicate matters by leading to long training times for each search.

(p10.1) Many hyper-parameter tuning approaches require the user to define a complete search space, i.e. the set of possible values each of the hyper-parameters can take. Unfortunately, in practical use cases this is often impossible due to insufficient knowledge about the problem at hand. Setting the hyper-parameter optimization bounds remains one of the main obstacles preventing wider use of the state-of-the-art HPO techniques [60].

(p10.2) HPO often needs to take into account specific requirements imposed by the environment where the model will run. This is exemplified by Marculescu et al. [61] in the context of hardware-aware ML. In order to deploy models to embedded and mobile devices, one needs to be aware of energy and memory constraints imposed by such devices. This creates a need for customized hardwareaware optimization techniques that efficiently optimize for the accuracy of the model and the hardware jointly.
## (s21) Law
(p21.0) As ML grows its influence on society's everyday life, it is natural to expect more regulations to govern how ML models should function and how businesses, governments and other bodies can use them. Such legal frameworks can sometimes be used to guide decisions on ethics, although in general ethics and legal should be considered separate aspects.

(p21.1) Various countries have produced regulations to protect personal data rights. Typically, the more sensitive the information collected from the individual, the stronger the regulations governing its use. Examples of such regulations include the General Data Protection Regulation in the European Union [96] and ethical screening laws in a range of Asian countries [97]. One domain that deals with some of the most sensitive information is healthcare. According to Han et al. [98], many countries have strict laws in place to protect the data of patients, which makes the adoption of ML in healthcare particularly difficult. On one hand there is no doubt that these rules are absolutely necessary to make sure people are comfortable with their data being used. On the other hand, the amount of reviews, software updates and cycles of data collection/annotation that are required make it exceptionally hard to keep up with technical advances in ML, as Han et al. [98] explain following their experience deploying ML solutions in the healthcare sector in Japan.
