# Computation-efficient Deep Learning for Computer Vision: A Survey

CorpusID: 261243890 - [https://www.semanticscholar.org/paper/a87947f88519dba980d0f16cdfb78ed09a8e02f0](https://www.semanticscholar.org/paper/a87947f88519dba980d0f16cdfb78ed09a8e02f0)

Fields: Engineering, Computer Science

## (s8) 3) Model Scaling.
(p8.0) On top of designing a single efficient model, it is also important to obtain a family of models that can adapt to varying computational budgets. An important principle for addressing this issue is compound scaling [29,82], which indicates that simultaneously increasing the depth, width and input resolution of a given base model will yield a family of efficient network architectures. Doll√°r et al. [137] further study how to design a proper model scaling rule in terms of the actual runtime. In addition, TinyNets [138] extend this idea to the shrinking of the model size.
## (s28) Pixel-level Dynamic Networks
(p28.0) A typical approach to spatial-wise adaptive inference is dynamically deciding whether to compute each pixel in a convolution block based on a binary mask [235,236,237]. This form is similar to that in layer skipping and channel skipping (Sec. 3.1), except that the gating module is required to output a spatial mask. Each element of this spatial mask determines the computation of a feature pixel. In this way, the mask generators learn to locate the most discriminative regions in image features, and redundant computation on less informative pixels can be skipped.
## (s30) Resolution-level Dynamic Networks
(p30.0) Most existing vision models process different images with the same resolution. However, the input complexity could vary, and not all images require a high-resolution representation. Ideally, low-resolution representations should be sufficient for those "easy" samples with large objects and canonical features. The early work [249] proposes to adaptively zoom input images in the face detection task. The recent resolution adaptive network (RANet) [217] builds a multi-scale architecture, in which inputs are first processed with a low resolution and a small sub-network. Large sub-networks and high-resolution representations are conditionally activated based on early predictions. Instead of using a specialized structure, dynamic resolution network [250] rescales each image with the resolution predicted by a small model and feeds the rescaled image to common CNNs.

(p30.1) Note that different spatial locations are still processed equally in the aforementioned methods. We categorize the relative works in this section since they mainly utilize the spatial redundancy of image inputs for efficient inference.
## (s44) Two-stage Approaches
(p44.0) From the lens of efficiency, a notable milestone of deep-learning-based instance segmentation is the proposing of Mask R-CNN [318]. Mask R-CNN is developed by introducing mask segmentation branches on the basis of Faster R-CNN [272]. It enjoys high computational efficiency by directly obtaining the regions of interest from the feature maps. In contrast, MaskLab [319] improved Faster R-CNN by adding the semantic segmentation and direction prediction paths. To improve the accuracy of Mask R-CNN, MS R-CNN [320] predicts the quality of the predicted instance masks and prioritizes more accurate mask predictions during validation. PANet [321] introduces a path augmentation mechanism to facilitate the bottom-up information interaction of feature maps. HTC [322] proposes a hybrid task cascade framework to learn more discriminative features progressively while integrating complementary features in the meantime.
## (s58) Hardware-aware Model Design
(p58.0) As the practical latency of models can be influenced by many factors other than theoretical computation, the commonly used FLOPs is an inaccurate proxy for network efficiency. Ideally, one should develop efficient models based on specific hardware properties. However, hand-designing networks for different hardware devices can be laborious. Therefore, automatically searching for efficient architectures is emerging as a promising direction. Compared to the traditional NAS methods [31,414], this line of works can generate appropriate models which satisfy different hardware constraints and gain realistic efficiency in practice. For example, ProxylessNAS [54] establishes a latency prediction function based on realistic tests on targeted hardware, and the predicted latency is then directly used as a regularization item in the NAS objective. A similar idea is also implemented by MnasNet [53] to search for efficient models on mobile devices. The following works FBNet [159], FBNet-v2 [415] and OFA [416] have improved NAS techniques.

(p58.1) Apart from the traditional static models, the hardware-aware design paradigm has also been applied to develop spatial-wise dynamic networks (Sec. 3.2) [39].

(p58.2) Note that we mainly give a brief introduction of basic ideas in this work due to the page limit. For more detailed techniques we refer the readers to the survey [417] which specifically focuses on this topic.
## (s63) Developing Task-specialized Models
(p63.0) In addition to the architectural advancements in backbone models, tailoring deep learning methodologies to specific computer vision tasks of interest has been demonstrated as crucial. Two research challenges of particular significance in this domain can be identified. Firstly, the exploitation of representations extracted by backbones to efficiently obtain task-specific features is essential, for example, multi-scale features for object detection and multi-path fused features for semantic segmentation. A potential solution to this challenge could involve designing specialized, efficient decoders (e.g., utilizing NAS [311,437]). Secondly, it is important to streamline the multi-stage design of visual tasks (e.g., two-stage object detection [273] and instance segmentation [318] algorithms) to achieve end-to-end paradigms with minimal performance compromises. Additionally, the removal of time-consuming components, such as non-maximum suppression (NMS) [8], is crucial. A promising area for future research may involve the development of an efficient, unified, and end-to-end learnable interface for a majority of prevalent computer vision tasks [438].
## (s65) Leveraging Large-scale Training Data
(p65.0) Contemporary large visual backbone models have exhibited remarkable scalability in response to the increasing volumes of training data [6], that is, the model's performance consistently enhances as more train-ing data becomes accessible. However, it is generally arduous for computationally efficient models with a reduced number of parameters to capitalize on this high-data regime to the same extent as their larger counterparts. For example, the improvements attained by pre-training light-weighted models on expansive ImageNet-22K/JFT datasets are typically inferior to those observed in larger models [6,7,74]. This challenge is similarly experienced by self-supervised learning algorithms, where the methods effective for larger models frequently produce limited gains for smaller models [440,441]. As a result, a propitious avenue of research involves the exploration of effective scalable supervised and unsupervised learning algorithms for light-weighted models, allowing them to reap the benefits of an unlimited amount of data without incurring the expense of acquiring annotations. Some recent works on novel training algorithms have started to preliminarily explore this direction [82,442,443,444,445].
