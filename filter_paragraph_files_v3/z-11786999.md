# Siamese Learning Visual Tracking: A Survey

CorpusID: 11786999 - [https://www.semanticscholar.org/paper/754fa133a250d824c50b4c3b9c73975059954f41](https://www.semanticscholar.org/paper/754fa133a250d824c50b4c3b9c73975059954f41)

Fields: Mathematics, Computer Science

## (s22) Connection of Branches
(p22.0) All proposed methods except SINT connect the branches, SiamFC and CFNet with a single crosscorrelation layer, YCNN and GOTURN with three fc layers. SINT omits the concatenating layer by using normalisation layers at the end of both branches. Fig. 2 illustrates these three variations of network architecture. This Siamese network architecture of SiamFC, CFNet and SINT in combination with parameter sharing limit the feature selection to the spatial image domain. Instead, YCNN and GO-TURN enable additional learning of spatiotemporal features in the concatenating layers, as argued by [52] such as "relationships between an object's appearance change and its motion" which seems very general for different categories of objects. Parameter sharing has the consequence that all methods require appearance constancy between template and search region, hence [51]'s argument that YCNN's deep features show "superiority of recognising an object with varying appearance" is questionable. SiamFC, Theoretically, the network of GOTURN generalises over the network of SiamFC which allows capturing features beyond sole visual features of the exemplar image and which allows regression of the bounding box instead of convoluting a final score map capturing potential positions of the exemplar image within the search image. The author's argue that GOTURN learns a generic relationship between arbitrary motion and visual features, however this is not clear yet. Due to the more general Y-shaped architecture it might learn features beyond pure visual such as motion and their relationship in the fully-connected layers, however the network might also be able to learn context features as well.

(p22.1) CFNet and SINT assume a specific function of similarity and the idea is to solely learn visual features to best match the given similarity. SINT even expresses similarity by the training loss which might have advantages in generalisation as particular different functions of similarity and training loss might derive adversary optimisation problems. This is not a problem for YCNN and GOTURN, as similarity and features are jointly learned, however, the interference with the particular training loss is unclear.
## (s23) Network Training
(p23.0) Training is a crucial for sufficient performance. All methods describe basically two training phases, (i) a pre-training phase to transfer-learn generic features of objects from labeled datasets and (ii) a fine-tuning phase to adapt features to given video sets. The cross-correlation layer has here advantages as crosscorrelation preserves the convolutional property of the whole network which introduces invariance to object translation. Therefore training samples must not contain translated versions which reduces significantly the effort for training. Less augmentation of training data is needed. The training loss and its choice has significant influence on the training result. [52] argue that L 1 is superior to L 2 as it penalises more harshly small errors near zero which increases substantially accuracy of the predicted bounding box. This argument is an exception, as none of the other studies show some insights into this important problem. [52] chose also different inputs for training and studied their influence on the mean error derived from VOT accuracy and robustness measures. They show that feeding the network with whole frames instead of template and search region pairs, the frames' contexts are exploited which reduces significantly the mean error, especially in cases of occlusion. SINT is the only method following this insight but without any hints of their awareness. The reason is that their motivation comes from image retrieval where processing of frames is common.

(p23.1) GOTURN allows the use of still images.
