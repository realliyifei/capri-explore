# Analysis of microbial compositions: a review of normalization and differential abundance analysis

CorpusID: 256690138 - [https://www.semanticscholar.org/paper/325fce0048d7e5905bf5c313628e1937f344aa72](https://www.semanticscholar.org/paper/325fce0048d7e5905bf5c313628e1937f344aa72)

Fields: Biology, Computer Science

## (s9) Scaling
(p9.0) Scaling is another popular method used for normalizing microbiome data. The basic idea is to divide the observed abundance in the feature table by a "scaling factor" or "normalization factor" to eliminate biases resulting from unequal sampling fractions. More precisely, scaling is defined as follows.

(p9.1) Definition 0.2 (Scaling microbiome data).

(p9.2) where (1)Õ ij is the normalized observed abundance for taxon i within sample j, (2) s j is the scaling/normalization factor for sample j.

(p9.3) Comparing with the definition of sampling fraction (Eq. (1)), it is clear that an ideal scaling method should have scaling factor close to the unknown sampling fraction c j , i.e. s j ≈ c j ; or is approximately proportional to c j , i.e. s j ≈ c j × c for all j, where c is a constant.

(p9.4) Some commonly used normalization methods include Cumulative-Sum Scaling (CSS) implemented in metagenome-Seq 21 , Median (MED) in DESeq2 41 , Upper Quartile (UQ) 42 and Trimmed Mean of M-values (TMM) 43 in edgeR 44 and Wrench 45 , and Total-Sum Scaling (TSS) which simply transforms the abundance table (feature table) into relative abundance table, i.e. scale by each sample's library size. The authors of the user manual of edgeR 46 state that to deal with the "RNA composition" effect, one should multiply the normalization factors with the corresponding library size to account for "effective library size". Hence, Lin and Peddada 20 also considered modified versions of UQ and TMM, denoted by "ELib-UQ" (Effective library size using UQ) and "ELib-TMM" (Effective library size using TMM) in their simulation studies. Since the literature is often not explicit regarding the mathematical formulas used by various methods, we provide some useful formulas in Table 3.

(p9.5) TSS is known to have a bias in differential abundance estimates 33,39,42,47 since a few preferentially sampled x axis denotes the library size, and y axis represents the corresponding alpha diversity. Data are presented as mean values ± standard error (SE). It shows that regardless of the choice of diversity measures, as the increase of library size, the rarefaction curve starts to "level out" suggesting that the diversity of the samples has been fully observed.
## (s10) Method
(p10.0) Sampling fraction estimate

(p10.1) where j 0 is the reference sample. G* represents a set of taxa that were not considered as extreme data for fold-change (M values) and average intensity (A values). Refer to Robinson and Oshlack 43 for details. b ij represents the taxon-specific weight. Refer to Kumar et al. 45 for details.

(p10.2) H. Lin and S.D. Peddada factors estimated by these methods (with the exception of ANCOM-BC, UQ, and TMM) systematically differ by group labels. Furthermore, the box plot of ANCOM-BC had the shortest width, suggesting that it not only successfully estimates the true sampling fractions and eliminates bias due to its variability, but it also has the smallest variance which is not the case with other methods. This has a direct effect on the type I error and FDR as seen later in this paper and demonstrated in 20 .

(p10.3) Sampling fraction estimate

(p10.4) where j 0 is the reference sample. G* represents a set of taxa that were not considered as extreme data for fold-change (M values) and average intensity (A values). Refer to Robinson and Oshlack 43 for details. b ij represents the taxon-specific weight. Refer to Kumar et al. 45 for details.

(p10.5) H. Lin and S.D. Peddada factors estimated by these methods (with the exception of ANCOM-BC, UQ, and TMM) systematically differ by group labels. Furthermore, the box plot of ANCOM-BC had the shortest width, suggesting that it not only successfully estimates the true sampling fractions and eliminates bias due to its variability, but it also has the smallest variance which is not the case with other methods. This has a direct effect on the type I error and FDR as seen later in this paper and demonstrated in 20 .
## (s11) Log-ratio based methods
(p11.0) As an alternative to the above class of methods, several methods have been proposed in the literature that are inspired by Aitchison's methodology for compositional data. These methods do not explicitly perform normalization such as the ones described above, since they convert the observed abundances to log-ratios within each sample. Thus, within each sample, by taking log-ratios of all taxa with respect to some common reference taxon or some suitable function of all taxa, these methods are intrinsically eliminating the effect of the sampling fraction. This class of methods include DR 8 , ANCOM 14 , and ALDEx2 51 . ALDEx2 uses a pre-specified taxon as a reference taxon and transforms the observed abundances to log ratios of the observed abundance each taxon relative to the reference taxon. Such a log-transformation of observed abundance data is called the additive log transformation (alr). Mathematically, it is defined as follows:
## (s13) RNA-seq based methods: edgeR and DESeq2
(p13.0) As alternatives to standard nonparametric tests, many parametric models have been proposed in the literature based on transcriptomics data, such as the RNA-Seq data, for testing differences across study groups. Among them, DESeq2 41 and edgeR 44 are two popular methods. These methods model the observed abundances using negative binomial (NB) distribution after normalizing data with corresponding scaling methods to account for differences in sampling fractions. Thus O ij are modeled using the a negative binomial distribution as follows:

(p13.1) where (1) s j is the scaling factor for sample j, (2) μ i is the mean absolute abundance (in ecosystem) for taxon i, (3) ϕ i is the dispersion parameter for taxon i.

(p13.2) Introduction of the dispersion parameter ϕ i is inspired by meanvariance dependence in count data (e.g. RNA-Seq, microbiome data), and recognizing that the variance is typically larger than mean especially when the mean value is large. Thus, the variance of the observed abundance is modeled as follows:
## (s16) ANCOM
(p16.0) Analysis of composition of microbiomes (ANCOM) 14 is an alr based methodology, which accounts for the compositional structure of microbiome data. Given a total of m taxa, ANCOM relies on two assumptions as follows.

(p16.1) Assumption 0.1: The mean log absolute abundance (in the ecosystem) of 2 taxa are not different.

(p16.2) Assumption 0.2: The mean log absolute abundance (in the ecosystem) of all m taxa do not differ by the same amount between two study groups. For example, suppose the absolute abundance of m taxa for a subject in group 1 (C-section born babies) are A 1 , A 2 , …, A m and suppose the absolute abundance of taxa for a subject in group 2 (vaginally born babies) are B 1 , B 2 , …, B m . Then B i ≠ CA i , for all i = 1, 2, …, m. Thus, not all taxa are changing by the same constant C.

(p16.3) Note that the first assumption made by ANCOM is substantially weaker than the assumptions made by DESeq2 and edgeR, which require very "few" taxa to be differentially abundant.

(p16.4) Under the above assumptions, together with the fact that ANCOM performs all possible DA analyses by successively using each taxon as a reference taxon, the authors proved that one can test the null hypothesis regarding mean log absolute abundance in a unit volume of an ecosystem using relative abundances.

(p16.5) For the ith taxon and jth sample, ANCOM uses standard ANOVA model formulation:

(p16.6) where (1) i 0 is the reference taxon, i 0 ≠ i ¼ 1; 2; ; m, (2) g = 1, 2, …, G is the number of study groups.

(p16.7) By virtue of Assumption 0.1 and Assumption 0.2, to test whether a taxon i is differentially abundant according to a factor of interest with G levels, it is equivalent to test:
## (s17) LEfSe
(p17.0) Linear Discriminant Analysis Effect Size (LEfSe) 67 is specifically designed for group comparisons of microbiome data with a particular focus on detecting change in relative abundance between two or more groups of samples with biological consistency. Important statistical and computational steps implemented in LEfSe are as follows: model is built with the group label as the dependent variable and observed abundance of taxa selected in above step, subgroup label, and demographic features as independent variables. This model is used to calculate the effect size for each taxon. This effect size serves as the average of each taxon's variability and discriminatory power. 4. Finally, the LDA score for each taxon is obtained by computing the logarithm (base 10) of the effect size after being scaled in the [1, 10 6 ] interval. The rank for each taxon is assigned based on the corresponding LDA score and further feature selection could be achieved by setting a threshold (e.g. 2.0) for LDA scores.

(p17.1) By its construction, LEfSe method is more a discriminant analysis method rather than a DA method. Unlike the DA analysis methods discussed earlier in this paper, LEfSe is more focused on investigating the relationship among microbial profiles and an outcome or phenotype (Step 3). More precisely, LEfSe tries to quantify the magnitude of the effect size of such associations between microbial profiles (e.g. a set of taxa) and the outcome of interest.

(p17.2) Age ≤ 2 years old Age > 2 years old y 0 y 2 y 1 8 y 4 y 1 5 y 3 y 1 2 y 1 6 y 7 y 9 y 2 y 1 y 1 4 y 5 y 1 5 y 1 7 y 1 9 y 1 8 y 6 y 0 

(p17.3) Linear Discriminant Analysis Effect Size (LEfSe) 67 is specifically designed for group comparisons of microbiome data with a particular focus on detecting change in relative abundance between two or more groups of samples with biological consistency. Important statistical and computational steps implemented in LEfSe are as follows: model is built with the group label as the dependent variable and observed abundance of taxa selected in above step, subgroup label, and demographic features as independent variables. This model is used to calculate the effect size for each taxon. This effect size serves as the average of each taxon's variability and discriminatory power. 4. Finally, the LDA score for each taxon is obtained by computing the logarithm (base 10) of the effect size after being scaled in the [1, 10 6 ] interval. The rank for each taxon is assigned based on the corresponding LDA score and further feature selection could be achieved by setting a threshold (e.g. 2.0) for LDA scores.

(p17.4) By its construction, LEfSe method is more a discriminant analysis method rather than a DA method. Unlike the DA analysis methods discussed earlier in this paper, LEfSe is more focused on investigating the relationship among microbial profiles and an outcome or phenotype (Step 3). More precisely, LEfSe tries to quantify the magnitude of the effect size of such associations between microbial profiles (e.g. a set of taxa) and the outcome of interest.

(p17.5) Age ≤ 2 years old Age > 2 years old y 0 y 2 y 1 8 y 4 y 1 5 y 3 y 1 2 y 1 6 y 7 y 9 y 2 y 1 y 1 4 y 5 y 1 5 y 1 7 y 1 9 y 1 8 y 6 y 0 
## (s18) DISCUSSION
(p18.0) Microbiome studies are becoming very popular in biomedical sciences. As new scientific questions emerge, so do new statistical and computational methods of analysis. This is a very rapidly growing area of research with new statistical methods being developed on a regular basis. Hence an up-to-date comprehensive review of the statistical methods in the field is a challenging problem. This is particularly true with methods for DA analysis. A number of methods exist in the literature and each method has its own strengths and weaknesses. One of the challenges in evaluating the performance of various methods is that not all methods are designed to test statistical hypotheses regarding the same parameter. Some methods are designed for testing hypotheses regarding the relative abundance, while others are designed for testing hypothesis regarding absolute abundance. If a simulation study is designed for testing hypothesis regarding absolute abundance then methods for relative abundance parameter may show an inflated FDR and vise versa. A related problem is that often researchers use the terms "relative abundance" and "absolute abundance in a unit volume" interchangeably. This makes the simulation studies difficult to interpret. Therefore journals and researchers should make the terminology precise. In this paper, simulation studies were set-up to compare FDR and power of various methods when testing hypotheses regarding absolute abundance of taxa in a unit volume of a tissue. We performed simulation studies using the log-normal distribution for modeling abundances. Consistent with the findings of 20 , ANCOM and ANCOM-BC control the FDR at the desired nominal level for most configurations while competing well with all procedures in terms of the overall power. The only situations where ANCOM as well as ANCOM-BC fail to control FDR is when the sample sizes are very small, such as <10 20 . All other methods considered in this paper tend to inflate FDR for all sample sizes and their FDR gets worse with the sample size increases 20 . This is because, under the null hypothesis, each of these methods is biased away from zero. This bias increases with sample size. Hence the FDR increases with sample size.

(p18.1) While ANCOM and ANCOM-BC have very similar operating characteristics in terms of FDR and power, ANCOM-BC is computationally simpler and faster to implement because unlike ANCOM it requires only m linear regression fits rather than m ðm À 1Þ 2 models fits needed by ANCOM. Secondly, unlike ANCOM, ANCOM-BC provides individual p-values and confidence intervals of pairwise difference in mean abundance for each taxon. Among the methods available today, ANCOM-BC is the only procedure that provides valid p-values and confidence intervals. Furthermore, since ANCOM-BC is based on a regression model framework, it can easily be extended to repeated measures/longitudinal data covariate adjustments.

(p18.2) Microbiome studies are becoming very popular in biomedical sciences. As new scientific questions emerge, so do new statistical and computational methods of analysis. This is a very rapidly growing area of research with new statistical methods being developed on a regular basis. Hence an up-to-date comprehensive review of the statistical methods in the field is a challenging problem. This is particularly true with methods for DA analysis. A number of methods exist in the literature and each method has its own strengths and weaknesses. One of the challenges in evaluating the performance of various methods is that not all methods are designed to test statistical hypotheses regarding the same parameter. Some methods are designed for testing hypotheses regarding the relative abundance, while others are designed for testing hypothesis regarding absolute abundance. If a simulation study is designed for testing hypothesis regarding absolute abundance then methods for relative abundance parameter may show an inflated FDR and vise versa. A related problem is that often researchers use the terms "relative abundance" and "absolute abundance in a unit volume" interchangeably. This makes the simulation studies difficult to interpret. Therefore journals and researchers should make the terminology precise. In this paper, simulation studies were set-up to compare FDR and power of various methods when testing hypotheses regarding absolute abundance of taxa in a unit volume of a tissue. We performed simulation studies using the log-normal distribution for modeling abundances. Consistent with the findings of 20 , ANCOM and ANCOM-BC control the FDR at the desired nominal level for most configurations while competing well with all procedures in terms of the overall power. The only situations where ANCOM as well as ANCOM-BC fail to control FDR is when the sample sizes are very small, such as <10 20 . All other methods considered in this paper tend to inflate FDR for all sample sizes and their FDR gets worse with the sample size increases 20 . This is because, under the null hypothesis, each of these methods is biased away from zero. This bias increases with sample size. Hence the FDR increases with sample size.

(p18.3) While ANCOM and ANCOM-BC have very similar operating characteristics in terms of FDR and power, ANCOM-BC is computationally simpler and faster to implement because unlike ANCOM it requires only m linear regression fits rather than m ðm À 1Þ 2 models fits needed by ANCOM. Secondly, unlike ANCOM, ANCOM-BC provides individual p-values and confidence intervals of pairwise difference in mean abundance for each taxon. Among the methods available today, ANCOM-BC is the only procedure that provides valid p-values and confidence intervals. Furthermore, since ANCOM-BC is based on a regression model framework, it can easily be extended to repeated measures/longitudinal data covariate adjustments.
## (s37) Scaling
(p37.0) Scaling is another popular method used for normalizing microbiome data. The basic idea is to divide the observed abundance in the feature table by a "scaling factor" or "normalization factor" to eliminate biases resulting from unequal sampling fractions. More precisely, scaling is defined as follows.

(p37.1) Definition 0.2 (Scaling microbiome data).

(p37.2) where (1)Õ ij is the normalized observed abundance for taxon i within sample j, (2) s j is the scaling/normalization factor for sample j.

(p37.3) Comparing with the definition of sampling fraction (Eq. (1)), it is clear that an ideal scaling method should have scaling factor close to the unknown sampling fraction c j , i.e. s j ≈ c j ; or is approximately proportional to c j , i.e. s j ≈ c j × c for all j, where c is a constant.

(p37.4) Some commonly used normalization methods include Cumulative-Sum Scaling (CSS) implemented in metagenome-Seq 21 , Median (MED) in DESeq2 41 , Upper Quartile (UQ) 42 and Trimmed Mean of M-values (TMM) 43 in edgeR 44 and Wrench 45 , and Total-Sum Scaling (TSS) which simply transforms the abundance table (feature table) into relative abundance table, i.e. scale by each sample's library size. The authors of the user manual of edgeR 46 state that to deal with the "RNA composition" effect, one should multiply the normalization factors with the corresponding library size to account for "effective library size". Hence, Lin and Peddada 20 also considered modified versions of UQ and TMM, denoted by "ELib-UQ" (Effective library size using UQ) and "ELib-TMM" (Effective library size using TMM) in their simulation studies. Since the literature is often not explicit regarding the mathematical formulas used by various methods, we provide some useful formulas in Table 3.

(p37.5) TSS is known to have a bias in differential abundance estimates 33,39,42,47 since a few preferentially sampled x axis denotes the library size, and y axis represents the corresponding alpha diversity. Data are presented as mean values ± standard error (SE). It shows that regardless of the choice of diversity measures, as the increase of library size, the rarefaction curve starts to "level out" suggesting that the diversity of the samples has been fully observed.
## (s38) Method
(p38.0) Sampling fraction estimate

(p38.1) where j 0 is the reference sample. G* represents a set of taxa that were not considered as extreme data for fold-change (M values) and average intensity (A values). Refer to Robinson and Oshlack 43 for details. b ij represents the taxon-specific weight. Refer to Kumar et al. 45 for details.

(p38.2) H. Lin and S.D. Peddada factors estimated by these methods (with the exception of ANCOM-BC, UQ, and TMM) systematically differ by group labels. Furthermore, the box plot of ANCOM-BC had the shortest width, suggesting that it not only successfully estimates the true sampling fractions and eliminates bias due to its variability, but it also has the smallest variance which is not the case with other methods. This has a direct effect on the type I error and FDR as seen later in this paper and demonstrated in 20 .

(p38.3) Sampling fraction estimate

(p38.4) where j 0 is the reference sample. G* represents a set of taxa that were not considered as extreme data for fold-change (M values) and average intensity (A values). Refer to Robinson and Oshlack 43 for details. b ij represents the taxon-specific weight. Refer to Kumar et al. 45 for details.

(p38.5) H. Lin and S.D. Peddada factors estimated by these methods (with the exception of ANCOM-BC, UQ, and TMM) systematically differ by group labels. Furthermore, the box plot of ANCOM-BC had the shortest width, suggesting that it not only successfully estimates the true sampling fractions and eliminates bias due to its variability, but it also has the smallest variance which is not the case with other methods. This has a direct effect on the type I error and FDR as seen later in this paper and demonstrated in 20 .
## (s39) Log-ratio based methods
(p39.0) As an alternative to the above class of methods, several methods have been proposed in the literature that are inspired by Aitchison's methodology for compositional data. These methods do not explicitly perform normalization such as the ones described above, since they convert the observed abundances to log-ratios within each sample. Thus, within each sample, by taking log-ratios of all taxa with respect to some common reference taxon or some suitable function of all taxa, these methods are intrinsically eliminating the effect of the sampling fraction. This class of methods include DR 8 , ANCOM 14 , and ALDEx2 51 . ALDEx2 uses a pre-specified taxon as a reference taxon and transforms the observed abundances to log ratios of the observed abundance each taxon relative to the reference taxon. Such a log-transformation of observed abundance data is called the additive log transformation (alr). Mathematically, it is defined as follows:
## (s41) RNA-seq based methods: edgeR and DESeq2
(p41.0) As alternatives to standard nonparametric tests, many parametric models have been proposed in the literature based on transcriptomics data, such as the RNA-Seq data, for testing differences across study groups. Among them, DESeq2 41 and edgeR 44 are two popular methods. These methods model the observed abundances using negative binomial (NB) distribution after normalizing data with corresponding scaling methods to account for differences in sampling fractions. Thus O ij are modeled using the a negative binomial distribution as follows:

(p41.1) where (1) s j is the scaling factor for sample j, (2) μ i is the mean absolute abundance (in ecosystem) for taxon i, (3) ϕ i is the dispersion parameter for taxon i.

(p41.2) Introduction of the dispersion parameter ϕ i is inspired by meanvariance dependence in count data (e.g. RNA-Seq, microbiome data), and recognizing that the variance is typically larger than mean especially when the mean value is large. Thus, the variance of the observed abundance is modeled as follows:
## (s44) ANCOM
(p44.0) Analysis of composition of microbiomes (ANCOM) 14 is an alr based methodology, which accounts for the compositional structure of microbiome data. Given a total of m taxa, ANCOM relies on two assumptions as follows.

(p44.1) Assumption 0.1: The mean log absolute abundance (in the ecosystem) of 2 taxa are not different.

(p44.2) Assumption 0.2: The mean log absolute abundance (in the ecosystem) of all m taxa do not differ by the same amount between two study groups. For example, suppose the absolute abundance of m taxa for a subject in group 1 (C-section born babies) are A 1 , A 2 , …, A m and suppose the absolute abundance of taxa for a subject in group 2 (vaginally born babies) are B 1 , B 2 , …, B m . Then B i ≠ CA i , for all i = 1, 2, …, m. Thus, not all taxa are changing by the same constant C.

(p44.3) Note that the first assumption made by ANCOM is substantially weaker than the assumptions made by DESeq2 and edgeR, which require very "few" taxa to be differentially abundant.

(p44.4) Under the above assumptions, together with the fact that ANCOM performs all possible DA analyses by successively using each taxon as a reference taxon, the authors proved that one can test the null hypothesis regarding mean log absolute abundance in a unit volume of an ecosystem using relative abundances.

(p44.5) For the ith taxon and jth sample, ANCOM uses standard ANOVA model formulation:

(p44.6) where (1) i 0 is the reference taxon, i 0 ≠ i ¼ 1; 2; ; m, (2) g = 1, 2, …, G is the number of study groups.

(p44.7) By virtue of Assumption 0.1 and Assumption 0.2, to test whether a taxon i is differentially abundant according to a factor of interest with G levels, it is equivalent to test:
## (s45) LEfSe
(p45.0) Linear Discriminant Analysis Effect Size (LEfSe) 67 is specifically designed for group comparisons of microbiome data with a particular focus on detecting change in relative abundance between two or more groups of samples with biological consistency. Important statistical and computational steps implemented in LEfSe are as follows: model is built with the group label as the dependent variable and observed abundance of taxa selected in above step, subgroup label, and demographic features as independent variables. This model is used to calculate the effect size for each taxon. This effect size serves as the average of each taxon's variability and discriminatory power. 4. Finally, the LDA score for each taxon is obtained by computing the logarithm (base 10) of the effect size after being scaled in the [1, 10 6 ] interval. The rank for each taxon is assigned based on the corresponding LDA score and further feature selection could be achieved by setting a threshold (e.g. 2.0) for LDA scores.

(p45.1) By its construction, LEfSe method is more a discriminant analysis method rather than a DA method. Unlike the DA analysis methods discussed earlier in this paper, LEfSe is more focused on investigating the relationship among microbial profiles and an outcome or phenotype (Step 3). More precisely, LEfSe tries to quantify the magnitude of the effect size of such associations between microbial profiles (e.g. a set of taxa) and the outcome of interest.

(p45.2) Age ≤ 2 years old Age > 2 years old y 0 y 2 y 1 8 y 4 y 1 5 y 3 y 1 2 y 1 6 y 7 y 9 y 2 y 1 y 1 4 y 5 y 1 5 y 1 7 y 1 9 y 1 8 y 6 y 0 

(p45.3) Linear Discriminant Analysis Effect Size (LEfSe) 67 is specifically designed for group comparisons of microbiome data with a particular focus on detecting change in relative abundance between two or more groups of samples with biological consistency. Important statistical and computational steps implemented in LEfSe are as follows: model is built with the group label as the dependent variable and observed abundance of taxa selected in above step, subgroup label, and demographic features as independent variables. This model is used to calculate the effect size for each taxon. This effect size serves as the average of each taxon's variability and discriminatory power. 4. Finally, the LDA score for each taxon is obtained by computing the logarithm (base 10) of the effect size after being scaled in the [1, 10 6 ] interval. The rank for each taxon is assigned based on the corresponding LDA score and further feature selection could be achieved by setting a threshold (e.g. 2.0) for LDA scores.

(p45.4) By its construction, LEfSe method is more a discriminant analysis method rather than a DA method. Unlike the DA analysis methods discussed earlier in this paper, LEfSe is more focused on investigating the relationship among microbial profiles and an outcome or phenotype (Step 3). More precisely, LEfSe tries to quantify the magnitude of the effect size of such associations between microbial profiles (e.g. a set of taxa) and the outcome of interest.

(p45.5) Age ≤ 2 years old Age > 2 years old y 0 y 2 y 1 8 y 4 y 1 5 y 3 y 1 2 y 1 6 y 7 y 9 y 2 y 1 y 1 4 y 5 y 1 5 y 1 7 y 1 9 y 1 8 y 6 y 0 
## (s46) DISCUSSION
(p46.0) Microbiome studies are becoming very popular in biomedical sciences. As new scientific questions emerge, so do new statistical and computational methods of analysis. This is a very rapidly growing area of research with new statistical methods being developed on a regular basis. Hence an up-to-date comprehensive review of the statistical methods in the field is a challenging problem. This is particularly true with methods for DA analysis. A number of methods exist in the literature and each method has its own strengths and weaknesses. One of the challenges in evaluating the performance of various methods is that not all methods are designed to test statistical hypotheses regarding the same parameter. Some methods are designed for testing hypotheses regarding the relative abundance, while others are designed for testing hypothesis regarding absolute abundance. If a simulation study is designed for testing hypothesis regarding absolute abundance then methods for relative abundance parameter may show an inflated FDR and vise versa. A related problem is that often researchers use the terms "relative abundance" and "absolute abundance in a unit volume" interchangeably. This makes the simulation studies difficult to interpret. Therefore journals and researchers should make the terminology precise. In this paper, simulation studies were set-up to compare FDR and power of various methods when testing hypotheses regarding absolute abundance of taxa in a unit volume of a tissue. We performed simulation studies using the log-normal distribution for modeling abundances. Consistent with the findings of 20 , ANCOM and ANCOM-BC control the FDR at the desired nominal level for most configurations while competing well with all procedures in terms of the overall power. The only situations where ANCOM as well as ANCOM-BC fail to control FDR is when the sample sizes are very small, such as <10 20 . All other methods considered in this paper tend to inflate FDR for all sample sizes and their FDR gets worse with the sample size increases 20 . This is because, under the null hypothesis, each of these methods is biased away from zero. This bias increases with sample size. Hence the FDR increases with sample size.

(p46.1) While ANCOM and ANCOM-BC have very similar operating characteristics in terms of FDR and power, ANCOM-BC is computationally simpler and faster to implement because unlike ANCOM it requires only m linear regression fits rather than m ðm À 1Þ 2 models fits needed by ANCOM. Secondly, unlike ANCOM, ANCOM-BC provides individual p-values and confidence intervals of pairwise difference in mean abundance for each taxon. Among the methods available today, ANCOM-BC is the only procedure that provides valid p-values and confidence intervals. Furthermore, since ANCOM-BC is based on a regression model framework, it can easily be extended to repeated measures/longitudinal data covariate adjustments.

(p46.2) Microbiome studies are becoming very popular in biomedical sciences. As new scientific questions emerge, so do new statistical and computational methods of analysis. This is a very rapidly growing area of research with new statistical methods being developed on a regular basis. Hence an up-to-date comprehensive review of the statistical methods in the field is a challenging problem. This is particularly true with methods for DA analysis. A number of methods exist in the literature and each method has its own strengths and weaknesses. One of the challenges in evaluating the performance of various methods is that not all methods are designed to test statistical hypotheses regarding the same parameter. Some methods are designed for testing hypotheses regarding the relative abundance, while others are designed for testing hypothesis regarding absolute abundance. If a simulation study is designed for testing hypothesis regarding absolute abundance then methods for relative abundance parameter may show an inflated FDR and vise versa. A related problem is that often researchers use the terms "relative abundance" and "absolute abundance in a unit volume" interchangeably. This makes the simulation studies difficult to interpret. Therefore journals and researchers should make the terminology precise. In this paper, simulation studies were set-up to compare FDR and power of various methods when testing hypotheses regarding absolute abundance of taxa in a unit volume of a tissue. We performed simulation studies using the log-normal distribution for modeling abundances. Consistent with the findings of 20 , ANCOM and ANCOM-BC control the FDR at the desired nominal level for most configurations while competing well with all procedures in terms of the overall power. The only situations where ANCOM as well as ANCOM-BC fail to control FDR is when the sample sizes are very small, such as <10 20 . All other methods considered in this paper tend to inflate FDR for all sample sizes and their FDR gets worse with the sample size increases 20 . This is because, under the null hypothesis, each of these methods is biased away from zero. This bias increases with sample size. Hence the FDR increases with sample size.

(p46.3) While ANCOM and ANCOM-BC have very similar operating characteristics in terms of FDR and power, ANCOM-BC is computationally simpler and faster to implement because unlike ANCOM it requires only m linear regression fits rather than m ðm À 1Þ 2 models fits needed by ANCOM. Secondly, unlike ANCOM, ANCOM-BC provides individual p-values and confidence intervals of pairwise difference in mean abundance for each taxon. Among the methods available today, ANCOM-BC is the only procedure that provides valid p-values and confidence intervals. Furthermore, since ANCOM-BC is based on a regression model framework, it can easily be extended to repeated measures/longitudinal data covariate adjustments.
