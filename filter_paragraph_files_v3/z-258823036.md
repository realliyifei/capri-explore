# Trustworthy Federated Learning: A Survey

CorpusID: 258823036 - [https://www.semanticscholar.org/paper/a0e40d9a07fdc5848ef2f10d9b63f5c28e0cec03](https://www.semanticscholar.org/paper/a0e40d9a07fdc5848ef2f10d9b63f5c28e0cec03)

Fields: Computer Science

## (s1) arXiv:2305.11537v1 [cs.AI] 19 May 2023
(p1.0) 3) Streamlined model verification and auditability: Facilitate users to confirm a model update's accuracy and easily access verifiable data for specific update versions. 4) Unalterable model update history: Showcase a globally uniform record of global model updates without changes. Within this log, each update corresponds to a distinct entry that cannot be edited or deleted once created. 5) Dependable client and model identification: Select trustworthy clients and models to enhance the FL process. 6) Reliable contribution evaluation and incentive allocation: Implement a credible assessment of contributions and provide incentives to encourage FL clients' participation in future sessions. Investigators must concentrate on novel approaches to address the challenges in FL by creating equitable and dependable metrics for worker selection and evaluation. 7) Dynamic authoritative keys management: Allow updates for authoritative keys, even if some, but not most, keys are compromised. 8) Timely Monitoring: Timely monitoring methods for workers and model assessment schemes are necessary. Strengthening security and privacy features is crucial for Trustworthy FL.

(p1.1) By emphasizing these objectives, crucial areas and fostering cooperation among stakeholders, the creation of secure and dependable FL systems can facilitate more responsible and ethical AI applications. Within the current research landscape, there is a noticeable absence of studies investigating the crucial pillars of trustworthiness, specifically in relation to FL. To the best of our knowledge, this is the pioneering work encompassing all facets of Trustworthy FL. In an effort to bridge the gaps in existing literature, this study presents the following contributions: 1) We furnish an overview of the fundamental principles underlying trustworthy FL, accompanied by a comprehensive architecture of Trustworthy FL and trust assessment mechanisms. 2) We develop a taxonomy centered on the most pertinent trustworthiness pillars within FL contexts. In order to construct this taxonomy, we identify three primary pillars as the foundational elements: Interpretability, Fairness, and Security & Privacy. Each pillar embodies a dimension of trust, which is further delineated into distinct concepts for each pillar. Additionally, we explore the key challenges and future directions in the realm of Trustworthy FL. 3) In conclusion, we highlighted the essential research challenges associated with each facet of Trustworthy FL, as well as the direction for future investigations.

(p1.2) The remainder of this paper is organized as follows: The structure of this paper is as follows: We commence with an introduction to FL and its classification in Section 2, succeeded by a discussion on trust in FL, fundamental principles of trustworthiness, and the architecture of Trustworthy FL systems in Section 3. Section 4 presents a literature review, emphasizing existing research in the domain. Sections 5-8 delve into trust evaluation, trust-aware interpretability, fairness-aware trustworthiness, and trust-aware security & privacy-preserving FL systems, respectively. Throughout the paper, we examine topics such as data and feature selection, data sharing, model selection, explainability, client selection, contribution assessment, incentive mechanisms, accountability, auditability, secure and data aggregation, privacy preservation, and more. In conclusion, we explore open challenges and future research avenues in the field of Trustworthy FL, laying the foundation for the creation of secure and dependable FL systems that facilitate responsible and ethical AI applications.

(p1.3) 3) Streamlined model verification and auditability: Facilitate users to confirm a model update's accuracy and easily access verifiable data for specific update versions. 4) Unalterable model update history: Showcase a globally uniform record of global model updates without changes. Within this log, each update corresponds to a distinct entry that cannot be edited or deleted once created. 5) Dependable client and model identification: Select trustworthy clients and models to enhance the FL process. 6) Reliable contribution evaluation and incentive allocation: Implement a credible assessment of contributions and provide incentives to encourage FL clients' participation in future sessions. Investigators must concentrate on novel approaches to address the challenges in FL by creating equitable and dependable metrics for worker selection and evaluation. 7) Dynamic authoritative keys management: Allow updates for authoritative keys, even if some, but not most, keys are compromised. 8) Timely Monitoring: Timely monitoring methods for workers and model assessment schemes are necessary. Strengthening security and privacy features is crucial for Trustworthy FL.

(p1.4) By emphasizing these objectives, crucial areas and fostering cooperation among stakeholders, the creation of secure and dependable FL systems can facilitate more responsible and ethical AI applications. Within the current research landscape, there is a noticeable absence of studies investigating the crucial pillars of trustworthiness, specifically in relation to FL. To the best of our knowledge, this is the pioneering work encompassing all facets of Trustworthy FL. In an effort to bridge the gaps in existing literature, this study presents the following contributions: 1) We furnish an overview of the fundamental principles underlying trustworthy FL, accompanied by a comprehensive architecture of Trustworthy FL and trust assessment mechanisms. 2) We develop a taxonomy centered on the most pertinent trustworthiness pillars within FL contexts. In order to construct this taxonomy, we identify three primary pillars as the foundational elements: Interpretability, Fairness, and Security & Privacy. Each pillar embodies a dimension of trust, which is further delineated into distinct concepts for each pillar. Additionally, we explore the key challenges and future directions in the realm of Trustworthy FL. 3) In conclusion, we highlighted the essential research challenges associated with each facet of Trustworthy FL, as well as the direction for future investigations.

(p1.5) The remainder of this paper is organized as follows: The structure of this paper is as follows: We commence with an introduction to FL and its classification in Section 2, succeeded by a discussion on trust in FL, fundamental principles of trustworthiness, and the architecture of Trustworthy FL systems in Section 3. Section 4 presents a literature review, emphasizing existing research in the domain. Sections 5-8 delve into trust evaluation, trust-aware interpretability, fairness-aware trustworthiness, and trust-aware security & privacy-preserving FL systems, respectively. Throughout the paper, we examine topics such as data and feature selection, data sharing, model selection, explainability, client selection, contribution assessment, incentive mechanisms, accountability, auditability, secure and data aggregation, privacy preservation, and more. In conclusion, we explore open challenges and future research avenues in the field of Trustworthy FL, laying the foundation for the creation of secure and dependable FL systems that facilitate responsible and ethical AI applications.
## (s2) II. FEDRATED LEARNING AN OVERVIEW
(p2.0) FL is a transformative approach to distributed machine learning, enabling the collaborative training of models across multiple devices or clients while preserving data privacy [11]. Various FL architectures have been developed to address the diverse challenges and requirements in data distribution, communication patterns, and coordination methods. These architectures can be broadly classified into three main categories: data distribution-based architectures, such as Horizontal FL (HFL), Vertical FL (VFL), and Federated Transfer Learning (FTL); scale and communication-based architectures, including Cross-Silo FL (CSFL) and Cross-Device FL (CDFL); and coordination-based architectures, which encompass Centralized FL, Decentralized FL, and Hierarchical FL. Each of these architectures caters to specific needs and constraints, ensuring optimal model development across a wide range of applications while maintaining data privacy and security.

(p2.1) A. Data Distribution-Based FL Architectures 1) Vertical FL: VFL involves federated training of datasets that share the same sample space but differ in feature spaces. It is apt for scenarios in which data is divided vertically based on feature dimensions, with different parties holding homogeneous data that partially overlaps in sample IDs. Entity alignment and encryption methods can be employed to address data sample overlapping during local training. One instance of VFL in the healthcare sector is the collaboration between hospitals and insurance companies, jointly training an AI model using their respective datasets. Although VFL provides data privacy and joint training benefits, it presents more implementation challenges than HFL due to the requirement for entity resolution and the limitations of current techniques for complex machine learning models.

(p2.2) 2) Horizontal FL: In HFL, multiple participants possessing datasets with identical feature spaces but varying sample spaces collaborate in training a joint global model. The datasets are used locally, and a server merges the local updates received from the participants to develop a global update without accessing the local data directly. One example of HFL in the healthcare domain is speech disorder detection, where users with different voices speak identical sentences, and the local updates are combined to create a comprehensive speech recognition model. HFL is primarily utilized in smart devices and IoT applications. It allows leveraging data from numerous sources without sharing raw data, thus maintaining privacy.

(p2.3) However, HFL may encounter challenges when dealing with a limited number of labeled entities. 3) Federated Transfer Learning: FTL is tailored to handle datasets that differ in both sample spaces and feature spaces. Transfer learning techniques are used to compute feature values from distinct feature spaces into a uniform representation, which is then employed for local dataset training. Privacy protection mechanisms, such as random masks, can be implemented during the gradient exchange between clients and servers. FTL can support smart healthcare use cases like disease diagnosis by enabling collaboration among multiple hospitals with distinct patients and treatment plans. Although FTL has potential, it remains an evolving research area with challenges related to communication efficiency and flexibility in dealing with diverse data structures. Nevertheless, it provides a promising solution for ensuring data security and user privacy while addressing data island problems. An illustration of these data distribution-based FL architectures is presented in Fig. 1.

(p2.4) FL is a transformative approach to distributed machine learning, enabling the collaborative training of models across multiple devices or clients while preserving data privacy [11]. Various FL architectures have been developed to address the diverse challenges and requirements in data distribution, communication patterns, and coordination methods. These architectures can be broadly classified into three main categories: data distribution-based architectures, such as Horizontal FL (HFL), Vertical FL (VFL), and Federated Transfer Learning (FTL); scale and communication-based architectures, including Cross-Silo FL (CSFL) and Cross-Device FL (CDFL); and coordination-based architectures, which encompass Centralized FL, Decentralized FL, and Hierarchical FL. Each of these architectures caters to specific needs and constraints, ensuring optimal model development across a wide range of applications while maintaining data privacy and security.

(p2.5) A. Data Distribution-Based FL Architectures 1) Vertical FL: VFL involves federated training of datasets that share the same sample space but differ in feature spaces. It is apt for scenarios in which data is divided vertically based on feature dimensions, with different parties holding homogeneous data that partially overlaps in sample IDs. Entity alignment and encryption methods can be employed to address data sample overlapping during local training. One instance of VFL in the healthcare sector is the collaboration between hospitals and insurance companies, jointly training an AI model using their respective datasets. Although VFL provides data privacy and joint training benefits, it presents more implementation challenges than HFL due to the requirement for entity resolution and the limitations of current techniques for complex machine learning models.

(p2.6) 2) Horizontal FL: In HFL, multiple participants possessing datasets with identical feature spaces but varying sample spaces collaborate in training a joint global model. The datasets are used locally, and a server merges the local updates received from the participants to develop a global update without accessing the local data directly. One example of HFL in the healthcare domain is speech disorder detection, where users with different voices speak identical sentences, and the local updates are combined to create a comprehensive speech recognition model. HFL is primarily utilized in smart devices and IoT applications. It allows leveraging data from numerous sources without sharing raw data, thus maintaining privacy.

(p2.7) However, HFL may encounter challenges when dealing with a limited number of labeled entities. 3) Federated Transfer Learning: FTL is tailored to handle datasets that differ in both sample spaces and feature spaces. Transfer learning techniques are used to compute feature values from distinct feature spaces into a uniform representation, which is then employed for local dataset training. Privacy protection mechanisms, such as random masks, can be implemented during the gradient exchange between clients and servers. FTL can support smart healthcare use cases like disease diagnosis by enabling collaboration among multiple hospitals with distinct patients and treatment plans. Although FTL has potential, it remains an evolving research area with challenges related to communication efficiency and flexibility in dealing with diverse data structures. Nevertheless, it provides a promising solution for ensuring data security and user privacy while addressing data island problems. An illustration of these data distribution-based FL architectures is presented in Fig. 1.
## (s11) A. Trustworthy Feature and Sample Selection
(p11.0) The authors proposes a new approach called Federated Stochastic Dual-Gate based Feature Selection (FedSDG-FS) [37] for feature selection in Vertical FL (VFL). Existing FS works for VFL assume prior knowledge on the number of noisy features or the threshold of useful features to be selected, making them unsuitable for practical applications. FedSDG-FS uses a Gaussian stochastic dual-gate to approximate the probability of a feature being selected with privacy protection through Partially Homomorphic Encryption without a trusted third-party. It also proposes a feature importance initialization method based on Gini impurity to reduce overhead. Experiments show that FedSDG-FS outperforms existing approaches in selecting high-quality features and building global models with higher performance. The proposed method solves the problem of efficient feature selection in VF.
## (s13) C. Trustworthy Model Selection
(p13.0) In FL, it is crucial to evaluate the contributions of participants to the performance of the final model while ensuring privacy. To achieve this, the widely adopted method is the use of Shapley Value (SV) techniques. However, existing SV-based approaches are computationally expensive and impractical for real-world applications. To tackle this issue, authors in [45] introduced the Guided Truncation Gradient Kapley (GTG-Shapley) approach, which reduces the computation cost of SVbased FL participant contribution evaluation. Unlike traditional methods, GTG-Shapley does not require extra learning tasks from participants, as it reconstructs FL sub-models using their previous gradient updates instead of training them from scratch. Additionally, GTG-Shapley employs guided Monte Carlo sampling to further reduce the number of required model reconstructions and evaluations, thereby enhancing the efficiency of SV computation. GTG-Shapley offers a more practical and scalable solution for fair FL participant contribution evaluation. GTG-Shapley enables FL to be more practical and widely adopted in real-world applications.

(p13.1) The aggregation of local models from participating clients is a critical component in generating the final global model in FL. However, traditional aggregation methods can be susceptible to adversarial attacks and client failures. To mitigate this issue, the authors of this paper propose a truth inference approach to FL that incorporates the reliability of each client's local model into the aggregation process. The proposed approach in [46] models the clients' reliability based on their submitted local model parameters and considers these parameters during the aggregation process to produce a robust estimate of the global model. The authors have further enhanced the method by considering the model parameters submitted by clients in previous rounds in addition to the current round, thus providing a more comprehensive evaluation of client reliability.The proposed truth inference approach provides a more robust estimate of the global model, protects against potential adversarial attacks, and considers client reliability in the aggregation process, thereby improving the robustness of FL.
## (s17) B. Trustworthy Contribution Evaluation
(p17.0) The contribution measurement strategies used in FL systems can be classified into three main categories: self-report based evaluation, Shapley value based evaluation, and influence and reputation based evaluation. Self-report based evaluation involves the data owner directly reporting their level of contribution to the model owner. Metrics used to evaluate the contribution include computational resources and data size. The Shapley value based evaluation takes into account the participation order of the data owners and assesses their contributions in a fair manner, typically used in cooperative games. Influence and reputation based evaluation considers the client's impact on the FL model's loss function and their reliability, and may involve techniques like Fed-Influence and reputation mechanisms that can be combined with blockchain. A client's reputation is generally a combination of their internal reputation in a task and their accumulated reputation based on historical records. The authors in [89] focuses on the critical aspect of measuring the contributions of users in FL systems. The authors conduct a comprehensive analysis of the different strategies for evaluating user contributions, examining the factors that can impact the effectiveness of these methods. The paper emphasizes the need for fair and accurate evaluation techniques to assess the contributions of data owners in FL and provides valuable insights into the current state of research in this area. This study highlights the importance of considering user contributions in FL systems and provides a solid foundation for future research in this field. The categorization and most relevant research work are presented in following sub sections.
## (s48) arXiv:2305.11537v1 [cs.AI] 19 May 2023
(p48.0) 3) Streamlined model verification and auditability: Facilitate users to confirm a model update's accuracy and easily access verifiable data for specific update versions. 4) Unalterable model update history: Showcase a globally uniform record of global model updates without changes. Within this log, each update corresponds to a distinct entry that cannot be edited or deleted once created. 5) Dependable client and model identification: Select trustworthy clients and models to enhance the FL process. 6) Reliable contribution evaluation and incentive allocation: Implement a credible assessment of contributions and provide incentives to encourage FL clients' participation in future sessions. Investigators must concentrate on novel approaches to address the challenges in FL by creating equitable and dependable metrics for worker selection and evaluation. 7) Dynamic authoritative keys management: Allow updates for authoritative keys, even if some, but not most, keys are compromised. 8) Timely Monitoring: Timely monitoring methods for workers and model assessment schemes are necessary. Strengthening security and privacy features is crucial for Trustworthy FL.

(p48.1) By emphasizing these objectives, crucial areas and fostering cooperation among stakeholders, the creation of secure and dependable FL systems can facilitate more responsible and ethical AI applications. Within the current research landscape, there is a noticeable absence of studies investigating the crucial pillars of trustworthiness, specifically in relation to FL. To the best of our knowledge, this is the pioneering work encompassing all facets of Trustworthy FL. In an effort to bridge the gaps in existing literature, this study presents the following contributions: 1) We furnish an overview of the fundamental principles underlying trustworthy FL, accompanied by a comprehensive architecture of Trustworthy FL and trust assessment mechanisms. 2) We develop a taxonomy centered on the most pertinent trustworthiness pillars within FL contexts. In order to construct this taxonomy, we identify three primary pillars as the foundational elements: Interpretability, Fairness, and Security & Privacy. Each pillar embodies a dimension of trust, which is further delineated into distinct concepts for each pillar. Additionally, we explore the key challenges and future directions in the realm of Trustworthy FL. 3) In conclusion, we highlighted the essential research challenges associated with each facet of Trustworthy FL, as well as the direction for future investigations.

(p48.2) The remainder of this paper is organized as follows: The structure of this paper is as follows: We commence with an introduction to FL and its classification in Section 2, succeeded by a discussion on trust in FL, fundamental principles of trustworthiness, and the architecture of Trustworthy FL systems in Section 3. Section 4 presents a literature review, emphasizing existing research in the domain. Sections 5-8 delve into trust evaluation, trust-aware interpretability, fairness-aware trustworthiness, and trust-aware security & privacy-preserving FL systems, respectively. Throughout the paper, we examine topics such as data and feature selection, data sharing, model selection, explainability, client selection, contribution assessment, incentive mechanisms, accountability, auditability, secure and data aggregation, privacy preservation, and more. In conclusion, we explore open challenges and future research avenues in the field of Trustworthy FL, laying the foundation for the creation of secure and dependable FL systems that facilitate responsible and ethical AI applications.

(p48.3) 3) Streamlined model verification and auditability: Facilitate users to confirm a model update's accuracy and easily access verifiable data for specific update versions. 4) Unalterable model update history: Showcase a globally uniform record of global model updates without changes. Within this log, each update corresponds to a distinct entry that cannot be edited or deleted once created. 5) Dependable client and model identification: Select trustworthy clients and models to enhance the FL process. 6) Reliable contribution evaluation and incentive allocation: Implement a credible assessment of contributions and provide incentives to encourage FL clients' participation in future sessions. Investigators must concentrate on novel approaches to address the challenges in FL by creating equitable and dependable metrics for worker selection and evaluation. 7) Dynamic authoritative keys management: Allow updates for authoritative keys, even if some, but not most, keys are compromised. 8) Timely Monitoring: Timely monitoring methods for workers and model assessment schemes are necessary. Strengthening security and privacy features is crucial for Trustworthy FL.

(p48.4) By emphasizing these objectives, crucial areas and fostering cooperation among stakeholders, the creation of secure and dependable FL systems can facilitate more responsible and ethical AI applications. Within the current research landscape, there is a noticeable absence of studies investigating the crucial pillars of trustworthiness, specifically in relation to FL. To the best of our knowledge, this is the pioneering work encompassing all facets of Trustworthy FL. In an effort to bridge the gaps in existing literature, this study presents the following contributions: 1) We furnish an overview of the fundamental principles underlying trustworthy FL, accompanied by a comprehensive architecture of Trustworthy FL and trust assessment mechanisms. 2) We develop a taxonomy centered on the most pertinent trustworthiness pillars within FL contexts. In order to construct this taxonomy, we identify three primary pillars as the foundational elements: Interpretability, Fairness, and Security & Privacy. Each pillar embodies a dimension of trust, which is further delineated into distinct concepts for each pillar. Additionally, we explore the key challenges and future directions in the realm of Trustworthy FL. 3) In conclusion, we highlighted the essential research challenges associated with each facet of Trustworthy FL, as well as the direction for future investigations.

(p48.5) The remainder of this paper is organized as follows: The structure of this paper is as follows: We commence with an introduction to FL and its classification in Section 2, succeeded by a discussion on trust in FL, fundamental principles of trustworthiness, and the architecture of Trustworthy FL systems in Section 3. Section 4 presents a literature review, emphasizing existing research in the domain. Sections 5-8 delve into trust evaluation, trust-aware interpretability, fairness-aware trustworthiness, and trust-aware security & privacy-preserving FL systems, respectively. Throughout the paper, we examine topics such as data and feature selection, data sharing, model selection, explainability, client selection, contribution assessment, incentive mechanisms, accountability, auditability, secure and data aggregation, privacy preservation, and more. In conclusion, we explore open challenges and future research avenues in the field of Trustworthy FL, laying the foundation for the creation of secure and dependable FL systems that facilitate responsible and ethical AI applications.
## (s49) II. FEDRATED LEARNING AN OVERVIEW
(p49.0) FL is a transformative approach to distributed machine learning, enabling the collaborative training of models across multiple devices or clients while preserving data privacy [11]. Various FL architectures have been developed to address the diverse challenges and requirements in data distribution, communication patterns, and coordination methods. These architectures can be broadly classified into three main categories: data distribution-based architectures, such as Horizontal FL (HFL), Vertical FL (VFL), and Federated Transfer Learning (FTL); scale and communication-based architectures, including Cross-Silo FL (CSFL) and Cross-Device FL (CDFL); and coordination-based architectures, which encompass Centralized FL, Decentralized FL, and Hierarchical FL. Each of these architectures caters to specific needs and constraints, ensuring optimal model development across a wide range of applications while maintaining data privacy and security.

(p49.1) A. Data Distribution-Based FL Architectures 1) Vertical FL: VFL involves federated training of datasets that share the same sample space but differ in feature spaces. It is apt for scenarios in which data is divided vertically based on feature dimensions, with different parties holding homogeneous data that partially overlaps in sample IDs. Entity alignment and encryption methods can be employed to address data sample overlapping during local training. One instance of VFL in the healthcare sector is the collaboration between hospitals and insurance companies, jointly training an AI model using their respective datasets. Although VFL provides data privacy and joint training benefits, it presents more implementation challenges than HFL due to the requirement for entity resolution and the limitations of current techniques for complex machine learning models.

(p49.2) 2) Horizontal FL: In HFL, multiple participants possessing datasets with identical feature spaces but varying sample spaces collaborate in training a joint global model. The datasets are used locally, and a server merges the local updates received from the participants to develop a global update without accessing the local data directly. One example of HFL in the healthcare domain is speech disorder detection, where users with different voices speak identical sentences, and the local updates are combined to create a comprehensive speech recognition model. HFL is primarily utilized in smart devices and IoT applications. It allows leveraging data from numerous sources without sharing raw data, thus maintaining privacy.

(p49.3) However, HFL may encounter challenges when dealing with a limited number of labeled entities. 3) Federated Transfer Learning: FTL is tailored to handle datasets that differ in both sample spaces and feature spaces. Transfer learning techniques are used to compute feature values from distinct feature spaces into a uniform representation, which is then employed for local dataset training. Privacy protection mechanisms, such as random masks, can be implemented during the gradient exchange between clients and servers. FTL can support smart healthcare use cases like disease diagnosis by enabling collaboration among multiple hospitals with distinct patients and treatment plans. Although FTL has potential, it remains an evolving research area with challenges related to communication efficiency and flexibility in dealing with diverse data structures. Nevertheless, it provides a promising solution for ensuring data security and user privacy while addressing data island problems. An illustration of these data distribution-based FL architectures is presented in Fig. 1.

(p49.4) FL is a transformative approach to distributed machine learning, enabling the collaborative training of models across multiple devices or clients while preserving data privacy [11]. Various FL architectures have been developed to address the diverse challenges and requirements in data distribution, communication patterns, and coordination methods. These architectures can be broadly classified into three main categories: data distribution-based architectures, such as Horizontal FL (HFL), Vertical FL (VFL), and Federated Transfer Learning (FTL); scale and communication-based architectures, including Cross-Silo FL (CSFL) and Cross-Device FL (CDFL); and coordination-based architectures, which encompass Centralized FL, Decentralized FL, and Hierarchical FL. Each of these architectures caters to specific needs and constraints, ensuring optimal model development across a wide range of applications while maintaining data privacy and security.

(p49.5) A. Data Distribution-Based FL Architectures 1) Vertical FL: VFL involves federated training of datasets that share the same sample space but differ in feature spaces. It is apt for scenarios in which data is divided vertically based on feature dimensions, with different parties holding homogeneous data that partially overlaps in sample IDs. Entity alignment and encryption methods can be employed to address data sample overlapping during local training. One instance of VFL in the healthcare sector is the collaboration between hospitals and insurance companies, jointly training an AI model using their respective datasets. Although VFL provides data privacy and joint training benefits, it presents more implementation challenges than HFL due to the requirement for entity resolution and the limitations of current techniques for complex machine learning models.

(p49.6) 2) Horizontal FL: In HFL, multiple participants possessing datasets with identical feature spaces but varying sample spaces collaborate in training a joint global model. The datasets are used locally, and a server merges the local updates received from the participants to develop a global update without accessing the local data directly. One example of HFL in the healthcare domain is speech disorder detection, where users with different voices speak identical sentences, and the local updates are combined to create a comprehensive speech recognition model. HFL is primarily utilized in smart devices and IoT applications. It allows leveraging data from numerous sources without sharing raw data, thus maintaining privacy.

(p49.7) However, HFL may encounter challenges when dealing with a limited number of labeled entities. 3) Federated Transfer Learning: FTL is tailored to handle datasets that differ in both sample spaces and feature spaces. Transfer learning techniques are used to compute feature values from distinct feature spaces into a uniform representation, which is then employed for local dataset training. Privacy protection mechanisms, such as random masks, can be implemented during the gradient exchange between clients and servers. FTL can support smart healthcare use cases like disease diagnosis by enabling collaboration among multiple hospitals with distinct patients and treatment plans. Although FTL has potential, it remains an evolving research area with challenges related to communication efficiency and flexibility in dealing with diverse data structures. Nevertheless, it provides a promising solution for ensuring data security and user privacy while addressing data island problems. An illustration of these data distribution-based FL architectures is presented in Fig. 1.
## (s58) A. Trustworthy Feature and Sample Selection
(p58.0) The authors proposes a new approach called Federated Stochastic Dual-Gate based Feature Selection (FedSDG-FS) [37] for feature selection in Vertical FL (VFL). Existing FS works for VFL assume prior knowledge on the number of noisy features or the threshold of useful features to be selected, making them unsuitable for practical applications. FedSDG-FS uses a Gaussian stochastic dual-gate to approximate the probability of a feature being selected with privacy protection through Partially Homomorphic Encryption without a trusted third-party. It also proposes a feature importance initialization method based on Gini impurity to reduce overhead. Experiments show that FedSDG-FS outperforms existing approaches in selecting high-quality features and building global models with higher performance. The proposed method solves the problem of efficient feature selection in VF.
## (s60) C. Trustworthy Model Selection
(p60.0) In FL, it is crucial to evaluate the contributions of participants to the performance of the final model while ensuring privacy. To achieve this, the widely adopted method is the use of Shapley Value (SV) techniques. However, existing SV-based approaches are computationally expensive and impractical for real-world applications. To tackle this issue, authors in [45] introduced the Guided Truncation Gradient Kapley (GTG-Shapley) approach, which reduces the computation cost of SVbased FL participant contribution evaluation. Unlike traditional methods, GTG-Shapley does not require extra learning tasks from participants, as it reconstructs FL sub-models using their previous gradient updates instead of training them from scratch. Additionally, GTG-Shapley employs guided Monte Carlo sampling to further reduce the number of required model reconstructions and evaluations, thereby enhancing the efficiency of SV computation. GTG-Shapley offers a more practical and scalable solution for fair FL participant contribution evaluation. GTG-Shapley enables FL to be more practical and widely adopted in real-world applications.

(p60.1) The aggregation of local models from participating clients is a critical component in generating the final global model in FL. However, traditional aggregation methods can be susceptible to adversarial attacks and client failures. To mitigate this issue, the authors of this paper propose a truth inference approach to FL that incorporates the reliability of each client's local model into the aggregation process. The proposed approach in [46] models the clients' reliability based on their submitted local model parameters and considers these parameters during the aggregation process to produce a robust estimate of the global model. The authors have further enhanced the method by considering the model parameters submitted by clients in previous rounds in addition to the current round, thus providing a more comprehensive evaluation of client reliability.The proposed truth inference approach provides a more robust estimate of the global model, protects against potential adversarial attacks, and considers client reliability in the aggregation process, thereby improving the robustness of FL.
## (s64) B. Trustworthy Contribution Evaluation
(p64.0) The contribution measurement strategies used in FL systems can be classified into three main categories: self-report based evaluation, Shapley value based evaluation, and influence and reputation based evaluation. Self-report based evaluation involves the data owner directly reporting their level of contribution to the model owner. Metrics used to evaluate the contribution include computational resources and data size. The Shapley value based evaluation takes into account the participation order of the data owners and assesses their contributions in a fair manner, typically used in cooperative games. Influence and reputation based evaluation considers the client's impact on the FL model's loss function and their reliability, and may involve techniques like Fed-Influence and reputation mechanisms that can be combined with blockchain. A client's reputation is generally a combination of their internal reputation in a task and their accumulated reputation based on historical records. The authors in [89] focuses on the critical aspect of measuring the contributions of users in FL systems. The authors conduct a comprehensive analysis of the different strategies for evaluating user contributions, examining the factors that can impact the effectiveness of these methods. The paper emphasizes the need for fair and accurate evaluation techniques to assess the contributions of data owners in FL and provides valuable insights into the current state of research in this area. This study highlights the importance of considering user contributions in FL systems and provides a solid foundation for future research in this field. The categorization and most relevant research work are presented in following sub sections.
