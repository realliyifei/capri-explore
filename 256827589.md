# The Construction of Reality in an AI: A Review

CorpusID: 256827589
 
tags: #Computer_Science, #Philosophy

URL: [https://www.semanticscholar.org/paper/e0f4a11f762c09c39ce7132d0df922943bda3db3](https://www.semanticscholar.org/paper/e0f4a11f762c09c39ce7132d0df922943bda3db3)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | False |
| By Annotator      | (Not Annotated) |

---

The Construction of Reality in an AI: A Review
January 23, 2023

Jeffrey W Johnston jeffj4a@earthlink.net 
The Construction of Reality in an AI: A Review
January 23, 20231AI constructivismdevelopmental roboticslifelong learningartificial general in- telligenceinfant bootstrapgeneral-purpose concept learning
AI constructivism as inspired by Jean Piaget, described and surveyed by Frank Guerin, and representatively implemented by Gary Drescher seeks to create algorithms and knowledge structures that enable agents to acquire, maintain, and apply a deep understanding of the environment through sensorimotor interactions. This paper aims to increase awareness of constructivist AI implementations to encourage greater progress toward enabling lifelong learning by machines. It builds on Guerin's 2008 "Learning Like a Baby: A Survey of AI approaches." After briefly recapitulating that survey, it summarizes subsequent progress by the Guerin referents, numerous works not covered by Guerin (or found in other surveys), and relevant efforts in related areas. The focus is on knowledge representations and learning algorithms that have been used in practice viewed through lenses of Piaget's schemas, adaptation processes, and staged development. The paper concludes with a preview of a simple framework for constructive AI being developed by the author that parses concepts from sensory input and stores them in a semantic memory network linked to episodic data. Extensive references are provided.Keywords: AI constructivism, developmental robotics, lifelong learning, artificial general intelligence, infant bootstrap, general-purpose concept learning has minimal, although extensive, built-in capabilities." AI constructivism offers a promising approach for aligning agents with human sensibilities, allowing them to acquire common sense, avoiding brittleness from trying to program them for all contingencies, and enabling lifelong learning.Biology supports the constructivist approach per evidence of brain plasticity (Bach-y-Rita and Kercel  2003), neural constructivism (Quartz and Sejnowski 1997), Mountcastle's hypothesis that a single learning algorithm operates in the primate neocortex (Hawkins 2004;Dean et al. 2012), postnatal neurogenesis(Kuhn et al. 2018), and the emergence of semantic hubs in human brains (Garagnani and Pulvermuller 2016). Machine learning research has shown that nodes in artificial neural networks correspond to features and concepts induced from input streams(Carter et al. 2019;Goh et al. 2021).This paper considers AI constructivism synonymous with developmental robotics (Cangelosi and Schlesinger 2015) 3 , autonomous mental developmentZhang 2009)4  , cognitive and developmental systems (Jin 2016) 5 , epigenetic robotics(Lungarella et al. 2003)6  , autonomous learning(Shen 1989(Shen , 1994, cognitive (developmental) robotics (Clark A and Grush 1999;), and the computational approach to constructivism(Riegler 2005). It favors the term "AI constructivism" in recognition of Piaget and Drescher's pioneering work and considers "constructivism" a more evocative and precise descriptor.Key elements of Piaget's theory of cognitive development often leveraged by AI constructivists include schemas (a.k.a. schemata) as the building blocks of skills and knowledge, adaptation processes of assimilation and accommodation as key learning processes 7 , and cognitive development occurring in stages. According to McLeod (2020), Piaget considered a schema "a cohesive, repeatable action sequence possessing component actions that are tightly interconnected and governed by a core meaning." Assimilation refers to the incorporation of experiential information into existing schemas. Accommodation refers to modification of existing schemas (or creation of new ones) when experiences are incompatible with existing schemas. Piaget defined stages of development as sensorimotor (ages 0-2), pre-operational (ages 2-7), concrete operational (ages 7-11), and formal operational (ages 11+). In the sensorimotor stage, schemas are constructed from reflexes (i.e., innate schemas) that develop into increasingly purposeful behaviors via circular reactions. 8 Cognitive abilities developed during this stage include understanding object permanence, recognizing the self, applying behaviors observed in others to one's own behaviors (i.e., deferred imitation), and using proxies (e.g., toys) to simulate real-world situations (i.e., representational play). The pre-operational stage is characterized by development of symbolic thought. The concrete operational stage is marked by development of logical thinking. In the formal operational stage, humans develop the ability to think abstractly and engage in scientific reasoning (McLeod 2020; Wikipedia, Piaget's theory of cognitive development).3 "Developmental robotics is the interdisciplinary approach to the autonomous design of behavioral and cognitive capabilities in artificial agents (robots) that takes direct inspiration from the developmental principles and mechanisms observed in the natural cognitive systems of children (C&S 2015, p. 4)." 4 This terminology was adopted for the IEEE Transactions on Autonomous Mental Development journal in 2009. 5 IEEE Transactions on Autonomous Mental Development was renamed Transactions on Cognitive and Developmental Systems in 2016. 6 Lungarella et al. distinguish epigenetic robotics from developmental robotics as follows: "The former focuses primarily on cognitive and social development, as well as on sensorimotor environmental interaction, the latter encompasses a broader spectrum of issues, by also investigating the acquisition of motor skills and the role played by morphological development." 7 Piaget's later work (e.g.(Piaget 1977(Piaget , 1985) also stresses equilibration-a process of continuous adaptation-that balances assimilation-accomodation constructions and genetic and social influences. This paper presumes equilibration is subsumed by assimilation and accommodation. That is, when disequilibrium ("cognitive dissonance") occurs an existing concept must be expanded by assimilation (e.g., adding new features to a class) or new schemas created by accommodation to relieve dissonance and restore equilibrium. 8 "Circular reaction" was used by Piaget (1952, p. 49) by way of Baldwin J (1895, p. 466) to refer to repetitive actions that become increasingly useful and purposeful as an agent develops. Merriam-Webster defines circular reaction as "a chain reflex in which the final response acts as stimulus for the initial response." sensorimotor stream and the value is a particular sensation or action relevant to that stream, e.g., (sightshape rattle-shape), (sight-color red), (tactile-hand wood), (hand close), (voice cry). Rosenstein et al. (1997)  extend Cohen and attempt to learn schemas as Lakoff and Johnson-style image schemas (Lakoff and Johnson 1980; Johnson M 1987 10 ;Gibbs and Colston 1995)represented as 2dimensional activity maps.Stojanov(2001)describes aspects of the Petitagé system including expectancies having a SensorState-Action-SensorState structure and schemas that are sequences of actions of arbitrary length.Chaput(2004)presents a Constructivist Learning Architecture that uses Self-Organizing Maps (Kohonen 2013) representing correlations of environmental features as nodes in a hierarchy of increasingly higherlevel knowledge. He summarizes six Information Processing Principles from Cohen LB et al.(2002)as key to "a domain-general learning system that provides continuous learning from the environment" which characterizes staged learning as: 1) Infants are endowed with an innate information-processing system, 2) Infants form higher schemas from lower schemas,3) Higher schemas serve as components for still-higher schemas, 4) There is a bias to process using highest-formed schemas, 5) If, for some reason, higher schemas are not available, lower-level schemas are utilized, 6) This learning system applies throughout development and across domains. (Chaput 2004, pp. 9-10) Barto et al. (2004) explore intrinsically motivated learning as a kind of reinforcement learning (RL) that can drive a developmental agent to learn increasingly complex behaviors. They focus on a surprise/novelty measure as an intrinsic reward signal. Agents repeatedly perform actions that elicit such rewards and lose interest as the novelty/reward subsequently decays. Barto et al. (2004) suggest such a policy can learn closed-loop control rules called options, which are a kind of schema consisting of an option policy, initiation set, and a termination condition. Details on the options framework, which combines RL with Markov Decision Processes (MDPs) and semi-Markov decision Processes (SMDPs), are provided by Sutton et al. (1999). Sutton (1999) wrote, "If the right features are represented prominent-ly�, then learning is easy�; otherwise it is hard.� It is time to consider seriously how features and other structures can be constructed automatically by machines rather than by people. … In psychology, the idea of a developing mind actively creating its representations of the world is called constructivism. My prediction is that for the next tens of years RL will be focused on constructivism."In an earlier paper, Barto and Mahadevan (2003)  describe work similar to the options framework that also involves hierarchical RL and SMDPs, i.e., Hierarchies of Abstract Machines (HAMs) by Parr and Russell, and MAXQ Value Decomposition by Dietterich. HAMs coordinate the execution of multiple finite-state machines to achieve goals such as in an exemplary robot navigation environment where higher-level behaviors are defined such as back-off or follow-wall. Regarding MAXQ, Barto and Mahadevan  (2003)  state: "Unlike options and HAMs, … the MAXQ approach does not rely directly on reducing the entire problem to a single SMDP. Instead, a hierarchy of SMDPs is created whose solutions can be learned simultaneously." MAXQ structures a hierarchy of actions (subtasks) in a task graph with nodes representing actions like Get, Put, Pickup, Dropoff, Navigate, and move North, South, East, and West.   10  Johnson M (1987, p. xiv) defines image schema as "a recurring, dynamic pattern of our perceptual interactions and motor programs that gives coherence and structure to our experience." It was called image schema because it "functions somewhat like the abstract structure of an image" (ibid, p. 2).IAC framework using active learning 13 terminology. They propose an improved metric for region splitting that balances the mixture rate and relative density of exemplars.Konidaris and Barto(2007)extend the work of Barto et al. (2004) by learning schemas in the options framework wherein agent-space options are generated in addition to the previously described problemspace options. Agent-space skills are reportedly transferrable to new tasks that have different problemspaces. Lee et al. (2007) describe a Lift-Constraint, Act, Saturate (LCAS) approach wherein learning consists of an agent performing actions in a constrained fashion until no new actions are possible. When learning saturates at the current level, constraints limiting the range of actions are lifted and learning continues to the next level. Lee et al. (2007) suggest levels of constraints may occur in an order such as gross motor coordination of limbs, followed by proprioception, tactile sensing, auditory sensation, visual sensation, and fine motor control. They explored primitive motor and sensory variables utilizing a "schema" consisting of 2-D Sensory Space and Motor Drive Space maps. Stoytchev (2007) describes a developmental approach a robot can use to autonomously learn the capabilities of its own body and extend those to tool use. Learning starts with random motor babbling. A Robot Body Schema (RBS) that builds on the Self-Organizing Body Schema (SO-BoS) of Morasso and Sanguineti (1995) is used to situate on-going development. The SO-BoS defines a multiplicity of processing elements (PEi) that each learn prototypical (preferred) body icons which consist of a vector of motor features θ i (e.g., joint positions) and associated sensory features V i (e.g., visual locations): (θ i , V i ). Adjacent PEs learn similar body icons which can be activated in parallel. Stoytchev (2007) also describes how different body frames can be learned by clustering body markers based on co-movement patterns.Kuipers and colleagues (see references above) focused on how to bootstrap learning about an agent's spatial environment. They describe methods an agent can use to learn a model of its sensors, a model of its motor apparatus, and a set of behaviors that allow it to abstract its environment to a discrete representation of places and paths. They propose a spatial semantic hierarchy (SSH) having egocentric models of the agent's sensorimotor apparatus at the bottom level and a representation of the environment defined by a discrete set of views and actions at the top. The SSH consists of five levels: sensorimotor, control, causal, topological, and metrical. It is constructed by learning sensorimotor features of the agent/environment and then proceeds to learning actions that predict sensorimotor events, to doing further (causal) abstraction into a finite set of views and actions, to learning global representation of world structure to, finally, filling in details about world structure. This work is notable for its degree of constructivism even at the lowest levels, e.g., sensory features are learned by feature generators that detect similar inputs over time and have similar frequency distributions. Motion control features are similarly learned via general low-level algorithms. At the causal level, Kuiper's schemas represent state transitions that similar to Drescher (1987/1991) and others, i.e., View-Action-View. This work also attempts to consolidate ideas from Sutton et al. (1999) (i.e., options), Chaput (2004) (i.e., Kohonen Self-Organizing Maps), and others into the context of the SSH architecture.Olsson et al. 's (2006)  extensions to low level sensorimotor learning in the SSH framework use information theoretical metrics for correlating sensors and developing sensoritopic maps that reflect the informational geometry of the agent's sensors. The maps are used to generate sensorimotor laws that specify how agent actions affect its sensors.  Kuipers (2004, 2007)  go beyond the SSH spatial learning model to describe unsupervised learning of objects via steps of Individuation, Tracking, Image Description, and Categorization. Objects 13 In active learning, the most informative training examples are sought (and generally labeled by an expert) to accelerate model learning.14 More formally, they note the probability of a concept being applicable to a scene is P(c) * =σ×P(c)+(1−σ)×P(c|χ), where c ∈ C = N ∪ A ∪ V is a concept (consisting of Noun, Adjective, and Verb parts), P(c) is the MRF-decided probability of the concept c, χ is the context, P(c|χ) is the probability of the concept given the context (decided by Incremental-LDA), and P(c) * is the updated value of the concept probability. σ is a hyper-parameter used for regulating the strength of contextual feedback. 15  Wubble World focused on constructivist language development.

# Introduction

Constructivism in artificial intelligence (AI), inspired by the developmental psychology of Jean Piaget (1936/1954 and successors like Cohen LB (1977), Karmiloff-Smith (1992), and Mandler (1992Mandler ( , 2004Mandler ( , 2012, has been described and implemented by Cunningham (1972), Drescher (1989Drescher ( /1991, Shen (1989), Cohen PR et al. (1997), Kuipers (2000), Barto et al. (2004), Chaput (2004), Guerin (2008aGuerin ( , 2008b, and others. McLeod (2020) describes a key insight of Piaget (that is core to constructivist AI) as "Children are born with a very basic mental structure (genetically inherited and evolved) on which all subsequent learning and knowledge are based." AI constructivists reject nativist positions that suggest innate, specialized, evolutionally programmed mechanisms underlie most mental activity. Rather, they presume agents have limited innate knowledge and general-purpose algorithms enable continuous learning in situated environments. 1 Many AI constructivists, such as Drescher (1989Drescher ( /1991, are aligned with developers like Albus (2008), Tenenbaum et al. (2011), Lake et al. (2016, Dupoux (2016), andDiCarlo (2018) in further characterizing the constructivist goal as "reverse engineering the human mind." Alan Turing (1950) anticipated AI constructivism writing, "Instead of trying to produce a programme to simulate the adult mind, why not rather try to produce one which simulates the child's? If this were then subjected to an appropriate course of education one would obtain the adult brain." This approach is seen as a path to artificial general intelligence 2 by developers like Adams et al. (2012) who join Nilsson (2005 in advocating for "the development of general-purpose, educable systems that can learn and be taught to perform any of the thousands of jobs that humans can perform … beginning with a system that AI constructivists have adopted Piagetian elements to varying degrees. Schemas generally correspond to knowledge, skill, or concept representations. Adaptation processes correspond to learning algorithms that create and maintain schemas. Staged development is a key influence on the constitution of learningalgorithms and agent architectures. At its core, staging is the principle that prior knowledge and skills provide the basis for subsequent knowledge and skills. Early AI schemas include Minsky's (1975) frames, Schank and Abelson's (1975) scripts, and Rumelhart's schemas (Rumelhart and Ortony 1977). Schemas have been implemented as data structures; small modular programs; software functions, subroutines, and objects; self-organizing maps; rules; production systems; finite state machines; semantic nets; artificial neural networks; physics simulators; mini Turing machines; combinations of these; and other constructs. This paper is structured around a recapitulation of Guerin's (2008a) survey of constructivist systems developed by AI practitioners. Section 2 provides a brief chronological summary of the developments covered therein with a focus on data structures, algorithms, and staging. Section 3 examines progress by the Guerin referents since 2008. Section 4 presents many notable works not covered in Guerin, including some that are lesser known, out of mainstream AI, and subsequent to 2008. Section 5 lists related areas of AI research. Section 6 provides an overview of a constructivist AI approach being developed by the author that parses concepts from sensory input and stores them in a semantic memory network linked to episodic data. The approach aims to provide "mechanisms to bridge the gap between the sensorimotor level and high-level cognition" (Guerin's comments to (Perotto 2013, p. 312). Appendix A lists topics, keywords, and references from Cangelosi and Schlesinger's (2015) excellent book on developmental robotics. Other AI constructivism surveys are available by Lungarella et al. (2003), Ziemke (2001). Guerin (2008a) summarizes some history and key developments of AI constructivism beginning with Drescher (1989Drescher ( /1991 and continuing through Cohen PR et al. (1997), Rosenstein et al. (1997), Stojanov et al. (1997Stojanov et al. ( , 2001, Chaput (2004), Barto et al. (2004), Barto and Mahadevan (2003), Bakker and Schmidhuber (2004), Holmes and Isbell (2006), Perotto and Alvares (2006), St. Amant et al. (2006), , Oudeyer et al. (2007), Bondu and Lemaire (2007), Konidaris and Barto (2007), , Stoytchev (2007), and Kuipers and colleagues (e.g., Pierce and Kuipers (1997), Kuipers (2000), Kuipers and Beeson (2002), Modayil and Kuipers (2004), , , Olsson et al. (2006), Modayil and Kuipers (2007), Provost et al. (2007)). This section briefly summarizes these works-characterizing the components, algorithms, and architectures in terms of Piaget's schemas, adaptation processes, and staged development.


# The Guerin 2008 Survey

For Drescher (1989Drescher ( /1991, the schema is a simple Context-Action-Result 9 structure, e.g., SeeHandAtPo-sitionX-MoveHandBackward-SeeHandAtPositionY. These schemas can grow to represent more sophisticated knowledge via mechanisms of chaining, synthetic item generation, spinoff schemas, and composite actions. The general learning algorithm, the "schema mechanism," utilizes processes of induction (i.e., marginal attribution), abstraction, and invention. It is focused on the first 5 sub-stages of Piaget's Sensorimotor stage, while presumed to apply to the later stages as well.

In Cohen PR et al.'s (1997) Neo system, temporally-coincident sensations and percepts form schemas called fluents which combine into increasingly sophisticated structures called composite fluents, chains, classes, and physical schemas. Base fluents are "(attribute value)" pairs where the attribute identifies a 9 Context-Action-Result (or CurrentState-Action-NextState) is a common design pattern for constructivist learning (e.g., Stojanov, 2001;Bakker and Schmidhuber, 2004;Perotto and Alvares, 2006). It may also be seen to be analogous to Bayesian reasoning where Prior (context) + New Evidence (action) = Posterior (result) and to rules in production systems (Klahr and Wallace, 1976). Bakker and Schmidhuber (2004) describe the HASSLE algorithm (Hierarchical Assignment of Subgoals to Subpolicies LEarning algorithm)-a hierarchical reinforcement learning algorithm that uses intrinsically motivated learning to allow high-level policies to discover sub-goals by clustering sensor data and have low-level policies specialize on reaching sub-goals. Observation vectors are clustered using ARAVQ (Adaptive Resource Allocation Vector Quantization). High-level and low-level options 11 (schemas) are learned as high-and low-level value functions using temporal difference learning at different temporal resolutions. The system claims to have automatically achieved three levels of learning for an agent navigating a simulated office grid world. Holmes and Isbell (2006) employ looping Prediction Suffix Trees to represent deterministic Partially Observable Markov Decision Processes to identify what state an agent is in and predict what can happen next. Perotto and Alvares' (2006) schemas consist of Context-Action-Expectation triples where each element is represented by a vector of sensor (or effector) states where each state can have a value of true, false, or undefined. The schemas are organized into trees where root nodes represent general situations and more specific situations are encoded in the more distal branches and leaves. In Perotto et al. (2007), a Constructivist Anticipatory Learning Mechanism (CALM) is introduced that extends Context-Action-Expectation schemas to more complex (partially deterministic and partially observable) environments by using synthetic elements to represent abstract or hidden properties. St. Amant et al. (2006) extends Rosenstein et al. (1997) in describing an image schema language (ISL) for representing Lakoff and Johnson-style image schemas (Lakoff and Johnson 1980;Johnson M 1987;Gibbs and Colston 1995). Therein, "image schemas are objects, as in the object-oriented data model" where "each schema has a set of operations that determine its capabilities" and "internal slots … that permit image schemas to be related to each other through their slot values." Sets of image schema instances can be used to define each state in a state machine 12 . St. Amant et al. (2006) also define learned sequences of image sequences called "gists" which serve as a kind of higher-level reusable action structure tied to particular goals. Chang et al.'s (2006) Jean system builds on St. Amant et al. (2006) using ISL concepts to implement an infant-like agent that attempts to learn, execute, and extend schemas in a simulated playpen environment. It introduces an Experimental State Splitting (ESS) algorithm for building a world model by composing schemas into gists (composite schemas) and differentiating (splitting) existing states into new states. The authors claim their policies allow Jean to learn causal relationships. Cohen PR et al. (2007) provides more details on action schemas and Jean's ability to learn and repurpose (transfer) gists in a 3-D real time strategy game environment. Oudeyer et al. (2007) use vector exemplars representing sensorimotor experiences, which are partitioned into distinct regions using an Intelligent Adaptive Curiosity (IAC) algorithm that utilizes intrinsically motivated learning similarly to Barto et al. (2004). Each region is associated with a particular learning machine, e.g. neural network, support vector machine, or Bayesian machine. The number of exemplars allocated to a region is limited to 250. Each region maintains a list of error rates representing how much the results of executed actions vary from what was predicted. These lists are subsequently used to select the best actions for new situations. Bondu and Lemaire (2007) extend this work by reformulating the are described by suitably constituted sensor readings that are clustered to identify particular objects. They describe an object ontology by a tuple " (Trackers, Perceptual Functions, Concepts, and Actions)." Object concepts are formed by clustering object percepts that are stable in time. Associated actions are actions that have been learned that reliably change a particular object's percepts.


# Subsequent Work by the Guerin Referents

This section summarizes constructivist AI work since 2008 by those surveyed in (Guerin 2008a). People not mentioned, like Drescher, Chaput, Bakker, Holmes, and Isbell, appear to have not continued this line of development.

Guerin and colleagues have published on learning object manipulation and tool use (Guerin et al. 2013) and on automatically identifying tools and their functions (Abelha et al. 2016;Abelha and Guerin 2017). Guerin et al. (2013) provides a summary of constructivist developmental paths, methods, and potential knowledge representations consistent with developmental psychology. Celikkanat et al. (2015a) describe work on modeling the context of an agent using a Random Markov Field "concept web" as a latent variable of an incremental Latent Dirichlet Allocation (LDA) process. They define context as the "set of active concepts in the scene" and leverage context for agent cognition and behavior 14 .

Subsequent to Neo, Jean, ISL, Wubble World 15 , and related systems described in (Cohen PR et al. 1997;Rosenstein et al. 1997;St. Amant et al. 2006;and Kerr et al. 2007), Paul Cohen and colleagues continued work in the AI constructivist vein on language learning (Hewlett and Cohen 2009;Hewlett 2011), an Action Schema Generator that can acquire and represent semantic knowledge based on a simulated agent's experience (Mu 2009), representing activities as finite state machines (Kerr et al. 2011), and ways for humans to teach autonomous agents (Kaochar et al. 2011). More recently Cohen has explored leveraging human-machine synergies, where machines focus on mining and synthesizing data into integrated causal models and "pushing" results to humans (Cohen PR 2015;Cohen PR 2018;Cohen PR 2020). This approach advocates AIs be deployed as knowledge extraction and synthesis tools rather than agents that learn and reason like humans. The Big Mechanism program (Cohen PR 2015) uses AI to automatically build causal models by extracting causal claims from scientific papers. Associated DARPA-affiliated programs "demonstrated that machines can read text, tables, equations and even FORTRAN code from legacy models, and build comprehensive models of the world's complicated, interacting systems" (Cohen PR 2020). Cohen contrasts this approach with typical big data and machine learning methods that focus on learning patterns (correlations) and not on discovering causal mechanisms.

Kuipers and colleagues continued work on autonomous environmental mapping, including further development of the Spatial Semantic Hierarchy (SSH) model through variants called hybrid-SSH (HSSH) (Kuipers 2008) and Hierarchical Hybrid Spatial Semantic Hierarchy (H 2 SSH) (Johnson CE 2018). The HSSH "represents a robot's environment using four distinct layers that provide metrical and topological representations of both small-scale and large-scale space." H 2 SSH (Johnson CE 2018) "improves on the HSSH by providing hierarchical representations of both local and global space that improve the scalability of the topological mapping problem." H 2 SSH updated the HSSH to represent three topological features: path segments, decision points, and destinations; support richer semantics for path segments; and allow nesting of topological maps to support more complex spatial environments. Prior to the H 2 SSH work, Mugan (2010) described an algorithm called the Qualitative Learner of Actions and Perception (QLAP) that autonomously learns predictive models of an environment and a set of hierarchical actions suitable for acting on it. Knowledge is represented as a network of plans and actions. 16 In other work, Xu C (2011) introduces an Object Semantic Hierarchy (OSH) that constructively recognizes and models objects in the environment. As summarized therein: "The agent initially treats everything in the sensory stream as noise. By repeatedly identifying new invariants to reduce the noise, the agent progressively builds models for the background world and foreground objects. For the background world or each foreground object, the model evolves from 2D2D to 2D3D to 3D3D." In another thread, Liu et al. (2011) explore how high-level semantic action concepts/attributes, both manually defined and autonomously learned, can be used to represent higher-level human actions. For example, they note attributes of singleleg-motion, arm-over-shoulder-motion, and torso-up-down-motion may effectively classify the action of golf-swinging. Thus they explore potentially useful decompositions of verbal/action concepts as opposed to the more-studied object recognition and classification domains. Mittelman et al. (2014) describe an attribute tree process (ATP) that learns a tree hierarchy of semantic concepts using an unsupervised Bayesian method. They provide evidence that ATP may be superior to agglomerative hierarchical clustering (AHC) and the factored Bernoulli likelihood model (FBLM) for doing concept clustering. Stojanov (2009) gives a brief summary of AI and robotics work influenced by Piaget from years 1963through 2008. Stojanov and Indurkhya (2013 discuss roles of perceptual similarity and analogy in a constructivist view on creativity. They see analogy as a "core mechanism in human cognitive development rather than a special skill among many" (in distinction to Piaget) and they discern perceptual similarity as a key to creative problem solving.

Perotto (2013) reprises and refines CALM (Perotto et al. 2007), adding a meta-architecture called the coupled agent environment system (CAES) in which an intrinsically motivated CALM agent is situated. The CAES consists of an agent (A) logically comprised of separate body (B) and mind (M) components that exchange percepts (p) and control signals (c). It also defines a "world outside the mind" (W) made up of the agent's body (B) and the wider environment (E) that interact through situations (s) and actuations (a). Perotto notes CAES and a CALM agent interact as two mutually dependent dynamical systems. The world is modeled as a factored and partially observable Markovian decision process (FPOMDP). The paper is followed by commentary by Guerin, Butz, Thorisson, Stojanov, Bickhard, Degris, and Scott on CALM, CAES, and the state of the art of constructivist solutions in general-providing a useful snapshot of the status of constructivist AI development in 2013. They suggest the main unsolved challenge is the ability to build up cognitive capabilities from the sensorimotor level to higher conceptual levels in the presence of complex, high-bandwidth environmental sensations and noise, e.g., create symbols, abstract structures, and models.

Oudeyer continued work on constructivist AI "focusing on sensorimotor development, language acquisition and life-long learning in robots." 17 In response to Lake et al. (2016), Oudeyer (2017a) discusses additional "crucial ingredients" necessary for autonomous learning: curiosity and intrinsic motivation, social learning and natural interaction with peers, and embodiment. In (Oudeyer 2017b), AI constructivism (development) is described as generating a "complex dynamical system, characterized by spontaneous self-organization or emergent patterns at multiple scales of time and space." In (Santucci et al. 2020), Oudeyer and colleagues summarize work on intrinsically motivated open-ended learning in autonomous robots and highlight key open problems including autonomous generation of goals, learning policies to achieve goals, appropriate use of intrinsic motivation ("to support learning compact representations of environment states"), and a need for better ways to encode goals and skills. 16 QLAP represents environmental models using dynamic Bayesian networks (DBNs) and represents action plans using  options framework. Many small Markov Decision Processes (MDPs) are created to represent small aspects of the environment. 17 http://www.pyoudeyer.com/bio/. Barto, Sutton, and colleagues 18 continued exploring sensorimotor approaches to knowledge acquisition (Sutton 2012) building on their work in reinforcement learning. Sutton (2009) summarizes status of the Predictive Empirical Abstract Knowledge (PEAK) project: "an attempt to understand world knowledge in terms of a minimal ontology of sensorimotor experience" where they endeavored to "connect lowlevel signals [consisting of sensations and actions] to higher-level representations in such a way that the knowledge remains grounded and autonomously verifiable." The approach, which included temporally abstract options, option models, and temporal-difference (TD) networks, were evaluated in two simulated environments (bit-to-bit world and compass world) and in a sensor-rich robotic environment (Critterbot).  describe the Horde architecture, which improved upon TD-networks and options using gradient-TD methods and General Value Functions (GVFs) as knowledge representations (schemas). The architecture relies on "a large number of independent reinforcement learning sub-agents, or demons" that learn in parallel, each "responsible for answering a single predictive or goal-oriented question about the world. … Each demon has its own policy, reward function, termination function, and terminal-reward function." Barto et al. (2013) summarize work related to exploring and representing behavioral hierarchies. They describe refinements to the  options framework while focusing on using hierarchical reinforcement learning (HRL) to learn hierarchies of behavioral modules. Da Silva et al. (2014) introduce an active learning method for efficiently acquiring parameterized skills that are more granular and reusable than skills originally defined in the options framework. Niekum et al. (2014) propose constructivist improvements in robotic learning from demonstration (LfD) by discerning "repeated structure at multiple levels of abstraction in demonstration data," thus discovering semantic knowledge about the world and building up a "library of skills" over time. Sutton and colleagues worked on improving the performance of online reinforcement learning algorithms to "true" online versions. These include true online TD(λ) 19 ( van Seijen and Sutton 2014), true online GTD(λ) (van Hasselt et al. 2014), true online Sarsa(λ) (van Seijen and Sutton 2014), and true online emphatic TD(λ) 20 (Sutton 2015). De Asis et al. (2020) suggest fixed-horizon temporal difference (FHTD) methods, which predict "the sum of rewards over a fixed number of future time steps," as being a further advance. Veeriah et al. (2017) describe the crossprop neural network-learning algorithm, which unlike backprop, can "learn to reuse the learned features for solving new and unseen tasks." Stoytchev has since collaborated on work to learn multi-sensory features to categorize common objects (Sinapov et al. 2014) and on work to teach robots to do other object recognition and manipulation tasks 21 . Schmidhuber (2010) summarizes his work on intrinsic motivation from 1990 to 2002. He suggests the purpose of intrinsic motivation is to "provoke event sequences exhibiting previously unknown but learnable algorithmic regularities" and to build an agent "that never stops generating non-trivial & novel & surprising data." Key components of such agents are: "an adaptive world model …, a learning algorithm that continually improves the model …, intrinsic rewards measuring the model's improvement …, [and] a separate reward optimizer or reinforcement learner." Intrinsic rewards assign values to "the discovery or creation of novel patterns," which Schmidhuber equates with "fun or internal joy." He reviews his previous "practical but non-optimal" proposals where reward values are: (1) proportional to the model's prediction errors 22 , (2) proportional to expected improvement (first derivative) of prediction error, (3) proportional to relative entropies of learning agent's priors and posteriors, and (4) determined through 18 Links to Barto's and Sutton's publications are at https://people.cs.umass.edu/~barto/pubs-Barto.html and http://incompleteideas.net/publications.html#beyond_reward. 19 This is a temporal difference algorithm that "combines basic TD learning with eligibility traces to further speed learning." 20 Emphatic approaches generate knowledge structures by selectively emphasizing or de-emphasizing updates on different time steps. Gu et al. (2019) suggest emphatic TD may be superior to other reinforcement learning algorithms. 21 See publications list at http://www.ece.iastate.edu/~alexs/lab/publications/index.html. 22 Schmidhuber (1991a) suggests intrinsic reinforcement be calculated based on the difference between predicted and actual experience where "zero reinforcement should be given in case of perfect matches, high reinforcement should be given in case of 'near-misses', and low reinforcement again should be given in case of strong mismatches." These cases correspond to concepts that are already learned (boring), effectively learnable (curiosity piquing), and unlearnable (befuddling). zero-sum games between a "right brain" and "left brain." Schmidhuber (2013) describes PowerPlay-an "implementation of basic principles of creativity" inspired by playful behavior in animals 23 . PowerPlay evaluates new tasks (problems) against existing skills (problem solvers) and, if a task cannot be solved by an existing skill, it modifies existing skills and remembers one that solves the new task and all previous related tasks. Thus solvers (skills, schemas) become more general over time. Types of solvers considered include deterministic universal computers, finite state automata, and feedforward neural networks. Procedures for task invention, solver modification, and correctness demonstration are described. Schmidhuber (2015) describes recurrent neural network-based AIs (RNNAIs) that learn to think by combining an RL controller with an RNN-based predictive world model. Schmidhuber (2017) suggests technology like Long Short-Term Memory (LSTM) 24 combined with artificial curiosity and creativity will soon enable "an AI that incrementally learns to become as smart as a little animal-curiously and creatively and continually learning to plan and reason and decompose a wide variety of problems into quickly solvable (or already solved) sub-problems." 25 Ha and Schmidhuber (2018) present a simplified framework based on Schmidhuber's work from 1990 -2015 that combines a large RNN-based world model with smaller controller models to enable agents to learn compact and simple task completion policies. They use a Variational Autoencoder to encode image frames, a Mixture Density Network combined with an RNN to predict future frames, and a simple linear model to control outputs. Van Steenkiste et al. (2018) describe a relational neural expectation maximization (R-NEM) method for learning objects and their physical interactions in an unsupervised manner from raw video images. Greff et al. (2020) propose a unifying framework aimed at solving the binding problem and approaching human-level generalization by segregating sensory inputs, maintaining separate symbolic (object) representations, and using those representations to compose new inferences, predictions, and behaviors. They provide an extensive survey of the object representation literature spanning AI and cognitive psychology. Csordás et al. (2021) propose modifying the Transformer architecture by adding a copy gate and using geometric attention to allow Transformers to learn more generally applicable rules.


# Other Constructivists

Early purveyors of constructivist ideas, appropriately not surveyed in (Guerin 2008a) given their less direct influence on AI constructivism, have been discussed by Ernst von Glasersfeld (1984, Michael Arbib (1992), D. C. Phillips (1995), and Sandra Marshall (1995). Perhaps most influential were John Locke (1690) for his embrace of empiricism, rejection of innate ideas, and promotion of the principle that sensations give rise to secondary qualities that enable all ideas 26 ; Immanuel Kant (1781) for challenging Locke's notions of substances and primary qualities and promoting the idea that all knowledge is derived from sensations 27 ; William James for his radical empiricism 28 and proposing how "blooming, buzzing confusion" gives way to knowledge through learning objects and relations via discrimination and synthesis (James 1890) 29 ;and Lev Vygotsky (2012) for emphasizing the significance of social interactions for creating schemas. 23 Playful behaviors are tasks that are usually self-generated and used to acquire skills that can be applied later to tasks encountered in the environment. 24 A type of memory cell used in hidden units of Recurrent Neural Nets (RNNs) that effectively handles long-term temporal dependencies (Greff et al. 2017). 25 Such a goal is being pursued by NNAISENSE, a company Schmidhuber cofounded with Gomez, Koutnik, Steunebrink, and Masci. (https://nnaisense.com). Their current focus is on intelligent automation, deep learning, and AGI. 26 Locke's primary qualities, interpreted as objective "measurable aspects of physical reality" (Wikipedia, Primary/secondary quality distinction), are unnecessary from a constructivist perspective. Secondary qualities interpreted as subjective qualities perceived by the senses, on the other hand, are fundamental to constructivism. 27 Agents have access only to the phenomenal world. The noumenal world (things as they really are) is inaccessible. Reason is used to create additional knowledge from sensed experiences. Kant's conceptions of schema, characterized as rules or filters mapping sensations to concepts, map well to Piaget and other modern psychologists (Scaglia 2018;Marshall 2015). 28 Radical empiricism posits that all knowledge, i.e., objects and relations, comes from direct experience (James 1904). 29 James uses the terms "association and dissociation," "subdividing and uniting," and "break asunder and reunite." He also notes the importance of selective attention and sensory filtering: "We do far more than emphasize things, and unite some, and keep others apart. We actually ignore most of the things before us" (James 1890, p. 284). This section does not examine such influences. Rather, it considers works subsequent to Piaget (1934Piaget ( /1954 that are not in (Guerin 2008a) and more directly relevant to AI constructivist implementations. As in previous sections, the work is presented chronologically.

George Kelly's (1955) Personal Construct Theory (PCT) defines constructs (schemas) as "transparent patterns or templates created by humans and lower animals that fit over the realities of the world and enable them to chart a course of behavior." 30 Developed in the context of clinical psychology, PCT posits that agents construct and adapt personal mental models that allow them to effectively predict events. Agents function as naïve scientists that form and test hypotheses and channel their thoughts and behaviors consistent with plausible hypotheses. 31 Different, often incompatible, constructs are used to make sense of events over time-a process Kelly called constructive alternativism. A distinguishing feature of PCT is that mental constructs consist of pairs of mutually exclusive binary values (e.g., old-young, goodbad, happy-sad, light-dark, comes_when_I_cry, doesn't_come_when_I_cry). These dichotomous constructs define axes of a multi-dimensional psychological space with elements of experience representing points in the space (Kelly 1955, Ch. 6;Gaines and Shaw 2012, p. 21). Constructs form hierarchies, where higher level constructs may change by "invoke[ing] new arrangements among the systems which are subordinate to them" (Kelly 1955, p. 55). To operationalize the theory, Kelly introduced a cognitive mapping technique called repertory grids that provides methods for eliciting constructs and observational elements from agents and organizing them into rows and columns in a matrix (Shaw 1978;Gaines and Shaw 1991;Curtis et al. 2008). This data can be clustered or otherwise compared to progressively refine constructs and better understand agent's mental models. Proponents have nudged PCT in constructivist AI directions by building computer applications that automate the creation and analysis of repertory grids, support the use of repertory grids in non-psychological applications, facilitate knowledge acquisition for expert systems, and aid in constructing semantic networks (Shaw 1978;Gaines and Shaw 1991;Curtis et al. 2008;Gaines and Shaw 2012). 32 Boeree (2006) provides a summary of Kelly's life and works. Ceccato and Zonta (1961) present work on machine translation (MT) 33 that leveraged constructivist principles from their Italian Operational School of philosophy (Hutchins 1986). They specify four key operations (adaptation mechanisms) for constructing thoughts: differentiation, figuration, categorization, and correlation. Differentiation refers to detecting changes of state, which gives rise to distinctions like dark-light, hot-cold, resistant-yielding, green-red-yellow, and silence-noise. Figuration detects changes of place, which allows recognition of shapes and volumes. Categorization corresponds to mental classification based on temporal differentiation, which "gives us the mental, or logical, categories, including, for example, substance, accident, subject, object, and, or, with, also, by, state, point, line, surface..." Correlation, which represents thought itself, links items created by the other three operations into distinct temporal units (Ceccato and Zonta 1961;Ceccato 1962, pp. 62 -65;Hutchins 1986). Ceccato's MT implementation reflected these operations via correlational tables and correlational nets. The latter consisted of a network of correlational triads (the temporal units) each unit comprising a correlator 34 and first and second correlatums. Semantic net-like constructs called notional spheres and frame-like constructs called constellations were used to resolve ambiguities (i.e., polysemanticity) in MT phrase mapping (Ceccato 1962, pp. 83 -87). Ceccato (1967) mentions early work on what he called "The 30 Slightly paraphrased from Kelly (1955, p. 7, pgphs. 1 -2). 31 Kelly's fundamental postulate states: "A person's processes are psychologically channelized by the ways in which he anticipates events." The fundamental postulate is supplemented with 11 corollaries (Kelly 1955, Ch.2). See Appendix I in (Curtis et al. 2008) for a concise summary. 32 Gaines and Shaw (2012, Sect. 4.3) note similar construct descriptions arising in various academic areas, including Bartlett's schema (human memory processes), Ranganathan's faceted taxonomy (library science), Kelly's conceptual/repertory grid (personal construct psychology), Minsky's frames (knowledge representation), Piaget's schema (developmental psychology), Filmore's frames (linguistics), and Barsalou's frames (cognitive psychology). 33 For Ceccato et al., MT signified "mechanical translation." 34 A modest number of primitive correlators (i.e., 100 -200) were envisioned. They consisted of "the conjunctions and prepositions, punctuation marks, and relations such as subject-predicate, substance-accident (i.e., noun-adjective), apposition, development-modality (i.e. verb-adverb), and comparison" (Hutchins 1986). Correlators temporally link correlatums. Fourth Approach to MT," aimed at producing a proof-of-concept machine "which observes and describes the events of its surroundings through the actual operations of perception, representation, categorization, etc." Ayn Rand's Objectivist epistemology (Rand 1967) is notable for its constructivist principles. Claims include: all knowledge is based on perception; a conceptual hierarchy spans from sensations to perceptions to concepts; understanding infant development is key to understanding concept formation; developmentally, existing things (existents) are recognized progressively-first as entities, then identities, then units (i.e., instances); concepts are constructed by differentiating (i.e., abstracting out) and integrating (i.e., uniting) attributes from two or more units using "in large part, a mathematical process;" units are distinguished as having shared attributes with different values; conceptual common denominators such as length, shape, kinds of motion, and color are used to build higher-level concepts; concepts are structured in a hierarchy of increasing abstraction. Boydstun (2012) discusses similarities between Rand and Piaget's ideas. He suggests Rand may have adapted her epistemology to more closely track Piaget given her familiarity with Flavell's (1963) account of Piaget.

Michael Cunningham (1972) proposes a constructivist system that seeks to synthesize Hebb's neural assemblies, Piaget's schemas, and Sokolov's cognitive reflexes. It focuses on modeling mechanisms that are active during the first two years of human development-corresponding to Piaget's Sensorimotor sub-stages. 35 Building-block elements, intended to approximate Piaget schemas and Hebb cell assemblies, are defined as neural structures that reliably produce a particular spatial and temporal firing pattern given a corresponding pattern of stimulation. The key dynamic of the system is characterized as "an ever continuing, ever changing and expanding circular reaction with the environment." Circular reactions are visualized as loops connecting input elements through reflex links to output elements to objects in the environment and back to input elements. The basic schema structure consists of an input element linked to an output element where each represents activations of particular sensory receptors and motor effectors respectively. Activated elements are said to reverberate. Initial circular reactions are entirely instinctual and reflexive 36 . Over time, as a result of experience, additional elements form, become more interlinked, and may exist independently from input and output elements ("tight little knots of mutually interconnected assemblies") enabling more complex behaviors and cognitive capabilities (e.g., memories, chains of thoughts, separation of goals from means). The main mechanism for constructing more complex elements is the linking together of lower-level elements that reverberate at the same time. 37 Drescher (1989, p. 201) cites Cunningham (1972) as the inspiration for his own work. Cunningham and Gray (1974) present an implementation based on (Cunningham 1972). They describe a computer simulation of an infant vocal tract capable of generating outputs based on sensations from rudimentary audio, kinesthetic, and proprioceptive inputs. They claim their system achieved learning spanning Piaget's first three sensorimotor sub-stages and speculate the model could be adapted to achieve sub-stage four.

Michael Arbib embraces constructivist principles in his computational neuroscience and AI research. In (Arbib 1972) he writes, "The animal perceives its environment to the extent that it is prepared to interact with it. … Perception of an object generally involves the gaining of access to 'programs' for controlling interaction with the object, rather than simply generating a 'name' for the object." He argues that brain models and AI implementations should be distributed, action-oriented, and layered, and such models consist of perceptual and motor programs. Arbib's (1981) analysis of visuomotor coordination in frogs 35 Cunningham, closely following Piaget, summarized the 6 sub-stages as: (I) reflex exercise, beginning from birth, (II) primary circular reactions, beginning in second week, (III) secondary circular reactions, beginning in fourth month, (IV) familiar procedures in new situations, beginning in eight month, (V) active experimentation, beginning in eleventh month, (VI) mental recombinations, beginning in second year. 36 Circular reactions are like central pattern generators (CPGs), i.e., "biological neural circuits that produce rhythmic outputs in the absence of rhythmic input" (Wikipedia, https://en.wikipedia.org/wiki/Central_pattern_generator) and innate behavior patterns (Witkowski 1997). 37 Cunningham gives an example of a hand sucking behavior learned as a conjunction of a previously learned arm flexion element occurring simultaneously (initially by chance) with a previous sucking reflex element.

(Rana computatrix) motivates a proposal for assemblages of perceptual and motor schemas to constitute an "animal's internal representation of the world." Arbib and Hesse's (1986) "The Construction of Reality" influenced Arbib's view of cognitive models as EvoDevoSocio constructions (Arbib 2018), therein formulating social schemas as constructed realities that encode mental building blocks of societies. 38 Arbib (1989) updates (Arbib 1972) with "programs" rechristened as "schemas" and schema theory described in more detail. Arbib (1992) summarizes schema theory-noting historical precedents, key architectural elements, and experimental findings. Arbib (2018) provides more information about schema theory, including a discussion of Draper et al.'s (1989) schema implementation for the VISIONS system and collaborations with Corbacho on schema-based learning. Corbacho (1997) describes schema-learning mechanisms of tuning, construction, and active learning. Weitzenfeld et al. (1998) present a neural-based schema architecture that builds on Arbib's work and utilizes an abstract schema language to integrate neural networks into schemas. Corbacho (2019) specifies a self-constructive AI framework that constructs predictive schemas, dual (inverse model) schemas, and goal schemas-each embodying a different behavior and communicating using input ports, output ports, and variable mappings. Arbib (2021) crystallizes his earlier work summarizing schemas as interacting functional units organized as networks of basic motor schemas and perceptual schemas that are instantiated as multiple instances and activated cooperatively using bottom-up (data-driven) and top-down (task-driven) signals to elicit appropriate behaviors (e.g., object recognition, motor actions). Explicit executive control is not needed. New schemas may form as assemblages of old schemas, be adaptively tuned, and become primitives.

Joseph Becker (1973) details the JCM model for encoding experiential information. He provides an example of a schema 39 as [Sensation 1 -> Action 1 -> Action 2 => Sensation 2 ] where if Sensation 1 is sensed, Action 1 and Action 2 may be executed in sequence to elicit Sensation 2 . More generally, conditions (contexts) and actions on the left side of the Big Arrow (=>) result in (predict) sensations on the right side. Sensation and action elements, called kernels, are n-tuples of nodes representing features of the environment. The kernels on the left side of the Big Arrow constitute an antecedent event. Those on the right constitute a consequent event. Nodes are atomic primitives equivalent to concepts. The first node in a kernel indicates its "type" and the other nodes represent parameters associated with that type. Nodes are visualized as "nests" of two-way pointers linking schemas to each other, presumably one nest per concept. Witkowski (1997, pp. 51-53) describes modifications to JCM made in Mott's 1981 ALP system, including adding motivational kernels as a kind of intrinsic motivation for influencing agent goals by indicating conditions agents should seek (<HIGH>S) and avoid (<LOW>S) 40 . James Albus leveraged control theory, biology, neural networks, and more 41 to engineer hierarchical systems capable of learning from and reacting to the environment (Albus 2007). His theory of cerebellar function (Albus 1971) proposes how feedback loops between different types of cells in the cerebellum may coordinate motor commands with body positions. Albus et al. (1980) specifies a hierarchical control system consisting of functionally similar, interconnected modules each containing elements for sensory processing, predictive memory, and task decomposition capable of coordinating sensations and actions from raw sensory inputs through increasing levels of abstract behavior. A hierarchical factory control system is described with levels mapping to output signals, action primitives (e.g., velocity, position, force, torque), elemental moves (e.g., reach, grasp, move, release, insert, twist, lock, pull), simple tasks (e.g., fetch, mate, fasten), and finally complex tasks (e.g., assemble). A detailed outline for a theory of intelligence describing structural and process components (including learning mechanisms of repetition, reinforcement, and specific error correction) is presented in (Albus 1991). Subsequent multi-resolutional architectures consisting of similar hierarchies of repeating, interconnected, looping modules include a real-time control system (RCS) (Albus 1999), a 4-dimensional real-time control system (4D/RCS) (Albus and Barbera 2006), and a model of the human brain where "each cortical hypercolumn together with its underlying thalamic nuclei performs as a Cortical Computational Unit (CCU) consisting of a frame-like data structure (containing attributes, state, and pointers) plus the computational processes and mechanisms required to build and maintain it" (Albus 2008). The 4D/RCS was "designed to enable any level of intelligent behavior, up to and including human levels of performance in driving vehicles and coordinating tactical behaviors between autonomous air, ground, and amphibious vehicle systems" (Albus 2007). "At the lower echelons, the nodes generate goal-seeking reactive behavior. At higher echelons, they enable goal-defining deliberative behavior" (Albus and Barbera 2006).

William Powers' (1973) Perceptual Control Theory (PCT) 42 offers a constructivist AI framework based on control theory and the hypothesis that the purpose of behavior is to control perceptions. It posits a hierarchy of feedback loops similar to Piaget (1952), Cunningham (1972, and Albus (1980) 43 (and to back-propagation artificial neural networks and to other applications of control theory). He suggests "The entire hierarchy is organized around a single concept: control by means of adjusting reference signals for lower-order systems" (Powers 1973, p. 78). PCT treats agents as being completely self-contained control systems. Hierarchy levels span from intensity to sensation, configuration, transition, sequence, relationships, program control, principles, and system concepts (Vaniver 2015;Forssell 2016, p. 341). 44 Loops at the intensity level process input-output (IO) from sensors. Loops at the sensation level aggregate IOs from the intensity level. The hierarchy continues up through levels of increasing complexity and abstraction.

Ernst von Glasersfeld promoted radical constructivism-the principle that agents construct their reality (external world and selves) entirely through the interplay of sense data and motor signals (von Glasersfelds 1974). Von Glasersfeld (1984) describes radical constructivism as "a theory of knowledge in which knowledge does not reflect an 'objective' ontological reality, but exclusively an ordering and organization of a world constituted by our experience." Glasersfeld's main contributions to AI constructivism may be his interpretations and advocacy of the work of Piaget (von Glasersfeld 1974;von Glasersfeld 1982), Ceccato (von Glasersfeld 2001), Powers (Richards and von Glasersfeld 1979), and others. He was particularly aligned with Ceccato (1962), engaging in work on linguistics and machine translation that included the Multistore System (von Glasersfeld and Pisani 1970;von Glasersfeld 2001, p. 6). Multistore operationalized Ceccato's ideas by providing rapid matching of elements in service of correlational concept structures. Von Glasersfeld (1984, p. 12) likens assimilation to judging the sameness of objects and experiences due to shared attributes and he suggests accommodation occurs when attributes are identified that distinguish objects and experiences from one another. 45 He further notes the starting point for perception is when things are isolated as "bounded, unitary objects in the total field of … experience." Klahr and Wallace (1976) proposed a production system 46 for implementing an information-processing view of cognitive development inspired by Piaget and psychological experiments. The goal was to "formulate precise models of performance of the organism at two different levels of development, and then to formulate a mechanism for the transition or developmental mechanisms" (p. ix). They focused on the domain of quantitative comparison (QC)-building a series of models that progressively added and adapted production rules consistent with Piagetian staged development. Constituent concepts included class inclusion (CI), conservation of quantity (CON), and transitivity of quantity (TRAN), which emerge from basic productions (operators) of subitizing (Qs), counting (Qc), and estimating (Qe). In the complete model, productions and production systems representing values, attributes, objects, relations, and 42 Not to be confused with Kelly's Personal Construct Theory. 43 Albus and Powers do not appear to have collaborated. However, both published articles about their work in the June 1979 issue of Byte magazine where Albus (1979, p. 10) wrote "The brain is first and foremost a control system" and Powers (1979, p. 132): "The key concept behind this revolution [in understanding the nature of all living systems] is control theory." 44 Forssell (2016) provides a comprehensive summary of PCT. 45 Von Glasersfeld (1984) uses the terms elements, properties, and components rather than attributes. 46 Production systems contain rules of the form Conditions -> Actions where Conditions are percepts that trigger the associated Actions.

procedures accumulate in long-term memory and are processed in short-term memories when activated by sensory input or other productions. Schemas develop in order of consistent sequences, common sequences, individual rules, individual productions, production subsystems (operators), and production systems 47 . They are organized in a hierarchy of 3 tiers each containing multiple levels, which determine the search order of the productions. Higher tiered/leveled productions, which are more specific, are searched before lower ones, which are more general. Innate productions exist at every tier and provide the basic mechanisms for concept construction. They include productions for detecting consistent sequences, transforming common sequences into rules, doing low-level visual and audio encoding, and processing goals. The authors provide "crude starting point" proposals for detecting consistent sequences and transforming sequences into rules (pp. 204 -207) but such productions were not implemented. The implemented models relied on hand-coded productions. The BAIRN system described by Wallace et al. (1987) leveraged production system elements into an architecture further suited to constructivist learning. It represented knowledge (schemas) as a network of nodes in long-term memory, each representing a feature of the world using several production rules (i.e., definition list) and information about the node's connectivity within the network (p. 365, Fig. 8.1). Nodes are highly interconnected such that, "each element in the condition and action of a production is semantically defined at a node elsewhere in the network" (p. 363). Short-term memory structures are used for sensoriperceptual buffering and semantic processing. Adaptation occurs via processes of node creation, node combination, redundancy elimination, and node modification. Other innovations included "a limited amount of distributed parallel processing and an explicit treatment of consciousness, motivation and emotion" (p. 359) 48 . As in their previous work (Klahr and Wallace 1976), the QC domain was used to develop and test the system. Other ideas about using production systems for modeling (or implementing) constructivist systems, with closer ties to Piaget, are described by Richard Young (1973, 1974) and Margaret Boden (1978. Rodney Brooks' (1986) subsumption architecture may be characterized as having constructivist elements. Schemas correspond to Brooks' finite state machines (implemented as LISP modules) that exchange short messages and are connected in a hierarchy of levels of competence. Adaptation is supported by suppression and inhibition signals that allow modules at different levels to override other modules' inputs and outputs. Brooks' approach has a nativist character with modules custom-engineered for specific functions 49 . Eight levels of competence suggest staged development-with the lower levels "built" prior to, and supporting, the upper ones. Brooks' (1986, p. 16) levels are: 0) Avoid contact with objects (whether the objects move or are stationary).

1) Wander aimlessly around without hitting things.

2) "Explore" the world by seeing places in the distance that look reachable and heading for them.

3) Build a map of the environment and plan routes from one place to another. 4) Notice changes in the "static" environment.

5) Reason about the world in terms of identifiable objects and perform tasks related to certain objects.

6) Formulate and execute plans that involve changing the state of the world in some desirable way.

7) Reason about the behavior of objects in the world and modify plans accordingly.

Wei-Min Shen (1989Shen ( , 1994 articulates constructivist AI principles in his work on autonomous learning from the environment. Shen (1989) defines learning as "the process of inferring the laws of the environment that allow the learner to solve problems." Shen (1994) states, "Intelligent behavior of any creature, animals or machines alike, is ultimately rooted in its physical abilities to perceive and act in its environment … Every concept or idea of [the] system must eventually have meaning in terms of [its] actions and percepts." He formalizes such systems as consisting of model applicator and model abstractor algorithms under control of an integration loop. The applicator selects actions based on agent goals and predicts new environmental states based on the system's internal (mental) models. The abstractor constructs and revises the models as needed. More generally, models are expressed as a six-tuple (A,P,S,φ,θ,t) where "A is the set of basic actions, P is the set of percepts, S is a set of model states (the internal representation of experience), φ is a state transition function S × A → S that maps a state and an action to the next state, θ is an appearance function that maps states to observations S → 2P (2P denotes the power set of P), and t is the current model state of M." Models are built using m-constructors (e.g., =, ∧, ∃, +, *). Percepts can be numeric values, objects, features, functions, or relations. Environments are viewed as black boxes represented by triples (Σ, ρ, ∆), where "Σ is a set of inputs, ∆ is a set of outputs, and ρ is the environmental mapping function that governs the mapping from the current input to the output." Environments have their own internal logic and can be manipulated by multiple agents.

After discussing various types of environments, models, and learning techniques, Shen (1994) describes the LIVE system that implements the algorithm:

Repeat 1 Generate a new goal or a new experiment (based on the current model); 2

While the goal or experiment is not accomplished: 3

Generate a prediction sequence for achieving the goals or experiment, 4

Execute the actions in the prediction sequence, 5

Perceive information from the environment, 6

If there is a prediction failure, 7 then find the difference between a success and the failure, 8

If some difference is found, 9

then call CDL to improve the current model, 10 else call CDL+1-like algorithms to create new features or variables.

The CDL (complementary discrimination learning) algorithm learns by modifying previously learned models when actions yield perceptions that do not match model predictions. Shen calls CDL a predictsurprise-identify-revise procedure-anticipating "surprise" as a trigger for making model adjustment in subsequent work such as ( Barto et al. 2004;Ranasinghe and Shen 2008;Schmidhuber 2010;Faraji et al. 2016). CDL is shown to learn Boolean concepts, decision lists, prediction rules, and finite automata. The main data structures in LIVE are prediction rules that map percepts and actions to changes in the environment. Each rule includes a summary of environmental conditions for a particular state (i.e., percepts), an action the system can take, the predicted change in the environment resulting from the action, and a sibling rule 50 . The rules are characterized by Shen as "c-a-p production rules with three components: conditions, actions, and prediction." CDL learns conjunctive and disjunctive concepts in an incremental manner via complementary discrimination, which performs rule generalization and specialization concurrently using rules and their logical complements. The CDL+1 component can create new features (i.e., rule terms) "that are beyond the scope of the initial perception description language." 51 LIVE environments explored in (Shen 1989) include a hidden-rule Tower of Hanoi environment, child development Balance Beam experiments, and Mendel's pea-hybridization experiments where the system showed "some encouraging results" in each case.

Building on their previous work in psychology and neurobiology (Quartz 1993;Quartz and Sejnowski 1994), Quartz and Sejnowski (1997) summarize evidence for neural constructivism, which enables constructive learning to occur in brains whereby "the representational properties of cortex are built [progressively] by the nature of the problem domain confronting it." This allows learning to occur in animals through interactions with external environments while not overly relying on innate, specialized, evolutionarily programmed circuits as suggested by nativist and selectionist theories. Their main arguments focus on brain structure changes that occur during cognitive skill acquisition, specifically: changes in synaptic numbers, axonal arborization, and dendritic arborization. Other evidence cited for neural constructivism includes: extensive and protracted postnatal cortical development (occurring well beyond the first two years of life in humans), environmental effects on ocular dominance column development, learning-theoretic models supporting effective incremental learning over time (e.g., Leslie Valiant's PAC), the metabolic efficiency of generating brain structure "as needed" versus retracting unnecessary structure, and neural plasticity in adults (p. 581). Their descriptions of neural constructivism share many characteristics with machine learning practice such as features, feature spaces, clustering, correlated activity, sampling mechanisms, and hierarchical representations-affording potential insights into AI structures and algorithms. Algorithmically, Quartz and Sejnowski (1997, p. 553) suggest: "The general strategy of constructivist learning is this. Rather than start with a large network as a guess about the class of target concepts, avoid the difficulties associated with overparameterized networks by starting with a small network. The learning algorithm then adds appropriate structure according to some performance criterion and where it is required until a desired error rate is achieved." 52 Further discussion about neural constructivism can be found in ).

Mark Ring (1994) introduces and explores continual learning, which focuses on constructivist principles of hierarchical development, unlimited behavior duration, intelligent behavior acquisition, incremental learning, and autonomous behavior. Temporal Transition Hierarchies (TTH) are described which are two-layer neural networks that automatically learn a probabilistic hierarchy of events (sensation-action sequences) based on actions taken by an autonomous agent exploring an environment. Primitive units representing atomic sensations and actions can be combined into sequences of sensations and actions to form higher-level units that are incrementally added to the network. Connection weights between units are adjusted to account for different contexts experienced by the agent. The system is evaluated using environments consisting of simple mazes, the Reber grammar, and the Mozer "gap" task. An agent capable of Continual, Hierarchical, Incremental Learning and Development (CHILD) is introduced that combines TTH with Q-learning. In (Ring 2011), Recurrent Transition Hierarchies (RTHs) are introduced as an improvement over TTH that add recurrent connections to the network to allow an agent to continually learn arbitrary temporal contingencies. Schaul and Ring (2013), show General Value Functions (GVFs) (aka "forecasts"), which are extensions of Sutton's options framework , are particularly effective constructivist learning algorithms, superior to Predictive State Representations (PSRs), Temporal Difference (TD) Networks, and TTH with regard to generalization and other properties desirable for continual learning. 51 Shen points out that new features must be present when existing features cannot discriminate between distinct outcomes (e.g., when different classifications are made despite all existing feature values being the same). Such creation of new features is sometimes called constructive induction, automatic feature discovery/engineering/generation or discovering hidden features-essentially what artificial neural networks do by default. 52 They cite the following "impressive work" on constructivist learners: Azimi-Sadjadi et al. (1993), Fahlman & Lebiere (1990), Frean (1990), Hirose et al. (1991), Kadirkamanathan & Niranjan (1993), Platt (1991), Shin & Ghosh (1995), Shultz et al. (1994), and Wynne-Jones (1993). Subject methods include Cascade-Correlation (CasCor), the upstart algorithm, RAN/GaRBF networks, Ridge Polynomial Networks, and node splitting. Foner and Maes (1994) extend Drescher (1991) to make schema formation more efficient using focus of attention mechanisms. One mechanism, perceptual selectivity, "restricts the set of sensor data the agent attends to at a particular instant." Another, cognitive selectivity, "restricts the set of internal structures that is updated at a particular instant." Perceptual selectivity relies on spatial and temporal coherence to prune out non-causal inputs. Cognitive selectivity relies on context and goals to prune inapplicable schemas ("facts").

Work by Cangelosi, Schlesinger, and colleagues from their developmental robotics perspective includes Schlesinger (1994) on neural constructivism; Cangelosi and Parisi (1998) (2020) on computational models of development classified as connectionist, dynamic field theory-based, rule-based, and Bayesian. In addition to SOMs per , they used Recurrent Neural Networks (esp. Jordan Networks) to integrate linguistic, visual, and proprioceptive inputs for grounded concept learning Stramandinoli et al. 2017). Cangelosi and Schlesinger's (2015) book on developmental robotics is a rich source of information about constructivist AI that describes work in developmental psychology that can inform agent development. Six "experiment-focused" chapters look at relevant psychological models and experiments grouped into topics of: novelty, curiosity, and surprise; perceptual development; motor development; social learning; language; and abstract knowledge. Appendix A herein summarizes topics, keywords, and references covered in that book.

Sandra Marshall (1995), inspired by the psychology of Bartlett (1932) and of Piaget, and the AI formalisms of Rumelhart, Minsky, and Schank (i.e., schemas, frames, and scripts), focuses on schemas, which she defines as:

A vehicle of memory, allowing organization of an individual's similar experiences in such a way that the individual • can easily recognize additional experiences that are also similar, discriminating between these and ones that are dissimilar; • can access a generic framework that contains the essential elements of all of these similar experiences, including verbal and nonverbal components; • can draw inferences, make estimates, create goals, and develop plans using the framework; and • can utilize skills, procedures, or rules as needed when faced with a problem for which this particular framework is relevant. (Marshall SP 1995, p. 39) Accordingly, each schema contains four types of knowledge: identification knowledge, elaboration knowledge, planning knowledge, and execution knowledge. Marshall SP (1995, pp. 377 -390) presents a hybrid model where a schema consists of one connectionist network and three production systems 55 . 53 This work explores the idea that assimilation and adaptation of motion schemas (i.e., "movement primitives") can progressively build a repertoire of sophisticated motor abilities. Degrees of freedom of motion become enabled gradually (or are "frozen") to limit the search space and develop schemas suitable for chaining. 54 They also discuss using Echo State Networks as dynamic reservoirs in ERA units to better address temporal and nonlinear relationships. 55 It is instructive to note similarities between Marshall SP (1995) and Klahr and Wallace (1976). Both describe hybrid models that use production system and connectionist elements. Both were strongly influenced by Piaget and developmental psychology literature and focused on arithmetic concept domains.

Identification knowledge uses a neural net classifier (the connectionist network) 56 to recognize the type of experience (problem or situation) at hand. Once recognized, relevant input from the environment is parsed into clause encodings containing information-like owner, object, and time-appropriate for executing rules contained in the production systems. The four components are connected via a blackboard where inputs, outputs, and queries are shared to allow situations to be parsed, evaluated, and action taken using knowledge specific to each schema. The identification network can iterate on current situation data to refine the assessment of the best matching situation, thus determining which productions are activated. Beyond suggesting that identification networks can be learned using backward propagation, Marshall does not address schema learning (adaptation). Production system components were manually programmed to handle the elaboration, planning, and execution appropriate for each schema. Marshall alludes to staged development in describing a hierarchy of levels progressing from microfeatures, to single knowledge components, to a full schema, to collections of schemas (p. 392).

Mark Witkowski, working with Bond and Mott (1981), leveraged Becker's (1973) constructive approach in developing the Mark IV Robot. Witkowski (1997) proposes a Dynamic Expectancy Model (DEM) that provides "a novel form of learning by reinforcement," which uses expectancies (predictions, micro-or μhypotheses) to control agent learning via μ-experiments. Influenced by animal behavior literature, the DEM accounts for both innate and learned capabilities. Witkowski (1997), particularly inspired by Tolman (1932Tolman ( , 1948 and MacCorquodale and Meehl (1953), builds on the implementations of Becker (1973), Bond and Mott (1981), and Drescher (1991). DEM processing is described as "a low level version of a scientific discovery process" (Witkowski 1997, p. 58)-reminiscent of Kelly (1955) and Shen (1984). μ-hypotheses are the basic units of learning (i.e., schemas). They are reinforced or extinguished over time based on the success or failure of their predictions. Sensory inputs are processed into tokens, which are incorporated into constructs called signs and sign sets. Internal symbols can cause the output of actions and compound actions. Adaptation processes include creation, corroboration, reinforcement, differentiation, and forgetting of μ-hypotheses. The model was implemented using the SRS/E algorithm, which generated Dynamic Policy Maps (DPMs) and operated similarly to Sutton's (1990) Dyna-Q. SRS/E stands for "Stimulus-Response-Stimulus/Expectancy" to reflect the key elements of each μhypothesis: the current state or context (Sign1) of the agent, an action (Response1) the agent can take, and a consequent state (Sign2) resulting from the action. Schemas are encoded using seven interrelated lists comprising: input tokens, signs denoting environmental states, responses, behaviors, goals, hypotheses, and predictions. The hypothesis list is used to construct DPMs. The lists are initialized to reflect the agent's innate capabilities (i.e., the ethogram) (Witkowski 1997, p. 57) and are continually adjusted thereafter to account for learning and other changes to the agent. SRS/E was shown to perform well on latent learning and place learning tasks. Witkowski (2007) proposes an action-selection calculus specifying three ways states can be connected to actions; five rules for how actions, signs, and predictions are updated; and four rules for how learning occurs. It claims to unify the five classic learning theories: stimulus-response behaviorism, associationism, classical conditioning, operant conditioning, and Tolman's sign-learning model.

Daniel Wolpert and colleagues focused on biological motor control and motor learning. Wolpert et al. (1995) present a Kalman filter model consistent with cerebellar function that combines a forward model that predicts motor states with a sensory output model that predicts sensory feedback and together reliably estimate the effects of motor commands.  examine various cerebellar learning models and conclude, "The cerebellum contains multiple pairs of corresponding forward and inverse models 57 , each instantiated within a microzone 58 ". The modules (schemas) also include a responsibility 56 The neural net was a 3-layer feedforward network with 27 input nodes, 14 hidden units, and 5 output nodes. Each problem was coded as 27 binary features used to classify 5 arithmetic problem types: Change, Group, Compare, Restate, Vary. The clause encodings and rules for the production systems were engineered for this domain. 57 Forward models "mimic the causal flow of a process by predicting its next state (for example, position and velocity) given the current state and the motor command." Inverse models "invert the causal flow by estimating the motor command that caused a particular state transition." (Wolpert et al. 1995) 58 Microzones are attributed to be the basic functional units of the cerebellum (Oscarsson 1979; De Zeeuw 2021).

detector that works in concert with the forward model to coordinate appropriate activation of multiple modules for effecting composite behaviors. Wolpert et al. (2011) summarize components, processes, and representations suitable for motor learning. Components determine how information extraction from the environment occurs (e.g., what elements are fixated on versus filtered out, how processing delays and noise are accounted for), what decisions and strategies are appropriate for executing given tasks (i.e., resolving interactions between sensorimotor, perceptual, and cognitive components), and how different classes of control contribute to generating appropriate motion sequences (i.e., predictive control, reactive control, and biomechanical control). Processes enabling motor learning include error-based learning (i.e., dynamically correcting for mismatches between goal states and actual states), reinforcement learning (e.g., using reward signals to drive actions), use-dependent learning (i.e., habituation), and observational learning (i.e., learning by observing others). Representations suitable for motor learning are characterized as being mechanistic or normative models. The former tend to be built from motor primitives (primitive schemas), which combine together using generalization functions. The latter tend to rely on credit assignment mechanisms (e.g., Bayesian analysis) to calculate how multiple underlying causes determine actions. McNamee and Wolpert (2019) provide a unifying account on how the brain may employ internal models for motor control using Bayesian inference and optimal feedback control. (1998), Moore (1989, 1997), and others to develop robots capable of learning motor behaviors using imitation and social perception. Demiris and Hayes (1996) present a biologically inspired architecture for imitative learning consisting of modules for visual preprocessing, proprioceptive analysis, relationship establishment, movement analysis, and movement matching. Per the architecture, an imitator visually collects posture data from a demonstrator and proprioceptively reproduces the motions it perceives in itself. Demiris and Hayes (2002) present a modular, dual-route architecture for motion learning that combines active and passive imitation. Each module, operating in parallel, pairs a previously learned behavior (inverse model) with a forward model to attempt to match demonstrated behaviors. The forward models simulate (imagine) the demonstrated behavior, predict the next observed states, and generate an error signal to indicate how well the actual next states matches the prediction. Errors accrue as a confidence factor for each behavior, which enables the imitator to determine the best-matching behavior. If no demonstrated behavior is matched with high confidence, a new schema is generated via passive imitation as described in (Demiris and Hayes 1996). The architecture was tested using simulated robots performing arm movements conforming to the international standard semaphore code. 59 Demiris and Khadhouri's (2006) HAMMER architecture arranges the modules (schemas) from (Demiris and Hayes 2002) into distributed hierarchies to enable complex and abstract behaviors to arise from more primitive behaviors. It relies on a top-down control of attention mechanism to determine what state information to collect from the environment that is appropriate for each schema. The forward model components determine what information is required to run the forward model simulations and that data is then used to drive the inverse model components. Experiments were conducted where an imitator perceived an action performed by a demonstrator and executed the best matching behavior from a set of eight previously programmed behaviors. Behaviors (forward models), represented as Baysian networks, can be learned using motor babbling as described in .


## Yiannis Demiris leveraged Wolpert and Kawato

Joshua Tenenbaum (1999) proposes a Bayesian framework for concept learning that supports learning from few or many examples, thus uniting similarity-and rule-oriented generalization 60 . It represents early work using Bayesian methods to understand human intelligence and build intelligent machines. Kemp and Tenenbaum (2008) describe a Bayesian model that discovers forms and structures for representing environmental data. They promote the view that different knowledge representations (schemas/models) are needed for different types of knowledge. Learnable forms include partitions, chains, orders, rings, hierarchies, trees, grids, and cylinders. Tenenbaum et al. (2011) discuss how "abstract knowledge encoded in a probabilistic generative model" can serve to constrain a hierarchy of models to more quickly achieve learning and induction. The authors suggest Hierarchical Bayesian models may be able to learn framework theories in key domains like intuitive physics, psychology, and biology, and lead to an answer to the (constructivist) question: "How can domain-general mechanisms of learning and representation build domain-specific systems of knowledge?" Ullman and Tenenbaum (2020) argue for harmonizing cognitive development and computational modeling to answer key questions underpinning constructivist AI. They discuss how hierarchical Bayesian models can account for learning in infancy and childhood by leveraging core knowledge about objects, agents, space, and time in infancy and building intuitive theories during childhood. They suggest implementing knowledge and theories as probabilistic generative programs. Like Kelly (1995), Shen (1989), and Witkowski (1997), they liken learning to naïve science: a (Bayesian) process where an agent hypothesizes representations (models) of the environment that are then assessed, refined-and maybe discarded-over time. They introduce a "child as hacker" metaphor likening learning agents to software developers, discussed in (Rule et al. 2020). Although Tenenbaum might balk at being called a constructivist 61 , his approach is aligned with AI constructivism and draws heavily on cognitive and developmental psychology research.

Juyang  promoted AI constructivism as a "new field" called Autonomous Cognitive Development citing Weng et al.'s (1999) robotic Self-organizing, Autonomous, Incremental Learner (SAIL) as a prototype embodying key constructivist principles. SAIL was engineered to learn representations and architectures through self-exploration and human teaching, enabling the robot to autonomously navigate unknown, unconstrained environments and to recognize and reach for objects. Motor movements were learned primarily by a trainer physically manipulating the robot to associate sensory input states with appropriate motor outputs. External reinforcement by human trainers pressing "good" or "bad" buttons and intrinsic reinforcement provided through a value system were also used (Huang and Weng 2002). Agent state consisted of sensor readings recursively convolved with resampled versions of themselves to account for different temporal contexts. These states were mapped to motor values using an Incremental Hierarchical Discriminating Regression (IHDR) tree algorithm Weng and Hwang 2007). IHDR is claimed to unify classification and regression 62 and (1) Handle high dimensional inputs, (2) Perform one-shot learning, (3) Dynamically adapt to increasing complexity, (4) Avoid getting stuck in local minima, (5) Operate incrementally, (6) Effectively maintain long term memory, and (7) Is suitable for real-time operation (W&H 2007, p. 3). IHDR maintains clusters of inputs (x-clusters) linked to associated outputs (y-clusters) at nodes of an oblique decision tree. 63 For each input-output sample (x i , y i ), y i is used to find the closest y-cluster via Euclidean distance. The identified y-cluster indicates which x-cluster sample (x i , y i ) belongs to. x i and y i are then used to update the statistics of their corresponding clusters. (If a y i value is not provided, the x i vector is used to find the "best" y to output from a tree leaf.) Child nodes are spawned (or searched) when finer granularity in input-output mapping is required as indicated by the statistical match of the current sample to each xcluster. Discriminating feature subspaces are calculated using the centers of x-clusters to determine which child nodes should be searched-thus focusing on the most discriminating features in x i for the current sample. IHDR is claimed to model the brain's associative cortex (i.e., the area between the primary sensory cortex and motor cortex) wherein layers represent different cortical layers, nodes represent cortical patches, and clusters represent neurons (W&H 2007, p. 24).

IHDR trees may be construed as schemas, with node levels corresponding to stages of development and x-and y-cluster constructs within nodes providing fine-grained structure. The learning (adaptation) algorithms are provided by eight procedures detailed in (W&H 2007). Schemas (trees) are further organized into levels where the lowest level encodes innate behaviors (e.g., visual motion detection and tracking). Such schemas can be learned offline using IHDR operating as a "prenatal learning process." Higher-level schemas incorporate progressively more temporal context and are learned (online) through interaction with the environment. Learned behaviors have priority over innate behaviors and are overridden by innate behaviors if an adequate learned behavior does not exist. (In general, the behavior having the highest confidence of being correct is executed.) In a more comprehensive architecture, Weng and Hwang (2006, Fig 4) describe stackable modules consisting of a sensor-to-effector mapper, stored context prototypes, a value controller, an attention selector, a motor mapper, and a delay mapper.  (2002) presents a neural schema mechanism to transform Drescher's (1991) constructivist system into more of a connectionist network. The mechanism defines item nodes to represent states of the environment, action nodes to represent actions that can be taken by the agent, schema nodes to specify relationships between items and actions, and goal nodes to control node activations. Nodes are connected using context links, result links, action links, goal links, host links, and none links. Unlike typical neural networks, node activations depend on the node and link types, e.g., link weights are determined by values of relevance, reliability, correlation, and desirability. Schema nodes maintain statistics for determining which actions to select and control production of new nodes (i.e., spin-off schemas, accommodation). An agent is said to be "conscious" of nodes that exceed a certain level of activation. "Conscious broadcasts" cause nodes related to those currently in the "spotlight" to increase activation potentials, which increase chances they cause an action to be selected so "an agent can discover new paths to a solution or goal state." McCauley implements and evaluates the system using Russell and Norvig's (1995) Wumpus World.

Jeff Hawkins (2004) does not focus on childhood development nor cite Piaget but subscribes to constructivist principles in his efforts to build intelligent machines:

• "The senses create patterns that are sent to the cortex, and processed by the same cortical algorithm to create a model of the world (p. 44)."

• "When you are born, your cortex essentially doesn't know anything. … All this information, the structure of the world, has to be learned (p. 111)."

• " [We] have to train the memory system much as we teach children. Over repetitive training sessions, our intelligent machine will build a model of its world as seen through its senses (p. 141)."

Persistent themes in Hawkins' work include a focus on the human neocortex as the seat of intelligence (Hawkins 2004), sequence learning and prediction as keys to cognition (Hawkins 2004;Hawkins and Ahmad 2016), cortical columns running a common algorithm as the essential processing units (Hawkins 2004;Hawkins et al. 2017b), use of sparse distributed representations for information coding and processing (Hawkins 2004;Ahmad and Scheinkman 2019;Numenta 2021a), and utilizing world models and reference frames for constructing intelligent agents (e.g., grid cells and allocentric representations) (Lewis et al. 2019; Klukas et al. 2020;Hawkins 2021;Lewis 2021).

Hawkins ' (2004) memory-prediction framework proposes a hierarchical auto-associative memory that stores sensorimotor sequences using invariant feature representations. That memory is used to predict what occurs next in newly encountered sequences. Signals flow up and down sensorimotor hierarchies to affect pattern learning, recognition, and behavior 64 . The basic learning functions are identified as classification formation and sensorimotor sequence construction and are roughly mapped to the mammalian cortex, hippocampus, and thalamus. Hawkins provides examples of human learning and suggests how the model may accommodate them, including visual saccades and fixation, language and music understanding, memory, environment navigation, and sensorimotor control of various forms. In young brains, Hawkins suggests memories are stored higher up in the cortical hierarchy and are thus slower to react than mature brains since "it takes time for the neural signals to travel up and down." He further notes young brains have "not yet formed complex sequences at the top and therefore cannot recognize and play back complex patterns." As the brain gains experience, it re-forms memory representations further down in the hierarchy which "frees up the top for learning more subtle, more complex relationships."

The memory-prediction framework was implemented as the Hierarchical Temporal Memory (HTM) model (Wikipedia, Memory-prediction framework; Hawkins et al. 2017a;Hole and Ahmad 2021). The first generation focused on spatial and temporal pooling of input patterns for learning, and probabilistic pattern matching for inference. Cortical learning algorithms (CLAs) formed the core of secondgeneration HTM implementations. CLAs more closely modeled layers and mini-columns of the cerebral cortex, accounting for the formation and decay of synapses. Key elements of this generation of HTM included sparse distributed representations (SDRs) 65 , a spatial pooling algorithm, and a sequence memory algorithm. A later generation of HTMs added a theory of sensorimotor inference that proposed "cortical columns at every level of the hierarchy can learn complete models of objects over time and features are learned at specific locations on objects" (Wikipedia, Hierarchical temporal memory). HTMs utilize sensorimotor feedback signals, feed forward signals, and context signals. Hawkins notes HTM networks need not integrate motor control-rather, they can learn to predict changes in the environment from sensory sequences occurring in the environment independently of any actions by the sensing agent. The latest incarnation of the work-the Thousand Brains Theory-posits "the brain uses maplike structures to build a model of the world-not just one model, but tens of thousands of models of everything we know" (Numenta 2021b).

Kristinn Thorisson (2012) takes a system-level view of AI constructivism, deprecating what he calls constructionism in favor of constructivism. The former is characterized as "systems whose gross architecture is mostly designed from the top-down and programmed by hand." He claims to take Drescher (1989) a step further by requiring an AGI architecture automatically grows from seeds and takes into account factors of "temporal grounding, feedback loops, pan-architectural pattern matching, small whitebox components, and architecture meta-programming and integration" (Thorisson 2012, pp. 160-161). Key elements of Thorisson's view were implemented in the Autocatalytic Endogenous Reflective Architecture (AERA) (Nivel et al. 2013;Nivel et al. 2014a). In AERA, schemas (models) consist of left-hand (LH) patterns, right-hand (RH) patterns, and guard equations. LH patterns are said to predict (also produce or cause) associated RH patterns. Patterns consist of sets of features (facts, states, concepts) sensed from or acting upon the environment. For example, an LH pattern might be ("A is_bus", "A has_color yellow", "A bears_number 19", "A bears_license_plate_number SX445") and an associated RH pattern might be ("A stops_at city_university") 66 . Guard equations assign values to variables between RH and 64 Roughly, expectation signals flow down the hierarchy and are compared with sensorimotor signals that flow up. 65 SDRs are the main knowledge representations in the HTM model. They are large sparse binary vectors where each bit, corresponding to a different neuron, represents a different learned feature. SDRs with similar bit patterns are semantically similar. "HTM theory defines how to create, store, and recall SDRs and sequences of SDRs." 66 This example was paraphrased from (Nivel 2013, p. 13). In (Nivel et al. 2013, p. 33 LH patterns based on the kind of reasoning being done. Deductive reasoning from causes (LH) to predictions (RH) uses forward chaining. Abductive reasoning from goals (RH) to causes (LH) uses backward chaining (Nivel et al. 2013, p. 14). Both occur simultaneously. The LH-RH schema structure is also used to represent discrete facts known by the agent. Some schemas are innate 67 but most are learned and are retained if they make successful predictions (confirmed from acting on the environment). Nivel et al. (2013, p. 24) write, "Model acquisition is triggered by either the unpredicted success of a goal or the failure of a prediction." Piagetian-like assimilation and accommodation (abstraction) is supported whereby "a new model is copied from the original model and differences between values held by the conflicting evidences are represented by variables introduced in the new model" (Nivel et al. 2013, p. 20). Sequences of schemas are chained to form more complex schemas and can be "compressed" to form more compact schemas. An executive program provides the inference engine that computes predictions and goals, creates and manages models, focuses attention, manages resources, and performs other functions. Promising results were achieved in experiments where an AI called S1 learned conversational speech and body movements by observing humans (Nivel et al. 2013, pp. 35-51). The initial AERA incarnation relied on learning by observation. Michael S. P. Miller (2013a, 2013b draws directly on Piaget's later work (Piaget 1977(Piaget , 1985 in specifying his Piagetian Modeler (a.k.a. Piagetian Autonomous Modeler). Piaget-defined processes of observation, coordination, reflection, and consolidation comprise the Piagetian Modeler's main functional units. Each unit (pattern) is decomposed into subpatterns-yielding a full-featured cognitive architecture consisting of many diverse specialized modules. Schemas are networks of memory elements called neural propositions organized collaterally and hierarchically to encode models of the world. Biologically, Miller claims elements of a neural proposition map to the axon, soma, and dendrites of a neuron. Logically, neural propositions are "cognitive containers" called schemes (also coordinations) that are affirmed or negated using markers and have 1 to n links to other schemes 68 . Scheme types include internal, external, and inference schemes. Internal and external schemes represent (link to) internal and external observables at the lowest level of the cognitive hierarchy, i.e., propriocepts and exterocepts respectively. Inference schemes link to internal and external schemes and to other inference schemes at increasingly higher levels of the hierarchy (also forming sequences). Each inference scheme represents a feature, action, event, situation, episode, concept, hypothesis, goal, or other mental element learned by the agent. Miller operationalizes other terminology from Piaget including subsystems 69 , actions, circular reactions, operations, groups, and totality. Schemas are learned through assimilation and accommodation acting upon schemes. Implementation details and experimental results are forthcoming.

Maria Hedblom and collaborators (Hedblom et al. 2015;Hedblom 2018) formalized Lakoff-Johnson image schemas as families (sets) of interlinked theories that could be used for constructing new concepts via conceptual blending (Fauconnier and Turner 1998) and for facilitating symbol grounding. In (Hedblom et al. 2015) they use the DOL language of Mossakowski et al. (2013) 70 and Common Logic (ISO/IEC 24707) for encoding image schemas-leveraging formal ontologies to represent agent knowledge. They focus on schemas related to path following and containment and show how low-level schemas like MOVEMENT_OF_OBJECT, MOVEMENT_ALONG_PATH, MOVE-MENT_IN_LOOPS, REVOLVING_MOVEMENT, and CLOSED_PATH_MOVEMENT can combine and specialize through the addition of features (spatial primitives) like PATH, START_PATH, END_PATH, FOCAL_POINT, and LANDMARK (Hedblom et al. 2015, Fig. 2). Primitive schemas were hand coded, not learned. Concept construction (learning) was investigated as a higher-level blending of schemas. A Common Logic sample for encoding the MOVEMENT_OF_OBJECT schema is:  o))))) 71 Hedblom et al. (2015) describe how image schemas related to path following can lead to concepts like "stream of consciousness," "train of thought," and "line of reasoning" using conceptual blending. They show how the concept THRILLER can emerge from concepts of STORY and ROLLER_COASTER which both share aspects of the more primitive schema SOURCE_PATH_GOAL. In (Hedblom 2018), a Two-Object schema family is presented that encompasses schemas CONTACT, SUPPORT, and LINK, which inherit from schemas VERTICALITY and ATTRACTION. The Image Schema Logic (ISL FOL ) language is introduced for representing image schemas, which leverages Region Connection Calculus (RCC) 72 , Qualitative Trajectory Calculus, and Linear Temporal Logic. Hedblom et al. (2021) suggest ISL FOL may be used to improve robot performance in unfamiliar environments by facilitating reasoning about functional relations, enabling reasoning about alternatives to a plan, increasing adaptability through analogy, and improving natural language understanding. Examples of ISL FOL for encoding MOVEMENT_OF_OBJECT and MOVEMENT_ALONG_PATH schemas from (Hedblom 2018) are: Aguilar andPerez y Perez (2015, 2017), working in the field of computational creativity, present a computational model called Developmental Engagement-Reflection (Dev E-R) that approximates Piaget's assimilation and accommodation processes. In (Aguilar and Perez y Perez 2015), they model visual development for a simple agent in a virtual 3D world. Endowed with monocular color vision and an ability to move its head in 9 front-facing directions, the agent develops the ability to recognize a multitude of color and size concepts from an initial capacity to recognize 3 color luminosities (red, green, blue) and 2 sizes (big and small). Learning occurs through repeated exposures to objects in the environment. In the case of colors, a count of each primitive color feature is incremented each time the feature is observed. The color is recognized as a salient feature when it reaches a threshold count. That feature is then used as the basis for recognizing new colors by distinguishing (and counting) lighter and darker versions observed in the environment. A similar process generates size concepts. Starting with recognizing a distinction between big (B) and small (S) stimuli, and counting such occurrences, finer grain size features emerge based on repeated exposure to new size stimuli (e.g., B2, B3, S2, S3). Object recognition emerges by biasing the agent to attend to stimuli that move, have bright colors, are novel, and are otherwise affective, i.e., elicit pleasure, displeasure, surprise, or cognitive curiosity.
∀O:Object �(MOVEMENT_OF_OBJECT(O) ↔ Move(O))� ∀O:Object, ∀P:Path (MOVEMENT_ALONG_PATH(O, P) ↔ Move(O) ∧ CONTACT(O, P) U(¬(Move(O) ∨ CONTACT(O, P))))
Once created, features are available for agent contexts and schemas. Contexts are memory structures containing: (1) features of the object at the current center of attention of the agent, (2) affective responses associated with the object, and (3) the agent's current expectations for feature change (if the context is a current-context). Schemas are either basic or developed. Basic schemas encode innate behaviors using context and associated action elements. Developed schemas encode behaviors learned through environmental interaction. They have the same structure as basic schemas but add an expected context element. The engagement-reflection process creates and maintains schemas. Engagement attempts to match cur-71 Note this schema uses OBJECT, MOVEMENT, and HAS_TRAJECTOR primitives. 72 RCC defines 8 relationships between spatial regions: disconnected (DC), externally connected (EC), equal (EQ), partially overlapping (PO), tangential proper part (TPP), tangential proper part inverse (TPPi), non-tangential proper part (NTPP), and non-tangential proper part inverse (NTPPi). rent contexts with contexts in stored schemas. If a suitable match is found and the associated action defined in the schema generates the expected result, the agent is in cognitive equilibrium and the selected schema is considered stable. If a suitable context match is not found, the agent is considered to be in disequilibrium and a reflection (accommodation) process occurs using generalization or differentiation to modify an existing schema or create new ones. Schemas are distinguished by how many specific (instantiated) context features they have. Those with more instantiated features are more concrete. Those with fewer instantiated features are more general. Schemas were generated that allowed an agent to attend to pleasurable objects in its environment. Aguilar and Perez y Perez (2017) extend the system to include tactile capabilities, i.e., hand movements, grasping, and touch sensing of object contact and textures. 73 They report that the agent learned schemas that allowed it to visually follow its own hand movements and coordinate reactions to visual and tactile stimuli. Unsupervised Representation Learning (CURL) that learns tasks (concepts) without task or class labels using a mixture-of-Gaussians latent space, dynamic expansion, and mixture regenerative replay; Groth et al. (2021) on SelMo-a (self-motivated) system that acquires and retains skills through optimized, curiosity-based, off-policy exploration of its environment; and Jaegle et al. (2021) on Perceiver IO which adds a cross-attention mechanism to the Perceiver (Transformers) model to produce a system that scales linearly with multiple inputs (e.g., images, audio, natural language) and multiple outputs (e.g., text prediction, image classification, optical flow fields, audiovisual sequences) and may hold promise as a general purpose neural network architecture. Piloto et al. (2022) present the PLATO model (for Physics Learning through Auto-encoding and Tracking Objects) that learns the intuitive physics concepts of solidity, object persistence, continuity, unchangeableness, and directional inertia from synthetic video data.

Constructivist-oriented work by Vicarious 74 includes:  and Vicarious (2017a) describe Schema Networks, inspired by Drescher (1991), which learn causal relationships and reusable concepts from sensory data. Schema Networks rely on object instances (entities) and associated attributes extracted from videos to predict attribute changes due to environmental actions. Schemas consist of entity-attribute and action variables logically connected to future entity-attribute states 75 . Multiple schemas are combined into a Schema Network capable of probabilistically predicting entity-attribute changes in a Markov Decision Process (MDP) framework. "Breakout" video game variations are used as learning and testing environments. The authors report (model-based) Schema Networks are superior to the model-free Asynchronous Advantage Actor-Critic (A3C) algorithm and Progressive Networks with respect to training efficiency, zero-shot generalization, robustness, and learning transfer.  describe generative models for visual object recognition using Recursive Cortical Networks (RCNs). In this work, RCNs are used to understand letterforms in a general purpose "common 73 Sensed features were {color, size, movement, position} for vision and {texture, hand_open_or_closed} for touch. 74 https://www.vicarious.com/science/. Vicarious was acquired by Alphabet in 2022 and folded into its Intrinsic subsidiary. Their original goal was to create generally intelligent systems. 75 Logical connections are comprised of conjunctions, disjunctions, and "self transitions." sense" way by modeling objects as a combination of contours and surfaces via a network of features, pooling nodes, and lateral connections. The authors used RCNs to solve text-based CAPTCHAs 76 in 2013. RCNs build on ideas used in other compositional models to create structured probabilistic graphical models amenable to inference using Belief Propagation. Characterized as providing scaffolding versus being a tabula rasa approach (Vicarious 2017c), the system is engineered to prioritize and distinguish (factorize) contour and surface features. This enables RCNs to be trained using orders of magnitude fewer examples than other neural networks. Unlike convolutional neural network CAPTCHA breakers, training data are clean examples of letters from representative fonts, as opposed to large sets of distorted examples. Stone et al. (2017) and Vicarious (2017b) propose a method for improving object recognition in computer vision applications using convolutional neural networks (CNNs) by understanding the compositionality of a scene. Understanding compositionality entails the ability to learn and recognize objects and parts of objects in a decomposable, reusable manner. By masking out distinct objects that exist in close spatial proximity 77 , they "encourage networks to form representations that disentangle objects from their surroundings and from each other"-a property not provided by current CNNs. They found no negative effects on performance from filtering out context information for the medium-to large-sized objects they tested and claim their method "is a step towards making CNN-based representations more amenable to explicit context modeling through an external mechanism (by cleanly separating the representation of objects from their context)." Hay et al. (2018) and Vicarious (2018) address learning abstract concepts called Sensorimotor Contingencies (SMCs) through interacting with the environment. Whereas Schema Networks ) are networks of entities and attributes linked by state transition probabilities, SMCs are small programs that encode perception-action sequences as hierarchies of concepts similar to the options of   78 . Some SMCs are action-focused ("bring-about SMCs") and others observation-focused ("classification SMCs"). A curriculum consisting of positive and negative examples of concepts are generated and used by human trainers in a 2D "PixelWorld" to facilitate concept learning in a hierarchical, layered manner. Exemplary concepts include containment, object, objects that are containers, pushability, being on top, and object number (i.e., being to the left of two objects). Pushability, for example, is built on six layers of lower level concepts. SMCs are invoked as functions that return a binary value indicating success or failure.

Other recent work from Vicarious includes: Lavin et al. (2018) on how reasoning about visual scenes learned using RCNs    2021) on a query training (QT) method for learning probabilistic graphical models (PGMs) with paired inference algorithms to yield state-of-the-art results in applications like masked image region completion, learning full 76 "Completely Automated Public Turing test to tell Computers and Humans Apart," commonly implemented using distorted or obfuscated characters to prevent non-human access to Web resources. 77 This is technically accomplished by adding a loss term ("novel cost function") to the CNN that balances two feature maps: "one obtained from masking the input, and another derived from applying a mask in the feature space." 78 In the Conclusion section of Vicarious (2018), it is suggested SMCs and Semantic Networks may be productively combined where schema networks "would allow the agent to have an internal representation of the external world that it can use for simulation and planning." 79 These results included: subjective contours, neon color spreading, occlusion versus detection, and the border-ownership competition phenomenon. The reasoning method used was approximate Bayesian inference via loopy belief propagation. parameterization of grid-arranged Markov random fields, recognizing digits from noisy images, and other classification tasks.  Klahr and Wallace 1976;Ring 1994;Cohen PR et al. 1996;Guerin 2008a;Mao et al. 2015;Lake et al. 2016;Hutson 2018;Kwon 2018 Continuous learning Continual learning Lifelong learning Never-ending learning Cumulative learning Ring 1994 80 ;Thrun and Mitchell 1995 81 ;Ring et al. 2011;Chen Z and Liu 2016;Fei et al. 2016;DARPA 2017;Kirkpatrick et al. 2017;Mankowitz et al. 2018;Mitchell et al. 2018;Schwarz et al. 2018 Cognitive architecture Computational models Hierarchical Temporal Memory Biologically inspired cognitive architecture Biological and machine intelligence Newell 1973;Anderson and Kline 1977;Albus 1991Albus , 1999Schlesinger and McMurray 2012;Hawkins 2004Hawkins , 2017Samsonovich 2010;Laird et al. 2017;Kotseruba and Tsotsos 2020 Concept learning Concept formation Surprise-based learning Gennari et al. 1989;Fisher et al. 1991;Tenenbaum 1999;Barto et al. 2004;Ranasinghe and Shen 2008;Jia et al. 2013;Celikkanat et al. 2015b;MacLellan et al. 2016;Higgins I et al. 2017 Knowledge bases Ontologies Learning to learn Meta-learning Thrun and Pratt 1998;Schaul and Schmidhuber 2010;Lake 2016;Finn et al. 2017;Frans et al. 2017;Wang JX et al. 2017;Al-Shedivat et al. 2017;Rusu et al. 2018 Reinforcement learning Deep reinforcement learning Model-based reinforcement learning Intrinsically motivated learning Sutton 1988;Barto et al. 2004;Oudeyer et al. 2007; Baldassarre and Mirolli 2013;Christiano et al. 2017;Arulkumaran et al. 2017;Weber et al. 2018;Sutton and Barto 2018 Model building Program induction Lake et al. 2016


# Related Topics

Incremental learning Online learning Nonstationary learning Gennari et al. 1989;Shen 1997;Utgoff and Stracuzzi 2002;Ditzler et al. 2015; Kuipers and Beeson 2002;Stober and Kuipers 2008;Dupoux 2016 One-shot learning Zero-shot learning Few-shot learning Zero-shot generalization Cunningham 1972; Fei-Fei et al. 2006;Palatucci et al. 2009;Norouzi et al. 2014;Koch et al. 2015;Santoro et al. 2016;Ravi and Larochelle 2017;Duan et al. 2017;Vinyals et al. 2017;Rusu et al. 2018 Active learning Cohn et al. 1996 Friesen and Rao 2010;Chalodhorn and Rao 2010;Chung et al. 2014;Niekum et al. 2014;Nivel et al. 2014a;Duan et al. 2017 Bottom-up learning Sun and Zhang 2004 Embodied cognition Grounded cognition Agent-based approach Lakoff and Johnson 1980;Schlesinger and Parisi 2001;Hedblom et al. 2015;Hedblom 2018 Computational Creativity Cohen LM 1989;Aguilar and Perez y Perez 2015, 2017Artificial Life Computational Autopoiesis Cellular Automata 82 Gardner 1970Wolfram 1984;McMullen and Varela 1997  Many other methods may be found in a constructivist AI toolkit. Shen (1994, section 3.4) suggests: function approximation, function optimization, classification and clustering, inductive inference and system identification, learning finite state machines and hidden Markov models, dynamic systems and chaos, problem solving and decision making, reinforcement learning, adaptive control, and developmental psychology. Appendix A lists dozens of other relevant topics from developmental psychology, neurobiology, and other disciplines.


# Toward a General-Purpose Concept Learner

The author is pursuing AI constructivist development inspired by Piaget and informed by those surveyed in this paper. The goal is to engineer components capable of creating and maintaining memory structures (schemas) that enable agents to continually develop and refine knowledge and skills through interactions with their physical and social environments. Mechanisms supporting assimilation, accommodation, and staged development are being defined. The mechanisms are intended to enable cognitive development characteristic of lower animals through superhuman intelligences as a function of available resources and specified drives and goals. An eventual goal of this work is to configure an "infant bootstrap" agent that achieves human developmental milestones when provided with humanlike sensors and effectors and immersed in humanlike environments.

The initial focus is on generating and maintaining semantic and episodic memory structures that support concept and skill learning. Concepts are represented as knowledge schemas stored in semantic memory. Skills are represented as sensorimotor schemas stored in episodic memory. These are seen as necessary (but not sufficient) elements of a full-featured cognitive architecture.

Semantic memory will contain an ever-growing network of features/concepts 83 parsed from sensory and sensorimotor input streams using a General-Purpose Concept Learner (GPCL). Episodic memory will store episodes such as: (1) "Raw" sensory and sensorimotor episodes from which extracted features are derived (i.e., training cases), (2) Generalized scripts derived from similar (assimilated) episodes spanning a full range of agent skills (e.g., <grasping>, <subitizing>, <language processing>, <navigating>, <grocery shopping>, <logical reasoning>), 84 and (3) Episodes imagined by the agent (e.g., narratives). Episodes and extracted features will be linked to facilitate grounding, reasoning, retraining, and creative thought. Stored episodes will be available for replay so additional features can be extracted based on subsequent learning and so alternate focuses of attention can be applied.

Concept and skill development will occur concurrently, complimentarily, and continuously. Learning will be driven by intrinsic and extrinsic reinforcement and generally occur in an incremental and layered manner, resulting in a gradually accumulated hierarchy of concepts and skills. However, concepts and skills can emerge top-down as well as bottom-up. In the bottom-up case, they emerge from primitive features extracted from instances identified in episodes. For example, instances of seeing one's mother will induce a concept <my mother> (via assimilation) and, later, the categorical concept of <mothers> may emerge from examples of other instances and types of mothers (via accommodation). In the top-down case, more general concepts are introduced and serve as seeds to facilitate acquisition of lower-level concepts. Such higher-level concepts may be learned primarily through watching, imitating, and receiving external reinforcement from other agents. For example, in humans, concepts of <letters>, <words>, and <reading> are learned through interactions with parents before acquiring concepts of individual letters and words and the skill of reading. In non-human animals, concepts of <stalking>, <eluding>, and <hid-ing>, likely acquired by watching and interacting with other agents, precede the acquisition of specific techniques and skills related (subordinate) to <stalking>, <eluding>, and <hiding>. Such higher-level concepts enable and motivate agents to "fill in the gaps" in the wider conceptual areas. Table 6.1 provides a simple example of knowledge schema labels at various levels of a knowledge hierarchy corresponding to six sensorimotor channels-from low-to high-level concepts. Each label represents a class consisting of a network of features parsed from and linked to episodes. Concepts and skills that persist (become reified) in semantic and episodic memory are those that prove most useful for subsequent reasoning and prediction. Other concepts and skills can be generated and forgotten on the fly in service of processing immediate sensorimotor inputs/outputs. Two key factors determining what features are learned are: (a) The biases (motivations) included in the learning algorithm and innate schemas (e.g., pain avoidance/pleasure attainment, survival, reproduction, discovering new concepts (curiosity), pleasing other agents, etc.), and (b) The order and nature of experienced episodes (i.e., curriculum learning). Persistent objects <move_arm> <grasp> <close> <far away> <nice_thing> <caregiver> <my mother> <containment> <pathway> <my dog> <joes dog> <crawling> <powerful being> <happy> <sad> <I did good> <I did bad> <funny> <left> <right> <forward> <back> <up> <down> <subitizing> <estimating> <smart phone> <using smart phone> <somersault> <reading> <back flip> <skiing> <counting> <comparing size> <addition> <subtraction> <mothers> <motherhood> <dogs> <parent> <god> <arithmetic> <sharing> <ownership> <cooperation> <competition> <empathy> <multiplying> <dividing> <measuring with stick> <playing chess> <glenn gould> <bachs art of the fugue> <art of the fugue performed by glenn gould> <mathematics> <logic> <democracy> <freedom> <physics> <chemistry> <biology> <liberal arts> <natural selection> <supervised learning> <unsupervised learning> <reinforcement learning> <set theory> <ai constructivism> <philosophy> <existentialism> <quantum mechanics> <big history> <cosmology> Concepts exist separate from language. Agents that intrinsically have or can learn language skills get a great cognitive boost from the ability to associate symbols with concepts. Words allow concepts to be introduced by "teachers" (i.e., assigned class labels) and skills acquired without the agent needing to be explicitly shown or experience the skill. Once associated with a concept, words serve as just another predictive feature linked to underlying schema concepts. Features that are learned subconsciously may later be accessed consciously, symbolically labeled (named), and used in creating new schemas. For example, <green patch> or <left loop> features discovered in doing visual object recognition could be named later and leveraged for additional concept formation.

As another example, an agent may learn the concept <wooly texture> (unconsciously) as a byproduct of learning the concepts <sheep>, <alpaca>, and <labradoodle> before learning the word "wooly" and (consciously) associating it with <wooly texture>. A dog may master the action <chew up master's fuzzy slippers> before learning <bad dog> and "bad dog" (simultaneously). When the dog later executes the action <defecate in master's sleeping area>, the <bad dog> concept quickly assimilates the new concept into the <bad dog> concept upon hearing and experiencing the master's "bad dog" reaction. An example of word learning occurring before concept learning may be illustrated by the word "quantum mechanics" being introduced to an agent before the agent has knowledge of the concept <quantum mechanics>. As concepts associated with <quantum mechanics> are taught, the agent builds the concept of <quantum mechanics> into a network of other concepts. One might think of semantic memory as constituted by Large Concept Models with one or more Large Language Models overlaid/integrated therein.

The GPCL framework presumes motor control is not strictly necessary for concept development. Much can be learned from purely sensory inputs given suitable innate concepts and (mental) skills 85 --say, an innate skill for doing object detection for example. One imagines an Intelligent Traffic Camera that can learn concepts about vehicles, environmental conditions, and other objects and actions just through appropriate parsing of its video input-without needing physical panning and zoom capabilities. This allows knowledge schemas to be developed without implementing (or simulating) motor controls. Companion sensorimotor schemas can be used and developed without needing the integrated motor aspects (a.k.a. sensory schemas or cognitive skills). That is, purely sensory streams (movies) consisting of one or more of video, audio, touch, taste, and olfaction, can be effectively parsed to yield significant levels of cognition. GPCL focuses on learning knowledge schemas and does not currently intend to implement sensorimotor learning 86 .

Although it draws on developmental psychology and cognitive neuroscience, the GPCL approach is AIoriented and leverages basic machine learning principles. Specifically, it plans to implement a hybrid of supervised and unsupervised learning (classification and clustering) driven by intrinsic and extrinsic reinforcement. It does not set out to model actual biological mechanisms. The memory structures and learning algorithms must support a practically unlimited number of episodes and concepts-as is the case in biological brains.


## Appendix A: Cangelosi and Schlesinger (2015) Topics, Keywords, and References

The following table summarizes topics and references covered in Cangelosi and Schlesinger's (2015) book Developmental Robotics: From Babies to Robots. It reflects work in developmental psychology and developmental robotics that was (mostly) not covered in this survey.  James 1890;Piaget 1952;Fantz 1956;Gibson and Walk 1960;Charlesworth 1969;Campos et al. 1970;Gallup 1970;Maurer and Salapatek 1976;Meltzoff and Moore 1977;Acredolo 1978;Lewis and Brooks-Gunn 1979;Meltzoff and Borton 1979;Acredolo and Evans 1980;Haith 1980;Maurer and Barrera 1981;Marr 1982;Acredolo et al. 1984;Bahrick and Watson 1985;Gibson 1986;Kestenbaum et al. 1987;Kermoian and Campos 1988;Bushnell IWR et al. 1989;Spelke 1990;Ballard 1991;Morton and Johnson 1991;Campos et al. 1992;Butterworth 1992;Bushnell EW and Boudreau 1993;Leinbach and Fagot 1993;van Leeuwen et al. 1994;Bahrick et al. 1996;Elman et al. 1996;Higgins C et al. 1996;Slater et al. 1996;Valenza et al. 1996;Adolph 1997;Hiraki et al. 1998;Rochat 1998;Asada et al. 1999;Greenough and Black 1999;Schlesinger and Langer 1999;Itti and Koch 2000;Bushnell IWR 2001;Meissner and Brigham 2001;Bednar and Miikkulainen 2002;Courage and Howe 2002;de Haan et al. 2002;Furl et al. 2002;Mareschal and Johnson 2002;Quinn et al. 2002;Rochat and Striano 2002;Bednar and Miikkulainen 2003;Cos-Aguilera et al. 2003;Johnson SP et al. 2003a;Johnson SP et al. 2003b;Chen Y and Weng 2004;Fitzpatrick and Arsenio 2004;Johnson SP 2004;Lovett and Scassellati 2004;Michel et al. 2004;Natale et al. 2005b;Stoytchev 2005;Amso and Johnson 2006;Fritz et al. 2006;Joh and Adolph 2006;Zhang and Lee 2006;Fuke et al. 2007;Sann and Streri 2007;Schlesinger and Parisi 2007;Fitzpatrick et al. 2008;Guerin and McKenzie 2008;Montesano et al. 2008;Stoytchev 2008;Sturm et al. 2008;Gold and Scassellati 2009;Kaipa et al. 2010;Franz and Triesch 2010;Chaudhuri 2011;Stoytchev 2011; Motor development (Ch. 5) learning motor skills, u-shaped development, motor babbling, body babbling, multiple sense integration, experience-expectant development, experience-dependent development, prereaching, pre-shaping, grasp development (palmar, scissors, radialdigital, pincer, mature pincer), locomotion development (pre-crawling, creeping, crawling, sideways cruising, frontward cruising, standing, walking) Field et al. 1983;Meltzoff and Moore 1983;Meltzoff 1988;Meltzoff and Moore 1989;Butterworth 1991;Butterworth and Jarrett 1991;Leslie 1994;Baron-Cohen 1995;Davies and Stone 1995;Fadiga et al. 1995;Meltzoff 1995;Demiris et al. 1997;Meltzoff and Moore 1997;Rizzolatti and Arbib 1998;Iacoboni et al. 1999;Nadel and Butterworth 1999;Scassellati 1999;Schaal 1999;Billard and Matarić 2001;Kozima and Yano 2001;Rizzolatti et al. 2001;Breazeal and Scassellati 2002; itation, collaboration/ cooperation, intention reading, goal prediction, theory of mind, self-recognition, AIM model, mirror neurons, MOSAIC model, HAMMER architecture, paired inverse-forward models, world model Call and Carpenter 2002;Demiris and Hayes 2002;Fasel et al. 2002;Nehaniv and Dautenhahn 2002;Demiris and Johnson 2003;Gergely 2003;Imai et al. 2003;Nagai et al. 2003b;Nagai et al. 2003b;Ude and Atkeson 2003;Carlson E and Triesch 2004;Ito and Tani 2004;Rizzolatti and Craighero 2004;Zöllner et al. 2004;Borenstein and Ruppin 2005;Demiris and Deardon 2005;Hafner and Kaplan 2005;Thomaz et al. 2005;Demiris and Khadhouri 2006;Demiris and Simmons 2006;Dominey et al. 2006;Ferrari et al. 2006;Hashimoto et al. 2006;Kaplan and Hafner 2006;Mavridis and Roy 2006;Nagai et al. 2006;Triesch et al. 2006;Meltzoff 2007;Nehaniv and Dautenhahn 2007;Rao et al. 2007;Tapus et al. 2007;Watanabe et al. 2007;Barsalou 2008;Call and Tomasello 2008;Demiris and Meltzoff 2008;Jasso et al. 2008;François et al. 2009a;François et al. 2009b;Gold and Scassellati 2009;Tomasello 2009;Kruger et al. 2010;Lallée et al. 2010;Dominey and Warneken 2011;Hafner and Schillaci 2011;Sarabia et al. 2011;Tanz 2011;Carlson T and Demiris 2012 Language development (Ch. 7) nature vs nurture, nativism vs empiricism, language acquisition device, grammaticalization, usage-based theory of language development, cognitive linguistic theories, symbol grounding, babbling, vocabulary spurt, verb islands, biases (reference, similarity, conventionality, wholeobject, whole-part juxtaposition, segmentation, taxonomic, mutual exclusivity, embodiment, social [Bahrick et al. 1996 


## Topics and keywords


,Cangelosi et al. (2007),,Morse and Cangelosi (2017) on developmental and agent-based language acquisition; Schlesinger et al. (2000) on constraint-based development of infant motor skills 53 ; Schlesinger and Parisi (2001) on online (real-time) sampling in agents that explore their environments; Morse et al. (2010b) on an Epigentic Robotics Architecture (ERA) where schemas ("basic ERA units") consist of Self-Organizing Maps (SOM) representing particular features of the environment (e.g., color, shape, body posture, word representations) connected to "hub" SOMs weighted using positive Hebbian learning 54 ; Cangelosi et al. (2000), Coventry et al. (2005), Cangelosi and Riga (2006), Marocco et al. (2010), Cangelosi (2010), Stramandinoli et al. (2012), Stramandinoli et al. (2017) on sensorimotor grounding of words and concepts; and Schlesinger


) the general form of a model (schema) is presented as "( ( 0, 1,..., , 0, 1), ( 0, 1,..., , 2, 3)) where and are variables representing arbitrary quantities, 0 and 1 are variables that define the time interval within which L holds, and 2 and 3 variables defining the time interval for R." In a 2013 lecture (AGI-13 Summer School -AERA 6), Nivel gives an example of a model where LT = robotic gripper move command with time and control parameters and RT = resulting gripper location with time parameters.

## Google
DeepMind research relevant to AI constructivism includes: Higgins I et al. (2016) on using a variational autoencoder (VAE) that learns disentangled features to mimic visual feature learning in humans; Battaglia et al. (2016) on an interaction network that decomposes environments into networks of objects and relations and reasons about them explicitly; Higgins I et al. (2017) on the Symbol-Concept Association Network (SCAN) that extends the VAE architecture to extract abstract concepts grounded in disentangled features from visual input, associate those concepts with symbols, and enable construction of novel concepts; Hill et al. (2017) on understanding grounded language learning in neural networks that link visual features (i.e., shapes, colors, patterns, shades, sizes) with words in a way that parallels human language acquisition; Rabinowitz et al. (2018) on using meta-learning to build a neural network (ToMnet) that learns Theory of Mind models for different species of agents; Rao et al. (2019) on Continual


can explain several well-known psychophysical and physiological results 79 ; Lázaro-Gredilla et al. (2019) on concepts as cognitive programs that are learned from pairs of input-output images using a small set of primitive instructions (concepts, schemas) and run on a visual cognitive computer (VCC); Rikhye et al. (2020) on clone-structured cognitive graphs (CSCGs) for representing the environment and improving autonomous navigation by extending cloned hidden Markov models (HMMs) to include agent actions; Sawyer et al. (2020) on improving the cognitive program approach to concept learning (Lázaro-Gredilla et al. 2019) by adding human-inspired heuristics of object factorization and sub-goaling to accelerate program learning; Lázaro-Gredilla et al. (

## Table 5 .
51 lists topics related to constructivist AI. The topics are grouped together and ordered roughly by decreasing relevance.Topics 
References 
Constructivist AI 
AI constructivism 
Developmental robotics 
Autonomous mental development 
Cognitive and developmental systems 
Epigenetic robotics 
Cognitive robotics 
Computational approach to constructivism 
Autonomous learning 

See previous sections 

Learning like a child 
Learning like a baby 
Building a baby 
Learning like people 

Turing 1950; 

## Table 5 .
51. Topics related to constructivist AI.

## Table 6 .# Introduction

Constructivism in artificial intelligence (AI), inspired by the developmental psychology of Jean Piaget (1936/1954 and successors like Cohen LB (1977), Karmiloff-Smith (1992), and Mandler (1992Mandler ( , 2004Mandler ( , 2012, has been described and implemented by Cunningham (1972), Drescher (1989Drescher ( /1991, Shen (1989), Cohen PR et al. (1997), Kuipers (2000), Barto et al. (2004), Chaput (2004), Guerin (2008aGuerin ( , 2008b, and others. McLeod (2020) describes a key insight of Piaget (that is core to constructivist AI) as "Children are born with a very basic mental structure (genetically inherited and evolved) on which all subsequent learning and knowledge are based." AI constructivists reject nativist positions that suggest innate, specialized, evolutionally programmed mechanisms underlie most mental activity. Rather, they presume agents have limited innate knowledge and general-purpose algorithms enable continuous learning in situated environments. 1 Many AI constructivists, such as Drescher (1989Drescher ( /1991, are aligned with developers like Albus (2008), Tenenbaum et al. (2011), Lake et al. (2016, Dupoux (2016), andDiCarlo (2018) in further characterizing the constructivist goal as "reverse engineering the human mind." Alan Turing (1950) anticipated AI constructivism writing, "Instead of trying to produce a programme to simulate the adult mind, why not rather try to produce one which simulates the child's? If this were then subjected to an appropriate course of education one would obtain the adult brain." This approach is seen as a path to artificial general intelligence 2 by developers like Adams et al. (2012) who join Nilsson (2005 in advocating for "the development of general-purpose, educable systems that can learn and be taught to perform any of the thousands of jobs that humans can perform … beginning with a system that AI constructivists have adopted Piagetian elements to varying degrees. Schemas generally correspond to knowledge, skill, or concept representations. Adaptation processes correspond to learning algorithms that create and maintain schemas. Staged development is a key influence on the constitution of learningalgorithms and agent architectures. At its core, staging is the principle that prior knowledge and skills provide the basis for subsequent knowledge and skills. Early AI schemas include Minsky's (1975) frames, Schank and Abelson's (1975) scripts, and Rumelhart's schemas (Rumelhart and Ortony 1977). Schemas have been implemented as data structures; small modular programs; software functions, subroutines, and objects; self-organizing maps; rules; production systems; finite state machines; semantic nets; artificial neural networks; physics simulators; mini Turing machines; combinations of these; and other constructs. This paper is structured around a recapitulation of Guerin's (2008a) survey of constructivist systems developed by AI practitioners. Section 2 provides a brief chronological summary of the developments covered therein with a focus on data structures, algorithms, and staging. Section 3 examines progress by the Guerin referents since 2008. Section 4 presents many notable works not covered in Guerin, including some that are lesser known, out of mainstream AI, and subsequent to 2008. Section 5 lists related areas of AI research. Section 6 provides an overview of a constructivist AI approach being developed by the author that parses concepts from sensory input and stores them in a semantic memory network linked to episodic data. The approach aims to provide "mechanisms to bridge the gap between the sensorimotor level and high-level cognition" (Guerin's comments to (Perotto 2013, p. 312). Appendix A lists topics, keywords, and references from Cangelosi and Schlesinger's (2015) excellent book on developmental robotics. Other AI constructivism surveys are available by Lungarella et al. (2003), Ziemke (2001). Guerin (2008a) summarizes some history and key developments of AI constructivism beginning with Drescher (1989Drescher ( /1991 and continuing through Cohen PR et al. (1997), Rosenstein et al. (1997), Stojanov et al. (1997Stojanov et al. ( , 2001, Chaput (2004), Barto et al. (2004), Barto and Mahadevan (2003), Bakker and Schmidhuber (2004), Holmes and Isbell (2006), Perotto and Alvares (2006), St. Amant et al. (2006), , Oudeyer et al. (2007), Bondu and Lemaire (2007), Konidaris and Barto (2007), , Stoytchev (2007), and Kuipers and colleagues (e.g., Pierce and Kuipers (1997), Kuipers (2000), Kuipers and Beeson (2002), Modayil and Kuipers (2004), , , Olsson et al. (2006), Modayil and Kuipers (2007), Provost et al. (2007)). This section briefly summarizes these works-characterizing the components, algorithms, and architectures in terms of Piaget's schemas, adaptation processes, and staged development.


# The Guerin 2008 Survey

For Drescher (1989Drescher ( /1991, the schema is a simple Context-Action-Result 9 structure, e.g., SeeHandAtPo-sitionX-MoveHandBackward-SeeHandAtPositionY. These schemas can grow to represent more sophisticated knowledge via mechanisms of chaining, synthetic item generation, spinoff schemas, and composite actions. The general learning algorithm, the "schema mechanism," utilizes processes of induction (i.e., marginal attribution), abstraction, and invention. It is focused on the first 5 sub-stages of Piaget's Sensorimotor stage, while presumed to apply to the later stages as well.

In Cohen PR et al.'s (1997) Neo system, temporally-coincident sensations and percepts form schemas called fluents which combine into increasingly sophisticated structures called composite fluents, chains, classes, and physical schemas. Base fluents are "(attribute value)" pairs where the attribute identifies a 9 Context-Action-Result (or CurrentState-Action-NextState) is a common design pattern for constructivist learning (e.g., Stojanov, 2001;Bakker and Schmidhuber, 2004;Perotto and Alvares, 2006). It may also be seen to be analogous to Bayesian reasoning where Prior (context) + New Evidence (action) = Posterior (result) and to rules in production systems (Klahr and Wallace, 1976). Bakker and Schmidhuber (2004) describe the HASSLE algorithm (Hierarchical Assignment of Subgoals to Subpolicies LEarning algorithm)-a hierarchical reinforcement learning algorithm that uses intrinsically motivated learning to allow high-level policies to discover sub-goals by clustering sensor data and have low-level policies specialize on reaching sub-goals. Observation vectors are clustered using ARAVQ (Adaptive Resource Allocation Vector Quantization). High-level and low-level options 11 (schemas) are learned as high-and low-level value functions using temporal difference learning at different temporal resolutions. The system claims to have automatically achieved three levels of learning for an agent navigating a simulated office grid world. Holmes and Isbell (2006) employ looping Prediction Suffix Trees to represent deterministic Partially Observable Markov Decision Processes to identify what state an agent is in and predict what can happen next. Perotto and Alvares' (2006) schemas consist of Context-Action-Expectation triples where each element is represented by a vector of sensor (or effector) states where each state can have a value of true, false, or undefined. The schemas are organized into trees where root nodes represent general situations and more specific situations are encoded in the more distal branches and leaves. In Perotto et al. (2007), a Constructivist Anticipatory Learning Mechanism (CALM) is introduced that extends Context-Action-Expectation schemas to more complex (partially deterministic and partially observable) environments by using synthetic elements to represent abstract or hidden properties. St. Amant et al. (2006) extends Rosenstein et al. (1997) in describing an image schema language (ISL) for representing Lakoff and Johnson-style image schemas (Lakoff and Johnson 1980;Johnson M 1987;Gibbs and Colston 1995). Therein, "image schemas are objects, as in the object-oriented data model" where "each schema has a set of operations that determine its capabilities" and "internal slots … that permit image schemas to be related to each other through their slot values." Sets of image schema instances can be used to define each state in a state machine 12 . St. Amant et al. (2006) also define learned sequences of image sequences called "gists" which serve as a kind of higher-level reusable action structure tied to particular goals. Chang et al.'s (2006) Jean system builds on St. Amant et al. (2006) using ISL concepts to implement an infant-like agent that attempts to learn, execute, and extend schemas in a simulated playpen environment. It introduces an Experimental State Splitting (ESS) algorithm for building a world model by composing schemas into gists (composite schemas) and differentiating (splitting) existing states into new states. The authors claim their policies allow Jean to learn causal relationships. Cohen PR et al. (2007) provides more details on action schemas and Jean's ability to learn and repurpose (transfer) gists in a 3-D real time strategy game environment. Oudeyer et al. (2007) use vector exemplars representing sensorimotor experiences, which are partitioned into distinct regions using an Intelligent Adaptive Curiosity (IAC) algorithm that utilizes intrinsically motivated learning similarly to Barto et al. (2004). Each region is associated with a particular learning machine, e.g. neural network, support vector machine, or Bayesian machine. The number of exemplars allocated to a region is limited to 250. Each region maintains a list of error rates representing how much the results of executed actions vary from what was predicted. These lists are subsequently used to select the best actions for new situations. Bondu and Lemaire (2007) extend this work by reformulating the are described by suitably constituted sensor readings that are clustered to identify particular objects. They describe an object ontology by a tuple " (Trackers, Perceptual Functions, Concepts, and Actions)." Object concepts are formed by clustering object percepts that are stable in time. Associated actions are actions that have been learned that reliably change a particular object's percepts.


# Subsequent Work by the Guerin Referents

This section summarizes constructivist AI work since 2008 by those surveyed in (Guerin 2008a). People not mentioned, like Drescher, Chaput, Bakker, Holmes, and Isbell, appear to have not continued this line of development.

Guerin and colleagues have published on learning object manipulation and tool use (Guerin et al. 2013) and on automatically identifying tools and their functions (Abelha et al. 2016;Abelha and Guerin 2017). Guerin et al. (2013) provides a summary of constructivist developmental paths, methods, and potential knowledge representations consistent with developmental psychology. Celikkanat et al. (2015a) describe work on modeling the context of an agent using a Random Markov Field "concept web" as a latent variable of an incremental Latent Dirichlet Allocation (LDA) process. They define context as the "set of active concepts in the scene" and leverage context for agent cognition and behavior 14 .

Subsequent to Neo, Jean, ISL, Wubble World 15 , and related systems described in (Cohen PR et al. 1997;Rosenstein et al. 1997;St. Amant et al. 2006;and Kerr et al. 2007), Paul Cohen and colleagues continued work in the AI constructivist vein on language learning (Hewlett and Cohen 2009;Hewlett 2011), an Action Schema Generator that can acquire and represent semantic knowledge based on a simulated agent's experience (Mu 2009), representing activities as finite state machines (Kerr et al. 2011), and ways for humans to teach autonomous agents (Kaochar et al. 2011). More recently Cohen has explored leveraging human-machine synergies, where machines focus on mining and synthesizing data into integrated causal models and "pushing" results to humans (Cohen PR 2015;Cohen PR 2018;Cohen PR 2020). This approach advocates AIs be deployed as knowledge extraction and synthesis tools rather than agents that learn and reason like humans. The Big Mechanism program (Cohen PR 2015) uses AI to automatically build causal models by extracting causal claims from scientific papers. Associated DARPA-affiliated programs "demonstrated that machines can read text, tables, equations and even FORTRAN code from legacy models, and build comprehensive models of the world's complicated, interacting systems" (Cohen PR 2020). Cohen contrasts this approach with typical big data and machine learning methods that focus on learning patterns (correlations) and not on discovering causal mechanisms.

Kuipers and colleagues continued work on autonomous environmental mapping, including further development of the Spatial Semantic Hierarchy (SSH) model through variants called hybrid-SSH (HSSH) (Kuipers 2008) and Hierarchical Hybrid Spatial Semantic Hierarchy (H 2 SSH) (Johnson CE 2018). The HSSH "represents a robot's environment using four distinct layers that provide metrical and topological representations of both small-scale and large-scale space." H 2 SSH (Johnson CE 2018) "improves on the HSSH by providing hierarchical representations of both local and global space that improve the scalability of the topological mapping problem." H 2 SSH updated the HSSH to represent three topological features: path segments, decision points, and destinations; support richer semantics for path segments; and allow nesting of topological maps to support more complex spatial environments. Prior to the H 2 SSH work, Mugan (2010) described an algorithm called the Qualitative Learner of Actions and Perception (QLAP) that autonomously learns predictive models of an environment and a set of hierarchical actions suitable for acting on it. Knowledge is represented as a network of plans and actions. 16 In other work, Xu C (2011) introduces an Object Semantic Hierarchy (OSH) that constructively recognizes and models objects in the environment. As summarized therein: "The agent initially treats everything in the sensory stream as noise. By repeatedly identifying new invariants to reduce the noise, the agent progressively builds models for the background world and foreground objects. For the background world or each foreground object, the model evolves from 2D2D to 2D3D to 3D3D." In another thread, Liu et al. (2011) explore how high-level semantic action concepts/attributes, both manually defined and autonomously learned, can be used to represent higher-level human actions. For example, they note attributes of singleleg-motion, arm-over-shoulder-motion, and torso-up-down-motion may effectively classify the action of golf-swinging. Thus they explore potentially useful decompositions of verbal/action concepts as opposed to the more-studied object recognition and classification domains. Mittelman et al. (2014) describe an attribute tree process (ATP) that learns a tree hierarchy of semantic concepts using an unsupervised Bayesian method. They provide evidence that ATP may be superior to agglomerative hierarchical clustering (AHC) and the factored Bernoulli likelihood model (FBLM) for doing concept clustering. Stojanov (2009) gives a brief summary of AI and robotics work influenced by Piaget from years 1963through 2008. Stojanov and Indurkhya (2013 discuss roles of perceptual similarity and analogy in a constructivist view on creativity. They see analogy as a "core mechanism in human cognitive development rather than a special skill among many" (in distinction to Piaget) and they discern perceptual similarity as a key to creative problem solving.

Perotto (2013) reprises and refines CALM (Perotto et al. 2007), adding a meta-architecture called the coupled agent environment system (CAES) in which an intrinsically motivated CALM agent is situated. The CAES consists of an agent (A) logically comprised of separate body (B) and mind (M) components that exchange percepts (p) and control signals (c). It also defines a "world outside the mind" (W) made up of the agent's body (B) and the wider environment (E) that interact through situations (s) and actuations (a). Perotto notes CAES and a CALM agent interact as two mutually dependent dynamical systems. The world is modeled as a factored and partially observable Markovian decision process (FPOMDP). The paper is followed by commentary by Guerin, Butz, Thorisson, Stojanov, Bickhard, Degris, and Scott on CALM, CAES, and the state of the art of constructivist solutions in general-providing a useful snapshot of the status of constructivist AI development in 2013. They suggest the main unsolved challenge is the ability to build up cognitive capabilities from the sensorimotor level to higher conceptual levels in the presence of complex, high-bandwidth environmental sensations and noise, e.g., create symbols, abstract structures, and models.

Oudeyer continued work on constructivist AI "focusing on sensorimotor development, language acquisition and life-long learning in robots." 17 In response to Lake et al. (2016), Oudeyer (2017a) discusses additional "crucial ingredients" necessary for autonomous learning: curiosity and intrinsic motivation, social learning and natural interaction with peers, and embodiment. In (Oudeyer 2017b), AI constructivism (development) is described as generating a "complex dynamical system, characterized by spontaneous self-organization or emergent patterns at multiple scales of time and space." In (Santucci et al. 2020), Oudeyer and colleagues summarize work on intrinsically motivated open-ended learning in autonomous robots and highlight key open problems including autonomous generation of goals, learning policies to achieve goals, appropriate use of intrinsic motivation ("to support learning compact representations of environment states"), and a need for better ways to encode goals and skills. 16 QLAP represents environmental models using dynamic Bayesian networks (DBNs) and represents action plans using  options framework. Many small Markov Decision Processes (MDPs) are created to represent small aspects of the environment. 17 http://www.pyoudeyer.com/bio/. Barto, Sutton, and colleagues 18 continued exploring sensorimotor approaches to knowledge acquisition (Sutton 2012) building on their work in reinforcement learning. Sutton (2009) summarizes status of the Predictive Empirical Abstract Knowledge (PEAK) project: "an attempt to understand world knowledge in terms of a minimal ontology of sensorimotor experience" where they endeavored to "connect lowlevel signals [consisting of sensations and actions] to higher-level representations in such a way that the knowledge remains grounded and autonomously verifiable." The approach, which included temporally abstract options, option models, and temporal-difference (TD) networks, were evaluated in two simulated environments (bit-to-bit world and compass world) and in a sensor-rich robotic environment (Critterbot).  describe the Horde architecture, which improved upon TD-networks and options using gradient-TD methods and General Value Functions (GVFs) as knowledge representations (schemas). The architecture relies on "a large number of independent reinforcement learning sub-agents, or demons" that learn in parallel, each "responsible for answering a single predictive or goal-oriented question about the world. … Each demon has its own policy, reward function, termination function, and terminal-reward function." Barto et al. (2013) summarize work related to exploring and representing behavioral hierarchies. They describe refinements to the  options framework while focusing on using hierarchical reinforcement learning (HRL) to learn hierarchies of behavioral modules. Da Silva et al. (2014) introduce an active learning method for efficiently acquiring parameterized skills that are more granular and reusable than skills originally defined in the options framework. Niekum et al. (2014) propose constructivist improvements in robotic learning from demonstration (LfD) by discerning "repeated structure at multiple levels of abstraction in demonstration data," thus discovering semantic knowledge about the world and building up a "library of skills" over time. Sutton and colleagues worked on improving the performance of online reinforcement learning algorithms to "true" online versions. These include true online TD(λ) 19 ( van Seijen and Sutton 2014), true online GTD(λ) (van Hasselt et al. 2014), true online Sarsa(λ) (van Seijen and Sutton 2014), and true online emphatic TD(λ) 20 (Sutton 2015). De Asis et al. (2020) suggest fixed-horizon temporal difference (FHTD) methods, which predict "the sum of rewards over a fixed number of future time steps," as being a further advance. Veeriah et al. (2017) describe the crossprop neural network-learning algorithm, which unlike backprop, can "learn to reuse the learned features for solving new and unseen tasks." Stoytchev has since collaborated on work to learn multi-sensory features to categorize common objects (Sinapov et al. 2014) and on work to teach robots to do other object recognition and manipulation tasks 21 . Schmidhuber (2010) summarizes his work on intrinsic motivation from 1990 to 2002. He suggests the purpose of intrinsic motivation is to "provoke event sequences exhibiting previously unknown but learnable algorithmic regularities" and to build an agent "that never stops generating non-trivial & novel & surprising data." Key components of such agents are: "an adaptive world model …, a learning algorithm that continually improves the model …, intrinsic rewards measuring the model's improvement …, [and] a separate reward optimizer or reinforcement learner." Intrinsic rewards assign values to "the discovery or creation of novel patterns," which Schmidhuber equates with "fun or internal joy." He reviews his previous "practical but non-optimal" proposals where reward values are: (1) proportional to the model's prediction errors 22 , (2) proportional to expected improvement (first derivative) of prediction error, (3) proportional to relative entropies of learning agent's priors and posteriors, and (4) determined through 18 Links to Barto's and Sutton's publications are at https://people.cs.umass.edu/~barto/pubs-Barto.html and http://incompleteideas.net/publications.html#beyond_reward. 19 This is a temporal difference algorithm that "combines basic TD learning with eligibility traces to further speed learning." 20 Emphatic approaches generate knowledge structures by selectively emphasizing or de-emphasizing updates on different time steps. Gu et al. (2019) suggest emphatic TD may be superior to other reinforcement learning algorithms. 21 See publications list at http://www.ece.iastate.edu/~alexs/lab/publications/index.html. 22 Schmidhuber (1991a) suggests intrinsic reinforcement be calculated based on the difference between predicted and actual experience where "zero reinforcement should be given in case of perfect matches, high reinforcement should be given in case of 'near-misses', and low reinforcement again should be given in case of strong mismatches." These cases correspond to concepts that are already learned (boring), effectively learnable (curiosity piquing), and unlearnable (befuddling). zero-sum games between a "right brain" and "left brain." Schmidhuber (2013) describes PowerPlay-an "implementation of basic principles of creativity" inspired by playful behavior in animals 23 . PowerPlay evaluates new tasks (problems) against existing skills (problem solvers) and, if a task cannot be solved by an existing skill, it modifies existing skills and remembers one that solves the new task and all previous related tasks. Thus solvers (skills, schemas) become more general over time. Types of solvers considered include deterministic universal computers, finite state automata, and feedforward neural networks. Procedures for task invention, solver modification, and correctness demonstration are described. Schmidhuber (2015) describes recurrent neural network-based AIs (RNNAIs) that learn to think by combining an RL controller with an RNN-based predictive world model. Schmidhuber (2017) suggests technology like Long Short-Term Memory (LSTM) 24 combined with artificial curiosity and creativity will soon enable "an AI that incrementally learns to become as smart as a little animal-curiously and creatively and continually learning to plan and reason and decompose a wide variety of problems into quickly solvable (or already solved) sub-problems." 25 Ha and Schmidhuber (2018) present a simplified framework based on Schmidhuber's work from 1990 -2015 that combines a large RNN-based world model with smaller controller models to enable agents to learn compact and simple task completion policies. They use a Variational Autoencoder to encode image frames, a Mixture Density Network combined with an RNN to predict future frames, and a simple linear model to control outputs. Van Steenkiste et al. (2018) describe a relational neural expectation maximization (R-NEM) method for learning objects and their physical interactions in an unsupervised manner from raw video images. Greff et al. (2020) propose a unifying framework aimed at solving the binding problem and approaching human-level generalization by segregating sensory inputs, maintaining separate symbolic (object) representations, and using those representations to compose new inferences, predictions, and behaviors. They provide an extensive survey of the object representation literature spanning AI and cognitive psychology. Csordás et al. (2021) propose modifying the Transformer architecture by adding a copy gate and using geometric attention to allow Transformers to learn more generally applicable rules.


# Other Constructivists

Early purveyors of constructivist ideas, appropriately not surveyed in (Guerin 2008a) given their less direct influence on AI constructivism, have been discussed by Ernst von Glasersfeld (1984, Michael Arbib (1992), D. C. Phillips (1995), and Sandra Marshall (1995). Perhaps most influential were John Locke (1690) for his embrace of empiricism, rejection of innate ideas, and promotion of the principle that sensations give rise to secondary qualities that enable all ideas 26 ; Immanuel Kant (1781) for challenging Locke's notions of substances and primary qualities and promoting the idea that all knowledge is derived from sensations 27 ; William James for his radical empiricism 28 and proposing how "blooming, buzzing confusion" gives way to knowledge through learning objects and relations via discrimination and synthesis (James 1890) 29 ;and Lev Vygotsky (2012) for emphasizing the significance of social interactions for creating schemas. 23 Playful behaviors are tasks that are usually self-generated and used to acquire skills that can be applied later to tasks encountered in the environment. 24 A type of memory cell used in hidden units of Recurrent Neural Nets (RNNs) that effectively handles long-term temporal dependencies (Greff et al. 2017). 25 Such a goal is being pursued by NNAISENSE, a company Schmidhuber cofounded with Gomez, Koutnik, Steunebrink, and Masci. (https://nnaisense.com). Their current focus is on intelligent automation, deep learning, and AGI. 26 Locke's primary qualities, interpreted as objective "measurable aspects of physical reality" (Wikipedia, Primary/secondary quality distinction), are unnecessary from a constructivist perspective. Secondary qualities interpreted as subjective qualities perceived by the senses, on the other hand, are fundamental to constructivism. 27 Agents have access only to the phenomenal world. The noumenal world (things as they really are) is inaccessible. Reason is used to create additional knowledge from sensed experiences. Kant's conceptions of schema, characterized as rules or filters mapping sensations to concepts, map well to Piaget and other modern psychologists (Scaglia 2018;Marshall 2015). 28 Radical empiricism posits that all knowledge, i.e., objects and relations, comes from direct experience (James 1904). 29 James uses the terms "association and dissociation," "subdividing and uniting," and "break asunder and reunite." He also notes the importance of selective attention and sensory filtering: "We do far more than emphasize things, and unite some, and keep others apart. We actually ignore most of the things before us" (James 1890, p. 284). This section does not examine such influences. Rather, it considers works subsequent to Piaget (1934Piaget ( /1954 that are not in (Guerin 2008a) and more directly relevant to AI constructivist implementations. As in previous sections, the work is presented chronologically.

George Kelly's (1955) Personal Construct Theory (PCT) defines constructs (schemas) as "transparent patterns or templates created by humans and lower animals that fit over the realities of the world and enable them to chart a course of behavior." 30 Developed in the context of clinical psychology, PCT posits that agents construct and adapt personal mental models that allow them to effectively predict events. Agents function as naïve scientists that form and test hypotheses and channel their thoughts and behaviors consistent with plausible hypotheses. 31 Different, often incompatible, constructs are used to make sense of events over time-a process Kelly called constructive alternativism. A distinguishing feature of PCT is that mental constructs consist of pairs of mutually exclusive binary values (e.g., old-young, goodbad, happy-sad, light-dark, comes_when_I_cry, doesn't_come_when_I_cry). These dichotomous constructs define axes of a multi-dimensional psychological space with elements of experience representing points in the space (Kelly 1955, Ch. 6;Gaines and Shaw 2012, p. 21). Constructs form hierarchies, where higher level constructs may change by "invoke[ing] new arrangements among the systems which are subordinate to them" (Kelly 1955, p. 55). To operationalize the theory, Kelly introduced a cognitive mapping technique called repertory grids that provides methods for eliciting constructs and observational elements from agents and organizing them into rows and columns in a matrix (Shaw 1978;Gaines and Shaw 1991;Curtis et al. 2008). This data can be clustered or otherwise compared to progressively refine constructs and better understand agent's mental models. Proponents have nudged PCT in constructivist AI directions by building computer applications that automate the creation and analysis of repertory grids, support the use of repertory grids in non-psychological applications, facilitate knowledge acquisition for expert systems, and aid in constructing semantic networks (Shaw 1978;Gaines and Shaw 1991;Curtis et al. 2008;Gaines and Shaw 2012). 32 Boeree (2006) provides a summary of Kelly's life and works. Ceccato and Zonta (1961) present work on machine translation (MT) 33 that leveraged constructivist principles from their Italian Operational School of philosophy (Hutchins 1986). They specify four key operations (adaptation mechanisms) for constructing thoughts: differentiation, figuration, categorization, and correlation. Differentiation refers to detecting changes of state, which gives rise to distinctions like dark-light, hot-cold, resistant-yielding, green-red-yellow, and silence-noise. Figuration detects changes of place, which allows recognition of shapes and volumes. Categorization corresponds to mental classification based on temporal differentiation, which "gives us the mental, or logical, categories, including, for example, substance, accident, subject, object, and, or, with, also, by, state, point, line, surface..." Correlation, which represents thought itself, links items created by the other three operations into distinct temporal units (Ceccato and Zonta 1961;Ceccato 1962, pp. 62 -65;Hutchins 1986). Ceccato's MT implementation reflected these operations via correlational tables and correlational nets. The latter consisted of a network of correlational triads (the temporal units) each unit comprising a correlator 34 and first and second correlatums. Semantic net-like constructs called notional spheres and frame-like constructs called constellations were used to resolve ambiguities (i.e., polysemanticity) in MT phrase mapping (Ceccato 1962, pp. 83 -87). Ceccato (1967) mentions early work on what he called "The 30 Slightly paraphrased from Kelly (1955, p. 7, pgphs. 1 -2). 31 Kelly's fundamental postulate states: "A person's processes are psychologically channelized by the ways in which he anticipates events." The fundamental postulate is supplemented with 11 corollaries (Kelly 1955, Ch.2). See Appendix I in (Curtis et al. 2008) for a concise summary. 32 Gaines and Shaw (2012, Sect. 4.3) note similar construct descriptions arising in various academic areas, including Bartlett's schema (human memory processes), Ranganathan's faceted taxonomy (library science), Kelly's conceptual/repertory grid (personal construct psychology), Minsky's frames (knowledge representation), Piaget's schema (developmental psychology), Filmore's frames (linguistics), and Barsalou's frames (cognitive psychology). 33 For Ceccato et al., MT signified "mechanical translation." 34 A modest number of primitive correlators (i.e., 100 -200) were envisioned. They consisted of "the conjunctions and prepositions, punctuation marks, and relations such as subject-predicate, substance-accident (i.e., noun-adjective), apposition, development-modality (i.e. verb-adverb), and comparison" (Hutchins 1986). Correlators temporally link correlatums. Fourth Approach to MT," aimed at producing a proof-of-concept machine "which observes and describes the events of its surroundings through the actual operations of perception, representation, categorization, etc." Ayn Rand's Objectivist epistemology (Rand 1967) is notable for its constructivist principles. Claims include: all knowledge is based on perception; a conceptual hierarchy spans from sensations to perceptions to concepts; understanding infant development is key to understanding concept formation; developmentally, existing things (existents) are recognized progressively-first as entities, then identities, then units (i.e., instances); concepts are constructed by differentiating (i.e., abstracting out) and integrating (i.e., uniting) attributes from two or more units using "in large part, a mathematical process;" units are distinguished as having shared attributes with different values; conceptual common denominators such as length, shape, kinds of motion, and color are used to build higher-level concepts; concepts are structured in a hierarchy of increasing abstraction. Boydstun (2012) discusses similarities between Rand and Piaget's ideas. He suggests Rand may have adapted her epistemology to more closely track Piaget given her familiarity with Flavell's (1963) account of Piaget.

Michael Cunningham (1972) proposes a constructivist system that seeks to synthesize Hebb's neural assemblies, Piaget's schemas, and Sokolov's cognitive reflexes. It focuses on modeling mechanisms that are active during the first two years of human development-corresponding to Piaget's Sensorimotor sub-stages. 35 Building-block elements, intended to approximate Piaget schemas and Hebb cell assemblies, are defined as neural structures that reliably produce a particular spatial and temporal firing pattern given a corresponding pattern of stimulation. The key dynamic of the system is characterized as "an ever continuing, ever changing and expanding circular reaction with the environment." Circular reactions are visualized as loops connecting input elements through reflex links to output elements to objects in the environment and back to input elements. The basic schema structure consists of an input element linked to an output element where each represents activations of particular sensory receptors and motor effectors respectively. Activated elements are said to reverberate. Initial circular reactions are entirely instinctual and reflexive 36 . Over time, as a result of experience, additional elements form, become more interlinked, and may exist independently from input and output elements ("tight little knots of mutually interconnected assemblies") enabling more complex behaviors and cognitive capabilities (e.g., memories, chains of thoughts, separation of goals from means). The main mechanism for constructing more complex elements is the linking together of lower-level elements that reverberate at the same time. 37 Drescher (1989, p. 201) cites Cunningham (1972) as the inspiration for his own work. Cunningham and Gray (1974) present an implementation based on (Cunningham 1972). They describe a computer simulation of an infant vocal tract capable of generating outputs based on sensations from rudimentary audio, kinesthetic, and proprioceptive inputs. They claim their system achieved learning spanning Piaget's first three sensorimotor sub-stages and speculate the model could be adapted to achieve sub-stage four.

Michael Arbib embraces constructivist principles in his computational neuroscience and AI research. In (Arbib 1972) he writes, "The animal perceives its environment to the extent that it is prepared to interact with it. … Perception of an object generally involves the gaining of access to 'programs' for controlling interaction with the object, rather than simply generating a 'name' for the object." He argues that brain models and AI implementations should be distributed, action-oriented, and layered, and such models consist of perceptual and motor programs. Arbib's (1981) analysis of visuomotor coordination in frogs 35 Cunningham, closely following Piaget, summarized the 6 sub-stages as: (I) reflex exercise, beginning from birth, (II) primary circular reactions, beginning in second week, (III) secondary circular reactions, beginning in fourth month, (IV) familiar procedures in new situations, beginning in eight month, (V) active experimentation, beginning in eleventh month, (VI) mental recombinations, beginning in second year. 36 Circular reactions are like central pattern generators (CPGs), i.e., "biological neural circuits that produce rhythmic outputs in the absence of rhythmic input" (Wikipedia, https://en.wikipedia.org/wiki/Central_pattern_generator) and innate behavior patterns (Witkowski 1997). 37 Cunningham gives an example of a hand sucking behavior learned as a conjunction of a previously learned arm flexion element occurring simultaneously (initially by chance) with a previous sucking reflex element.

(Rana computatrix) motivates a proposal for assemblages of perceptual and motor schemas to constitute an "animal's internal representation of the world." Arbib and Hesse's (1986) "The Construction of Reality" influenced Arbib's view of cognitive models as EvoDevoSocio constructions (Arbib 2018), therein formulating social schemas as constructed realities that encode mental building blocks of societies. 38 Arbib (1989) updates (Arbib 1972) with "programs" rechristened as "schemas" and schema theory described in more detail. Arbib (1992) summarizes schema theory-noting historical precedents, key architectural elements, and experimental findings. Arbib (2018) provides more information about schema theory, including a discussion of Draper et al.'s (1989) schema implementation for the VISIONS system and collaborations with Corbacho on schema-based learning. Corbacho (1997) describes schema-learning mechanisms of tuning, construction, and active learning. Weitzenfeld et al. (1998) present a neural-based schema architecture that builds on Arbib's work and utilizes an abstract schema language to integrate neural networks into schemas. Corbacho (2019) specifies a self-constructive AI framework that constructs predictive schemas, dual (inverse model) schemas, and goal schemas-each embodying a different behavior and communicating using input ports, output ports, and variable mappings. Arbib (2021) crystallizes his earlier work summarizing schemas as interacting functional units organized as networks of basic motor schemas and perceptual schemas that are instantiated as multiple instances and activated cooperatively using bottom-up (data-driven) and top-down (task-driven) signals to elicit appropriate behaviors (e.g., object recognition, motor actions). Explicit executive control is not needed. New schemas may form as assemblages of old schemas, be adaptively tuned, and become primitives.

Joseph Becker (1973) details the JCM model for encoding experiential information. He provides an example of a schema 39 as [Sensation 1 -> Action 1 -> Action 2 => Sensation 2 ] where if Sensation 1 is sensed, Action 1 and Action 2 may be executed in sequence to elicit Sensation 2 . More generally, conditions (contexts) and actions on the left side of the Big Arrow (=>) result in (predict) sensations on the right side. Sensation and action elements, called kernels, are n-tuples of nodes representing features of the environment. The kernels on the left side of the Big Arrow constitute an antecedent event. Those on the right constitute a consequent event. Nodes are atomic primitives equivalent to concepts. The first node in a kernel indicates its "type" and the other nodes represent parameters associated with that type. Nodes are visualized as "nests" of two-way pointers linking schemas to each other, presumably one nest per concept. Witkowski (1997, pp. 51-53) describes modifications to JCM made in Mott's 1981 ALP system, including adding motivational kernels as a kind of intrinsic motivation for influencing agent goals by indicating conditions agents should seek (<HIGH>S) and avoid (<LOW>S) 40 . James Albus leveraged control theory, biology, neural networks, and more 41 to engineer hierarchical systems capable of learning from and reacting to the environment (Albus 2007). His theory of cerebellar function (Albus 1971) proposes how feedback loops between different types of cells in the cerebellum may coordinate motor commands with body positions. Albus et al. (1980) specifies a hierarchical control system consisting of functionally similar, interconnected modules each containing elements for sensory processing, predictive memory, and task decomposition capable of coordinating sensations and actions from raw sensory inputs through increasing levels of abstract behavior. A hierarchical factory control system is described with levels mapping to output signals, action primitives (e.g., velocity, position, force, torque), elemental moves (e.g., reach, grasp, move, release, insert, twist, lock, pull), simple tasks (e.g., fetch, mate, fasten), and finally complex tasks (e.g., assemble). A detailed outline for a theory of intelligence describing structural and process components (including learning mechanisms of repetition, reinforcement, and specific error correction) is presented in (Albus 1991). Subsequent multi-resolutional architectures consisting of similar hierarchies of repeating, interconnected, looping modules include a real-time control system (RCS) (Albus 1999), a 4-dimensional real-time control system (4D/RCS) (Albus and Barbera 2006), and a model of the human brain where "each cortical hypercolumn together with its underlying thalamic nuclei performs as a Cortical Computational Unit (CCU) consisting of a frame-like data structure (containing attributes, state, and pointers) plus the computational processes and mechanisms required to build and maintain it" (Albus 2008). The 4D/RCS was "designed to enable any level of intelligent behavior, up to and including human levels of performance in driving vehicles and coordinating tactical behaviors between autonomous air, ground, and amphibious vehicle systems" (Albus 2007). "At the lower echelons, the nodes generate goal-seeking reactive behavior. At higher echelons, they enable goal-defining deliberative behavior" (Albus and Barbera 2006).

William Powers' (1973) Perceptual Control Theory (PCT) 42 offers a constructivist AI framework based on control theory and the hypothesis that the purpose of behavior is to control perceptions. It posits a hierarchy of feedback loops similar to Piaget (1952), Cunningham (1972, and Albus (1980) 43 (and to back-propagation artificial neural networks and to other applications of control theory). He suggests "The entire hierarchy is organized around a single concept: control by means of adjusting reference signals for lower-order systems" (Powers 1973, p. 78). PCT treats agents as being completely self-contained control systems. Hierarchy levels span from intensity to sensation, configuration, transition, sequence, relationships, program control, principles, and system concepts (Vaniver 2015;Forssell 2016, p. 341). 44 Loops at the intensity level process input-output (IO) from sensors. Loops at the sensation level aggregate IOs from the intensity level. The hierarchy continues up through levels of increasing complexity and abstraction.

Ernst von Glasersfeld promoted radical constructivism-the principle that agents construct their reality (external world and selves) entirely through the interplay of sense data and motor signals (von Glasersfelds 1974). Von Glasersfeld (1984) describes radical constructivism as "a theory of knowledge in which knowledge does not reflect an 'objective' ontological reality, but exclusively an ordering and organization of a world constituted by our experience." Glasersfeld's main contributions to AI constructivism may be his interpretations and advocacy of the work of Piaget (von Glasersfeld 1974;von Glasersfeld 1982), Ceccato (von Glasersfeld 2001), Powers (Richards and von Glasersfeld 1979), and others. He was particularly aligned with Ceccato (1962), engaging in work on linguistics and machine translation that included the Multistore System (von Glasersfeld and Pisani 1970;von Glasersfeld 2001, p. 6). Multistore operationalized Ceccato's ideas by providing rapid matching of elements in service of correlational concept structures. Von Glasersfeld (1984, p. 12) likens assimilation to judging the sameness of objects and experiences due to shared attributes and he suggests accommodation occurs when attributes are identified that distinguish objects and experiences from one another. 45 He further notes the starting point for perception is when things are isolated as "bounded, unitary objects in the total field of … experience." Klahr and Wallace (1976) proposed a production system 46 for implementing an information-processing view of cognitive development inspired by Piaget and psychological experiments. The goal was to "formulate precise models of performance of the organism at two different levels of development, and then to formulate a mechanism for the transition or developmental mechanisms" (p. ix). They focused on the domain of quantitative comparison (QC)-building a series of models that progressively added and adapted production rules consistent with Piagetian staged development. Constituent concepts included class inclusion (CI), conservation of quantity (CON), and transitivity of quantity (TRAN), which emerge from basic productions (operators) of subitizing (Qs), counting (Qc), and estimating (Qe). In the complete model, productions and production systems representing values, attributes, objects, relations, and 42 Not to be confused with Kelly's Personal Construct Theory. 43 Albus and Powers do not appear to have collaborated. However, both published articles about their work in the June 1979 issue of Byte magazine where Albus (1979, p. 10) wrote "The brain is first and foremost a control system" and Powers (1979, p. 132): "The key concept behind this revolution [in understanding the nature of all living systems] is control theory." 44 Forssell (2016) provides a comprehensive summary of PCT. 45 Von Glasersfeld (1984) uses the terms elements, properties, and components rather than attributes. 46 Production systems contain rules of the form Conditions -> Actions where Conditions are percepts that trigger the associated Actions.

procedures accumulate in long-term memory and are processed in short-term memories when activated by sensory input or other productions. Schemas develop in order of consistent sequences, common sequences, individual rules, individual productions, production subsystems (operators), and production systems 47 . They are organized in a hierarchy of 3 tiers each containing multiple levels, which determine the search order of the productions. Higher tiered/leveled productions, which are more specific, are searched before lower ones, which are more general. Innate productions exist at every tier and provide the basic mechanisms for concept construction. They include productions for detecting consistent sequences, transforming common sequences into rules, doing low-level visual and audio encoding, and processing goals. The authors provide "crude starting point" proposals for detecting consistent sequences and transforming sequences into rules (pp. 204 -207) but such productions were not implemented. The implemented models relied on hand-coded productions. The BAIRN system described by Wallace et al. (1987) leveraged production system elements into an architecture further suited to constructivist learning. It represented knowledge (schemas) as a network of nodes in long-term memory, each representing a feature of the world using several production rules (i.e., definition list) and information about the node's connectivity within the network (p. 365, Fig. 8.1). Nodes are highly interconnected such that, "each element in the condition and action of a production is semantically defined at a node elsewhere in the network" (p. 363). Short-term memory structures are used for sensoriperceptual buffering and semantic processing. Adaptation occurs via processes of node creation, node combination, redundancy elimination, and node modification. Other innovations included "a limited amount of distributed parallel processing and an explicit treatment of consciousness, motivation and emotion" (p. 359) 48 . As in their previous work (Klahr and Wallace 1976), the QC domain was used to develop and test the system. Other ideas about using production systems for modeling (or implementing) constructivist systems, with closer ties to Piaget, are described by Richard Young (1973, 1974) and Margaret Boden (1978. Rodney Brooks' (1986) subsumption architecture may be characterized as having constructivist elements. Schemas correspond to Brooks' finite state machines (implemented as LISP modules) that exchange short messages and are connected in a hierarchy of levels of competence. Adaptation is supported by suppression and inhibition signals that allow modules at different levels to override other modules' inputs and outputs. Brooks' approach has a nativist character with modules custom-engineered for specific functions 49 . Eight levels of competence suggest staged development-with the lower levels "built" prior to, and supporting, the upper ones. Brooks' (1986, p. 16) levels are: 0) Avoid contact with objects (whether the objects move or are stationary).

1) Wander aimlessly around without hitting things.

2) "Explore" the world by seeing places in the distance that look reachable and heading for them.

3) Build a map of the environment and plan routes from one place to another. 4) Notice changes in the "static" environment.

5) Reason about the world in terms of identifiable objects and perform tasks related to certain objects.

6) Formulate and execute plans that involve changing the state of the world in some desirable way.

7) Reason about the behavior of objects in the world and modify plans accordingly.

Wei-Min Shen (1989Shen ( , 1994 articulates constructivist AI principles in his work on autonomous learning from the environment. Shen (1989) defines learning as "the process of inferring the laws of the environment that allow the learner to solve problems." Shen (1994) states, "Intelligent behavior of any creature, animals or machines alike, is ultimately rooted in its physical abilities to perceive and act in its environment … Every concept or idea of [the] system must eventually have meaning in terms of [its] actions and percepts." He formalizes such systems as consisting of model applicator and model abstractor algorithms under control of an integration loop. The applicator selects actions based on agent goals and predicts new environmental states based on the system's internal (mental) models. The abstractor constructs and revises the models as needed. More generally, models are expressed as a six-tuple (A,P,S,φ,θ,t) where "A is the set of basic actions, P is the set of percepts, S is a set of model states (the internal representation of experience), φ is a state transition function S × A → S that maps a state and an action to the next state, θ is an appearance function that maps states to observations S → 2P (2P denotes the power set of P), and t is the current model state of M." Models are built using m-constructors (e.g., =, ∧, ∃, +, *). Percepts can be numeric values, objects, features, functions, or relations. Environments are viewed as black boxes represented by triples (Σ, ρ, ∆), where "Σ is a set of inputs, ∆ is a set of outputs, and ρ is the environmental mapping function that governs the mapping from the current input to the output." Environments have their own internal logic and can be manipulated by multiple agents.

After discussing various types of environments, models, and learning techniques, Shen (1994) describes the LIVE system that implements the algorithm:

Repeat 1 Generate a new goal or a new experiment (based on the current model); 2

While the goal or experiment is not accomplished: 3

Generate a prediction sequence for achieving the goals or experiment, 4

Execute the actions in the prediction sequence, 5

Perceive information from the environment, 6

If there is a prediction failure, 7 then find the difference between a success and the failure, 8

If some difference is found, 9

then call CDL to improve the current model, 10 else call CDL+1-like algorithms to create new features or variables.

The CDL (complementary discrimination learning) algorithm learns by modifying previously learned models when actions yield perceptions that do not match model predictions. Shen calls CDL a predictsurprise-identify-revise procedure-anticipating "surprise" as a trigger for making model adjustment in subsequent work such as ( Barto et al. 2004;Ranasinghe and Shen 2008;Schmidhuber 2010;Faraji et al. 2016). CDL is shown to learn Boolean concepts, decision lists, prediction rules, and finite automata. The main data structures in LIVE are prediction rules that map percepts and actions to changes in the environment. Each rule includes a summary of environmental conditions for a particular state (i.e., percepts), an action the system can take, the predicted change in the environment resulting from the action, and a sibling rule 50 . The rules are characterized by Shen as "c-a-p production rules with three components: conditions, actions, and prediction." CDL learns conjunctive and disjunctive concepts in an incremental manner via complementary discrimination, which performs rule generalization and specialization concurrently using rules and their logical complements. The CDL+1 component can create new features (i.e., rule terms) "that are beyond the scope of the initial perception description language." 51 LIVE environments explored in (Shen 1989) include a hidden-rule Tower of Hanoi environment, child development Balance Beam experiments, and Mendel's pea-hybridization experiments where the system showed "some encouraging results" in each case.

Building on their previous work in psychology and neurobiology (Quartz 1993;Quartz and Sejnowski 1994), Quartz and Sejnowski (1997) summarize evidence for neural constructivism, which enables constructive learning to occur in brains whereby "the representational properties of cortex are built [progressively] by the nature of the problem domain confronting it." This allows learning to occur in animals through interactions with external environments while not overly relying on innate, specialized, evolutionarily programmed circuits as suggested by nativist and selectionist theories. Their main arguments focus on brain structure changes that occur during cognitive skill acquisition, specifically: changes in synaptic numbers, axonal arborization, and dendritic arborization. Other evidence cited for neural constructivism includes: extensive and protracted postnatal cortical development (occurring well beyond the first two years of life in humans), environmental effects on ocular dominance column development, learning-theoretic models supporting effective incremental learning over time (e.g., Leslie Valiant's PAC), the metabolic efficiency of generating brain structure "as needed" versus retracting unnecessary structure, and neural plasticity in adults (p. 581). Their descriptions of neural constructivism share many characteristics with machine learning practice such as features, feature spaces, clustering, correlated activity, sampling mechanisms, and hierarchical representations-affording potential insights into AI structures and algorithms. Algorithmically, Quartz and Sejnowski (1997, p. 553) suggest: "The general strategy of constructivist learning is this. Rather than start with a large network as a guess about the class of target concepts, avoid the difficulties associated with overparameterized networks by starting with a small network. The learning algorithm then adds appropriate structure according to some performance criterion and where it is required until a desired error rate is achieved." 52 Further discussion about neural constructivism can be found in ).

Mark Ring (1994) introduces and explores continual learning, which focuses on constructivist principles of hierarchical development, unlimited behavior duration, intelligent behavior acquisition, incremental learning, and autonomous behavior. Temporal Transition Hierarchies (TTH) are described which are two-layer neural networks that automatically learn a probabilistic hierarchy of events (sensation-action sequences) based on actions taken by an autonomous agent exploring an environment. Primitive units representing atomic sensations and actions can be combined into sequences of sensations and actions to form higher-level units that are incrementally added to the network. Connection weights between units are adjusted to account for different contexts experienced by the agent. The system is evaluated using environments consisting of simple mazes, the Reber grammar, and the Mozer "gap" task. An agent capable of Continual, Hierarchical, Incremental Learning and Development (CHILD) is introduced that combines TTH with Q-learning. In (Ring 2011), Recurrent Transition Hierarchies (RTHs) are introduced as an improvement over TTH that add recurrent connections to the network to allow an agent to continually learn arbitrary temporal contingencies. Schaul and Ring (2013), show General Value Functions (GVFs) (aka "forecasts"), which are extensions of Sutton's options framework , are particularly effective constructivist learning algorithms, superior to Predictive State Representations (PSRs), Temporal Difference (TD) Networks, and TTH with regard to generalization and other properties desirable for continual learning. 51 Shen points out that new features must be present when existing features cannot discriminate between distinct outcomes (e.g., when different classifications are made despite all existing feature values being the same). Such creation of new features is sometimes called constructive induction, automatic feature discovery/engineering/generation or discovering hidden features-essentially what artificial neural networks do by default. 52 They cite the following "impressive work" on constructivist learners: Azimi-Sadjadi et al. (1993), Fahlman & Lebiere (1990), Frean (1990), Hirose et al. (1991), Kadirkamanathan & Niranjan (1993), Platt (1991), Shin & Ghosh (1995), Shultz et al. (1994), and Wynne-Jones (1993). Subject methods include Cascade-Correlation (CasCor), the upstart algorithm, RAN/GaRBF networks, Ridge Polynomial Networks, and node splitting. Foner and Maes (1994) extend Drescher (1991) to make schema formation more efficient using focus of attention mechanisms. One mechanism, perceptual selectivity, "restricts the set of sensor data the agent attends to at a particular instant." Another, cognitive selectivity, "restricts the set of internal structures that is updated at a particular instant." Perceptual selectivity relies on spatial and temporal coherence to prune out non-causal inputs. Cognitive selectivity relies on context and goals to prune inapplicable schemas ("facts").

Work by Cangelosi, Schlesinger, and colleagues from their developmental robotics perspective includes Schlesinger (1994) on neural constructivism; Cangelosi and Parisi (1998) (2020) on computational models of development classified as connectionist, dynamic field theory-based, rule-based, and Bayesian. In addition to SOMs per , they used Recurrent Neural Networks (esp. Jordan Networks) to integrate linguistic, visual, and proprioceptive inputs for grounded concept learning Stramandinoli et al. 2017). Cangelosi and Schlesinger's (2015) book on developmental robotics is a rich source of information about constructivist AI that describes work in developmental psychology that can inform agent development. Six "experiment-focused" chapters look at relevant psychological models and experiments grouped into topics of: novelty, curiosity, and surprise; perceptual development; motor development; social learning; language; and abstract knowledge. Appendix A herein summarizes topics, keywords, and references covered in that book.

Sandra Marshall (1995), inspired by the psychology of Bartlett (1932) and of Piaget, and the AI formalisms of Rumelhart, Minsky, and Schank (i.e., schemas, frames, and scripts), focuses on schemas, which she defines as:

A vehicle of memory, allowing organization of an individual's similar experiences in such a way that the individual • can easily recognize additional experiences that are also similar, discriminating between these and ones that are dissimilar; • can access a generic framework that contains the essential elements of all of these similar experiences, including verbal and nonverbal components; • can draw inferences, make estimates, create goals, and develop plans using the framework; and • can utilize skills, procedures, or rules as needed when faced with a problem for which this particular framework is relevant. (Marshall SP 1995, p. 39) Accordingly, each schema contains four types of knowledge: identification knowledge, elaboration knowledge, planning knowledge, and execution knowledge. Marshall SP (1995, pp. 377 -390) presents a hybrid model where a schema consists of one connectionist network and three production systems 55 . 53 This work explores the idea that assimilation and adaptation of motion schemas (i.e., "movement primitives") can progressively build a repertoire of sophisticated motor abilities. Degrees of freedom of motion become enabled gradually (or are "frozen") to limit the search space and develop schemas suitable for chaining. 54 They also discuss using Echo State Networks as dynamic reservoirs in ERA units to better address temporal and nonlinear relationships. 55 It is instructive to note similarities between Marshall SP (1995) and Klahr and Wallace (1976). Both describe hybrid models that use production system and connectionist elements. Both were strongly influenced by Piaget and developmental psychology literature and focused on arithmetic concept domains.

Identification knowledge uses a neural net classifier (the connectionist network) 56 to recognize the type of experience (problem or situation) at hand. Once recognized, relevant input from the environment is parsed into clause encodings containing information-like owner, object, and time-appropriate for executing rules contained in the production systems. The four components are connected via a blackboard where inputs, outputs, and queries are shared to allow situations to be parsed, evaluated, and action taken using knowledge specific to each schema. The identification network can iterate on current situation data to refine the assessment of the best matching situation, thus determining which productions are activated. Beyond suggesting that identification networks can be learned using backward propagation, Marshall does not address schema learning (adaptation). Production system components were manually programmed to handle the elaboration, planning, and execution appropriate for each schema. Marshall alludes to staged development in describing a hierarchy of levels progressing from microfeatures, to single knowledge components, to a full schema, to collections of schemas (p. 392).

Mark Witkowski, working with Bond and Mott (1981), leveraged Becker's (1973) constructive approach in developing the Mark IV Robot. Witkowski (1997) proposes a Dynamic Expectancy Model (DEM) that provides "a novel form of learning by reinforcement," which uses expectancies (predictions, micro-or μhypotheses) to control agent learning via μ-experiments. Influenced by animal behavior literature, the DEM accounts for both innate and learned capabilities. Witkowski (1997), particularly inspired by Tolman (1932Tolman ( , 1948 and MacCorquodale and Meehl (1953), builds on the implementations of Becker (1973), Bond and Mott (1981), and Drescher (1991). DEM processing is described as "a low level version of a scientific discovery process" (Witkowski 1997, p. 58)-reminiscent of Kelly (1955) and Shen (1984). μ-hypotheses are the basic units of learning (i.e., schemas). They are reinforced or extinguished over time based on the success or failure of their predictions. Sensory inputs are processed into tokens, which are incorporated into constructs called signs and sign sets. Internal symbols can cause the output of actions and compound actions. Adaptation processes include creation, corroboration, reinforcement, differentiation, and forgetting of μ-hypotheses. The model was implemented using the SRS/E algorithm, which generated Dynamic Policy Maps (DPMs) and operated similarly to Sutton's (1990) Dyna-Q. SRS/E stands for "Stimulus-Response-Stimulus/Expectancy" to reflect the key elements of each μhypothesis: the current state or context (Sign1) of the agent, an action (Response1) the agent can take, and a consequent state (Sign2) resulting from the action. Schemas are encoded using seven interrelated lists comprising: input tokens, signs denoting environmental states, responses, behaviors, goals, hypotheses, and predictions. The hypothesis list is used to construct DPMs. The lists are initialized to reflect the agent's innate capabilities (i.e., the ethogram) (Witkowski 1997, p. 57) and are continually adjusted thereafter to account for learning and other changes to the agent. SRS/E was shown to perform well on latent learning and place learning tasks. Witkowski (2007) proposes an action-selection calculus specifying three ways states can be connected to actions; five rules for how actions, signs, and predictions are updated; and four rules for how learning occurs. It claims to unify the five classic learning theories: stimulus-response behaviorism, associationism, classical conditioning, operant conditioning, and Tolman's sign-learning model.

Daniel Wolpert and colleagues focused on biological motor control and motor learning. Wolpert et al. (1995) present a Kalman filter model consistent with cerebellar function that combines a forward model that predicts motor states with a sensory output model that predicts sensory feedback and together reliably estimate the effects of motor commands.  examine various cerebellar learning models and conclude, "The cerebellum contains multiple pairs of corresponding forward and inverse models 57 , each instantiated within a microzone 58 ". The modules (schemas) also include a responsibility 56 The neural net was a 3-layer feedforward network with 27 input nodes, 14 hidden units, and 5 output nodes. Each problem was coded as 27 binary features used to classify 5 arithmetic problem types: Change, Group, Compare, Restate, Vary. The clause encodings and rules for the production systems were engineered for this domain. 57 Forward models "mimic the causal flow of a process by predicting its next state (for example, position and velocity) given the current state and the motor command." Inverse models "invert the causal flow by estimating the motor command that caused a particular state transition." (Wolpert et al. 1995) 58 Microzones are attributed to be the basic functional units of the cerebellum (Oscarsson 1979; De Zeeuw 2021).

detector that works in concert with the forward model to coordinate appropriate activation of multiple modules for effecting composite behaviors. Wolpert et al. (2011) summarize components, processes, and representations suitable for motor learning. Components determine how information extraction from the environment occurs (e.g., what elements are fixated on versus filtered out, how processing delays and noise are accounted for), what decisions and strategies are appropriate for executing given tasks (i.e., resolving interactions between sensorimotor, perceptual, and cognitive components), and how different classes of control contribute to generating appropriate motion sequences (i.e., predictive control, reactive control, and biomechanical control). Processes enabling motor learning include error-based learning (i.e., dynamically correcting for mismatches between goal states and actual states), reinforcement learning (e.g., using reward signals to drive actions), use-dependent learning (i.e., habituation), and observational learning (i.e., learning by observing others). Representations suitable for motor learning are characterized as being mechanistic or normative models. The former tend to be built from motor primitives (primitive schemas), which combine together using generalization functions. The latter tend to rely on credit assignment mechanisms (e.g., Bayesian analysis) to calculate how multiple underlying causes determine actions. McNamee and Wolpert (2019) provide a unifying account on how the brain may employ internal models for motor control using Bayesian inference and optimal feedback control. (1998), Moore (1989, 1997), and others to develop robots capable of learning motor behaviors using imitation and social perception. Demiris and Hayes (1996) present a biologically inspired architecture for imitative learning consisting of modules for visual preprocessing, proprioceptive analysis, relationship establishment, movement analysis, and movement matching. Per the architecture, an imitator visually collects posture data from a demonstrator and proprioceptively reproduces the motions it perceives in itself. Demiris and Hayes (2002) present a modular, dual-route architecture for motion learning that combines active and passive imitation. Each module, operating in parallel, pairs a previously learned behavior (inverse model) with a forward model to attempt to match demonstrated behaviors. The forward models simulate (imagine) the demonstrated behavior, predict the next observed states, and generate an error signal to indicate how well the actual next states matches the prediction. Errors accrue as a confidence factor for each behavior, which enables the imitator to determine the best-matching behavior. If no demonstrated behavior is matched with high confidence, a new schema is generated via passive imitation as described in (Demiris and Hayes 1996). The architecture was tested using simulated robots performing arm movements conforming to the international standard semaphore code. 59 Demiris and Khadhouri's (2006) HAMMER architecture arranges the modules (schemas) from (Demiris and Hayes 2002) into distributed hierarchies to enable complex and abstract behaviors to arise from more primitive behaviors. It relies on a top-down control of attention mechanism to determine what state information to collect from the environment that is appropriate for each schema. The forward model components determine what information is required to run the forward model simulations and that data is then used to drive the inverse model components. Experiments were conducted where an imitator perceived an action performed by a demonstrator and executed the best matching behavior from a set of eight previously programmed behaviors. Behaviors (forward models), represented as Baysian networks, can be learned using motor babbling as described in .


## Yiannis Demiris leveraged Wolpert and Kawato

Joshua Tenenbaum (1999) proposes a Bayesian framework for concept learning that supports learning from few or many examples, thus uniting similarity-and rule-oriented generalization 60 . It represents early work using Bayesian methods to understand human intelligence and build intelligent machines. Kemp and Tenenbaum (2008) describe a Bayesian model that discovers forms and structures for representing environmental data. They promote the view that different knowledge representations (schemas/models) are needed for different types of knowledge. Learnable forms include partitions, chains, orders, rings, hierarchies, trees, grids, and cylinders. Tenenbaum et al. (2011) discuss how "abstract knowledge encoded in a probabilistic generative model" can serve to constrain a hierarchy of models to more quickly achieve learning and induction. The authors suggest Hierarchical Bayesian models may be able to learn framework theories in key domains like intuitive physics, psychology, and biology, and lead to an answer to the (constructivist) question: "How can domain-general mechanisms of learning and representation build domain-specific systems of knowledge?" Ullman and Tenenbaum (2020) argue for harmonizing cognitive development and computational modeling to answer key questions underpinning constructivist AI. They discuss how hierarchical Bayesian models can account for learning in infancy and childhood by leveraging core knowledge about objects, agents, space, and time in infancy and building intuitive theories during childhood. They suggest implementing knowledge and theories as probabilistic generative programs. Like Kelly (1995), Shen (1989), and Witkowski (1997), they liken learning to naïve science: a (Bayesian) process where an agent hypothesizes representations (models) of the environment that are then assessed, refined-and maybe discarded-over time. They introduce a "child as hacker" metaphor likening learning agents to software developers, discussed in (Rule et al. 2020). Although Tenenbaum might balk at being called a constructivist 61 , his approach is aligned with AI constructivism and draws heavily on cognitive and developmental psychology research.

Juyang  promoted AI constructivism as a "new field" called Autonomous Cognitive Development citing Weng et al.'s (1999) robotic Self-organizing, Autonomous, Incremental Learner (SAIL) as a prototype embodying key constructivist principles. SAIL was engineered to learn representations and architectures through self-exploration and human teaching, enabling the robot to autonomously navigate unknown, unconstrained environments and to recognize and reach for objects. Motor movements were learned primarily by a trainer physically manipulating the robot to associate sensory input states with appropriate motor outputs. External reinforcement by human trainers pressing "good" or "bad" buttons and intrinsic reinforcement provided through a value system were also used (Huang and Weng 2002). Agent state consisted of sensor readings recursively convolved with resampled versions of themselves to account for different temporal contexts. These states were mapped to motor values using an Incremental Hierarchical Discriminating Regression (IHDR) tree algorithm Weng and Hwang 2007). IHDR is claimed to unify classification and regression 62 and (1) Handle high dimensional inputs, (2) Perform one-shot learning, (3) Dynamically adapt to increasing complexity, (4) Avoid getting stuck in local minima, (5) Operate incrementally, (6) Effectively maintain long term memory, and (7) Is suitable for real-time operation (W&H 2007, p. 3). IHDR maintains clusters of inputs (x-clusters) linked to associated outputs (y-clusters) at nodes of an oblique decision tree. 63 For each input-output sample (x i , y i ), y i is used to find the closest y-cluster via Euclidean distance. The identified y-cluster indicates which x-cluster sample (x i , y i ) belongs to. x i and y i are then used to update the statistics of their corresponding clusters. (If a y i value is not provided, the x i vector is used to find the "best" y to output from a tree leaf.) Child nodes are spawned (or searched) when finer granularity in input-output mapping is required as indicated by the statistical match of the current sample to each xcluster. Discriminating feature subspaces are calculated using the centers of x-clusters to determine which child nodes should be searched-thus focusing on the most discriminating features in x i for the current sample. IHDR is claimed to model the brain's associative cortex (i.e., the area between the primary sensory cortex and motor cortex) wherein layers represent different cortical layers, nodes represent cortical patches, and clusters represent neurons (W&H 2007, p. 24).

IHDR trees may be construed as schemas, with node levels corresponding to stages of development and x-and y-cluster constructs within nodes providing fine-grained structure. The learning (adaptation) algorithms are provided by eight procedures detailed in (W&H 2007). Schemas (trees) are further organized into levels where the lowest level encodes innate behaviors (e.g., visual motion detection and tracking). Such schemas can be learned offline using IHDR operating as a "prenatal learning process." Higher-level schemas incorporate progressively more temporal context and are learned (online) through interaction with the environment. Learned behaviors have priority over innate behaviors and are overridden by innate behaviors if an adequate learned behavior does not exist. (In general, the behavior having the highest confidence of being correct is executed.) In a more comprehensive architecture, Weng and Hwang (2006, Fig 4) describe stackable modules consisting of a sensor-to-effector mapper, stored context prototypes, a value controller, an attention selector, a motor mapper, and a delay mapper.  (2002) presents a neural schema mechanism to transform Drescher's (1991) constructivist system into more of a connectionist network. The mechanism defines item nodes to represent states of the environment, action nodes to represent actions that can be taken by the agent, schema nodes to specify relationships between items and actions, and goal nodes to control node activations. Nodes are connected using context links, result links, action links, goal links, host links, and none links. Unlike typical neural networks, node activations depend on the node and link types, e.g., link weights are determined by values of relevance, reliability, correlation, and desirability. Schema nodes maintain statistics for determining which actions to select and control production of new nodes (i.e., spin-off schemas, accommodation). An agent is said to be "conscious" of nodes that exceed a certain level of activation. "Conscious broadcasts" cause nodes related to those currently in the "spotlight" to increase activation potentials, which increase chances they cause an action to be selected so "an agent can discover new paths to a solution or goal state." McCauley implements and evaluates the system using Russell and Norvig's (1995) Wumpus World.

Jeff Hawkins (2004) does not focus on childhood development nor cite Piaget but subscribes to constructivist principles in his efforts to build intelligent machines:

• "The senses create patterns that are sent to the cortex, and processed by the same cortical algorithm to create a model of the world (p. 44)."

• "When you are born, your cortex essentially doesn't know anything. … All this information, the structure of the world, has to be learned (p. 111)."

• " [We] have to train the memory system much as we teach children. Over repetitive training sessions, our intelligent machine will build a model of its world as seen through its senses (p. 141)."

Persistent themes in Hawkins' work include a focus on the human neocortex as the seat of intelligence (Hawkins 2004), sequence learning and prediction as keys to cognition (Hawkins 2004;Hawkins and Ahmad 2016), cortical columns running a common algorithm as the essential processing units (Hawkins 2004;Hawkins et al. 2017b), use of sparse distributed representations for information coding and processing (Hawkins 2004;Ahmad and Scheinkman 2019;Numenta 2021a), and utilizing world models and reference frames for constructing intelligent agents (e.g., grid cells and allocentric representations) (Lewis et al. 2019; Klukas et al. 2020;Hawkins 2021;Lewis 2021).

Hawkins ' (2004) memory-prediction framework proposes a hierarchical auto-associative memory that stores sensorimotor sequences using invariant feature representations. That memory is used to predict what occurs next in newly encountered sequences. Signals flow up and down sensorimotor hierarchies to affect pattern learning, recognition, and behavior 64 . The basic learning functions are identified as classification formation and sensorimotor sequence construction and are roughly mapped to the mammalian cortex, hippocampus, and thalamus. Hawkins provides examples of human learning and suggests how the model may accommodate them, including visual saccades and fixation, language and music understanding, memory, environment navigation, and sensorimotor control of various forms. In young brains, Hawkins suggests memories are stored higher up in the cortical hierarchy and are thus slower to react than mature brains since "it takes time for the neural signals to travel up and down." He further notes young brains have "not yet formed complex sequences at the top and therefore cannot recognize and play back complex patterns." As the brain gains experience, it re-forms memory representations further down in the hierarchy which "frees up the top for learning more subtle, more complex relationships."

The memory-prediction framework was implemented as the Hierarchical Temporal Memory (HTM) model (Wikipedia, Memory-prediction framework; Hawkins et al. 2017a;Hole and Ahmad 2021). The first generation focused on spatial and temporal pooling of input patterns for learning, and probabilistic pattern matching for inference. Cortical learning algorithms (CLAs) formed the core of secondgeneration HTM implementations. CLAs more closely modeled layers and mini-columns of the cerebral cortex, accounting for the formation and decay of synapses. Key elements of this generation of HTM included sparse distributed representations (SDRs) 65 , a spatial pooling algorithm, and a sequence memory algorithm. A later generation of HTMs added a theory of sensorimotor inference that proposed "cortical columns at every level of the hierarchy can learn complete models of objects over time and features are learned at specific locations on objects" (Wikipedia, Hierarchical temporal memory). HTMs utilize sensorimotor feedback signals, feed forward signals, and context signals. Hawkins notes HTM networks need not integrate motor control-rather, they can learn to predict changes in the environment from sensory sequences occurring in the environment independently of any actions by the sensing agent. The latest incarnation of the work-the Thousand Brains Theory-posits "the brain uses maplike structures to build a model of the world-not just one model, but tens of thousands of models of everything we know" (Numenta 2021b).

Kristinn Thorisson (2012) takes a system-level view of AI constructivism, deprecating what he calls constructionism in favor of constructivism. The former is characterized as "systems whose gross architecture is mostly designed from the top-down and programmed by hand." He claims to take Drescher (1989) a step further by requiring an AGI architecture automatically grows from seeds and takes into account factors of "temporal grounding, feedback loops, pan-architectural pattern matching, small whitebox components, and architecture meta-programming and integration" (Thorisson 2012, pp. 160-161). Key elements of Thorisson's view were implemented in the Autocatalytic Endogenous Reflective Architecture (AERA) (Nivel et al. 2013;Nivel et al. 2014a). In AERA, schemas (models) consist of left-hand (LH) patterns, right-hand (RH) patterns, and guard equations. LH patterns are said to predict (also produce or cause) associated RH patterns. Patterns consist of sets of features (facts, states, concepts) sensed from or acting upon the environment. For example, an LH pattern might be ("A is_bus", "A has_color yellow", "A bears_number 19", "A bears_license_plate_number SX445") and an associated RH pattern might be ("A stops_at city_university") 66 . Guard equations assign values to variables between RH and 64 Roughly, expectation signals flow down the hierarchy and are compared with sensorimotor signals that flow up. 65 SDRs are the main knowledge representations in the HTM model. They are large sparse binary vectors where each bit, corresponding to a different neuron, represents a different learned feature. SDRs with similar bit patterns are semantically similar. "HTM theory defines how to create, store, and recall SDRs and sequences of SDRs." 66 This example was paraphrased from (Nivel 2013, p. 13). In (Nivel et al. 2013, p. 33 LH patterns based on the kind of reasoning being done. Deductive reasoning from causes (LH) to predictions (RH) uses forward chaining. Abductive reasoning from goals (RH) to causes (LH) uses backward chaining (Nivel et al. 2013, p. 14). Both occur simultaneously. The LH-RH schema structure is also used to represent discrete facts known by the agent. Some schemas are innate 67 but most are learned and are retained if they make successful predictions (confirmed from acting on the environment). Nivel et al. (2013, p. 24) write, "Model acquisition is triggered by either the unpredicted success of a goal or the failure of a prediction." Piagetian-like assimilation and accommodation (abstraction) is supported whereby "a new model is copied from the original model and differences between values held by the conflicting evidences are represented by variables introduced in the new model" (Nivel et al. 2013, p. 20). Sequences of schemas are chained to form more complex schemas and can be "compressed" to form more compact schemas. An executive program provides the inference engine that computes predictions and goals, creates and manages models, focuses attention, manages resources, and performs other functions. Promising results were achieved in experiments where an AI called S1 learned conversational speech and body movements by observing humans (Nivel et al. 2013, pp. 35-51). The initial AERA incarnation relied on learning by observation. Michael S. P. Miller (2013a, 2013b draws directly on Piaget's later work (Piaget 1977(Piaget , 1985 in specifying his Piagetian Modeler (a.k.a. Piagetian Autonomous Modeler). Piaget-defined processes of observation, coordination, reflection, and consolidation comprise the Piagetian Modeler's main functional units. Each unit (pattern) is decomposed into subpatterns-yielding a full-featured cognitive architecture consisting of many diverse specialized modules. Schemas are networks of memory elements called neural propositions organized collaterally and hierarchically to encode models of the world. Biologically, Miller claims elements of a neural proposition map to the axon, soma, and dendrites of a neuron. Logically, neural propositions are "cognitive containers" called schemes (also coordinations) that are affirmed or negated using markers and have 1 to n links to other schemes 68 . Scheme types include internal, external, and inference schemes. Internal and external schemes represent (link to) internal and external observables at the lowest level of the cognitive hierarchy, i.e., propriocepts and exterocepts respectively. Inference schemes link to internal and external schemes and to other inference schemes at increasingly higher levels of the hierarchy (also forming sequences). Each inference scheme represents a feature, action, event, situation, episode, concept, hypothesis, goal, or other mental element learned by the agent. Miller operationalizes other terminology from Piaget including subsystems 69 , actions, circular reactions, operations, groups, and totality. Schemas are learned through assimilation and accommodation acting upon schemes. Implementation details and experimental results are forthcoming.

Maria Hedblom and collaborators (Hedblom et al. 2015;Hedblom 2018) formalized Lakoff-Johnson image schemas as families (sets) of interlinked theories that could be used for constructing new concepts via conceptual blending (Fauconnier and Turner 1998) and for facilitating symbol grounding. In (Hedblom et al. 2015) they use the DOL language of Mossakowski et al. (2013) 70 and Common Logic (ISO/IEC 24707) for encoding image schemas-leveraging formal ontologies to represent agent knowledge. They focus on schemas related to path following and containment and show how low-level schemas like MOVEMENT_OF_OBJECT, MOVEMENT_ALONG_PATH, MOVE-MENT_IN_LOOPS, REVOLVING_MOVEMENT, and CLOSED_PATH_MOVEMENT can combine and specialize through the addition of features (spatial primitives) like PATH, START_PATH, END_PATH, FOCAL_POINT, and LANDMARK (Hedblom et al. 2015, Fig. 2). Primitive schemas were hand coded, not learned. Concept construction (learning) was investigated as a higher-level blending of schemas. A Common Logic sample for encoding the MOVEMENT_OF_OBJECT schema is:  o))))) 71 Hedblom et al. (2015) describe how image schemas related to path following can lead to concepts like "stream of consciousness," "train of thought," and "line of reasoning" using conceptual blending. They show how the concept THRILLER can emerge from concepts of STORY and ROLLER_COASTER which both share aspects of the more primitive schema SOURCE_PATH_GOAL. In (Hedblom 2018), a Two-Object schema family is presented that encompasses schemas CONTACT, SUPPORT, and LINK, which inherit from schemas VERTICALITY and ATTRACTION. The Image Schema Logic (ISL FOL ) language is introduced for representing image schemas, which leverages Region Connection Calculus (RCC) 72 , Qualitative Trajectory Calculus, and Linear Temporal Logic. Hedblom et al. (2021) suggest ISL FOL may be used to improve robot performance in unfamiliar environments by facilitating reasoning about functional relations, enabling reasoning about alternatives to a plan, increasing adaptability through analogy, and improving natural language understanding. Examples of ISL FOL for encoding MOVEMENT_OF_OBJECT and MOVEMENT_ALONG_PATH schemas from (Hedblom 2018) are: Aguilar andPerez y Perez (2015, 2017), working in the field of computational creativity, present a computational model called Developmental Engagement-Reflection (Dev E-R) that approximates Piaget's assimilation and accommodation processes. In (Aguilar and Perez y Perez 2015), they model visual development for a simple agent in a virtual 3D world. Endowed with monocular color vision and an ability to move its head in 9 front-facing directions, the agent develops the ability to recognize a multitude of color and size concepts from an initial capacity to recognize 3 color luminosities (red, green, blue) and 2 sizes (big and small). Learning occurs through repeated exposures to objects in the environment. In the case of colors, a count of each primitive color feature is incremented each time the feature is observed. The color is recognized as a salient feature when it reaches a threshold count. That feature is then used as the basis for recognizing new colors by distinguishing (and counting) lighter and darker versions observed in the environment. A similar process generates size concepts. Starting with recognizing a distinction between big (B) and small (S) stimuli, and counting such occurrences, finer grain size features emerge based on repeated exposure to new size stimuli (e.g., B2, B3, S2, S3). Object recognition emerges by biasing the agent to attend to stimuli that move, have bright colors, are novel, and are otherwise affective, i.e., elicit pleasure, displeasure, surprise, or cognitive curiosity.
∀O:Object �(MOVEMENT_OF_OBJECT(O) ↔ Move(O))� ∀O:Object, ∀P:Path (MOVEMENT_ALONG_PATH(O, P) ↔ Move(O) ∧ CONTACT(O, P) U(¬(Move(O) ∨ CONTACT(O, P))))
Once created, features are available for agent contexts and schemas. Contexts are memory structures containing: (1) features of the object at the current center of attention of the agent, (2) affective responses associated with the object, and (3) the agent's current expectations for feature change (if the context is a current-context). Schemas are either basic or developed. Basic schemas encode innate behaviors using context and associated action elements. Developed schemas encode behaviors learned through environmental interaction. They have the same structure as basic schemas but add an expected context element. The engagement-reflection process creates and maintains schemas. Engagement attempts to match cur-71 Note this schema uses OBJECT, MOVEMENT, and HAS_TRAJECTOR primitives. 72 RCC defines 8 relationships between spatial regions: disconnected (DC), externally connected (EC), equal (EQ), partially overlapping (PO), tangential proper part (TPP), tangential proper part inverse (TPPi), non-tangential proper part (NTPP), and non-tangential proper part inverse (NTPPi). rent contexts with contexts in stored schemas. If a suitable match is found and the associated action defined in the schema generates the expected result, the agent is in cognitive equilibrium and the selected schema is considered stable. If a suitable context match is not found, the agent is considered to be in disequilibrium and a reflection (accommodation) process occurs using generalization or differentiation to modify an existing schema or create new ones. Schemas are distinguished by how many specific (instantiated) context features they have. Those with more instantiated features are more concrete. Those with fewer instantiated features are more general. Schemas were generated that allowed an agent to attend to pleasurable objects in its environment. Aguilar and Perez y Perez (2017) extend the system to include tactile capabilities, i.e., hand movements, grasping, and touch sensing of object contact and textures. 73 They report that the agent learned schemas that allowed it to visually follow its own hand movements and coordinate reactions to visual and tactile stimuli. Unsupervised Representation Learning (CURL) that learns tasks (concepts) without task or class labels using a mixture-of-Gaussians latent space, dynamic expansion, and mixture regenerative replay; Groth et al. (2021) on SelMo-a (self-motivated) system that acquires and retains skills through optimized, curiosity-based, off-policy exploration of its environment; and Jaegle et al. (2021) on Perceiver IO which adds a cross-attention mechanism to the Perceiver (Transformers) model to produce a system that scales linearly with multiple inputs (e.g., images, audio, natural language) and multiple outputs (e.g., text prediction, image classification, optical flow fields, audiovisual sequences) and may hold promise as a general purpose neural network architecture. Piloto et al. (2022) present the PLATO model (for Physics Learning through Auto-encoding and Tracking Objects) that learns the intuitive physics concepts of solidity, object persistence, continuity, unchangeableness, and directional inertia from synthetic video data.

Constructivist-oriented work by Vicarious 74 includes:  and Vicarious (2017a) describe Schema Networks, inspired by Drescher (1991), which learn causal relationships and reusable concepts from sensory data. Schema Networks rely on object instances (entities) and associated attributes extracted from videos to predict attribute changes due to environmental actions. Schemas consist of entity-attribute and action variables logically connected to future entity-attribute states 75 . Multiple schemas are combined into a Schema Network capable of probabilistically predicting entity-attribute changes in a Markov Decision Process (MDP) framework. "Breakout" video game variations are used as learning and testing environments. The authors report (model-based) Schema Networks are superior to the model-free Asynchronous Advantage Actor-Critic (A3C) algorithm and Progressive Networks with respect to training efficiency, zero-shot generalization, robustness, and learning transfer.  describe generative models for visual object recognition using Recursive Cortical Networks (RCNs). In this work, RCNs are used to understand letterforms in a general purpose "common 73 Sensed features were {color, size, movement, position} for vision and {texture, hand_open_or_closed} for touch. 74 https://www.vicarious.com/science/. Vicarious was acquired by Alphabet in 2022 and folded into its Intrinsic subsidiary. Their original goal was to create generally intelligent systems. 75 Logical connections are comprised of conjunctions, disjunctions, and "self transitions." sense" way by modeling objects as a combination of contours and surfaces via a network of features, pooling nodes, and lateral connections. The authors used RCNs to solve text-based CAPTCHAs 76 in 2013. RCNs build on ideas used in other compositional models to create structured probabilistic graphical models amenable to inference using Belief Propagation. Characterized as providing scaffolding versus being a tabula rasa approach (Vicarious 2017c), the system is engineered to prioritize and distinguish (factorize) contour and surface features. This enables RCNs to be trained using orders of magnitude fewer examples than other neural networks. Unlike convolutional neural network CAPTCHA breakers, training data are clean examples of letters from representative fonts, as opposed to large sets of distorted examples. Stone et al. (2017) and Vicarious (2017b) propose a method for improving object recognition in computer vision applications using convolutional neural networks (CNNs) by understanding the compositionality of a scene. Understanding compositionality entails the ability to learn and recognize objects and parts of objects in a decomposable, reusable manner. By masking out distinct objects that exist in close spatial proximity 77 , they "encourage networks to form representations that disentangle objects from their surroundings and from each other"-a property not provided by current CNNs. They found no negative effects on performance from filtering out context information for the medium-to large-sized objects they tested and claim their method "is a step towards making CNN-based representations more amenable to explicit context modeling through an external mechanism (by cleanly separating the representation of objects from their context)." Hay et al. (2018) and Vicarious (2018) address learning abstract concepts called Sensorimotor Contingencies (SMCs) through interacting with the environment. Whereas Schema Networks ) are networks of entities and attributes linked by state transition probabilities, SMCs are small programs that encode perception-action sequences as hierarchies of concepts similar to the options of   78 . Some SMCs are action-focused ("bring-about SMCs") and others observation-focused ("classification SMCs"). A curriculum consisting of positive and negative examples of concepts are generated and used by human trainers in a 2D "PixelWorld" to facilitate concept learning in a hierarchical, layered manner. Exemplary concepts include containment, object, objects that are containers, pushability, being on top, and object number (i.e., being to the left of two objects). Pushability, for example, is built on six layers of lower level concepts. SMCs are invoked as functions that return a binary value indicating success or failure.

Other recent work from Vicarious includes: Lavin et al. (2018) on how reasoning about visual scenes learned using RCNs    2021) on a query training (QT) method for learning probabilistic graphical models (PGMs) with paired inference algorithms to yield state-of-the-art results in applications like masked image region completion, learning full 76 "Completely Automated Public Turing test to tell Computers and Humans Apart," commonly implemented using distorted or obfuscated characters to prevent non-human access to Web resources. 77 This is technically accomplished by adding a loss term ("novel cost function") to the CNN that balances two feature maps: "one obtained from masking the input, and another derived from applying a mask in the feature space." 78 In the Conclusion section of Vicarious (2018), it is suggested SMCs and Semantic Networks may be productively combined where schema networks "would allow the agent to have an internal representation of the external world that it can use for simulation and planning." 79 These results included: subjective contours, neon color spreading, occlusion versus detection, and the border-ownership competition phenomenon. The reasoning method used was approximate Bayesian inference via loopy belief propagation. parameterization of grid-arranged Markov random fields, recognizing digits from noisy images, and other classification tasks.  Klahr and Wallace 1976;Ring 1994;Cohen PR et al. 1996;Guerin 2008a;Mao et al. 2015;Lake et al. 2016;Hutson 2018;Kwon 2018 Continuous learning Continual learning Lifelong learning Never-ending learning Cumulative learning Ring 1994 80 ;Thrun and Mitchell 1995 81 ;Ring et al. 2011;Chen Z and Liu 2016;Fei et al. 2016;DARPA 2017;Kirkpatrick et al. 2017;Mankowitz et al. 2018;Mitchell et al. 2018;Schwarz et al. 2018 Cognitive architecture Computational models Hierarchical Temporal Memory Biologically inspired cognitive architecture Biological and machine intelligence Newell 1973;Anderson and Kline 1977;Albus 1991Albus , 1999Schlesinger and McMurray 2012;Hawkins 2004Hawkins , 2017Samsonovich 2010;Laird et al. 2017;Kotseruba and Tsotsos 2020 Concept learning Concept formation Surprise-based learning Gennari et al. 1989;Fisher et al. 1991;Tenenbaum 1999;Barto et al. 2004;Ranasinghe and Shen 2008;Jia et al. 2013;Celikkanat et al. 2015b;MacLellan et al. 2016;Higgins I et al. 2017 Knowledge bases Ontologies Learning to learn Meta-learning Thrun and Pratt 1998;Schaul and Schmidhuber 2010;Lake 2016;Finn et al. 2017;Frans et al. 2017;Wang JX et al. 2017;Al-Shedivat et al. 2017;Rusu et al. 2018 Reinforcement learning Deep reinforcement learning Model-based reinforcement learning Intrinsically motivated learning Sutton 1988;Barto et al. 2004;Oudeyer et al. 2007; Baldassarre and Mirolli 2013;Christiano et al. 2017;Arulkumaran et al. 2017;Weber et al. 2018;Sutton and Barto 2018 Model building Program induction Lake et al. 2016


# Related Topics

Incremental learning Online learning Nonstationary learning Gennari et al. 1989;Shen 1997;Utgoff and Stracuzzi 2002;Ditzler et al. 2015; Kuipers and Beeson 2002;Stober and Kuipers 2008;Dupoux 2016 One-shot learning Zero-shot learning Few-shot learning Zero-shot generalization Cunningham 1972; Fei-Fei et al. 2006;Palatucci et al. 2009;Norouzi et al. 2014;Koch et al. 2015;Santoro et al. 2016;Ravi and Larochelle 2017;Duan et al. 2017;Vinyals et al. 2017;Rusu et al. 2018 Active learning Cohn et al. 1996 Friesen and Rao 2010;Chalodhorn and Rao 2010;Chung et al. 2014;Niekum et al. 2014;Nivel et al. 2014a;Duan et al. 2017 Bottom-up learning Sun and Zhang 2004 Embodied cognition Grounded cognition Agent-based approach Lakoff and Johnson 1980;Schlesinger and Parisi 2001;Hedblom et al. 2015;Hedblom 2018 Computational Creativity Cohen LM 1989;Aguilar and Perez y Perez 2015, 2017Artificial Life Computational Autopoiesis Cellular Automata 82 Gardner 1970Wolfram 1984;McMullen and Varela 1997  Many other methods may be found in a constructivist AI toolkit. Shen (1994, section 3.4) suggests: function approximation, function optimization, classification and clustering, inductive inference and system identification, learning finite state machines and hidden Markov models, dynamic systems and chaos, problem solving and decision making, reinforcement learning, adaptive control, and developmental psychology. Appendix A lists dozens of other relevant topics from developmental psychology, neurobiology, and other disciplines.


# Toward a General-Purpose Concept Learner

The author is pursuing AI constructivist development inspired by Piaget and informed by those surveyed in this paper. The goal is to engineer components capable of creating and maintaining memory structures (schemas) that enable agents to continually develop and refine knowledge and skills through interactions with their physical and social environments. Mechanisms supporting assimilation, accommodation, and staged development are being defined. The mechanisms are intended to enable cognitive development characteristic of lower animals through superhuman intelligences as a function of available resources and specified drives and goals. An eventual goal of this work is to configure an "infant bootstrap" agent that achieves human developmental milestones when provided with humanlike sensors and effectors and immersed in humanlike environments.

The initial focus is on generating and maintaining semantic and episodic memory structures that support concept and skill learning. Concepts are represented as knowledge schemas stored in semantic memory. Skills are represented as sensorimotor schemas stored in episodic memory. These are seen as necessary (but not sufficient) elements of a full-featured cognitive architecture.

Semantic memory will contain an ever-growing network of features/concepts 83 parsed from sensory and sensorimotor input streams using a General-Purpose Concept Learner (GPCL). Episodic memory will store episodes such as: (1) "Raw" sensory and sensorimotor episodes from which extracted features are derived (i.e., training cases), (2) Generalized scripts derived from similar (assimilated) episodes spanning a full range of agent skills (e.g., <grasping>, <subitizing>, <language processing>, <navigating>, <grocery shopping>, <logical reasoning>), 84 and (3) Episodes imagined by the agent (e.g., narratives). Episodes and extracted features will be linked to facilitate grounding, reasoning, retraining, and creative thought. Stored episodes will be available for replay so additional features can be extracted based on subsequent learning and so alternate focuses of attention can be applied.

Concept and skill development will occur concurrently, complimentarily, and continuously. Learning will be driven by intrinsic and extrinsic reinforcement and generally occur in an incremental and layered manner, resulting in a gradually accumulated hierarchy of concepts and skills. However, concepts and skills can emerge top-down as well as bottom-up. In the bottom-up case, they emerge from primitive features extracted from instances identified in episodes. For example, instances of seeing one's mother will induce a concept <my mother> (via assimilation) and, later, the categorical concept of <mothers> may emerge from examples of other instances and types of mothers (via accommodation). In the top-down case, more general concepts are introduced and serve as seeds to facilitate acquisition of lower-level concepts. Such higher-level concepts may be learned primarily through watching, imitating, and receiving external reinforcement from other agents. For example, in humans, concepts of <letters>, <words>, and <reading> are learned through interactions with parents before acquiring concepts of individual letters and words and the skill of reading. In non-human animals, concepts of <stalking>, <eluding>, and <hid-ing>, likely acquired by watching and interacting with other agents, precede the acquisition of specific techniques and skills related (subordinate) to <stalking>, <eluding>, and <hiding>. Such higher-level concepts enable and motivate agents to "fill in the gaps" in the wider conceptual areas. Table 6.1 provides a simple example of knowledge schema labels at various levels of a knowledge hierarchy corresponding to six sensorimotor channels-from low-to high-level concepts. Each label represents a class consisting of a network of features parsed from and linked to episodes. Concepts and skills that persist (become reified) in semantic and episodic memory are those that prove most useful for subsequent reasoning and prediction. Other concepts and skills can be generated and forgotten on the fly in service of processing immediate sensorimotor inputs/outputs. Two key factors determining what features are learned are: (a) The biases (motivations) included in the learning algorithm and innate schemas (e.g., pain avoidance/pleasure attainment, survival, reproduction, discovering new concepts (curiosity), pleasing other agents, etc.), and (b) The order and nature of experienced episodes (i.e., curriculum learning). Persistent objects <move_arm> <grasp> <close> <far away> <nice_thing> <caregiver> <my mother> <containment> <pathway> <my dog> <joes dog> <crawling> <powerful being> <happy> <sad> <I did good> <I did bad> <funny> <left> <right> <forward> <back> <up> <down> <subitizing> <estimating> <smart phone> <using smart phone> <somersault> <reading> <back flip> <skiing> <counting> <comparing size> <addition> <subtraction> <mothers> <motherhood> <dogs> <parent> <god> <arithmetic> <sharing> <ownership> <cooperation> <competition> <empathy> <multiplying> <dividing> <measuring with stick> <playing chess> <glenn gould> <bachs art of the fugue> <art of the fugue performed by glenn gould> <mathematics> <logic> <democracy> <freedom> <physics> <chemistry> <biology> <liberal arts> <natural selection> <supervised learning> <unsupervised learning> <reinforcement learning> <set theory> <ai constructivism> <philosophy> <existentialism> <quantum mechanics> <big history> <cosmology> Concepts exist separate from language. Agents that intrinsically have or can learn language skills get a great cognitive boost from the ability to associate symbols with concepts. Words allow concepts to be introduced by "teachers" (i.e., assigned class labels) and skills acquired without the agent needing to be explicitly shown or experience the skill. Once associated with a concept, words serve as just another predictive feature linked to underlying schema concepts. Features that are learned subconsciously may later be accessed consciously, symbolically labeled (named), and used in creating new schemas. For example, <green patch> or <left loop> features discovered in doing visual object recognition could be named later and leveraged for additional concept formation.

As another example, an agent may learn the concept <wooly texture> (unconsciously) as a byproduct of learning the concepts <sheep>, <alpaca>, and <labradoodle> before learning the word "wooly" and (consciously) associating it with <wooly texture>. A dog may master the action <chew up master's fuzzy slippers> before learning <bad dog> and "bad dog" (simultaneously). When the dog later executes the action <defecate in master's sleeping area>, the <bad dog> concept quickly assimilates the new concept into the <bad dog> concept upon hearing and experiencing the master's "bad dog" reaction. An example of word learning occurring before concept learning may be illustrated by the word "quantum mechanics" being introduced to an agent before the agent has knowledge of the concept <quantum mechanics>. As concepts associated with <quantum mechanics> are taught, the agent builds the concept of <quantum mechanics> into a network of other concepts. One might think of semantic memory as constituted by Large Concept Models with one or more Large Language Models overlaid/integrated therein.

The GPCL framework presumes motor control is not strictly necessary for concept development. Much can be learned from purely sensory inputs given suitable innate concepts and (mental) skills 85 --say, an innate skill for doing object detection for example. One imagines an Intelligent Traffic Camera that can learn concepts about vehicles, environmental conditions, and other objects and actions just through appropriate parsing of its video input-without needing physical panning and zoom capabilities. This allows knowledge schemas to be developed without implementing (or simulating) motor controls. Companion sensorimotor schemas can be used and developed without needing the integrated motor aspects (a.k.a. sensory schemas or cognitive skills). That is, purely sensory streams (movies) consisting of one or more of video, audio, touch, taste, and olfaction, can be effectively parsed to yield significant levels of cognition. GPCL focuses on learning knowledge schemas and does not currently intend to implement sensorimotor learning 86 .

Although it draws on developmental psychology and cognitive neuroscience, the GPCL approach is AIoriented and leverages basic machine learning principles. Specifically, it plans to implement a hybrid of supervised and unsupervised learning (classification and clustering) driven by intrinsic and extrinsic reinforcement. It does not set out to model actual biological mechanisms. The memory structures and learning algorithms must support a practically unlimited number of episodes and concepts-as is the case in biological brains.


## Appendix A: Cangelosi and Schlesinger (2015) Topics, Keywords, and References

The following table summarizes topics and references covered in Cangelosi and Schlesinger's (2015) book Developmental Robotics: From Babies to Robots. It reflects work in developmental psychology and developmental robotics that was (mostly) not covered in this survey.  James 1890;Piaget 1952;Fantz 1956;Gibson and Walk 1960;Charlesworth 1969;Campos et al. 1970;Gallup 1970;Maurer and Salapatek 1976;Meltzoff and Moore 1977;Acredolo 1978;Lewis and Brooks-Gunn 1979;Meltzoff and Borton 1979;Acredolo and Evans 1980;Haith 1980;Maurer and Barrera 1981;Marr 1982;Acredolo et al. 1984;Bahrick and Watson 1985;Gibson 1986;Kestenbaum et al. 1987;Kermoian and Campos 1988;Bushnell IWR et al. 1989;Spelke 1990;Ballard 1991;Morton and Johnson 1991;Campos et al. 1992;Butterworth 1992;Bushnell EW and Boudreau 1993;Leinbach and Fagot 1993;van Leeuwen et al. 1994;Bahrick et al. 1996;Elman et al. 1996;Higgins C et al. 1996;Slater et al. 1996;Valenza et al. 1996;Adolph 1997;Hiraki et al. 1998;Rochat 1998;Asada et al. 1999;Greenough and Black 1999;Schlesinger and Langer 1999;Itti and Koch 2000;Bushnell IWR 2001;Meissner and Brigham 2001;Bednar and Miikkulainen 2002;Courage and Howe 2002;de Haan et al. 2002;Furl et al. 2002;Mareschal and Johnson 2002;Quinn et al. 2002;Rochat and Striano 2002;Bednar and Miikkulainen 2003;Cos-Aguilera et al. 2003;Johnson SP et al. 2003a;Johnson SP et al. 2003b;Chen Y and Weng 2004;Fitzpatrick and Arsenio 2004;Johnson SP 2004;Lovett and Scassellati 2004;Michel et al. 2004;Natale et al. 2005b;Stoytchev 2005;Amso and Johnson 2006;Fritz et al. 2006;Joh and Adolph 2006;Zhang and Lee 2006;Fuke et al. 2007;Sann and Streri 2007;Schlesinger and Parisi 2007;Fitzpatrick et al. 2008;Guerin and McKenzie 2008;Montesano et al. 2008;Stoytchev 2008;Sturm et al. 2008;Gold and Scassellati 2009;Kaipa et al. 2010;Franz and Triesch 2010;Chaudhuri 2011;Stoytchev 2011; Motor development (Ch. 5) learning motor skills, u-shaped development, motor babbling, body babbling, multiple sense integration, experience-expectant development, experience-dependent development, prereaching, pre-shaping, grasp development (palmar, scissors, radialdigital, pincer, mature pincer), locomotion development (pre-crawling, creeping, crawling, sideways cruising, frontward cruising, standing, walking) Field et al. 1983;Meltzoff and Moore 1983;Meltzoff 1988;Meltzoff and Moore 1989;Butterworth 1991;Butterworth and Jarrett 1991;Leslie 1994;Baron-Cohen 1995;Davies and Stone 1995;Fadiga et al. 1995;Meltzoff 1995;Demiris et al. 1997;Meltzoff and Moore 1997;Rizzolatti and Arbib 1998;Iacoboni et al. 1999;Nadel and Butterworth 1999;Scassellati 1999;Schaal 1999;Billard and Matarić 2001;Kozima and Yano 2001;Rizzolatti et al. 2001;Breazeal and Scassellati 2002; itation, collaboration/ cooperation, intention reading, goal prediction, theory of mind, self-recognition, AIM model, mirror neurons, MOSAIC model, HAMMER architecture, paired inverse-forward models, world model Call and Carpenter 2002;Demiris and Hayes 2002;Fasel et al. 2002;Nehaniv and Dautenhahn 2002;Demiris and Johnson 2003;Gergely 2003;Imai et al. 2003;Nagai et al. 2003b;Nagai et al. 2003b;Ude and Atkeson 2003;Carlson E and Triesch 2004;Ito and Tani 2004;Rizzolatti and Craighero 2004;Zöllner et al. 2004;Borenstein and Ruppin 2005;Demiris and Deardon 2005;Hafner and Kaplan 2005;Thomaz et al. 2005;Demiris and Khadhouri 2006;Demiris and Simmons 2006;Dominey et al. 2006;Ferrari et al. 2006;Hashimoto et al. 2006;Kaplan and Hafner 2006;Mavridis and Roy 2006;Nagai et al. 2006;Triesch et al. 2006;Meltzoff 2007;Nehaniv and Dautenhahn 2007;Rao et al. 2007;Tapus et al. 2007;Watanabe et al. 2007;Barsalou 2008;Call and Tomasello 2008;Demiris and Meltzoff 2008;Jasso et al. 2008;François et al. 2009a;François et al. 2009b;Gold and Scassellati 2009;Tomasello 2009;Kruger et al. 2010;Lallée et al. 2010;Dominey and Warneken 2011;Hafner and Schillaci 2011;Sarabia et al. 2011;Tanz 2011;Carlson T and Demiris 2012 Language development (Ch. 7) nature vs nurture, nativism vs empiricism, language acquisition device, grammaticalization, usage-based theory of language development, cognitive linguistic theories, symbol grounding, babbling, vocabulary spurt, verb islands, biases (reference, similarity, conventionality, wholeobject, whole-part juxtaposition, segmentation, taxonomic, mutual exclusivity, embodiment, social [Bahrick et al. 1996 


## Topics and keywords


,Cangelosi et al. (2007),,Morse and Cangelosi (2017) on developmental and agent-based language acquisition; Schlesinger et al. (2000) on constraint-based development of infant motor skills 53 ; Schlesinger and Parisi (2001) on online (real-time) sampling in agents that explore their environments; Morse et al. (2010b) on an Epigentic Robotics Architecture (ERA) where schemas ("basic ERA units") consist of Self-Organizing Maps (SOM) representing particular features of the environment (e.g., color, shape, body posture, word representations) connected to "hub" SOMs weighted using positive Hebbian learning 54 ; Cangelosi et al. (2000), Coventry et al. (2005), Cangelosi and Riga (2006), Marocco et al. (2010), Cangelosi (2010), Stramandinoli et al. (2012), Stramandinoli et al. (2017) on sensorimotor grounding of words and concepts; and Schlesinger


) the general form of a model (schema) is presented as "( ( 0, 1,..., , 0, 1), ( 0, 1,..., , 2, 3)) where and are variables representing arbitrary quantities, 0 and 1 are variables that define the time interval within which L holds, and 2 and 3 variables defining the time interval for R." In a 2013 lecture (AGI-13 Summer School -AERA 6), Nivel gives an example of a model where LT = robotic gripper move command with time and control parameters and RT = resulting gripper location with time parameters.

## Google
DeepMind research relevant to AI constructivism includes: Higgins I et al. (2016) on using a variational autoencoder (VAE) that learns disentangled features to mimic visual feature learning in humans; Battaglia et al. (2016) on an interaction network that decomposes environments into networks of objects and relations and reasons about them explicitly; Higgins I et al. (2017) on the Symbol-Concept Association Network (SCAN) that extends the VAE architecture to extract abstract concepts grounded in disentangled features from visual input, associate those concepts with symbols, and enable construction of novel concepts; Hill et al. (2017) on understanding grounded language learning in neural networks that link visual features (i.e., shapes, colors, patterns, shades, sizes) with words in a way that parallels human language acquisition; Rabinowitz et al. (2018) on using meta-learning to build a neural network (ToMnet) that learns Theory of Mind models for different species of agents; Rao et al. (2019) on Continual


can explain several well-known psychophysical and physiological results 79 ; Lázaro-Gredilla et al. (2019) on concepts as cognitive programs that are learned from pairs of input-output images using a small set of primitive instructions (concepts, schemas) and run on a visual cognitive computer (VCC); Rikhye et al. (2020) on clone-structured cognitive graphs (CSCGs) for representing the environment and improving autonomous navigation by extending cloned hidden Markov models (HMMs) to include agent actions; Sawyer et al. (2020) on improving the cognitive program approach to concept learning (Lázaro-Gredilla et al. 2019) by adding human-inspired heuristics of object factorization and sub-goaling to accelerate program learning; Lázaro-Gredilla et al. (

## Table 5 .
51 lists topics related to constructivist AI. The topics are grouped together and ordered roughly by decreasing relevance.Topics 
References 
Constructivist AI 
AI constructivism 
Developmental robotics 
Autonomous mental development 
Cognitive and developmental systems 
Epigenetic robotics 
Cognitive robotics 
Computational approach to constructivism 
Autonomous learning 

See previous sections 

Learning like a child 
Learning like a baby 
Building a baby 
Learning like people 

Turing 1950; 

## Table 5 .
51. Topics related to constructivist AI.

## Table 6 .
61. Possible concepts in a knowledge hierarchy.


ReferencesNovelty, curiosity, and surprise (Ch.3) intrinsic motivation (IM),knowledgebased IM, competence-based IM, prediction-based IM, extrinsic motivation, internal motivation, effectance,  self-efficacy, contingency  perception, personal causation, self-determination theory, functional assimilation, dopamine release in mesolimbic pathway, frontal eye field activity, superior colliculus activation, exploratory behavior, novelty detection, moderate novelty principle, exogenous orienting, habituation-dishabituation, comparator theory, internal templates, visual expectation paradigm (VExP), anticipations, object permanence, spontane-ous play, reinforcement learning (RL), uncertainty motivation, informationgain motivation, predictive-novelty motivation, maximizing-incompetence motivation, learning-progress motivation; maximizing-competence progress, salience maps, options framework, actor-critic architecture Visual development (Ch.4) experience-expectant development, moderate novelty principle,architectural innateness, preferential looking,  habituation-dishabituation, intermodal contingencies, face recognition,  spatial perception, optic flow, egocentric-allocentric bias, self-perception,  mirror self-recognition, object recognition (texture, shape, common surfaces, perceptual completion, unity  perception), learning affordances, tool use, forward-inverse model


, central pattern generator (CPG), CPG models, exploration-tuningmastery, stiffness to fluidity, INFANT model, freezing degrees of freedom, speed-accuracy tradeoff, visuomotor mapping Social learning (Ch. 6) eye contact, joint attention, gestures (deictic, representational), gaze following (sensitivity, ecological, geometrical, and representational stages), pointing (imperative, declarative), im-


cognition), Modi experiment, linguistically enabled synthetic agent (LESA), phoneme-syllabic-lexical layer models, epigenetic robotics architecture, fluid construction grammar (FCG), semantic compositionality Abstract knowledge (Ch. 8) Cognitive computational models, embodied robotic models, number cognition, set discrimination, cardinality principles, order/item irrelevance principles, number directionality, embodied number cognition effects (size and distance, SNARC, Posner-SNARC, context and function, subitizing (1-3), gesture and finger counting), entity concept, concrete-toabstract pathway, abstract words and symbols, mode of acquisition (MoA), function words, negation concepts, linguistic generativity, symbol grounding transfer, representations for decision-making, internal simulations, ISAC architecture, iCub architecture, other cognitivist/ emergentist/ hybrid architectures (25+ mentioned)


] L. E.Bahrick, L. Moss, and C. Fadil, Development of Visual Self-Recognition in Infancy, in Ecological  Psychology, 8(3): 189-208, 1996.    [Bakker andSchmidhuber 2004]  Bram Bakker and Juergen Schmidhuber, Hierarchical reinforcement learning based on subgoal discovery and subpolicy specialization, in Proceedings of the 8th Conference on Intelligent Autonomous Systems,IAS-8, 438-445, Princeton University Press, 2004, ftp://ftp.idsia.ch/pub/juergen/bakker_HRL_IAS2004.pdf. [Baldassarre 2011] G. Baldassarre, What Are Intrinsic Motivations? A Biological Perspective, paper presented at the 2011 IEEE International Conference on Development and Learning (ICDL), Frankfurt Biotechnology Innovation Center, Frankfurt, Germany, August 24-27, 2011.[Baldassarre andMirolli 2013] Gianluca Baldassarre and Marco Mirolli (eds.), Intrinsically Motivated Learning in Natural and Artificial Systems, Springer, Berlin, Heidelberg, 2013. [Baldwin J 1895] James Mark Baldwin, Mental Development in the Child and the Race: Methods and Processes, MacMillan and Co., 1895, https://www.google.com/books/edition/Mental_Development_in_the_Child_and_the/BS84AAAAMAAJ?hl=en&gbpv=1 &printsec=frontcover. [Baldwin D 1993] D. A. Baldwin, Early Referential Understanding-Infants Ability to Recognize Referential Acts for What They Are, in Developmental Psychology, 29(5)(Sept.): 832-843, 1993. [Baldwin and Meyer 2008] D. Baldwin and M. Meyer, How Inherently Social Is Language?, in Blackwell Handbook of Language Development, ed. Erika Hoff and Marilyn Shatz, 87-106, Oxford, UK: Blackwell Publishing, 2008. [Ballard 1991] D. H. Ballard, Animate Vision, in Artificial Intelligence, 48(1)(Feb.): 57-86, 1991. [Bandura 1986] A. Bandura, Social Foundations of Thought and Action: A Social Cognitive Theory, Englewood Cliffs, NJ: Prentice Hall, 1986. [Barborica and Ferrera 2004] A. Barborica and V. P. Ferrera, Modification of Saccades Evoked by Stimulation of Frontal Eye Field during Invisible Target Tracking, in Journal of Neuroscience, 24(13)(Mar.): 3260-3267, 2004. [Baron-Cohen 1995] S. Baron-Cohen, Mindblindness: An Essay on Autism and Theory of Mind, Cambridge, MA: MIT Press, 1995. [Barrett 1999] M. Barrett, The Development of Language (Studies in Developmental Psychology), New York: Psychology Press, 1999. [Barsalou 1999] L. W. Barsalou, Perceptual Symbol Systems, in Behavioral and Brain Sciences, 22(4)(Aug.): 577-609, 1999. [Barsalou 2008] L. W. Barsalou, Grounded Cognition, in Annual Review of Psychology, 59: 617-645, 2008. [Barsalou and Wiemer-Hastings 2005] L. W. Barsalou and K. Wiemer-Hastings, Situating Abstract Concepts, in Grounding Cognition: The Role of Perception and Action in Memory, Language, and Thought, D. Pecher and R. Zwaan (eds.), 129-163, New York: Cambridge University Press, 2005. [Bartlett 1932] F. C. Bartlett, Remembering: A Study in Experimental and Social Psychology, Cambridge University Press, 1932. [Barto and Mahadevan 2003] Andrew G. Barto and Sridhar Mahadevan, Recent advances in hierarchical reinforcement learning, in Discrete Event Dynamic Systems, 13(4): 341-379, 2003, https://people.cs.umass.edu/~mahadeva/papers/hrl.pdf. [Barto et al. 2004] Andrew G. Barto, Satinder Singh, and Nuttapong Chentanez, Intrinsically motivated learning of hierarchical collections of skills, in Proceedings of International Conference on Developmental Learning (ICDL), 112-119, MIT Press, Cambridge, MA, 2004, https://web.eecs.umich.edu/~baveja/Papers/Barto-Singh-Chentanezfinal.pdf. [Barto et al. 2013] Andrew G. Barto, George Konidaris, and Christopher Vigorito, Behavioral hierarchy: exploration and representation, in Computational and Robotic Models of the Hierarchical Organization of Behavior, G. Baldassarre and M. Mirolli (eds.), 13 -46, Springer, 2013, http://irl.cs.duke.edu/pubs/bher.pdf. [Bates and Elman 1993] E. Bates and J. L. Elman, Connectionism and the Study of Change, in Brain Development and Cognition: A Reader, Mark Johnson (ed.), 623-642, Oxford, UK: Blackwell Publishers, 1993. [Battaglia et al. 2016] Peter W. Battaglia, Razvan Pascanu, Matthew Lai, Danilo Rezende, and Koray Kavukcuoglu, Interaction networks for learning about objects, relations and physics, in arXiv, 2016, https://arxiv.org/pdf/1612.00222.pdf. [Becker 1973] Joseph D. Becker, A model for the encoding of experiential information, in Schank and Colby (eds.), Computer Models of Thought and Language, 1973. [Bednar and Miikkulainen 2002] J. A. Bednar and R. Miikkulainen, Neonatal Learning of Faces: Environmental and Genetic Influences, paper presented at the 24th Annual Conference of the Cognitive Science Society, George Mason University, Fairfax, VA, August 7-10, 2002. [Bednar and Miikkulainen 2003] J. A. Bednar and R. Miikkulainen, Learning Innate Face Preferences, in Neural Computation, 15(7): 1525-1557, 2003. [Bengio et al. 2009] Yoshua Bengio, Jerome Louradour, Ronan Collobert, and Jason Weston, Curriculum learning, in Proceedings of the Twenty-sixth International Conference on Machine Learning (ICML09), L. Bottou and M. Littman (eds.), 41-48, Montreal: ACM, 2009, https://ronan.collobert.com/pub/matos/2009_curriculum_icml.pdf. [Berlyne 1960] D. E. Berlyne, Conflict, Arousal, and Curiosity, New York: McGraw-Hill, 1960. [Berrah et al. 1996] A.-R. Berrah, H. Glotin, R. Laboissière, P. Bessière, and L.-J. Boë, From Form to Formation of Phonetic Structures: An Evolutionary Computing Perspective, paper presented at the International Conference on Machine Learning, Workshop on Evolutionary Computing and Machine Learning, Bari, Italy, 1996. [Berthier 1996] N. E. Berthier, Learning to Reach: A Mathematical Model, in Developmental Psychology, 32(5)(Sept.): 811-823, 1996. [Berthier and Keen 2005] N. E. Berthier and R. Keen, Development of Reaching in Infancy, in Experimental Brain Research, 169(4)(Mar.): 507-518, 2005. [Berthier et al. 2001] N. E. Berthier, The Syntax of Human Infant Reaching, paper presented at the 8th International Conference on Complex Systems, Cambridge, MA, 2001. [Berthier et al. 2005] N. E. Berthier, M. T. Rosenstein, and A. G. Barto, Approximate Optimal Control as a Model for Motor Learning, in Psychological Review, 112(2)(Apr.): 329-346, 2005. [Berthier 2011] N. E. Berthier, The Syntax of Human Infant Reaching, paper presented at the 8th International Conference on Complex Systems, Cambridge, MA, 2011. [Berthouze and Lungarella 2004] L. Berthouze and M. Lungarella, Motor Skill Acquisition under Environmental Perturbations: On the Necessity of Alternate Freezing and Freeing of Degrees of Freedom, in Adaptive Behavior, 12(1): 47-64, 2004. [Billard and Matarić 2001] A. Billard and M. J. Matarić, Learning Human Arm Movements by Imitation: Evaluation of a Biologically Inspired Connectionist Architecture, in Robotics and Autonomous Systems, 37(2-3)(Nov.): 145-160, 2001. [Bisanz et al. 2005] H. Bisanz, J. L. Sherman, C. Rasmussen, and E. Ho, Development of Arithmetic Skills and Knowledge in Preschool Children, in Handbook of Mathematical Cognition, J. I. D. Campbell (ed.), 143-162, New York: Psychology Press, 2005. [Bjorklund and Pellegrini 2002] D. F. Bjorklund and A. D. Pellegrini, Evolutionary Developmental Psychology, Washington, DC: American Psychological Association, 2002. [Bloom L 1970] L. Bloom, Language Development; Form and Function in Emerging Grammars, Cambridge, MA: MIT Press, 1970. [Bloom L 1973] L. Bloom, One Word at a Time: The Use of Single Word Utterances before Syntax, Vol. 154, The Hague: Mouton, 1973. [Bloom P 2000] P. Bloom, How Children Learn the Meaning of Words, Cambridge, MA: MIT Press, 2000. [Boden 1978] Margaret A. Boden, Artificial Intelligence and Pigetian Theory, in Synthese, Automaton-Theoretical Foundations of Psychology and Biology, Part I, 38(3): 389-414, Jul. 1978. [Boeree 2006] C. George Boeree, George Kelly: 1905 -1967, in Personality Theories, e-book at https://webspace.ship.edu/cgboer/kelly.html. [Bond and Mott 1981] Alan H. Bond and David H. Mott, Learning of Sensori-Motor Schemas in a Mobile Robot, in Proceedings of International Joint Conference on Artificial Intelligence, Vancouver, 159-161, 1981, https://www.ijcai.org/Proceedings/81-1/Papers/032.pdf. [Bondu and Lemaire 2007] Alexis Bondu and Vincent Lemaire, Active learning using adaptive curiosity, in Proceedings of the Seventh International Conference on Epigenetic Robotics, 2007, http://alexisbondu.free.fr/blog/wpcontent/uploads/ICER2007.pdf. [Borchani et al. 2015] Hanen Borchani, Gherardo Varando, Concha Bielza, and Pedro Larrañaga, A survey on multi-output regression, in WIREs Data Mining and Knowledge Discovery, 5:216-233, 2015, doi: 10.1002/widm.1157. [Borenstein and Ruppin 2005] E. Borenstein and E. Ruppin, The Evolution of Imitation and Mirror Neurons in Adaptive Agents, in Cognitive Systems Research, 6(3)(Sept.): 229-242, 2005. [Borghi and Cimatti 2010] A. M. Borghi and F. Cimatti, Embodied Cognition and Beyond: Acting and Sensing the Body, in Neuropsychologia, 48(3)(Feb.): 763-773, 2010. [Borghi et al. 2011] A. M. Borghi, A. Flumini, F. Cimatti, D. Marocco, and C. Scorolli, Manipulating Objects and Telling Words: A Study on Concrete and Abstract Words Acquisition, in Frontiers in Psychology, 2(15): 1-14, 2011.
For more discussion about nativism versus constructivism see(Karmiloff-Smith 1992;Elman et al. 1996;Cangelosi and Schlesinger 2015;Hutson 2018). 2 "The intelligence of a machine that could successfully perform any intellectual task that a human being can" (Wikipedia, Artificial general intelligence).
Bakker and Schmidhuber use the notation: os for start state observations, og for goal state observations, π for policies (action sequences), and r for rewards, each with an L or H superscript indicating whether they are low-level or high-level.12  The ISL description inSt. Amant et al. (2006) specifies three types of interacting schemas: static, dynamic, and action schemas. It appears static schemas are object-oriented-like objects. Dynamic schemas involve dynamic maps as sketched inRosenstein et al. (1997). Action schemas add the state machine representation aspect.
Arbib (2018) cites "The Law," "Presbyterianism," or "The English Language" as examples of social schemas. These might also be characterized as socially codified concepts. 39 Becker (1973) did not associate his schemas withPiaget.  40  See also(Bond and Mott 1981)  describing this work applied to the Mark IV Experimental Robot, a.k.a. "Mr Cube." 41 "Our proposed reference model architecture accommodates concepts from artificial intelligence, control theory, image understanding, signal processing, and decision theory"(Albus and Meystel 2001).
The authors do not use the term schema. They state, "The process-structure distinction made by Piaget does not figure in our developmental theory" and "Piaget's structures are replaced by production systems" (p. 189). Also, they rely on the term equilibration to characterize Piaget-like adaptation and do not refer to accommodation or assimilation in a Piagetian sense.48  The ACT-R(Anderson and Kline 1977) and SOAR(Laird et al. 1986) cognitive architectures, which, like BAIRN, originated at Carnegie Mellon University, are also production systems based, but much less constructivist given they were designed top-down to cognitively model adults. In the Preface to(Laird et al., 1986), Newell notes SOAR had roots in the Instructible Production System (IPS), which had a goal of being a production system that was "grown, not programmed." General learning mechanisms of chunking and weak methods/subgoaling were added later to facilitate constructive learning.49  The architecture might be extendible to allow modules to be constructively learned, but such methods are not specified or obvious from the paper.
A sibling rule is a rule that shares actions with the current rule but makes different predictions.
See https://en.wikipedia.org/wiki/Flag_semaphore.60  Tenenbaum defines the rule-oriented approach as "hypothesis testing in a constrained space of possible rules" and the similarity-oriented approach as "computing similarity to the observed examples"(Tenenbaum 1999, p. 2).
References to Piaget are mostly absent in his work.Tenenbaum et al. (2011) characterize "constructivism" (and "theory theory") as "less formal approaches to describing the growing minds of children." For an analysis of synergies between probabilistic models and Piaget's work see(Tourman, 2016). Learning as a form rational Bayesian inference has also been explored as rational constructivism. See(Xu F et al., 2012).62  Weng and Hwang (2007, p. 4) define regression as a task "similar to the corresponding classification one, except that the class label li is replaced by a vector yi in the output space." This differs from more typical definitions of regression where a vector input yields a scalar output. (See https://en.wikipedia.org/wiki/Regression_analysis.) The composition of "y-clusters" is unclear. In their main use case of robot motor control, Weng appears to consider an output vector to be a temporal sequence of values of one output variable-not a vector of different output variables. Multi-output regression(Borchani et al.  2015)  and multi-output learning(Xu D et al. 2019) are more typical of what is meant by regressing to vector outputs.63  Oblique trees use multiple input features for node splits.
Innate schemas consist of "a small seed, containing … "drives" (i.e., mission goals and constraints) and a relatively small amount of knowledge to bootstrap learning"(Nivel et al. 2014b, p. 2).68  This summary relies on introductory material in (Miller 2018) that supersedes(Miller 2013a(Miller  , 2013b.69  Subsystem is synonymous with schema inPiaget and Miller's descriptions.  70  The Distributed Ontology, Modelling and Specification Language (DOL), aims at providing a unified meta language for handling multiple ontology languages such as OWL, RDF, OBO, Common Logic, and F-logic.
These topics relate to discovering and implementing simple rules that combine to enable complex behaviors-consistent with constructivist AI schemas and staged development.
Features are used to induce concepts, which themselves are concepts induced from other features. "It's concepts all the way down." 84 Thus episodic memory doubles as procedural memory suitable for encoding common procedures and plans. Elements in semantic and episodic memory are reified (i.e., persisted), in contrast to temporary versions that are processed in short-term memory during reasoning and other cognitive operations.
Innate concepts and skills may be provided by preconfigured knowledge and sensorimotor schemas. They are expected to provide the fundamental goals and drives (foundational concepts) that direct subsequent development. In biological agents, such concepts and skills are learned through evolution and activated postnatally by appropriate sensations. 86 This is not to suggest sensorimotor learning is less important. It simply reflects the development focus of this project. The work of others will be drawn on for sensorimotor schema learning such as circular operations, backward and forward models, and many other approaches noted in this paper. However, classes of powerful cognitive agents can likely be created that have minimal motor abilities and learn exclusively through sensory inputs.

. Harlow. Kish and AnonitisButlerHull 1943; Harlow 1950; Butler 1953; Kish and Anonitis 1956;

. R W White, Wetherford and Cohen. VinogradovaSmilanskyWhite RW 1959; Berlyne 1960; Sokolov 1963; Hunt 1965; de Charms 1968; Smilansky 1968; Hunt 1970; Kagan 1972; Wetherford and Cohen 1973; Vinogradova

. K W Fischer, Fischer KW 1980;

. Rovee-Collier, ; Sullivan, Haith, Bahrick and Watson. Ginsburg and OpperRovee-Collier and Sullivan 1980; Bahrick and Watson 1985; Deci and Ryan 1985; Bandura 1986; Ginsburg and Opper 1988; Haith et al. 1988;

. Mh ; Johnson, Haith, Canfield and Haith. DannemillerJohnson MH 1990; Bronson 1991; Canfield and Haith 1991; Schmid- huber 1991b; Haith et al. 1993; Gergely and Watson 1999; Dannemiller 2000;

. Roder, Ryan and Deci. HorvitzRoder et al. 2000; Ryan and Deci 2000; Horvitz 2000; Berthier et al. 2001;

. Pellegrini ; Bjorklund, Wentworth, Gilmore and Thomas. Huang and WengBjorklund and Pellegrini 2002; Huang and Weng 2002; Gilmore and Thomas 2002; Wentworth et al. 2002;

. S P Johnson, Barborica and Ferrera. Johnson SP et al. 2003a; Barborica and Ferrera 2004; Barto et al. 2004;

. J Marshall, Sirois and Mareschal. Oudeyer et al.Marshall J et al. 2004; Sirois and Mareschal 2004; Co- lombo and Cheatham 2006; Redgrave and Gurney 2006; Kumaran and Maguire 2007; Matsumoto et al. 2007; Oudeyer et al. 2007; Schembri et al. 2007; Vieira- Neto and Nehmzow 2007;

. Adler, Fiore, Bromberg-Martin and Hikosaka. Wright and Panksepp. Mirolli and BaldassarreAdler at al. 2008; Fiore et al. 2008; Hiolle and Cañamero 2008; Isoda and Hikosaka 2008; Ryan and Deci 2008; Bromberg- Martin and Hikosaka 2009; Colombo and Mitchell 2009; Lee et al. 2009; Ferre- ra and Barborica 2010; Merrick 2010; Baldassarre 2011; Wright and Panksepp 2012; Gottlieb et al. 2013; Mirolli and Baldassarre 2013

. Gesell. McGrawGesell 1945; Gesell 1946; McGraw 1945;

. B L White, White BL et al. 1964; Bower et al.

. Zelazo, Trevarthen. von Hofsten. von Hofsten. von Hofsten and Fazel-ZandyZelazo et al. 1972; Trevarthen 1975; Field 1977; McDonnell and Abra- ham 1979; von Hofsten 1982; Lockman et al. 1984; von Hofsten 1984; von Hofsten and Fazel-Zandy 1984;

. Ew ; Bushnell, Thelen, Kermoian and Campos. KupersteinBushnell EW 1985; Thelen 1986; Thelen et al. 1987; Kermoian and Campos 1988; Kuperstein 1988; Goldfield 1989;

. Newell, Thelen and Ulrich. Bril and BreniereNewell et al. 1989; Kuperstein 1991; Thelen and Ulrich 1991; Bril and Breniere 1992; Ashmead et al. 1993; Bullock et al. 1993;

. J E Clark, Phillips ; Clifton, Sporns and EdelmanClark JE and Phil- lips 1993; Clifton et al. 1993; Goldfield et al. 1993; Sporns and Edelman

. Von Hofsten, Rönnqvist , Freedland and Bertenthal. Ennouri and BlochBerthiervon Hofsten and Rönnqvist 1993; Vos and Scheepstra 1993; Erhardt 1994; Freedland and Bertenthal 1994; Berthier 1996; Ennouri and Bloch

. Johnson , Blasco ; Adolph, Konczak and Dichgans. Johnson and Blasco 1997; Konczak and Dichgans 1997; Adolph et al.

. Yamazaki Hase, McCarty and Ashmead. Hase and Yamazaki 1998; McCarty and Ashmead 1999;

. Mccarty, McCarty et al.

. Metta, Lungarella and Berthouze. Berthier and KeenMetta et al. 1999; Smeets and Brenner 1999; Vereijken and Adolph 1999; Arena 2000; Schlesinger et al. 2000; McCarty et al. 2001a; McCarty et al. 2001b; Weng et al. 2001; Wheeler et al. 2002; Lungarella and Berthouze 2003; Berthouze and Lungarella 2004; Oztop et al. 2004; Shadmehr and Wise 2004; Berthier and Keen 2005; Berthier et al. 2005; Natale et al. 2005a;

Righetti and Ijspeert. Sangawa ; Kuniyoshi, Degallier, Righetti and Ijspeert. IjspeertWitherington 2005; Kuniyoshi and Sangawa 2006; Righetti and Ijspeert 2006a, Righetti and Ijspeert 2006b; Taga 2006; Degallier et al. 2007; Lee et al. 2007; Natale et al. 2007; Nori et al. 2007; von Hofsten 2007; Caligiore et al. 2008; Degallier et al. 2008; Ijspeert 2008; Asada et al. 2009;

. Q D Wu, Wu QD et al.

. Gerber, Hulse et al. Gerber et al. 2010; Hulse et al. 2010a; Hulse et al. 2010b; Metta et al.

. Law, Berthier. Berthier 2011; Law et al. 2011; Li et al. 2011; Lu et al. 2012; Savasta- no and Nolfi 2012; Li et al. 2013

. Chomsky. ChomskyChomsky 1957; Chomsky 1965;

. L Bloom, McClelland and Rumelhart. FlegeBloom L 1973; Braine 1976; McClelland and Rumelhart 1981; Markman and Hutchinson 1984; Brooks 1986; Flege 1987;

. Markman and Wachtel. GleitmanLangacker 1987; Mervis 1987; Markman and Wachtel 1988; Gleitman 1990;

. Plunkett, Tomasello. HarnadHarnad 1990; Plunkett et al. 1992; Tomasello 1992;

. D Baldwin, Baldwin D 1993;

. E V Clark, Clark EV

. Fenson, Pinker. Fenson et al. 1994; Golinkoff et al. 1994; Pinker 1994; Berrah et al. 1996;

. Elman, Tomasello and Brooks. MacWhinneyElman et al. 1996; Regier 1996; Saffran et al. 1996; Vihman 1996; Carpenter et al. 1998; MacWhinney 1998; Barrett 1999; Jusczyk 1999; Tomasello and Brooks 1999;

. P ; Bloom, Cangelosi, Browman and Goldstein. Bloom P 2000; Browman and Goldstein 2000; Cangelosi et al.

. Christiansen and Chater. deKirbyOller 2000; Christiansen and Chater 2001; de Boer 2001; Kirby 2001;

. Parisi Cangelosi, Cangelosi and Parisi 2002;

. Saylor, Steels and Kaplan. TomaselloSaylor et al. 2002; Steels and Kaplan 2002; Pulver- müller 2003; Steels 2003; Tani 2003; Tomasello 2003; Yoshikawa et al. 2003;

. Roy, Iverson and Goldin-Meadow. Sugita and TaniRoy et al. 2004; Bortfeld et al. 2005; Dominey and Boucher 2005a; Dominey and Boucher 2005b; Iverson and Goldin-Meadow 2005; Pecher and Zwaan 2005; Samuelson and Smith 2005; Smith 2005; Sugita and Tani 2005; Yu 2005;

. Riga Cangelosi, Cangelosi and Riga 2006;

. Ho, Goldberg. Ho et al. 2006; Goldberg 2006; Ogino et al. 2006;

. Santos-Victor Hornstein, Steels and de Beule. Lopes and ChauhanOudeyer 2006; Oudeyer and Kaplan 2006; Steels and de Beule 2006; Hornstein and Santos-Victor 2007; Lopes and Chauhan 2007;

. Mareschal, Mareschal et al. 2007;

. Tomasello, Baldwin and Meyer. McMurrayMcMurray 2007; Tomasello et al. 2007; Baldwin and Meyer 2008;

. Brandl, Hofe and Moore. HoffCarpenterBrandl et al. 2008; CMU 2008; Hofe and Moore 2008; Mikhailova et al. 2008; ten Bosch and Boves 2008; Tomasello 2008; Carpenter 2009; Driesen et al. 2009; Hoff

. Ishihara, Gläser and Joublin. Mayor and PlunkettIshihara et al. 2009; Cangelosi 2010; Cangelosi et al. 2010; Gläser and Joublin 2010; Lyon et al. 2010; Marocco et al. 2010; Mayor and Plunkett 2010;

. Morse, Smith and Samuelson. Morse et al. 2010a; Morse et al. 2010b; Smith and Samuelson 2010; Tuci et al.

. Laurent, Laurent et al. 2011; Rothwell et al. 2011; Tikhanoff et al. 2011; Steels

. Lyon, Tallerman and Gibson. Mangin and OudeyerLyon et al. 2012; Mangin and Oudeyer 2012; Spranger 2012a; Spranger 2012b; Steels 2012; Tallerman and Gibson 2012;

. Araki, Araki et al. 2013; Peelle et al.

. Kaufman, Piaget. SpitzKaufman et al. 1949; Piaget 1952; Piaget 1972; Spitz 1957;

. L Bloom, Bloom L 1970;

. Tucker ; Gelman, Gelman, Starkey and Cooper. KeilAustin 1975; Gelman and Tucker 1975; Pea 1978; Pea 1980; Starkey and Cooper 1980; von Hofsten 1982; Gelman et al. 1986; Choi 1988; Keil 1989;

. Schwanenflugel. WynnGelman 1990; Harnad 1990; Wynn 1990; Schwanenflugel 1991; Wynn 1992;

. Elman Bates, Bates and Elman 1993;

. Dehaene, Starkey and Cooper. Moxey and SanfordDehaene et al. 1993; Moxey and Sanford 1993; Simons and Keil 1995; Starkey and Cooper 1995;

. Cowan, Dehaene. Cowan et al. 1996; Dehaene 1997;

. Stein Schwarz, Alibali and DiRusso. GrahamBarsalouSchwarz and Stein 1998; Alibali and DiRusso 1999; Barsalou 1999; Graham

. Rodriguez, Lakoff and Núñez. Rodriguez et al. 1999; Lakoff and Núñez 2000;

. F Xu, Spelke, Xu F and Spelke 2000;

. Wiemer-Hastings, Sun et al. Parisi and SchlesingerWiemer-Hastings et al. 2001; Sun et al. 2001; Parisi and Schlesinger 2002;

. Wakeley, Wakeley et al. 2000;

. H Wang, Wang H et al. 2001;

. M H Fischer, Fischer MH et al. 2003; Wauters et al.

. Caramelli, Barsalou and Wiemer-Hastings. Caramelli et al. 2004; Barsalou and Wiemer-Hastings 2005; Bisanz et al.

. Coventry, Cangelosi and Riga. Cordes and GelmanCampbell 2005; Cordes and Gelman 2005; Coventry et al. 2005; Ra- japakse et al. 2005; Verguts et al. 2005; Cangelosi and Riga 2006;

. Andres , Andres et al.

. Cangelosi, Sun. Cangelosi et al. 2007; Sun 2007; Tikhanoff et al. 2007; Vernon et al.

. Barsalou. Barsalou 2008;

. M H Fischer, Fischer MH 2008;

. Kawamura, Thornton. Kawamura et al. 2008; Thornton 2008;

. Langley, Borghi and Cimatti. Langley et al. 2009; Borghi and Cimatti 2010; Caligiore et al. 2010;

. Chen Q Verguts, Chen Q and Verguts 2010;

. Della Rosa, Della Rosa et al. 2010; Gordon et al. 2010; Vernon et al.

. Borghi, FörsterBorghi et al. 2011; Förster et al. 2011; Rucinski, Cangelosi, and Belpae- me 2011; Kostas et al. 2011; Saunders et al. 2011; Rucinski et al. 2012; Lyon et al. 2012; Stramandinoli et al. 2012; Förster 2013

A Model-Based Approach to Finding Substitute Tools in 3D Vision Data. Abelha, Proceedings of IEEE International Conference on Robotics and Automation. IEEE International Conference on Robotics and AutomationReferences [Abelha et al. 2016] Paulo Abelha, Frank Guerin, and Markus Schoeler, A Model-Based Approach to Finding Substitute Tools in 3D Vision Data, in Proceedings of IEEE International Conference on Robotics and Automation, 2016, http://homepages.abdn.ac.uk/f.guerin/pages/root.pdf.

Learning How a Tool Affords by Simulating 3D Models from the Web. Paulo Abelha, Frank Guerin, Proceedings of IEEE International Conference on Intelligent Robots and Systems (IROS). IEEE International Conference on Intelligent Robots and Systems (IROS)[Abelha and Guerin 2017] Paulo Abelha and Frank Guerin, Learning How a Tool Affords by Simulating 3D Models from the Web, in Proceedings of IEEE International Conference on Intelligent Robots and Systems (IROS), 2017, http://homepages.abdn.ac.uk/f.guerin/pages/IROS2017.pdf.

Development of Spatial Orientation in Infancy. L P Acredolo, Developmental Psychology. 143[Acredolo 1978] L. P. Acredolo, Development of Spatial Orientation in Infancy, in Developmental Psychology, 14(3): 224- 234, 1978.

Developmental-Changes in the Effects of Landmarks on Infant Spatial-Behavior. L P Acredolo, D Evans, Developmental Psychology. 164Acredolo and Evans 1980[Acredolo and Evans 1980] L. P. Acredolo and D. Evans, Developmental-Changes in the Effects of Landmarks on Infant Spa- tial-Behavior, in Developmental Psychology, 16(4): 312-318, 1980.

The Role of Self-Produced Movement and Visual Tracking in Infant Spatial Orientation. L P Acredolo, A Adams, S W Goodwyn, Journal of Experimental Child Psychology. Adams et al. 2012] Sam S. Adams, Itamar Arel, Joscha Bach, Robert Coop, Rod Furlan, Ben Goertzel, J. Storrs Hall, Alexei Samsonovich, Matthias Scheutz, Matthew Schlesinger, Stuart C. Shapiro, and John F. Sowa382Mapping the Landscape of Human-Level Artificial General Intelligence[Acredolo et al. 1984] L. P. Acredolo, A. Adams, and S. W. Goodwyn, The Role of Self-Produced Movement and Visual Tracking in Infant Spatial Orientation, in Journal of Experimental Child Psychology, 38(2): 312-327, 1984. [Adams et al. 2012] Sam S. Adams, Itamar Arel, Joscha Bach, Robert Coop, Rod Furlan, Ben Goertzel, J. Storrs Hall, Alexei Samsonovich, Matthias Scheutz, Matthew Schlesinger, Stuart C. Shapiro, and John F. Sowa, Mapping the Landscape of Human-Level Artificial General Intelligence, in AI Magazine, 25-41, Spring 2012, https://www.aaai.org/ojs/index.php/aimagazine/article/view/2322/2269.

Infants' Visual Expectations and the Processing of Time. Adler, Journal of Cognition and Development. 91[Adler et al. 2008] S. A. Adler, M. M. Haith, D. M. Arehart, and E. C. Lanthier, Infants' Visual Expectations and the Pro- cessing of Time, in Journal of Cognition and Development, 9(1)(Jan.-Mar.): 1-25, 2008.

Learning in the Development of Infant Locomotion, in Monographs of the Society for Research in Child Development. K E Adolph, i-vi62K. E. Adolph, Learning in the Development of Infant Locomotion, in Monographs of the Society for Research in Child Development, 62(3): i-vi, 1-158, 1997.

Learning to Move. ; K E Adolph, Adolph, Current Directions in Psychological Science. 173Adolph 2008] K. E. Adolph, Learning to Move, in Current Directions in Psychological Science, 17(3)(June): 213-218, 2008.

Learning to Crawl. Adolph , Child Development. 695[Adolph et al. 1998] K. E. Adolph, B. Vereijken, and M. A. Denny, Learning to Crawl, in Child Development, 69(5)(Oct.): 1299-1312, 1998.

A computational model of early cognitive development as a creative process. Perez Aguilar, Wendy Perez, Rafael Aguilar, Perez Y Perez, E-R Dev, Cognitive Systems Research. 33[Aguilar and Perez y Perez 2015] Wendy Aguilar and Rafael Perez y Perez, Dev E-R: A computational model of early cogni- tive development as a creative process, in Cognitive Systems Research, 33:17-41, 2015.

Early-creative behavior: the first manifestations of creativity in a developmental agent. ICCC. Aguilar and Perez y Perez 2017] Wendy Aguilar and Rafael Perez y Perez[Aguilar and Perez y Perez 2017] Wendy Aguilar and Rafael Perez y Perez, Early-creative behavior: the first manifestations of creativity in a developmental agent, in ICCC, 2017, https://computationalcreativity.net/iccc2017/ICCC_17_accepted_submissions/ICCC-17_paper_7.pdf.

How Can We Be So Dense?. Subutai Ahmad, Luiz Scheinkman, The Benefits of Using Highly Sparse Representations, in arXiv. Ahmad and Scheinkman 2019[Ahmad and Scheinkman 2019] Subutai Ahmad and Luiz Scheinkman, How Can We Be So Dense? The Benefits of Using Highly Sparse Representations, in arXiv, 2019, https://arxiv.org/abs/1903.11257.

A Theory of Cerebellar Function. James S Albus, Mathematical Biosciences. 101James S. Albus, A Theory of Cerebellar Function, in Mathematical Biosciences, 10(1/2), Feb. 1971, https://robotictechnologyinc.com/images/upload/file/Albus%20Theory%20Of%20Cerebellar%20Function.pdf.

A Model of the Brain for Robot Control. James Albus, BYTE magazine. 4James Albus, A Model of the Brain for Robot Control, in BYTE magazine, 4(6): 10-34, June 1979, https://www.yumpu.com/en/document/read/36496244/byte-1979-06.

Outline for a Theory of General Intelligence. James S Albus, IEEE Transactions on Systems, Man, and Cybernetics. 21[Albus 1991] James S. Albus, Outline for a Theory of General Intelligence, in IEEE Transactions on Systems, Man, and Cy- bernetics, 21(3), May/June 1991, https://ws680.nist.gov/publication/get_pdf.cfm?pub_id=820297.

The Engineering of Mind. James S Albus, Dr. James Albus, A Computational Theory of Mind, on Robot Technology Inc. website, ~2007. 117Information Sciences[Albus 1999] James S. Albus, The Engineering of Mind, in Information Sciences, 117: 1-18, 1999. [Albus 2007] Dr. James Albus, A Computational Theory of Mind, on Robot Technology Inc. website, ~2007, https://robotictechnologyinc.com/index.php/jamesalbus.

Reverse Engineering the Brain. James S Albus, Proceedings of AAAI Fall Symposium on Biologically Inspired Cognitive Architectures. AAAI Fall Symposium on Biologically Inspired Cognitive ArchitecturesWashington, D.C.[Albus 2008] James S. Albus, Reverse Engineering the Brain, in Proceedings of AAAI Fall Symposium on Biologically In- spired Cognitive Architectures, Washington, D.C., 2008, https://pdfs.semanticscholar.org/9793/56d44f7bd798f01484e57382e616c4855599.pdf.

Intelligent Control and Tactical Behavior Development: A long term NIST Partnership with the Army, in 11th Robotics and Remote Systems for Hazardous Environments. James Albus, Anthony Barbera, Theory and Practice of Hierarchical Control. James Albus, Anthony Barbera, and Roger NagelNational Bureau of Standards publicationAlbus et al. 1980[Albus and Barbera 2006] James Albus and Anthony Barbera, Intelligent Control and Tactical Behavior Development: A long term NIST Partnership with the Army, in 11th Robotics and Remote Systems for Hazardous Environments, Salt Lake City, Feb. 11-16, 2006, https://robotictechnologyinc.com/images/upload/file/Albus%20Intelligent%20Control%20&%20Tactical%20Behavior.pdf [Albus et al. 1980] James Albus, Anthony Barbera, and Roger Nagel, Theory and Practice of Hierarchical Control, National Bureau of Standards publication, Washington DC, Nov. 1, 1980.

The Function of Gesture in Learning to Count: More than Keeping Track. M W Alibali, A A Dirusso, Cognitive Development. 141Alibali and DiRusso[Alibali and DiRusso 1999] M. W. Alibali and A. A. DiRusso, The Function of Gesture in Learning to Count: More than Keeping Track, in Cognitive Development, 14(1)(Jan.-Mar.): 37-56, 1999.

Al-Shedivat, Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments. Al-Shedivat et al. 2017] Maruan Al-Shedivat, Igor Mordatch, Trapit Bansal, Yura Burda, Ilya Sutskever, and Pieter Abbeel, Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments, in arXiv, 2017, https://arxiv.org/pdf/1710.03641.pdf.

Learning by Selection: Visual Search and Object Perception in Young Infants. D Amso, S P Johnson, Developmental Psychology. 426[Amso and Johnson 2006] D. Amso and S. P. Johnson, Learning by Selection: Visual Search and Object Perception in Young Infants, in Developmental Psychology, 42(6)(Nov.): 1236-1245, 2006.

Design of a Production System for Cognitive Modeling. John R Anderson, Paul J Kline, Proceedings of the Workshop on Pattern-Directed Inference Systems. the Workshop on Pattern-Directed Inference Systems[Anderson and Kline 1977] John R. Anderson and Paul J. Kline, Design of a Production System for Cognitive Modeling, in Proceedings of the Workshop on Pattern-Directed Inference Systems, 60-65, 1977, http://act-r.psy.cmu.edu/wordpress/wp- content/uploads/2012/12/23JRA-PK-Sigart.77.pdf.

Contribution of Hand Motor Circuits to Counting. Andres , Journal of Cognitive Neuroscience. 194[Andres et al. 2007] M. Andres, X. Seron, and E. Olivier, Contribution of Hand Motor Circuits to Counting, in Journal of Cognitive Neuroscience, 19(4)(Apr.): 563-576, 2007.

Long-Term Learning of Concept and Word by Robots: Interactive Learning Framework and Preliminary Results. [ Araki, RSJ International Conference on Intelligent Robots and Systems. Tokyo Big Sight[Araki et al. 2013] T. Araki, T. Nakamura, and T. Nagai, Long-Term Learning of Concept and Word by Robots: Interactive Learning Framework and Preliminary Results, paper presented at the IEEE/ RSJ International Conference on Intelligent Robots and Systems, Tokyo Big Sight, Tokyo, Japan, November 3-7, 2013.

The Metaphorical Brain: An Introduction to Cybernetics as Artificial Intelligence and Brain Theory. Michael A Arbib, Wiley-InterscienceNew YorkMichael A. Arbib, The Metaphorical Brain: An Introduction to Cybernetics as Artificial Intelligence and Brain Theory, New York: Wiley-Interscience, 1972.

Perceptual Structures and Distributed Motor Control. Michael A Arbib, Handbook of Physiology: The Nervous System Motor Control. J. M. Brookhart, V. B. Mountcastle, V. B. BrooksAmerican Physiological Society2Michael A. Arbib, Perceptual Structures and Distributed Motor Control, Chapter 33 in Handbook of Physiolo- gy: The Nervous System Motor Control (Vol. 2), J. M. Brookhart, V. B. Mountcastle, V. B. Brooks (eds), 1449 -1480, American Physiological Society, 1981.

The Metaphorical Brain 2: Neural Networks and Beyond. Michael A Arbib, Wiley-InterscienceNew YorkMichael A. Arbib, The Metaphorical Brain 2: Neural Networks and Beyond, New York: Wiley-Interscience, 1989.

Michael A Arbib, Schema Theory, The Encyclopedia of Artificial Intelligence. Wiley Interscience2Michael A. Arbib, Schema Theory, in The Encyclopedia of Artificial Intelligence, 2: 1427-1443, Wiley Inter- science, 1992, https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.470.6492&rep=rep1&type=pdf.

From cybernetics to brain theory, and more: A memoir. Michael A Arbib, Cognitive Systems Research. 50[Arbib 2018] Michael A. Arbib, From cybernetics to brain theory, and more: A memoir, in Cognitive Systems Research, 50: 83 -145, 2018, https://www.sciencedirect.com/science/article/abs/pii/S1389041718301360.

Symbols: A View from the 90s. Michael A Arbib, Journal of Knowledge Structures & Systems. 2Schemas vs[Arbib 2021] Michael A. Arbib, Schemas vs. Symbols: A View from the 90s, in Journal of Knowledge Structures & Systems, 2(1): 68-74, August 2021, https://philpapers.org/archive/ARBSVS.pdf.

A Michael, Mary B Arbib, Hesse, The Construction of Reality. Cambridge University Press[Arbib and Hesse 1986] Michael A. Arbib and Mary B. Hesse, The Construction of Reality, Cambridge University Press, 1986.

The Central Pattern Generator: A Paradigm for Artificial Locomotion. P Arena, Soft Computing. 4[Arena 2000] P. Arena, The Central Pattern Generator: A Paradigm for Artificial Locomotion, in Soft Computing, 4(4): 251- 266, 2000.

A Brief Survey of Deep Reinforcement Learning. arXiv:1708.05866IEEE Signal Processing Magazine, Special Issue on Deep Learning for Image Understanding. Arulkumaran et al. 2017] Kai Arulkumaran, Marc Peter Deisenroth, Miles Brundage, and Anil Anthony Bharath[Arulkumaran et al. 2017] Kai Arulkumaran, Marc Peter Deisenroth, Miles Brundage, and Anil Anthony Bharath, A Brief Survey of Deep Reinforcement Learning, in IEEE Signal Processing Magazine, Special Issue on Deep Learning for Image Understanding (arXiv extended version), 2017, arXiv:1708.05866, https://arxiv.org/pdf/1708.05866.pdf.

Cooperative Behavior Acquisition for Mobile Robots in Dynamically Changing Real Worlds Via Vision-Based Reinforcement Learning and Development. Asada, Artificial Intelligence. 1102[Asada et al. 1999] M. Asada, E. Uchibe, and K. Hosoda, Cooperative Behavior Acquisition for Mobile Robots in Dynami- cally Changing Real Worlds Via Vision-Based Reinforcement Learning and Development, in Artificial Intelligence, 110(2)(June): 275-292, 1999.

Cognitive developmental robotics as a new paradigm for the design of humanoid robots. Asada, Robotics and Autonomous Systems. Elsevier37Asada et al. 2001] Minoru Asada, Karl F. MacDorman, Hiroshi Ishiguro, and Yasuo Kuniyoshi, Cognitive developmental ro- botics as a new paradigm for the design of humanoid robots, in Robotics and Autonomous Systems, 37: 185-193, Elsevier, 2001, http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.510.1641&rep=rep1&type=pdf.

M Asada, K Hosoda, Y Kuniyoshi, H Ishiguro, T Inui, Y Yoshikawa, M Ogino, C Yoshida, Cognitive Developmental Robotics: A Survey. 1[Asada et al. 2009] M. Asada, K. Hosoda, Y. Kuniyoshi, H. Ishiguro, T. Inui, Y. Yoshikawa, M. Ogino, and C. Yoshida, Cog- nitive Developmental Robotics: A Survey, in IEEE Transactions on Autonomous Mental Development, 1(1)(May): 12-34, 2009.

Ashmead, Visual Guidance in Infants Reaching toward Suddenly Displaced Targets. 64[Ashmead et al. 1993] D. H. Ashmead, M. E. McCarty, L. S. Lucas, and M. C. Belvedere, Visual Guidance in Infants Reach- ing toward Suddenly Displaced Targets, in Child Development, 64(4)(Aug.): 1111-1127, 1993.

. J L Austin, How to Do Things with Words. 1955Oxford University PressJ. L. Austin, How to Do Things with Words, Vol. 1955, Oxford, UK: Oxford University Press, 1975.

Recursive dynamic node creation in multilayer neural networks. Azimi-Sadjadi, IEEE Transactions on Neural Networks. 4Azimi-Sadjadi et al. 1993] M. R. Azimi-Sadjadi, S. Sheedvash, and F. O. Trujillo, Recursive dynamic node creation in multi- layer neural networks, in IEEE Transactions on Neural Networks, 4: 242-56, 1993.

Sensory substitution and the human-machine interface. Trends in cognitive sciences. Bach-y-Rita and Kercel 2003] Paul Bach-y-Rita and Stephen W. Kercel7[Bach-y-Rita and Kercel 2003] Paul Bach-y-Rita and Stephen W. Kercel, Sensory substitution and the human-machine inter- face, in Trends in cognitive sciences, 7(12): 541-546, 2003.

Detection of Intermodal Proprioceptive Visual Contingency as a Potential Basis of Self-Perception in Infancy. L E Bahrick, J S Watson, Developmental Psychology. 216and Watson 1985and Watson 1985] L. E. Bahrick and J. S. Watson, Detection of Intermodal Proprioceptive Visual Contingency as a Potential Basis of Self-Perception in Infancy, in Developmental Psychology, 21(6): 963-973, 1985.

Mommy and Me-Familiar Names Help Launch Babies into Speech-Stream Segmentation. Bortfeld, Psychological Science. 164[Bortfeld et al. 2005] H. Bortfeld, J. L. Morgan, R. M. Golinkoff, and K. Rathbun, Mommy and Me-Familiar Names Help Launch Babies into Speech-Stream Segmentation, in Psychological Science, 16(4): 298-304, 2005.

Demonstration of Intention in Reaching Behaviour of Neonate Humans. [ Bower, Nature. 2285272[Bower et al. 1970] T. G. R. Bower, J. M. Broughton, and M. K. Moore, Demonstration of Intention in Reaching Behaviour of Neonate Humans, in Nature, 228(5272)(Nov.): 679-681, 1970.

Stephen Boydstun, Rand Piaget, Objectivist Living website Forum. Stephen Boydstun, Piaget and Rand, in Objectivist Living website Forum, Dec. 24. 2012, https://www.objectivistliving.com/forums/topic/12873-piaget-and-rand/.

A Self-Referential Childlike Model to Acquire Phones, Syllables and Words from Acoustic Speech. M D Braine, ; H Brandl, B Wrede, F Joublin, C Goerick, IEEE 7th International Conference on Development and Learning. Monterey, CAChicago: University of ChicagoChildren's First Word Combinations. paper presented at the[Braine 1976] M. D. Braine, Children's First Word Combinations, Chicago: University of Chicago, 1976. [Brandl et al. 2008] H. Brandl, B. Wrede, F. Joublin, and C. Goerick, A Self-Referential Childlike Model to Acquire Phones, Syllables and Words from Acoustic Speech, paper presented at the IEEE 7th International Conference on Development and Learning, Monterey, CA, August 9-12, 2008.

Learning from and About Others: Towards Using Imitation to Bootstrap the Social Understanding of Others by Robots. Breazeal, Artificial Life. 111-2[Breazeal et al. 2005] C. Breazeal, D. Buchsbaum, J. Gray, D. Gatenby, and B. Blumberg, Learning from and About Others: Towards Using Imitation to Bootstrap the Social Understanding of Others by Robots, in Artificial Life, 11(1-2): 31-62, 2005.

Robots That Imitate Humans. C Breazeal, B Scassellati, Trends in Cognitive Sciences. 611[Breazeal and Scassellati 2002] C. Breazeal and B. Scassellati, Robots That Imitate Humans, in Trends in Cognitive Sciences, 6(11): 481-487, 2002.

Postural Requirements and Progression Velocity in Young Walkers. B Bril, Y Breniere, Journal of Motor Behavior. 24and Breniere 1992and Breniere 1992] B. Bril and Y. Breniere, Postural Requirements and Progression Velocity in Young Walkers, in Jour- nal of Motor Behavior, 24(1)(Mar.): 105-116, 1992.

Midbrain Dopamine Neurons Signal Preference for Advance Information About Upcoming Rewards. -Martin Hikosaka, ; E S Bromberg-Martin, O Hikosaka, Neuron. 631-Martin and Hikosaka 2009] E. S. Bromberg-Martin and O. Hikosaka, Midbrain Dopamine Neurons Signal Prefer- ence for Advance Information About Upcoming Rewards, in Neuron, 63(1): 119-126, 2009.

Infant Differences in Rate of Visual Encoding. G W Bronson, Child Development. 621[Bronson 1991] G. W. Bronson, Infant Differences in Rate of Visual Encoding, in Child Development, 62(1)(Feb.): 44-54, 1991.

A Robust Layered Control-System for a Mobile Robot. R A Brooks, IEEE Journal on Robotics and Automation. 21[Brooks 1986] R. A. Brooks, A Robust Layered Control-System for a Mobile Robot, in IEEE Journal on Robotics and Auto- mation, 2(1)(Mar.): 14-23, 1986.

Computation for Metaphors, Analogy, and Agents. C. NehanivHeidelberg BerlinSpringer-Verlag1562The Cog Project: Building a Humanoid Robotet al. 1999] Rodney A. Brooks, Cynthia Breazeal, Matthew Marjanovíc, Brian Scassellati, and Matthew M. William- son, The Cog Project: Building a Humanoid Robot, in Computation for Metaphors, Analogy, and Agents, C. Nehaniv (ed.), LNCS 1562, 52-87, Heidelberg Berlin: Springer-Verlag, 1999, https://scazlab.yale.edu/sites/default/files/files/springer-final-cog.pdf.

Competing Constraints on Intergestural Coordination and Self-Organization of Phonological Structures, in Les Cahiers de l'IC. C P Browman, L Goldstein, Bulletin de la Communication Parlée. 5Browman and Goldstein[Browman and Goldstein 2000] C. P. Browman and L. Goldstein, Competing Constraints on Intergestural Coordination and Self-Organization of Phonological Structures, in Les Cahiers de l'IC, Bulletin de la Communication Parlée, 5:25-34, 2000.

A Self-Organizing Neural Model of Motor Equivalent Reaching and Tool Use by a Multijoint Arm. [ Bullock, Journal of Cognitive Neuroscience. 54[Bullock et al. 1993] D. Bullock, S. Grossberg, and F. H. Guenther, A Self-Organizing Neural Model of Motor Equivalent Reaching and Tool Use by a Multijoint Arm, in Journal of Cognitive Neuroscience, 5(4)(Fall): 408-435, 1993.

The Decline of Visually Guided Reaching During Infancy, in Infant Behavior and Development. Ew ; E W Bushnell, Bushnell, 8Bushnell EW 1985] E. W. Bushnell, The Decline of Visually Guided Reaching During Infancy, in Infant Behavior and De- velopment, 8(2): 139-155, 1985.

Motor Development and the Mind-the Potential Role of Motor Abilities as a Determinant of Aspects of Perceptual Development. E W Bushnell, ; E W Boudreau, J P Bushnell, Boudreau, Child Development. 644Bushnell EW and Boudreau 1993] E. W. Bushnell and J. P. Boudreau, Motor Development and the Mind-the Potential Role of Motor Abilities as a Determinant of Aspects of Perceptual Development, in Child Development, 64(4): 1005-1021, 1993.

Mother's Face Recognition in Newborn Infants: Learning and Memory. Iwr ; I W R Bushnell, Bushnell, Infant and Child Development. 10Bushnell IWR 2001] I. W. R. Bushnell, Mother's Face Recognition in Newborn Infants: Learning and Memory, in Infant and Child Development, 10:67-74, 2001.

Iwr Bushnell, Neonatal Recognition of the Mother's Face. 7Bushnell IWR et al. 1989] I. W. R. Bushnell, F. Sai, and J. T. Mullin, Neonatal Recognition of the Mother's Face, in British Journal of Developmental Psychology, 7(1): 3-15, 1989.

Discrimination Learning by Rhesus Monkeys to Visual-Exploration Motivation. R A Butler, Journal of Comparative and Physiological Psychology. 462[Butler 1953] R. A. Butler, Discrimination Learning by Rhesus Monkeys to Visual-Exploration Motivation, in Journal of Comparative and Physiological Psychology, 46(2): 95-98, 1953.

The Ontogeny and Phylogeny of Joint Visual Attention. G Butterworth, Natural Theories of Mind. Butterworth; Oxford, UKBlackwell Publishers[Butterworth 1991] G. Butterworth, The Ontogeny and Phylogeny of Joint Visual Attention, in Natural Theories of Mind, ed. A. Whiten, 223-232, Oxford, UK: Blackwell Publishers, 1991.

Using Motor Babbling and Hebb Rules for Modeling the Development of Reaching with Obstacles and Grasping, paper presented at the International Conference on Cognitive Systems. G Butterworth, ; G Butterworth, N Jarrett ; D. Caligiore, T Ferrauto, D Parisi, N Accornero, M Capozza, G Baldassarre ; D. Caligiore, A M Borghi, D Parisi, G Baldassarre, Psychological Inquiry. Butterworth; Karlsruhe, Germany3University of KarlsruhePsychological Review[Butterworth 1992] G. Butterworth, Origins of Self-Perception in Infancy, in Psychological Inquiry, 3(2): 103-111, 1992. [Butterworth and Jarrett 1991] G. Butterworth and N. Jarrett, What Minds Have in Common Is Space-Spatial Mechanisms Serving Joint Visual-Attention in Infancy, in British Journal of Developmental Psychology, 9(Mar.): 55-72, 1991. [Caligiore et al. 2008] D. Caligiore, T. Ferrauto, D. Parisi, N. Accornero, M. Capozza, and G. Baldassarre, Using Motor Bab- bling and Hebb Rules for Modeling the Development of Reaching with Obstacles and Grasping, paper presented at the In- ternational Conference on Cognitive Systems, University of Karlsruhe, Karlsruhe, Germany, April 2-4, 2008. [Caligiore et al. 2010] D. Caligiore, A. M. Borghi, D. Parisi, and G. Baldassarre, TRoPICALS: A Computational Embodied Neuroscience Model of Compatibility Effects, in Psychological Review, 117(4)(Oct.): 1188-1228, 2010.

Three Sources of Information in Social Learning. J Call, M Carpenter, Imitation in Animals and Artifacts. K. Dautenhahn and C. L. NehanivCambridge, MAMIT Pressand Carpenter 2002] J. Call and M. Carpenter, Three Sources of Information in Social Learning, in Imitation in Animals and Artifacts, ed. K. Dautenhahn and C. L. Nehaniv, 211-228, Cambridge, MA: MIT Press, 2002.

Does the Chimpanzee Have a Theory of Mind? 30 Years Later. J Call, M Tomasello, Trends in Cognitive Sciences. 125and Tomasello 2008] J. Call and M. Tomasello, Does the Chimpanzee Have a Theory of Mind? 30 Years Later, in Trends in Cognitive Sciences, 12(5): 187-192, 2008.

Handbook of Mathematical Cognition. J I D Campbell, ; J J Campos, A Langer, A Krowitz, Campos et al. 1970Cardiac Responses on Visual Cliff in Prelocomotor Human Infants. New YorkPsychology Press170[Campbell 2005] J. I. D. Campbell, Handbook of Mathematical Cognition, New York: Psychology Press, 2005. [Campos et al. 1970] J. J. Campos, A. Langer, and A. Krowitz, Cardiac Responses on Visual Cliff in Prelocomotor Human In- fants, in Science, 170(3954): 196-197, 1970.

Early Experience and Emotional Development: The Emergence of Wariness of Heights. Campos, Psychological Science. 31[Campos et al. 1992] J. J. Campos, B. I. Bertenthal, and R. Kermoian, Early Experience and Emotional Development: The Emergence of Wariness of Heights, in Psychological Science, 3(1): 61-64, 1992.

Young Infants Visual Expectations for Symmetrical and Asymmetric Stimulus Sequences. R L Canfield, M M Haith, Developmental Psychology. 272Canfield and Haith[Canfield and Haith 1991] R. L. Canfield and M. M. Haith, Young Infants Visual Expectations for Symmetrical and Asym- metric Stimulus Sequences, in Developmental Psychology, 27(2)(Mar.): 198-208, 1991.

Grounding Language in Action and Perception: From Cognitive Agents to Humanoid Robots. A Cangelosi, Physics of Life Reviews. 72[Cangelosi 2010] A. Cangelosi, Grounding Language in Action and Perception: From Cognitive Agents to Humanoid Robots, in Physics of Life Reviews, 7(2)(Jun.): 139-151, 2010.

Simulating the Evolution of Language. A. Cangelosi and D. ParisiSpringerLondon[Cangelosi and Parisi 2002] A. Cangelosi and D. Parisi (eds.), Simulating the Evolution of Language, London: Springer, 2002.

An Embodied Model for Sensorimotor Grounding and Grounding Transfer: Experiments with Epigenetic Robots. A Cangelosi, T Riga, Cognitive Science. 304and Riga 2006] A. Cangelosi and T. Riga, An Embodied Model for Sensorimotor Grounding and Grounding Transfer: Experiments with Epigenetic Robots, in Cognitive Science, 30(4)(July-Aug.): 673-689, 2006.

Developmental Robotics: From Babies to Robots. Angelo Cangelosi, Matthew Schlesinger, MIT Press[Cangelosi and Schlesinger 2015] Angelo Cangelosi and Matthew Schlesinger, Developmental Robotics: From Babies to Ro- bots, MIT Press, 2015, https://idoc.pub/documents/developmental-robotics-from-babies-to-robots-d47ey87vq2n2.

From Robotic Toil to Symbolic Theft: Grounding Transfer from Entry-Level to Higher-Level Categories. [ Cangelosi, Connection Science. 122[Cangelosi et al. 2000] A. Cangelosi, A. Greco, and S. Harnad, From Robotic Toil to Symbolic Theft: Grounding Transfer from Entry-Level to Higher-Level Categories, in Connection Science, 12(2)(Jun.): 143-162, 2000.

Integration of Action and Language Knowledge: A Roadmap for Developmental Robotics. [ Cangelosi, IEEE Computational Intelligence Magazine. 2Integrating Language and Cognition: A Cognitive Robotics Approach. Sept[Cangelosi et al. 2007] A. Cangelosi, V. Tikhanoff, J. F. Fontanari, and E. Hourdakis, Integrating Language and Cognition: A Cognitive Robotics Approach, in IEEE Computational Intelligence Magazine, 2(3)(Aug.): 65-70, 2007. [Cangelosi et al. 2010] A. Cangelosi, G. Metta, G. Sagerer, S. Nolfi, C. Nehaniv, K. Fischer, J. Tani, et al., Integration of Ac- tion and Language Knowledge: A Roadmap for Developmental Robotics, in IEEE Transactions on Autonomous Mental Development, 2(3)(Sept.): 167-195, 2010.

Concrete and Abstract Concepts in School Age Children. [ Caramelli, Psychology of Language and Communication. 82[Caramelli et al. 2004] N. Caramelli, A. Setti, and D. D. Maurizzi, Concrete and Abstract Concepts in School Age Children, in Psychology of Language and Communication, 8(2): 19-34, 2004.

Collaborative Control for a Robotic Wheelchair: Evaluation of Performance, Attention, and Workload. T Carlson, ; T Demiris, Y Carlson, Demiris, IEEE Transactions on Systems, Man, and Cybernetics. Part B, Cybernetics. 423Carlson T and Demiris 2012] T. Carlson and Y. Demiris, Collaborative Control for a Robotic Wheelchair: Evaluation of Per- formance, Attention, and Workload, in IEEE Transactions on Systems, Man, and Cybernetics. Part B, Cybernetics, 42(3)(Jun.): 876-888, 2012.

A Computational Model of the Emergence of Gaze Following. E Carlson, ; E Triesch, J Carlson, Triesch, Connectionist Models of Cognition and Perception II. H. Bowman and C. Labiouse15World Scientific PublishingCarlson E and Triesch 2004] E. Carlson and J. Triesch, A Computational Model of the Emergence of Gaze Following. Con- nectionist Models of Cognition and Perception II, Vol. 15, Ed. H. Bowman and C. Labiouse, Singapore: World Scientific Publishing, 2004.

M Carpenter, Just How Joint Is Joint Action in Infancy?, in Topics in Cognitive Science. 1M. Carpenter, Just How Joint Is Joint Action in Infancy?, in Topics in Cognitive Science, 1(2)(Apr.): 380- 392, 2009.

Joint Attention, and Communicative Competence from 9 to 15 Months of Age. [ Carpenter, Monographs of the Society for Research in Child Development. 63[Carpenter et al. 1998] M. Carpenter, K. Nagell, and M. Tomasello, Social Cognition, Joint Attention, and Communicative Competence from 9 to 15 Months of Age, in Monographs of the Society for Research in Child Development, 63(4): 1-143, 1998.

Role Reversal Imitation and Language in Typically Developing Infants and Children with Autism. [ Carpenter, Infancy. 83[Carpenter et al. 2005] M. Carpenter, M. Tomasello, and T. Striano, Role Reversal Imitation and Language in Typically De- veloping Infants and Children with Autism, in Infancy, 8(3): 253-278, 2005.

. [ Carter, Activation Atlas, in Distill. 4315[Carter et al. 2019] Shan Carter, Zan Armstrong, Ludwig Schubert, Ian Johnson, and Chris Olah, Activation Atlas, in Distill, 4(3): e15, 2019, https://staging.distill.pub/2019/activation-atlas/.

Human Translation and Translation by Machine. Silvio Ceccato, Bruna Zonta, Proceedings of the 1961 International Conference on Machine Translation of Languages and Applied Language Analysis. the 1961 International Conference on Machine Translation of Languages and Applied Language AnalysisTeddington, Middlesex[Ceccato and Zonta 1961] Silvio Ceccato and Bruna Zonta, Human Translation and Translation by Machine, in Proceedings of the 1961 International Conference on Machine Translation of Languages and Applied Language Analysis, Teddington, Middlesex, 1961, http://www.mt-archive.info/NPL-1961-Ceccato.pdf.

Automatic Translation of Languages. Ceccato Silvio, Proceedings of Automatic Translation of Languages NATO Summer School. Automatic Translation of Languages NATO Summer School[Ceccato 1962] Silvio Ceccato, Automatic Translation of Languages, in Proceedings of Automatic Translation of Languages NATO Summer School, July 1962, http://www.mt-archive.info/NATO-1962-Ceccato.pdf.

Correlational Analysis and Mechanical Translation, in Readings in Machine Translation. Silvio Ceccato, A Bradford Book. S. Nirenbure, H. Somers, and Y. WilksMIT Press[Ceccato 1967] Silvio Ceccato, Correlational Analysis and Mechanical Translation, in Readings in Machine Translation, S. Nirenbure, H. Somers, and Y. Wilks (eds.), A Bradford Book, MIT Press, 137-156, 2003, https://books.google.com/books?hl=en&lr=&id=yx3lEVJMBmMC&oi=fnd&pg=PA137&dq=Correlational+analysis+and +mechanical+translation&ots=se2sdSIIHu&sig=EKXIitcMPdXcX5fatTfQtKa-Z- M#v=onepage&q=Correlational%20analysis%20and%20mechanical%20translation&f=false.

Learning Context on a Humanoid Robot using Incremental Latent Dirichlet Allocation. [ Celikkanat, METU-CENG-TR-2015-01[Celikkanat et al. 2015a] Hande Celikkanat, Guner Orhan, Nicolas Pugeault, Frank Guerin, Erol Sahin, and Sinan Kalkan, Learning Context on a Humanoid Robot using Incremental Latent Dirichlet Allocation, METU-CENG-TR-2015-01, April 2015, http://kovan.ceng.metu.edu.tr/~sinan/publications/METU-CENG-TR-2015-01.pdf.

A Probabilistic Concept Web on a Humanoid Robot. Hande Celikkanat, Guner Orhan, Sinan Kalkan, IEEE Transactions on Autonomous Mental Development. 72Celikkanat et al. 2015b[Celikkanat et al. 2015b] Hande Celikkanat, Guner Orhan, and Sinan Kalkan, A Probabilistic Concept Web on a Humanoid Robot, in IEEE Transactions on Autonomous Mental Development, 7(2): 92-106, June 2015, http://kovan.ceng.metu.edu.tr/~sinan/publications/2015-TAMD-Celikkanat-Concept.pdf.

Learning to Imitate Human Actions through Eigenposes, in From Motor Learning to Interaction Learning in Robots, Studies in Computational Intelligence. [ Chalodhorn, Rao ; Rawichote Chalodhorn, P N Rajesh, Rao, O. Sigaud and J. PetersSpringer264Berlin, Heidelberg[Chalodhorn and Rao 2010] Rawichote Chalodhorn and Rajesh P.N. Rao, Learning to Imitate Human Actions through Eigen- poses, in From Motor Learning to Interaction Learning in Robots, Studies in Computational Intelligence, O. Sigaud and J. Peters (eds.) 264, Berlin, Heidelberg: Springer, 2010.

Amant, Piagetian Adaptation Meets Image Schemas: The Jean System. Chang , Lecture Notes in Computer Science, SAB. 4095Springer[Chang et al. 2006] Yu-Han Chang, Paul Cohen, Clayton Morrison, and Robert St. Amant, Piagetian Adaptation Meets Image Schemas: The Jean System, in Lecture Notes in Computer Science, SAB, 4095: 369-380, Springer, 2006, https://pdfs.semanticscholar.org/3daf/2a5de7a250937f95908aba596371284e98c5.pdf.

The Constructivist Learning Architecture: A Model of Cognitive Development for Robust Autonomous Robots. H Harold, Chaput, TR04-34University of Texas at AustinReport[Chaput 2004] Harold H. Chaput, The Constructivist Learning Architecture: A Model of Cognitive Development for Robust Autonomous Robots, Report TR04-34, University of Texas at Austin, August 2004, ftp://ftp.cs.utexas.edu/pub/qsim/papers/Chaput-PhD-04.pdf.

The Role of Surprise in Cognitive Development. W R Charlesworth, Studies in Cognitive Development: Essays in Honor of Jean Piaget. D. Elkind and J. FlavellOxford, UK; Don Mills, Ontario, CanadaOxford University PressFundamentals of Sensory Perception[Charlesworth 1969] W. R. Charlesworth, The Role of Surprise in Cognitive Development, in Studies in Cognitive Develop- ment: Essays in Honor of Jean Piaget, ed. D. Elkind and J. Flavell, 257-314, Oxford, UK: Oxford University Press, 1969. [Chaudhuri 2011] A. Chaudhuri, Fundamentals of Sensory Perception, Don Mills, Ontario, Canada: Oxford University Press, 2011.

Chen Q Verguts, ; Q Chen, T Verguts, Beyond the Mental Number Line: A Neural Network Model of Number-Space Interactions. 60Chen Q and Verguts 2010] Q. Chen and T. Verguts, Beyond the Mental Number Line: A Neural Network Model of Number- Space Interactions, in Cognitive Psychology, 60(3)(May): 218-240, 2010.

Developmental Learning: A Case Study in Understanding 'Object Permanence,' paper presented at the 4th International Workshop on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems. Y Chen, ; Y Weng, J Chen, Weng, Genoa, ItalyChen Y and Weng 2004] Y. Chen and J. Weng, Developmental Learning: A Case Study in Understanding 'Object Perma- nence,' paper presented at the 4th International Workshop on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems, Genoa, Italy, August 25-27, 2004.

Chen Z Liu ; Zhiyuan Chen, Bing Liu, Lifelong Machine Learning. Morgan & Claypool PublishersChen Z and Liu 2016] Zhiyuan Chen and Bing Liu, Lifelong Machine Learning, Morgan & Claypool Publishers, November 2016.

The Semantic Development of Negation-A Cross-Linguistic Longitudinal-Study. S Choi ; N. Chomsky, ; N Chomsky, Deep reinforcement learning from human preferences. Leike, Tom B. Brown, Miljan Martic, Shane Legg, and Dario AmodeiThe Hague, Netherlands; Cambridge, MAPaul Christiano15Syntactic Structures[Choi 1988] S. Choi, The Semantic Development of Negation-A Cross-Linguistic Longitudinal-Study, in Journal of Child Language, 15(3)(Oct.): 517-531, 1988. [Chomsky 1957] N. Chomsky, Syntactic Structures, The Hague, Netherlands: Mouton, 1957. [Chomsky 1965] N. Chomsky, Aspects of the Theory of Syntax, Vol. 11, Cambridge, MA: MIT Press, 1965. [Christiano et al. 2017] Paul Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg, and Dario Amodei, Deep re- inforcement learning from human preferences, in arXiv, 2017, https://arxiv.org/pdf/1706.03741.pdf.

Connectionist Psycholinguistics: Capturing the Empirical Data. M H Christiansen, N Chater, Trends in Cognitive Sciences. 52[Christiansen and Chater 2001] M. H. Christiansen and N. Chater, Connectionist Psycholinguistics: Capturing the Empirical Data, in Trends in Cognitive Sciences, 5(2): 82-88, 2001.

Accelerating imitation learning through crowdsourcing. Chung , Proceedings -IEEE International Conference on Robotics and Automation. -IEEE International Conference on Robotics and AutomationInstitute of Electrical and Electronics Engineers Inc[Chung et al. 2014] Michael Jae Yoon Chung, Maxwell Forbes, Maya Cakmak, and Rajesh P. N. Rao, Accelerating imitation learning through crowdsourcing, in Proceedings -IEEE International Conference on Robotics and Automation, 4777- 4784, [6907558] Institute of Electrical and Electronics Engineers Inc., 2014.

What's in a word? On the child's acquisition of semantics in his first language, in Cognitive development and the acquisition of language. Ev ; Clark, V Eve, Clark, T. E. MooreAcademic PressNew YorkClark EV 1973] Eve V. Clark, What's in a word? On the child's acquisition of semantics in his first language, in Cognitive development and the acquisition of language, T. E. Moore (ed.), New York: Academic Press, 1973.

The Lexicon in Acquisition. Ev ; E V Clark, Clark, https:/journals.sagepub.com/doi/pdf/10.1177/105971239900700101?casa_token=RjhU6tCDoO0AAAAA:pSVegqbZffMOVLSDzWZqb1V1M9JEt3PmmmC4wJQd2yKKklHwt9zdtXq_SDPLOmL2RQpUdWDeyQTowards a Cognitive Robotics. Clark A and Grush 1999] Andy Clark and Rick GrushCambridge, UKCambridge University Press7Adaptive BehaviorClark EV 1993] E. V. Clark, The Lexicon in Acquisition, Cambridge, UK: Cambridge University Press, 1993. [Clark A and Grush 1999] Andy Clark and Rick Grush, Towards a Cognitive Robotics, in Adaptive Behavior, 7(1): 5-16, 1999, https://journals.sagepub.com/doi/pdf/10.1177/105971239900700101?casa_token=RjhU6tCDoO0AAAAA:pSVegqbZffM OVLSDzWZqb1V1M9JEt3PmmmC4wJQd2yKKklHwt9zdtXq_SDPLOmL2RQpUdWDeyQ.

A Longitudinal-Study of Intralimb Coordination in the 1st Year of Independent Walking-a Dynamical-Systems Analysis. Clark Phillips, ; J E Clark, S J Phillips, Child Development. 644[Clark JE and Phillips 1993] J. E. Clark and S. J. Phillips, A Longitudinal-Study of Intralimb Coordination in the 1st Year of Independent Walking-a Dynamical-Systems Analysis, in Child Development, 64(4)(Aug.): 1143-1157, 1993.

Is Visually Guided Reaching in Early Infancy a Myth?. Clifton , CMU 2008] CMU, The CMU Pronouncing Dictionary. 64Cohen LB 1977. Concept acquisition in the human infant[Clifton et al. 1993] R. K. Clifton, D. W. Muir, D. H. Ashmead, and M. G. Clarkson, Is Visually Guided Reaching in Early In- fancy a Myth?, in Child Development, 64(4)(Aug.): 1099-1110, 1993. [CMU 2008] CMU, The CMU Pronouncing Dictionary, 2008, http://www.speech.cs.cmu.edu/cgi-bin/cmudict. [Cohen LB 1977] Leslie B. Cohen, Concept acquisition in the human infant, 1977, http://files.eric.ed.gov/fulltext/ED135493.pdf.

A constructivist model of infant cognition. L B Cohen, Cognitive Development. 17[Cohen LB et al. 2002] L. B. Cohen, H. H. Chaput, and C. H. Cashon, A constructivist model of infant cognition, in Cogni- tive Development, 17: 1323-1343, 2002.

Lm ; Cohen, M Leonora, Cohen, A continuum of adaptive creative behaviors. 2Cohen LM 1989] Leonora M. Cohen, A continuum of adaptive creative behaviors, in Creativity Research Journal, 2(3): 169- 183, 1989.

Elucidating the Structure of Episodes. Pr ; Cohen, R Paul, Fluent Cohen, Learning, Proceedings of the Fourth Symposium on Intelligent Data Analysis. the Fourth Symposium on Intelligent Data AnalysisLisbonSpringerCohen PR 2001] Paul R. Cohen, Fluent Learning: Elucidating the Structure of Episodes, in Proceedings of the Fourth Sym- posium on Intelligent Data Analysis, Lisbon, 268-277, Springer, 2001, https://pdfs.semanticscholar.org/12eb/949ab293481e25802999dd0c040b5c73453a.pdf.

DARPA's Big Mechanism program. Pr ; Cohen, R Paul, Cohen, https:/iopscience.iop.org/article/10.1088/1478-3975/12/4/045008/pdfPhysical Biology. 124Cohen PR 2015] Paul R. Cohen, DARPA's Big Mechanism program, in Physical Biology, 12:4, 2015, https://iopscience.iop.org/article/10.1088/1478-3975/12/4/045008/pdf.

Modeling and Managing the World's Complicated Systems: A Challenge for AI, talk at National Academy President's Circle Meeting. Paul R Cohen, Cohen, Cohen PR 2018] Paul R. Cohen, Modeling and Managing the World's Complicated Systems: A Challenge for AI, talk at Na- tional Academy President's Circle Meeting, April 17, 2018, http://paulrcohen.github.io/papers/NationalAcademyAITalk.pdf.

Push Science, in personal archive. Cohen, R Paul, Cohen, Cohen PR 2020] Paul R. Cohen, Push Science, in personal archive, March 19, 2020, http://paulrcohen.github.io/papers/pushScience.pdf.

Building a Baby. P R Cohen, Proceedings of the Eighteenth Annual Conference of the Cognitive Science Society. the Eighteenth Annual Conference of the Cognitive Science Society[Cohen PR et al. 1996] Paul R. Cohen, Tim Oates, Marc S. Atkin, and Carole R. Beal, Building a Baby, in Proceedings of the Eighteenth Annual Conference of the Cognitive Science Society, 518-522, 1996, https://pdfs.semanticscholar.org/222b/9d35c2a43c1458648d1834e412303069ab73.pdf.

Learning conceptual knowledge by sensorimotor interaction with an environment. P R Cohen, Proceedings of the first international conference on Autonomous agents. the first international conference on Autonomous agentsACM[Cohen PR et al. 1997] Paul R. Cohen, Marc S. Atkin, Tim Oates, and Carole R. Beal, Neo: Learning conceptual knowledge by sensorimotor interaction with an environment, in Proceedings of the first international conference on Autonomous agents, 170-177, ACM, 1997, https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1194&context=cs_faculty_pubs.

Learning and transferring action schemas. P R Cohen, IJCAI 2007, Proceedings of the 20th International Joint Conference on Artificial Intelligence. IndiaHyderabad[Cohen PR et al. 2007] Paul Cohen, Yu-Han Chang, Clayton Morrison, and Carole Beal, Learning and transferring action schemas, in IJCAI 2007, Proceedings of the 20th International Joint Conference on Artificial Intelligence, 720 -725, Hy- derabad, India, January 6 -12, 2007, http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.89.911&rep=rep1&type=pdf.

Active learning with statistical models. [ Cohn, Journal of artificial intelligence research. 4[Cohn et al. 1996] David A. Cohn, Zoubin Ghahramani, and Michael I. Jordan, Active learning with statistical models, in Journal of artificial intelligence research, 4: 129-145, 1996.

The Emergence and Basis of Endogenous Attention in Infancy and Early Childhood. J Colombo, C L Cheatham, Advances in Child Development and Behavior. R. V. KailNew YorkAcademic Pressand Cheatham 2006] J. Colombo and C. L. Cheatham, The Emergence and Basis of Endogenous Attention in In- fancy and Early Childhood, in Advances in Child Development and Behavior, ed. R. V. Kail, 283-322, New York: Aca- demic Press, 2006.

Infant Visual Habituation. J Colombo, D W Mitchell, Neurobiology of Learning and Memory. 922[Colombo and Mitchell 2009] J. Colombo and D. W. Mitchell, Infant Visual Habituation, in Neurobiology of Learning and Memory, 92(2)(Sept.): 225-234, 2009.

Schema Based Learning: Towards a Theory of Organization for Adaptive Autonomous Agents. Fernando Corbacho, University of Southern CaliforniaPhD thesisFernando Corbacho, Schema Based Learning: Towards a Theory of Organization for Adaptive Autonomous Agents, PhD thesis, University of Southern California, August 1997, https://www.proquest.com/openview/423e7228fcd375e6e1fc27b6fa342f27/1?pq-origsite=gscholar&cbl=18750&diss=y.

Fernando Corbacho, Towards Self-constructive Artificial Intelligence: Algorithmic basis (Part I). in arXiv[Corbacho 2019] Fernando Corbacho, Towards Self-constructive Artificial Intelligence: Algorithmic basis (Part I), in arXiv, https://arxiv.org/pdf/1901.01989.pdf.

Motivation-Driven Learning of Object Affordances: First Experiments Using a Simulated Khepera Robot. S Cordes, R Gelman ; I. Cos-Aguilera, L Cañamero, G M Hayes, 9th International Conference in Cognitive Modelling. J. CampbellNew York; Bamberg, GermanyPsychology PressThe Young Numerical Mind: When Does It Count?, in Handbook of Mathematical Cognition. paper presented at the[Cordes and Gelman 2005] S. Cordes and R. Gelman, The Young Numerical Mind: When Does It Count?, in Handbook of Mathematical Cognition, J. Campbell (ed.), 127-142, New York: Psychology Press, 2005. [Cos-Aguilera et al. 2003] I. Cos-Aguilera, L. Cañamero, and G. M. Hayes, Motivation-Driven Learning of Object Af- fordances: First Experiments Using a Simulated Khepera Robot, paper presented at the 9th International Conference in Cognitive Modelling, Bamberg, Germany, 2003.

Infant to Child: The Dynamics of Cognitive Change in the Second Year of Life. M L Courage, M L Howe, Psychological Bulletin. 1282and Howe 2002] M. L. Courage and M. L. Howe, Infant to Child: The Dynamics of Cognitive Change in the Sec- ond Year of Life, in Psychological Bulletin, 128(2)(Mar.): 250-277, 2002.

[ Coventry, Grounding Natural Language Quantifiers in Visual Attention, paper presented at the 27th Annual Meeting of the Cognitive Science Society. Stresa, Italy[Coventry et al. 2005] K. R. Coventry, A. Cangelosi, S. Newstead, A. Bacon, and R. Rajapakse, Grounding Natural Language Quantifiers in Visual Attention, paper presented at the 27th Annual Meeting of the Cognitive Science Society, Stresa, Italy, 2005.

Even More Precisely Assessing Children's Understanding of the Order-Irrelevance Principle. [ Cowan, arXiv:2110.07732Róbert Csordás, Kazuki Irie, and Jürgen Schmidhuber, The Neural Data Router: Adaptive control flow in Transformers improves systematic generalization. CunninghamAcademic Press62Intelligence: Its Organization and Development[Cowan et al. 1996] R. Cowan, A. Dowker, A. Christakis, and S. Bailey, Even More Precisely Assessing Children's Under- standing of the Order-Irrelevance Principle, in Journal of Experimental Child Psychology, 62(1)(June): 84-101, 1996. [Csordás et al. 2021] Róbert Csordás, Kazuki Irie, and Jürgen Schmidhuber, The Neural Data Router: Adaptive control flow in Transformers improves systematic generalization, in arXiv:2110.07732, 2021, https://arxiv.org/pdf/2110.07732.pdf. [Cunningham 1972] Michael Cunningham, Intelligence: Its Organization and Development, Academic Press, 1972, https://play.google.com/books/reader?id=93mLBQAAQBAJ&printsec=frontcover&output=reader&hl=en&pg=GBS.PP1.

Design and Test of a Cognitive Model. A Michael, Harry J Cunningham, Gray, International Journal of Man-Machine Studies. 61Cunningham and Gray 1974[Cunningham and Gray 1974] Michael A. Cunningham and Harry J. Gray, Design and Test of a Cognitive Model, in Interna- tional Journal of Man-Machine Studies, 6(1): 49-104, 1974, https://vdocuments.net/design-and-test-of-a-cognitive- model.html.

An Overview and Tutorial of the Repertory Grid Technique in Information Systems Research. Curtis , Communications of the Association for Information Systems. 23[Curtis et al. 2008] Aaron Curtis, Taylor Wells, Paul Benjamin Lowry, and Trevor Higbee, An Overview and Tutorial of the Repertory Grid Technique in Information Systems Research, in Communications of the Association for Information Sys- tems (CAIS), 23(3): 37-62, 2008, https://www.researchgate.net/profile/Paul_Lowry/publication/228296401_An_Overview_and_Tutorial_of_the_Repertory _Grid_Technique_in_Information_Systems_Research/links/0c96051ef5bde6944c000000/An-Overview-and-Tutorial-of- the-Repertory-Grid-Technique-in-Information-Systems-Research.pdf.

Active learning of parameterized skills. [da Silva, Proceedings of the 31st International Conference on Machine Learning. the 31st International Conference on Machine Learning[Da Silva et al. 2014] Bruno Castro da Silva, George Konidaris, and Andrew G. Barto, Active learning of parameterized skills, in Proceedings of the 31st International Conference on Machine Learning, 2014, http://inf.ufrgs.br/~bsilva//active_paramSkill_icml2014.pdf.

J L Dannemiller, Competition in Early Exogenous Orienting between 7 and 21 Weeks. 76[Dannemiller 2000] J. L. Dannemiller, Competition in Early Exogenous Orienting between 7 and 21 Weeks, in Journal of Experimental Child Psychology, 76(4)(Aug.): 253-274, 2000.

M Davies, T Stone, Mental Simulation: Evaluations and Applications. Oxford, UKBlackwell Publishers[Davies and Stone 1995] M. Davies and T. Stone, Mental Simulation: Evaluations and Applications, Oxford, UK: Blackwell Publishers, 1995.

Commonsense Reasoning and Commonsense Knowledge in Artificial Intelligence. Ernest Davis, Gary Marcus, Communications of the ACM. 589and Marcusand Marcus 2015] Ernest Davis and Gary Marcus, Commonsense Reasoning and Commonsense Knowledge in Artifi- cial Intelligence, in Communications of the ACM, 58(9): 92-103, 2015, https://cs.nyu.edu/davise/papers/CommonsenseFinal.pdf.

Fixed-horizon temporal difference methods for stable reinforcement learning. Kristopher De Asis, Alan Chan, Silviu Pitis, Richard S Sutton, Daniel Graves, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence34de Asis et al. 2020[de Asis et al. 2020] Kristopher De Asis, Alan Chan, Silviu Pitis, Richard S. Sutton, and Daniel Graves, Fixed-horizon tem- poral difference methods for stable reinforcement learning, in Proceedings of the AAAI Conference on Artificial Intelli- gence, 34(04): 3741-3748, 2020, http://incompleteideas.net/papers/deasis-et-al-AAAI2020.pdf.

The Origins of Vowel Systems: Studies in the Evolution of Language. B Boer, Boer. Oxford University PressBoer 2001] B. de Boer, The Origins of Vowel Systems: Studies in the Evolution of Language, Oxford, UK: Oxford Uni- versity Press, 2001.

Personal Causation: The Internal Affective Determinants of Behavior. R De Charms, Academic PressNew YorkCharms 1968] R. de Charms, Personal Causation: The Internal Affective Determinants of Behavior, New York: Academ- ic Press, 1968.

Specialization of Neural Mechanisms Underlying Face Recognition in Human Infants. Haan, Journal of Cognitive Neuroscience. 142Haan et al. 2002] M. de Haan, O. Pascalis, and M. H. Johnson, Specialization of Neural Mechanisms Underlying Face Recognition in Human Infants, in Journal of Cognitive Neuroscience, 14(2): 199-209, 2002.

Bidirectional learning in upbound and downbound microzones of the cerebellum. Chris I De Zeeuw, Nature Reviews Neuroscience. 22De Zeeuw 2021De Zeeuw 2021] Chris I. De Zeeuw, Bidirectional learning in upbound and downbound microzones of the cerebellum, in Nature Reviews Neuroscience, 22: 92-110, Feb. 2021.

Three Controversial Hypotheses Concerning Computation in the Primate Cortex. [ Dean, Twenty-Sixth AAAI Conference on Artificial Intelligence. [Dean et al. 2012] Thomas Dean, Greg S. Corrado, and Jonathon Shlens, Three Controversial Hypotheses Concerning Com- putation in the Primate Cortex, in Twenty-Sixth AAAI Conference on Artificial Intelligence, 1543-1549, 2012, https://pdfs.semanticscholar.org/cba5/de2d74c226726d7c55a8dd0d6fd3b8d50572.pdf.

Learning Forward Models for Robots. Anthony Dearden, Yiannis Demiris, ; E L Deci, R M Ryan, Intrinsic Motivation and Self-Determination in Human Behavior. New YorkPlenum Press5International Joint Conference on Artificial Intelligence[Dearden and Demiris 2005] Anthony Dearden and Yiannis Demiris, Learning Forward Models for Robots, in International Joint Conference on Artificial Intelligence, 5: 1440-1445, 2005, https://core.ac.uk/download/pdf/19783294.pdf. [Deci and Ryan 1985] E. L. Deci and R. M. Ryan, Intrinsic Motivation and Self-Determination in Human Behavior, New York: Plenum Press, 1985.

Hand Placement During Quadruped Locomotion in a Humanoid Robot: A Dynamical System Approach. [ Degallier, RSJ International Conference on Intelligent Robots and Systems. paper presented at the IEEE[Degallier et al. 2007] S. Degallier, L. Righetti, and A. Ijspeert, Hand Placement During Quadruped Locomotion in a Hu- manoid Robot: A Dynamical System Approach, paper presented at the IEEE/RSJ International Conference on Intelligent Robots and Systems, San Diego, CA, October 29-November 2, 2007.

A Modular Bio-Inspired Architecture for Movement Generation for the Infant-Like Robot iCub. [ Degallier, 2nd IEEE RAS & EMBS International Conference on Biomedical Robotics and Biomechatronics. New Yorkpaper presented at the[Degallier et al. 2008] S. Degallier, L. Righetti, L. Natale, F. Nori, G. Metta, and A. Ijspeert, A Modular Bio-Inspired Archi- tecture for Movement Generation for the Infant-Like Robot iCub, paper presented at the 2nd IEEE RAS & EMBS Interna- tional Conference on Biomedical Robotics and Biomechatronics, New York, October 19-22, 2008.

S Dehaene, The Number Sense: How the Mind Creates Mathematics. Oxford, UKOxford University Press[Dehaene 1997] S. Dehaene, The Number Sense: How the Mind Creates Mathematics, Oxford, UK: Oxford University Press, 1997.

The Mental Representation of Parity and Number Magnitude. [ Dehaene, Journal of Experimental Psychology: General. 1223[Dehaene et al. 1993] S. Dehaene, S. Bossini, and P. Giraux, The Mental Representation of Parity and Number Magnitude, in Journal of Experimental Psychology: General, 122(3)(Sept.): 371-396, 1993.

Beyond the Abstract-Concrete Dichotomy: Mode of Acquisition, Concreteness, Imageability, Familiarity, Age of Acquisition, Context Availability, and Abstractness Norms for a Set of 417 Italian Words. Rosa [della, Proceedings of the 5th International Workshop on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems. the 5th International Workshop on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems42Lund University Cognitive StudiesBehavior Research Methods[Della Rosa et al. 2010] P. A. Della Rosa, E. Catricala, G. Vigliocco, and S. F. Cappa, Beyond the Abstract-Concrete Dichot- omy: Mode of Acquisition, Concreteness, Imageability, Familiarity, Age of Acquisition, Context Availability, and Ab- stractness Norms for a Set of 417 Italian Words, in Behavior Research Methods, 42(4)(Nov.): 1042-1048, 2010. [Demiris and Deardon 2005] Y. Demiris and A. Dearden, From Motor Babbling to Hierarchical Learning by Imitation: A Ro- bot Developmental Pathway, in Proceedings of the 5th International Workshop on Epigenetic Robotics: Modeling Cogni- tive Development in Robotic Systems, ed. L. Berthouze et al., 31-37, Vol. 123, Lund University Cognitive Studies. 2005, http://cogprints.org/4961.

Imitation as a Dual-Route Process Featuring Predictive and Learning Components: A Biologically Plausible Computational Model. G Demiris, Hayes, Imitation in Animals and Artifacts. K. Dautenhahn and C. L. NehanivCambridge, MAMIT Press[Demiris and Hayes 2002] Y. Demiris and G. Hayes, Imitation as a Dual-Route Process Featuring Predictive and Learning Components: A Biologically Plausible Computational Model, in Imitation in Animals and Artifacts, ed. K. Dautenhahn and C. L. Nehaniv, 327-361, Cambridge, MA: MIT Press, 2002.

Distributed, Predictive Perception of Actions: A Biologically Inspired Robotics Architecture for Imitation and Learning. Y Demiris, M Johnson, Connection Science. 15Khadhouri, Hierarchical Attentive Multiple Models for Execution and Recognition of Actions[Demiris and Johnson 2003] Y. Demiris and M. Johnson, Distributed, Predictive Perception of Actions: A Biologically In- spired Robotics Architecture for Imitation and Learning, in Connection Science, 15(4)(Dec.): 231-243, 2003. [Demiris and Khadhouri 2006] Y. Demiris and B. Khadhouri, Hierarchical Attentive Multiple Models for Execution and Recognition of Actions, in Robotics and Autonomous Systems, 54(5): 361-369, 2006.

The Robot in the Crib: A Developmental Analysis of Imitation Skills in Infants and Robots. Y Demiris, A Meltzoff, Infant and Child Development. 17Demiris and Meltzoff[Demiris and Meltzoff 2008] Y. Demiris and A. Meltzoff, The Robot in the Crib: A Developmental Analysis of Imitation Skills in Infants and Robots, in Infant and Child Development, 17(1)(Jan.-Feb.): 43-53, 2008.

Perceiving the Unusual: Temporal Properties of Hierarchical Motor Representations for Action Perception. Y Demiris, G Simmons, Neural Networks. 193Demiris and Simmons[Demiris and Simmons 2006] Y. Demiris and G. Simmons, Perceiving the Unusual: Temporal Properties of Hierarchical Mo- tor Representations for Action Perception, in Neural Networks, 19(3): 272-284, 2006.

Deferred Imitation of Human Head Movements by an Active Stereo Vision Head, paper presented at the 6th IEEE International Workshop on Robot and Human Communication. Demiris, New York[Demiris et al. 1997] Y. Demiris, S. Rougeaux, G. M. Hayes, L. Berthouze, and Y. Kuniyoshi, Deferred Imitation of Human Head Movements by an Active Stereo Vision Head, paper presented at the 6th IEEE International Workshop on Robot and Human Communication, New York, September 29-October 1, 1997.

To Advance Artificial Intelligence, Reverse-Engineer the Brain, in Wired magazine Opinion on line. James J Dicarlo, [DiCarlo 2018] James J. DiCarlo, To Advance Artificial Intelligence, Reverse-Engineer the Brain, in Wired magazine Opinion on line, January 3, 2018, https://www.wired.com/story/to-advance-artificial-intelligence-reverse-engineer-the-brain/.

Learning in nonstationary environments: A survey. [ Ditzler, IEEE Computational Intelligence Magazine. 104[Ditzler et al. 2015] Gregory Ditzler, Manuel Roveri, Cesare Alippi, and Robi Polikar, Learning in nonstationary environ- ments: A survey, in IEEE Computational Intelligence Magazine, 10(4): 12-25, 2015, https://www.researchgate.net/profile/Robi- Polikar/publication/282907128_Learning_in_Nonstationary_Environments_A_Survey/links/562557eb08aeabddac91cc01/ Learning-in-Nonstationary-Environments-A-Survey.pdf.

Developmental Stages of Perception and Language Acquisition in a Perceptually Grounded Robot. P F Dominey, J D Boucher, Cognitive Systems Research. 63Dominey and Boucher[Dominey and Boucher 2005a] P. F. Dominey and J. D. Boucher, Developmental Stages of Perception and Language Acquisi- tion in a Perceptually Grounded Robot, in Cognitive Systems Research, 6(3): 243-259, 2005.

Learning to Talk about Events from Narrated Video in a Construction Grammar Framework. P F Dominey, J D Boucher, Artificial Intelligence. 1671-2Dominey and Boucher[Dominey and Boucher 2005b] P. F. Dominey and J. D. Boucher, Learning to Talk about Events from Narrated Video in a Construction Grammar Framework, in Artificial Intelligence, 167(1-2)(Dec.): 31-61, 2005.

The Basis of Shared Intentions in Human and Robot Cognition. P F Dominey, F Warneken, New Ideas in Psychology. 293and Warneken 2011] P. F. Dominey and F. Warneken, The Basis of Shared Intentions in Human and Robot Cogni- tion, in New Ideas in Psychology, 29(3)(Dec.): 260-274, 2011.

A Neurolinguistic Model of Grammatical Construction Processing. Dominey, Journal of Cognitive Neuroscience. 1812[Dominey et al. 2006] P. F. Dominey, M. Hoen, and T. Inui, A Neurolinguistic Model of Grammatical Construction Pro- cessing, in Journal of Cognitive Neuroscience, 18(12): 2088-2107, 2006.

The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World. Pedro Domingos, Pedro Domingos, The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World, 2015, https://homes.cs.washington.edu/~pedrod/.

The Schema System. [ Draper, International Journal of Computer Vision. 2[Draper et al. 1989] Bruce A. Draper, Robert T. Collins, John Brolio, Allen R. Hanson, and Edward M. Riseman, The Schema System, in International Journal of Computer Vision, 2: 209-250, 1989, https://www.cs.colostate.edu/~draper/papers/draper_ijcv89.pdf.

A mechanism for early piagetian learning. L Gary, Drescher, Proceedings of Fifth National Conference on Artificial Intelligence. Fifth National Conference on Artificial IntelligenceMIT Press[Drescher 1987] Gary L. Drescher, A mechanism for early piagetian learning, in Proceedings of Fifth National Conference on Artificial Intelligence, MIT Press, 1987, https://www.aaai.org/Papers/AAAI/1987/AAAI87-052.pdf.

Made-Up Minds: A Constructivist Approach to Artificial Intelligence. Gary Drescher, MIT PhD Thesis[Drescher 1989] Gary Drescher, Made-Up Minds: A Constructivist Approach to Artificial Intelligence, MIT PhD Thesis, 1989, https://dspace.mit.edu/handle/1721.1/77702.

Adaptive Non-negative Matrix Factorization in a Computational Model of Language Acquisition, paper presented at the 10th Annual Conference of the International Speech Communication Association. L Gary, Made-Up Drescher, J Minds ; Driesen, L Bosch, H Van Hamme, A Constructivist Approach to Artificial Intelligence. MIT PressDriesen et al. 2009[Drescher 1991] Gary L. Drescher, Made-Up Minds, A Constructivist Approach to Artificial Intelligence, MIT Press, 1991. [Driesen et al. 2009] Driesen, J., L. ten Bosch, and H. van Hamme, Adaptive Non-negative Matrix Factorization in a Compu- tational Model of Language Acquisition, paper presented at the 10th Annual Conference of the International Speech Communication Association, Brighton, UK, September 6-10, 2009.

One-shot imitation learning. Duan, Ilya Sutskever, Pieter Abbeel, and Wojciech Zaremba. [Duan et al. 2017] Yan Duan, Marcin Andrychowicz, Bradly C. Stadie, Jonathan Ho, Jonas Schneider, Ilya Sutskever, Pieter Abbeel, and Wojciech Zaremba, One-shot imitation learning, in arXiv, 2017, https://arxiv.org/pdf/1703.07326.pdf.

Cognitive Science in the era of Artificial Intelligence: A roadmap for reverse-engineering the infant language-learner. Jeffrey L Elman, 10.1016/j.cognition.2017.11.008Cognition. 48Learning and development in neural networks: The importance of starting small[Dupoux 2016] Emmanuel Dupoux, Cognitive Science in the era of Artificial Intelligence: A roadmap for reverse-engineering the infant language-learner, 2016, https://doi.org/10.1016/j.cognition.2017.11.008, https://arxiv.org/pdf/1607.08723.pdf. [Elman 1993] Jeffrey L. Elman, Learning and development in neural networks: The importance of starting small, in Cogni- tion, 48: 781-799, 1993.

Elman, Rethinking Innateness: A Connectionist Perspective on Development. Cambridge, MAMIT Press14Visual Control of Hand Approach Movements in New-Borns[Elman et al. 1996] Jeffrey Elman, Elizabeth Bates, Mark H. Johnson, Annette Karmiloff-Smith, Domenico Parisi, and Kim Plunkett, Rethinking Innateness: A Connectionist Perspective on Development, Cambridge, MA: MIT Press, 1996. [Ennouri and Bloch 1996] K. Ennouri and H. Bloch, Visual Control of Hand Approach Movements in New-Borns, in British Journal of Developmental Psychology, 14(Sept.): 327-338, 1996.

R P Erhardt, Developmental Hand Dysfunction: Theory, Assessment, and Treatment. Tuscon, AZTherapy Skill Builders[Erhardt 1994] R. P. Erhardt, Developmental Hand Dysfunction: Theory, Assessment, and Treatment, Tuscon, AZ: Therapy Skill Builders, 1994.

Motor Facilitation During Action Observation: A Magnetic Stimulation Study. [ Fadiga, Journal of Neurophysiology. 736[Fadiga et al. 1995] L. Fadiga, L. Fogassi, G. Pavesi, and G. Rizzolatti, Motor Facilitation During Action Observation: A Magnetic Stimulation Study, in Journal of Neurophysiology, 73(6): 2608-2611, 1995.

The cascade-correlation architecture. S E Fahlman, C Lebiere, Advances in neural information processing systems. D. S. TouretzkyMorgan KaufmannFahlman and Lebiere[Fahlman and Lebiere 1990] S. E. Fahlman and C. Lebiere, The cascade-correlation architecture, in Advances in neural in- formation processing systems, D. S. Touretzky (ed.), Morgan Kaufmann, 1990, http://web.cs.iastate.edu/~honavar/fahlman.pdf.

Balancing new against old information: The role of surprise in learning. R L Fantz, arXiv:1606.05642Mohammadjavad Faraji, Kerstin Preuschoff, and Wulfram Gerstner. 6arXiv[Fantz 1956] R. L. Fantz, A Method for Studying Early Visual Development, in Perceptual and Motor Skills, 6: 13-15,1956. [Faraji et al. 2016] Mohammadjavad Faraji, Kerstin Preuschoff, and Wulfram Gerstner, Balancing new against old infor- mation: The role of surprise in learning, in arXiv, arXiv:1606.05642, 2016, https://arxiv.org/pdf/1606.05642.pdf.

Combining Embodied Models and Empirical Research for Understanding the Development of Shared Attention. Fasel, 2nd International Conference on Development and Learning. Cambridge, MAMassachusetts Institute of Technologypaper presented at the[Fasel et al. 2002] I. Fasel, G. O. Deak, J. Triesch, and J. Movellan, Combining Embodied Models and Empirical Research for Understanding the Development of Shared Attention, paper presented at the 2nd International Conference on Devel- opment and Learning, Massachusetts Institute of Technology, Cambridge, MA, June 12-15, 2002.

Conceptual Integration Networks. Gilles Fauconnier, Mark Turner, Cognitive Science. 222and Turnerand Turner 1998] Gilles Fauconnier and Mark Turner, Conceptual Integration Networks, in Cognitive Science, 22(2): 133-187, 1998, https://markturner.org/cinLEA.pdf.

Learning Cumulatively to Become More Knowledgeable. [ Fei, KDD. [Fei et al. 2016] Geli Fei, Shuai Wang, and Bing Liu, Learning Cumulatively to Become More Knowledgeable, in KDD, 2016, http://www.kdd.org/kdd2016/papers/files/rpp0426-feiA.pdf.

One-Shot Learning of Object Categories. Fei-Fei, IEEE Transactions on Pattern Analysis and Machine Intelligence. 28Fei-Fei et al. 2006] Li Fei-Fei, Rob Fergus, and Pietro Perona, One-Shot Learning of Object Categories, in IEEE Transac- tions on Pattern Analysis and Machine Intelligence, 28(4), April 2006, http://vision.stanford.edu/documents/Fei- FeiFergusPerona2006.pdf.

Neonatal Imitation in Rhesus Macaques. Fenson, Variability in Early Communicative Development, in Monographs of the Society for Research in Child Development. 59discussion 74-85. Ferrari et al. 2006[Fenson et al. 1994] L. Fenson, P. S. Dale, J. S. Reznick, E. Bates, D. J. Thal, and S. J. Pethick, Variability in Early Commu- nicative Development, in Monographs of the Society for Research in Child Development, 59(5): 1-173, discussion 74-85, 1994. [Ferrari et al. 2006] P. F. Ferrari, E. Visalberghi, A. Paukner, L. Fogassi, A. Ruggiero, and S. J. Suomi, Neonatal Imitation in Rhesus Macaques, in PLoS Biology, 4(9): 1501-1508, 2006.

Internally Generated Error Signals in Monkey Frontal Eye Field During an Inferred Motion Task. V P Ferrera, A Barborica, Journal of Neuroscience. 3035Ferrera and Barborica 2010[Ferrera and Barborica 2010] V. P. Ferrera and A. Barborica, Internally Generated Error Signals in Monkey Frontal Eye Field During an Inferred Motion Task, in Journal of Neuroscience, 30(35)(Sept.): 11612-11623, 2010.

Discrimination and Imitation of Facial Expressions by Term and Preterm Neonates. J M Field ; T, R Field, D Woodson, R Cohen, R Greenberg, K Garcia, Collins, PMLR 70Proceedings of the 34th International Conference on Machine Learning. Finn, Pieter Abbeel, and Sergey Levinethe 34th International Conference on Machine LearningSydney, Australia48Child DevelopmentJ. Field, Coordination of Vision and Prehension in Young Infants, in Child Development, 48(1): 97-103, 1977. [Field et al. 1983] T. M. Field, R. Woodson, D. Cohen, R. Greenberg, R. Garcia, and K. Collins, Discrimination and Imitation of Facial Expressions by Term and Preterm Neonates, in Infant Behavior and Development, 6(4): 485-489, 1983. [Finn et al. 2017] Chelsea Finn, Pieter Abbeel, and Sergey Levine, Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks, in Proceedings of the 34th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017, https://arxiv.org/pdf/1703.03400.pdf.

Instrumental Conditioning Driven by Neutral Stimuli: A Model Tested with a Simulated Robotic Rat, paper presented at the 8th International Workshop on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems. [ Fiore, Brighton, UK[Fiore et al. 2008] V. Fiore, F. Mannella, M. Mirolli, K. Gurney, and G. Baldassarre, Instrumental Conditioning Driven by Neutral Stimuli: A Model Tested with a Simulated Robotic Rat, paper presented at the 8th International Workshop on Epi- genetic Robotics: Modeling Cognitive Development in Robotic Systems, Brighton, UK, July 30-31, 2008.

A Theory of Cognitive-Development: The Control and Construction of Hierarchies of Skills. W Fischer Kw 1980] K, Fischer, Psychological Review. 876Fischer KW 1980] K. W. Fischer, A Theory of Cognitive-Development: The Control and Construction of Hierarchies of Skills, in Psychological Review, 87(6): 477-531, 1980.

Perceiving Numbers Causes Spatial Shifts of Attention. M H Fischer, Nature Neuroscience. 66[Fischer MH et al. 2003] M. H. Fischer, A. D. Castel, M. D. Dodd, and J. Pratt, Perceiving Numbers Causes Spatial Shifts of Attention, in Nature Neuroscience, 6(6): 555-556, 2003.

Mh ; M H Fischer, Fischer, Finger Counting Habits Modulate Spatial-Numerical Associations. 44Fischer MH 2008] M. H. Fischer, Finger Counting Habits Modulate Spatial-Numerical Associations, in Cortex, 44(4)(Apr.): 386-392, 2008.

[ Fisher, Concept Formation: Knowledge and Experience in Unsupervised Learning. Douglas H. Fisher, Michael J. Pazzani, and Pat LangleyMorgan Kaufmann[Fisher et al. 1991] Douglas H. Fisher, Michael J. Pazzani, and Pat Langley (eds.), Concept Formation: Knowledge and Ex- perience in Unsupervised Learning, Morgan Kaufmann, 1991.

Feel the Beat: Using Cross-Modal Rhythm to Integrate Perception of Objects, Others, and Self, paper presented at the 4th International Workshop on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems. P Fitzpatrick, A Arsenio, Genoa, Italy[Fitzpatrick and Arsenio 2004] P. Fitzpatrick and A. Arsenio, Feel the Beat: Using Cross-Modal Rhythm to Integrate Percep- tion of Objects, Others, and Self, paper presented at the 4th International Workshop on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems, Genoa, Italy, August 25-27, 2004.

Shared Challenges in Object Perception for Robots and Infants. [ Fitzpatrick, Infant and Child Development. 17[Fitzpatrick et al. 2008] P. A. Fitzpatrick, A. Needham, L. Natale, and G. Metta, Shared Challenges in Object Perception for Robots and Infants, in Infant and Child Development, 17(1)(Jan.-Feb. 2008): 7-24, 2008.

. John Hurley Flavell, The Developmental Psychology Of Jean, D Piaget, Van Nostrand, John Hurley Flavell, The Developmental Psychology of Jean Piaget, D. Van Nostrand, 1963, https://www.amazon.com/Developmental-Psychology-Jean-Piaget-ebook/dp/B087J7RCP7/.

A Critical Period for Learning to Pronounce Foreign-Languages. J E Flege, Applied Linguistics. Summer8[Flege 1987] J. E. Flege, A Critical Period for Learning to Pronounce Foreign-Languages, in Applied Linguistics, 8(2)(Summer): 162-177, 1987.

Paying Attention to What's Important: Using Focus of Attention to Improve Unsupervised Learning. N Leonard, Pattie Foner, Maes, The Third International Conference on the Simulation of Adaptive Behavior (SAB94). Brighton, Englandand Maes 1994and Maes 1994] Leonard N. Foner and Pattie Maes, Paying Attention to What's Important: Using Focus of Attention to Improve Unsupervised Learning, paper presented at The Third International Conference on the Simulation of Adaptive Behavior (SAB94), Brighton, England, 1994, http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.7052&rep=rep1&type=pdf.

Perceptual Control Theory: An Overview of the Third Grand Theory in Psychology -Introduction, Readings, and Resources. Living Control Systems PublishingForssell 2016] Dag Forssell[Forssell 2016] Dag Forssell (ed.), Perceptual Control Theory: An Overview of the Third Grand Theory in Psychology -In- troduction, Readings, and Resources, Living Control Systems Publishing, 2016, https://books.google.com/books?hl=en&lr=&id=50MpDAAAQBAJ&oi=fnd&pg=PR7&dq=%22Living+control+systems +III:+The+fact+of+control%22&ots=kUIAwRKX0n&sig=AYZnz0U1me8y8DRfQ7FltPfJU2k#v=onepage&q=%22Livin g%20control%20systems%20III%3A%20The%20fact%20of%20control%22&f=false.

Robots that Say 'No': Acquisition of Linguistic Behaviour in Interaction Games with Humans. F Förster, UKHertfordshire UniversityPhD thesis[Förster 2013] F. Förster, Robots that Say 'No': Acquisition of Linguistic Behaviour in Interaction Games with Humans, PhD thesis, Hertfordshire University, UK, 2013.

Using Real-Time Recognition of Human-Robot Interaction Styles for Creating Adaptive Robot Behaviour in Robot-Assisted Play. [ Förster, IEEE Symposium on Artificial Life. Kampis, I. Karsai, and E. SzathmárySpringer-VerlagRobots That Say 'No,' in Advances in Artificial Life: Darwin Meets Von Neumann. paper presented at the 2nd[Förster et al. 2011] F. Förster, C. L. Nehaniv, and J. Saunders, Robots That Say 'No,' in Advances in Artificial Life: Darwin Meets Von Neumann, G. Kampis, I. Karsai, and E. Szathmáry (eds.), 158-166, Berlin: Springer-Verlag, 2011. [François et al. 2009a] D. François, K. Dautenhahn, and D. Polani, Using Real-Time Recognition of Human-Robot Interac- tion Styles for Creating Adaptive Robot Behaviour in Robot-Assisted Play, paper presented at the 2nd IEEE Symposium on Artificial Life, Nashville, TN, 2009.

A Long-Term Study of Children with Autism Playing with a Robotic Pet Taking Inspirations from Non-Directive Play Therapy to Encourage Children's Proactivity and Initiative-Taking. François, Interaction Studies: Social Behaviour and Communication in Biological and Artificial Systems. 103[François et al. 2009b] D. François, S. Powell, and K. Dautenhahn, A Long-Term Study of Children with Autism Playing with a Robotic Pet Taking Inspirations from Non-Directive Play Therapy to Encourage Children's Proactivity and Initiative- Taking, in Interaction Studies: Social Behaviour and Communication in Biological and Artificial Systems, 10(3): 324- 373, 2009.

. Frans, Meta Learning Shared Hierarchies. in arXiv[Frans et al. 2017] Kevin Frans, Jonathan Ho, Xi Chen, Pieter Abbeel, and John Schulman, Meta Learning Shared Hierar- chies, in arXiv, Oct. 2017, https://arxiv.org/pdf/1710.09767.pdf.

A Unified Computational Model of the Development of Object Unity, Object Permanence, and Occluded Object Trajectory Perception. A Franz, J Triesch, Infant Behavior and Development. 33Franz and Triesch 2010[Franz and Triesch 2010] A. Franz and J. Triesch, A Unified Computational Model of the Development of Object Unity, Ob- ject Permanence, and Occluded Object Trajectory Perception, in Infant Behavior and Development, 33(4)(Dec.): 635-653, 2010.

The upstart algorithm: A method for constructing and training feedforward neural networks. M Frean, Neural Computation. 2M. Frean, The upstart algorithm: A method for constructing and training feedforward neural networks, in Neu- ral Computation, 2: 198-209, 1990.

Developmental-Changes in Interlimb Coordition-Transition to Hands-and-Knees Crawling. R L Freedland, B I Bertenthal, Psychological Science. 51and Bertenthal 1994] R. L. Freedland and B. I. Bertenthal, Developmental-Changes in Interlimb Coordition- Transition to Hands-and-Knees Crawling, in Psychological Science, 5(1): 26-32, 1994.

Imitation learning with hierarchical actions. Rao ; A L Friesen, R P N Friesen, Rao, IEEE 9th International Conference on Development and Learning. Ann Arbor, MI[Friesen and Rao 2010] A. L. Friesen and R. P. N. Rao, Imitation learning with hierarchical actions, in IEEE 9th International Conference on Development and Learning, 263-268, Ann Arbor, MI, 2010, http://aiweb.cs.washington.edu/research/projects/aiweb/media/papers/mhrl_icdl2010.pdf.

Learning Predictive Features in Affordance Based Robotic Perception Systems. [ Fritz, RSJ International Conference on Intelligent Robots and Systems. paper presented at the IEEE[Fritz et al. 2006] G. Fritz, L. Paletta, R. Breithaupt, E. Rome, and G. Dorffner, Learning Predictive Features in Affordance Based Robotic Perception Systems, paper presented at the IEEE/RSJ International Conference on Intelligent Robots and Systems, Beijing, China, October 9-15, 2006.

[ Fuke, Visuo-Tactile Face Representation through Self-Induced Motor Activity, paper presented at the 1st International Conference on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems. Lund, Sweden[Fuke et al. 2007] S. Fuke, M. Ogino, and M. Asada, Visuo-Tactile Face Representation through Self-Induced Motor Activity, paper presented at the 1st International Conference on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems, Lund, Sweden, September 17-18, 2007.

Face Recognition Algorithms and the Other-Race Effect: Computational Mechanisms for a Developmental Contact Hypothesis. Basing Knowledge Acquisition Tools in Personal Construct Psychology. 26University of Calgaryet al. 2002] N. Furl, P. J. Phillips, and A. J. O'Toole, Face Recognition Algorithms and the Other-Race Effect: Computa- tional Mechanisms for a Developmental Contact Hypothesis, in Cognitive Science, 26(6)(Nov.-Dec.): 797-815, 2002. [Gaines and Shaw 1991] Brian R. Gaines and Mildred L. G. Shaw, Basing Knowledge Acquisition Tools in Personal Con- struct Psychology, University of Calgary, 1991, https://prism.ucalgary.ca/handle/1880/45483.

Computer aided constructivism. R Brian, Mildred L G Gaines, P Shaw ; Caputi, L L Viney, Constructivist Methods. Crittenden, N.Gaines and Shaw 2012[Gaines and Shaw 2012] Brian R. Gaines and Mildred L. G. Shaw, Computer aided constructivism, in Constructivist Meth- ods, Caputi, P., Viney, L. L., Walker, B. M. and Crittenden, N. (eds.), 183 -222, 2012, http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.414.1037&rep=rep1&type=pdf.

Max Garagnani and Friedemann Pulvermuller, Conceptual grounding of language in action and perception: a neurocomputational model of the emergence of category specificity and semantic hubs. G G Gallup, European Journal of Neuroscience. 1673914Science[Gallup 1970] G. G. Gallup, Chimpanzees: Self-Recognition, in Science, 167(3914)(Jan. 2): 86-87, 1970. [Garagnani and Pulvermuller 2016] Max Garagnani and Friedemann Pulvermuller, Conceptual grounding of language in ac- tion and perception: a neurocomputational model of the emergence of category specificity and semantic hubs, in European Journal of Neuroscience, 43: 721-737, 2016.

The fantastic combinations of John Conway's new solitaire game 'life', in Scientific American. Martin Gardner, Mathematical Games. 2234Martin Gardner, The fantastic combinations of John Conway's new solitaire game 'life', in Scientific Ameri- can, Mathematical Games, 223(4): 120-123, 1970.

First Principles Organize Attention to and Learning About Relevant Data: Number and the Animate-Inanimate Distinction as Examples. R Gelman, Cognitive Science. 141Gelman[Gelman 1990] R. Gelman, First Principles Organize Attention to and Learning About Relevant Data: Number and the Ani- mate-Inanimate Distinction as Examples, in Cognitive Science, 14(1): 79-106, 1990.

Further Investigations of the Young Child's Conception of Number. R Gelman, M F Tucker, Child Development. 461Gelman and Tucker 1975[Gelman and Tucker 1975] R. Gelman and M. F. Tucker, Further Investigations of the Young Child's Conception of Number, in Child Development, 46(1): 167-175, 1975.

Young Childrens Numerical Competence. [ Gelman, Cognitive Development. 11[Gelman et al. 1986] R. Gelman, E. Meck, and S. Merkin, Young Childrens Numerical Competence, in Cognitive Develop- ment, 1(1): 1-29, 1986.

Army Research Institute for the Behavioral and Social Sciences. [ Gennari, 88-79U.S; ARI Research NoteModels of Incremental Concept Formation[Gennari et al. 1989] John Gennari, Pat Langley, and Douglas Fisher, Models of Incremental Concept Formation, U.S. Army Research Institute for the Behavioral and Social Sciences, ARI Research Note 88-79, 1989, http://www.dtic.mil/dtic/tr/fulltext/u2/a199617.pdf.

A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs. [ George, Science. 3586368[George et al. 2017] Dileep George, Wolfgang Lehrach, Ken Kansky, Miguel Lázaro-Gredilla, Christopher Laan, Bhaskara Marthi, Xinghua Lou, Zhaoshi Meng, Yi Liu, Huayan Wang, Alex Lavin, and D. Scott Phoenix, A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs, in Science, 358(6368), 08 Dec 2017, http://science.sciencemag.org/content/358/6368/eaag2612/tab-pdf.

[ Gerber, Developmental Milestones: Motor Development. 31Pediatrics[Gerber et al. 2010] R. J. Gerber, T. Wilks, and C. Erdie-Lalena, Developmental Milestones: Motor Development, in Pediat- rics, 31(7)(July): 267-277, 2010.

What Should a Robot Learn from an Infant? Mechanisms of Action Interpretation and Observational Learning in Infancy. G Gergely, Connection Science. 154[Gergely 2003] G. Gergely, What Should a Robot Learn from an Infant? Mechanisms of Action Interpretation and Observa- tional Learning in Infancy, in Connection Science, 15(4)(Dec.): 191-209, 2003.

Early Socio-Emotional Development: Contingency Perception and the Social-Biofeedback Model. G Gergely, J S Watson, Early Social Cognition: Understanding Others in the First Months of Life. Mahwah, NJErlbaumand Watsonand Watson 1999] G. Gergely and J. S. Watson, Early Socio-Emotional Development: Contingency Perception and the Social-Biofeedback Model, in Early Social Cognition: Understanding Others in the First Months of Life, ed. P. Ro- chat, 101-136, Mahwah, NJ: Erlbaum, 1999.

The Ontogenesis of Infant Behavior. A , Manual of Child Psychology. L. CarmichaelNew York; New YorkWileyThe Embryology of BehaviorA. Gesell, The Embryology of Behavior, New York: Harper and Row, 1945. [Gesell 1946] A. Gesell, The Ontogenesis of Infant Behavior, in Manual of Child Psychology, ed. L. Carmichael, 295-331, New York: Wiley, 1946.

The cognitive psychological reality of image schemas and their transformations. Raymond W Gibbs, Jr Herbert, L Colston, Cognitive Linguistics. 6[Gibbs and Colston 1995] Raymond W. Gibbs, Jr. and Herbert L. Colston, The cognitive psychological reality of image schemas and their transformations, in Cognitive Linguistics, 6(4): 347-378, 1995.

The Ecological Approach to Visual Perception. J J Gibson, Lawrence Erlbaum AssociatesHillsdale, NJ[Gibson 1986] J. J. Gibson, The Ecological Approach to Visual Perception, Hillsdale, NJ: Lawrence Erlbaum Associates, 1986.

Piaget's Theory of Intellectual Development. E J Gibson, R D O Walk ; T, H Gilmore, H P Thomas, S Ginsburg, Opper, Examining Individual Differences in Infants' Habituation Patterns Using Objective Quantitative Techniques, in Infant Behavior and Development. Englewood Cliffs, NJPrentice-Hall, Inc202The 'Visual Cliffand Walk 1960] E. J. Gibson and R. D. Walk, The 'Visual Cliff,' in Scientific American, 202: 64-71, 1960. [Gilmore and Thomas 2002] T. O. Gilmore and H. Thomas, Examining Individual Differences in Infants' Habituation Pat- terns Using Objective Quantitative Techniques, in Infant Behavior and Development, 25(4): 399-412, 2002. [Ginsburg and Opper 1988] H. P. Ginsburg and S. Opper, Piaget's Theory of Intellectual Development, Englewood Cliffs, NJ: Prentice-Hall, Inc., 1988.

A Computational Model for Grounding Words in the Perception of Agents. C Gläser, F Joublin, 9th IEEE International Conference on Development and Learning. Ann Arbor, MIpaper presented at theand Joublin 2010] C. Gläser and F. Joublin, A Computational Model for Grounding Words in the Perception of Agents, paper presented at the 9th IEEE International Conference on Development and Learning, Ann Arbor, MI, August 18-21, 2010.

Alec Radford, and Chris Olah, Multimodal neurons in artificial neural networks. Gabriel Goh, Nick Cammarata, Chelsea Voss, Shan Carter, Michael Petrov, Ludwig Schubert, 630Goh et al. 2021. in Distill[Goh et al. 2021] Gabriel Goh, Nick Cammarata, Chelsea Voss, Shan Carter, Michael Petrov, Ludwig Schubert, Alec Rad- ford, and Chris Olah, Multimodal neurons in artificial neural networks, in Distill, 6(3): e30, 2021, https://distill.pub/2021/multimodal- neurons/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter.

Using Probabilistic Reasoning over Time to Self-Recognize. K Gold, B Scassellati, Robotics and Autonomous Systems. 57[Gold and Scassellati 2009] K. Gold and B. Scassellati, Using Probabilistic Reasoning over Time to Self-Recognize, in Ro- botics and Autonomous Systems, 57(4): 384-392, 2009.

Constructions at Work: The Nature of Generalization in Language. A Goldberg, Oxford University PressOxford, UK[Goldberg 2006] A. Goldberg, Constructions at Work: The Nature of Generalization in Language, Oxford, UK: Oxford Uni- versity Press, 2006.

Transition from Rocking to Crawling-Postural Constraints on Infant Movement. ] E C Goldfield, Psychology. 256in Developmental[Goldfield 1989] E. C. Goldfield, Transition from Rocking to Crawling-Postural Constraints on Infant Movement, in De- velopmental Psychology, 25(6)(Nov.): 913-919, 1989.

Infant Bouncing-the Assembly and Tuning of Action Systems. [ Goldfield, Child Development. 644[Goldfield et al. 1993] E. C. Goldfield, B. A. Kay, and W. H. Warren, Infant Bouncing-the Assembly and Tuning of Action Systems, in Child Development, 64(4)(Aug.): 1128-1142, 1993.

Early Object Labels-the Case for a Developmental Lexical Principles Framework. [ Golinkoff, Journal of Child Language. 211[Golinkoff et al. 1994] R. M. Golinkoff, C. B. Mervis, and K. Hirshpasek, Early Object Labels-the Case for a Developmen- tal Lexical Principles Framework, in Journal of Child Language, 21(1)(Feb.): 125-155, 1994.

Neuromorphically Inspired Appraisal-Based Decision Making in a Cognitive Robot. [ Gordon, Information-Seeking, Curiosity, and Attention: Computational and Neural Mechanisms. Goyal et al. 2017] Raghav Goyal, Samira Ebrahimi Kahou, Vincent Michalski, Joanna Materzynska, Susanne Westphal, Heuna Kim, Peter Yianilos, Christian Thurau, Valentin Haenel, Moritz Mueller-FreitagFlorianIngo Fruend2Trends in Cognitive Sciences. Ingo Bax[Gordon et al. 2010] S. M. Gordon, K. Kawamura, and D. M. Wilkes, Neuromorphically Inspired Appraisal-Based Decision Making in a Cognitive Robot, in IEEE Transactions on Autonomous Mental Development, 2(1)(Mar.): 17-39, 2010. [Gottlieb et al. 2013] J. Gottlieb, P. Y. Oudeyer, M. Lopes, and A. Baranes, Information-Seeking, Curiosity, and Attention: Computational and Neural Mechanisms, in Trends in Cognitive Sciences, 17(11): 585-593, 2013. [Goyal et al. 2017] Raghav Goyal, Samira Ebrahimi Kahou, Vincent Michalski, Joanna Materzynska, Susanne Westphal, Heuna Kim, Peter Yianilos, Christian Thurau, Valentin Haenel, Moritz Mueller-Freitag, Ingo Bax, Ingo Fruend, Florian

The "something something" video database for learning and evaluating visual common sense. Roland Hoppe, Memisevic, Hoppe, and Roland Memisevic, The "something something" video database for learning and evaluating visual common sense, in arXiv, 2017, https://arxiv.org/pdf/1706.04261.pdf.

The Role of Gesture in Children's Learning to Count. T A Graham, Journal of Experimental Child Psychology. 744[Graham 1999] T. A. Graham, The Role of Gesture in Children's Learning to Count, in Journal of Experimental Child Psy- chology, 74(4)(Dec.): 333-355, 1999.

LSTM: A Search Space Odyssey. Greff, IEEE Transactions on Neural Networks and Learning Systems. 28Greff et al. 2017] Klauss Greff, Rupesh K. Srivastava, Jan Koutník, Bas R. Steunebrink, and Juergen Schmidhuber, LSTM: A Search Space Odyssey, in IEEE Transactions on Neural Networks and Learning Systems, 28(10): 2222 -2232, Oct. 2017, https://arxiv.org/pdf/1503.04069.pdf?utm_content=buffereddc5&utm_medium=social&utm_source=plus.google.com&ut m_campaign=buffer.

Experience, Neural Plasticity, and Psychological Development, paper presented at The Role of Early Experience in Infant Development. W T Greenough, J E Black, Pediatric Round Table. Greenough and Black[Greenough and Black 1999] W. T. Greenough and J. E. Black, Experience, Neural Plasticity, and Psychological Develop- ment, paper presented at The Role of Early Experience in Infant Development, Pediatric Round Table, New York, January, 1999.

Groth, Is Curiosity All You Need? On the Utility of Emergent Behaviours from Curious Exploration, in arXiv. Groth et al. 2021] Oliver Groth, Markus Wulfmeier, Giulia Vezzani, Vibhavari Dasagi, Tim Hertweck, Roland Hafner, Nico- las Heess, and Martin Riedmiller, Is Curiosity All You Need? On the Utility of Emergent Behaviours from Curious Explo- ration, in arXiv, 2021, https://arxiv.org/abs/2109.08603.

[ Gu, Should All Temporal Difference Learning Use Emphasis?, in arXiv. [Gu et al. 2019] Xiang Gu, Sina Ghiassian, and Richard S. Sutton, Should All Temporal Difference Learning Use Emphasis?, in arXiv, 2019, http://incompleteideas.net/papers/GGS-2019.pdf.

Learning Like a Baby: A Survey of AI Approaches. Frank Guerin, The Knowledge Engineering Review. Cambridge University PressGuerin[Guerin 2008a] Frank Guerin, Learning Like a Baby: A Survey of AI Approaches, in The Knowledge Engineering Review, Cambridge University Press, 2008, http://homepages.abdn.ac.uk/f.guerin/pages/schemasKER2008.pdf.

Constructivism in AI: Prospects, Progress and Challenges. AISB Convention[Guerin 2008b] Frank Guerin, Constructivism in AI: Prospects, Progress and Challenges, in AISB Convention, 20-27, 2008, http://homepages.abdn.ac.uk/f.guerin/pages/guerinAISB2008.pdf.

A Piagetian Model of Early Sensorimotor Development, paper presented at the 8th International Workshop on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems. F Guerin, D Mckenzie, Brighton, UKGuerin and McKenzie[Guerin and McKenzie 2008] F. Guerin and D. McKenzie, A Piagetian Model of Early Sensorimotor Development, paper presented at the 8th International Workshop on Epigenetic Robotics: Modeling Cognitive Development in Robotic Sys- tems, Brighton, UK, July 30-31, 2008.

A Survey of the Ontogeny of Tool Use: From Sensorimotor Experience to Planning. [ Guerin, IEEE Transactions on Autonomous Mental Development. [Guerin et al. 2013] Frank Guerin, Norbert Kruger, and Dirk Kraft, A Survey of the Ontogeny of Tool Use: From Sensorimo- tor Experience to Planning, in IEEE Transactions on Autonomous Mental Development, 2013, http://homepages.abdn.ac.uk/f.guerin/pages/tamdToolUseSurvey.pdf.

. David Ha, Jürgen Schmidhuber, World Models. in arXiv[Ha and Schmidhuber 2018] David Ha and Jürgen Schmidhuber, World Models, in arXiv, https://arxiv.org/pdf/1803.10122.pdf.

V V Hafner, F Kaplan, ; S Wermter, G Palm, M Elshaw, From Field of View to Field of Reach-Could Pointing Emerge from the Development of Grasping?, paper presented at the IEEE Conference on Development and Learning and Epigenetic Robotics. Berlin; Frankfurt, GermanySpringer-VerlagBiomimetic Neural Learning for Intelligent Robots: Intelligent Systems, Cognitive Robotics, and Neuroscience[Hafner and Kaplan 2005] V. V. Hafner and F. Kaplan, Learning to Interpret Pointing Gestures: Experiments with Four- Legged Autonomous Robots, in Biomimetic Neural Learning for Intelligent Robots: Intelligent Systems, Cognitive Robot- ics, and Neuroscience, ed. S. Wermter, G. Palm, and M. Elshaw, 225-234, Berlin: Springer-Verlag, 2005. [Hafner and Schillaci 2011] V. V. Hafner and G. Schillaci, From Field of View to Field of Reach-Could Pointing Emerge from the Development of Grasping?, paper presented at the IEEE Conference on Development and Learning and Epige- netic Robotics, Frankfurt, Germany, August 24-27, 2011.

Rules That Babies Look By: The Organization of Newborn Visual Activity. M M Haith, ErlbaumHillsdale, NJM. M. Haith, Rules That Babies Look By: The Organization of Newborn Visual Activity, Hillsdale, NJ: Erlbaum, 1980.

Expectation and Anticipation of Dynamic Visual Events by 3.5-Month-Old Babies. M M Haith, C Hazan, G S Goodman, Child Development. 592Haith et al. 1988[Haith et al. 1988] M. M. Haith, C. Hazan, and G. S. Goodman, Expectation and Anticipation of Dynamic Visual Events by 3.5-Month-Old Babies, in Child Development, 59(2)(Apr.): 467-479, 1988.

M M Haith, N Wentworth, R L Canfield, The Formation of Expectations in Early Infancy, in Advances in Infancy Research. 8[Haith et al. 1993] M. M. Haith, N. Wentworth, and R. L. Canfield, The Formation of Expectations in Early Infancy, in Ad- vances in Infancy Research, 8:251-297, 1993.

Learning and Satiation of Response in Intrinsically Motivated Complex Puzzle Performance by Monkeys. H F Harlow, Journal of Comparative and Physiological Psychology. 434Physica D. Nonlinear Phenomena[Harlow 1950] H. F. Harlow, Learning and Satiation of Response in Intrinsically Motivated Complex Puzzle Performance by Monkeys, in Journal of Comparative and Physiological Psychology, 43(4): 289-294, 1950. [Harnad 1990] S. Harnad, The Symbol Grounding Problem, in Physica D. Nonlinear Phenomena, 42(1-3)(June): 335-346, 1990.

Computer Simulation of the Ontogeny of Bipedal Walking. K Hase, N Yamazaki, Anthropological Science. 106[Hase and Yamazaki 1998] K. Hase and N. Yamazaki, Computer Simulation of the Ontogeny of Bipedal Walking, in Anthro- pological Science, 106(4)(Oct.): 327-347, 1998.

Active learning in neural networks, in New learning paradigms in soft computing. Martina Hasenjäger, Helge Ritter, Physica, Heidelbergand Ritter 2002] Martina Hasenjäger and Helge Ritter, Active learning in neural networks, in New learning par- adigms in soft computing, pp. 137-169, Physica, Heidelberg, 2002, https://www.researchgate.net/profile/Martina- Hasenjaeger/publication/2471937_Active_Learning_in_Neural_Networks/links/5a13fe22aca27217b5a31bd1/Active- Learning-in-Neural-Networks.pdf.

Development of the Face Robot Saya for Rich Facial Expressions. [ Hashimoto, SICE-ICASE International Joint Conference. New York; New York: Times Books[Hashimoto et al. 2006] T. Hashimoto, S. Hitramatsu, T. Tsuji, and H. Kobayashi, Development of the Face Robot Saya for Rich Facial Expressions, paper presented at the SICE-ICASE International Joint Conference, New York, 2006. [Hawkins 2004] Jeff Hawkins with Sandra Blakeslee, On Intelligence, New York: Times Books, 2004, https://books.google.com/books/about/On_Intelligence.html?id=Qg2dmntfxmQC&printsec=frontcover&source=kp_read_ button#v=onepage&q&f=false.

Why Neurons Have Thousands of Synapses, a Theory of Sequence Memory in Neocortex. Jeff Hawkins, https:/www.frontiersin.org/articles/10.3389/fncir.2016.00023/fullA thousand brains: a new theory of intelligence. Jeff Hawkins and Subutai AhmadNew YorkBasic Books10Jeff Hawkins, A thousand brains: a new theory of intelligence, New York: Basic Books, 2021. [Hawkins and Ahmad 2016] Jeff Hawkins and Subutai Ahmad, Why Neurons Have Thousands of Synapses, a Theory of Se- quence Memory in Neocortex, in Frontiers in Neural Circuits, 10:23, 2016, https://www.frontiersin.org/articles/10.3389/fncir.2016.00023/full.

Biological and Machine Intelligence (BAMI). Hawkins, [Hawkins et al. 2017a] Jeff Hawkins et al., Biological and Machine Intelligence (BAMI), March 8, 2017, https://numenta.com/assets/pdf/biological-and-machine-intelligence/BAMI-Complete.pdf.

A Theory of How Columns in the Neocortex Enable Learning the Structure of the World. https:/www.frontiersin.org/articles/10.3389/fncir.2017.00081/fullFrontiers in Neural Circuits. Hawkins et al. 2017b] Jeff Hawkins, Subutai Ahmad, and Yuwei Cui1181[Hawkins et al. 2017b] Jeff Hawkins, Subutai Ahmad, and Yuwei Cui, A Theory of How Columns in the Neocortex Enable Learning the Structure of the World, in Frontiers in Neural Circuits, 11:81, 2017, https://www.frontiersin.org/articles/10.3389/fncir.2017.00081/full.

Behavior is Everything -Towards Representing Concepts with Sensorimotor Contingencies. [ Hay, AAAI. [Hay et al. 2018] Nicholas Hay, Michael Stark, Alexander Schlegel, Carter Wendelken, Dennis Park, Eric Purdy, Tom Silver, D. Scott Phoenix, and Dileep George, Behavior is Everything -Towards Representing Concepts with Sensorimotor Con- tingencies, in AAAI, 2018, https://www.vicarious.com/wp-content/uploads/2018/01/AAAI18-pixelworld.pdf.

Choosing the Right Path: Image Schema Theory as a Foundation for Concept Invention. [ Hedblom, J. Artif. Gen. Intell. 61[Hedblom et al. 2015] Maria M. Hedblom, Oliver Kutz, and Fabian Neuhaus, Choosing the Right Path: Image Schema Theo- ry as a Foundation for Concept Invention, in J. Artif. Gen. Intell., 6(1): 21-54, 2015, https://www.inf.unibz.it/~okutz/resources/Choosing-the-Right-Path_-Image-Schema-Theory-as-a-Foundation-for- Concept-Invention-(JAGI).pdf.

Dynamic Action Selection Using Image Schema-based Reasoning for Robots, forthcoming at Seventh Joint Ontology Workshops. Maria M Hedblom, Mihai Pomarlan, Robert Porzel, Rainer Malaka, Michael Beetz, 2021Bolzano, ItalyHedblom et al. 2021[Hedblom et al. 2021] Maria M. Hedblom, Mihai Pomarlan, Robert Porzel, Rainer Malaka, and Michael Beetz, Dynamic Ac- tion Selection Using Image Schema-based Reasoning for Robots, forthcoming at Seventh Joint Ontology Workshops, Bol- zano, Italy, 2021.

Maria M Hedblom, Image Schemas and Concept Invention: Cognitive, Logical, and Linguistic Investigations. University of MagdeburgPhD thesisMaria M. Hedblom, Image Schemas and Concept Invention: Cognitive, Logical, and Linguistic Investiga- tions, PhD thesis, University of Magdeburg, 2018, https://d-nb.info/121996610X/34.

A Framework for Recognizing and Executing Verb Phrases, U. of Arizona PhD Thesis. Hewlett Daniel Krishan, Hewlett[Hewlett 2011] Daniel Krishan Hewlett, A Framework for Recognizing and Executing Verb Phrases, U. of Arizona PhD The- sis, 2011, https://repository.arizona.edu/bitstream/handle/10150/203490/azu_etd_11918_sip1_m.pdf?sequence=1.

Word Segmentation as General Chunking, paper presented at Psychocomputational Models of Human Language Acquisition workshop. Daniel Hewlett, Paul Cohen, [Hewlett and Cohen 2009] Daniel Hewlett and Paul Cohen, Word Segmentation as General Chunking, paper presented at Psychocomputational Models of Human Language Acquisition workshop, 2009, http://paulrcohen.github.io/papers/segmentation.pdf.

Effect of Self-Produced Locomotion on Infant Postural Compensation to Optic Flow. C Higgins, Developmental Psychology. 325[Higgins C et al. 1996] C. I. Higgins, J. J. Campos, and R. Kermoian, Effect of Self-Produced Locomotion on Infant Postural Compensation to Optic Flow, in Developmental Psychology, 32(5)(Sept.): 836-841, 1996.

I Higgins, Shakir Mohamed, and Alexander Lerchner, Early Visual Concept Learning with Unsupervised Deep Learning, in arXiv. Higgins I et al. 2016] Irina Higgins, Loic Matthey, Xavier Glorot, Arka Pal, Benigno Uria, Charles Blundell, Shakir Mo- hamed, and Alexander Lerchner, Early Visual Concept Learning with Unsupervised Deep Learning, in arXiv, 2016, https://arxiv.org/pdf/1606.05579.pdf.

I Higgins, SCAN: Learning Abstract Hierarchical Compositional Visual Concepts. [Higgins I et al. 2017] Irina Higgins, Nicolas Sonnerat, Loic Matthey, Arka Pal, Christopher Burgess, Matthew Botvinick, Demis Hassabis, and Alexander Lerchner, SCAN: Learning Abstract Hierarchical Compositional Visual Concepts, in arXiv, 2017, https://arxiv.org/pdf/1707.03389.pdf.

Understanding Grounded Language Learning Agents. Felix Hill, Karl Moritz Hermann, Phil Blunsom, Stephen Clark, [Hill et al. 2017] Felix Hill, Karl Moritz Hermann, Phil Blunsom, and Stephen Clark, Understanding Grounded Language Learning Agents, in arXiv, 2017, https://arxiv.org/pdf/1710.09867.pdf.

Why Should You Care?-An Arousal-Based Model of Exploratory Behavior for Autonomous Robot. A Hiolle, L Cañamero, 11th International Conference on Artificial Life. Cambridge, MApaper presented at the[Hiolle and Cañamero 2008] A. Hiolle, and L. Cañamero, Why Should You Care?-An Arousal-Based Model of Explor- atory Behavior for Autonomous Robot, paper presented at the 11th International Conference on Artificial Life, Cambridge, MA, 2008.

From Egocentric to Allocentric Spatial Behavior: A Computational Model of Spatial Development. [ Hiraki, Adaptive Behavior. 63-4[Hiraki et al. 1998] K. Hiraki, A. Sashima, and S. Phillips, From Egocentric to Allocentric Spatial Behavior: A Computational Model of Spatial Development, in Adaptive Behavior, 6(3-4)(Winter-Spring): 371-391, 1998.

Back-propagation algorithm which varies the number of hidden units. Hirose, Neural Networks. 4Hirose et al. 1991] Y. Hirose, K. Yamashita, and S. Hijiya, Back-propagation algorithm which varies the number of hidden units, in Neural Networks, 4: 61-66, 1991.

[ Ho, A Study of Episodic Memory-Based Learning and Narrative Structure for Autobiographic Agents, paper presented at the AISB 2006: Adaptation in Artificial and Biological Systems Conference. Bristol, UKUniversity of Bristol[Ho et al. 2006] W. C. Ho, K. Dautenhahn, and C. L. Nehaniv, A Study of Episodic Memory-Based Learning and Narrative Structure for Autobiographic Agents, paper presented at the AISB 2006: Adaptation in Artificial and Biological Systems Conference, University of Bristol, Bristol, UK, April 3-6, 2006.

Towards an Investigation of Speech Energetics Using 'Anton': An Animatronic Model of a Human Tongue and Vocal Tract. R Hofe, R K Moore, ; E Hoff, https:/link.springer.com/content/pdf/10.1007/s42452-021-04715-0.pdfA thousand brains: toward biologically constrained AI. Kjell Jorgen Hole and Subutai AhmadBelmont, CAWadsworth Thomson Learning20743SN Applied Sciences[Hofe and Moore 2008] R. Hofe and R. K. Moore, Towards an Investigation of Speech Energetics Using 'Anton': An Anima- tronic Model of a Human Tongue and Vocal Tract, in Connection Science, 20(4): 319-336, 2008. [Hoff 2009] E. Hoff, Language Development, Belmont, CA: Wadsworth Thomson Learning, 2009. [Hole and Ahmad 2021] Kjell Jorgen Hole and Subutai Ahmad, A thousand brains: toward biologically constrained AI, in SN Applied Sciences, 3:743, 2021, https://link.springer.com/content/pdf/10.1007/s42452-021-04715-0.pdf.

Looping suffix tree-based inference of partially observable hidden state. P Michael, Charles Lee Holmes, IsbellJr, ICML '06: Proceedings of the 23rd international conference on Machine learning. New York, NY, USAACM[Holmes and Isbell 2006] Michael P. Holmes and Charles Lee Isbell Jr, Looping suffix tree-based inference of partially ob- servable hidden state, in ICML '06: Proceedings of the 23rd international conference on Machine learning, ACM, 409- 416, New York, NY, USA, 2006, https://www.cc.gatech.edu/~isbell/papers/isbell-state-icml-2006.pdf.

A Unified Approach to Speech Production and Recognition Based on Articulatory Motor Representations. Santos-Victor ; J Hornstein, J Hornstein, Santos-Victor, /RSJ International Conference on Intelligent Robots and Systems. San Diego, CApaper presented at the IEEE[Hornstein and Santos-Victor 2007] J. Hornstein and J. Santos-Victor, A Unified Approach to Speech Production and Recog- nition Based on Articulatory Motor Representations, paper presented at the IEEE/RSJ International Conference on Intelli- gent Robots and Systems, San Diego, CA, October 29-November 2, 2007.

Mesolimbocortical and Nigrostriatal Dopamine Responses to Salient Non-Reward Events. J C Horvitz, Neuroscience. 964[Horvitz 2000] J. C. Horvitz, Mesolimbocortical and Nigrostriatal Dopamine Responses to Salient Non-Reward Events, in Neuroscience, 96(4): 651-656, 2000.

Novelty and Reinforcement Learning in the Value System of Developmental Robots, paper presented at the 2nd International Workshop on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems. X Huang, J Weng, Edinburgh, Scotlandand Weng 2002] X. Huang and J. Weng, Novelty and Reinforcement Learning in the Value System of Developmental Robots, paper presented at the 2nd International Workshop on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems, Edinburgh, Scotland, August 10-11, 2002, http://cogprints.org/2511/1/Huang.pdf.

Principles of Behavior: An Introduction to Behavior Theory. C L Hull, Appleton-Century-CroftNew York[Hull 1943] C. L. Hull, Principles of Behavior: An Introduction to Behavior Theory, New York: Appleton-Century-Croft, 1943.

Integration of Active Vision and Reaching from a Developmental Robotics Perspective. [ Hulse, IEEE Transactions on Autonomous Mental Development. 24Cognitive Computation[Hulse et al. 2010a] M. Hulse, S. McBride, J. Law, and M. H. Lee, Integration of Active Vision and Reaching from a Devel- opmental Robotics Perspective, in IEEE Transactions on Autonomous Mental Development, 2(4)(Dec.): 355-367, 2010. [Hulse et al. 2010b] M. Hulse, S. McBride, and M. H. Lee, Fast Learning Mapping Schemes for Robotic Hand-Eye Coordi- nation, in Cognitive Computation, 2(1)(Mar.): 1-16, 2010.

Intrinsic Motivation and Its Role in Psychological Development, paper presented at the Nebraska Symposium on Motivation. J M Hunt, Lincoln, NEJ. M. Hunt, Intrinsic Motivation and Its Role in Psychological Development, paper presented at the Nebraska Symposium on Motivation, Lincoln, NE, 1965.

Attentional Preference and Experience. J M Hunt, Machine Translation: Past, Present. Halstead Press117University of MilanFutureJ. M. Hunt, Attentional Preference and Experience, in Journal of Genetic Psychology, 117(1): 99-107, 1970. [Hutchins 1986] William John Hutchins, Chapter 5.3: University of Milan (1959 -1966), in Machine Translation: Past, Pre- sent, Future, Halstead Press, 1986, http://www.hutchinsweb.me.uk/PPF-5.pdf.

How researchers are teaching AI to learn like a child. Matthew Hutson, Science Magazine. [Hutson 2018] Matthew Hutson, How researchers are teaching AI to learn like a child, in Science Magazine, May 24, 2018, http://www.sciencemag.org/news/2018/05/how-researchers-are-teaching-ai-learn-child.

Cortical Mechanisms of Human Imitation. M Iacoboni, R P Woods, M Brass, H Bekkering, J C Mazziotta, G Rizzolatti, Science. 2865449Iacoboni et al. 1999[Iacoboni et al. 1999] M. Iacoboni, R. P. Woods, M. Brass, H. Bekkering, J. C. Mazziotta, and G. Rizzolatti, Cortical Mecha- nisms of Human Imitation, in Science, 286(5449)(Dec.): 2526-2528, 1999.

Central Pattern Generators for Locomotion Control in Animals and Robots: A Review. A J Ijspeert, Neural Networks. 214Ijspeert[Ijspeert 2008] A. J. Ijspeert, Central Pattern Generators for Locomotion Control in Animals and Robots: A Review, in Neural Networks, 21(4)(May): 642-653, 2008.

Physical Relation and Expression: Joint Attention for Human-Robot Interaction. [ Imai, Robovie: An Interactive Humanoid Robot. 50Industrial Robot[Imai et al. 2003] M. Imai, T. Ono, and H. Ishiguro, Physical Relation and Expression: Joint Attention for Human-Robot In- teraction, in IEEE Transactions on Industrial Electronics, 50(4)(Aug.): 636-643, 2003. [Ishiguro et al. 2001] H. Ishiguro, T. Ono, M. Imai, T. Maeda, T. Kanda, and R. Nakatsu, Robovie: An Interactive Humanoid Robot, in Industrial Robot, 28(6): 498-503, 2001.

How Caregiver's Anticipation Shapes Infant's Vowel through Mutual Imitation. H Ishihara, Y Yoshikawa, K Miura, M Asada, Hikosaka, A Neural Correlate of Motivational Conflict in the Superior Colliculus of the Macaque. 1Journal of Neurophysiology. Sept[Ishihara et al. 2009] H. Ishihara, Y. Yoshikawa, K. Miura, and M. Asada, How Caregiver's Anticipation Shapes Infant's Vowel through Mutual Imitation, in IEEE Transactions on Autonomous Mental Development, 1(4)(Dec.): 217-225, 2009. [Isoda and Hikosaka 2008] M. Isoda and O. Hikosaka, A Neural Correlate of Motivational Conflict in the Superior Colliculus of the Macaque, in Journal of Neurophysiology, 100(3)(Sept.): 1332-1342, 2008.

On-Line Imitative Interaction with a Humanoid Robot Using a Dynamic Neural Network Model of a Mirror System. M Ito, J Tani, Adaptive Behavior. 122[Ito and Tani 2004] M. Ito and J. Tani, On-Line Imitative Interaction with a Humanoid Robot Using a Dynamic Neural Net- work Model of a Mirror System, in Adaptive Behavior, 12(2): 93-115, 2004.

A Saliency-Based Search Mechanism for Overt and Covert Shifts of Visual Attention. L Itti, C Koch, Vision Research. 40Itti and Koch[Itti and Koch 2000] L. Itti and C. Koch, A Saliency-Based Search Mechanism for Overt and Covert Shifts of Visual Atten- tion, in Vision Research, 40(10-12): 1489-1506, 2000.

Gesture Paves the Way for Language Development. J M Iverson, S Goldin-Meadow, Psychological Science. 165and Goldin-Meadow 2005] J. M. Iverson and S. Goldin-Meadow, Gesture Paves the Way for Language Develop- ment, in Psychological Science, 16(5): 367-371, 2005.

Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier Hénaff, Matthew M Botvinick, Andrew Zisserman, Oriol Vinyals, João Carreira, Perceiver IO: A General Architecture for Structured Inputs & Outputs, in arXiv. Jaegle et al. 2021[Jaegle et al. 2021] Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier Hénaff, Matthew M. Botvinick, Andrew Zisser- man, Oriol Vinyals, and João Carreira, Perceiver IO: A General Architecture for Structured Inputs & Outputs, in arXiv, 2021, https://arxiv.org/abs/2107.14795.

The Principles of Psychology. William James, Henry Holt & Company1890William James, The Principles of Psychology, Henry Holt & Company, 1890.

A World of Pure Experience. William James, Psychology and Scientific Methods. 120The Journal of PhilosophyWilliam James, A World of Pure Experience, in The Journal of Philosophy, Psychology and Scientific Methods, 1(20): 533-543, Sep. 29, 1904, https://www.jstor.org/stable/2011912.

Where-what network 1: "Where" and "What" assist each other through top-down connections. [ Jasso, IEEE 7th International Conference on Development and Learning. Monterey, CA7th IEEE International Conference on Development and Learning[Jasso et al. 2008] H. Jasso, J. Triesch, and G. Deak, A Reinforcement Learning Model of Social Referencing, paper present- ed at the IEEE 7th International Conference on Development and Learning, Monterey, CA, August 9-12, 2008. [Ji et al. 2008] Zhengping Ji, Juyang Weng, and Danil Prokhorov, Where-what network 1: "Where" and "What" assist each other through top-down connections, in 7th IEEE International Conference on Development and Learning, pp. 61-66, 2008, http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.151.5595&rep=rep1&type=pdf.

Visual concept learning: Combining machine vision and bayesian generalization on concept hierarchies. [ Jia, Advances in Neural Information Processing Systems. [Jia et al. 2013] Yangqing Jia, Joshua T. Abbott, Joseph L. Austerweil, Tom Griffiths, and Trevor Darrell, Visual concept learning: Combining machine vision and bayesian generalization on concept hierarchies, in Advances in Neural Infor- mation Processing Systems, pp. 1842-1850. 2013.

Y Jin, Editorial IEEE Transactions on Cognitive and Developmental Systems, in IEEE Transactions on Cognitive and Developmental Systems. 8[Jin 2016] Y. Jin, Editorial IEEE Transactions on Cognitive and Developmental Systems, in IEEE Transactions on Cognitive and Developmental Systems, 8(1): 1 -2, March 2016.

Learning from Falling. A S Joh, K E Adolph, ORCID iD: 0000-0002-0606-8423Child Development. 77University of MichiganPhD thesisJohnson CE 2018[Joh and Adolph 2006] A. S. Joh and K. E. Adolph, Learning from Falling, in Child Development, 77(1): 89-102, 2006. [Johnson CE 2018] Collin E. Johnson, Topological Mapping and Navigation in Real-World Environments, PhD thesis, Uni- versity of Michigan, 2008, ORCID iD: 0000-0002-0606-8423, http://web.eecs.umich.edu/~kuipers/papers/Johnson-PhD- 18.pdf.

Infant Growth and Development. Johnson Cp, ; C P Blasco, P A Johnson, Blasco, Pediatrics in Review/ American Academy of Pediatrics. 187[Johnson CP and Blasco 1997] C. P. Johnson and P. A. Blasco, Infant Growth and Development, in Pediatrics in Review/ American Academy of Pediatrics, 18(7): 224-242, 1997.

The Body in the Mind: The Bodily Basis of Meaning, Imagination, and Reason. Johnson M 1987] Mark Johnson, University of Chicago PressChicagoJohnson M 1987] Mark Johnson, The Body in the Mind: The Bodily Basis of Meaning, Imagination, and Reason, University of Chicago Press, Chicago, 1987.

Cortical Maturation and the Development of Visual Attention in Early Infancy. Mh ; M H Johnson, Johnson, Journal of Cognitive Neuroscience. 2Johnson MH 1990] M. H. Johnson, Cortical Maturation and the Development of Visual Attention in Early Infancy, in Jour- nal of Cognitive Neuroscience, 2(2): 81-95, 1990.

The nature of cognitive development. Sp ; Johnson, P Scott, Johnson, TRENDS in Cognitive Sciences. 7Johnson SP 2003] Scott P. Johnson, The nature of cognitive development, in TRENDS in Cognitive Sciences, 7(2): 102-104, March 2003, https://www.babylab.ucla.edu/wp-content/uploads/sites/8/2016/09/JohnsonTICS2003.pdf.

Development of Perceptual Completion in Infancy. Sp ; S P Johnson, Johnson, Psychological Science. 1511Johnson SP 2004] S. P. Johnson, Development of Perceptual Completion in Infancy, in Psychological Science, 15(11): 769- 775, 2004.

Development of Object Concepts in Infancy: Evidence for Early Learning in an Eye-Tracking Paradigm. S P Johnson, Proceedings of the National Academy of Sciences of the United States of America. the National Academy of Sciences of the United States of AmericaSept.100[Johnson SP et al. 2003a] S. P. Johnson, D. Amso, and J. A. Slemmer, Development of Object Concepts in Infancy: Evidence for Early Learning in an Eye-Tracking Paradigm, in Proceedings of the National Academy of Sciences of the United States of America, 100(18)(Sept.): 10568-10573, 2003.

How Infants Begin to Extract Words from Speech. S P Johnson, Trends in Cognitive Sciences. 741Child DevelopmentJohnson SP et al. 2003b] S. P. Johnson, J. G. Bremner, A. Slater, U. Mason, K. Foster, and A. Cheshire, Infants' Perception of Object Trajectories, in Child Development, 74(1): 94-108, 2003. [Jusczyk 1999] P. W. Jusczyk, How Infants Begin to Extract Words from Speech, in Trends in Cognitive Sciences, 3(9): 323- 328, 1999.

A function estimation approach to sequential learning with neural networks. V Kadirkamanathan, M Niranjan, in Neural Computation. 5Kadirkamanathan and Niranjan[Kadirkamanathan and Niranjan 1993] V. Kadirkamanathan and M. Niranjan, A function estimation approach to sequential learning with neural networks, in Neural Computation, 5: 954-75, 1993.

Motives and Development. J Kagan, Self Discovery Enables Robot Social Cognition: Are You My Teacher?, in Neural Networks. Kaipa et al. 2010] K. N. Kaipa, J. C. Bongard, and A. N. Meltzoff22Kagan 1972[Kagan 1972] J. Kagan, Motives and Development, in Journal of Personality and Social Psychology, 22(1): 51-66, 1972. [Kaipa et al. 2010] K. N. Kaipa, J. C. Bongard, and A. N. Meltzoff, Self Discovery Enables Robot Social Cognition: Are You My Teacher?, in Neural Networks, 23(8-9)(Oct.-Nov.): 1113-1124, 2010.

Schema Networks: Zero-Shot Transfer with a Generative Causal Model of Intuitive Physics. [ Kansky, ICML. [Kansky et al. 2017] Ken Kansky, Tom Silver, David A. Mély, Mohamed Eldawy, Miguel Lázaro-Gredilla, Xinghua Lou, Nimrod Dorfman, Szymon Sidor, Scott Phoenix, and Dileep George, Schema Networks: Zero-Shot Transfer with a Gener- ative Causal Model of Intuitive Physics, in ICML, 2017, https://arxiv.org/pdf/1706.04317.pdf.

Towards Understanding How Humans Teach Robots. Immanuel Kant, ; Kaochar, Proceedings of International Conference on User Modeling, Adaptation, and Personalization. International Conference on User Modeling, Adaptation, and PersonalizationCritique of Pure Reason, 1781Immanuel Kant, Critique of Pure Reason, 1781. [Kaochar et al. 2011] Tasneem Kaochar, Raquel Torres Peralta, Clayton T. Morrison, Ian R. Fasel, Thomas J. Walsh, and Paul R. Cohen, Towards Understanding How Humans Teach Robots, in Proceedings of International Conference on User Modeling, Adaptation, and Personalization, pp. 347-352, 2011, http://www.thomasjwalsh.net/pub/umap11Towards.pdf.

The Challenges of Joint Attention. F Kaplan, V V Hafner, Interaction Studies: Social Behaviour and Communication in Biological and Artificial Systems. 7Kaplan and Hafner[Kaplan and Hafner 2006] F. Kaplan and V. V. Hafner, The Challenges of Joint Attention, in Interaction Studies: Social Be- haviour and Communication in Biological and Artificial Systems, 7(2): 135-169, 2006.

Karmiloff-Smith, Beyond Modularity: A Developmental Perspective on Cognitive Science. MIT PressKarmiloff-Smith 1992] Annette Karmiloff-Smith, Beyond Modularity: A Developmental Perspective on Cognitive Science, MIT Press, 1992.

The Discrimination of Visual Number. [ Kaufman, American Journal of Psychology. 624[Kaufman et al. 1949] E. L. Kaufman, M. W. Lord, T. W. Reese, and J. Volkmann, The Discrimination of Visual Number, in American Journal of Psychology, 62(4): 498-525, 1949.

Implementation of Cognitive Control for a Humanoid Robot. [ Kawamura, Concepts, Kinds, and Cognitive Development. Cambridge, MA; NortonTaylor & Francis Group5The Psychology of Personal Constructs. reissue of 1992 Routledge version[Kawamura et al. 2008] K. Kawamura, S. M. Gordon, P. Ratanaswasd, E. Erdemir, and J. F. Hall, Implementation of Cogni- tive Control for a Humanoid Robot, in International Journal of Humanoid Robotics, 5(4)(Dec.): 547-586, 2008. [Keil 1989] Frank C. Keil, Concepts, Kinds, and Cognitive Development, Cambridge, MA: MIT Press, 1989. [Kelly 1955] George A. Kelly, The Psychology of Personal Constructs, Volume 1: Theory and Personality, Norton, 1955, (2020 Taylor & Francis Group, reissue of 1992 Routledge version), https://www.google.com/books/edition/The_Psychology_of_Personal_Constructs/-ALpDwAAQBAJ?hl=en&gbpv=1.

The discovery of structural form. Charles Kemp, Joshua B Tenenbaum, MIT. [Kemp and Tenenbaum 2008] Charles Kemp and Joshua B. Tenenbaum, The discovery of structural form, MIT, 2008, http://groups.csail.mit.edu/belief-dynamics/MURI/papers07/Kempsl.pdf.

Locomotor Experience: A Facilitator of Spatial Cognitive-Development. R Kermoian, J J Campos, Child Development. 594Kermoian and Campos[Kermoian and Campos 1988] R. Kermoian and J. J. Campos, Locomotor Experience: A Facilitator of Spatial Cognitive- Development, in Child Development, 59(4)(Aug.): 908-917, 1988.

Kerr, Proceedings of the IEEE 6th International Conference on Learning and Development. the IEEE 6th International Conference on Learning and Development[Kerr et al. 2007] Wesley Kerr, Shane Hoversten, Daniel Hewlett Paul Cohen, and Yu-Han Chang, Learning in Wubble World, in Proceedings of the IEEE 6th International Conference on Learning and Development, 330-335, 2007, http://paulrcohen.github.io/papers/icdl07.pdf.

Activity Recognition with Finite State Machines. Kerr, Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence. the Twenty-Second International Joint Conference on Artificial Intelligence[Kerr et al. 2011] Wesley Kerr, Anh Tran, and Paul Cohen, Activity Recognition with Finite State Machines, in Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence, 2011, https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.419.1673&rep=rep1&type=pdf.

Perception of Objects and Object Boundaries by 3-Month-Old Infants. R Kestenbaum, N Termine, E S Spelke, British Journal of Developmental Psychology. 54Kestenbaum et al. 1987[Kestenbaum et al. 1987] R. Kestenbaum, N. Termine, and E. S. Spelke, Perception of Objects and Object Boundaries by 3- Month-Old Infants, in British Journal of Developmental Psychology, 5(4): 367-383, 1987.

Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and Raia Hadsell, Overcoming catastrophic forgetting in neural networks. S Kirby ; James Kirkpartrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Spontaneous Evolution of Linguistic Structure: An Iterated Learning Model of the Emergence of Regularity and Irregularity. PNAS5[Kirby 2001] S. Kirby, Spontaneous Evolution of Linguistic Structure: An Iterated Learning Model of the Emergence of Reg- ularity and Irregularity, in IEEE Transactions on Evolutionary Computation, 5(2)(Apr.): 102-110, 2001. [Kirkpatrick et al. 2017] James Kirkpartrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and Raia Hadsell, Overcoming catastrophic forgetting in neural networks, in PNAS, 114(13): 3521 - 3526, March 28, 2017, http://www.pnas.org/content/114/13/3521.full.pdf.

Unconditioned Operant Behavior in Two Homozygous Strains of Mice. G B Kish, J J Antonitis, Journal of Genetic Psychology. 881Kish and Antonitis 1956[Kish and Antonitis 1956] G. B. Kish and J. J. Antonitis, Unconditioned Operant Behavior in Two Homozygous Strains of Mice, in Journal of Genetic Psychology, 88(1): 121-129, 1956.

Cognitive development: An information-processing view. David Klahr, J G Wallace, Lawrence ErlbaumOxford, England[Klahr and Wallace 1976] David Klahr and J. G. Wallace, Cognitive development: An information-processing view, Oxford, England: Lawrence Erlbaum, 1976, https://archive.org/details/CognitiveDevelopmentAndInformationProcessingView.

Efficient and flexible representation of higher-dimensional cognitive variables with grid cells. Mirko Klukas, Marcus Lewis, Ila Fiete, 10.1371/journal.pcbi.1007796PLoS Comput Biol. 1641007796Klukas et al. 2020[Klukas et al. 2020] Mirko Klukas, Marcus Lewis, and Ila Fiete, Efficient and flexible representation of higher-dimensional cognitive variables with grid cells, in PLoS Comput Biol, 16(4): e1007796, 2020, https://doi.org/10.1371/journal.pcbi.1007796.

Siamese Neural Networks for One-shot Image Recognition. [ Koch, Proceedings of the 32nd International Conference on Machine Learning. the 32nd International Conference on Machine LearningLille, France[Koch et al. 2015] Gregory Koch, Richard Zemel, and Ruslan Salakhutdinov, Siamese Neural Networks for One-shot Image Recognition, in Proceedings of the 32nd International Conference on Machine Learning, Lille, France, 2015, https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf.

Essentials of the self-organizing map. Neural Networks. 37Kohonen 2013] Teuvo Kohonen[Kohonen 2013] Teuvo Kohonen, Essentials of the self-organizing map, in Neural Networks, 37: 52-65, 2013, http://aisii.azc.uam.mx/mcbc/Cursos/IntCompt/Lectura 8. SOM.pdf.

The Development toward Stereotypic Arm Kinematics during Reaching in the First Three Years of Life. J Konczak, J Dichgans, 117Konczak and Dichgans. in Experimental Brain Research[Konczak and Dichgans 1997] J. Konczak and J. Dichgans, The Development toward Stereotypic Arm Kinematics during Reaching in the First Three Years of Life, in Experimental Brain Research, 117(2): 346-354, 1997.

Building portable options: Skill transfer in reinforcement learning. Georg Konidaris, Andrew Barto, IJCAI 2007, Proceedings of the 20th International Joint Conference on Artificial Intelligence. IndiaHyderabadKonidaris and Barto[Konidaris and Barto 2007] Georg Konidaris and Andrew Barto, Building portable options: Skill transfer in reinforcement learning, in IJCAI 2007, Proceedings of the 20th International Joint Conference on Artificial Intelligence, 895 -900, Hy- derabad, India, January 6 -12, 2007, http://www.ijcai.org/Proceedings/07/Papers/144.pdf.

A Review of 40 Years in Cognitive Architecture Research Core Cognitive Abilities and Practical Applications. Iuliia Kotseruba, John K Tsotsos, 10.1007/s10462-018-9646-yArtificial Intelligence Review. 53Kotseruba and Tsotsos 2020[Kotseruba and Tsotsos 2020] Iuliia Kotseruba and John K. Tsotsos, A Review of 40 Years in Cognitive Architecture Re- search Core Cognitive Abilities and Practical Applications. in Artificial Intelligence Review, 53:17 -94, 2020, https://doi.org/10.1007/s10462-018-9646-y.

A Robot That Learns to Communicate with Human Caregivers, paper presented at the 1st International Workshop on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems. H Kozima, H Yano, Lund, Sweden[Kozima and Yano 2001] H. Kozima and H. Yano, A Robot That Learns to Communicate with Human Caregivers, paper pre- sented at the 1st International Workshop on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems, Lund, Sweden, September 17-18, 2001.

Learning Actions from Observations. Kruger, IEEE Robotics & Automation Magazine. 172Kruger et al. 2010] V. Krüger, D. Herzog, S. Baby, A. Ude, and D. Kragic, Learning Actions from Observations, in IEEE Robotics & Automation Magazine, 17(2): 30-43, 2010.

Adult hippocampal neurogenesis: a coming-of-age story. [ Kuhn, Journal of Neuroscience. 3849[Kuhn et al. 2018] H. Georg Kuhn, Tomohisa Toda, and Fred H. Gage, Adult hippocampal neurogenesis: a coming-of-age story, in Journal of Neuroscience, 38(49): 10401-10410, 2018, https://www.jneurosci.org/content/jneuro/38/49/10401.full.pdf.

Benjamin Kuipers, An Intellectual History of the Spatial Semantic Hierarchy. Benjamin Kuipers, Robotics and Cognitive Approaches to Spatial Mapping. M. E. Jefferies and W. K. YeapHeidelbergSpringer119Springer Tracts in Advanced Robotics[Kuipers 2000] Benjamin Kuipers, The Spatial Semantic Hierarchy, in Artificial Intelligence, 119: 191-233, 2000. [Kuipers 2008] Benjamin Kuipers, An Intellectual History of the Spatial Semantic Hierarchy, in Robotics and Cognitive Ap- proaches to Spatial Mapping, vol. 38, M. E. Jefferies and W. K. Yeap (eds.), Springer Tracts in Advanced Robotics, Ber- lin, Heidelberg: Springer, 2008, https://web.eecs.umich.edu/~kuipers/papers/Kuipers-NZ-08.pdf.

Bootstrap learning for place recognition. Benjamin Kuipers, Patrick Beeson, Eighteenth national conference on Artificial intelligence. Menlo Park, CA, USA[Kuipers and Beeson 2002] Benjamin Kuipers and Patrick Beeson, Bootstrap learning for place recognition, in Eighteenth national conference on Artificial intelligence, 174-180, Menlo Park, CA, USA, American Association for Artificial Intel- ligence, 2002, https://www.aaai.org/Papers/AAAI/2002/AAAI02-027.pdf.

Kuipers, Bootstrap learning of foundational representations. Connection Science[Kuipers et al. 2006] B. Kuipers, P. Beeson, J. Modayil, and J. Provost J, Bootstrap learning of foundational representations, in Connection Science, 2006, ftp://ftp.cs.utexas.edu/pub/qsim/papers/Kuipers-connsci-06.pdf.

Which Computational Mechanisms Operate in the Hippocampus During Novelty Detection?. D Kumaran, E A Maguire, Hippocampus. 179Kumaran and Maguire[Kumaran and Maguire 2007] D. Kumaran and E. A. Maguire, Which Computational Mechanisms Operate in the Hippocam- pus During Novelty Detection?, in Hippocampus, 17(9): 735-748, 2007.

Early Motor Development from Partially Ordered Neural-Body Dynamics: Experiments with a Cortico-Spinal-Musculo-Skeletal Model. Y Kuniyoshi, S Sangawa, Biological Cybernetics. 956and Sangawa 2006] Y. Kuniyoshi and S. Sangawa, Early Motor Development from Partially Ordered Neural- Body Dynamics: Experiments with a Cortico-Spinal-Musculo-Skeletal Model, in Biological Cybernetics, 95(6): 589-605, 2006.

Neural Model of Adaptive Hand-Eye Coordination for Single Postures. M Kuperstein, Science. 2394845M. Kuperstein, Neural Model of Adaptive Hand-Eye Coordination for Single Postures, in Science, 239(4845)(Mar.): 1308-1311, 1988.

Infant Neural Controller for Adaptive Sensory Motor Coordination. M Kuperstein, Neural Networks. 4M. Kuperstein, Infant Neural Controller for Adaptive Sensory Motor Coordination, in Neural Networks, 4(2): 131-145, 1991.

Self-Taught Robots: Machines that learn like children provide deep insights into how the mind and body act together to bootstrap knowledge and skills. Scientific American. Diana Kwon, Self-Taught Robots: Machines that learn like children provide deep insights into how the mind and body act together to bootstrap knowledge and skills, in Scientific American, 26-31, March 2018.

Universal Subgoaling and Chunking: The Automatic Generation and Learning of Goal Hierarchies. [ Laird, Springer-VerlagUSpreface[Laird et al. 1986] John Laird, Paul Rosenbloom, and Allen Newell, Universal Subgoaling and Chunking: The Automatic Generation and Learning of Goal Hierarchies, US: Springer-Verlag, 1986, https://link.springer.com/content/pdf/bfm%3A978-1-4613-2277-1%2F1.pdf (preface).

Building Machines That Learn and Think Like People. [ Laird, A Standard Model of the Mind: Toward a Common Computational Framework across Artificial Intelligence, Cognitive Science, Neuroscience, and Robotics, in AI Magazine. Lakoff and Johnson 1980] George Lakoff and Mark JohnsonNew YorkBasic Books38Where Mathematics Comes From: How the Embodied Mind Brings Mathematics into Being[Laird et al. 2017] John E. Laird, Christian Lebiere, and Paul S. Rosenbloom, A Standard Model of the Mind: Toward a Common Computational Framework across Artificial Intelligence, Cognitive Science, Neuroscience, and Robotics, in AI Magazine 38(4), 2017, https://www.dropbox.com/s/z50a70vl8sn3all/LLR-SMM-AI Magazine-Published-Personal.pdf [Lake et al. 2016] Brenden M. Lake, Tomer D. Ullman, Joshua B. Tenenbaum, and Samuel J. Gershman, Building Machines That Learn and Think Like People, in Behavioral and Brain Sciences, 2016, https://arxiv.org/pdf/1604.00289.pdf. [Lakoff and Johnson 1980] George Lakoff and Mark Johnson, Metaphors we live by, University of Chicago Press, 1980. [Lakoff and Núñez 2000] G. Lakoff and R. E. Núñez, Where Mathematics Comes From: How the Embodied Mind Brings Mathematics into Being, New York: Basic Books, 2000.

Human-Robot Cooperation Based on Interaction Learning. [ Lallée, Motor Learning to Interaction Learning in Robots. O. Sigaud and J. PetersBerlinSpringer-Verlag[Lallée et al. 2010] S. Lallée, E. Yoshida, A. Mallet, F. Nori, L. Natale, G. Metta, F. Warneken, and P. F. Dominey, Human- Robot Cooperation Based on Interaction Learning, in Motor Learning to Interaction Learning in Robots, ed. O. Sigaud and J. Peters, 491-536, Berlin: Springer-Verlag, 2010.

. R W Langacker, Foundations of Cognitive Grammar: Theoretical Prerequisites. 1Stanford University Press[Langacker 1987] R. W. Langacker, Foundations of Cognitive Grammar: Theoretical Prerequisites, Vol. 1, Stanford, CA: Stanford University Press, 1987.

Cognitive Architectures: Research Issues and Challenges. Langley, Cognitive Systems Research. 102Langley et al. 2009] P. Langley, J. E. Laird, and S. Rogers, Cognitive Architectures: Research Issues and Challenges, in Cognitive Systems Research, 10(2)(June): 141-160, 2009.

Noise and Inter-Speaker Variability Improve Distinguishability of Auditory, Motor and Perceptuo-Motor Theories of Speech Perception: An Exploratory Bayesian Modeling Study, paper presented at the 9th International Seminar on Speech Production. Laurent, Montreal, Canada[Laurent et al. 2011] R. Laurent, C. Moulin-Frier, P. Bessière, J. L. Schwartz, and J. Diard, Noise and Inter-Speaker Variabil- ity Improve Distinguishability of Auditory, Motor and Perceptuo-Motor Theories of Speech Perception: An Exploratory Bayesian Modeling Study, paper presented at the 9th International Seminar on Speech Production, Montreal, Canada, June 20-23, 2011.

Explaining Visual Cortex Phenomena using Recursive Cortical Network, in bioRxiv. Lavin, 10.1101/380048[Lavin et al. 2018] Alexander Lavin, J. Swaroop Guntupalli, Miguel Lázaro-Gredilla, Wolfgang Lehrach, and Dileep George, Explaining Visual Cortex Phenomena using Recursive Cortical Network, in bioRxiv, 2018, https://doi.org/10.1101/380048.

The Infant Development Timeline and Its Application to Robot Shaping. [ Law, Adaptive Behavior. 195[Law et al. 2011] J. Law, M. H. Lee, M. Hulse, and A. Tomassetti, The Infant Development Timeline and Its Application to Robot Shaping, in Adaptive Behavior, 19(5)(Oct.): 335-358, 2011.

Beyond imitation: Zero-shot task transfer on robots by learning concepts as cognitive programs. Lázaro-Gredilla, Science Robotics. 4Lázaro-Gredilla et al. 2019] Miguel Lázaro-Gredilla, Dianhuan Lin, J. Swaroop Guntupalli, and Dileep George, Beyond imi- tation: Zero-shot task transfer on robots by learning concepts as cognitive programs, in Science Robotics, 4(26), 2019, https://vcrs.wpengine.com/wp-content/uploads/2020/03/10.1126@scirobotics.aav3150.pdf.

Lázaro-Gredilla, Query Training: Learning a Worse Model to Infer Better Marginals in Undirected Graphical Models with Hidden Variables, in arXiv. Lázaro-Gredilla et al. 2021] Miguel Lázaro-Gredilla, Wolfgang Lehrach, Nishad Gothoskar, Guangyao Zhou, Antoine Dedieu, and Dileep George, Query Training: Learning a Worse Model to Infer Better Marginals in Undirected Graphical Models with Hidden Variables, in arXiv, 2021, https://arxiv.org/abs/2006.06803.

Staged competence learning in developmental robotics. [ Lee, Adaptive Behavior -Animals, Animats, Software Agents, Robots, Adaptive Systems. 15[Lee et al. 2007] Mark H. Lee, Qinggang Meng, and Fei Chao, Staged competence learning in developmental robotics, in Adaptive Behavior -Animals, Animats, Software Agents, Robots, Adaptive Systems, 15(3): 241-255, 2007, http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.127.8723&rep=rep1&type=pdf.

Core Architecture and Domain Specificity, in Mapping the Mind: Domain Specificity in Cognition and Culture. [ Lee, the 9th International Conference on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems. L. A. Hirschfeld and S. A. GelmanVenice, Italy; Leslie; Cambridge, UKCambridge University Press16Hippocampal Spatial Mapping as Fast Graph Learning. in arXiv[Lee et al. 2009] R. Lee, R. Walker, L. Meeden, and J. Marshall, Category-Based Intrinsic Motivation, paper presented at the 9th International Conference on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems, Venice, Italy, November 12-14, 2009. [Leinbach and Fagot 1993] M. D. Leinbach and B. I. Fagot, Categorical Habituation to Male and Female Faces-Gender Schematic Processing in Infancy, in Infant Behavior and Development, 16(3)(July-Sept.): 317-332, 1993. [Leslie 1994] A. M. Leslie, Tomm, Toby, and Agency: Core Architecture and Domain Specificity, in Mapping the Mind: Do- main Specificity in Cognition and Culture, L. A. Hirschfeld and S. A. Gelman (eds.), 119-148, Cambridge, UK: Cam- bridge University Press, 1994. [Lewis 2021] Marcus Lewis, Hippocampal Spatial Mapping as Fast Graph Learning, in arXiv, 2021, https://arxiv.org/pdf/2107.00567.pdf.

. Brooks-Gunn Lewis, ; M Lewis, J Brooks-Gunn, Social Cognition and the Acquisition of Self. Plenum Press[Lewis and Brooks-Gunn 1979] M. Lewis and J. Brooks-Gunn, Social Cognition and the Acquisition of Self, New York: Ple- num Press, 1979.

Locations in the Neocortex: A Theory of Sensorimotor Object Recognition Using Cortical Grid Cells. https:/www.frontiersin.org/articles/10.3389/fncir.2019.00022/fullFrontiers in Neural Circuits. Lewis et al. 2019] Marcus Lewis, Scott Purdy, Subutai Ahmad, and Jeff Hawkins1322[Lewis et al. 2019] Marcus Lewis, Scott Purdy, Subutai Ahmad, and Jeff Hawkins, Locations in the Neocortex: A Theory of Sensorimotor Object Recognition Using Cortical Grid Cells, in Frontiers in Neural Circuits, 13:22, 2019, https://www.frontiersin.org/articles/10.3389/fncir.2019.00022/full.

Humanoids that Crawl: Comparing Gait Performance of iCub and NAO Using a CPG Architecture. [ Li, International Conference on Computer Science and Automation Engineering (CSAE). Shanghaipaper presented at the[Li et al. 2011] C. Li, R. Lowe, B. Duran, and T. Ziemke, Humanoids that Crawl: Comparing Gait Performance of iCub and NAO Using a CPG Architecture, paper presented at the International Conference on Computer Science and Automation Engineering (CSAE), Shanghai, 2011.

Li, Humanoids Learning to Crawl Based on Natural CPG-Actor-Critic and Motor Primitives, paper presented at the Workshop on Neuroscience and Robotics (IROS 2013): Towards a Robot-Enabled. Tokyo, JapanNeuroscience-Guided Healthy SocietyLi et al. 2013] C. Li, R. Lowe, and T. Ziemke, Humanoids Learning to Crawl Based on Natural CPG-Actor-Critic and Motor Primitives, paper presented at the Workshop on Neuroscience and Robotics (IROS 2013): Towards a Robot-Enabled, Neu- roscience-Guided Healthy Society, Tokyo, Japan, November 3, 2013.

Recognizing human actions by attributes. [ Liu, IEEE Conf. Computer Vision and Pattern Recognition (CVPR-11). [Liu et al. 2011] Jingen Liu, Benjamin Kuipers, and Silvio Savarese, Recognizing human actions by attributes, in IEEE Conf. Computer Vision and Pattern Recognition (CVPR-11), 2011, http://web.eecs.umich.edu/~kuipers/papers/Liu-cvpr- 11_action_attributes.pdf.

The Development of Anticipatory Hand Orientation during Infancy. John Locke, ; J J Lockman, D H Ashmead, E W Bushnell, Journal of Experimental Child Psychology. 371An Essay Concerning Human Understanding, 1690John Locke, An Essay Concerning Human Understanding, 1690. [Lockman et al. 1984] J. J. Lockman, D. H. Ashmead, and E. W. Bushnell, The Development of Anticipatory Hand Orienta- tion during Infancy, in Journal of Experimental Child Psychology, 37(1): 176-186, 1984.

How Many Words Can My Robot Learn? An Approach and Experiments with One-Class Learning. L S Lopes, A Chauhan, Interaction Studies: Social Behaviour and Communication in Biological and Artificial Systems. 81and Chauhan 2007] L. S. Lopes and A. Chauhan, How Many Words Can My Robot Learn? An Approach and Experi- ments with One-Class Learning, in Interaction Studies: Social Behaviour and Communication in Biological and Artificial Systems, 8(1): 53-81, 2007.

Using a Robot to Reexamine Looking Time Experiments. A Lovett, B Scassellati, 3rd International Conference on Development and Learning. San Diego, CApaper presented at theand Scassellati 2004] A. Lovett and B. Scassellati, Using a Robot to Reexamine Looking Time Experiments, paper presented at the 3rd International Conference on Development and Learning, San Diego, CA, 2004.

[ Lu, Bent Leg Walking Gait Design for Humanoid Robotic Child-iCub Based on Key State Switching Control, paper presented at the IEEE Symposium on Robotics and Applications (ISRA). Kuala Lumpur[Lu et al. 2012] Z. Lu, S. Lallee, V. Tikhanoff, and P. F. Dominey, Bent Leg Walking Gait Design for Humanoid Robotic Child-iCub Based on Key State Switching Control, paper presented at the IEEE Symposium on Robotics and Applications (ISRA), Kuala Lumpur, June 3-5, 2012.

Learning to Bounce: First Lessons from a Bouncing Robot. M Lungarella, L Berthouze ; Max Lungarella, Giorgio Mettay, Rolf Pfeiferz, Giulio Sandini, 2nd International Symposium on Adaptive Motion in Animals and Machines. Kyoto, Japan15Connection Science[Lungarella and Berthouze 2003] M. Lungarella and L. Berthouze, Learning to Bounce: First Lessons from a Bouncing Ro- bot, paper presented at the 2nd International Symposium on Adaptive Motion in Animals and Machines, Kyoto, Japan, March 4-8, 2003. [Lungarella et al. 2003] Max Lungarella, Giorgio Mettay, Rolf Pfeiferz, and Giulio Sandini, Developmental robotics: a sur- vey, in Connection Science, 15(4): 151-190, December 2003, https://www.cs.swarthmore.edu/~meeden/DevelopmentalRobotics/lungarella03.pdf.

Preparing to Talk: Interaction between a Linguistically Enabled Agent and a Human Teacher. Lyon, Robots AAAI Fall Symposium Series. paper presented at the Dialog with[Lyon et al. 2010] C. Lyon, C. L. Nehaniv, and J. Saunders, Preparing to Talk: Interaction between a Linguistically Enabled Agent and a Human Teacher, paper presented at the Dialog with Robots AAAI Fall Symposium Series, Arlington, VA, No- vember 11-13, 2010.

Interactive Language Learning by Robots: The Transition from Babbling to Word Forms. Lyon, PLoS ONE. 76[Lyon et al. 2012] C. Lyon, C. L. Nehaniv, and J. Saunders, Interactive Language Learning by Robots: The Transition from Babbling to Word Forms, in PLoS ONE, 7(6): 1-16, 2012.

Overlapping Layered Learning. Patrick Macalpine, Peter Stone, Artificial Intelligence. 254MacAlpine and Stone[MacAlpine and Stone 2018] Patrick MacAlpine and Peter Stone, Overlapping Layered Learning, in Artificial Intelligence, 254: 21 -43, January 2018, http://www.cs.utexas.edu/~pstone/Papers/bib2html-links/AIJ18-MacAlpine.pdf.

Preliminary Suggestions as to a Formalization of Expectancy Theory. K Maccorquodale, P E Meehl, Psychological Review. 601MacCorquodale and Meehl 1953[MacCorquodale and Meehl 1953] K. MacCorquodale and P. E. Meehl, Preliminary Suggestions as to a Formalization of Ex- pectancy Theory, in Psychological Review, 60(1): 55-63, 1953.

TRESTLE: A Model of Concept Formation in Structured Domains. [ Maclellan, Advances in Cognitive Systems. 4[MacLellan et al. 2016] Christopher J. MacLellan, Erik Harpstead, Vincent Aleven, and Kenneth R. Koedinger, TRESTLE: A Model of Concept Formation in Structured Domains, in Advances in Cognitive Systems, 4: 131-150, 2016, http://christopia.net/media/publications/maclellan-trestle-2016.pdf.

Models of the Emergence of Language. B Macwhinney, Annual Review of Psychology. 49MacWhinney[MacWhinney 1998] B. MacWhinney, Models of the Emergence of Language, in Annual Review of Psychology, 49: 199- 227, 1998.

How to build a baby: II, Conceptual primitives. Jean M Mandler, Psychological Review. 994Jean M. Mandler, How to build a baby: II, Conceptual primitives, in Psychological Review, 99(4): 587-604, 1992, https://pdfs.semanticscholar.org/0f3d/c8fda72b596652c2452908a3a141a809f59f.pdf.

On the spatial foundations of the conceptual system and its enrichment. M Jean, M Mandler ; Jean, Mandler, The Foundations of Mind: Origins of Conceptual Thought. Oxford University Press36[Mandler 2004] Jean M. Mandler, The Foundations of Mind: Origins of Conceptual Thought, Oxford University Press, 2004. [Mandler 2012] Jean M. Mandler, On the spatial foundations of the conceptual system and its enrichment, in Cognitive Sci- ence, 36: 421-451, 2012, http://www.cogsci.ucsd.edu/~jean/abstract/SpatialEnrichment.pdf.

Learning to Recognize Parallel Combinations of Human Motion Primitives with Linguistic Descriptions Using Non-Negative Matrix Factorization. O Mangin, P Y Oudeyer, IEEE/RSJ International Conference on Intelligent Robots and Systems. New YorkMangin and Oudeyer 2012. paper presented at the[Mangin and Oudeyer 2012] O. Mangin and P. Y. Oudeyer, Learning to Recognize Parallel Combinations of Human Motion Primitives with Linguistic Descriptions Using Non-Negative Matrix Factorization, paper presented at the IEEE/RSJ Inter- national Conference on Intelligent Robots and Systems, New York, 2012.

Unicorn: Continual Learning with a Universal. [ Mankowitz, Off-policy Agent, in arXiv. [Mankowitz et al. 2018] Daniel J. Mankowitz, Augustin Žídek, André Barreto, Dan Horgan, Matteo Hessel, John Quan, Junhyuk Oh, Hado van Hasselt, David Silver, and Tom Schaul, Unicorn: Continual Learning with a Universal, Off-policy Agent, in arXiv, 2018, https://arxiv.org/pdf/1802.08294.pdf.

[ Mao, Fast Novel Visual Concept Learning from Sentence Descriptions of Images. in arXiv[Mao et al. 2015] Junhua Mao, Wei Xu, Yi Yang, Jiang Wang, Zhiheng Huang, and Alan L. Yuille, Learning like a Child: Fast Novel Visual Concept Learning from Sentence Descriptions of Images, in arXiv, 2015, https://arxiv.org/pdf/1504.06692.pdf.

Learning to Perceive Object Unity: A Connectionist Account. Gary Marcus, ; D Mareschal, S P Johnson, Deep Learning: A Critical Appraisal, in arXiv. Marcus5[Marcus 2018] Gary Marcus, Deep Learning: A Critical Appraisal, in arXiv, 2018, https://arxiv.org/pdf/1801.00631.pdf. [Mareschal and Johnson 2002] D. Mareschal and S. P. Johnson, Learning to Perceive Object Unity: A Connectionist Account, in Developmental Science, 5(2)(May): 151-172, 2002.

Children's Sensitivity to Constraints on Word Meaning: Taxonomic Versus Thematic Relations. Neuroconstructivism: How the Brain Constructs Cognition. Oxford, UKOxford University Press1Markman and Hutchinson 1984[Mareschal et al. 2007] D. Mareschal, M. H. Johnson, S. Sirois, M. Spratling, M. S. C. Thomas, and G. Westermann, Neuro- constructivism: How the Brain Constructs Cognition, Vol. 1, Oxford, UK: Oxford University Press, 2007. [Markman and Hutchinson 1984] E. M. Markman and J. E. Hutchinson, Children's Sensitivity to Constraints on Word Mean- ing: Taxonomic Versus Thematic Relations, in Cognitive Psychology, 16(1): 1-27, 1984.

Children's use of mutual exclusivity to constrain the meanings of words. E M Markman, G F Wachtel, Cognitive psychology. 20Markman and Wachtel[Markman and Wachtel 1988] E. M. Markman and G. F. Wachtel, Children's use of mutual exclusivity to constrain the mean- ings of words, in Cognitive psychology, 20(2): 121-157, 1988.

Grounding Action Words in the Sensorimotor Interaction with the World: Experiments with a Simulated iCub Humanoid Robot. [ Marocco, 10.3389/fnbot.2010.00007Frontiers in Neurorobotics. 47[Marocco et al. 2010] D. Marocco, A. Cangelosi, K. Fischer, and T. Belpaeme, Grounding Action Words in the Sensorimotor Interaction with the World: Experiments with a Simulated iCub Humanoid Robot, in Frontiers in Neurorobotics, 4(7)(May 31), 2010, doi:10.3389/fnbot.2010.00007.

Vision: A Computational Investigation into the Human Representation and Processing of Visual Information. D Marr, FreemanSan FranciscoD. Marr, Vision: A Computational Investigation into the Human Representation and Processing of Visual Infor- mation, San Francisco: Freeman, 1982.

Sp ; Marshall, P Sandra, Marshall, 10.1017/CBO9780511527890Schemas in problem solving. Cambridge University PressMarshall SP 1995] Sandra P. Marshall, Schemas in problem solving, Cambridge University Press, 1995, https://doi.org/10.1017/CBO9780511527890.

An Emergent Framework for Self-Motivation in Developmental Robotics. J Marshall, 3rd International Conference on Development and Learning. La Jolla, CApaper presented at the[Marshall J et al. 2004] J. Marshall, D. Blank, and L. Meeden, An Emergent Framework for Self-Motivation in Developmen- tal Robotics, paper presented at the 3rd International Conference on Development and Learning (ICDL 2004), La Jolla, CA, October 20-22, 2004.

Medial Prefrontal Cell Activity Signaling Prediction Errors of Action Values. [ Matsumoto, Nature Neuroscience. 105[Matsumoto et al. 2007] M. Matsumoto, M., K. Matsumoto, H. Abe, and K. Tanaka, Medial Prefrontal Cell Activity Signal- ing Prediction Errors of Action Values, in Nature Neuroscience, 10(5): 647-656, 2007.

Infants' Perception of Natural and Distorted Arrangements of a Schematic Face. D Maurer, M Barrera, Child Development. 521and Barrera 1981] D. Maurer and M. Barrera, Infants' Perception of Natural and Distorted Arrangements of a Sche- matic Face, in Child Development, 52(1): 196-202, 1981.

Developmental-Changes in Scanning of Faces by Young Infants. D Maurer, P Salapatek, Child Development. 472Maurer and Salapatek 1976[Maurer and Salapatek 1976] D. Maurer and P. Salapatek, Developmental-Changes in Scanning of Faces by Young Infants, in Child Development, 47(2): 523-527, 1976.

Grounded Situation Models for Robots: Where Words and Percepts Meet. N Mavridis, D Roy, RSJ International Conference on Intelligent Robots and Systems. Mavridis and Roy. paper presented at the IEEE[Mavridis and Roy 2006] N. Mavridis and D. Roy, Grounded Situation Models for Robots: Where Words and Percepts Meet, paper presented at the IEEE/RSJ International Conference on Intelligent Robots and Systems, Beijing, China, October 9- 15, 2006.

Vocabulary Spurt: Are Infants Full of Zipf?. J Mayor, K Plunkett, Cognitive Science Society. and Plunkett 2010. paper presented at the 32nd Annual Conference of theand Plunkett 2010] J. Mayor and K. Plunkett, Vocabulary Spurt: Are Infants Full of Zipf?, paper presented at the 32nd Annual Conference of the Cognitive Science Society, Austin, TX, 2010.

Visual Control of Reaching and Grasping in Infants. M E Mccarty, D H Ashmead, Developmental Psychology. 353and Ashmead 1999] M. E. McCarty and D. H. Ashmead, Visual Control of Reaching and Grasping in Infants, in Developmental Psychology, 35(3)(May): 620-631, 1999.

Problem Solving in Infancy: The Emergence of an Action Plan. [ Mccarty, Developmental Psychology. 354[McCarty et al. 1999] M. E. McCarty, R. K. Clifton, and R. R. Collard. Problem Solving in Infancy: The Emergence of an Action Plan, in Developmental Psychology, 35(4)(Jul): 1091-1101, 1999.

How Infants Use Vision for Grasping Objects. [ Mccarty, Child Development. 724[McCarty et al. 2001a] McCarty, M. E., R. K. Clifton, D. H. Ashmead, P. Lee, and N. Goubet, How Infants Use Vision for Grasping Objects, in Child Development, 72(4)(Jul-Aug.): 973-987, 2001.

The Beginnings of Tool Use by Infants and Toddlers. [ Mccarty, Infancy. 22[McCarty et al. 2001b] M. E. McCarty, R. K. Clifton, and R. R. Collard, The Beginnings of Tool Use by Infants and Toddlers, in Infancy, 2(2): 233-256, 2001.

Thomas Lee Mccauley, Neural Schemas: Toward a Comprehensive Mechanism of Mind. University of MemphisPhD thesisThomas Lee McCauley, Neural Schemas: Toward a Comprehensive Mechanism of Mind, PhD thesis, Uni- versity of Memphis, 2002, https://www.cs.memphis.edu/~tmccauly/McCauley-Dis.pdf.

An Interactive Activation Model of Context Effects in Letter Perception. 1. An Account of Basic Findings. J L Mcclelland, D E Rumelhart, Psychological Review. 885McClelland and Rumelhart 1981[McClelland and Rumelhart 1981] J. L. McClelland and D. E. Rumelhart, An Interactive Activation Model of Context Effects in Letter Perception. 1. An Account of Basic Findings, in Psychological Review, 88(5): 375-407, 1981.

Adaptation to Displacing Prisms in Human Infants. P M Mcdonnell, W C Abraham, Perception. 82and Abraham 1979and Abraham 1979] P. M. McDonnell and W. C. Abraham, Adaptation to Displacing Prisms in Human Infants, in Perception, 8(2): 175-185, 1979.

The Neuro-Muscular Maturation of the Human Infant. M B Mcgraw, New YorkColumbia UniversityM. B. McGraw, The Neuro-Muscular Maturation of the Human Infant, New York: Columbia University, 1945.

Jean Piaget's Theory of Cognitive Development. A Saul, Mcleod, Simply Psychology. [McLeod 2020] Saul A. McLeod, Jean Piaget's Theory of Cognitive Development, in Simply Psychology, updated December 7, 2020, https://www.simplypsychology.org/piaget.html.

Defusing the Childhood Vocabulary Explosion. B Mcmurray, ; D Mcnamee, D M Wolpert, Annual review of control, robotics, and autonomous systems. 317Internal models in biological control[McMurray 2007] B. McMurray, Defusing the Childhood Vocabulary Explosion, in Science, 317(5838)(Aug.): 631, 2007. [McNamee and Wolpert 2019] D. McNamee and D. M. Wolpert, Internal models in biological control, in Annual review of control, robotics, and autonomous systems, 2: 339-364, 2019, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6520231/.

Infant Imitation after a One-Week Delay-Long-Term-Memory for Novel Acts and Multiple Stimuli. C A Meissner, J C Brigham, Developmental Psychology. 71Public Policy, and Law[Meissner and Brigham 2001] C. A. Meissner and J. C. Brigham, Thirty Years of Investigating the Own-Race Bias in Memory for Faces-a Meta-Analytic Review, in Psychology, Public Policy, and Law, 7(1)(Mar.): 3-35, 2001. [Meltzoff 1988] A. N. Meltzoff, Infant Imitation after a One-Week Delay-Long-Term-Memory for Novel Acts and Multiple Stimuli, in Developmental Psychology, 24(4)(July): 470-476, 1988.

Understanding the Intentions of Others: Re-Enactment of Intended Acts by Eighteen-Month-Old Children. A N Meltzoff, Developmental Psychology. 315[Meltzoff 1995] A. N. Meltzoff, Understanding the Intentions of Others: Re-Enactment of Intended Acts by Eighteen-Month- Old Children, in Developmental Psychology, 31(5): 838-850, 1995.

The 'Like Me' Framework for Recognizing and Becoming an Intentional Agent. A N Meltzoff, Acta Psychologica. 1241[Meltzoff 2007] A. N. Meltzoff, The 'Like Me' Framework for Recognizing and Becoming an Intentional Agent, in Acta Psy- chologica, 124(1): 26-43, 2007.

Inter-Modal Matching by Human Neonates. A N Meltzoff, R W Borton, Nature. 2825737and Borton 1979] A. N. Meltzoff and R. W. Borton, Inter-Modal Matching by Human Neonates, in Nature, 282(5737): 403-404, 1979.

Imitation of Facial and Manual Gestures by Human Neonates. A N Meltzoff, M K Moore, Science. 1984312and Mooreand Moore 1977] A. N. Meltzoff and M. K. Moore, Imitation of Facial and Manual Gestures by Human Neonates, in Science, 198(4312): 75-78, 1977.

Newborn-Infants Imitate Adult Facial Gestures. A N Meltzoff, M K Moore, Child Development. 543and Moore 1983and Moore 1983] A. N. Meltzoff and M. K. Moore, Newborn-Infants Imitate Adult Facial Gestures, in Child De- velopment, 54(3): 702-709, 1983.

Imitation in Newborn-Infants-Exploring the Range of Gestures Imitated and the Underlying Mechanisms. A N Meltzoff, M K K Moore ; M, Moore, Explaining Facial Imitation: A Theoretical Model, in Early Development & Parenting. 25and Moore 1989and Moore 1989] A. N. Meltzoff and M. K. Moore, Imitation in Newborn-Infants-Exploring the Range of Ges- tures Imitated and the Underlying Mechanisms, in Developmental Psychology, 25(6)(Nov.): 954-962, 1989. [Meltzoff and Moore 1997] A. N. Meltzoff and M. K. Moore, Explaining Facial Imitation: A Theoretical Model, in Early De- velopment & Parenting, 6(3-4)(Sept.-Dec.): 179-192, 1997.

A Comparative Study of Value Systems for Self-Motivated Exploration and Learning by Robots. ] K E Merrick 2010, Merrick, IEEE Transactions on Autonomous Mental Development. 22Merrick 2010] K. E. Merrick, A Comparative Study of Value Systems for Self-Motivated Exploration and Learning by Ro- bots, in IEEE Transactions on Autonomous Mental Development, 2(2)(June): 119-131, 2010.

A Developmental Approach to Visually-Guided Reaching in Artificial Systems. [ Metta, Neural Networks. 1210[Metta et al. 1999] G. Metta, G. Sandini, and J. Konczak, A Developmental Approach to Visually-Guided Reaching in Artifi- cial Systems, in Neural Networks, 12(10)(Dec.): 1413-1427, 1999.

The iCub Humanoid Robot: An Open-Systems Platform for Research in Cognitive Development. [ Metta, Neural Networks. 23[Metta et al. 2010] G. Metta, L. Natale, F. Nori, G. Sandini, D. Vernon, L. Fadiga, C. von Hofsten, K. Rosander, J. Santos- Victor, A. Bernardino, and L. Montesano, The iCub Humanoid Robot: An Open-Systems Platform for Research in Cogni- tive Development, in Neural Networks, 23(2010): 1125-1134, 2010.

Motion-Based Robotic Self-Recognition. Michel, 8th International Workshop on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems. Sendai, Japan; Brighton, UKpaper presented at the IEEE. Mikhailova et al. 2008. Coupling of Mental Concepts to a Reactive Layer: Incremental Approach in System Design, paper presented at the Proceedings of theMichel et al. 2004] P. Michel, K. Gold, and B. Scassellati, Motion-Based Robotic Self-Recognition, paper presented at the IEEE/RSJ International Conference on Intelligent Robots and Systems, Sendai, Japan, September 28-October 2, 2004. [Mikhailova et al. 2008] I. Mikhailova, M. Heracles, B. Bolder, H. Janssen, H. Brandl, J. Schmüdderich, and C. Goerick, Coupling of Mental Concepts to a Reactive Layer: Incremental Approach in System Design, paper presented at the Pro- ceedings of the 8th International Workshop on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems, Brighton, UK, July 30-31, 2008.

The Construction of Reality in a Cognitive System. S P Michael, Miller, Papers from the AAAI Spring Symposium. Michael S. P. Miller, The Construction of Reality in a Cognitive System, in Papers from the AAAI Spring Symposium, 2013, https://www.aaai.org/ocs/index.php/WS/AAAIW13/paper/viewFile/7014/6580.

The Neural Proposition: Structures for Cognitive Systems. S P Michael, Miller, Papers from the AAAI Spring Symposium. [Miller 2013b] Michael S. P. Miller, The Neural Proposition: Structures for Cognitive Systems, in Papers from the AAAI Spring Symposium, 2013.

. S P Michael, Miller, Building Minds with Patterns. Michael S. P. Miller, Building Minds with Patterns, 2018, ISBN 1980362661.

A Framework for Representing Knowledge, in The Psychology of Computer Vision. Marvin Minsky, P. H. WinstonMcGraw-HillNew YorkMarvin Minsky, A Framework for Representing Knowledge, in The Psychology of Computer Vision, P. H. Winston (ed.), New York: McGraw-Hill, 1975.

Never-ending learning. Mitchell, Communications of the ACM. 615Mitchell et al. 2018] T. Mitchell, W. Cohen, E. Hruschka, P. Talukdar, B. Yang, J. Betteridge, A. Carlson, B. Dalvi, M. Gardner, B. Kisiel, J. Krishnamurthy, N. Lao, K. Mazaitis, T. Mohamed, N. Nakashole, E. Platanios, A. Ritter, M. Samadi, B. Settles, R. Wang, D. Wijaya, A. Gupta, X. Chen, A. Saparov, M. Greaves, and J. Welling, Never-ending learning, in Communications of the ACM, 61(5): 103 -115, May 2018.

Functions and Mechanisms of Intrinsic Motivations. M Mirolli, G Baldassarre, Intrinsically Motivated Learning in Natural and Artificial Systems. G. Baldassarre and M. MirolliHeidelbergSpringer-Verlag[Mirolli and Baldassarre 2013] M. Mirolli and G. Baldassarre, Functions and Mechanisms of Intrinsic Motivations, in Intrin- sically Motivated Learning in Natural and Artificial Systems, ed. G. Baldassarre and M. Mirolli, 49-72. Heidelberg: Springer-Verlag, 2013.

A Bayesian generative model for learning semantic hierarchies. [ Mittelman, Frontiers in Psychology: Hypothesis and Theory. 5[Mittelman et al. 2014] R. Mittelman, M. Sun, B. Kuipers and S. Savarese, A Bayesian generative model for learning seman- tic hierarchies, in Frontiers in Psychology: Hypothesis and Theory 5(417): 1-9, May 2014, http://web.eecs.umich.edu/~kuipers/papers/Mittelman-fp-14.pdf.

Bootstrap learning for object discovery. IEEE/RSJ International Conference on Intelligent Robots and Systems, Proceedings. 1Modayil and Kuipers[Modayil and Kuipers 2004] Joseph Modayil and Benjamin J. Kuipers, Bootstrap learning for object discovery, in IEEE/RSJ International Conference on Intelligent Robots and Systems, Proceedings, 1: 742-747, 2004.

Autonomous development of a grounded object ontology by a learning robot. Joseph Modayil, Benjamin J Kuipers, Proceedings of the Twenty-Second AAAI Conference on Artificial Intelligence. the Twenty-Second AAAI Conference on Artificial IntelligenceVancouver, British Columbia, CanadaAAAI Pressand Kuipers 2007] Joseph Modayil and Benjamin J. Kuipers, Autonomous development of a grounded object on- tology by a learning robot, in Proceedings of the Twenty-Second AAAI Conference on Artificial Intelligence, 1095-1101, Vancouver, British Columbia, Canada, pages, AAAI Press, July 22-26, 2007.

Learning Object Affordances: From Sensory-Motor Coordination to Imitation. [ Montesano, IEEE Transactions on Robotics. 241[Montesano et al. 2008] L. Montesano, M. Lopes, A. Bernardino, and J. Santos-Victor, Learning Object Affordances: From Sensory-Motor Coordination to Imitation, in IEEE Transactions on Robotics, 24(1) (Feb.): 15-26, 2008.

Self-organizing body-schema for motor planning. Pietro Morasso, Vittorio Sanguineti, Journal of Motor Behavior. 271Morasso and Sanguineti[Morasso and Sanguineti 1995] Pietro Morasso and Vittorio Sanguineti, Self-organizing body-schema for motor planning, in Journal of Motor Behavior, 27(1): 52 -66, 1995.

Why Are There Developmental Stages in Language Learning? A Developmental Robotics Model of Language Development. Anthony F Morse, Angelo Cangelosi, https:/onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12390Cognitive Science. 41and Cangelosi 2017] Anthony F. Morse and Angelo Cangelosi, Why Are There Developmental Stages in Language Learning? A Developmental Robotics Model of Language Development, in Cognitive Science, 41: 32-51, 2017, https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12390.

Thinking with Your Body: Modelling Spatial Biases in Categorization Using a Real Humanoid Robot. Morse, 32nd Annual Meeting of the Cognitive Science Society. Portland, ORpaper presented at the[Morse et al. 2010a] A. F. Morse, T. Belpaeme, A. Cangelosi, and L. B. Smith, Thinking with Your Body: Modelling Spatial Biases in Categorization Using a Real Humanoid Robot, paper presented at the 32nd Annual Meeting of the Cognitive Sci- ence Society, Portland, OR, August 11-14, 2010.

Epigenetic Robotics Architecture (ERA). Morse, IEEE Transactions on Autonomous Mental Development. 24Morse et al. 2010b] A. F. Morse, J. de Greeff, T. Belpeame, and A. Cangelosi, Epigenetic Robotics Architecture (ERA), in IEEE Transactions on Autonomous Mental Development, 2(4)(Dec.): 325-339, 2010.

Conspec and Conlern-A 2-Process Theory of Infant Face Recognition. J Morton, M H Johnson, Psychological Review. 982and Johnsonand Johnson 1991] J. Morton and M. H. Johnson, Conspec and Conlern-A 2-Process Theory of Infant Face Recog- nition, in Psychological Review, 98(2)(Apr.): 164-181, 1991.

The Distributed Ontology, Modelling and Specification Language -DOL. [ Mossakowski, Proceedings of the 7th International Workshop on Modular Ontologies. the 7th International Workshop on Modular OntologiesCorunna, Spain[Mossakowski et al. 2013] Till Mossakowski, Oliver Kutz, Mihai Codescu, and Christoph Lange, The Distributed Ontology, Modelling and Specification Language -DOL, in Proceedings of the 7th International Workshop on Modular Ontologies, pp. 1-21, Corunna, Spain, September 15, 2013.

Communicating Quantities: A Psychological Perspective. L M Moxey, A J Sanford, ErlbaumSanford; Hove, UK[Moxey and Sanford 1993] L. M. Moxey and A. J. Sanford, Communicating Quantities: A Psychological Perspective, Hove, UK: Erlbaum, 1993.

A Schematic Representation for Cognitive Tool-Using Agents, North Carolina State University PhD thesis. Wei Mu, Wei Mu, A Schematic Representation for Cognitive Tool-Using Agents, North Carolina State University PhD the- sis, 2009, https://repository.lib.ncsu.edu/bitstream/handle/1840.16/4031/etd.pdf?sequence=1.

Imitation in Infancy. J. Nadel and G. ButterworthNew YorkCambridge University PressNadel and Butterworth[Nadel and Butterworth 1999] J. Nadel and G. Butterworth (eds.), Imitation in Infancy, New York: Cambridge University Press, 1999.

How Does an Infant Acquire the Ability of Joint Attention?: A Constructive Approach, paper presented at the 3rd International Workshop on Epigenetic Robotics. [ Nagai, A Constructive Model for the Development of Joint Attention. Nagai et al. 2003b] Y. Nagai, K. Hosoda, A. Morita, and M. AsadaLund, Sweden15[Nagai et al. 2003a] Y. Nagai, K. Hosoda, and M. Asada, How Does an Infant Acquire the Ability of Joint Attention?: A Con- structive Approach, paper presented at the 3rd International Workshop on Epigenetic Robotics, Lund, Sweden, 2003. [Nagai et al. 2003b] Y. Nagai, K. Hosoda, A. Morita, and M. Asada, A Constructive Model for the Development of Joint At- tention, in Connection Science, 15(4)(Dec.): 211-229, 2003.

Learning for Joint Attention Helped by Functional Development. [ Nagai, Advanced Robotics. 2010[Nagai et al. 2006] Y. Nagai, M. Asada, and K. Hosoda, Learning for Joint Attention Helped by Functional Development, in Advanced Robotics, 20(10): 1165-1181, 2006.

From Sensorimotor Development to Object Perception, paper presented at the 5th IEEE. Natale, Learning Precise 3D Reaching in a Humanoid Robot, paper presented at the IEEE 6th International Conference on Development and Learning. C. Nehaniv and K. DautenhahnStanford, CA; Japan; London; Cambridge, MA; CambridgeCambridge University PressStanford UniversityImitation and Social Learning in Robots, Humans and Animals[Natale et al. 2005a] L. Natale, G. Metta, and G. Sandini, A Developmental Approach to Grasping, paper presented at the AAAI Spring Symposium on Developmental Robotics, Stanford University, Stanford, CA, March 21-23, 2005. [Natale et al. 2005b] L. Natale, F. Orabona, F. Berton, G. Metta, and G. Sandini, From Sensorimotor Development to Object Perception, paper presented at the 5th IEEE-RAS International Conference on Humanoid Robots, Japan, 2005. [Natale et al. 2007] L. Natale, F. Nori, G. Sandini, and G. Metta, Learning Precise 3D Reaching in a Humanoid Robot, paper presented at the IEEE 6th International Conference on Development and Learning, London, July 11-13, 2007. [Nehaniv and Dautenhahn 2002] C. L. Nehaniv and K. Dautenhahn, The Correspondence Problem, in Imitation in Animals and Artifacts, ed. K. Dautenhahn and C. L. Nehaniv, 41-61, Cambridge, MA: MIT Press, 2002. [Nehaniv and Dautenhahn 2007] C. Nehaniv and K. Dautenhahn (eds.), Imitation and Social Learning in Robots, Humans and Animals, Cambridge: Cambridge University Press, 2007.

You can't play 20 questions with nature and win: projective comments on the papers of this symposium. Allen Newell, 10.1016/B978-0-12-170150-5.50012-3Visual Information Processing. William G. ChaseAcademic PressAllen Newell, You can't play 20 questions with nature and win: projective comments on the papers of this symposium, in Visual Information Processing, William G. Chase (ed.), Academic Press, pp. 283-308, 1973, https://doi.org/10.1016/B978-0-12-170150-5.50012-3.

Newell, Task Constraints and Infant Grip Configurations. 22[Newell et al. 1989] K. M. Newell, D. M. Scully, P. V. McDonald, and R. Baillargeon, Task Constraints and Infant Grip Con- figurations, in Developmental Psychobiology, 22(8)(Dec.): 817-832, 1989.

Nils Nilsson, Human-Level Artificial Intelligence? Be Serious!, in AI Magazine. 26[Nilsson 2005] Nils Nilsson, Human-Level Artificial Intelligence? Be Serious!, in AI Magazine, 26(4): 68-75, 2005. https://ai.stanford.edu/~nilsson/OnlinePubs-Nils/General%20Essays/AIMag26-04-HLAI.pdf.

Learning grounded finite-state representations from unstructured demonstrations. Niekum, International Journal of Robotics Research. 342[Niekum et al. 2014] Scott Niekum, Sarah Osentoski, George Konidaris, Sachin Chitta, Bhaskara Marthi, and Andrew G. Barto, Learning grounded finite-state representations from unstructured demonstrations, in International Journal of Ro- botics Research, 34(2): 131-157, 2014, http://www.cs.utexas.edu/users/sniekum/pubs/IJRR2014.pdf.

E Nivel, K R Thórisson, B R Steunebrink, H Dindo, G Pezzulo, M Rodriguez, C Hernandez, D Ognibene, J Schmidhuber, R Sanz, H P Helgason, A Chella, G K Jonsson, Bounded Recursive Self-Improvement. Nivel et al. 2013. in arXiv[Nivel et al. 2013] E. Nivel, K. R. Thórisson, B. R. Steunebrink, H. Dindo, G. Pezzulo, M. Rodriguez, C. Hernandez, D. Og- nibene, J. Schmidhuber, R. Sanz, H. P. Helgason, A. Chella, and G. K. Jonsson, Bounded Recursive Self-Improvement, in arXiv, 2013, https://arxiv.org/abs/1312.6764.

Autonomous acquisition of natural language. Nivel, Proceedings of IADIS International Conference on Intelligent Systems & Agents. IADIS International Conference on Intelligent Systems & AgentsHeidelbergSpringerProceedings of the 7th Conference on Artificial General Intelligence[Nivel et al. 2014a] Eric Nivel, Kristinn R. Thórisson, Bas R. Steunebrink, Haris Dindo, Giovanni Pezzulo, Manuel Rodríguez Hernández, Carlos Hernández Corbato et al., Autonomous acquisition of natural language, in Proceedings of IADIS International Conference on Intelligent Systems & Agents, pp. 58-66, 2014. [Nivel et al. 2014b] Eric Nivel, Kristinn R. Thórisson, Bas R. Steunebrink, Haris Dindo, Giovanni Pezzulo, Manuel Rodríguez, Carlos Hernández, Dimitri Ognibene, Juergen Schmidhuber, Ricardo Sanz, Helgi P. Helgason, and Antonio Chella, Bounded Seed-AGI, in Proceedings of the 7th Conference on Artificial General Intelligence, Heidelberg: Springer, 2014, http://people.idsia.ch/~steunebrink/Publications/AGI14_seed-AGI.pdf.

Autonomous Learning of 3D Reaching in a Humanoid Robot. [ Nori, Zero-Shot Learning by Convex Combination of Semantic Embeddings. Norouzi et al. 2014] Mohammad Norouzi, Tomas Mikolov, Samy Bengio, Yoram Singer, Jonathon Shlens, Andrea Frome, Greg S. Corrado, and Jeffrey DeanSan Diego, CApaper presented at the IEEE. in arXiv[Nori et al. 2007] F. Nori, L. Natale, G. Sandini, and G. Metta, Autonomous Learning of 3D Reaching in a Humanoid Robot, paper presented at the IEEE/RSJ International Conference on Intelligent Robots and Systems, San Diego, CA, October 29-November 2, 2007. [Norouzi et al. 2014] Mohammad Norouzi, Tomas Mikolov, Samy Bengio, Yoram Singer, Jonathon Shlens, Andrea Frome, Greg S. Corrado, and Jeffrey Dean, Zero-Shot Learning by Convex Combination of Semantic Embeddings, in arXiv, 2014, https://arxiv.org/pdf/1312.5650.pdf.

Sparsity Enables 100x Performance Acceleration in Deep Learning Networks: A Technology Demonstration. Inc Numenta, V2.0[Numenta 2021a] Numenta, Inc., Sparsity Enables 100x Performance Acceleration in Deep Learning Networks: A Technolo- gy Demonstration, V2.0, May 20, 2021, https://numenta.com/assets/pdf/research-publications/papers/Sparsity-Enables- 100x-Performance-Acceleration-Deep-Learning-Networks.pdf.

A Thousand Brains: A New Theory of Intelligence by Jeff Hawkins, Numenta website. Inc Numenta, [Numenta 2021b] Numenta, Inc., A Thousand Brains: A New Theory of Intelligence by Jeff Hawkins, Numenta website, 2021, https://numenta.com/a-thousand-brains-by-jeff-hawkins.

How Can Humanoid Acquire Lexicon?-Active Approach by Attention and Learning Biases Based on Curiosity, paper presented at the IEEE/RSJ International Con-ference on Intelligent Robots and Systems. M Ogino, M Kikuchi, M K Asada ; D, Oller, Connection Science. Chrystopher L. Nehaniv, and Daniel PolaniBeijing, China; London, UK: Erlbaum18From unknown sensors and actuators to actions grounded in sensorimotor perceptions[Ogino et al. 2006] M. Ogino, M. Kikuchi, and M. Asada, How Can Humanoid Acquire Lexicon?-Active Approach by At- tention and Learning Biases Based on Curiosity, paper presented at the IEEE/RSJ International Con-ference on Intelligent Robots and Systems, Beijing, China, October 9-15, 2006. [Oller 2000] D. K. Oller, The Emergence of the Speech Capacity, London, UK: Erlbaum, 2000. [Olsson et al. 2006] Lars Olsson, Chrystopher L. Nehaniv, and Daniel Polani, From unknown sensors and actuators to actions grounded in sensorimotor perceptions, in Connection Science, 18(2): 121-144, 2006, http://homepages.herts.ac.uk/~comqdp1/publications/files/olssonl_cs.pdf.

[ Oord, Representation Learning with Contrastive Predictive Coding. in arXiv[Oord et al. 2018] Aaron van den Oord, Yazhe Li, and Oriol Vinyals, Representation Learning with Contrastive Predictive Coding, in arXiv, 2018, https://arxiv.org/pdf/1807.03748.pdf.

Olov Oscarsson, Functional units of the cerebellum -sagittal zones and microzones. Trends in Neurosciences. 2[Oscarsson 1979] Olov Oscarsson, Functional units of the cerebellum -sagittal zones and microzones, in Trends in Neurosci- ences, 2: 143-145, 1979.

Self-Organization in the Evolution of Speech. P Y Oudeyer, Oxford University Press6Oxford, UK[Oudeyer 2006] P. Y. Oudeyer, Self-Organization in the Evolution of Speech, Vol. 6, Oxford, UK: Oxford University Press, 2006.

Pierre-Yves Oudeyer, Autonomous Development and Learning in Artificial Intelligence and Robotics: Scaling Up Deep Learning to Human-Like Learning, in Behavioural and Brain Sciences. 40Oudeyer[Oudeyer 2017a] Pierre-Yves Oudeyer, Autonomous Development and Learning in Artificial Intelligence and Robotics: Scal- ing Up Deep Learning to Human-Like Learning, in Behavioural and Brain Sciences, 40: 45-46, 2017, http://www.pyoudeyer.com/oudeyerBBS17.pdf.

What can we learn about development from baby robots?. Pierre-Yves Oudeyer, WIREs Cogn Sci. 8Oudeyer[Oudeyer 2017b] Pierre-Yves Oudeyer, What can we learn about development from baby robots?, in WIREs Cogn Sci, 8:e1395, 2017, http://www.pyoudeyer.com/oudeyerWiley16.pdf.

Discovering Communication. P Y Oudeyer, F Kaplan, Connection Science. 18Oudeyer and Kaplan[Oudeyer and Kaplan 2006] P. Y. Oudeyer and F. Kaplan, Discovering Communication, in Connection Science, 18(2)(June): 189-206, 2006.

Intrinsic motivation systems for autonomous mental development. [ Oudeyer, IEEE Transactions on Evolutionary Computation. 11[Oudeyer et al. 2007] Pierre-Yves Oudeyer, Frederic Kaplan, and Verena V. Hafner, Intrinsic motivation systems for autono- mous mental development, in IEEE Transactions on Evolutionary Computation, 11(6): 265-286, 2007, http://www.pyoudeyer.com/ims.pdf.

Infant Grasp Learning: A Computational Model, in Experimental. [ Oztop, Brain Research. 1584[Oztop et al. 2004] E. Oztop, N. S. Bradley, and M. A. Arbib, Infant Grasp Learning: A Computational Model, in Experi- mental Brain Research, 158(4)(Oct.): 480-503, 2004.

Zero-shot learning with semantic output codes. [ Palatucci, Advances in Neural Information Processing Systems. [Palatucci et al. 2009] Mark Palatucci, Dean Pomerleau, Geoffrey E. Hinton, and Tom M. Mitchell, Zero-shot learning with semantic output codes, in Advances in Neural Information Processing Systems, NIPS, 2009, http://www.cs.cmu.edu/afs/cs/project/theo-73/www/papers/zero-shot-learning.pdf.

Sinno Jialin Pan and Qiang Yang, A survey on transfer learning. IEEE Transactions on Knowledge and Data Engineering. 2210Pan and Yang 2010[Pan and Yang 2010] Sinno Jialin Pan and Qiang Yang, A survey on transfer learning, in IEEE Transactions on Knowledge and Data Engineering, 22(10): 1345 -1359, 2010, https://www.cse.ust.hk/~qyang/Docs/2009/tkde_transfer_learning.pdf.

. D Parisi, M Schlesinger, Artificial Life and Piaget. 173-4)Cognitive Development[Parisi and Schlesinger 2002] D. Parisi and M. Schlesinger, Artificial Life and Piaget, in Cognitive Development, 17(3- 4)(Sept.-Dec.): 1301-1321, 2002.

The Development of Negation in Early Child Language, Unpublished diss. R D Pea, University of OxfordR. D. Pea, The Development of Negation in Early Child Language, Unpublished diss., University of Oxford, 1978.

R D Pea, Grounding Cognition: The Role of Perception and Action in Memory, Language, and Thinking. D. Pecher and R. A. ZwaanNew York; Cambridge, UKCambridge University PressThe Social Foundations of Language and Thought: Essays inR. D. Pea, The Development of Negation in Early Child Language, in The Social Foundations of Language and Thought: Essays in Honor of Jerome S. Bruner, D. R. Olson (ed.), 156-186. New York: W. W. Norton, 1980. [Pecher and Zwaan 2005] D. Pecher and R. A. Zwaan (eds.), Grounding Cognition: The Role of Perception and Action in Memory, Language, and Thinking, Cambridge, UK: Cambridge University Press, 2005.

Phase-Locked Responses to Speech in Human Auditory Cortex Are Enhanced During Comprehension. Peellee, Cerebral Cortex. 23Peellee et al. 2013] J. E. Peelle, J. Gross, and M. H. Davis, Phase-Locked Responses to Speech in Human Auditory Cortex Are Enhanced During Comprehension, in Cerebral Cortex, 23(6): 1378-1387, 2013.

Learning regularities with a constructivist agent. S Filipo, Luis O Perotto, Alvares, AAMAS '06: Proceedings of the fifth international joint conference on Autonomous agents and multiagent systems. New York, NY, USAPerotto and Alvares[Perotto and Alvares 2006] Filipo S. Perotto and Luis O. Alvares, Learning regularities with a constructivist agent, in AAMAS '06: Proceedings of the fifth international joint conference on Autonomous agents and multiagent systems, 807-809, New York, NY, USA, 2006, https://www.researchgate.net/publication/221456902_Learning_regularities_with_a_constructivist_agent.

Constructivist anticipatory learning mechanism (CALM): Dealing with partially deterministic and partially observable environments. [ Perotto, Proceedings of the Seventh International Conference on Epigenetic Robotics. the Seventh International Conference on Epigenetic RoboticsPiscataway, NJ, USA[Perotto et al. 2007] Filipo Perotto, Jean-Christophe Buisson, and Luis Alvares, Constructivist anticipatory learning mecha- nism (CALM): Dealing with partially deterministic and partially observable environments, in Proceedings of the Seventh International Conference on Epigenetic Robotics, 117-127, Piscataway, NJ, USA, 2007, http://www.lucs.lu.se/LUCS/135/Perotto.pdf.

A Computational Constructivist Model as an Anticipatory Learning Mechanism for Coupled Agent-Environment Systems. S Filipo, Perotto, Constructivist Foundations. 9Vrije Universiteit BrusselPerotto 2013[Perotto 2013] Filipo S. Perotto, A Computational Constructivist Model as an Anticipatory Learning Mechanism for Coupled Agent-Environment Systems, in Constructivist Foundations, 9(1): 46-56, Vrije Universiteit Brussel, 2013, http://www.fsperotto.com/papers/PEROTTO -CF 2013.pdf.

The Good, the Bad, and the Ugly: The Many Faces of Constructivism, in Educational Researcher. ] D C Phillips, https:/journals.sagepub.com/doi/pdf/10.3102/0013189X024007005?casa_token=IIewdawoqDgAAAAA:zig1wfVHRuoiQyh7EjWg2KAjJQMxtI431SZJ03F8B-oiT-k3UdtuNHlzXfxswoiQ2TNLTizvOQ24Phillips[Phillips 1995] D. C. Phillips, The Good, the Bad, and the Ugly: The Many Faces of Constructivism, in Educational Re- searcher, 24(7): 5-1, Oct. 1995, https://journals.sagepub.com/doi/pdf/10.3102/0013189X024007005?casa_token=IIewdawoqDgAAAAA:zig1wfVHRuoi Qyh7EjWg2KAjJQMxtI431SZJ03F8B-oiT-k3UdtuNHlzXfxswoiQ2TNLTizvOQ.

The construction of reality in the child. Jean Piaget, RoutlegeInternational Universities PressNew York, NY; New York, NYThe Origins of Intelligence in Children[Piaget 1934/1954] Jean Piaget, The construction of reality in the child, New York, NY: Routlege, 1954. [Piaget 1952] Jean Piaget, The Origins of Intelligence in Children, New York, NY: International Universities Press, 1952, http://www.pitt.edu/~strauss/origins_r.pdf.

The Development of Thought: Equilibration of Cognitive Structures. J Piaget ; Jean, Piaget, trans. Arnold Rosin. Viking PressThe Psychology of Intelligence[Piaget 1972] J. Piaget, The Psychology of Intelligence, Totowa, NJ: Littlefields Adams, 1972. [Piaget 1977] Jean Piaget, The Development of Thought: Equilibration of Cognitive Structures, trans. Arnold Rosin, Viking Press, 1977.

The Equilibration of Cognitive Structures: The Central Problem of Intellectual Development, trans. Jean Piaget, University of Chicago PressPiaget 1985[Piaget 1985] Jean Piaget, The Equilibration of Cognitive Structures: The Central Problem of Intellectual Development, trans. Terrance Brown, University of Chicago Press, 1985.

Map learning with uninterpreted sensors and effectors. David Pierce, Benjamin Kuipers, Artificial Intelligence. 92and Kuipers 1997] David Pierce and Benjamin Kuipers, Map learning with uninterpreted sensors and effectors, in Ar- tificial Intelligence, 92: 169-229, 1997, https://www.cs.cmu.edu/~motionplanning/papers/sbp_papers/integrated1/pierce_sonar.pdf.

Intuitive physics learning in a deep-learning model inspired by developmental psychology. Luis S Piloto, Ari Weinstein, Peter Battaglia, Matthew Botvinick, 10.1038/s41562-022-01394-8Nature Human Behavior. Piloto et al. 2022[Piloto et al. 2022] Luis S. Piloto, Ari Weinstein, Peter Battaglia, and Matthew Botvinick, Intuitive physics learning in a deep-learning model inspired by developmental psychology, in Nature Human Behavior, July 2022, https://doi.org/10.1038/s41562-022-01394-8.

A resource-allocating network for function interpolation. S ; J C Pinker, Platt, Neural Computation. New YorkHarperCollins3The Language Instinct: How the Mind Creates Language[Pinker 1994] S. Pinker, The Language Instinct: How the Mind Creates Language, New York: HarperCollins, 1994. [Platt 1991] J. C. Platt, A resource-allocating network for function interpolation, in Neural Computation, 3: 213-25, 1991, https://sci2s.ugr.es/keel/pdf/algorithm/classification-algorithm/plat1991.pdf.

Symbol Grounding or the Emergence of Symbols? Vocabulary Growth in Children and a Connectionist Net. K Plunkett, C Sinha, M F Møller, O Strandsby, T William, Powers, Connection Science. William T. Powers4BYTE magazine[Plunkett et al. 1992] K. Plunkett, C. Sinha, M. F. Møller, and O. Strandsby, Symbol Grounding or the Emergence of Sym- bols? Vocabulary Growth in Children and a Connectionist Net, in Connection Science, 4(3-4): 293-312, 1992. [Powers 1973] William T. Powers, Behavior: The Control of Perceptions, Aldine Publishing Co., 1973. [Powers 1979] William T. Powers, The Nature of Robots, in BYTE magazine, 4(6): 132 -144, June 1979, https://www.yumpu.com/en/document/read/36496244/byte-1979-06.

Developing navigation behavior through self-organizing distinctive-state abstraction. Provost, Connection Science. 18[Provost et al. 2006] Jefferson Provost, Benjamin J. Kuipers, and Risto Miikkulainen, Developing navigation behavior through self-organizing distinctive-state abstraction, in Connection Science, 18(2): 159 -172, June 2006, ftp://www.cs.utexas.edu/pub/qsim/papers/Provost-connsci-06.pdf.

Self-organizing distinctive state abstraction using options. Provost, Proceedings of the Seventh International Conference on Epigenetic Robotics. the Seventh International Conference on Epigenetic Robotics[Provost et al. 2007] Jefferson Provost, Benjamin J. Kuipers, and Risto Miikkulainen, Self-organizing distinctive state ab- straction using options, in Proceedings of the Seventh International Conference on Epigenetic Robotics, 2007, https://www.researchgate.net/publication/228630725_Self-organizing_distinctive_state_abstraction_using_options.

The Neuroscience of Language: On Brain Circuits of Words and Serial Order. F Pulvermüller, Cambridge University PressCambridge, UK[Pulvermüller 2003] F. Pulvermüller, The Neuroscience of Language: On Brain Circuits of Words and Serial Order, Cam- bridge, UK: Cambridge University Press, 2003.

R Steven, Quartz, Neural networks, nativism, and the plausibility of constructivism. 48pdfSteven R. Quartz, Neural networks, nativism, and the plausibility of constructivism, in Cognition, 48: 223 - 242, 1993, http://wexler.free.fr/library/files/quartz%20(1993)%20neural%20networks%2C%20nativism%2C%20and%20the%20plau sibility%20of%20constructivism.pdf.

Beyond modularity: Neural evidence for constructivist principles in development. R Steven, Terrence J Quartz, Sejnowski, Behavioral and Brain Sciences. 17Quartz and Sejnowski 1994[Quartz and Sejnowski 1994] Steven R. Quartz and Terrence J. Sejnowski, Beyond modularity: Neural evidence for construc- tivist principles in development, in Behavioral and Brain Sciences, 17: 725 -726, 1994.

The neural basis of cognitive development: A constructivist manifesto. R Steven, Terrence J Quartz, Sejnowski, Behavioral and Brain Sciences. 20and Sejnowski 1997] Steven R. Quartz and Terrence J. Sejnowski, The neural basis of cognitive development: A con- structivist manifesto, in Behavioral and Brain Sciences, 20: 537 -596, 1997, https://pdfs.semanticscholar.org/f61b/125715cdfda589109b6349cd7861ee6a00e2.pdf?_ga=2.265746383.1572644612.152 0000887-1848517411.1520000887.

Representation of the Gender of Human Faces by Infants: A Preference for Female. [ Quinn, Perception. 319[Quinn et al. 2002] P. C. Quinn, J. Yahr, A. Kuhn, A. M. Slater, and O. Pascalis, Representation of the Gender of Human Fac- es by Infants: A Preference for Female, in Perception, 31(9):1109-1121, 2002.

C Neil, Frank Rabinowitz, H Francis Perbet, Chiyuan Song, S M Zhang, Matthew Ali Eslami, Botvinick, Machine Theory of Mind. Rabinowitz et al. 2018. in arXiv[Rabinowitz et al. 2018] Neil C. Rabinowitz, Frank Perbet, H. Francis Song, Chiyuan Zhang, S.M. Ali Eslami, and Matthew Botvinick, Machine Theory of Mind, in arXiv, 2018, https://arxiv.org/abs/1802.07740.

Connectionist Modeling of Linguistic Quantifiers. [ Rajapakse, Artificial Neural Networks: Formal Models and Their Applications-ICANN 2005. W. Duch et al.BerlinSpringer-Verlag[Rajapakse et al. 2005] R. K. Rajapakse, A. Cangelosi, K. R. Coventry, S. Newstead, and A. Bacon, Connectionist Modeling of Linguistic Quantifiers, in Artificial Neural Networks: Formal Models and Their Applications-ICANN 2005, W. Duch et al. (eds.), 679-684, Berlin: Springer-Verlag, 2005.

The Surprise-Based Learning Algorithm. Nadeesha Ranasinghe, Wei-Min Shen, University Of Southern California, Information Sciences Institute -11thTechnical Report forand Shenand Shen 2008] Nadeesha Ranasinghe and Wei-Min Shen, The Surprise-Based Learning Algorithm, Technical Report for University Of Southern California, Information Sciences Institute -11th April 2008.

A Bayesian Model of Imitation in Infants and Robots. Ayn Rand, ; R P N Rao, A P Shon, A N Meltzoff, Imitation and Social Learning in Robots, Humans, and Animals: Behavioural, Social and Communicative Dimensions. C. L. Nehaniv and K. DautenhahnCambridge, UKCambridge University PressThe Objectivist[Rand 1967] Ayn Rand, Introduction to Objectivist Epistemology, in The Objectivist, 1967. [Rao et al. 2007] R. P. N. Rao, A. P. Shon, and A. N. Meltzoff, A Bayesian Model of Imitation in Infants and Robots, in Imita- tion and Social Learning in Robots, Humans, and Animals: Behavioural, Social and Communicative Dimensions, ed. C. L. Nehaniv and K. Dautenhahn, 217-247, Cambridge, UK: Cambridge University Press, 2007.

[ Rao, Continual Unsupervised Representation Learning, in arXiv. [Rao et al. 2019] Dushyant Rao, Francesco Visin, Andrei A. Rusu, Yee Whye Teh, Razvan Pascanu, and Raia Hadsell, Con- tinual Unsupervised Representation Learning, in arXiv, 2019, https://arxiv.org/abs/1910.14481.

Optimization as a model for few-shot learning. Sachin Ravi, Hugo Larochelle, International Conference on Learning Representations. Ravi and Larochelle 2017[Ravi and Larochelle 2017] Sachin Ravi and Hugo Larochelle, Optimization as a model for few-shot learning, in Internation- al Conference on Learning Representations, 2017, https://openreview.net/pdf?id=rJY0-Kcll.

The Short-Latency Dopamine Signal: A Role in Discovering Novel Actions?. P Redgrave, K Gurney, Nature Reviews Neuroscience. 712Redgrave and Gurney[Redgrave and Gurney 2006] P. Redgrave and K. Gurney, The Short-Latency Dopamine Signal: A Role in Discovering Novel Actions?, in Nature Reviews Neuroscience, 7(12): 967-975, 2006.

T Regier, The Human Semantic Potential: Spatial Language and Constrained Connectionism. Cambridge, MAMIT PressT. Regier, The Human Semantic Potential: Spatial Language and Constrained Connectionism, Cambridge, MA: MIT Press, 1996.

The Control of Perception and the Construction of Reality: Epistemological Aspects of the Feedback-Control System. John Richards, Glasersfeld Ernst Von, Dialectica. 33Richards and von Glasersfeld 1979[Richards and von Glasersfeld 1979] John Richards and Ernst von Glasersfeld, The Control of Perception and the Construc- tion of Reality: Epistemological Aspects of the Feedback-Control System, in Dialectica, 33(1): 37-58, 1979, http://www.vonglasersfeld.com/055.

Alexander Riegler, The Constructivist Challenge. 1Constructivist Foundations[Riegler 2005] Alexander Riegler, Editorial: The Constructivist Challenge, in Constructivist Foundations, 1(1): 1 -8, 2005, http://www.univie.ac.at/constructivism/journal/coretexts/riegler2005editorial.pdf.

Design Methodologies for Central Pattern Generators: An Application to Crawling Humanoids, paper presented at the Robotics: Science and Systems II. L Righetti, A J Ijspeert, Philadelphia, PAUniversity of PennsylvaniaRighetti and Ijspeert[Righetti and Ijspeert 2006a] L. Righetti and A. J. Ijspeert, Design Methodologies for Central Pattern Generators: An Appli- cation to Crawling Humanoids, paper presented at the Robotics: Science and Systems II, University of Pennsylvania, Phil- adelphia, PA, August 16-19, 2006.

Programmable Central Pattern Generators: An Application to Biped Locomotion Control. L Righetti, A J Ijspeert, IEEE International Conference on Robotics and Automation. New Yorkand Ijspeert. paper presented at theand Ijspeert 2006b] L. Righetti and A. J. Ijspeert, Programmable Central Pattern Generators: An Application to Bi- ped Locomotion Control, paper presented at the IEEE International Conference on Robotics and Automation, New York, 2006.

Continual Learning in Reinforcement Environments. B Mark, Ring, University of Texas at Austin dissertationMark B. Ring, Continual Learning in Reinforcement Environments, University of Texas at Austin dissertation, 1994, https://www.cs.utexas.edu/~ring/Ring-dissertation.pdf.

Recurrent Transition Hierarchies for Continual Learning: A general overview. AAAI Workshops at the Twenty-Fifth AAAI Conference on Artificial Intelligence. Ring 2011] Mark Ring[Ring 2011] Mark Ring, Recurrent Transition Hierarchies for Continual Learning: A general overview, in AAAI Workshops at the Twenty-Fifth AAAI Conference on Artificial Intelligence, 2011, https://www.aaai.org/ocs/index.php/WS/AAAIW11/paper/view/4002/4294.

The Two-Dimensional Organization of Behavior. Mark Ring, Tom Schaul, Juergen Schmidhuber, Proc. Joint IEEE International Conference on Development and Learning (ICDL) and on Epigenetic Robotics. Joint IEEE International Conference on Development and Learning (ICDL) and on Epigenetic RoboticsFrankfurtRing et al. 2011[Ring et al. 2011] Mark Ring, Tom Schaul, and Juergen Schmidhuber, The Two-Dimensional Organization of Behavior, in Proc. Joint IEEE International Conference on Development and Learning (ICDL) and on Epigenetic Robotics, Frankfurt, 2011, http://people.idsia.ch/~juergen/icdl2011mots.pdf.

Language within Our Grasp. G Rizzolatti, M A Arbib, Trends in Neurosciences. 215Rizzolatti and Arbib[Rizzolatti and Arbib 1998] G. Rizzolatti and M. A. Arbib, Language within Our Grasp, in Trends in Neurosciences, 21(5): 188-194, 1998.

The Mirror-Neuron System. G Rizzolatti, L Craighero, Annual Review of Neuroscience. 27Rizzolatti and Craighero[Rizzolatti and Craighero 2004] G. Rizzolatti and L. Craighero, The Mirror-Neuron System, in Annual Review of Neurosci- ence, 27: 169-192, 2004.

Neurophysiological Mechanisms Underlying the Understanding and Imitation of Action. [ Rizzolatti, Nature Reviews Neuroscience. 29[Rizzolatti et al. 2001] G. Rizzolatti, L. Fogassi, and V. Gallese, Neurophysiological Mechanisms Underlying the Under- standing and Imitation of Action, in Nature Reviews Neuroscience, 2(9): 661-670, 2001.

Who's in the Mirror? Self-Other Discrimination in Specular Images by Four-and Nine-Month-Old Infants. P Rochat ; P. Rochat, T Striano, Experimental Brain Research. 1231-2Child Development[Rochat 1998] P. Rochat, Self-Perception and Action in Infancy, in Experimental Brain Research, 123(1-2): 102-109, 1998. [Rochat and Striano 2002] P. Rochat and T. Striano, Who's in the Mirror? Self-Other Discrimination in Specular Images by Four-and Nine-Month-Old Infants, in Child Development, 73(1): 35-46, 2002.

Infants' Preferences for Familiarity and Novelty During the Course of Visual Processing. [ Roder, Infancy. 14[Roder et al. 2000] B. J. Roder, E. W. Bushnell, and A. M. Sasseville, Infants' Preferences for Familiarity and Novelty During the Course of Visual Processing, in Infancy, 1(4): 491-507, 2000.

[ Rodriguez, A Recurrent Neural Network That Learns to Count. 11Connection Science[Rodriguez et al. 1999] P. Rodriguez, J. Wiles, and J. L. Elman, A Recurrent Neural Network That Learns to Count, in Con- nection Science, 11(1)(May): 5-40, 1999.

From Babbling towards First Words: The Emergence of Speech in a Robot in Real-Time Interaction. Rothwell, Artificial Life (ALIFE) IEEE Symposium. Francepaper presented at theRothwell et al. 2011] A. Rothwell, C. Lyon, C. L. Nehaniv, and J. Saunders, From Babbling towards First Words: The Emer- gence of Speech in a Robot in Real-Time Interaction, paper presented at the Artificial Life (ALIFE) IEEE Symposium, Par- is, France, April 11-15, 2011.

Organization of Infant Memory. Sullivan ; C K Rovee-Collier, M W Rovee-Collier, Sullivan, Journal of Experimental Psychology Human Learning and Memory. 66Rovee-Collier and Sullivan 1980] C. K. Rovee-Collier and M. W. Sullivan, Organization of Infant Memory, in Journal of Experimental Psychology Human Learning and Memory, 6(6)(Nov.): 798-807, 1980.

Mental Imagery for a Conversational Robot. Roy, IEEE Transactions on Systems, Man, and Cybernetics. 34[Roy et al. 2004] D. Roy, K. Y. Hsiao, and N. Mavridis, Mental Imagery for a Conversational Robot, in IEEE Transactions on Systems, Man, and Cybernetics. Part B, Cybernetics, 34(3): 1374-1383, 2004.

An Embodied Developmental Robotic Model of Interactions between Numbers and Space, paper presented at the Expanding the Space of Cognitive Science: 23rd Annual Meeting of the. [ Rucinski, Cognitive Science Society. [Rucinski et al. 2011] M. Rucinski, A. Cangelosi, and T. Belpaeme, An Embodied Developmental Robotic Model of Interac- tions between Numbers and Space, paper presented at the Expanding the Space of Cognitive Science: 23rd Annual Meet- ing of the Cognitive Science Society, Boston, MA, July 20-23, 2011.

Robotic model of the contribution of gesture to learning to count. M Rucinski, A Cangelosi, T Belpaeme, 2012 IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL). IEEERucinski et al. 2012[Rucinski et al. 2012] M. Rucinski, A. Cangelosi, and T. Belpaeme, Robotic model of the contribution of gesture to learning to count, in 2012 IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL), pp. 1-6, IEEE, 2012.

The Child as Hacker. Joshua S Rule, Joshua B Tenenbaum, Steven T Piantadosi, Trends in Cognitive Sciences. 24Rule at al. 2020[Rule at al. 2020] Joshua S. Rule, Joshua B. Tenenbaum, and Steven T. Piantadosi, The Child as Hacker, in Trends in Cogni- tive Sciences, 24(11): 900-915, November 2020, https://www.sciencedirect.com/science/article/abs/pii/S1364661320301741.

The Representation of Knowledge in Memory. David E Rumelhart, Andrew Ortony, Schooling and the Acquisition of Knowledge. 99135Rumelhart and Ortony 1977[Rumelhart and Ortony 1977] David E. Rumelhart and Andrew Ortony, The Representation of Knowledge in Memory, in Schooling and the Acquisition of Knowledge, 99: 135, 1977.

. Stuart Russell, Peter Norvig, Artificial Intelligence: A Modern Approach. Prentice-HallRussell and Norvig[Russell and Norvig 1995] Stuart Russell and Peter Norvig, Artificial Intelligence: A Modern Approach, Upper Saddle River, NJ: Prentice-Hall, 1995.

. Andrei A Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu, Simon Osindero, Raia Hadsell, Meta-Learning with Latent Embedding Optimization, in arXiv. Rusu et al. 2018[Rusu et al. 2018] Andrei A. Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu, Simon Osindero, and Raia Hadsell, Meta-Learning with Latent Embedding Optimization, in arXiv, 2018, https://arxiv.org/pdf/1807.05960.pdf.

Intrinsic and Extrinsic Motivations: Classic Definitions and New Directions. R M Ryan, E L Deci, Contemporary Educational Psychology. 251Ryan and Deci[Ryan and Deci 2000] R. M. Ryan and E. L. Deci, Intrinsic and Extrinsic Motivations: Classic Definitions and New Direc- tions, in Contemporary Educational Psychology, 25(1): 54-67, 2000.

Self-Determination Theory and the Role of Basic Psychological Needs in Personality and the Organization of Behavior. R M Ryan, E L Deci, Handbook of Personality: Theory and Research. O. P. John, R. W. Robins, and L. A. PervinNew YorkGuilford PressRyan and Deci. 3rd ed.[Ryan and Deci 2008] R. M. Ryan and E. L. Deci, Self-Determination Theory and the Role of Basic Psychological Needs in Personality and the Organization of Behavior, in Handbook of Personality: Theory and Research, 3rd ed., ed. O. P. John, R. W. Robins, and L. A. Pervin, 654-678, New York: Guilford Press, 2008.

Word Segmentation: The Role of Distribu-tional Cues. Saffran, Journal of Memory and Language. 354[Saffran et al. 1996] J. R. Saffran, E. L. Newport, and R. N. Aslin, Word Segmentation: The Role of Distribu-tional Cues, in Journal of Memory and Language, 35(4)(Aug.): 606-621, 1996.

To Afford or Not to Afford: A New Formalization of Affordances toward Affordance-Based Robot Control. Sahin, Biologically Inspired Cognitive Architectures. V. Samsonovich et al.IOS Press15Toward a Unified Catalog of Implemented Cognitive Architectures[Sahin et al. 2007] E. Sahin, M. Cakmak, M. R. Dogar, E. Ugur, and G. Ucoluk, To Afford or Not to Afford: A New Formali- zation of Affordances toward Affordance-Based Robot Control, in Adaptive Behavior, 15(4): 447-472, 2007. [Samsonovich 2010] Alexei Samsonovich, Toward a Unified Catalog of Implemented Cognitive Architectures, in Biological- ly Inspired Cognitive Architectures, A. V. Samsonovich et al. (eds.), IOS Press, 2010.

They Call It Like They See It: Spontaneous Naming and Attention to Shape. L K Samuelson, L B Smith, Developmental Science. 82Samuelson and Smith[Samuelson and Smith 2005] L. K. Samuelson and L. B. Smith, They Call It Like They See It: Spontaneous Naming and At- tention to Shape, in Developmental Science, 8(2)(Mar.): 182-198, 2005.

Perception of Object Shape and Texture in Human Newborns: Evidence from Cross-Modal Transfer Tasks. C Sann, A Streri, Developmental Science. 103Sann and Streri[Sann and Streri 2007] C. Sann and A. Streri, Perception of Object Shape and Texture in Human Newborns: Evidence from Cross-Modal Transfer Tasks, in Developmental Science, 10(3)(May): 399-410, 2007.

[ Santoro, One-shot Learning with Memory-Augmented Neural Networks, in arXiv. [Santoro et al. 2016] Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy Lillicrap, One-shot Learning with Memory-Augmented Neural Networks, in arXiv, 2016, https://arxiv.org/pdf/1605.06065.pdf.

Editorial: Intrinsically Motivated Open-Ended Learning in Autonomous Robots. Vieri Giuliano, Pierre-Yves Santucci, Andrew Oudeyer, Gianluca Barto, Baldassarre, https:/www.frontiersin.org/articles/10.3389/fnbot.2019.00115/fullFrontiers in Neurorobotics. 13115Santucci et al. 2020[Santucci et al. 2020] Vieri Giuliano Santucci, Pierre-Yves Oudeyer, Andrew Barto, and Gianluca Baldassarre, Editorial: In- trinsically Motivated Open-Ended Learning in Autonomous Robots, in Frontiers in Neurorobotics, 13(115): 1-3, January 2020, https://www.frontiersin.org/articles/10.3389/fnbot.2019.00115/full.

Towards an Open-Source Social Middleware for Humanoid Robots, paper presented at the 11th IEEE. [ Sarabia, RAS International Conference on Humanoid Robots. Slovenia; BerlinSpringer-VerlagBiomimetic and Biohybrid Systems[Sarabia et al. 2011] M. Sarabia, R. Ros, and Y. Demiris, Towards an Open-Source Social Middleware for Humanoid Robots, paper presented at the 11th IEEE-RAS International Conference on Humanoid Robots, Slovenia, October 26-28, 2011. [Savastano and Nolfi 2012] P. Savastano and S. Nolfi, Incremental Learning in a 14 Dof Simulated iCub Robot: Modeling In- fant Reach/Grasp Development, in Biomimetic and Biohybrid Systems, ed. T. J. Prescott et al., 250-261, Berlin Springer- Verlag, 2012.

Daniel P Sawyer, Miguel Lázaro-Gredilla, Dileep George, A Model of Fast Concept Inference with Object-Factorized Cognitive Programs, in arXiv. Sawyer et al. 2020[Sawyer et al. 2020] Daniel P. Sawyer, Miguel Lázaro-Gredilla, and Dileep George, A Model of Fast Concept Inference with Object-Factorized Cognitive Programs, in arXiv, 2020, https://arxiv.org/abs/2002.04021.

Children Use Whole-Part Juxtaposition as a Pragmatic Cue to Word Meaning. M M Saylor, M A Sabbagh, D A Baldwin, Developmental Psychology. 386[Saylor et al. 2002] M. M. Saylor, M. A. Sabbagh, and D. A. Baldwin, Children Use Whole-Part Juxtaposition as a Pragmatic Cue to Word Meaning, in Developmental Psychology, 38(6): 993-1003, 2002.

Kant's Notion of a Transcendental Schema: The Constitution of Objective Knowledge Between Epistemology and Psychology. Lara Scaglia, Autonomous University of BarcelonaPhD ThesisScaglia[Scaglia 2018] Lara Scaglia, Kant's Notion of a Transcendental Schema: The Constitution of Objective Knowledge Between Epistemology and Psychology, PhD Thesis, Autonomous University of Barcelona, 2018, https://www.tdx.cat/bitstream/handle/10803/665656/lasc1de1.pdf?sequence=1&isAllowed=y.

B Scassellati, Imitation and Mechanisms of Joint Attention: A Developmental Structure for Building Social Skills on a Humanoid Robot. C. L. NehanivGermany; BerlinSpringer-VerlagHeidelberg[Scassellati 1999] B. Scassellati, Imitation and Mechanisms of Joint Attention: A Developmental Structure for Building So- cial Skills on a Humanoid Robot, in Computation for Metaphors, Analogy, and Agents, ed. C. L. Nehaniv, 176-195, Hei- delberg, Germany: Springer-Verlag Berlin, 1999.

Is Imitation Learning the Route to Humanoid Robots?. B Scassellati, ; S Schaal, Trends in Cognitive Sciences. 121Autonomous Robots[Scassellati 2002] B. Scassellati, Theory of Mind for a Humanoid Robot, in Autonomous Robots, 12(1): 13-24, 2002. [Schaal 1999] S. Schaal, Is Imitation Learning the Route to Humanoid Robots?," in Trends in Cognitive Sciences, 3(6): 233- 242, 1999.

C Roger, Robert P Schank, Abelson, Scripts, plans, and knowledge. 75IJCAI[Schank and Abelson 1975] Roger C. Schank and Robert P. Abelson, Scripts, plans, and knowledge, in IJCAI, 75: 151-157, 1975, https://home.mis.u-picardie.fr/~furst/docs/Schank_Abelson_Scripts_1975.pdf.

Better Generalization with Forecasts. Tom Schaul, Mark Ring, Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI). the International Joint Conference on Artificial Intelligence (IJCAI)Beijing, ChinaSchaul and Ring 2013[Schaul and Ring 2013] Tom Schaul and Mark Ring, Better Generalization with Forecasts, in Proceedings of the Internation- al Joint Conference on Artificial Intelligence (IJCAI), Beijing, China, 2013, http://www.ijcai.org/Proceedings/13/Papers/246.pdf.

. Tom Schaul and Juergen Schmidhuber, Metalearning, in Scholarpedia. 564650Schaul and Schmidhuber[Schaul and Schmidhuber 2010] Tom Schaul and Juergen Schmidhuber, Metalearning, in Scholarpedia, 5(6): 4650, 2010, http://www.scholarpedia.org/article/Metalearning.

Evolving Internal Reinforcers for an Intrinsically Motivated Reinforcement-Learning Robot. M Schembri, M Mirolli, G Baldassarre, IEEE 6th International Conference on Development and Learning. Londonpaper presented at the[Schembri et al. 2007] M. Schembri, M. Mirolli, and G. Baldassarre, Evolving Internal Reinforcers for an Intrinsically Moti- vated Reinforcement-Learning Robot, paper presented at the IEEE 6th International Conference on Development and Learning, London, July 11-13, 2007.

Computational Models of Development. Matthew Schlesinger, Encyclopedia of Infant and Early Childhood Development, Second Edition. A-F, ed. Janette B. BensonElsevier1Matthew Schlesinger, Computational Models of Development, in Encyclopedia of Infant and Early Childhood Development, Second Edition, Vol. 1: A-F, ed. Janette B. Benson, 337-346, Elsevier, 2020, https://books.google.com/books?hl=en&lr=&id=59LVDwAAQBAJ&oi=fnd&pg=PP1&ots=mTTiusF5i- &sig=xQcIQrFK7Efo_T0liFAMpHS6Nh4#v=onepage&q&f=false.

Infants' Developing Expectations of Possible and Impossible Tool-Use Events between Ages Eight and Twelve Months. M Schlesinger, J Langer, 10.1016/j.cogdev.2012.07.002Cognitive Development. McMurray 2012] Matthew Schlesinger and Bob McMurray22The past, present, and future of computational models of cognitive development[Schlesinger and Langer 1999] M. Schlesinger and J. Langer, Infants' Developing Expectations of Possible and Impossible Tool-Use Events between Ages Eight and Twelve Months, in Developmental Science, 2(2)(May): 195-205, 1999. [Schlesinger and McMurray 2012] Matthew Schlesinger and Bob McMurray, The past, present, and future of computational models of cognitive development, in Cognitive Development, 27: 326-348, 2012, https://doi.org/10.1016/j.cogdev.2012.07.002.

The agent-based approach: A new direction for computational models of development. Matthew Schlesinger, Domenico Parisi, Developmental Review. 211[Schlesinger and Parisi 2001] Matthew Schlesinger and Domenico Parisi, The agent-based approach: A new direction for computational models of development, in Developmental Review, 21(1): 121-146, 2001, https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1166&context=cs_faculty_pubs.

M Schlesinger, D Parisi, Connectionism in an Artificial Life Perspective: Simulating Motor, Cognitive, and Language Development. Neuroconstructivism, ed. D. Mareschal, S. Sirois, G. Westermann, and M. H. JohnsonOxford, UKOxford University Press[Schlesinger and Parisi 2007] M. Schlesinger and D. Parisi, Connectionism in an Artificial Life Perspective: Simulating Mo- tor, Cognitive, and Language Development, in Neuroconstructivism, ed. D. Mareschal, S. Sirois, G. Westermann, and M. H. Johnson, 129-158, Oxford, UK: Oxford University Press, 2007.

Learning to Reach by Constraining the Movement Search Space. M Schlesinger, D Parisi, J Langer, Developmental Science. 31[Schlesinger et al. 2000] M. Schlesinger, D. Parisi, and J. Langer, Learning to Reach by Constraining the Movement Search Space, in Developmental Science, 3(1)(Mar.): 67-80, 2000.

Simulating Infants' Gaze Patterns during the Development of Perceptual Completion, paper presented at the 7th International Workshop on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems. M Schlesinger, D Amso, S P Johnson, Piscataway, NJ[Schlesinger et al. 2007] M. Schlesinger, D. Amso, and S. P. Johnson, Simulating Infants' Gaze Patterns during the Develop- ment of Perceptual Completion, paper presented at the 7th International Workshop on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems, Piscataway, NJ, November 5-7, 2007.

Simulating the Role of Visual Selective Attention during the Development of Perceptual Completion. M Schlesinger, D Amso, S P Johnson, Developmental Science. 156[Schlesinger et al. 2012] M. Schlesinger, D. Amso, and S. P. Johnson, Simulating the Role of Visual Selective Attention dur- ing the Development of Perceptual Completion, in Developmental Science, 15(6)(Nov.): 739-752, 2012.

A possibility for implementing curiosity and boredom in model-building neural controllers, in From Animals to Animats: Proceedings of the First International Conference on Simulation of Adaptive Behavior. Cambridge, MAMIT Press[Schmidhuber 1991a] Juergen Schmidhuber, A possibility for implementing curiosity and boredom in model-building neural controllers, in From Animals to Animats: Proceedings of the First International Conference on Simulation of Adaptive Be- havior, 222-227, Cambridge, MA: MIT Press, 1991, ftp://ftp.idsia.ch/pub/juergen/curiositysab.pdf.

J Schmidhuber, Curious Model-Building Control-Systems, paper presented at the 1991 IEEE International Joint Conference on Neural Networks. Singapore[Schmidhuber 1991b] J. Schmidhuber, Curious Model-Building Control-Systems, paper presented at the 1991 IEEE Interna- tional Joint Conference on Neural Networks, Singapore, 1991.

Formal Theory of Creativity, Fun, and Intrinsic Motivation. 2Schmidhuber 2010] Juergen Schmidhuber[Schmidhuber 2010] Juergen Schmidhuber, Formal Theory of Creativity, Fun, and Intrinsic Motivation (1990-2010), in IEEE Transactions on Autonomous Mental Development, 2(3): 230 -247, 2010, https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.467.5494&rep=rep1&type=pdf.

PowerPlay: Training an Increasingly General Problem Solver by Continually Searching for the Simplest Still Unsolvable Problem. https:/www.frontiersin.org/articles/10.3389/fpsyg.2013.00313/fullFrontiers in Psychology. 4313Juergen Schmidhuber[Schmidhuber 2013] Juergen Schmidhuber, PowerPlay: Training an Increasingly General Problem Solver by Continually Searching for the Simplest Still Unsolvable Problem, in Frontiers in Psychology, 4(313), 2013, https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00313/full.

On Learning to Think: Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers and Recurrent Neural World Models, in arXiv. [Schmidhuber 2015] Juergen Schmidhuber, On Learning to Think: Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers and Recurrent Neural World Models, in arXiv, 2015, https://arxiv.org/pdf/1511.09249.pdf.

Falling Walls: The Past, Present and Future of Artificial Intelligence. Scientific American Blogs. [Schmidhuber 2017] Juergen Schmidhuber, Falling Walls: The Past, Present and Future of Artificial Intelligence, in Scientific American Blogs, Nov. 2, 2017, https://blogs.scientificamerican.com/observations/falling-walls-the-past-present-and- future-of-artificial-intelligence/.

Why Are Abstract Concepts Hard to Understand. Psychology of Word Meanings. P. J. SchwanenflugelErlbaum[Schwanenflugel 1991] P. J. Schwanenflugel (ed.), Why Are Abstract Concepts Hard to Understand. Psychology of Word Meanings, Hillsdale, NJ: Erlbaum, 1991.

On the Temporal Dynamics of Digit Comparison Processes. W Schwarz, F Stein, Journal of Experimental Psychology. Learning, Memory, and Cognition. 245[Schwarz and Stein 1998] W. Schwarz and F. Stein, On the Temporal Dynamics of Digit Comparison Processes, in Journal of Experimental Psychology. Learning, Memory, and Cognition, 24(5)(Sept.): 1275-1293, 1998.

Progress & Compress: A scalable framework for continual learning. Schwarz, [Schwarz et al. 2018] Jonathan Schwarz, Jelena Luketina, Wojciech M. Czarnecki, Agnieszka Grabska-Barwinska, Yee Whye Teh, Razvan Pascanu, and Raia Hadsell, Progress & Compress: A scalable framework for continual learning, in arXiv, 2018, https://arxiv.org/pdf/1805.06370.pdf.

Active Learning Literature Survey. 1648MadisonComputer Sciences ; University of WisconsinTechnical ReportSettles 2010] Burr Settles[Settles 2010] Burr Settles, Active Learning Literature Survey, Computer Sciences Technical Report 1648, University of Wis- consin, Madison, 2010, http://www.cs.northwestern.edu/~pardo/courses/mmml/papers/active_learning/active_learning_lit_survey_TR2010.pdf.

The Computational Neurobiology of Reaching and Pointing. R Shadmehr, S P Wise, MIT PressCambridge, MAShadmehr and Wise[Shadmehr and Wise 2004] R. Shadmehr and S. P. Wise, The Computational Neurobiology of Reaching and Pointing, Cam- bridge, MA: MIT Press, 2004.

On Becoming a Personal Scientist: Interactive Computer Programs for Developing Personal Models of the World. L G Mildred, Shaw, Centre for the Study of Human Learning, Brunel UniversityPhD thesisMildred L. G. Shaw, On Becoming a Personal Scientist: Interactive Computer Programs for Developing Per- sonal Models of the World, PhD thesis, Centre for the Study of Human Learning, Brunel University, 1978, https://bura.brunel.ac.uk/handle/2438/7408.

Learning from the Environment Based on Percepts and Actions. Wei-Min Shen, Carnegie Mellon UniversityPhD thesisWei-Min Shen, Learning from the Environment Based on Percepts and Actions, PhD thesis, Carnegie Mellon University, June 16, 1989.

Wei-Min Shen ; Wei-Min Shen, Autonomous Learning from the Environment. W. H. Freeman and CompanyWei-Min Shen, Autonomous Learning from the Environment, Computer Science Press, W. H. Freeman and Company, 1994, http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.419.7798. [Shen 1997] Wei-Min Shen, Active and Semi-Incremental Learning with Bordering Counterexamples, 1997, http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.52.9305&rep=rep1&type=pdf.

Ridge polynomial networks. Y Shin, J Ghosh, IEEE Transactions on Neural Networks. 6Shin and Ghosh[Shin and Ghosh 1995] Y. Shin and J. Ghosh, Ridge polynomial networks, in IEEE Transactions on Neural Networks, 6: 610-22, 1995.

Modeling cognitive development on balance scale phenomena. [ Shultz, Machine Learning. 16[Shultz et al. 1994] T. R. Shultz, D. Mareschal, and W. C. Schmidt, Modeling cognitive development on balance scale phe- nomena, in Machine Learning, 16: 57-86, 1994, http://ego.psych.mcgill.ca/perpg/fac/shultz/personal/Recent_Publications_files/balance94.pdf.

An Abstract to Concrete Shift in the Development of Biological Thought-the Insides Story. D J Simons, F C Keil, Cognition. 562Simons and Keil[Simons and Keil 1995] D. J. Simons and F. C. Keil, An Abstract to Concrete Shift in the Development of Biological Thought-the Insides Story, in Cognition, 56(2)(Aug.): 129-163, 1995.

Grounding semantic categories in behavioral interactions: Experiments with 100 objects. [ Sinapov, Robotics and Autonomous Systems. 62[Sinapov et al. 2014] Jivko Sinapov, Connor Schenck, Kerrick Staley, Vladimir Sukhoy, and Alexander Stoytchev, Grounding semantic categories in behavioral interactions: Experiments with 100 objects, in Robotics and Autonomous Systems, 62(5): 632 -645, May 2014, https://www.eecs.tufts.edu/~jsinapov/papers/Sinapov_RAS2014.pdf.

An Interacting Systems Model of Infant Habituation. S Sirois, D , Journal of Cognitive Neuroscience. 168Sirois and Mareschal[Sirois and Mareschal 2004] S. Sirois and D. Mareschal, An Interacting Systems Model of Infant Habituation, in Journal of Cognitive Neuroscience, 16(8): 1352-1362, 2004.

Newborn Infant's Perception of Partly Occluded Objects. Slater, Infant Behavior and Development. 19Slater et al. 1996] A. Slater, S. P. Johnson, E. Brown, and M. Badenoch, Newborn Infant's Perception of Partly Occluded Objects, in Infant Behavior and Development, 19(1): 145-148, 1996.

J B J Smeets, E Brenner, A New View on Grasping. 3Smeets and Brenner[Smeets and Brenner 1999] J. B. J. Smeets and E. Brenner, A New View on Grasping, in Motor Control, 3(3)(July): 237-271, 1999.

The Effects of Sociodramatic Play on Disadvantaged Preschool Children. S B Smilansky ; L, Smith, Developmental Review. 253-4WileyCognition as a Dynamic System: Principles from Embodiment[Smilansky 1968] S. Smilansky, The Effects of Sociodramatic Play on Disadvantaged Preschool Children, New York: Wiley, 1968. [Smith 2005] L. B. Smith, Cognition as a Dynamic System: Principles from Embodiment, in Developmental Review, 25(3- 4)(Sept.-Dec.): 278-298, 2005.

Principles of Object Perception. L B Smith, L K N Samuelson ; E, Sokolov, The Spatial Foundations of Language and Cognition: Thinking through. Space, K. S. Mix, L. B. Smith, and M. GasserOxford; Sokolov; New York; Madison, CTInternational Universities Press14Perception and the Conditioned Reflex. Spelke 1990] E. S. Spelke. Spitz 1957] R. A. Spitz, No and Yes: On the Genesis of Human Communicationand Samuelson 2010] L. B. Smith and L. K. Samuelson, Objects in Space and Mind: From Reaching to Words, in The Spatial Foundations of Language and Cognition: Thinking through Space, K. S. Mix, L. B. Smith, and M. Gasser (eds.), 188-207, Oxford: Oxford University Press, 2010. [Sokolov 1963] E. N. Sokolov, Perception and the Conditioned Reflex, New York: Pergamon, 1963. [Spelke 1990] E. S. Spelke, Principles of Object Perception, in Cognitive Science, 14(1): 29-56, 1990. [Spitz 1957] R. A. Spitz, No and Yes: On the Genesis of Human Communication, Madison, CT: International Universities Press, 1957.

Solving Bernstein Problem-a Proposal for the Development of Coordinated Movement by Selection. O Sporns, G M Edelman, Child Development. 644and Edelman 1993] O. Sporns and G. M. Edelman, Solving Bernstein Problem-a Proposal for the Development of Coordinated Movement by Selection, in Child Development, 64(4)(Aug.): 960-981, 1993.

A Basic Emergent Grammar for Space. M Spranger, Experiments in Cultural Language Evolution, L. Steels. AmsterdamJohn Benjamins[Spranger 2012a] M. Spranger, A Basic Emergent Grammar for Space, in Experiments in Cultural Language Evolution, L. Steels (ed.), 207-232, Amsterdam: John Benjamins, 2012.

The Co-evolution of Basic Spatial Terms and Categories. M Spranger, Experiments in Cultural Language Evolution. L. SteelsAmsterdamJohn Benjamins[Spranger 2012b] M. Spranger, The Co-evolution of Basic Spatial Terms and Categories, in Experiments in Cultural Lan- guage Evolution, L. Steels (ed.), 111-141, Amsterdam: John Benjamins, 2012.

An image schema language. St, Amant, International Conference on Cognitive Modeling. St. Amant et al. 2006] Robert St. Amant, Clayton T. Morrison, Yu-Han Chang, Paul R. Cohen, and Carole R. Beal, An image schema language, in International Conference on Cognitive Modeling, 634-640, 2006, https://pdfs.semanticscholar.org/1334/04573f2e93739d17037f7f54eaf91fa7a71f.pdf.

Perception of Numbers by Human Infants. P Starkey, R G Cooper, Science. 2104473Starkey and Cooper[Starkey and Cooper 1980] P. Starkey and R. G. Cooper, Perception of Numbers by Human Infants, in Science, 210(4473): 1033-1035, 1980.

The Development of Subitizing in Young-Children. P Starkey, R G Cooper, British Journal of Developmental Psychology. 13Starkey and Cooper[Starkey and Cooper 1995] P. Starkey and R. G. Cooper, The Development of Subitizing in Young-Children, in British Jour- nal of Developmental Psychology, 13(Nov.): 399-420, 1995.

A (Very) Brief Introduction to Fluid Construction Grammar. L Steels, Proceedings of the Third Workshop on Scalable Natural Language Understanding. L. Steels and J. de Beulethe Third Workshop on Scalable Natural Language UnderstandingAmsterdam; Amsterdam; Stroudsburg, PAJohn Benjamins7Association for Computational Linguistics[Steels 2003] L. Steels, Evolving Grounded Communication for Robots, in Trends in Cognitive Sciences, 7(7)(July): 308- 312, 2003. [Steels 2011] L. Steels (ed.), Design Patterns in Fluid Construction Grammar, Vol. 11, Amsterdam: John Benjamins, 2011. [Steels 2012] L. Steels (ed), Experiments in Cultural Language Evolution, Vol. 3, Amsterdam: John Benjamins, 2012. [Steels and de Beule 2006] L. Steels and J. de Beule, A (Very) Brief Introduction to Fluid Construction Grammar, in Proceed- ings of the Third Workshop on Scalable Natural Language Understanding, 73-80, Stroudsburg, PA: Association for Com- putational Linguistics, 2006.

Aibos First Words: The Social Learning of Language and Meaning. L Steels, F Kaplan, Evolution of Communication. 4and Kaplan 2002] L. Steels and F. Kaplan, Aibos First Words: The Social Learning of Language and Meaning, in Evo- lution of Communication, 4(1): 3-32, 2002.

From Pixels to Policies: A Bootstrapping Agent. Jeremy Stober, Benjamin Kuipers, 7th IEEE International Conference on Development and Learning. and Kuipers 2008] Jeremy Stober and Benjamin Kuipers, From Pixels to Policies: A Bootstrapping Agent, in 2008 7th IEEE International Conference on Development and Learning: 103-108, 2008.

Petitagé: A case study in developmental robotics. Stojanov ] Georgi, Proceedings of the 1st International Workshop on Epigenetic Robotics. the 1st International Workshop on Epigenetic RoboticsLund, Sweden85Lund University Cognitive StudiesStojanov[Stojanov 2001] Georgi Stojanov, Petitagé: A case study in developmental robotics, in Proceedings of the 1st International Workshop on Epigenetic Robotics, Lund University Cognitive Studies, 85, Lund, Sweden, 2001, https://pdfs.semanticscholar.org/337f/3d4eb37f079016c7e2bf3ac9a947d01971d0.pdf.

History of Usage of Piaget's Theory of Cognitive Development in AI and Robotics: a Look Backwards for a Step Forwards. Stojanov ] Georgi, [Stojanov 2009] Georgi Stojanov, History of Usage of Piaget's Theory of Cognitive Development in AI and Robotics: a Look Backwards for a Step Forwards, 2009, https://www.researchgate.net/publication/234112233_History_of_Usage_of_Piaget's_Theory_of_Cognitive_Development _in_AI_and_Robotics_a_Look_Backwards_for_a_Step_Forwards and http://ac.aup.fr/~gstojanov/References_Stojanov_Epirob2009.pdf.

Creativity and Cognitive Development: The Role of Perceptual Similarity and Analogy. Georgi Stojanov, Bipin Indurkhya, Creativity and (Early) Cognitive Development: Papers from the AAAI Spring Symposium. Stojanov and Indurkhya 2013[Stojanov and Indurkhya 2013] Georgi Stojanov and Bipin Indurkhya, Creativity and Cognitive Development: The Role of Perceptual Similarity and Analogy, in Creativity and (Early) Cognitive Development: Papers from the AAAI Spring Sym- posium, 2013, https://pdfs.semanticscholar.org/3333/8a26be36f0b4015336e3cabb884520aadbbd.pdf.

Interactionist-expectative view on agency and learning. [ Stojanov, Mathematics and Computers in Simulation. 443[Stojanov et al. 1997] Georgi Stojanov, Stevo Bozinovski, and Goran Trajkovski, Interactionist-expectative view on agency and learning, in Mathematics and Computers in Simulation, 44(3): 295 -310, 1997.

Layered Learning. Peter Stone, Manuela Veloso, 17th International Conference on Machine Learning. Ramon Lopez de Mantaras and Enric PlazaSpringer Verlagand Veloso 2000] Peter Stone and Manuela Veloso, Layered Learning, in 17th International Conference on Machine Learning, Ramon Lopez de Mantaras and Enric Plaza (eds.), 369-381, Springer Verlag, May/June 2000, https://pdfs.semanticscholar.org/3c81/a9c6deed924ef1598046ee92805edac4b107.pdf.

[ Stone, arXiv:1706.04313v1Teaching Compositionality to CNNs, in arXiv. [Stone et al. 2017] Austin Stone, Huayan Wang, Michael Stark, Yi Liu, D. Scott Phoenix, and Dileep George, Teaching Com- positionality to CNNs, in arXiv, arXiv:1706.04313v1, 2017, https://arxiv.org/pdf/1706.04313.pdf.

Behavior-Grounded Representation of Tool Affordances. A Stoytchev, 2005 IEEE International Conference on Robotics and Automation. New Yorkpaper presented at the[Stoytchev 2005] A. Stoytchev, Behavior-Grounded Representation of Tool Affordances, paper presented at the 2005 IEEE International Conference on Robotics and Automation, New York, 2005.

Robot Tool Behavior: A Developmental Approach To Autonomous Tool Use, PhD thesis, College of Computing, Georgia Institute of Technology. Alexander Stoytchev, [Stoytchev 2007] Alexander Stoytchev, Robot Tool Behavior: A Developmental Approach To Autonomous Tool Use, PhD the- sis, College of Computing, Georgia Institute of Technology, 2007, https://pdfs.semanticscholar.org/35c7/161a17c3ea82ebfdfaa6cfeded55f67bc176.pdf.

Learning the Affordances of Tools Using a Behavior-Grounded Approach, in Towards Affordance-Based Robot Control. A Stoytchev, Self-Detection in Robots: A Method Based on Detecting Temporal Contingencies, in Robotica. E. Rome, J. Hertzberg, and G. Dorffner29Springer-VerlagStoytchev 2011] A. Stoytchev[Stoytchev 2008] A. Stoytchev, Learning the Affordances of Tools Using a Behavior-Grounded Approach, in Towards Af- fordance-Based Robot Control, E. Rome, J. Hertzberg, and G. Dorffner (eds.), 140-158, Berlin: Springer-Verlag, 2008. [Stoytchev 2011] A. Stoytchev, Self-Detection in Robots: A Method Based on Detecting Temporal Contingencies, in Robot- ica, 29(Jan.): 1-21, 2011.

The Grounding of Higher Order Concepts in Action and Language: A Cognitive Robotics Model. F Stramandinoli, D Marocco, A Cangelosi, Neural Networks. 32Stramandinoli et al. 2012[Stramandinoli et al. 2012] F. Stramandinoli, D. Marocco, and A. Cangelosi, The Grounding of Higher Order Concepts in Ac- tion and Language: A Cognitive Robotics Model, in Neural Networks, 32(Aug.): 165-173, 2012.

Making sense of words: a robotic model for language abstraction. [ Stramandinoli, Auton Robot. 41[Stramandinoli et al. 2017] F. Stramandinoli, D. Marocco, and A. Cangelosi, Making sense of words: a robotic model for lan- guage abstraction, in Auton Robot, 41: 367-383, 2017.

Unsupervised Body Scheme Learning through Self-Perception. [ Sturm, Learning Semantic Combinatoriality from the Interaction between Linguistic and Behavioral Processes. New York13IEEE International Conference on Robotics and Automation (ICRA)[Sturm et al. 2008] J. Sturm, C. Plagemann, and W. Burgard, Unsupervised Body Scheme Learning through Self-Perception, paper presented at the IEEE International Conference on Robotics and Automation (ICRA), New York, 2008. [Sugita and Tani 2005] Y. Sugita and J. Tani, Learning Semantic Combinatoriality from the Interaction between Linguistic and Behavioral Processes, in Adaptive Behavior, 13(1): 33-52, 2005.

The Importance of Cognitive Architectures: An Analysis Based on Clarion. R Sun, Journal of Experimental & Theoretical Artificial Intelligence. 192R. Sun, The Importance of Cognitive Architectures: An Analysis Based on Clarion, in Journal of Experimental & Theoretical Artificial Intelligence, 19(2)(June): 159-193, 2007.

Top-down versus bottom-up learning in cognitive skill acquisition. Ron Sun, Xi Zhang, Cognitive Systems Research. 5and Zhang 2004] Ron Sun and Xi Zhang, Top-down versus bottom-up learning in cognitive skill acquisition, in Cogni- tive Systems Research, 5(1): 63-89, 2004.

From Implicit Skills to Explicit Knowledge: A Bottom-up Model of Skill Learning. R Sun, E Merrill, T Peterson, Cognitive Science. 252Sun et al. 2001[Sun et al. 2001] R. Sun, E. Merrill, and T. Peterson, From Implicit Skills to Explicit Knowledge: A Bottom-up Model of Skill Learning, in Cognitive Science, 25(2)(Mar.-Apr.): 203-244, 2001.

Learning to predict by the methods of temporal differences. Richard S Sutton, https:/link.springer.com/content/pdf/10.1007/BF00115009.pdfMachine Learning. Sutton3[Sutton 1988] Richard S. Sutton, Learning to predict by the methods of temporal differences, in Machine Learning, 3(1): 9- 44, 1988, https://link.springer.com/content/pdf/10.1007/BF00115009.pdf.

Richard S Sutton, Reinforcement Learning: Past, Present, and Future, extended abstract in Simulated Evolution and Learning. B. McKay, X. Yao, C. S. Newton, J.-H. Kim, and T. FuruhashiSuttonSpringerpublished as Lecture Notes in Computer Science 1585[Sutton 1999] Richard S. Sutton, Reinforcement Learning: Past, Present, and Future, extended abstract in Simulated Evolu- tion and Learning, B. McKay, X. Yao, C. S. Newton, J.-H. Kim, and T. Furuhashi (eds.), published as Lecture Notes in Computer Science 1585, pp. 195-197, Springer, 1999, http://incompleteideas.net/papers/sutton-99b.pdf.

The grand challenge of predictive empirical abstract knowledge. Richard S Sutton, from Working Notes of the IJCAI-09 Workshop on Grand Challenges for Reasoning from Experiences. Sutton[Sutton 2009] Richard S. Sutton, The grand challenge of predictive empirical abstract knowledge, from Working Notes of the IJCAI-09 Workshop on Grand Challenges for Reasoning from Experiences, 2009, http://incompleteideas.net/papers/sutton09.pdf.

The Problem of Knowledge and Data. Richard S Sutton, Beyond Reward, Inductive Logic Programming. S. H. Muggleton, A. Tamaddoni-Nezhad, and F. A. LisiBerlin, HeidelbergSpringer7207Richard S. Sutton, Beyond Reward: The Problem of Knowledge and Data, in Inductive Logic Programming, ILP 2011, Lecture Notes in Computer Science, S. H. Muggleton, A. Tamaddoni-Nezhad, and F. A. Lisi (eds.), vol. 7207, Springer, Berlin, Heidelberg, 2012, https://pdfs.semanticscholar.org/ff01/08d7d8c95303ee1fcbfb840b70f2bd8c67ee.pdf.

Richard S Sutton, True online Emphatic TD(λ): Quick Reference and Implementation Guide. Sutton[Sutton 2015] Richard S. Sutton, True online Emphatic TD(λ): Quick Reference and Implementation Guide, arXiv, 2015, https://arxiv.org/pdf/1507.07147.pdf.

Reinforcement Learning: An Introduction, Second Edition. Richard S Sutton, Andrew G Barto, The MIT PressSutton and Barto[Sutton and Barto 2018] Richard S. Sutton and Andrew G. Barto, Reinforcement Learning: An Introduction, Second Edition, The MIT Press, 2018, http://incompleteideas.net/book/the-book-2nd.html.

Between MDPs and semi-MDPs: a framework for temporal abstraction in reinforcement learning. Sutton, Artificial Intelligence. 1121-2[Sutton et al. 1999] Richard S. Sutton, Doina Precup, and Satinder Singh, Between MDPs and semi-MDPs: a framework for temporal abstraction in reinforcement learning, in Artificial Intelligence, 112(1-2): 181 -211, 1999, http://www- anw.cs.umass.edu/~barto/courses/cs687/Sutton-Precup-Singh-AIJ99.pdf.

Horde: A scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction. Sutton, Proc. of 10th Int. Conf. on Autonomous Agents and Multiagent Systems (AAMAS 2011. Tumer, Yolum, Sonenberg and Stoneof 10th Int. Conf. on Autonomous Agents and Multiagent Systems (AAMAS 2011Taipei, Taiwan[Sutton et al. 2011] Richard S. Sutton, Joseph Modayil, Michael Delp, Thomas Degris, Patrick M. Pilarski, Adam White, and Doina Precup, Horde: A scalable real-time architecture for learning knowledge from unsupervised sensorimotor interac- tion, in Proc. of 10th Int. Conf. on Autonomous Agents and Multiagent Systems (AAMAS 2011), 761 -768, Tumer, Yolum, Sonenberg and Stone (eds.), May 2 -6, 2011, Taipei, Taiwan, https://www.cs.swarthmore.edu/~meeden/DevelopmentalRobotics/horde1.pdf.

Nonlinear Dynamics of Human Locomotion: From Real-Time Adaptation to Development. G Taga, Adaptive Motion of Animals and Machines. H. Kimura, K. Tsuchiya, A. Ishiguro, and H. WitteTokyoSpringer-Verlag[Taga 2006] G. Taga, Nonlinear Dynamics of Human Locomotion: From Real-Time Adaptation to Development, in Adaptive Motion of Animals and Machines, H. Kimura, K. Tsuchiya, A. Ishiguro, and H. Witte (eds.), 189-204, Tokyo: Springer- Verlag, 2006.

The Oxford Handbook of Language Evolution. M Tallerman, K R Gibson, Oxford University PressOxford, UKand Gibson 2012] M. Tallerman and K. R. Gibson, The Oxford Handbook of Language Evolution, Oxford, UK: Oxford University Press, 2012.

Learning to Generate Articulated Behavior through the Bottom-Up and the Top-Down Interaction Processes. J Tani, Neural Networks. Tani16[Tani 2003] J. Tani, Learning to Generate Articulated Behavior through the Bottom-Up and the Top-Down Interaction Pro- cesses, in Neural Networks, 16(1): 11-23, 2003.

Kinect Hackers Are Changing the Future of Robotics, in Wired Magazine. J Tanz, J. Tanz, Kinect Hackers Are Changing the Future of Robotics, in Wired Magazine, June 28, 2011, http://www.wired.com/2011/06/mf_kinect.

Unsupervised Detection of Words-Questioning the Relevance of Segmentation, paper presented at ITRW on Speech Analysis and Processing for Knowledge Discovery Workshop. Tapus, IEEE Robotics & Automation Magazine. 141Socially Assistive Robotics-the Grand Challenges in Helping Humans through Social Interaction[Tapus et al. 2007] A. Tapus, M. J. Matarić, and B. Scassellati, Socially Assistive Robotics-the Grand Challenges in Helping Humans through Social Interaction, in IEEE Robotics & Automation Magazine, 14(1)(Mar.): 35-42, 2007. [ten Bosch and Boves 2008] L. ten Bosch and L. Boves, Unsupervised Detection of Words-Questioning the Relevance of Segmentation, paper presented at ITRW on Speech Analysis and Processing for Knowledge Discovery Workshop, Aalborg, Denmark, June 4-6, 2008.

A Bayesian Framework for Concept Learning. Joshua B Tenenbaum, MITPhD thesisJoshua B. Tenenbaum, A Bayesian Framework for Concept Learning, PhD thesis, MIT, 1999, https://dspace.mit.edu/bitstream/handle/1721.1/16714/42471842-MIT.pdf.

Tenenbaum, 3/11/11How to Grow a Mind: Statistics, Structure, and Abstraction. [Tenenbaum et al. 2011] Joshua B. Tenenbaum, Charles Kemp, Thomas L. Griffiths, and Noah D. Goodman, How to Grow a Mind: Statistics, Structure, and Abstraction, in Science, 3/11/11, http://courses.csail.mit.edu/6.803/pdf/tenenbaum2011.pdf.

E Thelen, Treadmill-Elicited Stepping in 7-Month-Old Infants. 57[Thelen 1986] E. Thelen, Treadmill-Elicited Stepping in 7-Month-Old Infants, in Child Development, 57(6)(Dec.): 1498- 1506, 1986.

Hidden Skills: A Dynamic Systems Analysis of Treadmill Stepping during the First Year, in Monographs of the Society for Research in Child Development. E Thelen, B D Ulrich ; E. Thelen, B D Ulrich, D L Niles ; A, M Thomaz, C Berlin, Breazeal, 2005 IEEE International Workshop on Robot and Human Interactive Communication. New York56Bilateral Coordination in Human Infants-Stepping on a Split-Belt Treadmill[Thelen and Ulrich 1991] E. Thelen and B. D. Ulrich, Hidden Skills: A Dynamic Systems Analysis of Treadmill Stepping during the First Year, in Monographs of the Society for Research in Child Development, 56(1)(1991): 1-98, 1991. [Thelen et al. 1987] E. Thelen, B. D. Ulrich, and D. Niles, Bilateral Coordination in Human Infants-Stepping on a Split-Belt Treadmill, in Journal of Experimental Psychology Human Perception and Performance, 13(3)(Aug.): 405-410, 1987. [Thomaz et al. 2005] A. L. Thomaz, M. Berlin, and C. Breazeal, An Embodied Computational Model of Social Referencing, paper presented at the 2005 IEEE International Workshop on Robot and Human Interactive Communication, New York, 2005.

Understanding Human Development. R Kristinn, ; S Thorisson, Tom M Thornton ; Sebastian Thrun, Mitchell, New Constructivist AI: From Manual Methods to Self-Constructive Systems. Pei Wang and Ben GoertzelThornton; Basingstoke, UKPalgrave Macmillan15Robotics and Autonomous Systems[Thorisson 2012] Kristinn R. Thorisson, Chapter 9: A New Constructivist AI: From Manual Methods to Self-Constructive Systems, in Theoretical Foundations of Artificial General Intelligence, Pei Wang and Ben Goertzel (eds.), 141 -177, At- lantis Press, 2012, http://alumni.media.mit.edu/~kris/ftp/Thorisson_chapt9_TFofAGI_Wang_Goertzel_2012.pdf. [Thornton 2008] S. Thornton, Understanding Human Development, Basingstoke, UK: Palgrave Macmillan, 2008. [Thrun and Mitchell 1995] Sebastian Thrun and Tom M. Mitchell, Lifelong robot learning, in Robotics and Autonomous Sys- tems, 15: 25 -46, 1995, http://robots.stanford.edu/papers/thrun.lifelong-learning.ps.gz.

Learning To Learn. Sebastian Thrun and Lorien Y. PrattBoston, MAKluwer Academic PublishersThrun and Pratt[Thrun and Pratt 1998] Sebastian Thrun and Lorien Y. Pratt (eds.), Learning To Learn, Boston, MA: Kluwer Academic Pub- lishers, 1998.

Scaling up of Action Repertoire in Linguistic Cognitive Agents. [ Tikhanoff, International Conference on Integration of Knowledge Intensive Multi-Agent Systems. New Yorkpaper presented at the[Tikhanoff et al. 2007] V. Tikhanoff, A. Cangelosi, J. F. Fontanari, and L. I. Perlovsky, Scaling up of Action Repertoire in Linguistic Cognitive Agents, paper presented at the International Conference on Integration of Knowledge Intensive Mul- ti-Agent Systems, New York, 2007.

Integration of Speech and Action in Humanoid Robots: iCub Simulation Experiments. [ Tikhanoff, IEEE Transactions on Autonomous Mental Development. 311932The Century CoPurposive Behavior in Animals and Men. Century Psychology Series[Tikhanoff et al. 2011] V. Tikhanoff, A. Cangelosi, and G. Metta, Integration of Speech and Action in Humanoid Robots: iCub Simulation Experiments, in IEEE Transactions on Autonomous Mental Development, 3(1): 17-29, 2011. [Tolman 1932] E. C. Tolman, Purposive Behavior in Animals and Men, New York: The Century Co. (Century Psychology Se- ries), 1932.

Constructing a Language: A Usage-Based Theory of Language Acquisition. E C Tolman, ; M Tomasello, ; M Tomasello, ; M Tomasello, ; M Tomasello, ; M Tomasello, P J Brooks, Early Syntactic Development: A Construction Grammar Approach. Cambridge, UK; Cambridge, MA; Cambridge, MA; Cambridge, MA; New YorkPsychology Press55Cognitive Maps in Rats and Men[Tolman 1948] E. C. Tolman, Cognitive Maps in Rats and Men, in Psychological Review, 55: 189-208, 1948. [Tomasello 1992] M. Tomasello, First Verbs: A Case Study of Early Grammatical Development, Cambridge, UK: Cambridge University Press, 1992. [Tomasello 2003] M. Tomasello, Constructing a Language: A Usage-Based Theory of Language Acquisition, Cambridge, MA: Harvard University Press, 2003. [Tomasello 2008] M. Tomasello, Origins of Human Communication, Cambridge, MA: MIT Press, 2008. [Tomasello 2009] M. Tomasello, Why We Cooperate, Cambridge, MA: MIT Press, 2009. [Tomasello and Brooks 1999] M. Tomasello and P. J. Brooks, Early Syntactic Development: A Construction Grammar Ap- proach, New York: Psychology Press, 1999.

Understanding and Sharing Intentions: The Origins of Cultural Cognition. [ Tomasello, Behavioral and Brain Sciences. 285[Tomasello et al. 2005] M. Tomasello, M. Carpenter, J. Call, T. Behne, and H. Moll, Understanding and Sharing Intentions: The Origins of Cultural Cognition, in Behavioral and Brain Sciences, 28(5)(Oct.): 675-691, 2005.

A New Look at Infant Pointing, in Child Development. [ Tomasello, 78May-June[Tomasello et al. 2007] M. Tomasello, M. Carpenter, and U. Liszkowski, A New Look at Infant Pointing, in Child Develop- ment, 78(3)(May-June): 705-722, 2007.

With or Beyond Piaget? A Dialogue between New Probabilistic Models of Learning and the Theories of Jean Piaget. 59Tourman 2016] Claire Tourmen[Tourman 2016] Claire Tourmen, With or Beyond Piaget? A Dialogue between New Probabilistic Models of Learning and the Theories of Jean Piaget, in Human Development, 59: 4 -25, 2016, https://www.karger.com/Article/Abstract/446670.

Growth of Visuomotor Coordination in Infants. C Trevarthen, Journal of Human Movement Studies. 157[Trevarthen 1975] C. Trevarthen, Growth of Visuomotor Coordination in Infants, in Journal of Human Movement Studies, 1: 57, 1975.

[ Triesch, Gaze Following: Why (Not) Learn It?, in Developmental Science. 9[Triesch et al. 2006] J. Triesch, C. Teuscher, G. O. Deák, and E. Carlson, Gaze Following: Why (Not) Learn It?, in Develop- mental Science, 9(2): 125-147, 2006.

An Experiment on the Evolution of Compositional Semantics and Behaviour Generalisation in Artificial Agents, in Special issue on. [ Tuci, Turing 1950] Alan M. Turing, Computing machinery and intelligence. 3Mind[Tuci et al. 2010] E. Tuci, T. Ferrauto, A. Zeschel, G. Massera, and S. Nolfi, An Experiment on the Evolution of Composi- tional Semantics and Behaviour Generalisation in Artificial Agents, in Special issue on "Grounding Language in Action." IEEE Transactions on Autonomous Mental Development, 3(2): 1-14, 2010. [Turing 1950] Alan M. Turing, Computing machinery and intelligence, in Mind, 59: 433 -460, 1950, https://www.csee.umbc.edu/courses/471/papers/turing.pdf.

The Learning and Use of Traversability Affordance Using Range Images on a Mobile Robot. A Ude, C G Atkeson, ; E Ugur, M R Dogar, M Cakmak, E Sahin, IEEE International Conference on Robotics and Automation (ICRA). New York17Advanced Robotics[Ude and Atkeson 2003] A. Ude and C. G. Atkeson, Online Tracking and Mimicking of Human Movements by a Humanoid Robot, in Advanced Robotics, 17(2): 165-178, 2003. [Ugur et al. 2007] E. Ugur, M. R. Dogar, M. Cakmak, and E. Sahin, The Learning and Use of Traversability Affordance Us- ing Range Images on a Mobile Robot, paper presented at the 2007 IEEE International Conference on Robotics and Auto- mation (ICRA), New York, 2007.

Bayesian Models of Conceptual Development: Learning as Building Models of the World, preprint submitted to Annual Review of Developmental Psychology. D Tomer, Joshua B Ullman, Tenenbaum, and Tenenbaum 2020and Tenenbaum 2020] Tomer D. Ullman and Joshua B. Tenenbaum, Bayesian Models of Conceptual Development: Learning as Building Models of the World, preprint submitted to Annual Review of Developmental Psychology, 2020, https://psyarxiv.com/aq3rp/download?format=pdf.

Many-Layered Learning. Paul E Utgoff, David J Stracuzzi, Neural Computation. 14[Utgoff and Stracuzzi 2002] Paul E. Utgoff and David J. Stracuzzi, Many-Layered Learning, in Neural Computation, 14: 2497 -2539, 2002, https://people.cs.umass.edu/~utgoff/papers/neco-stl.pdf.

Face Preference at Birth. [ Valenza, Journal of Experimental Psychology Human Perception and Performance. 224[Valenza et al. 1996] E. Valenza, F. Simion, V. M. Cassia, and C. Umilta, Face Preference at Birth, in Journal of Experimental Psychology Human Perception and Performance, 22(4)(Aug.): 892-903, 1996.

Off-policy TD(λ) with a true online equivalence. Van Hassselt, Proceedings of the 30th Conference on Uncertainty in Artificial Intelligence. the 30th Conference on Uncertainty in Artificial IntelligenceQuebec City, Canada[van Hassselt et al. 2014] Hado van Hasselt, A. Rupam Mahmood, and Richard S. Sutton, Off-policy TD(λ) with a true online equivalence, in Proceedings of the 30th Conference on Uncertainty in Artificial Intelligence, Quebec City, Canada, 2014, http://incompleteideas.net/papers/vHMS-UAI-2014.pdf.

Affordances, Perceptual Complexity, and the Development of Tool Use. Leeuwen, Journal of Experimental Psychology Human Perception and Performance. 201Leeuwen, et al.1994] L. van Leeuwen, A. Smitsman, and C. van Leeuwen, Affordances, Perceptual Complexity, and the Development of Tool Use, in Journal of Experimental Psychology Human Perception and Performance, 20(1): 174-191, 1994.

True online TD(λ). Sutton ; Harm Seijen, Richard S Van Seijen, Sutton, Proceedings of the 31st International Conference on Machine Learning. the 31st International Conference on Machine LearningBeijing, ChinaSeijen and Sutton 2014] Harm van Seijen and Richard S. Sutton, True online TD(λ), in Proceedings of the 31st Interna- tional Conference on Machine Learning, Beijing, China., 2014, http://incompleteideas.net/papers/vSS-trueonline-ICML- 2014-corrected.pdf.

Relational neural expectation maximization: Unsupervised discovery of objects and their interactions. Steenkiste, in arXivSteenkiste et al. 2018] Sjoerd Van Steenkiste, Michael Chang, Klaus Greff, and Jürgen Schmidhuber, Relational neural expectation maximization: Unsupervised discovery of objects and their interactions, in arXiv, https://arxiv.org/pdf/1802.10353.pdf.

Vaniver, Behavior: The Control of Perception, on LessWrong website. [Vaniver 2015] Vaniver, Behavior: The Control of Perception, on LessWrong website, Jan. 20, 2015, https://www.lesswrong.com/posts/nPs63hpijnQs37jme/behavior-the-control-of-perception.

Crossprop: Learning Representations by Stochastic Meta-Gradient Descent in Neural Networks. [ Veeriah, European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD. [Veeriah et al. 2017] Vivek Veeriah, Shangtong Zhang, and Richard S. Sutton, Crossprop: Learning Representations by Sto- chastic Meta-Gradient Descent in Neural Networks, in European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD), 2017, http://incompleteideas.net/papers/Crossprop.pdf.

Transitions in the Development of Locomotion. B Vereijken, K Adolph, Non-Linear Developmental Processes, G. J. P. Savelsbergh, H. L. J. VanderMaas, and P. L. C. VanGeertElsevierAmsterdam[Vereijken and Adolph 1999] B. Vereijken and K. Adolph, Transitions in the Development of Locomotion, in Non-Linear De- velopmental Processes, G. J. P. Savelsbergh, H. L. J. VanderMaas, and P. L. C. VanGeert (eds.), 137-149, Amsterdam: Elsevier, 1999.

A Model of Exact Small-Number Representation. Verguts, Psychonomic Bulletin & Review. 121[Verguts et al. 2005] T. Verguts, W. Fias, and M. Stevens, A Model of Exact Small-Number Representation, in Psychonomic Bulletin & Review, 12(1): 66-80, 2005.

A Survey of Artificial Cognitive Systems: Implica-tions for the Autonomous Development of Mental Capabilities in Computational Agents. Vernon, IEEE Transactions on Evolutionary Computation. 112[Vernon et al. 2007] D. Vernon, G. Metta, and G. Sandini, A Survey of Artificial Cognitive Systems: Implica-tions for the Autonomous Development of Mental Capabilities in Computational Agents, in IEEE Transactions on Evolutionary Com- putation, 11(2)(Apr.): 151-180, 2007.

A Roadmap for Cognitive Development in Humanoid Robots. Vernon, Vicarious 2017a] Vicarious, General Game Playing with Schema Networks, in blog post. Berlin; BerlinSpringer-Verlag11Cognitive Systems Monographs (COSMOS)[Vernon et al. 2010] D. Vernon, C. von Hofsten, and L. Fadiga, A Roadmap for Cognitive Development in Humanoid Robots, in Cognitive Systems Monographs (COSMOS), vol. 11, Berlin: Springer-Verlag Berlin, 2010. [Vicarious 2017a] Vicarious, General Game Playing with Schema Networks, in blog post, August 17, 2017, https://www.vicarious.com/2017/08/07/general-game-playing-with-schema-networks/.

Toward Learning a Compositional Visual Representation, in blog post. Vicarious 2017b] Vicarious[Vicarious 2017b] Vicarious, Toward Learning a Compositional Visual Representation, in blog post, October 20, 2017, https://www.vicarious.com/2017/10/20/toward-learning-a-compositional-visual-representation/.

Common Sense, Cortex, and CAPTCHA, in blog post. Vicarious 2017c] Vicarious[Vicarious 2017c] Vicarious, Common Sense, Cortex, and CAPTCHA, in blog post, October 26, 2017, https://www.vicarious.com/2017/10/26/common-sense-cortex-and-captcha/.

From Action to Abstraction: Learning Concepts through Sensorimotor Interactions, in blog post. Vicarious 2018] Vicarious[Vicarious 2018] Vicarious, From Action to Abstraction: Learning Concepts through Sensorimotor Interactions, in blog post, February 7, 2018, https://www.vicarious.com/2018/02/07/learning-concepts-through-sensorimotor-interactions/.

Real-Time Automated Visual Inspection Using Mobile Robots. H Vieira-Neto, U Nehmzow, Journal of Intelligent & Robotic Systems. 493[Vieira-Neto and Nehmzow 2007] H. Vieira-Neto and U. Nehmzow, Real-Time Automated Visual Inspection Using Mobile Robots, in Journal of Intelligent & Robotic Systems, 49(3): 293-307, 2007.

Phonological Development: The Origins of Language in the Child. M M Vihman, Blackwell PublishersOxford, UKM. M. Vihman, Phonological Development: The Origins of Language in the Child, Oxford, UK: Blackwell Publishers, 1996.

The Hippocampus and the Orienting Reflex. O S Vinogradova, Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Koray Kavukcuoglu, and Daan Wierstra, Matching Networks for One Shot Learning. E. N. Sokolov and O. S. VinogradovaHillsdale, NJErlbaumNeuronal Mechanisms of the Orienting Reflex. in arXiv[Vinogradova 1975] O. S. Vinogradova, The Hippocampus and the Orienting Reflex, in Neuronal Mechanisms of the Orient- ing Reflex, E. N. Sokolov and O. S. Vinogradova (eds.), 128-154, Hillsdale, NJ: Erlbaum, 1975. [Vinyals et al. 2017] Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Koray Kavukcuoglu, and Daan Wierstra, Matching Networks for One Shot Learning, in arXiv, 2017, https://arxiv.org/pdf/1606.04080.pdf.

Eye-Hand Coordination in the Newborn. Developmental Psychology. Hofsten 1982] C. von Hofsten183Hofsten 1982] C. von Hofsten, Eye-Hand Coordination in the Newborn, in Developmental Psychology, 18 (3)(May): 450-461, 1982.

Developmental Changes in the Organization of Prereaching Movements. ; C Hofsten, Von Hofsten, Developmental Psychology. 203Hofsten 1984] C. von Hofsten, Developmental Changes in the Organization of Prereaching Movements, in Developmen- tal Psychology, 20(3): 378-388, 1984.

Hofsten and Fazel-Zandy 1984] C. von Hofsten and S. Fazel-Zandy, Development of Visually Guided Hand Orientation in Reaching. ; C Hofsten, Von Hofsten, Journal of Experimental Child Psychology. 101Developmental ScienceHofsten 2007] C. von Hofsten, Action in Development, in Developmental Science, 10(1): 54-60, 2007. [von Hofsten and Fazel-Zandy 1984] C. von Hofsten and S. Fazel-Zandy, Development of Visually Guided Hand Orientation in Reaching, in Journal of Experimental Child Psychology, 38(2)(Oct.): 208-219, 1984.

The Structuring of Neonatal Arm Movements. Rönnqvist ; C Hofsten, L Von Hofsten, Rönnqvist, Child Development. 644Hofsten and Rönnqvist 1993] C. von Hofsten and L. Rönnqvist, The Structuring of Neonatal Arm Movements, in Child Development, 64(4)(Aug.): 1046-1057, 1993.

Ernst von Glasersfeld, An Interpretation of Piaget's Constructivism. Piaget Ernst Von Glasersfeld, The Radical Constructivist, Epistemology, Revue Internationale de Philosophie. Epistemology and education, Smock & Glasersfeld36Follow Through PublicationsGlasersfeld 1974] Ernst von Glasersfeld, Piaget and the Radical Constructivist Epistemology, in Epistemology and edu- cation, Smock & Glasersfeld (eds.), Follow Through Publications, 1-24, 1974, http://vonglasersfeld.com/034. [von Glasersfeld 1982] Ernst von Glasersfeld, An Interpretation of Piaget's Constructivism, in Revue Internationale de Phi- losophie, 36(4): 612 -635, 1982, http://vonglasersfeld.com/077.

Ernst von Glasersfeld, An Introduction to Radical Constructivism. The invented reality. P. WatzlawickNortonvon Glasersfeld 1984[von Glasersfeld 1984] Ernst von Glasersfeld, An Introduction to Radical Constructivism, in The invented reality, P. Watzlawick (ed.), Norton, 17 -40, 1984, http://vonglasersfeld.com/070.1.

An Exposition of Constructivism: Why Some Like it Radical. Glasersfeld Ernst Von, Monographs of the Journal for Research in Mathematics Education. R. B. Davis, C. A. Maher, and N. Noddings4von Glasersfeld 1990[von Glasersfeld 1990] Ernst von Glasersfeld, An Exposition of Constructivism: Why Some Like it Radical, in Monographs of the Journal for Research in Mathematics Education, R. B. Davis, C. A. Maher, and N. Noddings (eds.), 4: 19-29, 1990, http://www.vonglasersfeld.com/127.

Ernst von Glasersfeld and Pier Paolo Pisani, The Multistore Parser for Hierarchical Syntactic Structures. Glasersfeld Ernst Von, Communications of the ACM. W. J. Hutchins132John Benjamins Publishing CoSilvio Ceccato and the Correlational Grammar, in Early years in machine translationGlasersfeld 2001] Ernst von Glasersfeld, Silvio Ceccato and the Correlational Grammar, in Early years in machine translation, W. J. Hutchins (ed.), John Benjamins Publishing Co., 313-324, 2001, http://vonglasersfeld.com/242. [von Glasersfeld and Pisani 1970] Ernst von Glasersfeld and Pier Paolo Pisani, The Multistore Parser for Hierarchical Syn- tactic Structures, in Communications of the ACM, 13(2): 74-82, 1970.

Computer-Simulated Neural Networks-an Appropriate Model for Motor Development. J E Vos, K A Scheepstra ; Lev, S Vygotsky, ; A Wakeley, S Rivera, J Langer, Early Human Development. MIT Press34Can Young Infants Add and Subtract?. in Child Development[Vos and Scheepstra 1993] J. E. Vos and K. A. Scheepstra, Computer-Simulated Neural Networks-an Appropriate Model for Motor Development, in Early Human Development, 34(1-2)(Sept.): 101-112, 1993. [Vygotsky 2012] Lev S. Vygotsky, Thought and Language, MIT Press, 2012. [Wakeley et al. 2000] A. Wakeley, S. Rivera, and J. Langer, Can Young Infants Add and Subtract?, in Child Development, 71(6)(Nov.-Dec.): 1525-1534, 2000.

A self-modifying production system model of cognitive development. Wallace, Production System Models of Learning and Development. David Klahr, Pat Langley and Robert NechesCambridge MAMIT PressWallace et al. 1987] Iain Wallace, David Klahr, and Kevin Bluff, A self-modifying production system model of cognitive de- velopment, in Production System Models of Learning and Development, David Klahr, Pat Langley and Robert Neches (eds.), Cambridge MA: MIT Press, 1987.

The Mind's Views of Space, paper presented at the 3rd International Conference of Cognitive Science. H Wang, Tehran, IranWang H et al. 2001] H. Wang, T. R. Johnson, and J. Zhang, The Mind's Views of Space, paper presented at the 3rd Interna- tional Conference of Cognitive Science, Tehran, Iran, May 10-12, 2001.

J X Wang, Altruistic Helping in Human Infants and Young Chimpanzees. 311Learning to Reinforcement Learn[Wang JX et al. 2017] J. X. Wang, Z. Kurth-Nelson, D. Tirumala, H. Soyer, J. Z. Leibo, R. Munos, C. Blundell, D. Kumaran, and M. Botvinick, Learning to Reinforcement Learn, in arXiv, 2017, https://arxiv.org/pdf/1611.05763.pdf. [Warneken and Tomasello 2006] F. Warneken and M. Tomasello, Altruistic Helping in Human Infants and Young Chimpan- zees, in Science, 311(5765): 1301-1303, 2006.

[ Warneken, Cooperative Activities in Young Children and Chimpanzees. May-June77[Warneken et al. 2006] F. Warneken, F. Chen, and M. Tomasello, Cooperative Activities in Young Children and Chimpanzees, in Child Development, 77(3)(May-June): 640-663, 2006.

Mapping Facial Expression to Internal States Based on Intuitive Parenting. [ Watanabe, Journal of Robotics and Mechatronics. 193[Watanabe et al. 2007] A. Watanabe, M. Ogino, and M. Asada, Mapping Facial Expression to Internal States Based on Intui- tive Parenting, in Journal of Robotics and Mechatronics, 19(3): 315-323, 2007.

Mode of Acquisition of Word Meanings: The Viability of a Theoretical Construct. Wauters, arXiv:1707.06203Imagination-Augmented Agents for Deep Reinforcement Learning. Weber et al. 2018] Théophane Weber, Sébastien Racanière, David P. Reichert, Lars Buesing, Arthur Guez, Danilo Rezende, Nicolas Heess, Yujia Li, Demis Hassabis, Adria Puigdomènech Badia, Oriol Vinyals, Razvan Pascanu, Peter Battaglia, David Silver, and Daan Wierstra24in arXiv[Wauters et al. 2003] L. N. Wauters, A. E. J. M. Tellings, W. H. J. van Bon, and A. W. van Haafren, Mode of Acquisition of Word Meanings: The Viability of a Theoretical Construct, in Applied Psycholinguistics, 24(3)(July): 385-406, 2003. [Weber et al. 2018] Théophane Weber, Sébastien Racanière, David P. Reichert, Lars Buesing, Arthur Guez, Danilo Rezende, Nicolas Heess, Yujia Li, Demis Hassabis, Adria Puigdomènech Badia, Oriol Vinyals, Razvan Pascanu, Peter Battaglia, David Silver, and Daan Wierstra, Imagination-Augmented Agents for Deep Reinforcement Learning, in arXiv, 2018, arXiv:1707.06203, https://arxiv.org/pdf/1707.06203.pdf.

A Neural Schema Architecture for Autonomous Robots. [ Weitzenfeld, [Weitzenfeld et al. 1998] Alfredo Weitzenfeld, Ronald C. Arkin, Francisco Cervantes-Pérez, Fernando Corbacho, and Roberto Olivares, A Neural Schema Architecture for Autonomous Robots, 1998, https://smartech.gatech.edu/bitstream/handle/1853/21584/Iberamia.pdf.

A Model for Auto-Programming for General Purposes. Juyang Weng, Weng[Weng 2018] Juyang Weng, A Model for Auto-Programming for General Purposes, in arXiv, 2018, https://arxiv.org/pdf/1810.05764.pdf.

From Neural Networks to the Brain: Autonomous Mental Development. Juyang Weng, Wey-Shiuan Hwang, IEEE Computational Intelligence Magazine. 13[Weng and Hwang 2006] Juyang Weng and Wey-Shiuan Hwang, From Neural Networks to the Brain: Autonomous Mental Development, in IEEE Computational Intelligence Magazine, 1(3): 15-31, Aug. 2006, http://cse.msu.edu/ei/seminarreadings/CIM-FNB-AMD.pdf.

Incremental Hierarchical Discriminant Regression. Juyang Weng, Wey-Shiuan Hwang, IEEE Transactions on Neural Networks. 18[Weng and Hwang 2007] Juyang Weng and Wey-Shiuan Hwang, Incremental Hierarchical Discriminant Regression, in IEEE Transactions on Neural Networks, 18(2): 397-415, 2007, https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.84.753&rep=rep1&type=pdf.

Dually Optimal Neuronal Layers: Lobe Component Analysis. Juyang Weng, Matthew Luciw, IEEE Transactions on Autonomous Mental Development. 11[Weng and Luciw 2009] Juyang Weng and Matthew Luciw, Dually Optimal Neuronal Layers: Lobe Component Analysis, in IEEE Transactions on Autonomous Mental Development, 1(1): 68-85, May 2009, https://www.cse.msu.edu/~weng/research/LCA-IEEE.pdf.

Brain-Inspired Concept Networks: Learning Concepts from Cluttered Scenes. Juyang Weng, Matthew Luciw, IEEE Intelligent Systems. Weng and Luciw[Weng and Luciw 2014] Juyang Weng and Matthew Luciw, Brain-Inspired Concept Networks: Learning Concepts from Clut- tered Scenes, in IEEE Intelligent Systems, pp. 14-22, November/December 2014.

Developmental Robots: Theory, Method and Experimental Results. [ Weng, Proc. 2nd International Conference on Humanoid Robots. 2nd International Conference on Humanoid Robots[Weng et al. 1999] Juyang Weng, Wey S. Hwang, Yilu Zhang, and Colin H. Evans, Developmental Robots: Theory, Method and Experimental Results, in Proc. 2nd International Conference on Humanoid Robots, pp. 57-64, 1999, http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.46.4760&rep=rep1&type=pdf.

Autonomous Mental Development by Robots and Animals. [ Weng, Science Magazine. 291[Weng et al. 2001] Juyang Weng, James McClelland, Alex Pentland, Olaf Sporns, Ida Stockman, Mriganka Sur, and Esther Thelen, Autonomous Mental Development by Robots and Animals, in Science Magazine, 291(5504): 599 -600, 26 Jan 2001, http://www.cse.msu.edu/dl/SciencePaper.pdf.

[ Wentworth, Spatiotemporal Regularity and Interevent Contingencies as Information for Infants' Visual Expectations. 3[Wentworth et al. 2002] N. Wentworth, M. M. Haith, and R. Hood, Spatiotemporal Regularity and Interevent Contingencies as Information for Infants' Visual Expectations, in Infancy, 3(3): 303-321, 2002.

. [ Westermann, Neuroconstructivism, in Developmental Science. 101[Westermann et al. 2007] Gert Westermann, Denis Mareschal, Mark H. Johnson, Sylvain Sirois, Michael W. Spratling, and Michael S. C. Thomas, Neuroconstructivism, in Developmental Science, 10(1): 75 -83, 2007, http://www.sla.mdx.ac.uk/research/groups/ai/reading/Westermann_et_al-2007-Developmental_Science.pdf.

Developmental Changes in Infant Visual Preferences for Novelty and Familiarity. M J Wetherford, L B Cohen, Child Development. 443Wetherford and Cohen 1973[Wetherford and Cohen 1973] M. J. Wetherford and L. B. Cohen, Developmental Changes in Infant Visual Preferences for Novelty and Familiarity, in Child Development, 44(3): 416-424, 1973.

Learning Prospective Pick and Place Behavior. [ Wheeler, the 2nd International Conference on Development and Learning. Cambridge, MAMassachusetts Institute of Technologypaper presented at[Wheeler et al. 2002] D. S. Wheeler, A. H. Fagg, and R. A. Grupen, Learning Prospective Pick and Place Behavior, paper presented at the 2nd International Conference on Development and Learning (ICDL 2002), Massachusetts Institute of Technology, Cambridge, MA, June 12-15, 2002.

Motivation Reconsidered: The Concept of Competence. Rw ; R W White, White, Psychological Review. 66White RW 1959] R. W. White, Motivation Reconsidered: The Concept of Competence, in Psychological Review, 66: 297- 333, 1959.

B L White, Observations on the Development of Visually-Directed Reaching. 35White BL et al. 1964] B. L. White, P. Castle, and R. Held, Observations on the Development of Visually-Directed Reaching, in Child Development, 35: 349-364, 1964.

Imagery, Context Availability, Contextual Constraint, and Abstractness, paper presented at the 23rd Annual Conference of the. Wiemer-Hastings, Cognitive Science Society. Wiemer-Hastings et al. 2001] K. Wiemer-Hastings, J. Krug, and X. Xu, Imagery, Context Availability, Contextual Con- straint, and Abstractness, paper presented at the 23rd Annual Conference of the Cognitive Science Society, Edinburgh, Scotland, August 1-4, 2001.

The Development of Prospective Grasping Control between 5 and 7 Months: A Longitudinal Study. D C Witherington, Infancy. 72[Witherington 2005] D. C. Witherington, The Development of Prospective Grasping Control between 5 and 7 Months: A Longitudinal Study, in Infancy, 7(2): 143-161, 2005.

C Mark Witkowski, Schemes for Learning and Behaviour: A New Expectancy Model. Queen Mary Westfield College, U. of LondonPhD thesis[Witkowski 1997] C. Mark Witkowski, Schemes for Learning and Behaviour: A New Expectancy Model, Queen Mary West- field College, U. of London, PhD thesis, Feb. 1997, http://www.ee.ic.ac.uk/mark/thesis/thesis.pdf.

An Action-Selection Calculus. Mark Witkowski, Adaptive Behavior. 15[Witkowski 2007] Mark Witkowski, An Action-Selection Calculus, in Adaptive Behavior, 15(1): 73-97, 2007, http://www.ee.ic.ac.uk/mark/papers/Adaptive%20Behavior-2007-Witkowski-73-97.pdf.

Multiple paired forward and inverse models for motor control. ; D M Stephen Wolfram, M Wolpert, Kawato, Cellular Automata as Models of Complexity. 311Neural NetworksStephen Wolfram, Cellular Automata as Models of Complexity, in Nature, 311(5985): 419-424, 1984. [Wolpert and Kawato 1998] D. M. Wolpert and M. Kawato, Multiple paired forward and inverse models for motor control, in Neural Networks, 11(7-8): 1317-1329, 1998, https://wolpertlab.neuroscience.columbia.edu/sites/default/files/content/papers/WolKaw98.pdf.

An internal model for sensorimotor integration. [ Wolpert, Science. 2695232[Wolpert et al. 1995] D. M. Wolpert, Z. Ghahramani, and M. I. Jordan, An internal model for sensorimotor integration, in Sci- ence, 269(5232): 1880-1882, 1995.

Internal models in the cerebellum. [ Wolpert, Trends in cognitive sciences. 2[Wolpert et al. 1998] Daniel M. Wolpert, R. Chris Miall, and Mitsuo Kawato, Internal models in the cerebellum, in Trends in cognitive sciences, 2(9): 338-347, 1998, http://cbl.eng.cam.ac.uk/pub/Public/Wolpert/Publications/WolMiaKaw98.pdf.

Principles of sensorimotor learning. [ Wolpert, Nature Reviews Neuroscience. 1212[Wolpert et al. 2011] Daniel M. Wolpert, Jörn Diedrichsen, and J. Randall Flanagan, Principles of sensorimotor learning, in Nature Reviews Neuroscience, 12(12): 739-751, 2011, https://ir.lib.uwo.ca/cgi/viewcontent.cgi?article=1167&context=brainpub.

An Evolutionary Framework to Understand Foraging, Wanting, and Desire: The Neuropsychology of the Seeking System. J S Wright, J Panksepp, Neuropsychoanalysis: An Interdisciplinary Journal for Psycho-analysis and the Neurosciences. 14Wright and Panksepp 2012[Wright and Panksepp 2012] J. S. Wright and J. Panksepp, An Evolutionary Framework to Understand Foraging, Wanting, and Desire: The Neuropsychology of the Seeking System, in Neuropsychoanalysis: An Interdisciplinary Journal for Psy- cho-analysis and the Neurosciences, 14(1): 5-39, 2012.

Survey of Locomotion Control of Legged Robots Inspired by Biological Concept. Q D Wu, Science in China Series F-Information Sciences. 52[Wu QD et al. 2009] Q. D. Wu, C. J. Liu, J. Q. Zhang, and Q. J. Chen, Survey of Locomotion Control of Legged Robots In- spired by Biological Concept, in Science in China Series F-Information Sciences, 52(10): 1715-1729, 2009.

On Machine Thinking. X Wu, Proc. International Joint Conference on Neural Networks. International Joint Conference on Neural NetworksShengzhen, China[Wu X et al. 2021] Xiang Wu, Zejia Zheng, and Juyang Weng, On Machine Thinking, in Proc. International Joint Conference on Neural Networks, pp. 1-8, Shengzhen, China, July 18-22, 2021, http://www.cse.msu.edu/~weng/research/IJCNN2021rvsd-cited.pdf.

Children's Understanding of Counting. K Wynn, Cognition. 362[Wynn 1990] K. Wynn, Children's Understanding of Counting, in Cognition, 36(2)(Aug.): 155-193, 1990.

Addition and Subtraction by Human Infants. K Wynn, ; M. Wynne-Jones , Node splitting: A constructive algorithm for feed-forward neural networks, in Neural Computing and Applications. 358K. Wynn, Addition and Subtraction by Human Infants, in Nature, 358(6389)(Aug.): 749-750, 1992. [Wynne-Jones 1993] M. Wynne-Jones, Node splitting: A constructive algorithm for feed-forward neural networks, in Neural Computing and Applications, 1: 17-22, 1993.

Steps Towards the Object Semantic Hierarchy, Doctoral dissertation. Xu C 2011] Changhai XuComputer Science Department, University of Texas at AustinXu C 2011] Changhai Xu, Steps Towards the Object Semantic Hierarchy, Doctoral dissertation, Computer Science Depart- ment, University of Texas at Austin, 2011, http://web.eecs.umich.edu/~kuipers/papers/Xu-PhD-11.pdf.

D Xu, A Survey on Multioutput Learning, in arXiv. [Xu D et al. 2019] Donna Xu, Yaxin Shi, Ivor W. Tsang, Yew-Soon Ong, Chen Gong, and Xiaobo Shen, A Survey on Multi- output Learning, in arXiv, 2019, https://arxiv.org/abs/1901.00248.

Large Number Discrimination in Six-Month-Old Infants. F Xu, ; F Spelke, E S Xu, Spelke, Cognition. 741Xu F and Spelke 2000] F. Xu and E. S. Spelke, Large Number Discrimination in Six-Month-Old Infants, in Cognition, 74(1): B1-B11, 2000.

F Xu, Advances in Child Development and Behavior: Rational Constructivism in Cognitive Development. Fei Xu, Tamar Kushnir, and Janette B. BensonAcademic Press43Xu F et al. 2012] Fei Xu, Tamar Kushnir, and Janette B. Benson (eds.), Advances in Child Development and Behavior: Ra- tional Constructivism in Cognitive Development, Vol. 43, Academic Press, 2012.

Infants are Rational Constructivist Learners. F Xu, Fei Kushnir, Tamar Xu, Kushnir, Current Directions in Psychological Science. Xu F and Kushnir 2013] Fei Xu and Tamar Kushnir, Infants are Rational Constructivist Learners, in Current Directions in Psychological Science, 2013, https://www.researchgate.net/profile/Fei_Xu18/publication/258128091_Infants_Are_Rational_Constructivist_Learners/lin ks/54e624d70cf2bff5a4f38c84.pdf.

A Constructivist Approach to Infants' Vowel Acquisition through Mother-Infant Interaction. [ Yoshikawa, Connection Science. 15Carnegie-Mellon UniversityPhD thesisChildren's seriation behavior: A production system analysis[Yoshikawa et al. 2003] Y. Yoshikawa, M. Asada, K. Hosoda, and J. Koga, A Constructivist Approach to Infants' Vowel Ac- quisition through Mother-Infant Interaction, in Connection Science, 15(4): 245-258, 2003. [Young 1973] R. M. Young, Children's seriation behavior: A production system analysis, PhD thesis, Carnegie-Mellon Uni- versity, 1973.

Production Systems as Models of Cognitive Development. Richard M Young, https:/dl.acm.org/doi/abs/10.5555/3015486.3015507Proceedings of the 1st Summer Conference on Artificial Intelligence and Simulation of Behaviour. the 1st Summer Conference on Artificial Intelligence and Simulation of BehaviourRichard M. Young, Production Systems as Models of Cognitive Development, in Proceedings of the 1st Sum- mer Conference on Artificial Intelligence and Simulation of Behaviour, pp. 284-295, 1974 Jul 1, https://dl.acm.org/doi/abs/10.5555/3015486.3015507.

Seriation by Children: An Artificial Intelligence Analysis of a Piagetian Task. Richard M Young, BirkhauserBaselRichard M. Young, Seriation by Children: An Artificial Intelligence Analysis of a Piagetian Task, Basel: Birk- hauser, 1976.

The Emergence of Links between Lexical Acquisition and Object Categorization: A Computational Study. C Yu, Connection Science. 17C. Yu, The Emergence of Links between Lexical Acquisition and Object Categorization: A Computational Study, in Connection Science, 17(3-4)(Sept.-Dec.): 381-397, 2005.

General Intelligence and Seed AI 2.3.02, Singularity Institute for Artificial Intelligence. Eliezer Yudkowsky, Inc. [Yudkowsky 2001] Eliezer Yudkowsky, General Intelligence and Seed AI 2.3.02, Singularity Institute for Artificial Intelli- gence, Inc., 2001, https://www.scribd.com/document/7864310/general-intelligence-and-seed-ai.

Walking' in the Newborn. [ Zelazo, Science. 1764032[Zelazo et al. 1972] P. R. Zelazo, N. A. Zelazo, and S. Kolb, 'Walking' in the Newborn, in Science, 176(4032): 314-315, 1972.

Autonomous Mental Development: A New Interdisciplinary Transactions for Natural and Artificial Intelligence. IEEE Transactions on Autonomous Mental Development. 11Zhang 2009] Zhengyou Zhang[Zhang 2009] Zhengyou Zhang, Autonomous Mental Development: A New Interdisciplinary Transactions for Natural and Ar- tificial Intelligence, in IEEE Transactions on Autonomous Mental Development, 1(1), May 2009.

The Construction of 'Reality' in the Robot: Constructivist Perspectives on Situated Artificial Intelligence and Adaptive Robotics, in Foundations of Science, special issue on "The Impact of Radical Constructivism on Science. X Zhang, M H Lee ; Tom Ziemke, ; R Zöllner, T Asfour, R Dillmann, 9th International Conference on Simulation of Adaptive Behavior. Systems, SendaiBerlin, Germany; Japan6Programming by Demonstration: Dual-Arm Manipulation Tasks for Humanoid Robots. paper presented at the IEEE[Zhang and Lee 2006] X. Zhang and M. H. Lee, Early Perceptual and Cognitive Development in Robot Vision, paper pre- sented at the 9th International Conference on Simulation of Adaptive Behavior (SAB 2006), Berlin, Germany, 2006. [Ziemke 2001] Tom Ziemke, The Construction of 'Reality' in the Robot: Constructivist Perspectives on Situated Artificial In- telligence and Adaptive Robotics, in Foundations of Science, special issue on "The Impact of Radical Constructivism on Science," A. Riegler (ed.), 2001, 6(1-3): 163 -233, https://www.univie.ac.at/constructivism/pub/fos/pdf/ziemke.pdf. [Zöllner et al. 2004] R. Zöllner, T. Asfour, and R. Dillmann, Programming by Demonstration: Dual-Arm Manipulation Tasks for Humanoid Robots, paper presented at the IEEE/RSJ International Conference on Intelligent Robots and Systems, Sen- dai, Japan, September 28-October 2, 2004.