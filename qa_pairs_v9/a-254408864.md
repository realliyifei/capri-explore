# A Comprehensive Survey on Multi-hop Machine Reading Comprehension Approaches

CorpusID: 254408864 - [https://www.semanticscholar.org/paper/bad1ea60373fc77c1ff82c5ff99f1fd38c972ae8](https://www.semanticscholar.org/paper/bad1ea60373fc77c1ff82c5ff99f1fd38c972ae8)

Fields: Linguistics, Computer Science

## (s7) Decomposition technique:
### Question: How does decomposition simplify multi-hop MRC challenges?

#Reference=1 ['b25']

(p7.0) Complicated question is a basic challenge of multi-hop MRC, unlike the single-hop questions, they cannot be answered easily and require complicated reasoning. Since the human reasoning about complex questions is done by decomposition, answering subquestions, summarizing, and comparing [26], then this technique has focused on simplifying the problem by decomposition of a complex question into multiple simple sub-questions. It means it reduces multi-hop MRC to multiple single-hop MRC. This technique mostly uses the single-hop MRC models to find the answers to sub-questions and then combine the answers to obtain the final answer. In the following, the models which use this technique for multi-hop MRC will be reviewed in detail.

## (s10) •
### Question: What are the structures and main disadvantage of the Relation Extractor in MRC models?

#Reference=1 ['b25']

(p10.1) The main part of this model is Relation Extractor with two different structures: 1) classification-type (CRERC), where the evidence relation information in the dataset is used as prior knowledge, and the question text is mapped to question relations through the classifier; 2) span-type (SRERC), where the type of question relations is unrestricted, and the Relation Extractor can automatically extract multiple corresponding spans from the question text as question relations. Figure 9: Architecture of the RERC models [26] The Decomposition technique was one of the first ideas for multi-hop MRC and as you can see in recent years (2021) still has attracted attention. The main disadvantage of this technique is that, instead of focusing on multi-hop reasoning as an important key of multi-hop MRC, it focuses on reducing the problem to a single-hop MRC. Thus, they actually do not go far beyond single-hop models.

## (s11) Recurrent reasoning-based technique
### Question: What are the characteristics and applications of sequence models in MRC tasks?

#Reference=1 ['b27']

(p11.0) The sequence models have been first used for single-hop MRC tasks, and most of them are based on Recurrent Neural Networks (RNNs), some studies focus on using them in multi-hop MRC. It can be called state-based reasoning models and they are closer to a standard attention-based RC model with an additional "state" representation that is iteratively updated. The changing state representation results in the model focusing on different parts of the passage during each iteration, allowing it to combine information from different parts of the passage [28]. Most models, presented in this section, have used advanced neural network concepts, such as attention mechanism and network memory for multi-hop reasoning. In the following the models which use this technique will be reviewed in detail including the architecture alongside the superiority and the motivation of them.

## (s15) •
### Question: How does the PathNet model identify and score potential paths for answering questions?

#Reference=1 ['b34']

(p15.3) They first find all possible path from passages. It starts with selecting a passage that contains a head entity from the question, and then finds all entities and noun phrases from the same sentence. Afterward, it selects the next passage that contains the potential intermediate entity identified above. Finally, it is checked whether the next passage contains any of the candidate answer choices or not. The resulting will be a set of entity sequences. After obtaining all potential paths, it is time to score each path using the PathNet model based on two perspectives: 1) Context-based Path Scoring, which is based on the interaction with the question encoding, and 2) Passage-based Path Scoring, which is based on the interaction between the passage-based path encoding vector and the candidate encoding. There is an example of the process in Figure 15 which In the Rank-1 path, the model composes the implicit located in relations between (Zoo lake, Johannesburg) and (Johannesburg, Gauteng). However, this method extracts many invalid paths, then causes wasting the computing resources [35].

## (s16) Rank-2 Path:
### Question: What is the Sentence-level Multi-hop Reasoning approach in document analysis?

#Reference=1 ['b36']

(p16.1) As Figure 16 shows, after embedding sentences into a matrix and constructing a graph, the policy is run to select the next sentence. In this regard, the convolution-based policy network is used to learn a traversal policy from current options, previously accepted sentences, and the current question. For example, in this figure, the policy has learned to select the correct next sentence (ct) from the previous sentence (ct-1). After this action, the answer sentence (o1) can be selected during the next step. SMR: Huo, Ge and Zhao [37] proposed a Sentence-level Multi-hop Reasoning approach named SMR while most existing approaches only use document-level or entity-level inferences. In this regard, an initial sentence is first found based on the main entity in the question, and that sentence is then used to find more relevant sentences to create multiple sentence-based reasoning chains as a memory network. Besides, some sentences are concatenated to prevent the mistakes of Co-Reference resolution methods and to reduce the number of hops. An example of such a concatenation is shown in Figure 17.

### Question: What are the phases and methodology of ChainEx's sentence-based model for multi-hop reasoning?

#Reference=2 ['b36', 'b37']

(p16.2) There are two phases in this model: 1) the Selecting phase to select the most relevant sentence to the network memory state as the initial sentence of the current hop, and 2) the Establishing phase to prepare to go to the next hop by updating the network memory state. Finally, the information of the reasoning chains is used to predict the final answer. Figure 17: Representation enrichment via concatenation of adjacent sentences [37] ChainEx: Chen, Lin and Durrett [38] proposed a sentence-based model that does not rely on gold annotated chains or supporting facts at the training and test phases, instead, pseudo-gold reasoning chains are derived using some heuristics based on named entity recognition and coreference resolution during the training time, and it learns to extract chains from raw texts at the test time. They first extract a reasoning chain over the text for a multi-hop reasoning task, and then apply a BERT-based QA system to find the answer by learning from these chains.

## (s17) Graph-based technique
### Question: Why have graph-based techniques gained attention in multihop MRC?

#Reference=2 ['b38', 'b13']

(p17.0) Graph-based techniques because of their natural language relationship representation ability [39] has attracted attention in multihop MRC. It is natural to model natural language context into graph structure and the process of multi-hop reasoning as moving among nodes [14]. The main idea of the Graph-based technique is to construct a graph based on the context and question, and then the reasoning is performed by message passing over this structure using graph neural networks. The process of constructing the graph from large textual data and reasoning over it are challenging tasks. There are a lot of studies that focus on these challenges which are explained in this subsection in detail.

## (s19) MHQA-GRN:
### Question: How does Song et al.'s model improve global context inference in multi-hop reading comprehension?

#Reference=1 ['b39']

(p19.0) Song et al. [40] focused on inferring global context as an important key in multi-hop reading comprehension, while previous studies approximate global evidence with local coreference information with DAG-styled GRU. They proposed a model for better connecting global evidence, with a more complex graph compared to DAGs. They construct an entity graph with three types of edges: the edge between the same entity within a passage, the edges between two mentions of different entities within a context window, and coreference-typed edges. The graph might also have cycles which makes it difficult to apply a DAG network to it. (A graph with three types of edges and a DAG graph are shown in Figure 21).

### Question: How do GCN and GRN contribute to evidence aggregation in graph-based models?

#Reference=2 ['b27', 'b40']

(p19.1) For inferring the global context, the related information of the constructed graph has been merged. In this study, two recent graph neural networks have been applied to this graph: graph convolutional network (GCN) and graph recurrent network (GRN) for evidence aggregation. Afterward, an attention mechanism is applied in order to match the hidden states at each graph encoding step with the question representation. Finally, a probability distribution is calculated from the matching results. The architecture of this model is shown in Figure 22. However, this model still only implicitly combines knowledge from all passages, and are therefore unable to provide explicit reasoning paths [28]. DFGN: Xiao et al. [41] proposed a model to improve the interaction between the information of documents and the entity graph.

## (s22) HDE:
### Question: What is the structure and purpose of the Heterogeneous Document-Entity graph?

#Reference=1 ['b45']

(p22.0) Tu et al. [46] proposed a more complex graph named Heterogeneous Document-Entity (HDE) graph with different types of nodes and edges. This graph can cover different granularity levels of information in context and also enables rich information interaction among different types of nodes for accurate reasoning. The nodes in the HDE graph are candidates, documents, and entities. Besides, it has seven types of edges: 1) between a document node and a candidate node that appears in the same document.

### Question: What is the Select, Answer, and Explain (SAE) system and how does it work?

#Reference=3 ['b34', 'b45', 'b46']

(p22.2) However, [35] have shown that if the number of inferences increases, the complexity of models will rise sharply due to the iteration of cumbersome message passing algorithm, resulting in low efficiency.  [46] SAE: Tu et al. [47] proposed an interpretable system named Select, Answer, and Explain (SAE) with multi-hop reasoning graphs based on GNN with contextual sentence embeddings as nodes. This kind of sentence graph makes lead to an interpretable model because it can directly output supporting sentences with the answer prediction. The edges capture the global information presented within each document and also the cross-document reasoning path. Also, the contextual sentence embedding used in GNN is summarized over token representations based on a novel mixed attentive pooling mechanism. The attention weight is calculated from both answer span logits and self-attention output on token representations. This attention-based interaction enables the exploitation of complementary information between "answer" and "explain" tasks. The SAE system first filters unrelated documents, and selects gold documents using a document classifier trained with a novel pairwise learning-to-rank loss function.

## (s23) •
### Question: What is the IP-LQR method and its impact on multi-hop MRC systems?

#Reference=2 ['b51', 'b11']

(p23.1) Then they proposed the latent query reformulation method (IP-LQR), which incorporates phrases in the latent query reformulation to improve the cognitive ability of the system. They also design a semantic-augmented fusion method based on the phrase graph, which is then used to propagate the information (Figure 38). After encoding the context and question into the high vector space and acquiring the representations of phrases, sentences, and paragraphs via the mean-pooling layer. Then, a similarity evaluation strategy is designed to calculate the weights of edges in the graph, also the fusion layer is used as an information aggregation to latently update the original question's representation. Finally, a re-attention mechanism is used to help locate the gold answer based on the new representation.  Recently, graph-based models have become very popular and recognized as the main solution for multi-hop MRC because of the nature of modeling such a process into graph structure and the good results. But there is some drawback to this technique, the first one is the expensive computational process of the graph-based methods [52], and the second problem is that the graph-based models often can't cover all the inherent structure of documents and loss valuable structural information by modeling documents into graphs [12].

## (s24) Graph-free technique
### Question: How does graph structure impact multi-hop question answering effectiveness?

#Reference=7 ['b52', 'b53', 'b13', None, 'b52', 'b51', 'b47']

(p24.1) GF: Shao et al. [53] attempted to answer this question: How much does graph structure contribute to answer a multi-hop question. They reimplement a graph-based model-Dynamically Fused Graph Network [54]-and claimed that the graph structure can play an important role only if the pre-trained models are used in a feature-based manner, while if the pre-trained models are used in the fine-tuning approach, the graph structure may not be helpful. Then the adjacency matrix based on manually defined rules and the graph structure can be regarded as prior knowledge, which could be learned by self-attention or Transformers. They proved that when texts have been modeled as an entity graph, both graph-attention and self-attention can achieve comparable results, but when texts have been modeled as a sequence structure, only a 2-layer Transformer could achieve similar results as DFGN. As you can see in Figure 40 when the entity graph is fully connected, a graph-attention layer will degenerate into a selfattention layer. However, this study as the first attempt of a graph-free model suffers from huge performance gap compared to the state-art-of the graph based-models [14]. Figure 40: An example of the relation between the graph-attention network and the self-attention network [53] AMS: Yuntao et al. [52] proposed another non-graph model with a focus on the document filters step to denoise irrelevant documents, and proves that if this step has been done properly, even a single-hop model can be used for multi-hop. They investigate that promising performance of the filter from Hierarchical Graph Network (HGN) (Fang et al., 2020) and showed that for 2paragraph selection, both precision and recall can achieve around 95%, and for 4-paragraph selection, recall will be nearly 99%.

### Question: What are the AMS and S2G models' approaches to multi-hop question answering?

#Reference=3 ['b51', 'b13', 'b13']

(p24.2) Then they proposed Answer Multi-hop questions by Single-hop QA (AMS) models and used a single-hop QA models based on the attention mechanism with the HGN's document filter. As you can see in Figure 41 after the Document denoise layer, they used an Attention-based single-hop layer. AMS could achieve a comparable result with stat-of-the-art graph-bade models but still couldn't improve them. Figure 41: Overall architecture of AMS [52] S2G: Wu, Zhang, and Zhao [14] investigated whether graph modeling is necessary for multi-hop. In this regard, they first proved that the retrieval stage is the most important module, while the existing studies focus on the reader module by graph modeling. This study presents a graph-free alternative named select-to-guide (S2G) to retrieve evidence paragraphs in a coarse-tofine manner, incorporated with two attention mechanisms, which shows conforming to the nature of multi-hop reasoning. For the paragraph retrieval module, this study introduced a cascaded paragraph retrieval module that retrieves the evidence paragraphs in an explicit coarse-to-fine manner, and in multi-task module there are one shared encoder module alongside with two interdependent modules with an attention mechanism ( Figure 42). However Concrete error analysis on S2G shows that there is still room for improvement on the multi-hop retriever module design. Figure 42: The multi-task module of S2G [14] As the last part of this section, Figure 43 has been prepared to summarize the techniques and models.

## (s29) HotpotQA
### Question: How are model performances evaluated on HotpotQA according to the study?

#Reference=1 ['b10']

(p29.0) In this section, the performance of models on HotpotQA [11] will be investigated. Exact-match (EM) and F1 metrics have been used in this study to evaluate the model performance. EM is used to show whether the predicated answer and the ground-truth answer are exactly the same. F1 measures the average overlap between the predicted answer and the ground-truth answer. In addition, there are three sets of metrics: 1) Answer EM/F1 to evaluate the answer span prediction, 2) Support EM/F1 to evaluate the supporting facts prediction, and 3) Joint EM/F1 to combine the two previous ones.

