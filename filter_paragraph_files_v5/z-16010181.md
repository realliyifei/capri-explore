# Facial Feature Point Detection: A Comprehensive Survey

CorpusID: 16010181 - [https://www.semanticscholar.org/paper/fcecaa3eed9574028bb3887a0eaa6a8b5a30bd9d](https://www.semanticscholar.org/paper/fcecaa3eed9574028bb3887a0eaa6a8b5a30bd9d)

Fields: Computer Science

## (s0) Introduction
Number of References: 3

(p0.0) Facial feature points, also known as facial landmarks or facial fiducial points, have semantic meaning. Facial feature points are mainly located around facial components such as eyes, mouth, nose and chin (see Fig.  1). Facial feature point detection (FFPD) refers to a supervised or semi-supervised process using abundant manually labeled images. FFPD usually starts from a rectangular bounding box returned by face detectors (Viola and Jones, 2004;Yang et al, 2002) which implies the location of a face. This bounding box can be employed to initialize the positions of facial feature points. Facial feature points are different from keypoints for image registration (Ozuysal et al, 2010) and keypoint detection is usually an unsupervised procedure.
## (s3) Local Expert
Number of References: 3

(p3.0) A local expert functions to compute a response map on the local region around corresponding facial feature points, i.e. we have N local experts in a FFPD model. The region that supports a local expert could be either one-dimensional (i.e. a line) or two-dimensional (such as a rectangular region). A local expert can be a distance metric such as the Mahalanobis distance , a classifier such as linear support vector machine (Wang et al, 2008a), or a regressor (Cristinacce and Cootes, 2007;Saragih et al, 2009c).
## (s12) Graphical Model-based Methods
Number of References: 7

(p12.0) Graphical model-based FFPD methods mainly refer to tree-structure-based methods and Markov random field (MRF)-based methods. Tree-structure-based methods take each facial feature point as a node and all points as a tree. The locations of facial feature points can be optimally solved by dynamic programming. Unlike the tree-structure which has no loop, MRF-based methods model the location of all points with loops. Coughlan and Ferreira (2002) developed a generative Bayesian graphical model that deployed separate models to describe shape variability (shape prior) and appearance variations (appearance likelihood) to find deformable shapes. The shape prior takes the location of each facial feature point and these points' normal orientation as a node in MRF. An edge map and an orientation map are calculated to model the appearance likelihood. A variant of the belief propagation method is utilized to optimize the problem. MRF has been also explored to constrain the relative position of all facial feature points obtained from the regression procedure in ; Martinez et al (2013). Gu et al (2007) learned a sparse Gaussian MRF structure to regularize the spatial configuration of face parts by lasso regression.

(p12.1) Unlike the method in Coughlan and Ferreira (2002) which models the shape prior only in a local neighborhood, Liang et al (2006a) proposed a method that incorporates a global shape prior directly into the Markov network. The local shape prior is enforced by denoting a line segment as a node of the constructed Markov network. Here, line segments draw from one facial point to another neighboring point. Subsequently, Liang et al (2006b) claimed that although CLM-based methods take the global shape prior into account, these methods neglect the neighboring constraint between points since they compute the response map of each point independently. Based on the thought in Liang et al (2006a), Liang et al. further incorporated the PDM shape prior into their model.
## (s13) Joint Face Alignment Methods
Number of References: 13

(p13.0) Joint face alignment jointly aligns a batch of images undergoing a variety of geometric and appearance variations (Zhao et al, 2011), motivated by the congealingstyle joint alignment method (Learned-Miller, 2006) and sparse and low-rank decomposition method (Peng et al, 2012). Zhao et al (2011) designed a joint AAM by assuming that the images of the same face should lie in the same linear subspace and the person-specific space should be proximate the generic appearance space. The problem is formulated as a nonlinear problem constrained by a rank term which can be transformed to a nuclear norm. An augmented Lagrangian method is explored to optimize the nonlinear problem. Smith and Zhang (2012) stated that the method (Zhao et al, 2011) breaks down under several common conditions, such as significant occlusion or shadow, image degradation, and outliers. Considering the fact that a non-parametric set of global shape models (Belhumeur et al, 2011) results in excellent facial feature point localization accuracy on facial images undergoing significant occlusions, shadows, and pose and expression variation, they introduced the same shape model combined with a local appearance model into the joint alignment framework.

(p13.1) Different from the aforementioned two joint face alignment methods, which both incorporate the rank term into the objective, Zhao et al (2012) proposed a novel two-stage approach to align a set of images of the same person. The initial facial feature point estimation is first computed by an off-the-shelf approach (Gu and Kanade, 2008). To distinguish the "good" alignments from the "bad" ones among all these initial estimations, a discriminative face alignment evaluation metric is designed by virtue of cascaded AdaBoost framework (Viola and Jones, 2004) and Real AdaBoost (Friedman et al, 2000). Selected "good" alignments are utilized to improve the accuracy of "bad" ones through appearance consistency between the "bad" estimate and its selected K neighboring "good" estimates. Tong et al (2009Tong et al ( , 2012 proposed a semi-supervised facial landmark localization approach which utilizes a small number of manually labeled images. Their objective function is to minimize the sum of squared error of two distances: the distance between the labeled and unlabeled images, and the distance between the unlabeled images. To obtain a reasonable shape, an on-line learned PDM shape model is imposed as a constraint.
