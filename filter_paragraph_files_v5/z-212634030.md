# A Survey on The Expressive Power of Graph Neural Networks

CorpusID: 212634030 - [https://www.semanticscholar.org/paper/6fb8b967dad742eb390a3090f094a12f2d909538](https://www.semanticscholar.org/paper/6fb8b967dad742eb390a3090f094a12f2d909538)

Fields: Mathematics, Computer Science

## (s11) Connection between GNNs And The WL Algorithm
Number of References: 2

(p11.0) In this section, we introduce the connection between GNNs and the WL algorithm, found by Xu et al. (2019) and Morris et al. (2019). First, the following theorem is easy to see.  2019)). For any message passing GNN and for any graphs G and H, if the 1-WL algorithm outputs that G and H are "possibly isomorphic", the embeddings h G and h H computed by the GNN are the same.
## (s13) Relational Pooling
Number of References: 2

(p13.0) In this section, we introduce another approach to build powerful GNNs proposed by Murphy et al. (2019b). The idea is very simple. The relational pooling layer takes an average of all permutations, as Jannosy pooling (Murphy et al., 2019a). Namely, let f be a message passing GNN, A be the adjacency matrix of G = (V, E, X), I n ∈ R n×n be the identity matrix, and S n be the symmetric group over V . Then, relational pooling GNNs (RP-GNNs) are defined as follows.
