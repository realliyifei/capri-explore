# Towards More Precise Automatic Analysis: A Comprehensive Survey of Deep Learning-based Multi-organ Segmentation

CorpusID: 257255572 - [https://www.semanticscholar.org/paper/564ec33ed2cbfae044e8c770f73e0044d305107f](https://www.semanticscholar.org/paper/564ec33ed2cbfae044e8c770f73e0044d305107f)

Fields: Medicine, Computer Science, Engineering

## (s3) A. Network Architecture
Number of References: 11

(p3.0) Based on the design of the network architecture, multi-organ segmentation methods can be classified according to singlestage and multistage implementations. Single-stage methods include those based on CNN (Convolutional Neural Network), GAN (Generative Adversarial Network), transformer or hybrid networks. Multistage approaches include coarse-to-fine methods, localization and segmentation methods, or other cascade approaches. Tables II-IV summarize the literature related to single-stage methods for the segmentation of multi-organ in the head and neck, abdomen and chest based on DSC metrics. Since there are too many organs in the head and neck as well as abdomen, this paper mainly reports 9 organs in the head and neck and 7 organs in the abdomen. Tables XI-XII in the  supplementary materials summarize the DSC values of other  organs. 1) CNN-Based Methods: Convolutional Neural Network (CNN) is a feedforward neural network which can automatically extract deep features of the image. Multiple neurons are connected to each neuron in next layer, where each layer can perform complex tasks such as convolution, pooling, or loss computation [37]. CNNs have been successfully applied to medical images, such as brain [38], [39] and pancreas [40] segmentation tasks. a) Early CNN-Based Methods: Earlier CNN-based methods mainly used convolutional layers to extract features and then went through pooling layers and fully connected layers to obtain the final prediction results. Ibragimov and Xing [41] used deep learning methods to segment OARs in head and neck CT images for the first time, training 13 CNNs for 13 OARs, and showed that the CNNs outperformed or were comparable to advanced algorithms in segmentation accuracy for organs such as the spinal cord, mandible, larynx, pharynx, eye, and optic nerve, but performed poorly in the segmentation of organs such as the parotid gland, submandibular gland, and optical chiasm. Fritscher et al. [42] combined the shape location as well as the intensity with CNN for segmentation of the parotid gland, submandibular gland and optic nerve. Moeskops et al. [43] investigated whether a single CNN can be used to segment six tissues in brain MR images, pectoral muscles in breast MR images, and coronary arteries in heart CTA images. The results showed that a single CNN can segment multiple organs not only on a single modality but also on multiple modalities. b) FCN-Based Methods: Early CNN-based methods made some improvements in segmentation accuracy compared to traditional methods. However, CNN involves multiple identical computations of overlapping voxels during the convolution operation, which may cause some performance loss. Moreover, the spatial information of the image is lost when the convolutional features are input into the final fully connected network layer. Thus, Shelhamer et al. [44] proposed the Fully Convolutional Network (FCN), which enables endto-end segmentation by using transposed convolutional layers that allow the size of the predicted image to match the size of the input image. Wang et al. [45] used FCN combined with a new sample selection strategy to segment 16 organs in the abdomen, and Trullo et al. [83] used a variant of FCN, SharpMask [46], to segment the esophagus, heart, trachea, and aorta in the thorax, which showed the segmentation results of all four organs were improved compared with the normal FCN.
## (s13) VI. DISCUSSION AND FUTURE TRENDS
Number of References: 2

(p13.0) In this paper, a systematic review of deep learning methods for multi-organ segmentation is presented from the perspectives of both full annotation and imperfect annotation. The main innovations of the full annotation method focus on the design of network architectures, the combination of network dimensions, the innovation of network modules and the proposal of new loss functions. In terms of the network architecture design, with the development of the transformer [75] architectures, better utilization of these advanced architectures for multi-organ segmentation is a promising direction, as well as the automatic search for the optimal architecture for each organ through neural network architecture search (NAS) [191]. In the network dimension, optimally combining 2D and 3D architectures is a worthwhile research direction. In terms of network module, more dedicated modules need to design to improve the segmentation accuracy according to the multi-organ segmentation task. In terms of the loss functions, targeting the class imbalance, geometric prior or introducing adversarial learning loss will have great potential for designing more comprehensive and diverse loss functions.
## (s17) D. Study of Transfer Learning Models
Number of References: 2

(p17.0) Existing deep learning models usually trained on one part of the body, which usually tend to obtain poor results when migrated to other datasets or applied to other parts of the body. Therefore, transfer learning models need to be explored in the future. For example, Fu et al. [194] proposed a new method called domain adaptive relational reasoning (DARR). It is used to generalize 3D multi-organ segmentation models to medical data from different domains. In addition, a very significant problem with medical images compared to other natural images is that many private datasets are not publicly available, and many hospitals only release trained models. Therefore, source free domain adaptation problem will be a very important research direction in the future. For example, Hong et al. [195] proposed a source free unsupervised domain adaptive cross-modal approach for abdomen multi-organ segmentation.
