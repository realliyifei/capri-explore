# Natural Example-Based Explainability: a Survey

CorpusID: 261582519 - [https://www.semanticscholar.org/paper/078e311f88009cedcbb44a4852f93a2c48cbf5d8](https://www.semanticscholar.org/paper/078e311f88009cedcbb44a4852f93a2c48cbf5d8)

Fields: Computer Science, Psychology

## (s9) Influence functions
Number of References: 2

(p9.0) Influence functions originated from robust statistics in the early 70s. In essence, they evaluate the change of a model's parameters as we up-weight a training sample by an infinitesimal amount: [45]θ ϵ,zj := arg min θ L(θ)+ϵl(z j , θ). One way to estimate the change in a model's parameters of a single training sample would be to perform Leave-One-Out (LOO) retraining, that is, to train the model again with the sample of interest being held out of the training dataset. However, repeatedly re-training the model to exactly retrieve the parameters' changes could be computationally prohibitive, especially when the dataset size and/or the number of parameters grows. As removing a sample z j can be linearly approximated by up-weighting it by ϵ = − 1 n , computing influence helps to estimate the change of a model's parameters if a specific training point was removed. Thus, by making the assumption that the empirical risk L is twicedifferentiable and strictly convex w.r.t. the model's parameters θ making the Hessian Hθ := 1 n zi∈Dtrain ∇ 2 θ l(z i ,θ) positive definite, Cook and Weisberg [24] proposed to compute the influence of z j on the parametersθ as:
