# Trustworthy Federated Learning: A Survey

CorpusID: 258823036 - [https://www.semanticscholar.org/paper/a0e40d9a07fdc5848ef2f10d9b63f5c28e0cec03](https://www.semanticscholar.org/paper/a0e40d9a07fdc5848ef2f10d9b63f5c28e0cec03)

Fields: Computer Science

## (s11) A. Trustworthy Feature and Sample Selection
Number of References: 10

(p11.0) The authors proposes a new approach called Federated Stochastic Dual-Gate based Feature Selection (FedSDG-FS) [37] for feature selection in Vertical FL (VFL). Existing FS works for VFL assume prior knowledge on the number of noisy features or the threshold of useful features to be selected, making them unsuitable for practical applications. FedSDG-FS uses a Gaussian stochastic dual-gate to approximate the probability of a feature being selected with privacy protection through Partially Homomorphic Encryption without a trusted third-party. It also proposes a feature importance initialization method based on Gini impurity to reduce overhead. Experiments show that FedSDG-FS outperforms existing approaches in selecting high-quality features and building global models with higher performance. The proposed method solves the problem of efficient feature selection in VF.

(p11.1) A trustworthiness evaluation framework, TrustE-VC, is proposed in [38] that combines criteria importance and performance rates to determine the service attributes of vertical FL that require more attention. It also suggests a three-level security feature to enhance effectiveness and trustworthiness in VC. The proposed framework comprises three interconnected components, including an aggregation of the security evaluation values, a fuzzy multicriteria decision-making algorithm, and a simple additive weight associated with importanceperformance analysis and performance rate to visualize the framework findings. The proposed framework provides a useful tool for designers and industrial CV practices to evaluate and select industrial CV trust requirements. The framework addresses the challenges of developing effective and trustworthy VFL models.

(p11.2) In [39], authors present an XAI Federated Deep Reinforcement Learning model aimed at improving decision-making for new Autonomous Vehicles (AVs) in trajectory and motion planning. This model tackles appropriate AV selection for FL and guarantees explainability and trustworthiness. Using XAI, it determines each feature's importance and AV's trust value. A trust-based deep reinforcement learning model is introduced for selections, showing superior performance in real-world data experiments. The study highlights trust's role in AV selection and proposes an innovative XAI-based trust computation method, providing a sophisticated mechanism for new AVs' decision-making.

(p11.3) The main contribution of [40] is a FL model named Fed-PARL, which aims to reduce the model size while performing sample-based pruning, avoiding misbehaved clients, and considering resource-availability for partial workloads. This is especially useful for resource-constrained IoT clients. FedPARL, a tri-level FL strategy, aids clients in conserving resources throughout training, eliminates unreliable or resource-deficient clients during selection, and allows for flexible local epochs based on client resource availability. An incentive-deterrent framework promotes effective clients and discourages poorperforming or malicious ones. This approach exhibits robustness in constrained FL-IoT environments, and results reveal that FedPARL outperforms existing methods, delivering an enhanced FL solution.

(p11.4) This authors proposes a new approach to optimize smart device sampling and data offloading in FL [41]. The authors propose a joint sampling and data offloading optimization problem where devices are selected based on their expected contribution to model training. The non-selected devices can transfer data to selected ones based on estimated data dissimilarities between nodes. The proposed approach aims to improve the efficiency and accuracy of FedL by reducing the communication and computational costs. The approach is evaluated using real-world data, and the results demonstrate its effectiveness in improving the performance of FedL.
## (s13) C. Trustworthy Model Selection
Number of References: 6

(p13.0) In FL, it is crucial to evaluate the contributions of participants to the performance of the final model while ensuring privacy. To achieve this, the widely adopted method is the use of Shapley Value (SV) techniques. However, existing SV-based approaches are computationally expensive and impractical for real-world applications. To tackle this issue, authors in [45] introduced the Guided Truncation Gradient Kapley (GTG-Shapley) approach, which reduces the computation cost of SVbased FL participant contribution evaluation. Unlike traditional methods, GTG-Shapley does not require extra learning tasks from participants, as it reconstructs FL sub-models using their previous gradient updates instead of training them from scratch. Additionally, GTG-Shapley employs guided Monte Carlo sampling to further reduce the number of required model reconstructions and evaluations, thereby enhancing the efficiency of SV computation. GTG-Shapley offers a more practical and scalable solution for fair FL participant contribution evaluation. GTG-Shapley enables FL to be more practical and widely adopted in real-world applications.

(p13.1) The aggregation of local models from participating clients is a critical component in generating the final global model in FL. However, traditional aggregation methods can be susceptible to adversarial attacks and client failures. To mitigate this issue, the authors of this paper propose a truth inference approach to FL that incorporates the reliability of each client's local model into the aggregation process. The proposed approach in [46] models the clients' reliability based on their submitted local model parameters and considers these parameters during the aggregation process to produce a robust estimate of the global model. The authors have further enhanced the method by considering the model parameters submitted by clients in previous rounds in addition to the current round, thus providing a more comprehensive evaluation of client reliability.The proposed truth inference approach provides a more robust estimate of the global model, protects against potential adversarial attacks, and considers client reliability in the aggregation process, thereby improving the robustness of FL.

(p13.2) In FL, the server aggregates the uploaded model parameters from participating clients to generate a global model. The common practice is to evenly weight the local models, assuming equal contribution from all nodes. However, the heterogeneous nature of devices and data leads to variations in contribution from users. To address this issue, authors in [47] introduces a reputation-enabled aggregation method that adjusts the aggregation weights based on the reputation scores of users. The reputation score is computed based on the performance metrics of the local models during each training round. The proposed method showed an improvement of 17.175% over the standard baseline in non-independent and identically distributed (non-IID) scenarios for a FL network of 100 participants. This work considers the mobile network of distributed computing nodes where the performance and reputation of individual nodes vary. The reputation-enabled weighted aggregation is hypothesized to lead to faster convergence and a higher accuracy level for FL in a mobile environment.
## (s17) B. Trustworthy Contribution Evaluation
Number of References: 32

(p17.0) The contribution measurement strategies used in FL systems can be classified into three main categories: self-report based evaluation, Shapley value based evaluation, and influence and reputation based evaluation. Self-report based evaluation involves the data owner directly reporting their level of contribution to the model owner. Metrics used to evaluate the contribution include computational resources and data size. The Shapley value based evaluation takes into account the participation order of the data owners and assesses their contributions in a fair manner, typically used in cooperative games. Influence and reputation based evaluation considers the client's impact on the FL model's loss function and their reliability, and may involve techniques like Fed-Influence and reputation mechanisms that can be combined with blockchain. A client's reputation is generally a combination of their internal reputation in a task and their accumulated reputation based on historical records. The authors in [89] focuses on the critical aspect of measuring the contributions of users in FL systems. The authors conduct a comprehensive analysis of the different strategies for evaluating user contributions, examining the factors that can impact the effectiveness of these methods. The paper emphasizes the need for fair and accurate evaluation techniques to assess the contributions of data owners in FL and provides valuable insights into the current state of research in this area. This study highlights the importance of considering user contributions in FL systems and provides a solid foundation for future research in this field. The categorization and most relevant research work are presented in following sub sections.

(p17.1) 1) Smart Contract based Trustworthy Contribution Evaluation: The authors in [91] proposes a solution to the issue of data validity and quality in FL systems by utilizing the EOS blockchain and IPFS. The system records uploaded updates in a scalable manner and rewards users based on the cost of their training data. To ensure that only valuable updates are validated and rewarded, the authors propose the Class-Sampled Validation Error Scheme (CSVES). This scheme tailors the validation set to a device's data breakdown and Reputation mechanism evaluates model quality and contribution, which encourages data owners to join the BFL and contribute high-quality data for local and weighted global model aggregation and reward allocation. checks the validity of the data cost claimed by the device. By implementing CSVES, the system can ensure that the data quality is maintained while incentivizing users to contribute high-quality updates to the FL model.

(p17.2) A BC-based FL scheme with a reputation mechanism to motivate data owners in high-quality data contribution has been proposed in [96]. By integrating smart contract technology and blockchain, the authors aim to create a decentralized and trustworthy environment for conducting FL tasks transparently and fairly. The proposed reputation mechanism evaluates model quality and contribution, which encourages data owners to join the BFL and contribute high-quality data for local and weighted global model aggregation and reward allocation. The noncooperative game theory with equilibrium point make sure the highest rewrard to the contributer with high quality data. Moreover, an optional grouping mechanism is proposed to address the high complexity of a large number of participants. The BFL mechanism is expected to improve the credibility and reliability of FL and guarantee the model quality.

(p17.3) 2) Shapely Value and Consensus based Trustworthy Contribution Evaluation: In [90], a blockchain-assisted FL framework is presented to encourage honest participation and reward fair contributions. The framework employs a new consensus mechanism known as "Proof of Interpretation and Selection" (PoIS), which evaluates the contributions of individual clients by analyzing model interpretation results. PoIS aggregates feature attributions to distinguish prominent contributors and outliers and uses a credit function that considers contribution, relevance, and past performance to determine incentives. The proposed framework has been tested against various types of adversaries, datasets, and attack strategies and found to be robust. This framework offers a promising solution for addressing the issues of traditional FL and ensuring fairness in contribution-based incentivization.

(p17.4) The authors propose a decentralized FL system named BESIFL (Blockchain Empowered Secure and Incentive FL) that leverages blockchain technology to remove the central FL server in [94]. Three essential components are there in system: an accuracy-based malicious node detection mechanism, a contribution-based incentive mechanism, and an algorithm that coordinates both mechanisms. The malicious node detection mechanism identifies and removes malicious nodes during the training process, while the contribution-based incentive mechanism motivates nodes to participate in FL and rewards them based on their contribution to model training. BESIFL is designed to address the security and incentive issues in FL while also stimulating credible nodes to contribute to the model training. The proposed system applies the consensus algorithm and identity authentication of blockchain to ensure the security of model training and employs mechanisms for accuracy-based malicious node detection, contribution-based node selection, and token-based node incentive.

(p17.5) The varying data quality and heterogeneous data distributions across multiple healthcare institutions pose significant challenges to existing FL frameworks. To address these issues, a Contribution-Aware FL (CAreFL) framework [95], has been proposed, which focuses on fair and efficient contribution evaluation of FL participants. The proposed GTG-Shapley approach allows for fast and accurate evaluation of participant contributions. Moreover, the framework introduces a novel FL model aggregation approach, which selects the best performing sub-model for the next round of local training instead of always aggregating all received local models. This approach addresses the heterogeneity issues of data distribution in the healthcare sector. The historical contribution evaluation records are further converted into reputation values for the FL participants, which can serve as a basis for stakeholder management decision support. The CAreFL framework offers a promising solution to the challenges faced by existing FL frameworks in the healthcare sector, improving FL model performance while ensuring privacy and fairness.

(p17.6) 3) Privacy Preserving Trustworthy Contribution Evaluation: Authors presents a novel architecture for healthcare institutions to collaborate in improving the performance of a global ML model in [92]. The proposed system utilizes a combination of blockchain and secure multi-party computation (SMPC) to ensure data integrity, model versioning and privacy preservation during model training and ensemble. Unlike traditional methods, proposed architecture prioritizes general model evaluation over incentivization for fair contribution assessment. This evaluation process is carried out by the blockchain nodes and recorded on tamper-proof storage. The final contribution of each participant's ML model is determined based on their performance on unforeseen data. Additionally, the architecture enables each participant to define their own model structure, taking into account the varying computing power among participants. The proposed hierarchical ensemble FL method promises to advance the field of collaborative ML in healthcare while maintaining the privacy and security of sensitive medical data.

(p17.7) The authors present a decentralized Fair and Privacy-Preserving Deep Learning (FPPDL) framework in [93], that aims to address the issue of fairness in FL models. Unlike traditional FL solutions that provide all parties with the same model regardless of their contribution, FPPDL aims to provide each participant with a final FL model that reflects their individual contributions. To achieve fairness, the authors propose a local credibility mutual evaluation mechanism, and for privacy preservation, a three-layer onion-style encryption scheme is proposed. The framework operates by recording all transactions, including uploading and downloading, through blockchain technology. This eliminates the need for participants to trust each other or a third party. The proposed framework is designed to create a healthy FL ecosystem where each participant's contribution is valued and accurately reflected in the final FL model. Table 3 provides an extensive overview of the research conducted on trustworthy contribution evaluation in FL.

(p17.8) The contribution measurement strategies used in FL systems can be classified into three main categories: self-report based evaluation, Shapley value based evaluation, and influence and reputation based evaluation. Self-report based evaluation involves the data owner directly reporting their level of contribution to the model owner. Metrics used to evaluate the contribution include computational resources and data size. The Shapley value based evaluation takes into account the participation order of the data owners and assesses their contributions in a fair manner, typically used in cooperative games. Influence and reputation based evaluation considers the client's impact on the FL model's loss function and their reliability, and may involve techniques like Fed-Influence and reputation mechanisms that can be combined with blockchain. A client's reputation is generally a combination of their internal reputation in a task and their accumulated reputation based on historical records. The authors in [89] focuses on the critical aspect of measuring the contributions of users in FL systems. The authors conduct a comprehensive analysis of the different strategies for evaluating user contributions, examining the factors that can impact the effectiveness of these methods. The paper emphasizes the need for fair and accurate evaluation techniques to assess the contributions of data owners in FL and provides valuable insights into the current state of research in this area. This study highlights the importance of considering user contributions in FL systems and provides a solid foundation for future research in this field. The categorization and most relevant research work are presented in following sub sections.

(p17.9) 1) Smart Contract based Trustworthy Contribution Evaluation: The authors in [91] proposes a solution to the issue of data validity and quality in FL systems by utilizing the EOS blockchain and IPFS. The system records uploaded updates in a scalable manner and rewards users based on the cost of their training data. To ensure that only valuable updates are validated and rewarded, the authors propose the Class-Sampled Validation Error Scheme (CSVES). This scheme tailors the validation set to a device's data breakdown and Reputation mechanism evaluates model quality and contribution, which encourages data owners to join the BFL and contribute high-quality data for local and weighted global model aggregation and reward allocation. checks the validity of the data cost claimed by the device. By implementing CSVES, the system can ensure that the data quality is maintained while incentivizing users to contribute high-quality updates to the FL model.

(p17.10) A BC-based FL scheme with a reputation mechanism to motivate data owners in high-quality data contribution has been proposed in [96]. By integrating smart contract technology and blockchain, the authors aim to create a decentralized and trustworthy environment for conducting FL tasks transparently and fairly. The proposed reputation mechanism evaluates model quality and contribution, which encourages data owners to join the BFL and contribute high-quality data for local and weighted global model aggregation and reward allocation. The noncooperative game theory with equilibrium point make sure the highest rewrard to the contributer with high quality data. Moreover, an optional grouping mechanism is proposed to address the high complexity of a large number of participants. The BFL mechanism is expected to improve the credibility and reliability of FL and guarantee the model quality.

(p17.11) 2) Shapely Value and Consensus based Trustworthy Contribution Evaluation: In [90], a blockchain-assisted FL framework is presented to encourage honest participation and reward fair contributions. The framework employs a new consensus mechanism known as "Proof of Interpretation and Selection" (PoIS), which evaluates the contributions of individual clients by analyzing model interpretation results. PoIS aggregates feature attributions to distinguish prominent contributors and outliers and uses a credit function that considers contribution, relevance, and past performance to determine incentives. The proposed framework has been tested against various types of adversaries, datasets, and attack strategies and found to be robust. This framework offers a promising solution for addressing the issues of traditional FL and ensuring fairness in contribution-based incentivization.

(p17.12) The authors propose a decentralized FL system named BESIFL (Blockchain Empowered Secure and Incentive FL) that leverages blockchain technology to remove the central FL server in [94]. Three essential components are there in system: an accuracy-based malicious node detection mechanism, a contribution-based incentive mechanism, and an algorithm that coordinates both mechanisms. The malicious node detection mechanism identifies and removes malicious nodes during the training process, while the contribution-based incentive mechanism motivates nodes to participate in FL and rewards them based on their contribution to model training. BESIFL is designed to address the security and incentive issues in FL while also stimulating credible nodes to contribute to the model training. The proposed system applies the consensus algorithm and identity authentication of blockchain to ensure the security of model training and employs mechanisms for accuracy-based malicious node detection, contribution-based node selection, and token-based node incentive.

(p17.13) The varying data quality and heterogeneous data distributions across multiple healthcare institutions pose significant challenges to existing FL frameworks. To address these issues, a Contribution-Aware FL (CAreFL) framework [95], has been proposed, which focuses on fair and efficient contribution evaluation of FL participants. The proposed GTG-Shapley approach allows for fast and accurate evaluation of participant contributions. Moreover, the framework introduces a novel FL model aggregation approach, which selects the best performing sub-model for the next round of local training instead of always aggregating all received local models. This approach addresses the heterogeneity issues of data distribution in the healthcare sector. The historical contribution evaluation records are further converted into reputation values for the FL participants, which can serve as a basis for stakeholder management decision support. The CAreFL framework offers a promising solution to the challenges faced by existing FL frameworks in the healthcare sector, improving FL model performance while ensuring privacy and fairness.

(p17.14) 3) Privacy Preserving Trustworthy Contribution Evaluation: Authors presents a novel architecture for healthcare institutions to collaborate in improving the performance of a global ML model in [92]. The proposed system utilizes a combination of blockchain and secure multi-party computation (SMPC) to ensure data integrity, model versioning and privacy preservation during model training and ensemble. Unlike traditional methods, proposed architecture prioritizes general model evaluation over incentivization for fair contribution assessment. This evaluation process is carried out by the blockchain nodes and recorded on tamper-proof storage. The final contribution of each participant's ML model is determined based on their performance on unforeseen data. Additionally, the architecture enables each participant to define their own model structure, taking into account the varying computing power among participants. The proposed hierarchical ensemble FL method promises to advance the field of collaborative ML in healthcare while maintaining the privacy and security of sensitive medical data.

(p17.15) The authors present a decentralized Fair and Privacy-Preserving Deep Learning (FPPDL) framework in [93], that aims to address the issue of fairness in FL models. Unlike traditional FL solutions that provide all parties with the same model regardless of their contribution, FPPDL aims to provide each participant with a final FL model that reflects their individual contributions. To achieve fairness, the authors propose a local credibility mutual evaluation mechanism, and for privacy preservation, a three-layer onion-style encryption scheme is proposed. The framework operates by recording all transactions, including uploading and downloading, through blockchain technology. This eliminates the need for participants to trust each other or a third party. The proposed framework is designed to create a healthy FL ecosystem where each participant's contribution is valued and accurately reflected in the final FL model. Table 3 provides an extensive overview of the research conducted on trustworthy contribution evaluation in FL.
## (s19) 1) Game Theory based Trustworthy Incentive Mechanism:
Number of References: 2

(p19.0) In [100], the authors propose a novel approach to designing incentives for a blockchain-enabled FL platform using mechanism design, an economic approach to realizing desired objectives in situations where participants act rationally. The main idea behind the incentive mechanism is to introduce a repeated competition for model updates, so that any rational worker follows the protocol and maximizes their profits. During each round, selected workers choose the best k model updates from previous round and update their own model based on them. The reward to workers in the previous round is decided by the vote of the next round workers. The model updates of the next round workers are also competed and voted by workers in the subsequent round, ensuring that they cannot sabotage the system. The authors provide a rigorous theoretical analysis of the incentive compatibility based on contest theory and clarify the optimal conditions for reward policy in a blockchain-enabled FL platform. The contribution of the paper includes a competitive incentive mechanism design, a fullfledged protocol that can be implemented on existing public blockchains, and a theoretical analysis to clarify incentive compatibility based on contest theory.
## (s58) A. Trustworthy Feature and Sample Selection
Number of References: 10

(p58.0) The authors proposes a new approach called Federated Stochastic Dual-Gate based Feature Selection (FedSDG-FS) [37] for feature selection in Vertical FL (VFL). Existing FS works for VFL assume prior knowledge on the number of noisy features or the threshold of useful features to be selected, making them unsuitable for practical applications. FedSDG-FS uses a Gaussian stochastic dual-gate to approximate the probability of a feature being selected with privacy protection through Partially Homomorphic Encryption without a trusted third-party. It also proposes a feature importance initialization method based on Gini impurity to reduce overhead. Experiments show that FedSDG-FS outperforms existing approaches in selecting high-quality features and building global models with higher performance. The proposed method solves the problem of efficient feature selection in VF.

(p58.1) A trustworthiness evaluation framework, TrustE-VC, is proposed in [38] that combines criteria importance and performance rates to determine the service attributes of vertical FL that require more attention. It also suggests a three-level security feature to enhance effectiveness and trustworthiness in VC. The proposed framework comprises three interconnected components, including an aggregation of the security evaluation values, a fuzzy multicriteria decision-making algorithm, and a simple additive weight associated with importanceperformance analysis and performance rate to visualize the framework findings. The proposed framework provides a useful tool for designers and industrial CV practices to evaluate and select industrial CV trust requirements. The framework addresses the challenges of developing effective and trustworthy VFL models.

(p58.2) In [39], authors present an XAI Federated Deep Reinforcement Learning model aimed at improving decision-making for new Autonomous Vehicles (AVs) in trajectory and motion planning. This model tackles appropriate AV selection for FL and guarantees explainability and trustworthiness. Using XAI, it determines each feature's importance and AV's trust value. A trust-based deep reinforcement learning model is introduced for selections, showing superior performance in real-world data experiments. The study highlights trust's role in AV selection and proposes an innovative XAI-based trust computation method, providing a sophisticated mechanism for new AVs' decision-making.

(p58.3) The main contribution of [40] is a FL model named Fed-PARL, which aims to reduce the model size while performing sample-based pruning, avoiding misbehaved clients, and considering resource-availability for partial workloads. This is especially useful for resource-constrained IoT clients. FedPARL, a tri-level FL strategy, aids clients in conserving resources throughout training, eliminates unreliable or resource-deficient clients during selection, and allows for flexible local epochs based on client resource availability. An incentive-deterrent framework promotes effective clients and discourages poorperforming or malicious ones. This approach exhibits robustness in constrained FL-IoT environments, and results reveal that FedPARL outperforms existing methods, delivering an enhanced FL solution.

(p58.4) This authors proposes a new approach to optimize smart device sampling and data offloading in FL [41]. The authors propose a joint sampling and data offloading optimization problem where devices are selected based on their expected contribution to model training. The non-selected devices can transfer data to selected ones based on estimated data dissimilarities between nodes. The proposed approach aims to improve the efficiency and accuracy of FedL by reducing the communication and computational costs. The approach is evaluated using real-world data, and the results demonstrate its effectiveness in improving the performance of FedL.
## (s60) C. Trustworthy Model Selection
Number of References: 6

(p60.0) In FL, it is crucial to evaluate the contributions of participants to the performance of the final model while ensuring privacy. To achieve this, the widely adopted method is the use of Shapley Value (SV) techniques. However, existing SV-based approaches are computationally expensive and impractical for real-world applications. To tackle this issue, authors in [45] introduced the Guided Truncation Gradient Kapley (GTG-Shapley) approach, which reduces the computation cost of SVbased FL participant contribution evaluation. Unlike traditional methods, GTG-Shapley does not require extra learning tasks from participants, as it reconstructs FL sub-models using their previous gradient updates instead of training them from scratch. Additionally, GTG-Shapley employs guided Monte Carlo sampling to further reduce the number of required model reconstructions and evaluations, thereby enhancing the efficiency of SV computation. GTG-Shapley offers a more practical and scalable solution for fair FL participant contribution evaluation. GTG-Shapley enables FL to be more practical and widely adopted in real-world applications.

(p60.1) The aggregation of local models from participating clients is a critical component in generating the final global model in FL. However, traditional aggregation methods can be susceptible to adversarial attacks and client failures. To mitigate this issue, the authors of this paper propose a truth inference approach to FL that incorporates the reliability of each client's local model into the aggregation process. The proposed approach in [46] models the clients' reliability based on their submitted local model parameters and considers these parameters during the aggregation process to produce a robust estimate of the global model. The authors have further enhanced the method by considering the model parameters submitted by clients in previous rounds in addition to the current round, thus providing a more comprehensive evaluation of client reliability.The proposed truth inference approach provides a more robust estimate of the global model, protects against potential adversarial attacks, and considers client reliability in the aggregation process, thereby improving the robustness of FL.

(p60.2) In FL, the server aggregates the uploaded model parameters from participating clients to generate a global model. The common practice is to evenly weight the local models, assuming equal contribution from all nodes. However, the heterogeneous nature of devices and data leads to variations in contribution from users. To address this issue, authors in [47] introduces a reputation-enabled aggregation method that adjusts the aggregation weights based on the reputation scores of users. The reputation score is computed based on the performance metrics of the local models during each training round. The proposed method showed an improvement of 17.175% over the standard baseline in non-independent and identically distributed (non-IID) scenarios for a FL network of 100 participants. This work considers the mobile network of distributed computing nodes where the performance and reputation of individual nodes vary. The reputation-enabled weighted aggregation is hypothesized to lead to faster convergence and a higher accuracy level for FL in a mobile environment.
## (s64) B. Trustworthy Contribution Evaluation
Number of References: 32

(p64.0) The contribution measurement strategies used in FL systems can be classified into three main categories: self-report based evaluation, Shapley value based evaluation, and influence and reputation based evaluation. Self-report based evaluation involves the data owner directly reporting their level of contribution to the model owner. Metrics used to evaluate the contribution include computational resources and data size. The Shapley value based evaluation takes into account the participation order of the data owners and assesses their contributions in a fair manner, typically used in cooperative games. Influence and reputation based evaluation considers the client's impact on the FL model's loss function and their reliability, and may involve techniques like Fed-Influence and reputation mechanisms that can be combined with blockchain. A client's reputation is generally a combination of their internal reputation in a task and their accumulated reputation based on historical records. The authors in [89] focuses on the critical aspect of measuring the contributions of users in FL systems. The authors conduct a comprehensive analysis of the different strategies for evaluating user contributions, examining the factors that can impact the effectiveness of these methods. The paper emphasizes the need for fair and accurate evaluation techniques to assess the contributions of data owners in FL and provides valuable insights into the current state of research in this area. This study highlights the importance of considering user contributions in FL systems and provides a solid foundation for future research in this field. The categorization and most relevant research work are presented in following sub sections.

(p64.1) 1) Smart Contract based Trustworthy Contribution Evaluation: The authors in [91] proposes a solution to the issue of data validity and quality in FL systems by utilizing the EOS blockchain and IPFS. The system records uploaded updates in a scalable manner and rewards users based on the cost of their training data. To ensure that only valuable updates are validated and rewarded, the authors propose the Class-Sampled Validation Error Scheme (CSVES). This scheme tailors the validation set to a device's data breakdown and Reputation mechanism evaluates model quality and contribution, which encourages data owners to join the BFL and contribute high-quality data for local and weighted global model aggregation and reward allocation. checks the validity of the data cost claimed by the device. By implementing CSVES, the system can ensure that the data quality is maintained while incentivizing users to contribute high-quality updates to the FL model.

(p64.2) A BC-based FL scheme with a reputation mechanism to motivate data owners in high-quality data contribution has been proposed in [96]. By integrating smart contract technology and blockchain, the authors aim to create a decentralized and trustworthy environment for conducting FL tasks transparently and fairly. The proposed reputation mechanism evaluates model quality and contribution, which encourages data owners to join the BFL and contribute high-quality data for local and weighted global model aggregation and reward allocation. The noncooperative game theory with equilibrium point make sure the highest rewrard to the contributer with high quality data. Moreover, an optional grouping mechanism is proposed to address the high complexity of a large number of participants. The BFL mechanism is expected to improve the credibility and reliability of FL and guarantee the model quality.

(p64.3) 2) Shapely Value and Consensus based Trustworthy Contribution Evaluation: In [90], a blockchain-assisted FL framework is presented to encourage honest participation and reward fair contributions. The framework employs a new consensus mechanism known as "Proof of Interpretation and Selection" (PoIS), which evaluates the contributions of individual clients by analyzing model interpretation results. PoIS aggregates feature attributions to distinguish prominent contributors and outliers and uses a credit function that considers contribution, relevance, and past performance to determine incentives. The proposed framework has been tested against various types of adversaries, datasets, and attack strategies and found to be robust. This framework offers a promising solution for addressing the issues of traditional FL and ensuring fairness in contribution-based incentivization.

(p64.4) The authors propose a decentralized FL system named BESIFL (Blockchain Empowered Secure and Incentive FL) that leverages blockchain technology to remove the central FL server in [94]. Three essential components are there in system: an accuracy-based malicious node detection mechanism, a contribution-based incentive mechanism, and an algorithm that coordinates both mechanisms. The malicious node detection mechanism identifies and removes malicious nodes during the training process, while the contribution-based incentive mechanism motivates nodes to participate in FL and rewards them based on their contribution to model training. BESIFL is designed to address the security and incentive issues in FL while also stimulating credible nodes to contribute to the model training. The proposed system applies the consensus algorithm and identity authentication of blockchain to ensure the security of model training and employs mechanisms for accuracy-based malicious node detection, contribution-based node selection, and token-based node incentive.

(p64.5) The varying data quality and heterogeneous data distributions across multiple healthcare institutions pose significant challenges to existing FL frameworks. To address these issues, a Contribution-Aware FL (CAreFL) framework [95], has been proposed, which focuses on fair and efficient contribution evaluation of FL participants. The proposed GTG-Shapley approach allows for fast and accurate evaluation of participant contributions. Moreover, the framework introduces a novel FL model aggregation approach, which selects the best performing sub-model for the next round of local training instead of always aggregating all received local models. This approach addresses the heterogeneity issues of data distribution in the healthcare sector. The historical contribution evaluation records are further converted into reputation values for the FL participants, which can serve as a basis for stakeholder management decision support. The CAreFL framework offers a promising solution to the challenges faced by existing FL frameworks in the healthcare sector, improving FL model performance while ensuring privacy and fairness.

(p64.6) 3) Privacy Preserving Trustworthy Contribution Evaluation: Authors presents a novel architecture for healthcare institutions to collaborate in improving the performance of a global ML model in [92]. The proposed system utilizes a combination of blockchain and secure multi-party computation (SMPC) to ensure data integrity, model versioning and privacy preservation during model training and ensemble. Unlike traditional methods, proposed architecture prioritizes general model evaluation over incentivization for fair contribution assessment. This evaluation process is carried out by the blockchain nodes and recorded on tamper-proof storage. The final contribution of each participant's ML model is determined based on their performance on unforeseen data. Additionally, the architecture enables each participant to define their own model structure, taking into account the varying computing power among participants. The proposed hierarchical ensemble FL method promises to advance the field of collaborative ML in healthcare while maintaining the privacy and security of sensitive medical data.

(p64.7) The authors present a decentralized Fair and Privacy-Preserving Deep Learning (FPPDL) framework in [93], that aims to address the issue of fairness in FL models. Unlike traditional FL solutions that provide all parties with the same model regardless of their contribution, FPPDL aims to provide each participant with a final FL model that reflects their individual contributions. To achieve fairness, the authors propose a local credibility mutual evaluation mechanism, and for privacy preservation, a three-layer onion-style encryption scheme is proposed. The framework operates by recording all transactions, including uploading and downloading, through blockchain technology. This eliminates the need for participants to trust each other or a third party. The proposed framework is designed to create a healthy FL ecosystem where each participant's contribution is valued and accurately reflected in the final FL model. Table 3 provides an extensive overview of the research conducted on trustworthy contribution evaluation in FL.

(p64.8) The contribution measurement strategies used in FL systems can be classified into three main categories: self-report based evaluation, Shapley value based evaluation, and influence and reputation based evaluation. Self-report based evaluation involves the data owner directly reporting their level of contribution to the model owner. Metrics used to evaluate the contribution include computational resources and data size. The Shapley value based evaluation takes into account the participation order of the data owners and assesses their contributions in a fair manner, typically used in cooperative games. Influence and reputation based evaluation considers the client's impact on the FL model's loss function and their reliability, and may involve techniques like Fed-Influence and reputation mechanisms that can be combined with blockchain. A client's reputation is generally a combination of their internal reputation in a task and their accumulated reputation based on historical records. The authors in [89] focuses on the critical aspect of measuring the contributions of users in FL systems. The authors conduct a comprehensive analysis of the different strategies for evaluating user contributions, examining the factors that can impact the effectiveness of these methods. The paper emphasizes the need for fair and accurate evaluation techniques to assess the contributions of data owners in FL and provides valuable insights into the current state of research in this area. This study highlights the importance of considering user contributions in FL systems and provides a solid foundation for future research in this field. The categorization and most relevant research work are presented in following sub sections.

(p64.9) 1) Smart Contract based Trustworthy Contribution Evaluation: The authors in [91] proposes a solution to the issue of data validity and quality in FL systems by utilizing the EOS blockchain and IPFS. The system records uploaded updates in a scalable manner and rewards users based on the cost of their training data. To ensure that only valuable updates are validated and rewarded, the authors propose the Class-Sampled Validation Error Scheme (CSVES). This scheme tailors the validation set to a device's data breakdown and Reputation mechanism evaluates model quality and contribution, which encourages data owners to join the BFL and contribute high-quality data for local and weighted global model aggregation and reward allocation. checks the validity of the data cost claimed by the device. By implementing CSVES, the system can ensure that the data quality is maintained while incentivizing users to contribute high-quality updates to the FL model.

(p64.10) A BC-based FL scheme with a reputation mechanism to motivate data owners in high-quality data contribution has been proposed in [96]. By integrating smart contract technology and blockchain, the authors aim to create a decentralized and trustworthy environment for conducting FL tasks transparently and fairly. The proposed reputation mechanism evaluates model quality and contribution, which encourages data owners to join the BFL and contribute high-quality data for local and weighted global model aggregation and reward allocation. The noncooperative game theory with equilibrium point make sure the highest rewrard to the contributer with high quality data. Moreover, an optional grouping mechanism is proposed to address the high complexity of a large number of participants. The BFL mechanism is expected to improve the credibility and reliability of FL and guarantee the model quality.

(p64.11) 2) Shapely Value and Consensus based Trustworthy Contribution Evaluation: In [90], a blockchain-assisted FL framework is presented to encourage honest participation and reward fair contributions. The framework employs a new consensus mechanism known as "Proof of Interpretation and Selection" (PoIS), which evaluates the contributions of individual clients by analyzing model interpretation results. PoIS aggregates feature attributions to distinguish prominent contributors and outliers and uses a credit function that considers contribution, relevance, and past performance to determine incentives. The proposed framework has been tested against various types of adversaries, datasets, and attack strategies and found to be robust. This framework offers a promising solution for addressing the issues of traditional FL and ensuring fairness in contribution-based incentivization.

(p64.12) The authors propose a decentralized FL system named BESIFL (Blockchain Empowered Secure and Incentive FL) that leverages blockchain technology to remove the central FL server in [94]. Three essential components are there in system: an accuracy-based malicious node detection mechanism, a contribution-based incentive mechanism, and an algorithm that coordinates both mechanisms. The malicious node detection mechanism identifies and removes malicious nodes during the training process, while the contribution-based incentive mechanism motivates nodes to participate in FL and rewards them based on their contribution to model training. BESIFL is designed to address the security and incentive issues in FL while also stimulating credible nodes to contribute to the model training. The proposed system applies the consensus algorithm and identity authentication of blockchain to ensure the security of model training and employs mechanisms for accuracy-based malicious node detection, contribution-based node selection, and token-based node incentive.

(p64.13) The varying data quality and heterogeneous data distributions across multiple healthcare institutions pose significant challenges to existing FL frameworks. To address these issues, a Contribution-Aware FL (CAreFL) framework [95], has been proposed, which focuses on fair and efficient contribution evaluation of FL participants. The proposed GTG-Shapley approach allows for fast and accurate evaluation of participant contributions. Moreover, the framework introduces a novel FL model aggregation approach, which selects the best performing sub-model for the next round of local training instead of always aggregating all received local models. This approach addresses the heterogeneity issues of data distribution in the healthcare sector. The historical contribution evaluation records are further converted into reputation values for the FL participants, which can serve as a basis for stakeholder management decision support. The CAreFL framework offers a promising solution to the challenges faced by existing FL frameworks in the healthcare sector, improving FL model performance while ensuring privacy and fairness.

(p64.14) 3) Privacy Preserving Trustworthy Contribution Evaluation: Authors presents a novel architecture for healthcare institutions to collaborate in improving the performance of a global ML model in [92]. The proposed system utilizes a combination of blockchain and secure multi-party computation (SMPC) to ensure data integrity, model versioning and privacy preservation during model training and ensemble. Unlike traditional methods, proposed architecture prioritizes general model evaluation over incentivization for fair contribution assessment. This evaluation process is carried out by the blockchain nodes and recorded on tamper-proof storage. The final contribution of each participant's ML model is determined based on their performance on unforeseen data. Additionally, the architecture enables each participant to define their own model structure, taking into account the varying computing power among participants. The proposed hierarchical ensemble FL method promises to advance the field of collaborative ML in healthcare while maintaining the privacy and security of sensitive medical data.

(p64.15) The authors present a decentralized Fair and Privacy-Preserving Deep Learning (FPPDL) framework in [93], that aims to address the issue of fairness in FL models. Unlike traditional FL solutions that provide all parties with the same model regardless of their contribution, FPPDL aims to provide each participant with a final FL model that reflects their individual contributions. To achieve fairness, the authors propose a local credibility mutual evaluation mechanism, and for privacy preservation, a three-layer onion-style encryption scheme is proposed. The framework operates by recording all transactions, including uploading and downloading, through blockchain technology. This eliminates the need for participants to trust each other or a third party. The proposed framework is designed to create a healthy FL ecosystem where each participant's contribution is valued and accurately reflected in the final FL model. Table 3 provides an extensive overview of the research conducted on trustworthy contribution evaluation in FL.
## (s66) 1) Game Theory based Trustworthy Incentive Mechanism:
Number of References: 2

(p66.0) In [100], the authors propose a novel approach to designing incentives for a blockchain-enabled FL platform using mechanism design, an economic approach to realizing desired objectives in situations where participants act rationally. The main idea behind the incentive mechanism is to introduce a repeated competition for model updates, so that any rational worker follows the protocol and maximizes their profits. During each round, selected workers choose the best k model updates from previous round and update their own model based on them. The reward to workers in the previous round is decided by the vote of the next round workers. The model updates of the next round workers are also competed and voted by workers in the subsequent round, ensuring that they cannot sabotage the system. The authors provide a rigorous theoretical analysis of the incentive compatibility based on contest theory and clarify the optimal conditions for reward policy in a blockchain-enabled FL platform. The contribution of the paper includes a competitive incentive mechanism design, a fullfledged protocol that can be implemented on existing public blockchains, and a theoretical analysis to clarify incentive compatibility based on contest theory.
