# Computation-efficient Deep Learning for Computer Vision: A Survey

CorpusID: 261243890 - [https://www.semanticscholar.org/paper/a87947f88519dba980d0f16cdfb78ed09a8e02f0](https://www.semanticscholar.org/paper/a87947f88519dba980d0f16cdfb78ed09a8e02f0)

Fields: Computer Science, Engineering

## (s8) 3) Model Scaling.
Number of References: 4

(p8.0) On top of designing a single efficient model, it is also important to obtain a family of models that can adapt to varying computational budgets. An important principle for addressing this issue is compound scaling [29,82], which indicates that simultaneously increasing the depth, width and input resolution of a given base model will yield a family of efficient network architectures. Doll√°r et al. [137] further study how to design a proper model scaling rule in terms of the actual runtime. In addition, TinyNets [138] extend this idea to the shrinking of the model size.
## (s28) Pixel-level Dynamic Networks
Number of References: 6

(p28.0) A typical approach to spatial-wise adaptive inference is dynamically deciding whether to compute each pixel in a convolution block based on a binary mask [235,236,237]. This form is similar to that in layer skipping and channel skipping (Sec. 3.1), except that the gating module is required to output a spatial mask. Each element of this spatial mask determines the computation of a feature pixel. In this way, the mask generators learn to locate the most discriminative regions in image features, and redundant computation on less informative pixels can be skipped.

(p28.1) The limitation of such pixel-level dynamic computation is that the acceleration is currently not supported by most deep learning libraries. The memory access cost can be heavier than static convolutions, and the computation parallelism is reduced due to sparse convolution. As a result, although the computation can be significantly reduced, the practical efficiency of these methods usually lags behind their theoretical efficiency. To this end, researchers have also proposed "coarse-grained" spatial-wise dynamic networks [39,238], which means that an element of a spatial mask can decide a patch rather than a pixel. In this way, more contiguous memory access is realized for realistic speedup. Moreover, the scheduling strategies are also proven to have a considerable effect on the inference latency [39]. It is also promising to co-design algorithm, scheduling, and hardware devices to better harvest the theoretical efficiency of spatial-wise dynamic networks.
## (s30) Resolution-level Dynamic Networks
Number of References: 3

(p30.0) Most existing vision models process different images with the same resolution. However, the input complexity could vary, and not all images require a high-resolution representation. Ideally, low-resolution representations should be sufficient for those "easy" samples with large objects and canonical features. The early work [249] proposes to adaptively zoom input images in the face detection task. The recent resolution adaptive network (RANet) [217] builds a multi-scale architecture, in which inputs are first processed with a low resolution and a small sub-network. Large sub-networks and high-resolution representations are conditionally activated based on early predictions. Instead of using a specialized structure, dynamic resolution network [250] rescales each image with the resolution predicted by a small model and feeds the rescaled image to common CNNs.
## (s32) Dynamic Recurrent Models
Number of References: 5

(p32.0) Different video frames are unequally informative. To this end, extensive studies propose to dynamically activate computation when updating the hidden state in recurrent models. For example, LiteEval [251] establishes two different sized LSTM [252]. In each time step, a gating module is used to decide which LSTM should be executed for processing the current frame. AdaFuse [253] dynamically skips the computation of some convolution channels, and these channels are filled with the hidden state from the previous step. Moreover, the numerical precision [254] and image resolution [255] of different frames can also be dynamically decided.
## (s33) Dynamic Key Frame Sampling
Number of References: 8

(p33.0) An alternative to skipping computation in recurrent networks is sampling key frames and then feeding the sampled frames rather than the whole video to a standard model. Reinforcement learning is a popular technique for training frame samplers [261,262,263].

(p33.1) A recent trend is simultaneously achieving dynamic inference from multiple perspectives. For example, AdaFocus and its variants [38,264,265,266] makes use of both spatial and temporal redundancy in video data. Dynamic architecture with 3D convolution [267] is also an interesting topic.
## (s44) Two-stage Approaches
Number of References: 6

(p44.0) From the lens of efficiency, a notable milestone of deep-learning-based instance segmentation is the proposing of Mask R-CNN [318]. Mask R-CNN is developed by introducing mask segmentation branches on the basis of Faster R-CNN [272]. It enjoys high computational efficiency by directly obtaining the regions of interest from the feature maps. In contrast, MaskLab [319] improved Faster R-CNN by adding the semantic segmentation and direction prediction paths. To improve the accuracy of Mask R-CNN, MS R-CNN [320] predicts the quality of the predicted instance masks and prioritizes more accurate mask predictions during validation. PANet [321] introduces a path augmentation mechanism to facilitate the bottom-up information interaction of feature maps. HTC [322] proposes a hybrid task cascade framework to learn more discriminative features progressively while integrating complementary features in the meantime.
## (s58) Hardware-aware Model Design
Number of References: 7

(p58.0) As the practical latency of models can be influenced by many factors other than theoretical computation, the commonly used FLOPs is an inaccurate proxy for network efficiency. Ideally, one should develop efficient models based on specific hardware properties. However, hand-designing networks for different hardware devices can be laborious. Therefore, automatically searching for efficient architectures is emerging as a promising direction. Compared to the traditional NAS methods [31,414], this line of works can generate appropriate models which satisfy different hardware constraints and gain realistic efficiency in practice. For example, ProxylessNAS [54] establishes a latency prediction function based on realistic tests on targeted hardware, and the predicted latency is then directly used as a regularization item in the NAS objective. A similar idea is also implemented by MnasNet [53] to search for efficient models on mobile devices. The following works FBNet [159], FBNet-v2 [415] and OFA [416] have improved NAS techniques.
## (s63) Developing Task-specialized Models
Number of References: 6

(p63.0) In addition to the architectural advancements in backbone models, tailoring deep learning methodologies to specific computer vision tasks of interest has been demonstrated as crucial. Two research challenges of particular significance in this domain can be identified. Firstly, the exploitation of representations extracted by backbones to efficiently obtain task-specific features is essential, for example, multi-scale features for object detection and multi-path fused features for semantic segmentation. A potential solution to this challenge could involve designing specialized, efficient decoders (e.g., utilizing NAS [311,437]). Secondly, it is important to streamline the multi-stage design of visual tasks (e.g., two-stage object detection [273] and instance segmentation [318] algorithms) to achieve end-to-end paradigms with minimal performance compromises. Additionally, the removal of time-consuming components, such as non-maximum suppression (NMS) [8], is crucial. A promising area for future research may involve the development of an efficient, unified, and end-to-end learnable interface for a majority of prevalent computer vision tasks [438].
## (s65) Leveraging Large-scale Training Data
Number of References: 11

(p65.0) Contemporary large visual backbone models have exhibited remarkable scalability in response to the increasing volumes of training data [6], that is, the model's performance consistently enhances as more train-ing data becomes accessible. However, it is generally arduous for computationally efficient models with a reduced number of parameters to capitalize on this high-data regime to the same extent as their larger counterparts. For example, the improvements attained by pre-training light-weighted models on expansive ImageNet-22K/JFT datasets are typically inferior to those observed in larger models [6,7,74]. This challenge is similarly experienced by self-supervised learning algorithms, where the methods effective for larger models frequently produce limited gains for smaller models [440,441]. As a result, a propitious avenue of research involves the exploration of effective scalable supervised and unsupervised learning algorithms for light-weighted models, allowing them to reap the benefits of an unlimited amount of data without incurring the expense of acquiring annotations. Some recent works on novel training algorithms have started to preliminarily explore this direction [82,442,443,444,445].
