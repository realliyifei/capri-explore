# Control strategies for active lower extremity prosthetics and orthotics: a review Tucker et al. Control strategies for active lower extremity prosthetics and orthotics: a review

CorpusID: 255962315 - [https://www.semanticscholar.org/paper/a8625ac3f5d642095e8990be170a1017612aa621](https://www.semanticscholar.org/paper/a8625ac3f5d642095e8990be170a1017612aa621)

Fields: Medicine, Engineering

## (s0) Definitions, scope and prior work
Number of References: 18

(p0.0) Adopting the terminology provided by the review of Herr [10], the term exoskeleton is used to describe a device that enhances the physical capabilities of an able-bodied user, whereas the term orthosis is used to describe a device used to assist a person with an impairment of the limbs. Though exceptions exist, orthoses and exoskeletons typically act in parallel with the limb. A prosthesis is a device which supplants a missing limb, and therefore acts in series with the residual limb. http://www.jneuroengrehab.com/content/12/1/1 Several related review papers have been published in recent years that comprehensively establish the state-ofthe-art in portable and active lower limb prosthetics, orthotics and exoskeletons, mostly in terms of the design and hardware realization [10][11][12][13][14][15]. While these reviews do touch on some of the implemented control strategies, the holistic descriptions of the considered devices often do not leave room to ruminate on this particular subject. Chapters 4 and 5 of [16] provide a nice depth of theory regarding cognitive and physical human-robot interaction, which complements the breadth of practical examples provided herein.

(p0.1) Controllers for robotic prosthetic, orthotic and exoskeletal systems for the ankle were recently reviewed by Jimenez-Fabian and Verlinden [17]. The present work extends their review by considering controllers for the hip, knee and ankle, with special emphasis on P/O devices. The discussion and classification of controllers herein is structured and enhanced by the provision of a generalized control framework. Furthermore, this architecture is also proposed as a template for the development of the next generation of multifunctional controllers for active lower limb P/O devices.
## (s1) Generalized control framework
Number of References: 4

(p1.0) To structure the classification and discussion of the various control approaches for active lower limb P/Os, we propose the generalized framework of Figure 1. This framework was inspired by and extended from that of Varol et al. 2010 [24] to be applied to a wider range of devices (i.e. prostheses and orthoses) and joints (i.e. hip, knee and ankle). The diagram reflects the physical interaction and signal-level feedback loops underlying powered assistive devices during practical use. The major subsystems include a hierarchical control structure, the user of the P/O device, the environment through which he ambulates, and the device itself. The framework has been generalized to describe "what" each component of the hierarchical controller should do rather than "how" it should be done. Safety layers have been included to emphasize the importance of safe human-robot interaction, especially considering the amount of power such devices can generate. Furthermore, the structure of the rest of the paper follows that of this framework, which provides a holistic consideration of the challenges facing P/O control developments today.
## (s4) Compensatory and assisted control of locomotion
Number of References: 22

(p4.0) In the wake of a neurologic injury or limb amputation, parts of the sensory-motor control loop responsible for locomotion may be disrupted and would need to be assisted or even taken over by a P/O device. Stemming from the inherent adaptability and plasticity of the CNS, compensatory mechanisms may arise to counteract the loss of structure and function post-disease or injury. These are typically manifested as a gait abnormality and may range from a simple limp to a total inability to walk, any of which may be considered to be the optimal outcome for a given condition [32]. Thus, the P/O controller must be robust enough to accommodate gait patterns that are potentially far-removed from the nominal condition.

(p4.1) Pathological gait has also been linked to numerous secondary conditions, including increased energy expenditure [37], increased risk and fear of falling [38,39], and degenerative bone and joint disorders (e.g. osteoarthritis, osteopenia/osteoporosis, and back pain). These will not only involve the affected limb, but also the unaffected limb and others involved in compensatory movements [15,40].

(p4.2) The purpose of a powered assistive device is to interface with the residual neuromusculoskeletal structures such that the support, control and actuation loops are reconnected. This provides the immediate benefit of reenabling locomotive ADL, and potentially the long-term benefit of rehabilitating and retraining physiological gait patterns over time. This may result in a "spiral of adaptation" as the user adapts to the new conditions imposed by the use of a P/O device, and that the device itself may need to adapt to the evolving needs of the user [41].

(p4.3) Based on the review of Marchal-Crespo and Reinkensmeyer [20], most training paradigms for gait rehabilitation can be classified into two groups. An assistive controller directly helps the user in moving their affected limbs in accordance with the desired movement. A challengebased controller could be used to provoke motor plasticity within the user by making movements more difficult through, for example, error amplification. While there remains some debate regarding which of these strategies would provide the most lasting rehabilitative benefit to the user when employed during a dedicated therapy session [42], intuition indicates that an assistive controller would provide the most utility in the performance of ADL in a real-world setting. This may at least partially explain why, within the scope of the devices covered in this review, no examples of challenge-based controllers were found.

(p4.4) It is left as an open question whether one of the control objectives of the device should be to minimize the user's exhibition of compensatory mechanisms or whether restoration of functional ADLs is sufficient. In either case, an oft-cited hypothesis motivating the development of active P/Os is that only an actuated device would be capable of providing the full power-output capabilities of the corresponding physiological joints, and could thus enable gait patterns resembling those of unaffected persons across a wide variety of activities and terrain [15,43]. The corollary is that the aforementioned secondary conditions could be prevented -providing a direct benefit for the user and a potential incentive for health care and insurance providers to opt for an active device as opposed to a passive one.
## (s5) Sensor modalities for motion intention estimation
Number of References: 6

(p5.0) The intention of a user to execute a movement can be estimated through the sensing of cortical and neuromuscular activity, posture, locomotive state, and physical http://www.jneuroengrehab.com/content/12/1/1 interaction with the environment and the P/O device. The sensor modalities corresponding to each of these differ widely in terms of their relative invasiveness and the richness of the provided information [15]. Here, invasiveness is intended to indicate the relative ease (in time, effort, and risk) with which a sensor may be applied and removed. These range from completely noninvasive (e.g. fully embedded within the device) to highly invasive (e.g. surgically implanting electrode arrays in the motor cortex) [15]. The richness of information is related to both the variety of discernible activities and the specificity of motion intention obtainable through a given modality.

(p5.1) The optimization to be performed is to maximize the richness of information while minimizing the invasiveness of the required instrumentation. From a practical standpoint, the error threshold for correctly identifying the user's motion intentions needs to be such that he neither gets frustrated (or potentially injured) by incorrect estimates, nor feels like a Christmas tree due to the "decoration" of one's self with a multitude of sensors with each donning and doffing of the device. The level of invasiveness required must also correspond to the severity of the morbidities stemming from the underlying condition. Societal acceptance and cosmesis are also critical practicality issues [44].
## (s6) Supraspinal neural activity
Number of References: 72

(p6.0) Recalling that motor intentions originate at the cortical level, several groups have investigated methods for triggering the device to provide assistance through Brain-Computer Interfaces (BCI) [45]. Recording of activity at this level has the potential to allow for a wide-variety of volitional movements, however, these may be difficult to decipher given that the brain is concurrently responsible for a multitude of tasks, including the control of the other limbs. In addition, many of the control loops responsible for physiological locomotion take place at the spinal level via reflex arcs (Figure 2), which may fundamentally preclude the use of neural activity to directly control the legs while maintaining balance during a dynamic task. However, there may still be utility in using brain activity to provide high-level commands to the device, which it will then execute (as in the shared control context promoted in [45][46][47] and demonstrated in [48,49]).

(p6.1) Functional near-infrared spectroscopy (fNIRS) uses optical light emitters and receivers placed on the scalp to sense the haemodynamic response of the brain, which correlates with brain activity. This modality is subject to non-specific brain activity, motion artifacts, significant haemodynamic delay, and requires that optodes be worn on the head. Even so, a recent pilot study investigated the use of an fNIRS-BCI to detect the preparation for movement of the hip in seated stroke subjects, which may indicate its suitability in shared control with severely impaired subjects [50].

(p6.2) Electroencephalography (EEG) uses an array of surface electrodes to non-invasively record the electrical activity of the brain as evident on the scalp [45]. The EEG electrode arrays typically used in research are built into a snug-fitting skull cap that can be extremely difficult and time-consuming to put on by oneself, especially for the patient groups whose injuries would necessitate direct cortical input to the P/O controller. This supposedly could be countered with advancements in self-contained EEG headsets designed for consumer use. The electrodes can be either dry or wet, depending on whether an electrically conductive gel is required. Signals recorded via EEG can encode a wide variety of movements with high temporal resolution.

(p6.3) In practice, the use of EEG signals demands a high level of focus and concentration from the user and is susceptible to movement artifacts, autonomic neural activity and electrical noise. Use in real-world environments is further complicated by the presence of distractions and the performance of tasks that are unrelated to locomotion. However, EEG signals could be combined with other sensory inputs in the framework of the so-called hybrid BCIs [51,52] in order to decode user's high-level commands more reliably.

(p6.4) Environmental sensing (see section below) can add an additional layer of safety in the context of shared control with BCIs, as the controller may prevent certain movements due to the presence of obstacles [47]. For example, prior to executing a high-level command (e.g. go forward, turn left), the controller would check first whether there are any terrain features in the way. Similarly, the execution of the high-level command "sit down" would not require the user to align perfectly with the chair, but would rely on the controller's ability to compensate for the misalignment. As these examples illustrate, shared control reduces cognitive workload, as the user does not need to care about the mid-to-low-level execution over long periods of time or during critical operations.

(p6.5) Implanted electrode arrays within the motor cortex enable measurements which may encode a wide variety of movements, with the noted downside of requiring a highly invasive (and still experimental) surgical procedure [15,53,54]. Such an interface may also be used to provide sensory feedback to the user, thus closing the sensory-motor control loop [54]. Intracortical electrode arrays have been successfully demonstrated to allow control of multi-degree-of-freedom reach and grasp movements with robotic arms in tetraplegic subjects [55,56], http://www.jneuroengrehab.com/content/12/1/1 though to date there are no known examples of corticallyimplanted electrodes being used to control a lower limb device in humans. Similar experiments have been done, however, in rhesus macaques to demonstrate the prediction of leg movements to control of bipedal gait in a humanoid robot [57]. It remains to be demonstrated how well this technique would translate to the control of a wearable P/O device.

(p6.6) Recalling that motor intentions originate at the cortical level, several groups have investigated methods for triggering the device to provide assistance through Brain-Computer Interfaces (BCI) [45]. Recording of activity at this level has the potential to allow for a wide-variety of volitional movements, however, these may be difficult to decipher given that the brain is concurrently responsible for a multitude of tasks, including the control of the other limbs. In addition, many of the control loops responsible for physiological locomotion take place at the spinal level via reflex arcs (Figure 2), which may fundamentally preclude the use of neural activity to directly control the legs while maintaining balance during a dynamic task. However, there may still be utility in using brain activity to provide high-level commands to the device, which it will then execute (as in the shared control context promoted in [45][46][47] and demonstrated in [48,49]).

(p6.7) Functional near-infrared spectroscopy (fNIRS) uses optical light emitters and receivers placed on the scalp to sense the haemodynamic response of the brain, which correlates with brain activity. This modality is subject to non-specific brain activity, motion artifacts, significant haemodynamic delay, and requires that optodes be worn on the head. Even so, a recent pilot study investigated the use of an fNIRS-BCI to detect the preparation for movement of the hip in seated stroke subjects, which may indicate its suitability in shared control with severely impaired subjects [50].

(p6.8) Electroencephalography (EEG) uses an array of surface electrodes to non-invasively record the electrical activity of the brain as evident on the scalp [45]. The EEG electrode arrays typically used in research are built into a snug-fitting skull cap that can be extremely difficult and time-consuming to put on by oneself, especially for the patient groups whose injuries would necessitate direct cortical input to the P/O controller. This supposedly could be countered with advancements in self-contained EEG headsets designed for consumer use. The electrodes can be either dry or wet, depending on whether an electrically conductive gel is required. Signals recorded via EEG can encode a wide variety of movements with high temporal resolution.

(p6.9) In practice, the use of EEG signals demands a high level of focus and concentration from the user and is susceptible to movement artifacts, autonomic neural activity and electrical noise. Use in real-world environments is further complicated by the presence of distractions and the performance of tasks that are unrelated to locomotion. However, EEG signals could be combined with other sensory inputs in the framework of the so-called hybrid BCIs [51,52] in order to decode user's high-level commands more reliably.

(p6.10) Environmental sensing (see section below) can add an additional layer of safety in the context of shared control with BCIs, as the controller may prevent certain movements due to the presence of obstacles [47]. For example, prior to executing a high-level command (e.g. go forward, turn left), the controller would check first whether there are any terrain features in the way. Similarly, the execution of the high-level command "sit down" would not require the user to align perfectly with the chair, but would rely on the controller's ability to compensate for the misalignment. As these examples illustrate, shared control reduces cognitive workload, as the user does not need to care about the mid-to-low-level execution over long periods of time or during critical operations.

(p6.11) Implanted electrode arrays within the motor cortex enable measurements which may encode a wide variety of movements, with the noted downside of requiring a highly invasive (and still experimental) surgical procedure [15,53,54]. Such an interface may also be used to provide sensory feedback to the user, thus closing the sensory-motor control loop [54]. Intracortical electrode arrays have been successfully demonstrated to allow control of multi-degree-of-freedom reach and grasp movements with robotic arms in tetraplegic subjects [55,56], http://www.jneuroengrehab.com/content/12/1/1 though to date there are no known examples of corticallyimplanted electrodes being used to control a lower limb device in humans. Similar experiments have been done, however, in rhesus macaques to demonstrate the prediction of leg movements to control of bipedal gait in a humanoid robot [57]. It remains to be demonstrated how well this technique would translate to the control of a wearable P/O device.
## (s8) Joint torques and positions
Number of References: 16

(p8.0) Mechanomyography (MMG) can be used to estimate the force production in muscle by measuring the sound or vibrations evident on the surface of the skin using microphones or accelerometers [68]. A potential advantage of MMG over EMG is that the muscle force estimated through MMG is less sensitive to fatigue [69]. Force production can also be estimated via changes in muscle hardness [70,71] and the volume of the muscle [72,73]. A substantial downside to all of these approaches is their high sensitivity to motion artifacts, which may be significant given the nature of the physical coupling at the user-device interface.

(p8.1) Joint torques can be estimated via inverse dynamics provided measurements of the joint positions and external forces being applied to the limbs. Wearable sensors for estimating joint positions or limb segment orientations are summarized in [74] and include goniometers, inclinometers, accelerometers, gyroscopes, magnetometers, and inertial measurement units (IMUs). Ground reaction forces can be sensed using instrumented insoles worn under the foot (reviewed in [75]) or e.g. by measuring the load in the shank of a prosthesis. A variety of foot switches can also be used to deliver binary ground contact information, for example using force-sensitive resistors, sensed air pressure in a sealed tube under the foot, or a physical switch.
## (s13) Explicit environmental sensing
Number of References: 6

(p13.0) Scandaroli et al. presented a method using gyroscopes and infrared sensors [112] for estimation of the ground slope and elevation of the foot above the ground. In this application, two single-axis gyroscopes and four distancemeasuring infrared sensors were mounted underneath a prosthetic foot. So far, only bench-top test results have been presented. Zhang et al. presented a "Terrain Recognition System" comprised of a body-worn laser distance sensor and IMUs fixed to the limbs [113]. The system estimates the height and slope of the terrain and was tested using an unassisted, able-bodied user with the laser sensor attached to the waist. An array of sonar sensors and digital video cameras was used to detect obtacles, which was used in the shared control context allow/disallow user commands with a brain-controlled wheelchair [47]. This approach could easily be extended to P/O devices.
## (s16) High-level control
Number of References: 12

(p16.0) The purpose of the high-level controller is to perceive the locomotive intent of the user through a combination of activity mode detection and direct volitional control. Depending on the user's underlying pathology, the ability to generate, transmit, and execute appropriate locomotor commands may be impaired at some level. Therefore, once the user has provided a high-level command, the device should be responsible for the execution of movement via the mid-and low-level controllers. This shared control approach limits the cognitive burden imposed on the user [45,46].

(p16.1) The desired high-level control output allows for the device to autonomously switch between different locomotive activities, ideally without imposing any conscious inputs from the user. Activity mode recognition can be coupled with direct volitional control to provide the user the ability to modulate the device's behavior within a particular activity [120]. It is also possible to provide direct volitional control of the device in the absence of activity mode recognition.

(p16.2) The purpose of the high-level controller is to perceive the locomotive intent of the user through a combination of activity mode detection and direct volitional control. Depending on the user's underlying pathology, the ability to generate, transmit, and execute appropriate locomotor commands may be impaired at some level. Therefore, once the user has provided a high-level command, the device should be responsible for the execution of movement via the mid-and low-level controllers. This shared control approach limits the cognitive burden imposed on the user [45,46].

(p16.3) The desired high-level control output allows for the device to autonomously switch between different locomotive activities, ideally without imposing any conscious inputs from the user. Activity mode recognition can be coupled with direct volitional control to provide the user the ability to modulate the device's behavior within a particular activity [120]. It is also possible to provide direct volitional control of the device in the absence of activity mode recognition.
## (s23) Coordinated motion control and load sharing
Number of References: 14

(p23.0) Prosthetic and orthotic devices are part of an overall system involving physical interactions, and thus cannot operate as if in isolation. A coordinated mid-level control scheme is necessary whenever there are multiple actuated degrees of freedom, whether contained within one device [117,170,181,213,214] or distributed across multiple devices [176]. Uncoordinated motion between limbs and joints can result in loss of balance or falls, and so the states of each should be communicated and taken into account to prevent such an occurrence. Monitoring of the state of the user (e.g. ground contact state, joint positions) also provides relevant information to the controller.

(p23.1) It should also be noted that the joints in the human body are subject to biarticular coupling on both a mechanical and neural level [215]. As a result, the realizable voluntary torque output and range-of-motion (RoM) of the user's joints are functions of posture, which potentially involves joints that are not specifically actuated by the device. Considering this, the mid-level controller should take into account the configuration of the user to ensure that the device does not over-power the joint nor exceed his RoM.
## (s24) Low-level control
Number of References: 28

(p24.0) The purpose of the low-level controller (Figure 1) is to calculate the error between the device's current and desired states (i.e. the output from the mid-level controller) and to drive the actuator to reduce this error. This executionlevel of control tends to be highly device-specific, and may rely on a combination of feedforward and feedback loops. http://www.jneuroengrehab.com/content/12/1/1 Feedforward control requires some form of model to predict the system's future state based on the past and current set of inputs and device state. Such control inputs can be effective at reducing undesired interaction forces due to the added mass, inertia, and friction of the device [178].

(p24.1) Feedback controllers do not require a model of the system per se, but do require an estimate of the current state. The controller compares this with the desired state of the device and modulates the power input to the device to drive any discrepancy to zero. A wide variety of control techniques can be used to achieve this, the details of which are left to any reputable controls textbook. Many classical control strategies employ negative feedback, though the Berkeley Lower Extremity Exoskeleton (BLEEX) employs a positive feedback loop [220,221]. In this example, the net effect of the positive feedback is to increase the controller's sensitivity to the user's interactions without requiring force sensing between the user and the device. The trade-off is that very precise models of the device's dynamics are required for each of the bilateral ground contact states. This was counteracted using the hybrid control scheme outlined in subsequent work [214].

(p24.2) The physical configuration and dynamics (i.e. friction, inertia, actuator power output) of the device will fundamentally limit its ability to stably track a desired output trajectory. The performance of digitally-controlled systems is further constrained by sensor noise, signal quantization, discrete sampling effects, and control loop execution times. The use of passivity constraints (i.e. that the device is controlled to store or dissipate energy, but not add) provides a means to guarantee the stability of the device as it interacts with the user and his environment [182,200,202].

(p24.3) The purpose of the low-level controller (Figure 1) is to calculate the error between the device's current and desired states (i.e. the output from the mid-level controller) and to drive the actuator to reduce this error. This executionlevel of control tends to be highly device-specific, and may rely on a combination of feedforward and feedback loops. http://www.jneuroengrehab.com/content/12/1/1 Feedforward control requires some form of model to predict the system's future state based on the past and current set of inputs and device state. Such control inputs can be effective at reducing undesired interaction forces due to the added mass, inertia, and friction of the device [178].

(p24.4) Feedback controllers do not require a model of the system per se, but do require an estimate of the current state. The controller compares this with the desired state of the device and modulates the power input to the device to drive any discrepancy to zero. A wide variety of control techniques can be used to achieve this, the details of which are left to any reputable controls textbook. Many classical control strategies employ negative feedback, though the Berkeley Lower Extremity Exoskeleton (BLEEX) employs a positive feedback loop [220,221]. In this example, the net effect of the positive feedback is to increase the controller's sensitivity to the user's interactions without requiring force sensing between the user and the device. The trade-off is that very precise models of the device's dynamics are required for each of the bilateral ground contact states. This was counteracted using the hybrid control scheme outlined in subsequent work [214].

(p24.5) The physical configuration and dynamics (i.e. friction, inertia, actuator power output) of the device will fundamentally limit its ability to stably track a desired output trajectory. The performance of digitally-controlled systems is further constrained by sensor noise, signal quantization, discrete sampling effects, and control loop execution times. The use of passivity constraints (i.e. that the device is controlled to store or dissipate energy, but not add) provides a means to guarantee the stability of the device as it interacts with the user and his environment [182,200,202].
## (s25) The P/O device
Number of References: 14

(p25.0) The device represents the hardware embodiment of the robotic P/O. This includes the device's physical structure, actuators, embedded sensors, control system, energy storage, and power amplifiers. While the mechanical design and implementation of P/O devices is beyond the scope of this review, the hardware must be taken into account as it heavily influences the low-level control possibilities. For example, it may be difficult and inefficient to render forces with an assistive device whose actuator output impedance is high [197], conversely the maximum torque output, controllable bandwidth and the dynamic range of renderable impedance (i.e. Z-width) are reduced for an actuator with low output impedance [202].

(p25.1) Additional considerations are the performance limitations and saturation effects of the actuator and power source [14,60,170]. Even state-of-the-art portable devices must be driven beyond their continuous operating range to achieve the power outputs required during energetically demanding activities, such as sit-to-stand, stair ascent, running, or jumping [61,217]. While this is generally acceptable for short bursts, it may be necessary for the controller to derate the actuator if these conditions are sustained for long periods.
## (s29) Definitions, scope and prior work
Number of References: 18

(p29.0) Adopting the terminology provided by the review of Herr [10], the term exoskeleton is used to describe a device that enhances the physical capabilities of an able-bodied user, whereas the term orthosis is used to describe a device used to assist a person with an impairment of the limbs. Though exceptions exist, orthoses and exoskeletons typically act in parallel with the limb. A prosthesis is a device which supplants a missing limb, and therefore acts in series with the residual limb. http://www.jneuroengrehab.com/content/12/1/1 Several related review papers have been published in recent years that comprehensively establish the state-ofthe-art in portable and active lower limb prosthetics, orthotics and exoskeletons, mostly in terms of the design and hardware realization [10][11][12][13][14][15]. While these reviews do touch on some of the implemented control strategies, the holistic descriptions of the considered devices often do not leave room to ruminate on this particular subject. Chapters 4 and 5 of [16] provide a nice depth of theory regarding cognitive and physical human-robot interaction, which complements the breadth of practical examples provided herein.

(p29.1) Controllers for robotic prosthetic, orthotic and exoskeletal systems for the ankle were recently reviewed by Jimenez-Fabian and Verlinden [17]. The present work extends their review by considering controllers for the hip, knee and ankle, with special emphasis on P/O devices. The discussion and classification of controllers herein is structured and enhanced by the provision of a generalized control framework. Furthermore, this architecture is also proposed as a template for the development of the next generation of multifunctional controllers for active lower limb P/O devices.
## (s30) Generalized control framework
Number of References: 4

(p30.0) To structure the classification and discussion of the various control approaches for active lower limb P/Os, we propose the generalized framework of Figure 1. This framework was inspired by and extended from that of Varol et al. 2010 [24] to be applied to a wider range of devices (i.e. prostheses and orthoses) and joints (i.e. hip, knee and ankle). The diagram reflects the physical interaction and signal-level feedback loops underlying powered assistive devices during practical use. The major subsystems include a hierarchical control structure, the user of the P/O device, the environment through which he ambulates, and the device itself. The framework has been generalized to describe "what" each component of the hierarchical controller should do rather than "how" it should be done. Safety layers have been included to emphasize the importance of safe human-robot interaction, especially considering the amount of power such devices can generate. Furthermore, the structure of the rest of the paper follows that of this framework, which provides a holistic consideration of the challenges facing P/O control developments today.
## (s33) Compensatory and assisted control of locomotion
Number of References: 22

(p33.0) In the wake of a neurologic injury or limb amputation, parts of the sensory-motor control loop responsible for locomotion may be disrupted and would need to be assisted or even taken over by a P/O device. Stemming from the inherent adaptability and plasticity of the CNS, compensatory mechanisms may arise to counteract the loss of structure and function post-disease or injury. These are typically manifested as a gait abnormality and may range from a simple limp to a total inability to walk, any of which may be considered to be the optimal outcome for a given condition [32]. Thus, the P/O controller must be robust enough to accommodate gait patterns that are potentially far-removed from the nominal condition.

(p33.1) Pathological gait has also been linked to numerous secondary conditions, including increased energy expenditure [37], increased risk and fear of falling [38,39], and degenerative bone and joint disorders (e.g. osteoarthritis, osteopenia/osteoporosis, and back pain). These will not only involve the affected limb, but also the unaffected limb and others involved in compensatory movements [15,40].

(p33.2) The purpose of a powered assistive device is to interface with the residual neuromusculoskeletal structures such that the support, control and actuation loops are reconnected. This provides the immediate benefit of reenabling locomotive ADL, and potentially the long-term benefit of rehabilitating and retraining physiological gait patterns over time. This may result in a "spiral of adaptation" as the user adapts to the new conditions imposed by the use of a P/O device, and that the device itself may need to adapt to the evolving needs of the user [41].

(p33.3) Based on the review of Marchal-Crespo and Reinkensmeyer [20], most training paradigms for gait rehabilitation can be classified into two groups. An assistive controller directly helps the user in moving their affected limbs in accordance with the desired movement. A challengebased controller could be used to provoke motor plasticity within the user by making movements more difficult through, for example, error amplification. While there remains some debate regarding which of these strategies would provide the most lasting rehabilitative benefit to the user when employed during a dedicated therapy session [42], intuition indicates that an assistive controller would provide the most utility in the performance of ADL in a real-world setting. This may at least partially explain why, within the scope of the devices covered in this review, no examples of challenge-based controllers were found.

(p33.4) It is left as an open question whether one of the control objectives of the device should be to minimize the user's exhibition of compensatory mechanisms or whether restoration of functional ADLs is sufficient. In either case, an oft-cited hypothesis motivating the development of active P/Os is that only an actuated device would be capable of providing the full power-output capabilities of the corresponding physiological joints, and could thus enable gait patterns resembling those of unaffected persons across a wide variety of activities and terrain [15,43]. The corollary is that the aforementioned secondary conditions could be prevented -providing a direct benefit for the user and a potential incentive for health care and insurance providers to opt for an active device as opposed to a passive one.
## (s34) Sensor modalities for motion intention estimation
Number of References: 6

(p34.0) The intention of a user to execute a movement can be estimated through the sensing of cortical and neuromuscular activity, posture, locomotive state, and physical http://www.jneuroengrehab.com/content/12/1/1 interaction with the environment and the P/O device. The sensor modalities corresponding to each of these differ widely in terms of their relative invasiveness and the richness of the provided information [15]. Here, invasiveness is intended to indicate the relative ease (in time, effort, and risk) with which a sensor may be applied and removed. These range from completely noninvasive (e.g. fully embedded within the device) to highly invasive (e.g. surgically implanting electrode arrays in the motor cortex) [15]. The richness of information is related to both the variety of discernible activities and the specificity of motion intention obtainable through a given modality.

(p34.1) The optimization to be performed is to maximize the richness of information while minimizing the invasiveness of the required instrumentation. From a practical standpoint, the error threshold for correctly identifying the user's motion intentions needs to be such that he neither gets frustrated (or potentially injured) by incorrect estimates, nor feels like a Christmas tree due to the "decoration" of one's self with a multitude of sensors with each donning and doffing of the device. The level of invasiveness required must also correspond to the severity of the morbidities stemming from the underlying condition. Societal acceptance and cosmesis are also critical practicality issues [44].
## (s35) Supraspinal neural activity
Number of References: 72

(p35.0) Recalling that motor intentions originate at the cortical level, several groups have investigated methods for triggering the device to provide assistance through Brain-Computer Interfaces (BCI) [45]. Recording of activity at this level has the potential to allow for a wide-variety of volitional movements, however, these may be difficult to decipher given that the brain is concurrently responsible for a multitude of tasks, including the control of the other limbs. In addition, many of the control loops responsible for physiological locomotion take place at the spinal level via reflex arcs (Figure 2), which may fundamentally preclude the use of neural activity to directly control the legs while maintaining balance during a dynamic task. However, there may still be utility in using brain activity to provide high-level commands to the device, which it will then execute (as in the shared control context promoted in [45][46][47] and demonstrated in [48,49]).

(p35.1) Functional near-infrared spectroscopy (fNIRS) uses optical light emitters and receivers placed on the scalp to sense the haemodynamic response of the brain, which correlates with brain activity. This modality is subject to non-specific brain activity, motion artifacts, significant haemodynamic delay, and requires that optodes be worn on the head. Even so, a recent pilot study investigated the use of an fNIRS-BCI to detect the preparation for movement of the hip in seated stroke subjects, which may indicate its suitability in shared control with severely impaired subjects [50].

(p35.2) Electroencephalography (EEG) uses an array of surface electrodes to non-invasively record the electrical activity of the brain as evident on the scalp [45]. The EEG electrode arrays typically used in research are built into a snug-fitting skull cap that can be extremely difficult and time-consuming to put on by oneself, especially for the patient groups whose injuries would necessitate direct cortical input to the P/O controller. This supposedly could be countered with advancements in self-contained EEG headsets designed for consumer use. The electrodes can be either dry or wet, depending on whether an electrically conductive gel is required. Signals recorded via EEG can encode a wide variety of movements with high temporal resolution.

(p35.3) In practice, the use of EEG signals demands a high level of focus and concentration from the user and is susceptible to movement artifacts, autonomic neural activity and electrical noise. Use in real-world environments is further complicated by the presence of distractions and the performance of tasks that are unrelated to locomotion. However, EEG signals could be combined with other sensory inputs in the framework of the so-called hybrid BCIs [51,52] in order to decode user's high-level commands more reliably.

(p35.4) Environmental sensing (see section below) can add an additional layer of safety in the context of shared control with BCIs, as the controller may prevent certain movements due to the presence of obstacles [47]. For example, prior to executing a high-level command (e.g. go forward, turn left), the controller would check first whether there are any terrain features in the way. Similarly, the execution of the high-level command "sit down" would not require the user to align perfectly with the chair, but would rely on the controller's ability to compensate for the misalignment. As these examples illustrate, shared control reduces cognitive workload, as the user does not need to care about the mid-to-low-level execution over long periods of time or during critical operations.

(p35.5) Implanted electrode arrays within the motor cortex enable measurements which may encode a wide variety of movements, with the noted downside of requiring a highly invasive (and still experimental) surgical procedure [15,53,54]. Such an interface may also be used to provide sensory feedback to the user, thus closing the sensory-motor control loop [54]. Intracortical electrode arrays have been successfully demonstrated to allow control of multi-degree-of-freedom reach and grasp movements with robotic arms in tetraplegic subjects [55,56], http://www.jneuroengrehab.com/content/12/1/1 though to date there are no known examples of corticallyimplanted electrodes being used to control a lower limb device in humans. Similar experiments have been done, however, in rhesus macaques to demonstrate the prediction of leg movements to control of bipedal gait in a humanoid robot [57]. It remains to be demonstrated how well this technique would translate to the control of a wearable P/O device.

(p35.6) Recalling that motor intentions originate at the cortical level, several groups have investigated methods for triggering the device to provide assistance through Brain-Computer Interfaces (BCI) [45]. Recording of activity at this level has the potential to allow for a wide-variety of volitional movements, however, these may be difficult to decipher given that the brain is concurrently responsible for a multitude of tasks, including the control of the other limbs. In addition, many of the control loops responsible for physiological locomotion take place at the spinal level via reflex arcs (Figure 2), which may fundamentally preclude the use of neural activity to directly control the legs while maintaining balance during a dynamic task. However, there may still be utility in using brain activity to provide high-level commands to the device, which it will then execute (as in the shared control context promoted in [45][46][47] and demonstrated in [48,49]).

(p35.7) Functional near-infrared spectroscopy (fNIRS) uses optical light emitters and receivers placed on the scalp to sense the haemodynamic response of the brain, which correlates with brain activity. This modality is subject to non-specific brain activity, motion artifacts, significant haemodynamic delay, and requires that optodes be worn on the head. Even so, a recent pilot study investigated the use of an fNIRS-BCI to detect the preparation for movement of the hip in seated stroke subjects, which may indicate its suitability in shared control with severely impaired subjects [50].

(p35.8) Electroencephalography (EEG) uses an array of surface electrodes to non-invasively record the electrical activity of the brain as evident on the scalp [45]. The EEG electrode arrays typically used in research are built into a snug-fitting skull cap that can be extremely difficult and time-consuming to put on by oneself, especially for the patient groups whose injuries would necessitate direct cortical input to the P/O controller. This supposedly could be countered with advancements in self-contained EEG headsets designed for consumer use. The electrodes can be either dry or wet, depending on whether an electrically conductive gel is required. Signals recorded via EEG can encode a wide variety of movements with high temporal resolution.

(p35.9) In practice, the use of EEG signals demands a high level of focus and concentration from the user and is susceptible to movement artifacts, autonomic neural activity and electrical noise. Use in real-world environments is further complicated by the presence of distractions and the performance of tasks that are unrelated to locomotion. However, EEG signals could be combined with other sensory inputs in the framework of the so-called hybrid BCIs [51,52] in order to decode user's high-level commands more reliably.

(p35.10) Environmental sensing (see section below) can add an additional layer of safety in the context of shared control with BCIs, as the controller may prevent certain movements due to the presence of obstacles [47]. For example, prior to executing a high-level command (e.g. go forward, turn left), the controller would check first whether there are any terrain features in the way. Similarly, the execution of the high-level command "sit down" would not require the user to align perfectly with the chair, but would rely on the controller's ability to compensate for the misalignment. As these examples illustrate, shared control reduces cognitive workload, as the user does not need to care about the mid-to-low-level execution over long periods of time or during critical operations.

(p35.11) Implanted electrode arrays within the motor cortex enable measurements which may encode a wide variety of movements, with the noted downside of requiring a highly invasive (and still experimental) surgical procedure [15,53,54]. Such an interface may also be used to provide sensory feedback to the user, thus closing the sensory-motor control loop [54]. Intracortical electrode arrays have been successfully demonstrated to allow control of multi-degree-of-freedom reach and grasp movements with robotic arms in tetraplegic subjects [55,56], http://www.jneuroengrehab.com/content/12/1/1 though to date there are no known examples of corticallyimplanted electrodes being used to control a lower limb device in humans. Similar experiments have been done, however, in rhesus macaques to demonstrate the prediction of leg movements to control of bipedal gait in a humanoid robot [57]. It remains to be demonstrated how well this technique would translate to the control of a wearable P/O device.
## (s37) Joint torques and positions
Number of References: 16

(p37.0) Mechanomyography (MMG) can be used to estimate the force production in muscle by measuring the sound or vibrations evident on the surface of the skin using microphones or accelerometers [68]. A potential advantage of MMG over EMG is that the muscle force estimated through MMG is less sensitive to fatigue [69]. Force production can also be estimated via changes in muscle hardness [70,71] and the volume of the muscle [72,73]. A substantial downside to all of these approaches is their high sensitivity to motion artifacts, which may be significant given the nature of the physical coupling at the user-device interface.

(p37.1) Joint torques can be estimated via inverse dynamics provided measurements of the joint positions and external forces being applied to the limbs. Wearable sensors for estimating joint positions or limb segment orientations are summarized in [74] and include goniometers, inclinometers, accelerometers, gyroscopes, magnetometers, and inertial measurement units (IMUs). Ground reaction forces can be sensed using instrumented insoles worn under the foot (reviewed in [75]) or e.g. by measuring the load in the shank of a prosthesis. A variety of foot switches can also be used to deliver binary ground contact information, for example using force-sensitive resistors, sensed air pressure in a sealed tube under the foot, or a physical switch.
## (s42) Explicit environmental sensing
Number of References: 6

(p42.0) Scandaroli et al. presented a method using gyroscopes and infrared sensors [112] for estimation of the ground slope and elevation of the foot above the ground. In this application, two single-axis gyroscopes and four distancemeasuring infrared sensors were mounted underneath a prosthetic foot. So far, only bench-top test results have been presented. Zhang et al. presented a "Terrain Recognition System" comprised of a body-worn laser distance sensor and IMUs fixed to the limbs [113]. The system estimates the height and slope of the terrain and was tested using an unassisted, able-bodied user with the laser sensor attached to the waist. An array of sonar sensors and digital video cameras was used to detect obtacles, which was used in the shared control context allow/disallow user commands with a brain-controlled wheelchair [47]. This approach could easily be extended to P/O devices.
## (s45) High-level control
Number of References: 12

(p45.0) The purpose of the high-level controller is to perceive the locomotive intent of the user through a combination of activity mode detection and direct volitional control. Depending on the user's underlying pathology, the ability to generate, transmit, and execute appropriate locomotor commands may be impaired at some level. Therefore, once the user has provided a high-level command, the device should be responsible for the execution of movement via the mid-and low-level controllers. This shared control approach limits the cognitive burden imposed on the user [45,46].

(p45.1) The desired high-level control output allows for the device to autonomously switch between different locomotive activities, ideally without imposing any conscious inputs from the user. Activity mode recognition can be coupled with direct volitional control to provide the user the ability to modulate the device's behavior within a particular activity [120]. It is also possible to provide direct volitional control of the device in the absence of activity mode recognition.

(p45.2) The purpose of the high-level controller is to perceive the locomotive intent of the user through a combination of activity mode detection and direct volitional control. Depending on the user's underlying pathology, the ability to generate, transmit, and execute appropriate locomotor commands may be impaired at some level. Therefore, once the user has provided a high-level command, the device should be responsible for the execution of movement via the mid-and low-level controllers. This shared control approach limits the cognitive burden imposed on the user [45,46].

(p45.3) The desired high-level control output allows for the device to autonomously switch between different locomotive activities, ideally without imposing any conscious inputs from the user. Activity mode recognition can be coupled with direct volitional control to provide the user the ability to modulate the device's behavior within a particular activity [120]. It is also possible to provide direct volitional control of the device in the absence of activity mode recognition.
## (s52) Coordinated motion control and load sharing
Number of References: 14

(p52.0) Prosthetic and orthotic devices are part of an overall system involving physical interactions, and thus cannot operate as if in isolation. A coordinated mid-level control scheme is necessary whenever there are multiple actuated degrees of freedom, whether contained within one device [117,170,181,213,214] or distributed across multiple devices [176]. Uncoordinated motion between limbs and joints can result in loss of balance or falls, and so the states of each should be communicated and taken into account to prevent such an occurrence. Monitoring of the state of the user (e.g. ground contact state, joint positions) also provides relevant information to the controller.

(p52.1) It should also be noted that the joints in the human body are subject to biarticular coupling on both a mechanical and neural level [215]. As a result, the realizable voluntary torque output and range-of-motion (RoM) of the user's joints are functions of posture, which potentially involves joints that are not specifically actuated by the device. Considering this, the mid-level controller should take into account the configuration of the user to ensure that the device does not over-power the joint nor exceed his RoM.
## (s53) Low-level control
Number of References: 28

(p53.0) The purpose of the low-level controller (Figure 1) is to calculate the error between the device's current and desired states (i.e. the output from the mid-level controller) and to drive the actuator to reduce this error. This executionlevel of control tends to be highly device-specific, and may rely on a combination of feedforward and feedback loops. http://www.jneuroengrehab.com/content/12/1/1 Feedforward control requires some form of model to predict the system's future state based on the past and current set of inputs and device state. Such control inputs can be effective at reducing undesired interaction forces due to the added mass, inertia, and friction of the device [178].

(p53.1) Feedback controllers do not require a model of the system per se, but do require an estimate of the current state. The controller compares this with the desired state of the device and modulates the power input to the device to drive any discrepancy to zero. A wide variety of control techniques can be used to achieve this, the details of which are left to any reputable controls textbook. Many classical control strategies employ negative feedback, though the Berkeley Lower Extremity Exoskeleton (BLEEX) employs a positive feedback loop [220,221]. In this example, the net effect of the positive feedback is to increase the controller's sensitivity to the user's interactions without requiring force sensing between the user and the device. The trade-off is that very precise models of the device's dynamics are required for each of the bilateral ground contact states. This was counteracted using the hybrid control scheme outlined in subsequent work [214].

(p53.2) The physical configuration and dynamics (i.e. friction, inertia, actuator power output) of the device will fundamentally limit its ability to stably track a desired output trajectory. The performance of digitally-controlled systems is further constrained by sensor noise, signal quantization, discrete sampling effects, and control loop execution times. The use of passivity constraints (i.e. that the device is controlled to store or dissipate energy, but not add) provides a means to guarantee the stability of the device as it interacts with the user and his environment [182,200,202].

(p53.3) The purpose of the low-level controller (Figure 1) is to calculate the error between the device's current and desired states (i.e. the output from the mid-level controller) and to drive the actuator to reduce this error. This executionlevel of control tends to be highly device-specific, and may rely on a combination of feedforward and feedback loops. http://www.jneuroengrehab.com/content/12/1/1 Feedforward control requires some form of model to predict the system's future state based on the past and current set of inputs and device state. Such control inputs can be effective at reducing undesired interaction forces due to the added mass, inertia, and friction of the device [178].

(p53.4) Feedback controllers do not require a model of the system per se, but do require an estimate of the current state. The controller compares this with the desired state of the device and modulates the power input to the device to drive any discrepancy to zero. A wide variety of control techniques can be used to achieve this, the details of which are left to any reputable controls textbook. Many classical control strategies employ negative feedback, though the Berkeley Lower Extremity Exoskeleton (BLEEX) employs a positive feedback loop [220,221]. In this example, the net effect of the positive feedback is to increase the controller's sensitivity to the user's interactions without requiring force sensing between the user and the device. The trade-off is that very precise models of the device's dynamics are required for each of the bilateral ground contact states. This was counteracted using the hybrid control scheme outlined in subsequent work [214].

(p53.5) The physical configuration and dynamics (i.e. friction, inertia, actuator power output) of the device will fundamentally limit its ability to stably track a desired output trajectory. The performance of digitally-controlled systems is further constrained by sensor noise, signal quantization, discrete sampling effects, and control loop execution times. The use of passivity constraints (i.e. that the device is controlled to store or dissipate energy, but not add) provides a means to guarantee the stability of the device as it interacts with the user and his environment [182,200,202].
## (s54) The P/O device
Number of References: 14

(p54.0) The device represents the hardware embodiment of the robotic P/O. This includes the device's physical structure, actuators, embedded sensors, control system, energy storage, and power amplifiers. While the mechanical design and implementation of P/O devices is beyond the scope of this review, the hardware must be taken into account as it heavily influences the low-level control possibilities. For example, it may be difficult and inefficient to render forces with an assistive device whose actuator output impedance is high [197], conversely the maximum torque output, controllable bandwidth and the dynamic range of renderable impedance (i.e. Z-width) are reduced for an actuator with low output impedance [202].

(p54.1) Additional considerations are the performance limitations and saturation effects of the actuator and power source [14,60,170]. Even state-of-the-art portable devices must be driven beyond their continuous operating range to achieve the power outputs required during energetically demanding activities, such as sit-to-stand, stair ascent, running, or jumping [61,217]. While this is generally acceptable for short bursts, it may be necessary for the controller to derate the actuator if these conditions are sustained for long periods.
