# Convergence of Edge Computing and Deep Learning: A Comprehensive Survey

CorpusID: 197935335 - [https://www.semanticscholar.org/paper/4cd03cd34e7e94d1b1ee293d5dead8efc24c1a6d](https://www.semanticscholar.org/paper/4cd03cd34e7e94d1b1ee293d5dead8efc24c1a6d)

Fields: Computer Science, Engineering

## (s5) B. Deep Reinforcement Learning (DRL)
Number of References: 5

(p5.0) As depicted in Fig. 8, the goal of RL is to enable an agent in the environment to take the best action in the current state to maximize long-term gains, where the interaction between the agent's action and state through the environment is modeled as a Markov Decision Process (MDP). DRL is the combination of DL and RL, but it focuses more on RL and aims to solve decision-making problems. The role of DL is to use the powerful representation ability of DNNs to fit the value function or the direct strategy to solve the explosion of state-action space or continuous state-action space problem. By virtue of these characteristics, DRL becomes a powerful solution in robotics, finance, recommendation system, wireless communication, etc [18], [72].  1) Value-based DRL: As a representative of value-based DRL, Deep Q-Learning (DQL) uses DNNs to fit action values, successfully mapping high-dimensional input data to actions [73]. In order to ensure stable convergence of training, experience replay method is adopted to break the correlation between transition information and a separate target network is set up to suppress instability. Besides, Double Deep Q-Learning (Double-DQL) can deal with that DQL generally overestimating action values [74], and Dueling Deep Q-Learning (Dueling-DQL) [75] can learn which states are (or are not) valuable without having to learn the effect of each action at each state.
## (s10) A. Real-time Video Analytic
Number of References: 4

(p10.0) Real-time video analytic is important in various fields, such as automatic pilot, VR and Augmented Reality (AR), smart surveillance, etc. In general, applying DL for it requires high computation and storage resources. Unfortunately, executing these tasks in the cloud often incurs high bandwidth consumption, unexpected latency, and reliability issues. With the development of edge computing, those problems tend to be addressed by moving video analysis near to the data source, viz., end devices or edge nodes, as the complementary of the cloud. In this section, as depicted in Fig. 10, we summarize related works as a hybrid hierarchical architecture, which is divided into three levels: end, edge, and cloud.  1) End Level: At the end level, video capture devices, such as smartphones and surveillance cameras are responsible for video capture, media data compression [89], image preprocessing, and image segmentation [90]. By coordinating with these participated devices, collaboratively training a domain-aware adaptation model can lead to better object recognition accuracy when used together with a domainconstrained deep model [91]. Besides, in order to appropriately offload the DL computation to the end devices, the edge nodes or the cloud, end devices should comprehensively consider tradeoffs between video compression and key metrics, e.g., network condition, data usage, battery consumption, processing delay, frame rate and accuracy of analytics, and thus determine the optimal offloading strategy [89].
## (s12) C. Intelligent Manufacturing
Number of References: 3

(p12.0) Two most important principles in the intelligent manufacturing era are automation and data analysis, the former one of which is the main target and the latter one is one of the most useful tools [98]. In order to follow these principles, intelligent manufacturing should first address response latency, risk control, and privacy protection, and hence requires DL and edge computing. In intelligent factories, edge computing is conducive to expand the computation resources, the network bandwidth, and the storage capacity of the cloud to the IoT edge, as well as realizing the resource scheduling and data processing during manufacturing and production [99]. For autonomous manufacturing inspection, aDeepIns [98] uses DL and edge computing to guarantee performance and process delay respectively. The main idea of this system is partitioning the DL model, used for inspection, and deploying them on the end, edge and cloud layer separately for improving the inspection efficiency.
## (s15) A. Optimization of DL Models in Edge
Number of References: 2

(p15.0) DL tasks are usually computationally intensive and requires large memory footprints. But in the edge, there are not enough resources to support raw large-scale DL models. Optimizing DL models and quantize their weights can reduce resource costs. In fact, model redundancies are common in DNNs [109], [110] and can be utilized to make model optimization possible. The most important challenge is how to ensure that there is no significant loss in model accuracy after being optimized. In other words, the optimization approach should transform or re-design DL models and make them fit in edge devices, with as little loss of model performance as possible. In this section, optimization methods for different scenarios are discussed: 1) general optimization methods for edge nodes with relatively sufficient resources; 2) fine-grained optimization methods for end devices with tight resource budgets.
## (s16) B. Segmentation of DL Models in Edge
Number of References: 11

(p16.0) In [12], the delay and power consumption of the most advanced DL models are evaluated on the cloud and edge devices, finding that uploading data to the cloud is the bottleneck of current DL servicing methods (leading to a large overhead of transmitting). Dividing the DL model and performing distributed computation can achieve better endto-end delay performance and energy efficiency. In addition, by pushing part of DL tasks from the cloud to the edge, the throughput of the cloud can be improved. Therefore, the DL model can be segmented into multiple partitions and then allocated to 1) heterogeneous local processors (e.g., GPUs, CPUs) on the end device [133], 2) distributed edge nodes [134], [135], or 3) collaborative 'end-edge-cloud" architecture [12], [46], [136], [137].

(p16.1) Partitioning the DL model horizontally, i.e., along the end, edge and cloud, is the most common segmentation method. The challenge lies in how to intelligently select the partition points. As illustrated in Fig. 13, a general process for determining the partition point can be divided into three steps [12], [136]: 1) measuring and modeling the resource cost of different DNN layers and the size of intermediate data between layers; 2) predicting the total cost by specific layer configurations and network bandwidth; 3) choosing the best one from candidate partition points according to delay, energy requirements, etc. Another kind of model segmentation is vertically partitioning particularly for CNNs [135]. In contrast to horizontal partition, vertical partition fuses layers and partitions them vertically in a grid fashion, and thus divides CNN layers into independently distributable computation tasks.  
