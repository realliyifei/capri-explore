# Deep Learning on Knowledge Graph for Recommender System: A Survey

CorpusID: 214743520 - [https://www.semanticscholar.org/paper/d44050abf76b2d1a2cb6d127093cfb83ab2d96c8](https://www.semanticscholar.org/paper/d44050abf76b2d1a2cb6d127093cfb83ab2d96c8)

Fields: Computer Science

## (s17) Single-interaction Updater.
(p17.0) For any node u in the knowledge graph, the single-interaction updater takes both u's context representation n u and u's current embedding z u as input to compute a new representation z new u = f (n u , z u ). f is a function that involves a binary operator such as sum, concatenation, etc, which is applied to both n u and z u . This operator builds an interaction between the node u and its context, and could potentially improve the model performance.

(p17.1) KGNN-LS [30] and KGCN [31] both utilize summation as the interaction operator. The only difference is that KGNN-LS applies a scaling operation on the input node embeddings before feeding them to the operator. Their updaters can be written as
## (s23) Masked Embedding
(p23.0) Training with Encoder-Decoder Architecture. STAR-GCN [45] adopts a multi-block graph encoder-decoder architecture. Each block contains two components: a graph encoder and a graph decoder. The graph encoder generates node representations by encoding semantic graph structure and input content features, and the decoder aims to recover the input node embeddings. To train STAR-GCN, the authors mask some percentage of the input nodes at random and then reconstruct the clean node embeddings utilizing their context information. This is referred as masked embedding training mechanism. By using this mechanism, STAR-GCN can learn embeddings for nodes that are not observed in the training phase. In a cold start scenario, STAR-GCN initializes the embeddings of new nodes to be zero and gradually refines the estimated embeddings by multiple blocks of GNN encoder-decoders.
## (s30) Dynamicity
(p30.0) Knowledge graph could evolve over time dynamically, i.e, its nodes/edges may appear or disappear. For example, in the scenario of social recommendation, a user's friend list may change from time to time. When a user adds a number of new friends with similar interests, the recommender system should update its recommendation strategy accordingly and reflect this change in its results.

(p30.1) To address this issue, Wu et al. [23] consider a dynamic feature graph setting. Specifically, for each user, they construct a graph where each node represents either this user or one of his/her friends. If user u has |N (u)| friends, then the total number of nodes in this graph is |N (u) + 1|. The node feature of friends in this graph is kept unchanged but that of user u is updated whenever u consumes a new item. Moreover, to capture the context-dependent social influence, the authors propose a graph attention neural network, which utilizes an attention mechanism to guide the influence propogation in its aggregator. Each friend of user u is assigned with an attention weight which measures its level of influence.
## (s38) Cross-Domain Recommendation
(p38.0) Besides mining a single knowledge graph, there is an increasing need of computing recommendations using data from multiple sources. For instance, a customer may be users of more than one social networks at the same time, e.g., Facebook and LinkedIn. Each of these social networks collect data regarding this customer and embed them into their own knowledge graphs. Thus, it is reasonable to leverage information from all these knowledge graphs to boost the recommendation performance.

(p38.1) However, there are two significant gaps in the current research. The first gap is that existing research lacks exploration on effectively integrating information from multiple knowledge graph sources [12]. Most of them attempt to build associations between two different knowledge graphs by connecting related entities (i.e., nodes), as in Wang et al. [34]. The group knowledge represented by a collection of nodes or edges of the same types, which may be critical to align multiple knowledge graphs, is ignored in these methods.
