# Convergence of Edge Computing and Deep Learning: A Comprehensive Survey

CorpusID: 197935335 - [https://www.semanticscholar.org/paper/4cd03cd34e7e94d1b1ee293d5dead8efc24c1a6d](https://www.semanticscholar.org/paper/4cd03cd34e7e94d1b1ee293d5dead8efc24c1a6d)

Fields: Computer Science, Engineering

## (s15) A. Optimization of DL Models in Edge
(p15.0) DL tasks are usually computationally intensive and requires large memory footprints. But in the edge, there are not enough resources to support raw large-scale DL models. Optimizing DL models and quantize their weights can reduce resource costs. In fact, model redundancies are common in DNNs [109], [110] and can be utilized to make model optimization possible. The most important challenge is how to ensure that there is no significant loss in model accuracy after being optimized. In other words, the optimization approach should transform or re-design DL models and make them fit in edge devices, with as little loss of model performance as possible. In this section, optimization methods for different scenarios are discussed: 1) general optimization methods for edge nodes with relatively sufficient resources; 2) fine-grained optimization methods for end devices with tight resource budgets.
## (s18) VI. EDGE COMPUTING FOR DEEP LEARNING
(p18.0) Extensive deployment of DL services, especially mobile DL, requires the support of edge computing. This support is not just at the network architecture level, the design, adaptation, and optimization of edge hardware and software are equally important. Specifically, 1) customized edge hardware and corresponding optimized software frameworks and libraries can help DL execution more efficiently; 2) the edge computing architecture can enable the offloading of DL computation; 3) well-designed edge computing systems can better maintain DL services running on the edge; 4) fair platforms for evaluating DL performance on the edge help to further evolve above implementations.

(p18.1) A. Edge Hardware and Software Stacks for DL 1) Mobile CPUs and GPUs: DL applications are more valuable if directly enabled on lightweight edge devices, such as mobile phones, wearable devices and surveillance cameras, near to the location of events. Low-power IoT devices, as a part of edge devices, can be used to undertake lightweight DL computation, and hence avoiding communication with the cloud, but it still need to face limited computation resources, memory footprint and energy consumption. To relax these bottlenecks, in [125], ARM Cortex-M micro-controllers are studied to make them potentially feasible edge hardware for DL. By the developed CMSIS-NN, a collection of efficient NN kernels, the memory footprint of NNs on ARM Cortex-M processor cores can be minimized, and then the DL model can be fitted into IoT devices, meantime achieving normal performance and energy efficiency.
## (s31) B. ("DL in Edge") General DL Model for Inference
(p31.0) When deploying DL in edge devices, it is necessary to accelerate DL inference by model optimization. In this section, challenges with respect to model compression, model segmentation and EEoI, used to optimize DL models, is discussed.

(p31.1) 1) Generalization of EEoI: Currently, EEoI can be applied to classification problems in DL [139], but there is no generalized solution for a wider range of DL applications. Furthermore, in order to build an intelligent edge and support edge intelligence, not only DL but also the possibility of applying EEoI to DRL should be explored, since applying DRL to real-time resource management for the edge, as discussed in Section VIII, requires stringent response speed.

(p31.2) 2) Hybrid Model Modification: Coordination issues with respect to model optimization, model segmentation, and EEoI should be thought over. These customized DL models are often used independently to enable "end-edge-cloud" collaboration. Model optimizations, such as model quantification and pruning, may be required on the end and edge sides, but because of the sufficient computation resources, the cloud does not need to take the risk of model accuracy to use these optimizations. Therefore, how to design a hybrid precision scheme, that is, to effectively combine the simplified DL models in the edge with the raw DL model in the cloud is important.

(p31.3) 3) Coordination between training and inference: Pruning, quantizing and introducing EEoI into trained raw DL models require retraining to give them the desired inference performance. In general, customized models can be trained offline in the cloud. However, the advantage of edge computing lies in its response speed and might be neutralized because of belated DL training. Moreover, due to a large number of heterogeneous devices in the edge and the dynamic network environment, the customization requirements of DL models are not monotonous. Then, is this continuous model training requirement reasonable, and will it affect the timeliness of model inference? How to design a mechanism to avoid these side-effects?

(p31.4) C. ("Edge for DL") Complete Edge Architecture for DL Edge intelligence and intelligent edge require a complete system framework, covering data acquisition, service deployment and task processing. In this section, we discuss the efforts that need to be made to build a complete edge computing framework for DL, as summarized in Table VI. 1) Edge for Data Processing: Both pervasively deployed DL services on the edge and DL algorithms for optimizing edge cannot be realized without data acquiring. Edge architecture should be able to efficiently acquire and process the original data, sensed or collected by edge devices, and then feed them to DL models.
