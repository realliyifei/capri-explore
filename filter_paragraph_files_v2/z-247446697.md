# Medical Image Segmentation on MRI Images with Missing Modalities: A Review

CorpusID: 247446697 - [https://www.semanticscholar.org/paper/0528bfb852be916a18962db033bb9ff84bc8b97f](https://www.semanticscholar.org/paper/0528bfb852be916a18962db033bb9ff84bc8b97f)

Fields: Computer Science, Medicine, Engineering

## (s11) Common Latent Space Models
(p11.0) Adopting deep learning for biomedical image segmentation was one of the significant steps for finding a viable strategy for dealing with missing modality issues in MR images. The objective of early deep learning methods for the missing modalities issue was to translate modalities to a shared subspace and create a shared latent vector. Hetero-Modal Image Segmentation (HeMIS) [44] is a well-known example that utilizes this concept. HeMIS consists of three main layers as it is also shown in Figure 5: back-end layer, abstraction layer and front-end layer. Each modality will be directed into a specific set of convolutional layers in the network's back-end layer, which will subsequently translate each modality into a common representation of all modalities. Arithmetic operations like mean and variance will be computed in the abstraction layer. The mean and variance will then be combined and supplied into the front-end layer, which will provide the segmentation outputs.

(p11.1) Although establishing a common latent embedding for all available modalities is one of HeMIS' major goals, computing the mean and variance alone will not always suffice. Besides that HeMIS can only function properly in the absence of modalities if each modality input in the test set is labeled. The authors of [85] were inspired by the aforementioned  [44] applies a series of three connected blocks: a Back-end block to encode each modality into a latent space and learn modality-specific features, an Abstraction block to extract statistical features (first and second-order moments) and finally a Front-end block to generate the segmentation map based on the learned representation.

(p11.2) HeMIS problem to create a network that, in addition to missing modalities, tackles the issue of missing modality labels. Figure 6 shows a HeMIS modification called Permutation Invariant Multi-Modal Segmentation (PIMMS), which can perform segmentation tasks without using modality labels. PIMMS uses a classifier to build a distribution across modalities for the available inputs, then awards a score and labels each unlabeled input data. The inputs are then further adjusted by applying two different types of attention: soft and hard attention. The adjusted inputs are subsequently supplied into the second part of the network, which is a HeMIS model.  [85], which is designed to tackle the problem of missing modality and labels. At first, it applies a f mod function to generate a new representation for each modality using a joint representation and then it deploys a HeMIS approach to perform semantic segmentation.
## (s27) ADNI
(p27.0) The Alzheimer's Disease Neuroimaging Initiative (ADNI) [85] database comprises MRI scans of 973 Alzheimer's patients, including T1 and FLAIR sequences, captured using scanners from only three manufacturers: GE, Philips, and Siemens. It's also relevant to note that ADNI suggests a unified and specific criteria for the scans it contains, resulting in a lack of diversity across its containing scans.
## (s31) CHAOS2019
(p31.0) The CHAOS benchmark [55], or Combined Healthy Abdominal Organ Segmentation, is comprised of two databases, one containing CT scans and the other MRI images. The latter is the case of most interest in this IXI dataset [19] 600 subjects T1 , T2, PD [19] study, thus we devote this section to it. The MRI database comprises 120 Digital Imaging and Communications in Medicine (DICOM) datasets, including 40 T1-DUAL in phase datasets, 40 T2-SPIR datasets, and 40 T1-DUAL out phase datasets, all of which were obtained utilizing different RF Pulse and gradient combinations. All the MRI scans were acquired with a 1.5T Philips machine.
## (s33) IXI dataset
(p33.0) This dataset [19] comprises almost 600 MR scans from healthy subjects, including T1, T2, and PD sequences as well as Diffusion-weighted (DW) sequences, taken on two different vendor systems: a Philips 1.5 and 3T system as well as a GE 1.5T system. Table 2 summarizes the aforementioned dataset along with the number of samples, modalities and research work performed on these benchmarks.
## (s35) Metrics For Evaluating the Performance
(p35.0) Most articles in recent years have focused only on the issue of quantitative accuracy of the model and compare and report the performance of their model in terms of quantitative accuracy. They lack to includes other important aspects such as speed (inference time) and the amount of memory required (which we will discuss in section 6). In this section, we briefly introduce some popular metrics used for evaluating the accuracy of missing modality compensating networks. The results will compare the most promising method for the popular datasets. Dice score In semantic segmentation, the Dice loss which is based on dice coefficient similarity is well-known. In the segmentation of medical images, most of the time the region of interest (ROI) is a small part of the image. Therefore, the model is prone to be trapped in the local minimum in the training process of the model. Accordingly, the model will bias to the background, the object of interest will not be detected appropriately and so many of them will miss. Thus, the Dice loss was proposed to alleviate this problem [64,5]. The Dice loss is formulated for a 3D MRI image as written in Equation 1:
## (s37) Quantitative Performance Analysis
(p37.0) In this section, the performance of the reviewed methods on the most common benchmarks including (MSGC, MICCAI-WMH, BraTS2015 and BraTS2018 dataset) will be reported. In our comparison tables, we only include methods that are using the same setting on a particular dataset (to provide a fair evaluation). We further provide experimental results on a BraTS series with extreme missing modalities to provide a user a clear view of the overall performance gained till now. Table 3 demonstrates the experimental results on the MSGC dataset.

(p37.1) The experimental results reported in [44] suggest that the HeMIS method outperforms other competitors when subjects with missing modalities are presented. Table 4 focuses on the comparison results reported on the MICCAI-WMH dataset and provides a experimental results have been done by PIMMS [85] method to overcome the issue of missing labels in MRI series.  Table 5 focuses on the BraTS2015 which is more popular benchmark for missing modality compensation networks. There have been a large number of work reported their performance on this dataset, however, in this paper we only tabulated the methods which performed the evaluation through the online system provided by the BraTS challenge.  Table 6 provided experimental results on BraTS2018 with the same setting and compares four well-known approaches for missing modality compensation. The recent approach SMU-Net and ACN outperforms the baseline methods HeMIS and HVED with large margins. It is crystal clear that, with the advance of new approaches there have been a 15% performance gain achieved by the recent works since the introduction of HeMIS method.
## (s38) Extreme missing modality
(p38.0) In this section, we analyze the performance of several algorithms in case of extreme missing modality. More precisely we assume that on the training time all modalities are presented, however, the inference only applies to a single modality data. This extreme missing scenario provided a good benchmark to evaluate the effectiveness of different approaches to tackle the problem of missing information. Table 7 provides experimental results on the BraTS2015 and BraTS2018 series. It is worthwhile to mention that for each modality we reported the average dice score (average of the whole, enhance and core tumour dice scores). The experimental results show that compared to the fullmodality scenario, the performance dramatically decreases in a single modality case, however, recent approaches (e.g. [87] takes the strength of knowledge distillation and information maximization approaches to train a robust model to missing modality.
