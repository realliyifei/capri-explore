# IET Image Processing Deep learning for occluded and multi-scale pedestrian detection: A review

CorpusID: 230596690 - [https://www.semanticscholar.org/paper/abf4b0aa85edafc82886365bf473ac157509629e](https://www.semanticscholar.org/paper/abf4b0aa85edafc82886365bf473ac157509629e)

Fields: Computer Science, Engineering

## (s0) INTRODUCTION
(p0.0) Pedestrian detection, as an important research topic in the field of computer vision for a long time, has many applications such as autonomous driving, video surveillance, robotics and so on.

(p0.1) In addition, pedestrian detection as a special case of object detection, its research achievements play an important role in promoting the development of other object detection methods. The process of pedestrian detection is to predict, locate and mark the position of pedestrian to obtain information such as the position and action of the pedestrian [1], as shown in Figure 1. However, due to the random distribution and dynamic characteristics of pedestrian, many detection algorithms cannot detect pedestrians accurately in real time. There will be false positives and false negatives in the process of pedestrian detection since the influence by weather, similar objects, occlusion and other factors results in poor robustness of current pedestrian detection algorithms in more complex scenes. Therefore, a lot of research is still devoted every year to establish a state-of-theart method. Figure 2 shows the amount of researches from 2000 to 2018 in pedestrian detection, the data from Google scholar advanced search the pedestrian detection as allintitle.

(p0.2) Pedestrian detection is a special task of object detection. Its technological progress is closely related to the development of general object detection. This connection can be described as follows: The general object detection algorithm can be used for pedestrian detection after appropriate improvement. Pedestrian detection is a kind of object detection, and the problems it studies can promote the development of general object detection from another view.
## (s7) Single-stage detection framework
(p7.0) Although the two-stage network framework has made great breakthroughs in accuracy, the performance of end-to-end learning cannot be reflected due to the hierarchical method of region extraction combined with training. To solve this issue, a single-stage network framework is proposed to speed up detection by removing the regional proposals generation stage. By setting anchors in advance, the input image is convoluted directly, and then the anchors in the convolution map are regressed and classified. In practical testing, it has more efficient detection speed and is easily transplanted to embedded system. However, its direct detection on the original image means that the training process is very complex and the trained model is difficult to guarantee better robustness, so the accuracy cannot replace the two-stage framework. You only look once (YOLO) [35], Single Shot MultiBox Detector (SSD) [36] are representative single-stage network frameworks. YOLO divides the input image into S Ã— S units, each unit is responsible for the centre of the unit's object detection, using a one-time prediction of the object boundaries, positioning confidence and all kinds of probability vectors. At present, several versions have been updated according to their performance, such as YOLOv2 [37], YOLOv3 [38]. Different from YOLO, SSD detects multi-scale objects directly in the convolution layer by setting anchors of different scales on the image, calculating and regressing all the anchors and confidence in the detection process, and detecting multi-scale objects by setting convolution maps of different scales. SSD has advantages over YOLO in solving small-scale and location problems. The network structure of SSD and YOLO is shown in Figure 6.
## (s10) Multi-scale proposals or feature maps
(p10.0) The initial RCNN focused on the sampling of multi-scale object in the process of generating proposals, but the excessive number of proposals led to the inefficiency of its calculation. Although the proposals of RPN solve this problem to some extent, the proposals for small-scale pedestrians are not fully covered. SAF RCNN [26] and MS-CNN [20] extended Fast RCNN and Faster RCNN to deal with scale change, respectively. F-DNN [41] used multiple deep classifiers combined with soft filters to further validate each proposal. SSD [36] divided the output feature map into a set of template boxes by using boundary boxes with different aspect ratios and proportions, and then constructed multi-scale target detector using complementary detection method in different output layers. Recent studies have different views on multi-scale pedestrian detection. But they have similarities, that is, they all consider the impact of the region proposals generation on multi-scale pedestrians.
## (s12) Annotation method
(p12.0) The pedestrian detection method based on deep learning needs to input a certain number of labelled images to train the CNN. The quality of the input image determines the detection ability of the trained detector. Among them, the size, resolution and label position of the image affect the accuracy of the detector after training. Therefore, some researchers explore how to label pedestrian images with different scales to guide the feature extraction ability of CNN for small-scale pedestrians. In order to better realise the ability of the detector to learn small-scale pedestrians, Song et al. [53] analysed the bias of image boundary frames in the training stage, and a multi-scale pedestrian detection method (TLL) was proposed based on the topological line localisation and temporal feature aggregation. By establishing the topological information of human body model in different scales, the topological information is used as the annotated training detector in the training stage as shown in Figure 9. Pedestrians over different scales could be modelled as a group of 2D Gaussian kernels. And a post-processing scheme based on Markov random field is proposed to improve the positioning accuracy under crowd occlusion. Zhang et al. [47] verified that the initial annotation information plays a decisive role in detector training. Through more detailed post annotation training in Caltech dataset, MR is 3% lower than before. In addition, CMFs [48] used additional pixel annotation to improve the perfor-
