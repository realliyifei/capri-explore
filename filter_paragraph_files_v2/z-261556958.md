# Robust Recommender System: A Survey and Future Directions

CorpusID: 261556958 - [https://www.semanticscholar.org/paper/73d4a4e39eafc5884247f6cacf42228476ae3b54](https://www.semanticscholar.org/paper/73d4a4e39eafc5884247f6cacf42228476ae3b54)

Fields: Computer Science

## (s8) In-processing Detection.
(p8.0) In-processing detection refers to identifying and mitigating fraudulent activities in recommender systems during model training. This approach allows for more comprehensive information to be gathered than pre-processing detection, as it takes into account both the initial data and the information from ongoing training process, which could reveal more complex and latent relationships among users and items.

(p8.1) A representative work, GraphRfi [165], formulates the in-processing detection as two tasks: Fraudster Detection: GraphRfi leverages the output of recommender systems to assist the detector. This assistance is based on the principle of cognitive psychology, which assumes that the behavior of genuine users is coherent and predictable. In other words, if a significant discrepancy exists between a user's actual behavior and their predicted behavior, i.e., the predictionˆ, is much different from the ground-truth rating , , the user is likely to be a fraudulent user. The discrepancy of user ' behavior can be calculated by:
## (s10) Post-processing Detection.
(p10.0) Post-processing refers to the detection process after the recommender systems have been trained. The primary objective of post-processing detection is to filter out poor-quality recommendations generated as a result of fraudsters, ensuring that the recommender systems provide accurate and reliable suggestions to its genuine users. A presentative method for post-processing detection is proposed by Cao et al. [20]. In the Reinforcement Learning (RL)-based recommendation scenario, they propose a two-part detection model. The first part is a Gated Recurrent Unit (GRU) encoder, which encodes the action methods, i.e., the list recommended by the RL agent, into a low-dimensional feature vector. The second part is an attention-based decoder with a classifier to distinguish between high-quality and low-quality recommendations. The method identifies poor-quality recommendations stemming from fraudsters. The RL-based framework allows the model to continuously learn and improve its decision-making process as it filters recommendations, thus enhancing the overall robustness of the recommender systems' output.
## (s20) Adjustment of Training Process
(p20.0) Orthogonal Mapping where , is the ground truth rating andˆ, is predicted rating computing by Θ. The 1 -norm offers enhanced robustness against outliers or anomalous data in comparison to the Euclidean distance (i.e., 2 -norm). By integrating the 1 -norm regularization, the model prioritizes essential features over noise, leading to more refined recommendations. In recent times, researchers continue to innovate regularization strategies to improve the robustness of recommender systems in the presence of natural noise. As an illustration, Chen et al. [23] meld Jacobian regularization [68] with the transformer block in sequential recommender systems. This regularization enables a significant reduction in the model's susceptibility to noisy sequences, consequently delivering more consistent and trustworthy recommendations amidst noise.

(p20.1) While regularization offers a versatile means to enhance noise robustness across diverse recommender systems, its broad scope might dilute its efficacy against specific noise types. While instrumental in countering overfitting and amplifying generalization, regularization does not directly target the genesis of noise. Consequently, it's necessary to couple regularization with other noise-mitigation approaches for superior outcomes.
## (s34) RELATIONSHIP WITH OTHER TRUSTWORTHY PROPERTIES
(p34.0) Robustness is a key property in trustworthy recommender systems. In this section, we will explore the interplay between robustness and other key properties of trustworthy recommender systems. The four critical aspects are accuracy, explainability, privacy, and fairness [78]. We will also discuss the potential trade-offs and synergies that may arise when pursuing robustness in conjunction with these other performance goals.
