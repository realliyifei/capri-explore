# False Information on Web and Social Media: A Survey

CorpusID: 5058880 - [https://www.semanticscholar.org/paper/1bb23fd4252a76b55ff77ed982fc78c3e06d1452](https://www.semanticscholar.org/paper/1bb23fd4252a76b55ff77ed982fc78c3e06d1452)

Fields: Computer Science

## (s14) Textual characteristics.
(p14.0) Since most reviews include textual content, researchers have extensively studied textual and linguistic features for discerning review fraud. Several works have posited that review fraudsters minimize effort by repeating the same reviews. Jindal et al. [43] provided the first well-known characterizations of review fraud, in which the authors characterized duplicate reviews (according to Jaccard similarity) across Amazon data as cases of fraud. The authors showed that many of these fraudulent duplicate reviews were from the same user on different products, rather than different users on the same product or different products. Figure 6 shows the distribution of maximum similarity between two reviewers' reviews. At the higher similarity end, 6% of the reviewers with more than one review have a maximum similarity score of 1, which is a sudden jump indicating that many reviewers copy reviews. Furthermore, Sandulescu et al. [82] showed that many review fraudsters adjust their reviews slightly so as not to post near or exactly similar reviews and be easily caught-instead, these sophisticated fraudsters tend to post semantically similar text (i.e. instead of duplicating "the hotel room had an excellent view, " the fraudster might post "the hotel room had a superb view" instead).
## (s23) 5.2.5
(p23.0) Debunking characteristics. Once false information spreads, attempts are made to debunk it and limit its spread. Recent research has shown that there is a significant time delay between the spread and its debunking. Zubiaga et al. [121] found that true information tends to be resolved faster than false information, which tends to take about 14 hours to be debunked. Shao et al. [86] came to a similar conclusion-they found a delay of 10-20 hours between the start of a rumor and sharing of its fact-checking contents.

(p23.1) But once debunking information reaches the rumor spreaders, do they stop spreading it or does it 'back-fire', as observed in in-lab settings [68] where corrections led to an increase in misperception? Several empirical studies on web-based false information suggest that debunking rumors is in fact effective, and people start deleting and questioning the rumor when presented with corrective information. Frigerri et al. [30] studied the spread of thousands of rumor reshare cascades on Facebook, and found that false information is more likely to be linked to debunking articles than true information. Moreover, once it is linked, it leads to a 4.4 times increase in deletion probability of false information than when it is not, and the probability is even higher if the link is made shortly after the post is created. Moreover, Zubiaga et al. [121] found that there are more tweets denying a rumor than supporting it after it is debunked, while prior to debunking, more tweets support the rumor. Furthermore, Vosoughi et al. [105] showed that there is a striking difference between replies on tweet containing false information than those containing true information-while people express fear, disgust, and surprise in replies, true information generates anticipation, sadness, joy, and trust. These differences can potentially be used to create early detection and debunking tools.
