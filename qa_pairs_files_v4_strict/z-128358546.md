# A Survey on Practical Applications of Multi-Armed and Contextual Bandits

CorpusID: 128358546 - [https://www.semanticscholar.org/paper/b24e6b0539d6e27d82c60fa7c53a1d0905e41a19](https://www.semanticscholar.org/paper/b24e6b0539d6e27d82c60fa7c53a1d0905e41a19)

Fields: Computer Science, Business, Mathematics

## (s4) Dynamic Pricing
(p4.0) Online retailer companies are often faced with the dynamic pricing problem: the company must decide on real-time prices for each of its multiple products. The company can run price experiments (make frequent price changes) to learn about demand and maximize long-run profits. The authors in [Misra et al., 2018] propose a dynamic price experimentation policy, where the company has only incomplete demand information. For this general setting, authors derive a pricing algorithm that balances earning an immediate profit vs. learning for future profits. The approach combines multi-armed bandit with partial identification of consumer demand from economic theory. Similar to [Misra et al., 2018], authors in [Mueller et al., 2018] consider high-dimensional dynamic multi-product pricing with an evolving lowdimensional linear demand model. They show that the revenue maximization problem reduces to an online bandit convex optimization with side information given by the observed demands. The approach applies a bandit convex optimization algorithm in a projected low-dimensional space spanned by the latent product features, while simultaneously learning this span via online singular value decomposition of a carefully-crafted matrix containing the observed demands.
## (s7) Information Retrieval
(p7.0) Authors in [Losada et al., 2017] argue that Information Retrieval iterative selection process can be naturally modeled as a contextual bandit problem. Casting document judging as a multi-armed bandit problem leads to highly effective adjudication methods. Under this bandit allocation framework, they consider stationary and non-stationary models and propose seven new document adjudication methods (five stationary methods and two non-stationary variants). This comparative study includes existing methods designed for poolingbased evaluation and existing methods designed for metasearch. In mobile information retrieval, authors in [Bouneffouf et al., 2013] introduce an algorithm that tackles this dilemma in Context-Based Information Retrieval (CBIR) area. It is based on dynamic exploration/exploitation and can adaptively balance the two aspects by deciding which users situation is most relevant for exploration or exploitation. Within a deliberately designed online framework they conduct evaluations with mobile users.
## (s9) Anomaly Detection
(p9.0) Performing anomaly detection on attributed networks concerns with finding nodes whose behaviors deviate significantly from the majority of nodes. Authors in [Ding et al., 2019] investigate the problem of anomaly detection in an interactive setting by allowing the system to proactively communicate with the human expert in making a limited number of queries about ground truth anomalies. Their objective is to maximize the true anomalies presented to the human expert after a given budget is used up. Along with this line, they formulate the problem through the principled multiarmed bandit framework and develop a novel collaborative contextual bandit algorithm, that explicitly models the nodal attributes and node dependencies seamlessly in a joint framework, and handles the explorationexploitation dilemma when querying anomalies of different types. Credit card transactions predicted to be fraudulent by automated detection systems are typically handed over to human experts for verification. To limit costs, it is standard practice to select only the most suspicious transactions for investigation. Authors in [Soemers et al., 2018] claim that a trade-off between ex-ploration and exploitation is imperative to enable adaptation to changes in behavior. Exploration consists of the selection and investigation of transactions with the purpose of improving predictive models, and exploitation consists of investigating transactions detected to be suspicious. Modeling the detection of fraudulent transactions as rewarding, they use an incremental regression tree learner to create clusters of transactions with similar expected rewards. This enables the use of a contextual multi-armed bandit (CMAB) algorithm to provide the exploration/exploitation trade-off.
## (s16) Bandit for Active Learning
(p16.0) Labelling all training examples in supervised classification setting can be costly. Active learning strategies solve this problem by selecting the most useful unlabelled examples to obtain the label for, and to train a predictive model. The choice of examples to label can be seen as a dilemma between the exploration and the exploitation over the input space. In [Bouneffouf et al., 2014], a novel active learning strategy manages this compromise by modelling the active learning problem as a contextual bandit problem. they propose a sequential algorithm named Active Thompson Sampling (ATS), which, in each round, assigns a sampling distribution on the pool, samples one point from this distribution, and queries the oracle for this sample point label. The authors of [Ganti and Gray, 2013] also propose a multi-armed bandit inspired, pool-based active learning algorithm for the problem of binary classification. They utilize ideas such as lower confidence bounds, and self-concordant regularization from the multi-armed bandit literature to design their proposed algorithm. In each round, the proposed algorithm assigns a sampling distribution on the pool, samples one point from this distribution, and queries the oracle for the label of this sampled point.
