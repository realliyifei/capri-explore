# A Systematic Literature Review of Computer Vision Applications in Robotized Wire Harness Assembly

CorpusID: 262466559
 
tags: #Computer_Science, #Engineering

URL: [https://www.semanticscholar.org/paper/ebd0b4e7e7dfa8c203709cb14d31255996a704c9](https://www.semanticscholar.org/paper/ebd0b4e7e7dfa8c203709cb14d31255996a704c9)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | False |
| By Annotator      | (Not Annotated) |

---

A Systematic Literature Review of Computer Vision Applications in Robotized Wire Harness Assembly
September 26, 2023

Hao Wang haowang@chalmers.se 
Department of Industrial and Materials Science
Chalmers University of Technology
7A, SE-412 96Hörsalsvägen, GothenburgSweden

Omkar Salunkhe 
Department of Industrial and Materials Science
Chalmers University of Technology
7A, SE-412 96Hörsalsvägen, GothenburgSweden

Walter Quadrini 
Department of Management
Economics and Industrial Engineering
Politecnico di Milano
piazza Leonardo da Vinci 3220133MilanItaly

Björn Johansson 
Department of Industrial and Materials Science
Chalmers University of Technology
7A, SE-412 96Hörsalsvägen, GothenburgSweden

Dan Lämkull 
Department of Manufacturing Technology
Volvo Car Corporation
SE-418 78GothenburgSweden

Fredrik Ore 
Department of Global Industrial Development
SE-151 87SödertäljeScania CV ABSweden

Mélanie Despeisse 
Department of Industrial and Materials Science
Chalmers University of Technology
7A, SE-412 96Hörsalsvägen, GothenburgSweden

Luca Fumagalli 
Department of Management
Economics and Industrial Engineering
Politecnico di Milano
piazza Leonardo da Vinci 3220133MilanItaly

Johan Stahre 
Department of Industrial and Materials Science
Chalmers University of Technology
7A, SE-412 96Hörsalsvägen, GothenburgSweden

A Systematic Literature Review of Computer Vision Applications in Robotized Wire Harness Assembly
September 26, 202361EF80FFED771DC01C49CE333D35F377arXiv:2309.13744v1[cs.CV]Preprint submitted to Elsevierwire harness assemblyrobotized assemblycomputer visiondeformable linear objectcollaborative robot applicationselectric vehicle (EV)
The shift in the automotive industry toward electrification and autonomous driving has propelled a remarkable increase in the usage of automotive electronics that are responsible for quality-essential and safety-critical functions, such as energy transmission, maneuvering, driver assistance, and safety system.This paradigm shift places more demand on automotive wire harnesses, an essential hardware for automotive electronic systems, from the function and safety perspectives and stresses the greater significance of high-quality wire harness assembly in vehicles.However, most of the operations of wire harness assembly in current automobile production are performed manually by skilled operators, and some of the manual processes are problematic regarding safety, assembly quality, and ergonomics.On the other hand, the automotive industry retains persistent aspirations to increase competitiveness and gain market share.Hence, assuring assembly quality and promoting productivity while improving ergonomics and optimizing labor costs is desired.Robotized assembly, accomplished by robots only or human-robot collaboration, is a key enabler for fulfilling the increasingly challenging demands on safety, quality, and ergonomics as it facilitates more replicable, transparent, and comprehensible processes than completely manual operations.Nonetheless, robotized assembly of wire harnesses is challenging in practical applications due to the flexibility of the deformable objects, though many preliminary automation solutions have been discussed under simplified industrial configurations.Previous research efforts have proposed to facilitate the robotized wire harness assembly with computer vision techniques enabling the robots to better perceive and manipulate flexible wire harnesses.Yet, the industry has not been able to introduce any computer vision-enabled method to automate this assembly operation fully or partially.This article presents a systematic literature review on computer vision applications that have been proposed for robotized wire harness assembly, derives challenges from existing studies, and identifies opportunities for future research to promote a more practical robotized assembly of wire harnesses.

## Introduction

Electrification of vehicles is a primary way to facilitate the automotive industry reaching the goal of net-zero carbon emission [1] and contributing to more sustainable transport.The shift towards electrification and autonomous driving in the current automotive industry stresses the increasing significance of the automotive electronic system, which is responsible for quality-essential processes, for example, engine control unit and energy transmission system, and safety-critical functions, for instance, maneuvering, driver assistance, and safety system [2].

The wire harness is a fundamental element within the automotive electronic system.Figure 1 presents an example of an automotive wire harness.A wire harness is a bundle of routed cables and wires with a tree-like structure, consisting of numerous components, such as wires, terminals, connectors, clamps, and wrapping materials, supporting the connection and current and signal transmission among different electrical components scattered throughout any electrical equipment [3,4].Automotive wire harnesses can be categorized regarding the installation area in automobiles, for example, engine harnesses, instrument panel harnesses, floor harnesses, and bumper harnesses.Figure 2 illustrates an electrical infrastructure of a Volvo XC40 Recharge.Thus, it is crucial to guarantee a safe, efficient, and high-quality assembly of wire harnesses in vehicles.The usage of wire harnesses in modern vehicles has been enlarging remarkably in the past decades, as an example from the sector of passenger vehicles is illustrated in Figure 3, and the number of wire harnesses installed in future automobiles is expected to keep increasing, especially considering the growing number of electronic devices installed for various functions and the shift towards electrification and autonomous driving in the automotive industry.However, a large proportion of the operations of wire harness assembly in the current automotive industry remains manual and skill-demanding.This situation leads to problems regarding assembly quality due to the inevitable inconsistency of manual operation quality.Some manual assembly procedures are also not ergonomic for human operators, such as heavy lifting (for example, approximately 40 kg for some automotive wire harnesses), high-pressure pressing, and far-reaching operation, leading to musculoskeletal disorders (MSDs) and occupational health and safety (OHS) issues in the workforce.Although the physical strength of a human operator can be enhanced by adapting exoskeleton or other powered mechanics [5,6], the assembly quality problem stemmed from manual operations could not be addressed effectively.Moreover, there are also high-voltage wire harnesses installed in automobiles, especially in electric vehicles, which demands more careful handling regarding assembly quality, safety, and reliability [7,8].Meanwhile, the automotive industry persists in a continuous demand to promote competitiveness and acquire market share, which lays a consistent requirement on productivity.Hence, assuring assembly quality and promoting production rate while improving ergonomics and optimizing labor costs is desired, where the implementation of automation is one of the prominent approaches.

Robotized assembly, accomplished by robots or in human-robot collaboration, has been implemented to facilitate automation in various industries [9].Compared to entirely manual operations, the better replicability, transparency, and comprehensibility of robotized assembly enable more rigorous, safer, and more ergonomic-friendly manufacturing, which is favored to fulfill the increasingly demanding wire harness assembly in the automotive industry.Various preliminary automation solutions for wire harness assembly have been proposed under simplified industrial configurations [10,11].However, robotized assembly of wire harnesses remains challenging in actual circumstances [12] due to the flexibility of the deformable objects [13] and the limitation on process time in practical production [14].

Computer vision has demonstrated to the automotive industry the potential on facilitating robotized wire harness assembly, considering its vast applications in different scenarios in manufacturing [15], and has been discussed to facilitate better visual machine perception and manipulation on flexible wire harnesses in previous research [11,16,17,18].Nonetheless, the practical robotized assembly of automotive wire harnesses assisted by a vision system remains unsolved and the full potential of computer vision in the robotized wire harness assembly remains unrevealed [17,19,20,21].

This study targeted on understanding the state of the art of computer vision applications in robotized assembly of wire harnesses and identifying the challenges and future research directions for a more practical vision-driven robotized automotive wire harness assembly.For clarification, the wire harness assembly discussed in this article is defined as the final installation of wire harnesses onto other products, for example, installing wire harnesses onto an electric vehicle on an automotive production line, instead of wire harness manufacturing, which has been reviewed in several studies previously [22,2,23].

To understand the state of the art of research related to computer vision-based solutions on robotized assembly of wire harnesses and identify research gaps that demand further studies, a systematic literature review of relevant scientific publications was conducted in this study, addressing the following research questions:

• RQ1: What computer vision-based solutions have been proposed for robotized assembly of wire harnesses?

• RQ2: What are the challenges for computer vision applications in robotized assembly of wire harnesses?

• RQ3: What are the required future research activities and fields for more efficient and practical computer vision-driven robotized assembly of wire harnesses?

This article is organized as follows: Section 1 introduces the background and the research questions of the systematic literature review in this study.Section 2 describes the current assembly operations of automotive wire harnesses and the challenges of automating the assembly.Section 3 describes the methodology implemented for the systematic literature review in this study.Section 4 summarizes the latest advances in computer vision techniques implemented in robotized wire harness assembly, followed by discussions on currently existing challenges and opportunities for future studies in Section 5. Section 6 concludes the study with an outlook of future trends and research.


## Robotized assembly of automotive wire harnesses


### Current manual assembly of automotive wire harnesses

Based on current work instructions at Volvo Car Corporation and an observation beside a production line in a car manufacturing plant, the current manual assembly of automotive wire harnesses in the passenger cabin of an automobile can be summarized into the following five procedures: (1) preparation; (2) transport; (3) disentanglement; (4) route; and (5) assembly.

Preparation Initially, the wire harness arrives at the assembly station tied and packed in a plastic bag or a box.The wire harness is too stiff to manipulate manually by human operators in later assembly processes.Therefore, the pack of wire harnesses is sent into an oven to get warmed, making the wire harness softer and easier to manipulate.

Transport After getting warmed, the wire harness is transported by a lifting machine operated by a human operator and dumped in the cabin.In this stage, the wire harness remains tied in a whole chunk.

Disentanglement After placing the wire harness, a group of human operators bends into the car body to untie and disentangle the wire harness manually.

Route After disentangling, a wire harness is routed in the car body manually so that different branches of a wire harness reach the mating area based on functionality.

Assembly At last, human operators manually mate the clamps and connectors of the wire harness to the counterparts in the car.


### General automation challenges in manufacturing

The third industrial revolution initiated the broad adoption of automation in various sectors of industry [9].However, many challenges still hamper the scale-up of automation applications in manufacturing.

Safety is one matter of utmost importance in manufacturing, especially when robots are deployed in the production line [24,25].Typically, different devices, such as steel fences and laser curtains, are installed around the working area of robots to guarantee safety by keeping human operators at a safe distance from functioning robots.Introducing new robots demands comprehensive consideration of the interaction between humans and robots, which will further pose new challenges to safety and risk management within the existing system.

Moreover, some production systems are non-stop, for example, the final assembly line in the automotive industry, which means that automation systems need to handle the assembly during the movement of the product.Thus, it is inevitable for the development of automation systems in such scenarios to consider how to mobilize the robotic manipulators while executing the assembly operations.

Besides, multiple variants of products are commonly produced on the same production line, which increases the complexity of the design of automation control systems and challenges the adaptiveness and agility of automation systems regarding different product variants.Also, the requirement for automation in practical production varies among different sub-sections within an industry.For example, in the automotive industry, the production of passenger vehicles is different from that of heavy vehicles regarding the required production rate and assembly environment, which demands heterogeneous automation solutions.

In addition, an everlasting challenge in manufacturing is the essential requirement of fulfilling the demand on the takt time and maintaining productivity, which requires automation systems operating within a limited time reliably.


### Automation challenges in wire harness assembly

Automated assembly has been adopted in the automotive industry for years to fulfill the continuously-increasing demand for quality and productivity and relieve more and more ergonomic problems [13,11,12,26].However, among other assembly operations, most of the current operations of wire harness assembly remain manual and challenging to be automated [12].

Theoretically, a wire harness can be generalized as a Deformable Linear Object (DLO) [27], and wire harness assembly can be regarded as a specific task of DLO manipulation, which is one of the remaining challenges in the robot-centered flexible automation, although tremendous achievements in recent years have promoted the capability of robots [19].In particular, challenges in DLO manipulation exists in modeling, state estimation, and operation [19,28].On the other hand, methods and strategies designed for manipulating regular rigid objects cannot be adapted for DLO manipulation directly due to the high degrees of freedom and deformability of DLOs [29,19].

Similarly, automating the assembly of wire harnesses is particularly difficult because it is hard to recognize the long and uneven shape, estimate the state of a deformable wire harness, and control the force for manipulation due to the property of flexibility of wire harnesses [13], as well as it is usually complex to design paths avoiding the formation of knots and entanglements which could block the process or break the harness.The flexible characteristics of the cables make the presentation of material to the automotive system very challenging.Additionally, it is generally required to deal with extremely tight position accuracy, complex structures of connectors, and non-rigid materials for connector mating in the automated mating of electric connectors [10].The previous research proposals depend on the availability of precise contactless measurement to the state of the target wire in real-time significantly, which makes many proposals challenging to implement and unreliable in actual production [30].


## Methodology

The systematic literature review is an important methodology for comprehensively understanding a subject's state of the art and identifying the gaps requiring future research [31,32,33].The systematic literature review in this study followed the methodology for planning and conducting a review suggested by Kitchenham [31].The co-authors of this article collaborated continuously through all aspects of this systematic literature review.A review protocol was developed first to ensure a systematic and reproducible review method, as shown in Table 1.


### Literature search

The literature search was conducted on the Scopus database.Scopus was selected as the online database for searching scientific peer-reviewed articles considering it as a de facto reference standard for the engineering community [34] and its adequate coverage of publications provided by various publishers.It is preferred because of its higher inclusiveness in terms of contributions over the Web of Science database and its higher reliability of collected peer-reviewed sources over Google Scholar [35].To ensure identifying as many relevant articles as possible to our research questions, the co-authors deliberated the keywords and string for searching and inclusion and exclusion criteria for scrutinizing.After several search trials with different combinations of keywords, the following string was defined for the search within the field of Article title, Abstract, Keywords on Scopus: (wir* OR cabl*) AND (harness* OR bundl*) AND assembl*, where the asterisk character was used to retrieve more results based on variations of the term and the words "cable" and "bundle" were included as synonyms of "wire" and "harness".The initial search returned a set of 990 items.A filter on the subject area was conducted on the initial search and limited to Engineering, Computer Science, Decision Sciences, Multidisciplinary, and Business, Management and Accounting to exclude studies referring to irrelevant subjects, which reduced the number of items to 711.The language of the article was also limited to English.In addition, no filter regarding the year of publication was implemented, that is, all past research works were kept for screening.Finally, there were 645 articles identified based on the search strategy on February 2, 2023.


### Literature selection

After the literature search, a two-step screening was conducted by three researchers regarding the inclusion and exclusion criteria shown in Table 1 to select the literature for later data synthesis and analysis.Firstly, a study would be excluded if it did not regard wire harnesses, as described in Section 1, as the object of interest to the study.A study would also be excluded if no robot system was involved in the proposed solution for wire harness assembly.Then, as clarified in Section 1, articles that proposed computer vision-based solutions for robotized assembly of wire harnesses would be qualified for the analysis in this study, while articles presenting studies that focused on the manufacturing of wire harnesses would be excluded from the analysis.

In the first round of screening, the title and abstract of the 645 articles were initially examined by three researchers independently based on the inclusion and exclusion criteria to minimize subjective bias during screening.After the respective screening, all three researchers synchronized their opinions and fixed disagreements by consensus.Firstly, 439 articles were excluded because they were not about the wire harnesses focused in this review.Then, 92 articles were excluded because no robotized assembly was involved.Furthermore, 82 articles were excluded because they addressed the robotized assembly process in the manufacturing of wire harnesses.Lastly, 12 articles were excluded because they addressed robotized wire harness assembly without proposing vision-based solutions.After the first screening on title and abstract, there were 625 articles excluded, and, thus, 20 articles qualified, whose full texts were downloaded and evaluated in the second round of screening.

In the second screening, the full texts of downloaded articles were scrutinized meticulously according to the inclusion and exclusion criteria to filter the articles for later analysis.After the second screening, there were 12 articles left for full-text analysis.

Moreover, "snowballing" [36], including reference tracking and citation tracking, was implemented on the selected 12 articles for analysis to identify other relevant articles missed in the original search, which returned two more articles.Thus, there were 14 peer-reviewed scientific articles selected for further extensive, qualitative descriptive, and quantitative data synthesis and analysis.

The article selection process is reported following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) [37] in Figure 4.


## Results

After searching and screening following the methodology described in Section 3, 14 articles were identified for analysis, including five articles and nine conference papers in terms of the document type, whose contributions from the perspective of computer vision applications are summarized in Table 2. Figure 5 illustrates the development of research including computer vision applications in robotized assembly of wire harnesses throughout the past years regarding the total number of publications and citations, which indicates a long-term persistent effort on facilitating the robotized wire harness assembly with vision systems and increasing research in relevant subjects.Figure 6 presents the citation relationships among the selected 14 studies, where each study is represented by a colorized circle in the 2D coordinate regarding the year of publication, the first author of the paper, and the component of wire harnesses the article focused on.The citation relationships are visualized by solid and dashed arrows, representing the citation between two studies discussing the same and different wire harness components, respectively.Figure 6 illustrates that the research on vision-enabled robotized wire harness assembly began with the recognition and manipulation of components of wire harnesses, such as clamps and connectors, and more recent studies have initiated new directions involving the understanding of the overall structure of wire harnesses.However, the research regarding different components of wire harnesses ceased at different times.


### Research on components of wire harnesses

The articles identified for this systematic literature review were all experimental studies in laboratory settings and are categorized into three main groups regarding the component of wire harnesses the study focused on: (1) for clamp manipulation (four studies), (2) for the mating of connectors (seven studies), and (3) for wire harness recognition (three studies).


#### Clamp manipulation

Clamps are bound on wire harnesses for attaching wire harnesses to target positions.Four reviewed articles addressed the manipulation of clamps on wire harnesses achieved with computer vision-based clamp recognition, as summarized in Table 3.

This group of articles focused on the mating of wire harnesses onto a car body, for example, inserting the clamps on a wire harness into an instrument panel frame.In these proposals, clamps were recognized using CCD camera [13,11,12] and CMOS camera [30] so that the gripper or end-effector on a robot arm could reach the clamps for further manipulations.All four studies implemented hand-eye vision systems by mounting cameras on the end-effectors of robot arms [13,11,12,30].Two of them also adopted global vision systems with multiple cameras fixed around the operation area [11,12].

Although the clamps can be regarded as rigid objects, their relatively small sizes and complex shapes make them difficult to be grasped by a robot gripper directly [13].The complexity of control program development and the insufficiency of the payload make multi-finger robot hands difficult to be adapted in practical applications [13].Thus, Koo et al. [13] proposed to install cubic clamp covers to facilitate the manipulation of clamps with small sizes and complex shapes and introduce stereo vision systems mounted on the end-effectors of two robot arms to recognize [13] [11]

[12]

[30]

[38]

[10]

[16]

[39]

[40]

[17]

[19]

[20]

[18]

[21] Figure 6: The citation map among the analyzed studies.The red, orange, and yellow circles represent previous studies focusing on clamps, connectors, and wires, respectively.Correspondingly, the red, orange, and yellow bars by the x-axis indicate the time span of previous studies focusing on clamps, connectors, and wires, respectively.Each arrow represents a citation-reference relationship between two previous studies, e.g., "A"→"B" means that "A" was cited by "B".Solid arrows represent the citation between two studies focusing on the same component; dashed arrows represent the citation between two studies focusing on different components.The double line between [11] and [12] represents the extension on details and discussions in [12] from [11].


## Year

Table 2: Selected works and their contributions from the perspective of computer vision applications.

Article Component Contributions on computer vision applications [13] Clamp This paper proposes to use two stereo vision systems mounted on each end-effector of two robot arms to recognize the designed markers on the designed cubic clamp covers using Scale Invariant Feature Transform (SIFT) [41,42].The experiment results show that the vision system can provide enough precision for gripping clamp covers.

[11] Clamp This paper improves Koo et al. [13] by using three stereo vision systems mounted on each end-effector of three robot arms and ten fixed cameras surrounding the work cell to recognize the ARToolKit [43,44] markers on the designed cylinder-like-shape clamp covers.

[12] Clamp This paper adds more details and discussions on Jiang et al. [11].

[30] Clamp This paper proposes to use a wrist camera on the right robot arm to recognize the AR-ToolKit [43,44] markers on the clamp cover, whose position is estimated beforehand based on tracing trajectory.

[38] Connector This paper proposes to use one CCD camera for connector grasping error detection and quality control based on basic pattern matching.

[10] Connector This paper improves Di et al. [38] by using two mutually perpendicular CCD cameras to detect magnitudes of tilt angles and horizontal displacements from each side by pattern matching.

[16] Connector This paper focuses on the monitoring task for the connector mating process and uses two mutually perpendicular cameras to observe the relative and online motions between the two connectors based on pattern matching.

[39] Connector This paper proposes to use a high-speed vision system to acquire the categories, orientations, and positions of connectors at a frame rate of 500 fps via connector corner detection.

[40]

Connector This paper proposes a method for monitoring the mating process of electric connectors, where a hand-eye camera is used for locating the connector headers via visual servoing with markers.

[17] Connector This paper proposes using an RGB-D camera for the recognition of plug-in cable connectors based on image processing, where the positions of connectors are detected based on RGB images and the 3D information of the detected connectors are acquired by registering the depth information to the RGB-based detection results.

[19] Connector This paper proposes to acquire the position and pose of a connector via learning-based rough locating and shape-based fine positioning of connectors.The proposal uses three cameras:

(1) a fixed global camera for rough locating; (2) a hand-eye camera per robot arm for fine positioning.

[20] Wire This paper focuses on the interpretable classification of wire harness branches.The interpretability is visualized using a saliency map based on class activation mapping (CAM) [45].

The experimental results demonstrate the best classification based on a late prediction fusion [46] of RGB and depth modalities, the deteriorating performance with the network pre-trained on the inpainting task, and the positive effect of elastic transform for data augmentation.The saliency maps promote the interpretability of the experimental results.

[18] Wire This paper proposes a multi-branch wire harness object recognition with segmentation and estimation based on point clouds acquired using an RGB-D camera.

[21] Wire This paper explores the industrial bin-picking problem on wire harnesses and proposes learning a bin-picking policy to infer an optimal grasp and a post-grasping action based on a top-down depth image of the cluttered wire harnesses captured by a Photoneo PhoXi 3D scanner M.However, visual noise and heavy occlusion are two major challenges leading to failure results.ARToolKit [43,44] the designed markers on the clamp covers based on Scale Invariant Feature Transform (SIFT) [41,42].The stereo vision system in Koo et al. [13] contained two CCD cameras with different focal lengths.Based on the recognition results, the robot arms moved to the clamp covers for further manipulation.The results of experiments in Koo et al. [13] qualitatively indicated that the implemented vision system could provide enough precision for gripping clamp covers [13].

Later, Jiang et al. [11] and Jiang et al. [12] made further improvements to Koo et al. [13] by: (1) deploying one more robot arm; (2) using newly designed cylinder-like-shape clamp covers with more markers from ARToolKit [43,44] for recognition; (3) implementing a global vision system containing ten fixed cameras surrounding the work frame from various directions beside the three hand-eye vision systems for clamp cover detection to address the occlusion problem on clamps, which increased the number of cameras to sixteen; and (4) adding a laser head on the end-effector of each robot arm in case precise measurement of a wire segment was demanded.

Instead of directly detecting the clamp covers on a wire harness visually, Jiang et al. [30] proposed to adapt a tracing operation to identify the position of clamp covers on a wire harness first.Then, the markers on the clamp cover were recognized with one wrist CMOS camera (Point Grey Firefly MV) on the right robot arm to estimate the pose of the identified clamp cover so that the robot could manipulate it in later procedures [30].


#### Mating of connectors

Mating of connectors is critical in the final assembly of wire harnesses in terms of function and quality.Table 4 summarizes the seven articles focusing on different stages of the mating of connectors, which can be grouped into three sub-procedures: (1) pre-assembly; (2) mating; and (3) post-assembly.Pre-assembly is the initial process where the vision system acquires the necessary information to guide the movement of a robot toward connectors and the later robotized mating operation.There were five articles discussing various tasks in pre-assembly, including connector detection [39,17,19], pose estimation [19], and fault detection [38,10].

Perceiving the 3D geometric information of connectors, such as position and orientation, are essential for robotized mating connectors on flexible wire harnesses.Tamada et al. [39] proposed to use a high-speed camera (EoSens series, MC1362, Mikrotron) fixed above the workbench to distinguish the types of connectors and acquire their positions and orientations by detecting the corners of the connectors at a frame rate of 500 fps.Yumbla et al. [17] targeted on obtaining the precise positions of the plug-in cable connectors on a workbench and proposed to adopt an Intel RealSense D435 depth camera for the recognition process based on image processing.The captured RGB images were first processed through a sequence of image processing methods, including color space conversion and color thresholding [17].Then, depth information captured by the depth camera was integrated to obtain the 3D information of connectors for further robotized manipulation [17].Zhou et al. [19] proposed a two-step connector detection algorithm and verified it with a dual-arm robot using three cameras: one fixed global camera and one hand-eye camera on each of the two robot arms.The first step of Zhou et al. [19] was a learning-based rough locating, where a 2D grayscale image of the wire harness captured by the fixed global camera was processed by MobileNet-SSD [47] to locate the connectors roughly.Then, one of the hand-eye cameras on the robot arms reached the top of the located connector to capture images for a shape-based fine positioning to obtain the 6-degrees-of-freedom (6-DOF) pose of the detected connector for further manipulation based on computer-aided design (CAD) models and multi-view image matching [19].

Previous studies have also discussed quality assurance in collecting connectors by the gripper on a robot arm.Di et al. [38] proposed to use an In-Sight 5100 camera for computer vision-based connector grasping error detection and quality control to confirm that the connector was caught correctly and conveyed to the correct position.To do so, the relative translational and rotational displacements between the gripper and the connector were examined based on basic pattern matching with image processing [38].Besides, Di et al. [38] implemented this fault detection after inserting the connectors to examine the operation result.However, the experiment results of Di et al. [38] indicated the insufficient training samples and the only single camera used as the main reasons behind the misclassifications.Sun et al. [10] further improved Di et al. [38] by adding one more camera perpendicular to the first one to detect magnitudes of tilt angles and horizontal displacements on each side based on pattern matching.

Been collected by a gripper, the connector is transported and mated to the target counterpart.Previous studies proposed vision-based solutions for guiding and monitoring the mating process [16,39,40].Di et al. [16] focused on the monitoring task and implemented two mutually perpendicular cameras to observe all the relative and online motions between the two connectors by pattern matching.To locate the connector headers, Song et al. [40] proposed visual servoing with markers and adopted a hand-eye camera (FL2G-13S2C-C, Point Grey Research) to track the headers of connectors.In addition to connector detection in pre-assembly, Tamada et al. [39] also proposed to use the high-speed vision system to monitor the mating process in real-time by detecting the distance between the held and the target connector.


#### Wire harness recognition

Besides clamps and connectors, the wire part of a wire harness is also critical to address.The recognition of the wire part can provide a better perception of the overall structure of a wire harness.There are three studies discussing wire harness recognition, as listed in Table 5, focusing on the interpretable classification of branches [20], wire recognition [18], and grasp detection [21], respectively.Visual recognition RGB-D --Machine learning-based [21] Grasp detection Photoneo PhoXi M GF 1 Fast Graspability Evaluation [48] Kicki et al. [20] focused on the interpretable classification of wire harness branches.For classification, Kicki et al. [20] proposed a dataset containing RGB-D images of four branches of an automotive wire harness and several convolutional neural networks (CNNs) [49] sharing the same Downsample layer from ERFNet [50] for classification based on different data modalities.The images in the proposed dataset of Kicki et al. [20] were captured by an Intel RealSense D435 depth camera mounted 50 cm above the ground level.Data augmentation with elastic transformation and a network pre-trained with the inpainting task were also evaluated in Kicki et al. [20].The experiment results of Kicki et al. [20] on various input modalities demonstrated the best accuracy achieved by classifying with a sum of logits of models taking RGB data and depth information as input, respectively, following the late prediction fusion [46].

Further experiments dealing with small datasets in Kicki et al. [20] indicated a significant drop in the performance with the classification network pre-trained on the inpainting task but a performance improvement with data augmentation using elastic transform.Kicki et al. [20] also visualized the classification results using a saliency map based on class activation mapping (CAM) [45] to interpret the experimental results better visually.

Guo et al. [18] proposed a multi-branch wire harness object recognition with sequential segmentation and probabilistic estimation in aircraft assembly.In the proposal [18], the raw point cloud data was first acquired using an RGB-D camera.Then, the raw data was pre-processed to supervoxels by over-segmentation.Based on the supervoxels, wires were segmented considering the Cartesian distance, color similarity, and bending continuity.After segmentation, there were inevitable gaps in the segmentation result due to sheltering or occlusion, which were further remedied by estimation with Gaussian Mixture Model (GMM) [51] to obtain the complete segmented point cloud of deformable wires.

Zhang et al. [21] explored the industrial bin-picking problem on wire harnesses and proposed learning a bin-picking policy to infer an optimal grasp and a post-grasping action from a top-down depth image of the cluttered wire harnesses, which enabled the system to prioritize grasping the untangled objects, avoid grasping at the bad positions, and reason the extracting distance to reduce the execution time for a successful picking.The vision system in Zhang et al. [21] included a Photoneo PhoXi 3D scanner M fixed directly above the workbench.Given a top-down depth image as an observation of the current entanglement situation, a model-free grasp detection based on Fast Graspability Evaluation (FGE) [48] was adapted in Zhang et al. [21] to detect collision-free grasps, which output a set of grasp candidates ordered by their FGE scores.Then, Zhang et al. [21] trained an action success prediction module via a proposed active learning scheme to predict the success possibilities of the disentangling actions, where the captured depth image, the set of grasp candidates, and the pre-defined action candidates were encoded and processed using different convolutional neural networks (CNNs) [49].The action-grasp pair to conduct the operation was then selected based on the FGE [48] score and the action complexity [21].However, the experiment results of Zhang et al. [21] indicated visual noise and heavy occlusion as two significant challenges leading to failure pickings.


### Research on operations of wire harness assembly

The identified studies can also be synthesized regarding to which operation of wire harness assembly the proposed vision systems contributed, as shown in Table 6.The majority of previous research discussed computer vision techniques for the assembly procedure, including four studies on the fixing of clamps [13,11,12,30] and seven studies on the mating of connectors [38,10,16,39,40,17,19].The interpretable classification of wire harness branches explored in Kicki et al. [20] and the recognition method for wires proposed in Guo et al. [18] can support the robotic routing with a better understanding of the topology of wire harnesses.Koo et al. [13], Jiang et al. [11], and Jiang et al. [12] proposed to install covers on clamps to facilitate the detection and manipulation of clamps on wire harnesses, which, on the other hand, can also assist the robotic routing of wire harnesses by locating the positions of clamps.However, as summarized in Section 2.1, there are also other operations within the overall wire harness assembly onto vehicles, such as preparation, transport, and disentanglement, which gained little attentions [21].

Since the wire harness is processed as a pack in the operation of preparation and transport, the task for the vision system will mainly be identifying the pack of wire harnesses and the location for dropping it.However, the disentanglement of wire harnesses leads to more problems requiring future research because a dynamic robotic manipulation strategy is needed so that the robot system can react to the deformation of wire harnesses, which stresses the significance of the real-time tracking of the wire harness.


### Evaluation on the vision systems

All the analyzed articles contained experimental studies in laboratory configurations and conducted various evaluations of their proposals [13,11,12,30,38,10,16,39,40,17,19,20,18,21].Specifically, there were various metrics for evaluating the performance of the vision systems in some of the proposals qualitatively and quantitatively, as summarized in Table 7 and Table 8, respectively, though some studies adopted vision systems without reporting the evaluation of their vision systems explicitly [11,12,30,10,16,39,40,21]. Koo et al. [13] and Song et al. [40] qualitatively indicated the technical feasibility of their vision systems for facilitating the robotized manipulation of clamp covers and estimating the relative position of the connector header, respectively.Yumbla et al. [17] demonstrated the qualitative evaluation of their vision system by presenting the detection results with bounding boxes around detected connectors and position references of detected connectors in a simulation environment.Di et al. [38] reported the fault detection rate to quantitatively reflect the performance of their proposed vision system.Besides, Zhou et al. [19], Kicki et al. [20], and Guo et al. [18] reported both qualitative and quantitative experiment results.Zhou et al. [19] presented a bounding box and a pose frame around the detected connector to demonstrate the performance of detection qualitatively and summarized average precision (AP), repeatability evaluation, and average and max-min error to illustrate the performance and reliability of the proposed algorithm quantitatively.In addition to the qualitative evaluation result with saliency map, Kicki et al. [20] also reported classification accuracy and confusion matrix to demonstrate the performance of their proposal quantitatively.Moreover, Guo et al. [18] evaluated the practicality of their proposal by examining the time cost of each block of their proposed recognition method.Article Component Metrics [13] Clamp - [40] Connector - [17] Connector Bounding box; position reference [19] Connector Bounding box; pose [20] Wire Class-agnostic saliency map based on CAM [45] [18] Wire Recognition results

Table 8: Quantitative evaluation on vision systems in previous studies.

Article Component Metrics [38] Connector Fault detection rate [19] Connector Average precision (AP); evaluation of repeatability; average and max-min error [20] Wire Classification accuracy; confusion matrix [18] Wire Accuracy; time cost


## Discussion

In general, computer vision-based methods proposed in previous research efforts were designed for a better visual machine perception on different levels of constituent structure of wire harnesses so that the control system of robotized wire harness assembly could estimate the state of assembly autonomously for various tasks, including manipulation of different components of wire harnesses [13,38,10,11,12,16,39,30,40,17,19], monitoring sub-processes of the assembly [38,16,40,20,18], and fault detection in the assembly [38].These solutions were mainly achieved with vision-based classification and detection on various components of wire harnesses, such as clamps [13,11,12,30], connectors [38,10,16,39,40,17,19], and wires [20,18,21].The proposed vision systems also contributed to different operations regarding current work instructions for wire harness assembly in practical production, including disentanglement [21], routing [13,11,12,20,18], and assembly [13,11,12,30,38,10,16,39,40,17,19].Nevertheless, these existing studies have also implied challenges and opportunities for future research toward more efficient and practical computer vision-driven robotized wire harness assembly.


### Object recognition and detection algorithms

Computer vision techniques have been implemented in various industrial manufacturing systems to promote the level of informatization, digitization, and intelligence [15].Increasing research efforts in computer vision and robotics have paid attention to the complex DLO manipulation, addressing both theoretical research [52,53,54] and engineering practices [38,12,30,29,18].

However, for robotized wire harness assembly, it is necessary to recognize wire harnesses successfully within a limited processing time in order to conduct planning and control of automated manipulation under constrained production rate [18].Besides, estimating the shape of a wire harness by a totally vision-based algorithm in practical applications in an actual production plant indicates extracting image features from an intricate background [13].On the other hand, the automotive industry has not identified a satisfactory vision-based automation solution that can recognize different components of a wire harness as robustly as humans, especially under hardly consistent production configuration in practical manufacturing, which has attracted plenty of studies on wire harness component recognition in the past few years [13,11,12,30,38,10,16,39,40,17,19,20,18,21].

Previously, clamp detection was achieved with the assistance of clamp covers with a unique design and markers [13,11,12,30].The clamp covers can facilitate the recognition and manipulation of clamps with relatively small sizes and complex structures.However, the clamp covers can be problematic considering the practical assembly of wire harnesses in a vehicle, especially in cramped installation areas.It is also not feasible considering an increasing number of wire harnesses assembled in future products like electric cars.Thus, clamp detection methods without installing additional parts on clamps are desired.

As for connector, recognition was mainly used to provide geometric information to the control system so that the robot could flexibly perceive and manipulate the connectors [38,10,16,39,40,17,19].Previous research mainly adapted 2D image recognition to acquire the positions or orientations of connectors [38,10,16,39,40,19].Tamada et al. [39], using a 2D camera, assumed that all connectors were placed on a flat workbench to reduce the degrees of freedom.However, considering the actual manufacturing scenario, wire harnesses are not fixed on a flat workbench before or during assembly, making the connectors distribute randomly in a 3D space.Thus, the degrees of freedom of connectors cannot be reduced directly.Although an RGB-D camera was adopted, Yumbla et al. [17] acquired the positions of connectors based on 2D image processing and integrated depth information captured by the RGB-D camera to further obtain the 3D measurement of connectors instead of processing depth or other 3D information independently or together with 2D color information.Zhou et al. [19] proposed a shape-based 3D matching method, where CAD models of connectors were registered to the detection results based on 2D connector detection to obtain the 3D information of detected connectors.Considering the increasingly advancing and affordable photography technology and recent development of algorithms in the computer vision community, it is promising to implement depth or other 3D cameras to acquire spatial information and process 3D information directly, which indicates detection and pose estimation of connectors based on 3D information a direction of future research.

Besides, studies on recognition of the wire part [20,18,21] have explored more advanced RGB-D camera or 3D scanner and learning-based algorithms and have demonstrated the performance of 3D vision applications on facilitating a better perception of the structure of wire harnesses, which, on the one hand, creates a possibility for robotized preparation, transport, disentangling, and routing of wire harnesses in the future assembly station, on the other hand, provides references to address computer vision applications on the other components of wire harnesses based on 3D data.

Furthermore, the timeliness of previous studies deserves further research, especially for research in clamp manipulation, as indicated in Figure 6.Earlier research in the analysis mainly achieved 2D image recognition on clamp covers and connectors with traditional image processing methods [13,11,12,30,38,10,16,39,40,17].By contrast, more recent studies on wire recognition took advantage of learning-based algorithms [19,20,18], which enabled more robust recognition of objects with a more complex structure, like the flexible and deformable wire.The boosting development in 3D cameras makes acquiring and processing 3D visual information more achievable.The recent renaissance of convolutional neural network (CNN) [49] and the successful development of deep learning in computer vision research [55] also provide more learning-based designs and solutions for 2D and 3D visual machine perception in the future robotized assembly of wire harnesses.Nonetheless, the dataset is essential for learning-based object detection [56,57,58] and scalable deep learning-based computer vision applications in manufacturing [59,15].Additionally, using benchmarks is critical to assess and compare the performance across different computer vision and robotic systems, which is, though increasingly popular within the robotics community, missing in previous research in robotized wire harness assembly [60].Thus, it demands more studies on the learning networks, datasets, benchmarks, and metrics to promote the performance of learning-based computer vision techniques implemented for future robotized wire harness assembly and evaluate them consistently.

In addition, some studies in the initial search results also referred wire harness assembly to the operations in the manufacturing process of wire harnesses [22,2,23].Straightforwardly, some problems are shared among computer vision applications in the manufacturing of wire harnesses and the assembly of wire harnesses onto other products, for example, the detection of connectors or clamps and state estimation for wire manipulation.Some vision-based solutions have already been discussed in previous research for wire harness manufacturing or wire harness assembly process [61,62,63], whose designs on vision systems could be transplanted to robotized assembly of wire harnesses being discussed in this study.


### Practicality and reliability of vision systems

Although the analyzed articles [13,11,12,30,38,10,16,39,40,17,19,20,18,21] have demonstrated various solutions for achieving different tasks of robotized wire harness assembly under laboratory settings, the practicality and reliability of the state-of-the-art vision system in practical applications remain obscure.Table 7 and Table 8 present the qualitative and quantitative evaluations conducted on vision systems in different studies.Yet, few studies considered the issues of practicality and reliability, such as repeatability of the proposal [19] and time cost on the vision system [18].

In a practical manufacturing environment, it is inevitable for the vision system to cope with inconsistent conditions, such as background [13] and illumination [12].Koo et al. [13] revealed the complex background as a non-negligible hindrance for a totally vision-based wire shape estimation in an actual plant.Jiang et al. [12] indicated the lack of vision and laser processing robustness as one of the significant reasons behind experiment failures, for example, the variation of illumination conditions.

From the business perspective, there is also a demand for the processing time of robotized assembly to fulfill the productivity in practical production, which requires the vision system to perceive the state of the object to be manipulated fast enough to allow for a following robot action [64].Jiang et al. [11] demonstrated the technical feasibility of robotized wire harness assembly, but the average speed and reliability were still far from the requirement of practical application.Guo et al. [18] also identified the necessity of promoting time efficiency.Therefore, evaluating the vision system from the perspective of processing time is desired and necessary, which, however, was involved little in previous research [18].

Thus, it is critical to evaluate the practicality and reliability of vision systems regarding different perspectives, such as recognition accuracy, processing speed, and physical facilities in the assembly station, under actual production configurations with various background and illumination conditions.It is also critical for practical application to consider the pay-off of implementing vision systems to automate the wire harness assembly, which affects sustainability from the economic perspective [3,65,60].

Another practical issue that has not been discussed in previous studies [13,11,12,30,38,10,16,39,40,17,19,20,18,21] is the fact that some wire harnesses are installed onto the vehicle frames on a moving production line [14], for which Shi et al. [14] proposed a method for guiding a mobile robot manipulator to assemble wire harnesses onto a moving vehicle with visual servoing.Nevertheless, the processing time and feature engineering are still challenging [14].


### Human-robot collaboration in future wire harness assembly

The flexibility of wire harnesses has been identified as a significant problem for automating the assembly of wire harnesses regarding the perception and manipulation [13].Automation has been widely adopted in manufacturing since the third industrial revolution [9].Nevertheless, the lack of flexibility and cognitive ability in robots motivates the study of human-robot collaboration (HRC) [66], where the system can benefit from the symbiosis of humans' flexibility and robots' repeatability and high accuracy.Recently, Industrial 5.0 [67,68,69] has also been initiated with a focus on sustainability, human-centricity, and resilience, further promoting the discussions on implementing human-robot collaboration in industrial applications towards human-centric automation [66].

There have also been studies on human-robot collaboration driven by computer vision techniques in industrial applications [70,71,72,73].However, previous research on robotized assembly of wire harnesses with computer vision applications [13,11,12,30,38,10,16,39,40,17,19,20,18,21] focused on fully robotized assembly and considered the manipulation of components of wire harnesses separately, which leads to a lack of research on robotized assembly of wire harnesses considering human-centered automation or human-robot collaboration.

Nonetheless, several challenges demand further research to introduce human-robot collaboration to robotized wire harness assembly, for example, safety and the interaction between the human operator and the robot, which makes it crucial to design the workspace to maximize the efficiency of human-robot collaboration while minimizing the risk of accidents.Conventionally, industrial robots are surrounded by physical fences or laser curtains in practical automated production lines to ensure the safety of the operation.However, in human-robot collaboration, a human operator and a robot work at a closer distance than the one for current industrial robots, which significantly promotes the priority of ensuring the safety of human operators [74,75].Various computer vision techniques for facilitating an efficient and safe human-robot collaboration have been discussed previously, including collision detection, environment perception, human action or gesture recognition, and proactive human-robot collaboration [76,77,78,79], which pave the way for robotized wire harness assembly with computer vision-driven human-robot collaboration.


### Product design on wire harnesses and robot grippers

Previously, Koo et al. [13] identified that, though the clamps could be regarded as rigid objects, their relatively small sizes and complex shapes made clamps challenging to grasp directly by a robot gripper.Multi-finger robot hands were also problematic, considering the difficulty of developing the control program and the insufficient payload [13].Therefore, clamp covers with markers were installed to facilitate the detection and manipulation of clamps [13,11,12,30].However, affixing clamp covers will be impractical in future production with increasingly more wire harnesses installed in tight areas.Thus, inspired by "Design for X (DfX)" philosophy [80] and the development of new tools for automating the manufacturing process of wire harnesses [81], new gripper designs [82] and novel clamp designs are desired to facilitate visual detection and robotic manipulation without any additional parts attached to clamps.

Besides, various intrinsic properties of current wire harnesses, for example, the same color of clamps and taped wires and the small radial scale and complex structure of wire harnesses with irregular curves and crossings, also make it considerably challenging to recognize wire harnesses from the complex background and assemble automatically [13,18].Therefore, product designs on other components of wire harnesses are also promising to promote computer vision-driven robotized wire harness assembly.


## Conclusion

Robotized wire harness assembly is desired in the automotive industry, considering its strength in promoting quality, productivity, and ergonomics.However, it is challenging due to the demanding production requirements and the flexibility and deformability of wire harnesses.Previous research efforts explored various computer vision techniques for facilitating robotized wire harness assembly with better visual machine perception of the wire harness components to be manipulated and the operation of manipulation.They proposed different computer vision-based solutions for multiple tasks in robotized wire harness assembly, such as manipulating clamps and connectors, monitoring the mating of connectors, fault detection, and bin picking by detecting different components of wire harnesses, including clamps, connectors, and wires.Nonetheless, the automotive industry has identified no practical application of computer vision-driven robotized wire harness assembly in actual production.Therefore, it is necessary to understand the current research and identify the challenges to advance toward a more efficient and practical computer vision-enabled robotized wire harness assembly.

This article presents a systematic literature review of the state of the art in computer vision applications in robotized wire harness assembly, where the challenges for vision systems were identified, including that:

• The robustness of vision systems in actual production has not achieved the compatible level as humans, especially considering the demanding production rate and intricate production environments, such as the background and illumination conditions of visual inputs;

• Intrinsic physical properties of different components of wire harnesses and robot grippers were identified as hindrances to the automatization of wire harness assembly.

Nevertheless, future research opportunities toward more efficient and practical computer vision applications in robotized wire harness assembly were also suggested based on the findings from the literature, including:

• Developing new object detection and recognition algorithms based on the recent significant advances in 3D imaging technology and deep learning in computer vision in addition to the 2D RGB-based object detection and recognition prevailing in previous studies;

• Discussing and adapting computer vision-based solutions for object recognition and detection proposed for the robotized assembly process of manufacturing wire harnesses;

• Assessing the computer vision solutions under practical manufacturing scenarios to validate the practicality, reliability, and sustainability of the proposed vision systems;

• Discussing new vision system designs considering human-robot collaborations and different assembly operations besides fully automated operation on different parts of wire harnesses to take advantage of the combination of humans' strength in perception and flexibility and robots' superiority in payload, accuracy, and repeatability;

• Exploring new product designs of wire harnesses and robot grippers to facilitate more efficient visual recognition and robotic manipulation.

## Figure 1 :
1
Figure 1: An example of an automotive wire harness.


## Figure 2 :
2
Figure 2: The electrical infrastructure: front, central, cabin, and rear cable systems of a Volvo XC40 Recharge.(Courtesy of Volvo Car Corporation).


## Figure 3 :
3
Figure 3: The heavily-increasing length of wires in passenger cars over time.(Courtesy of Volvo Car Corporation)


## Figure 4 :
4
Figure 4: PRISMA [37] flow diagram of review process.


## Figure 5 :
5
Figure 5: The number of publications per year and the total number of publications and citations by each year.The total number of publications and citations for the year 2023 are excluded considering the incomplete statistics at the time of searching.


## Table 1 :
1
Review protocol for a systematic literature review on computer vision applications in the robotized assembly of wire harnesses.
Review criteriaDatabaseScopusSearch string(wir* OR cabl*) AND (harness* OR bundl*) AND assembl*Search fieldArticle title, Abstract, KeywordsSubject areaEngineering; Computer Science; Multidisciplinary; Business, Management and Accounting; Decision SciencesArticle languageEnglishInclusion criteria Proposing computer vision-based algorithm and/or technology for robotized wire harness assemblyExclusion criteria Not about wire harnesses; not about robotized assembly; about the manufacturing of wire harnessesSearch dateFebruary 2, 2023

## Table 3 :
3
Computer vision-based clamp recognition for clamp manipulation.
Location of cameras Article Type of vision Number of camerasMethodEnd-effector[13]Stereo4SIFT [41, 42][11, 12]Stereo6ARToolKit [43, 44][30]Monocular1ARToolKit [43, 44]Work cell[11, 12]Monocular10

## Table 4 :
4
Computer vision applications in articles addressing the mating of connectors.(TV = type of vision; TC = type of cameras; LC = location of cameras; NC = number of cameras; GF = globally fixed; HE = hand-eye)
ProcessPurposeTVTCLCNCMethod2D 2.5DPre-assemblyConnector detection[39]-MC1362GF1Image processing-[17]RealSense D435HE1Image processing[19]-Industrial cameras GF+HE 1+2Learning-and model-basedPose estimation[19]-Industrial cameras GF+HE 1+2Learning-and model-basedFault detection[38]-In-Sight 5100GF1Pattern matching[10]-CCD camerasGF2Pattern matchingMatingRelative position detection [16]-CCD camerasGF2Pattern matching[39]-MC1362GF1Image processing[40]-FL2G-13S2C-CHE1Visual servoing with pattern matchingPost-assemblyFault detection[38]-In-Sight 5100GF1Pattern matching

## Table 5 :
5
Computer vision applications in articles for wire harness recognition.(TC = type of cameras; LC = location of cameras; NC = number of cameras; GF = globally fixed)
ArticlePurposeTCLC NCMethod[20]Interpretable classificationRealSense D435GF (1)Deep learning-based[18]

## Table 6 :
6
Contributions of computer vision techniques in previous studies to different assembly operations.
Assembly operation ArticlesPreparation-Transport-Disentanglement[21]Route[13, 11, 12, 20, 18]Assembly[13, 11, 12, 30, 38, 10, 16, 39, 40, 17, 19]

## Table 7 :
7
Qualitative evaluation on vision systems in previous studies.

This work was supported by the Swedish innovation agency, Vinnova, and the strategic innovation program, Produktion2030, under grant number 2022-01279.The work was carried out within Chalmers' Area of Advance Production.The support is gratefully acknowledged.
The meaning of net zero and how to get it right. S Fankhauser, S M Smith, M Allen, K Axelsson, T Hale, C Hepburn, J M Kendall, R Khosla, J Lezaun, E Mitchell-Larson, 10.1038/s41558-021-01245-wNature Climate Change. 1212022

Manufacturing automation for automotive wiring harnesses. H G Nguyen, M Kuhn, J Franke, 10.1016/j.procir.2020.05.254Procedia CIRP. 972021

Economic comparison of wire harness assembly systems. E Aguirre, B Raucent, 10.1016/0278-6125(94)90035-3Journal of Manufacturing Systems. 1341994

The effect of learning factors due to low volume order fluctuations in the automotive wiring harness production. J Tilindis, V Kleiza, 10.1016/j.procir.2014.05.019Procedia CIRP. 192014

Ergonomic contribution of able exoskeleton in automotive industry. N Sylla, V Bonnet, F Colledani, P Fraisse, 10.1016/j.ergon.2014.03.008International Journal of Industrial Ergonomics. 4442014

Towards an operator 4.0 typology: A human-centric perspective on the fourth industrial revolution technologies. D Romero, J Stahre, T Wuest, O Noran, P Bernus, Å Fast-Berglund, D Gorecky, 2016

Worker information system to support during complex and exhausting assembly of high-voltage harness. C Fischer, J Bönig, J Franke, M Lušić, R Hornfeck, 10.1109/EDPC.2015.73232115th International Electric Drives Production Conference (EDPC). 2015. 2015

Manufacturing processes of automotive high-voltage wire harnesses: State of the art, current challenges and fields of action to reach a higher level of automation. S Olbrich, J Lackinger, 10.1016/j.procir.2022.05.041leading manufacturing systems transformation -Proceedings of the 55th CIRP Conference on Manufacturing Systems. 2022. 2022107

J Leng, W Sha, B Wang, P Zheng, C Zhuang, Q Liu, T Wuest, D Mourtzis, L Wang, 10.1016/j.jmsy.2022.09.017Industry 5.0: Prospect and retrospect. 202265

Robotic wiring harness assembly system for fault-tolerant electric connectors mating. B Sun, F Chen, H Sasaki, T Fukuda, 10.1109/MHS.2010.56695332010 International Symposium on Micro-NanoMechatronics and Human Science. 2010

Robotized assembly of a wire harness in car production line. X Jiang, K -M. Koo, K Kikuchi, A Konno, M Uchiyama, 10.1109/IROS.2010.5653133IEEE/RSJ International Conference on Intelligent Robots and Systems. 2010. 2010

Robotized assembly of a wire harness in a car production line. X Jiang, K.-M Koo, K Kikuchi, A Konno, M Uchiyama, 10.1163/016918610X551782doi:10.1163/016918610X551782Advanced Robotics. 253-42011

Development of a robot car wiring system. K Mo Koo, X Jiang, K Kikuchi, A Konno, M Uchiyama, 10.1109/AIM.2008.4601774IEEE/ASME International Conference on Advanced Intelligent Mechatronics. 2008. 2008

Mobile robotic assembly on a moving vehicle. J Shi, B Hamner, R Simmons, S Singh, 10.1115/ISFA2012-7193International Symposium on Flexible Automation. American Society of Mechanical Engineers201245110

Computer vision techniques in manufacturing. L Zhou, L Zhang, N Konz, 10.1109/TSMC.2022.3166397IEEE Transactions on Systems, Man, and Cybernetics: Systems. 5312023

Vision-force guided monitoring for mating connectors in wiring harness assembly systems. P Di, F Chen, H Sasaki, J Huang, T Fukuda, T Matsuno, 10.20965/jrm.2012.p0666Journal of Robotics and Mechatronics. 2442012

Preliminary connector recognition system based on image processing for wire harness assembly tasks. F Yumbla, M Abeyabas, T Luong, J.-S Yi, H Moon, 10.23919/ICCAS50221.2020.926829120th International Conference on Control, Automation and Systems (ICCAS). 2020. 2020

Visual recognition method for deformable wires in aircrafts assembly based on sequential segmentation and probabilisitic estimation. J Guo, J Zhang, Y Gai, D Wu, K Chen, 10.1109/ITOEC53115.2022.97344322022 IEEE 6th Information Technology and Mechatronics Engineering Conference (ITOEC). 20226

A practical solution to deformable linear object manipulation: A case study on cable harness connection. H Zhou, S Li, Q Lu, J Qian, 10.1109/ICARM49381.2020.91953802020 5th International Conference on Advanced Robotics and Mechatronics (ICARM). 2020

Tell me, what do you see?-interpretable classification of wiring harness branches with deep neural networks. P Kicki, M Bednarek, P Lembicz, G Mierzwiak, A Szymko, M Kraft, K Walas, 10.3390/s21134327Sensors. 21132021

Learning efficient policies for picking entangled wire harnesses: An approach to industrial bin picking. X Zhang, Y Domae, W Wan, K Harada, 10.1109/LRA.2022.3222995IEEE Robotics and Automation Letters. 812023

Overview of the state of the art in the production process of automotive wire harnesses, current research and future trends. J Trommnau, J Kühnle, J Siegert, R Inderka, T Bauernhansl, 10.1016/j.procir.2019.03.067Procedia CIRP. 812019

Wire harness assembly process supported by collaborative robots: Literature review and call for r&d. G E Navas-Reascos, D Romero, J Stahre, A Caballero-Ruiz, 10.3390/robotics11030065Robotics. 113652022

International Organization for Standardization, Iso 10218-1:2011 robots and robotic devices -safety requirements for industrial robots -part 1: Robots. 2011

International Organization for Standardization, Iso 10218-2:2011 robots and robotic devices -safety requirements for industrial robots -part 2: Robot systems and integration. 2011

Safety design and development of a human-robot collaboration assembly process in the automotive industry. S Heydaryan, J Suaza, G Bedolla, Belingardi, 10.3390/app8030344Applied Sciences. 832018

Dynamic modeling and control of deformable linear objects for single-arm and dual-arm robot manipulations. N Lv, J Liu, Y Jia, 10.1109/TRO.2021.3139838IEEE Transactions on Robotics. 3842022

Challenges and outlook in robotic manipulation of deformable objects. J Zhu, A Cherubini, C Dune, D Navarro-Alarcon, F Alambeigi, D Berenson, F Ficuciello, K Harada, J Kober, X Li, J Pan, W Yuan, M Gienger, 10.1109/MRA.2022.3147415IEEE Robotics & Automation Magazine. 2932022

Robotic manipulation and sensing of deformable objects in domestic and industrial applications: a survey. J Sanchez, J.-A Corrales, B.-C Bouzgarrou, Y Mezouar, 10.1177/0278364918779698The International Journal of Robotics Research. 3772018

Robotized recognition of a wire harness utilizing tracing operation. X Jiang, Y Nagaoka, K Ishii, S Abiko, T Tsujita, M Uchiyama, 10.1016/j.rcim.2014.12.002Robotics and Computer-Integrated Manufacturing. 342015

B Kitchenham, Procedures for performing systematic reviews. edures for performing systematic reviewsKeele, UK, Keele University2004. 200433

J Rowley, F Slack, 10.1108/01409170410784185Conducting a literature review. 2004

Producing a systematic review. D Denyer, D Tranfield, 2009

A comparison study of impact factor in web of science and scopus databases for engineering education and educational technology journals. P.-N Chou, 10.28945/1615Issues in Informing Science and Information Technology. 92012

Microsoft academic: is the phoenix getting wings?. A.-W Harzing, S Alakangas, 10.1007/s11192-016-2185-xScientometrics. 11012017

Effectiveness and efficiency of search methods in systematic reviews of complex evidence: audit of primary sources. T Greenhalgh, R Peacock, 10.1136/bmj.38636.593461.68BMJ. 33175242005

The prisma 2020 statement: an updated guideline for reporting systematic reviews. M J Page, J E Mckenzie, P M Bossuyt, I Boutron, T C Hoffmann, C D Mulrow, L Shamseer, J M Tetzlaff, E A Akl, S E Brennan, doi:s13643-021-01626-4Systematic reviews. 1012021

Hybrid vision-force guided fault tolerant robotic assembly for electric connectors. P Di, J Huang, F Chen, H Sasaki, T Fukuda, 10.1109/MHS.2009.53520782009 International Symposium on Micro-NanoMechatronics and Human Science. 2009

High-speed manipulation of cable connector using a high-speed robot hand. T Tamada, Y Yamakawa, T Senoo, M Ishikawa, 10.1109/ROBIO.2013.67396952013 IEEE International Conference on Robotics and Biomimetics (ROBIO). 2013

Electric connector assembly based on vision and impedance control using cable connector-feeding system. H.-C Song, Y.-L Kim, D.-H Lee, J.-B Song, 10.1007/s12206-017-1144-7Journal of Mechanical Science and Technology. 31122017

Object recognition from local scale-invariant features. D Lowe, 10.1109/ICCV.1999.790410Proceedings of the Seventh IEEE International Conference on Computer Vision. the Seventh IEEE International Conference on Computer Vision19992

Distinctive image features from scale-invariant keypoints. D G Lowe, 10.1023/B:VISI.0000029664.99615.94International journal of computer vision. 6022004

. H Kato, Artoolkit , 1999

Marker tracking and hmd calibration for a video-based augmented reality conferencing system. H Kato, M Billinghurst, 10.1109/IWAR.1999.803809Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99). 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99)1999

Learning deep features for discriminative localization. B Zhou, A Khosla, A Lapedriza, A Oliva, A Torralba, 10.1109/CVPR.2016.3192016 IEEE Conference on Computer Vision and Pattern Recognition. 2016

On robustness of multi-modal fusion-robotics perspective. M Bednarek, P Kicki, K Walas, 10.3390/electronics9071152Electronics. 972020

A G Howard, M Zhu, B Chen, D Kalenichenko, W Wang, T Weyand, M Andreetto, H Adam, 10.48550/arXiv.1704.04861arXiv:1704.04861Mobilenets: Efficient convolutional neural networks for mobile vision applications. 2017arXiv preprint

Fast graspability evaluation on single depth maps for bin picking with general grippers. Y Domae, H Okuda, Y Taguchi, K Sumi, T Hirai, 10.1109/ICRA.2014.6907124IEEE International Conference on Robotics and Automation (ICRA). 2014. 2014

Deep learning. I Goodfellow, Y Bengio, A Courville, 2016MIT press

Erfnet: Efficient residual factorized convnet for real-time semantic segmentation. E Romera, J M Álvarez, L M Bergasa, R Arroyo, 10.1109/TITS.2017.2750080IEEE Transactions on Intelligent Transportation Systems. 1912018

Gaussian mixture models. D A Reynolds, 10.1007/978-0-387-73003-5_196Encyclopedia of biometrics. 7412009

Motion planning for robotic manipulation of deformable linear objects. M Saha, P Isto, 10.1109/ROBOT.2006.1642074IEEE. 2006. 2006. ICRA 2006. 2006

Tracking deformable objects with point clouds. J Schulman, A Lee, J Ho, P Abbeel, 10.1109/ICRA.2013.6630714IEEE. 2013. 2013

A framework for manipulating deformable linear objects by coherent point drift. T Tang, C Wang, M Tomizuka, 10.1109/LRA.2018.2852770IEEE Robotics and Automation Letters. 342018

Deep learning. Y Lecun, Y Bengio, G Hinton, 10.1038/nature14539nature. 52175532015

The pascal visual object classes (voc) challenge. M Everingham, L Van Gool, C K Williams, J Winn, A Zisserman, 10.1007/s11263-009-0275-4International journal of computer vision. 882009

T.-Y Lin, M Maire, S Belongie, J Hays, P Perona, D Ramanan, P Dollár, C L Zitnick, 10.1007/978-3-319-10602-1_48Microsoft coco: Common objects in context, in: Computer Vision-ECCV 2014: 13th European Conference. Zurich, SwitzerlandSpringerSeptember 6-12, 2014. 2014Proceedings, Part V 13

Imagenet large scale visual recognition challenge. O Russakovsky, J Deng, H Su, J Krause, S Satheesh, S Ma, Z Huang, A Karpathy, A Khosla, M Bernstein, 10.1007/s11263-015-0816-yInternational journal of computer vision. 1152015

Enabling deep learning using synthetic data: A case study for the automotive wiring harness manufacturing. H G Nguyen, R Habiboglu, J Franke, 10.1016/j.procir.2022.05.142Procedia CIRP. 1072022

Performance measures to benchmark the grasping, manipulation, and assembly of deformable objects typical to manufacturing applications. K Kimble, J Albrecht, M Zimmerman, J Falco, 10.3389/frobt.2022.999348Frontiers in Robotics and AI. 92022

Application of machine vision to inspect a wiring harness. W.-C Lee, K.-S Cao, 10.1109/ICPHYS.2019.87802922019 IEEE International Conference on Industrial Cyber Physical Systems (ICPS). 2019

Robotic wire pinning for wire harness assembly automation. E Tunstel, A Dani, C Martinez, B Blakeslee, J Mendoza, R Saltus, D Trombetta, G Rotithor, T Fuhlbrigge, D Lasko, J Wang, 10.1109/AIM43001.2020.91589052020 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM). 2020

A novel vision-based method for 3d profile extraction of wire harness in robotized assembly process. T P Nguyen, J Yoon, 10.1016/j.jmsy.2021.10.003Journal of Manufacturing Systems. 612021

An adaptable robot vision system performing manipulation actions with flexible objects. L Bodenhagen, A R Fugl, A Jordt, M Willatzen, K A Andersen, M M Olsen, R Koch, H G Petersen, N Krüger, 10.1109/TASE.2014.2320157IEEE Transactions on Automation Science and Engineering. 1132014

Robotic assembly of wire harnesses: Economic and technical justification. E Aguirre, L Ferrière, B Raucent, 10.1016/S0278-6125(97)88890-5Journal of Manufacturing Systems. 1631997

Overview of human-robot collaboration in manufacturing. L Wang, S Liu, H Liu, X V Wang, 10.1007/978-3-030-46212-3_2Proceedings of 5th International Conference on the Industry 4.0 Model for Advanced Manufacturing: AMP 2020. 5th International Conference on the Industry 4.0 Model for Advanced Manufacturing: AMP 2020Springer2020

Enabling Technologies for Industry 5.0 : results of a workshop with Europe's technology leaders, Publications Office. E Commission, D.-G Research, J Innovation, Müller, 10.2777/0826342020

Industry 5.0 : towards a sustainable, human-centric and resilient European industry, Publications Office of the European Union. E Commission, D.-G Research, M Innovation, L Breque, A De Nul, Petridis, 10.2777/3084072021

Industry 5.0, a transformative vision for Europe : governing systemic transformations towards a sustainable industry. E Commission, D.-G Research, A Innovation, S Renda, Schwaag, D Serger, A Tataj, D Morlet, F Isaksson, M Martins, C Mir Roca, A Hidalgo, S Huang, P Dixson-Declève, F Balland, C Bria, K Charveriat, E Dunlop, Giovannini, 10.2777/173222022Publications Office of the European Union

Robot guidance using machine vision techniques in industrial environments: A comparative review. L Pérez, Í Rodríguez, N Rodríguez, R Usamentiaga, D F García, 10.3390/s16030335Sensors. 1633352016

Design and implementation of a fuzzy logic-based joint controller on a 6-dof robot arm with machine vision feedback. D D Ligutan, L J S Cruz, M C D P Del Rosario, J N S Kudhal, A C Abad, E P Dadios, 10.1109/SAI.2017.8252111Computing Conference. 2017. 2017

Active collision avoidance for human-robot collaboration driven by vision sensors. A Mohammed, B Schmidt, L Wang, 10.1080/0951192X.2016.1268269International Journal of Computer Integrated Manufacturing. 3092017

Optimization of wire harness assembly using human-robot-collaboration. P Heisler, D Utsch, M Kuhn, J Franke, 10.1016/j.procir.2020.05.2358th CIRP Conference of Assembly Technology and Systems. 202197

Safe, flexible and productive human-robot-collaboration for disassembly of lithium-ion batteries, Recycling of lithium-ion batteries: the lithorec way. R Gerbers, K Wegener, F Dietrich, K Dröder, 10.1007/978-3-319-70572-9_6201899

Considerations of potential runaway motion and physical interaction for speed and separation monitoring. E Kim, Y Yamada, S Okamoto, M Sennin, H Kito, 10.1016/j.rcim.2020.102034Robotics and Computer-Integrated Manufacturing. 671020342021

Towards proactive human-robot collaboration: A foreseeable cognitive manufacturing paradigm. S Li, R Wang, P Zheng, L Wang, 10.1016/j.jmsy.2021.07.017Journal of Manufacturing Systems. 602021

Toward proactive human-robot collaborative assembly: A multimodal transfer-learning-enabled action prediction approach. S Li, P Zheng, J Fan, L Wang, 10.1109/TIE.2021.3105977IEEE Transactions on Industrial Electronics. 6982022

Vision-based holistic scene understanding towards proactive human-robot collaboration. J Fan, P Zheng, S Li, 10.1016/j.rcim.2021.102304Robotics and Computer-Integrated Manufacturing. 751023042022

Proactive human-robot collaboration: Mutual-cognitive, predictable, and self-organising perspectives. S Li, P Zheng, S Liu, Z Wang, X V Wang, L Zheng, L Wang, 10.1016/j.rcim.2022.102510Robotics and Computer-Integrated Manufacturing. 811025102023

10.1115/DETC2010-2909115th Design for Manufacturing and the Lifecycle Conference; 7th Symposium on International Design and Design Education of International Design Engineering Technical Conferences and Computers and Information in Engineering Conference. 6Evolution of Design for X Tools Applicable to Design Stages: A Literature Review

Development and validation of a material application tool for the covering process of a wire harness. P Heisler, E Hausecker, J Regler, R Süß-Wolf, J Franke, 10.1109/EDPC51184.2020.971855410th International Electric Drives Production Conference (EDPC). 2020. 2020

Design of a gripper for cable assembly with integrated in-hand cable manipulation functions. Y Zhou, X Jiang, D Chen, Y Guo, Y Liu, 10.1109/ROBIO54168.2021.97393982021 IEEE International Conference on Robotics and Biomimetics. 2021