# A Review on Deep Learning in UAV Remote Sensing

CorpusID: 231709807
 
tags: #Engineering, #Environmental_Science, #Computer_Science

URL: [https://www.semanticscholar.org/paper/6a78801c67313c67e20c76375d6a704964f50abb](https://www.semanticscholar.org/paper/6a78801c67313c67e20c76375d6a704964f50abb)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | False |
| By Annotator      | (Not Annotated) |

---

A Review on Deep Learning in UAV Remote Sensing


Lucas Prado 
Osco Id 
Faculty of Engineering and Architecture and Urbanism
University of Western São Paulo (UNOESTE)
Rod. Raposo Tavares, km 57219067-175Limoeiro, Presidente PrudenteSP

José Marcato jose.marcarto@ufms.br 
Junior Id 
Faculty of Engineering
Architecture and Urbanism and Geography, Federal University of Mato Grosso do Sul (UFMS), Av. Costa e Silva-Pioneiros, Cidade Universitária
Campo Grande 79070-900, MSBrazil

Ana Paula Marques marques.ramos@unesp.br 
Ramos Id 
Departament of Cartography
São Paulo State University (UNESP)
Centro Educacional, R. Roberto Simonsen, 305, Presidente Prudente, 19060-900, SPBrazil

Lúcio André De Castro 
Jorge Id 
National Research Center of Development of Agricultural Instrumentation, Brazilian Agricultural Research Agency, R. XV de Novembro
1452, São Carlos, 13560-970, SPBrazil

Sarah Narges 
Fatholahi Id nfatholahi@uwaterloo.ca 
Department of Geography and Environmental Management
University of Waterloo
N2L 3G1WaterlooONCanada

Jonathan De Andrade jonathan.andrade@ufms.br 
Silva Id 
Faculty of Computing
Federal University of Mato Grosso do Sul (UFMS), Av. Costa e Silva-Pioneiros, Cidade Universitária
Campo Grande 79070-900, MSBrazil

Edson Takashi edsontm@facom.ufms.br 
Matsubara Id 
Faculty of Computing
Federal University of Mato Grosso do Sul (UFMS), Av. Costa e Silva-Pioneiros, Cidade Universitária
Campo Grande 79070-900, MSBrazil

Hemerson Pistori Id 
Inovisão
Catholic University of Dom Bosco
Av. Tamandaré, Campo Grande, 79117-900, MS6000Brazil

Wesley Nunes Gonçalves Id 
Faculty of Computing
Federal University of Mato Grosso do Sul (UFMS), Av. Costa e Silva-Pioneiros, Cidade Universitária
Campo Grande 79070-900, MSBrazil

Jonathan Li 
Department of Geography and Environmental Management
University of Waterloo
N2L 3G1WaterlooONCanada

I D 
A Review on Deep Learning in UAV Remote Sensing
Preprint, compiled August 22, 2023
Deep Neural Networks (DNNs) learn hierarchical representations from data, bringing significant advances in image processing, and time-series analysis, as well as in natural language, audio, video, and many others. In the field of remote sensing, research and literature reviews specifically involving DNN applications have been conducted to summarize the amount of information produced. Recently, applications based on Unmanned Aerial Vehicles (UAVs) have stood out in aerial sensing research, as they allow for fast, less costly data collection at high spatial resolution. However, a literature review that combines the themes of "Deep Learning" (DL) and "remote sensing with UAVs" has not yet been conducted. The motivation for our work was to present a review of the fundamentals of DL applied to images collected by sensors onboard these aircraft. We especially present a description of the classification and segmentation techniques used in recent applications with data acquired by UAVs. For this, a total of 232 articles published in international scientific journal databases were examined. We gathered all this material and evaluated its characteristics in relation, for example, to the application, sensor, and type of network used. We relate how DL presents promising results and has the potential for processing tasks associated with aerial image data collected by UAVs. Finally, we project future perspectives, commenting on the prominent paths of DL to be explored in aerial remote sensing. Our review consists of a simplistic and objective approach to present, comment and summarize the state of the art in applications of sub-meter spatial resolution images with DNNs in various subfields of remote sensing, grouping them in the environmental, urban, and agricultural contexts.

# Introduction

For investigations using remote sensing image data, multiple processing tasks depend on computer vision algorithms. In the past decade, applications conducted with statistical and Machine Learning (ML) algorithms were mainly used in classification/regression tasks. The increase of remote sensing systems allowed a wide collection of data from any target on the Earth's surface. Aerial imaging has become a common approach to acquiring data with the advent of Unnamed Aerial Vehicles (UAV). These are also known as Remotely Piloted Aircrafts (RPA), or, as a commonly adopted term, drones (multi-rotor, fixed wings, hybrid, etc). These devices have grown in market availability for their relatively low cost and high operational capability to capture images quickly and in an easy manner. The high-spatial-resolution of UAV-based imagery and its capacity for multiple visits allowed the creation of large and detailed amounts of datasets to be dealt with.

The surface mapping with UAV platforms presents some advantages compared to orbital and other aerial sensing methods of acquisition. Less atmospheric interference, the possibility to fly within lower altitudes, and mainly, the low operational cost have made this acquisition system popular in both commercial and scientific explorations. However, the visual inspection of multiple objects can still be a time-consuming, biased, and inaccurate operation. Currently, the real challenge in remote sensing approaches is to obtain automatic, rapid, and accurate information from this type of data. In recent years, the advent of Deep Learning (DL) techniques has offered robust and intelligent methods to improve the mapping of the Earth's surface.

DL is an Artificial Neural Network (ANN) method with multiple hidden layers and deeper combinations, which is responsible for optimizing and returning better learning patterns than a common ANN. There is an impressive amount of revision material in the scientific journals explaining DL-based techniques, its historical evolution, general usage, as well as detailing networks and functions. Highly detailed publications, such as Lecun [113] and Goodfellow [69] are both considered important material in this area. As computer processing and labeled examples (i.e. samples) became more available in recent years, the performance of Deep Neural Networks (DNNs) increased in the image-processing applications. DNN has been successfully applied in data-driven methods. However, much needs to be covered to truly understand its potential, as well as its limitations. In this regard, several surveys on the application of DL in remote sensing were developed in both general and specific contexts to better explain its importance.

The context in which remote sensing literature surveys are presented is variated. Zhang et al. [203] organized a revision material which explains how DL methods were being applied, at the time, to image classification tasks. Later, Cheng et al. [39] investigated object detection in optical images, but focused more on the traditional ANN and ML. A complete and systematic review was presented by Ball et al. [12] in a survey describing DL theories, tools, and its challenges in dealing with remote sensing data. Cheng et al. [40] produced a revision on image classification with examples produced at their experiments. Also, focusing on classification, Zhu et al. [215] summarized most of the current information to understand the DL methods used for this task. Additionally, a survey performed by Li et al. [114] helped to understand some DL applications regarding the overall performance of DNNs in publicly available datasets for image classification task. Yao et al. [200] stated in their survey that DL will become the dominant method of image classification in remote sensing community.

Although DL does provide promising results, many observations and examinations are still required. Interestingly enough, multiple remote sensing applications using hyperspectral imagery (HSI) data were in the process, which gained attention. In Petersson et al. [152], probably one of the first surveys on hyperspectral data was performed. In [172], is presented a multidisciplinary review about how DL models have been widely used in the field of HSI dataset processing. These authors highlighted that, among the distinct areas of applications, remote sensing approaches are one of the most emerging. Regarding the use of DL models to process highly detailed remotely sensed HSI data, Signoroni et al. [172] summarized usage into classification tasks, object detection, semantic segmentation, and data enhancement, such as denoising, spatial super-resolution, and fusion. Adão et al. [1] present a recent review on hyperspectral imaging acquired by UAV-based sensors for agriculture and forestry applications, and show that there are manifold DL approaches to deal with HSI dataset complexity.

A more recent survey is presented by Jia et al. [98] regarding DL for hyperspectral image classification considering few labeled samples. They commentate how there is a notable gap between deep learning models and HSI datasets because DL models usually need sufficient labeled samples, but it is generally difficult to acquire many samples in HSI dataset due to the difficulty and time-consuming nature of manual labeling. However, the issues of small-sample sets may be well defined by the fusion of deep learning methods and related techniques, such as transfer learning and a lightweight model. Deep learning is also a new approach for the domain of infrared thermal imagery processing to attend different domains, especially in satellite-provided data. Some of these applications are the usage of convolutional layers to detect potholes on roads with terrestrial imagery [5], detection of land surface temperatures from combined multispectral and microwave observations from orbital platforms [193], or determining sea surface temperature patterns to identify ocean temperatures extremes [196] from orbital imagery.

Yet in the literature revision theme, a comparative review by Audebert et al. [8] was conducted by examining various families of networks' architectures while providing a toolbox to perform such methods to be publicly available. In this regard, another paper written by Paoletti et al. [149] organized the source code of DNNs to be easily reproduced. Similar to [40], Li et al. [115] conducted a literature revision while presenting an experimental analysis with DNNs' methods. As of recently, literature revision focused on more specific approaches within this theme. Some of which included DL methods for enhancement of remote sensing observations, as super-resolution, denoising, restoration, pansharpening, and image fusion techniques, as demonstrated by Tsagkatakis et al. [186] and Signoroni et al. [172]. Also, a meta-analysis by Ma et al. [128] was performed concerning the usage of DL algorithms in seven subfields of remote sensing: image fusion and image registration, scene classification, object detection, land use and land cover classification, semantic segmentation, and object-based image analysis (OBIA).

Although, from these recent reviews, various remote sensing applications using DL can be verified, it should be noted that the authors did not focus on specific surveying in the context of DL algorithms applied to UAV-image sets, which is something that, at the time of writing, has gained the attention of remote sensing investigations. We verified in the literature that, in general, similar DL methods are used for imagery acquired at different levels, resolutions and domains, such as the ones from orbital, aerial, terrestrial and proximal sensing platforms. However, as of recently, some of the proposed deep neural networks are maintaining high resolution images into deeper layers [101]. This type of deep networks may benefit from UAVbased data, taking advantage of its resolutions. Indeed, there are orbital images with high spatial resolutions, but these are not as commonly available to the general public as UAV-based images. Because of that, these kinds of architectures associated with UAV-based data may be a surging trend in remote sensing applications.

Another interesting take on DL-based methods was related to image segmentation in a survey by Hossain et al. [83], which its theme was expanded by Yuan et al. [202] and included stateof-the-art algorithms. A summarized analysis by Zheng et al. [213] focused on remote sensing images with object detection approaches, indicating some of the challenges related to the detection with few labeled samples, multi-scale issues, network structure problems, and cross-domain detection difficulties. In more of a "niche" type of research, environmental applications and land surface change detection were investigated in literature revision papers by Yuan et al. [201] and Khelifi et al. [106], respectively.

The aforementioned studies were evaluated with a text processing method that returned a word cloud in which the word size denotes the frequency of the word within these papers (Fig. 1). An interesting observation regarding this world-cloud is that the term "UAV" is under or not represented at all. This revision gap is a problem since UAV image data is daily produced in large amounts, and no scientific investigation appears to offer a comprehensive literature revision to assist new research on this matter. In the UAV context, there are some revision papers published in important scientific journals from the remote sensing community. As of recently, a revision-survey [23] focused on the implications of ML methods being applied to UAV image processing, but no investigation was conducted on DL algorithms for this particular issue. This is an important theme, especially since UAV platforms are more easily available to the public and DL-based methods are being tested to provide accurate mapping in highly detailed imagery. As mentioned, UAVs offer flexibility in data collection, as flights are programmed under users' demand; they are low-cost when compared to other platforms that offer similar spatialresolution images; produce high-level of detail in its data collection; presents dynamic data characteristics since it is possible to embed RGB, multispectral, hyperspectral, thermal and, LiDAR sensors on it; and are capable of gathering data from difficult to access places. Aside from that, sensors embedded in UAVs are known to generate data at different altitudes and point-of-views. These characteristics, alongside others, are known to produce a higher dynamic range of images than common sensing systems. This ensures that the same object is viewed from different angles, where not only their spatial and spectral information is affected, as well as form, texture, pattern, geometry, illumination, etc. This becomes a challenge for multidomain detection. As such, studies indicate that DL is the most prominent solution for dealing with these disadvantages. These studies, which most are presented in this revision paper, were conducted within a series of data criteria and evaluated DL architectures in classifying, detecting, and segmenting various objects from UAV scenes.

To the best of our knowledge, there is a literature gap related to review articles combining both "deep learning" and "UAV remote sensing" thematics. This survey is important to summarize the direction of DL applications in the remote sensing community, particularly related to UAV-imagery. The purpose of this study is to provide a brief review of DL methods and their applications to solve classification, object detection, and semantic segmentation problems in the remote sensing field. Herein, we discuss the fundamentals of DL architectures, including recent proposals. There is no intention of summarizing existing literature, but to present an examination of DL models while offering the necessary information to understand the state-of-the-art in which it encounters. Our revision is conducted highlighting traits about the UAV-based image data, their applications, sensor types, and techniques used in recent approaches in the remote sensing field. Additionally, we relate how DL models present promising results and project future perspectives of prominent paths to be explored. In short, this paper brings the following contributions:

1. A presentation of fundamental ideas behind the DL models, including classification, object detection, and semantic segmentation approaches; as well as the application of these concepts to attend UAV-image based mapping tasks;

2. The examination of published material in scientific sources regarding sensors types and applications, categorized in environmental, urban, and agricultural mapping contexts;

3. The organization of publicly available datasets from previous researches, conducted with UAV-acquired data, also labeled for both object detection and segmentation tasks; 4. A description of the challenges and future perspectives of DL-based methods to be applied with UAV-based image data.


# Deep Neural Networks Overview

DNNs are based on neural networks which are composed of neurons (or units) with certain activations and parameters that transform input data (e.g., UAV remote sensing image) to outputs (e.g., land use and land cover maps) while progressively learning higher-level features [128,167]. This progressive feature learning occurs, among others, on layers between the input and the output, which are referred to as hidden layers [128]. DNNs are considered as a DL method in their most traditional form (i.e. with 2 or more hidden layers). Their concept, based on an Artificial Intelligence (AI) modeled after the biological neurons' connections, exists since the 1950s. But only later, with advances in computer hardware and the availability of a high number of labeled examples, its interest has resurged in major scientific fields. In the remote sensing community, the interest in DL algorithms has been gaining attention since mid 2010s decade, specifically because these algorithms achieved significant success at digital image processing tasks [128,105].

A DNN works similarly to an ANN, when as a supervised algorithm, uses a given number of input features to be trained, and that these feature observations are combined through multiple operations, where a final layer is used to return the desired prediction. Still, this explanation does not do much to highlight the differences between traditional ANNs and DNNs. LeCun et. al. [113], the paper amongst the most cited articles in DL literature, defines DNN as follows: "Deep-learning methods are representation-learning methods with multiple levels of representation". Representation-learning is a key concept in DL. It allows the DL algorithm to be fed with raw data, usually unstructured data such as images, texts, and videos, to automatically discover representations.

The most common DNNs (Fig. 2) are generally composed of dense layers, wherein activation functions are implemented in. Activation functions compute the weighted sum of input and biases, which is used to decide if a neuron can be activated or not [141]. These functions constitute decision functions that help in learning intrinsic patterns [105]; i.e., they are one of the main aspects of how each neuron learns from its interaction with the other neurons. Known as a piecewise linear function type, ReLu defines the 0 valor for all negative values of X. This function is, at the time of writing, the most popular in current DNNs models. Regardless, another potential activation function recently explored is Mish, a self regularized non-monotonic activation function [105]. Aside from the activation function, another important information on how a DNN works is related to its layers, such as dropout, batch-normalization, convolution, deconvolution, max-pooling, encode-decode, memory cells, and others. This layer is regularly used to solve issues with covariance-shift within feature-maps [105]. The organization in which the layers are composed, as well as its parameters, is one of the main aspects of the architecture.

Multiple types of architectures were proposed in recent years to improve and optimize DNNs by implementing different kinds of layers, optimizers, loss functions, depth-level, etc. However, it is known that one of the major reasons behind DNNs' popularity today is also related to the high amount of available data to learn from it. A rule of thumb conceived among data scientists indicates that at least 5,000 labeled examples per category was recommended [69]. But, as of today, DNNs' proposals focused on improving these network's capacities to predict features with fewer examples than that. Some applications which are specifically oriented may benefit from it, as it reduces the amount of labor required at sample collection by human inspection. Even so, it should be noted that, although this pursuit is being conducted, multiple takes are performed by the vision computer communities and novel research includes methods for data-augmentation, self-supervising, and unsupervised learning strategies, as others. A detailed discussion of this manner is presented in [105].


## Convolutional and Recurrent Neural Networks

A DNN can be formed by different architectures, and the complexity of the model is related to how each layer and additional computational method is implemented. Different DL architectures are proposed regularly, Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Deep Belief Networks (DBN) [12], and, more recently yet, Generative Adversarial Networks (GAN) [69]. However, the most common DNNs in the supervised networks categories are usually classified as CNNs (Fig. 3) and RNNs [105].

As a different kind of DL network structure, RNNs refer to another supervised learning model. The main idea behind implementing RNNs regards their capability of improving their learning by repetitive observations of a given phenom or object, often associated with a time-series collection. A type of RNN being currently implemented in multiple tasks is the Long Short-Term Memory (LSTM) [81]. In the remote sensing field, RNN models have been applied to deal with time series tasks analysis, aiming to produce, for example, land cover mapping [93,84]. For a pixel-based time series analysis aiming to discriminate classes of winter vegetation coverage using SAR Sentinel-1 [84], it was verified that RNN models outperformed classical ML approaches. A recent approach [56] for accurate vegetation mapping combined multiscale CNN to extract spatial features from UAV-RGB imagery and then fed an attention-based RNN to establish the sequential dependency between multitemporal features. The aggregated spatial-temporal features are used to predict the vegetable category. Such examples with remote sensing data demonstrate the potential in which RNNs are being used. Also, one prominent type of architecture is the CNN-LSTM method (Fig. 4). This network uses convolutional layers to extract important features from the given input image and feed the LSTM. Although few studies implemented this type of network, it should be noted that it serves specific purposes, and its usage, for example, can be valued for multitemporal applications.

As aforementioned, other types of neural networks, aside from CNNs and RNNs, are currently being proposed to also deal with an image type of data. GANs are amongst the most innovative unsupervised DL models. GANs are composed of two networks: generative and discriminative, that contest between themselves. The generative network is responsible for extracting features from a particular data distribution of interest, like images, while the discriminative network distinguishes between real (reference or ground truth data) and those data generated by the generative part of GANs (fake data) [68,128]. Recently approaches in the image processing context like the classification of remote sensing images [123] and image-to-image translation problems solution [96] adopted GANs as DL model, obtaining successful results.

In short, several DNNs are constantly developed, in both scientific and/or image competition platforms, to surpass existing methods. However, as each year passes, some of these neural networks are often mentioned, remembered, or even improved by novel approaches. A summary of well-known DL methods built in recent years is presented in Fig. 5. A detailed take on this, which we recommend to anyone interested, is found in Khan et al. [105]. Alongside the creations and developments of these and others, researchers observed that higher depth channel exploration, and, as of recently proposed, attention-based feature extraction neural networks, are regarded as some of the most prominent approaches for DL. Initially, most of the proposed supervised DNNs, like CNN and RNN, or CNN-LSTM models, were created to perform and deal with specific issues. Often, these approaches can be grouped into classification tasks, like scene-wise classification, object detection, semantic and instance segmentation (pixel-wise), and regression tasks.


## Classification and Regression Approaches

When considering remote sensing data processed with DL-based algorithms, the following tasks can be highlighted: scene-wise classification, semantic and instance segmentation, and object detection. Scene-wise classification involves assigning a class label to each image (or patch), while the object detection task aims to draw bounding boxes around objects in an image (or patch) and labeling each of them according to the class label. Object detection can be considered a more challenging task since it requires to locate the objects in the image and then perform their classification. Another manner to detect objects in an image, instead of drawing bounding boxes, is to draw regions or structures around the boundary of objects, i.e., distinguish the class of the object at the pixel level. This task is known as semantic segmentation. However, in semantic segmentation, it is not possible to distinguish multiple objects of the same category, as each pixel receives one class label [195]. To overcome this drawback, a task that combines semantic segmentation and object detection named instance segmentation was proposed to detect multiple objects in pixel-level masks and labeling each Figure 2: A DNN architecture. This is a simple example of how a DNN may be built. Here the initial layer (X input ) is composed of the collected data samples. Later this data information can be extracted by hidden layers in a back-propagation manner, which is used by subsequent hidden layers to learn these features' characteristics. In the end, another layer is used with an activation function related to the given problem (classification or regression, as an example), by returning a prediction outcome (Y label ). where a dropout layer is added between each conv layer, and a max-pooling layer is adopted each time the convolution window-size is decreased. By the end of it, a deconvolutional layer is used with the same size as the last convolutional, and then it uses information from the previous step to reconstruct the image with its original size. The final layer is of a softmax, where it returns the models' predictions.

mask with a class label [180,36]. The instance segmentation, however, consists of a method that, while classifying the image with this pixel-wise approach, is able to individualize objects [170].

To produce a deep regression approach, the model needs to be adapted so that the last fully-connected layer of the architecture is changed to deal with a regression problem instead of a common classification one. With this adaptation, continuous values are estimated, differently from classification tasks. In compari-son to classification, the regression task using DL is not often used; however, recent publications have shown its potential in remote sensing applications. One approach [111] performed a comprehensive analysis of deep regression methods and pointed out that well-known fine-tuned networks, like VGG-16 [192] and ResNet-50 [75], can provide interesting results. These methods, however, are normally developed for specific applications, which is a drawback for general-purpose solutions. Another important point is that depending on the application, not always layers, and a max-pooling layer is used to introduce the information to the LSTM. Each memory cell is updated with weights from the previous cell. After this process, one may use a flatten layer to transform the data in an arrangement to be read by a dense (fully-connected) layer, returning a classification prediction, for instance.

deep regression succeeds. A strategy is to discretize the output space and consider it as a classification solution. For UAV remote sensing applications, the strategy of using well-known networks is in general adopted. Not only VGG-16 and ResNet-50, as investigated by [111], but also other networks including AlexNet [108] and VGG-11 have been used. An important issue that could be investigated in future research, depending on the application, is the optimizer. Algorithms with adaptive learning rates such as AdaGrad, RMSProp, AdaDelta (an extension of AdaGrad), and Adam are among the commonly used.


### Scene-Wise Classification, Object Detection, and Segmentation

Scene-wise classification or scene recognition refers to methods that associate a label/theme for one image (or patch) based on numerous images, such as in agricultural scenes, beach scenes, urban scenes, and others [219,128]. Basic DNNs methods were developed for this task, and they are among the most common networks for traditional image recognition tasks. In remote sensing applications, scene-wise classification is not usually applied. Instead, most applications benefit more from object detection and pixel-wise semantic segmentation approaches. For scenewise classification, the method needs only the annotation of the class label of the image, while other tasks like object detection method needs a drawn of a bounding box for all objects in an image, which makes it more costly to build labeled datasets. For instance or semantic segmentation, the specialist (i.e., the person who performs the annotation or object labeling) needs to draw a mask involving each pixel of the object, which needs more attention and precision in the annotation task, reducing, even more, the availability of datasets. Fig. 6 shows the examples of both annotation approaches (object detection and instance segmentation).

Object detection methods can be described into two mainstream categories: one-stage detectors (or regression-based methods) and two-stage detectors (or region proposal-based methods) [212,126,195]. The usual two-stage object detection pipeline is to generate region proposals (candidate rectangular bounding boxes) on the feature map. It then classifies each one into an object class label and refines the proposals with a bounding box regression. A widely used strategy in the literature to generate proposals was proposed with the Faster-RCNN algorithm with the Region Proposal Network (RPN) [212]. Other state-of-theart representatives of such algorithms are Cascade-RCNN [32], Trident-Net [185], Grid-RCNN [71], Dynamic-RCNN [52], De-tectoRS [44]. As for one-stage detectors, they directly make a classification and detect the location of objects without a region proposal classification step. This reduced component achieves a high detection speed for the models but tends to reduce the accuracy of the results. These are known as region-free detectors since they typically use cell grid strategies to divide the image and predict the class label of each one. Besides that, some detectors may serve for both one-stage and two-stage categories.

Object detection-based methods can be described in three components: a) backbone, which is responsible to extract semantic features from images; b) the neck, which is an intermediate component between the backbone and the head components, used to enrich the features obtained by the backbone, and; c) head component, which performs the detection and classification of the bounding boxes.

The backbone is a CNN that receives as input an image and outputs a feature map that describes the image with semantically features. In the DL, the state-of-the-art is composed of the following backbones: VGG [192], ResNet [160], ResNeXt [161], HRNet [88], RegNet [157], Res2Net [158], and ResNesT [159]. The neck component combines in several scales lowresolution and semantically strong features, capable of detecting (greenish color), and segmentation (bluish color). These networks often intertwine, and many adaptations have been proposed for them. Although it may appear that most of the DL methods were developed during 2015-2017 annuals, it is important to note that, as some, novel deep networks use most of the already developed methods as backbones, or accompanied from other types of architectures, mainly used as the feature extraction part of a much more complex structure.

large objects, with high-resolution and semantically weak features, capable of detecting small objects, which is done with the lateral and top-down connections of the convolutional layers of the Feature Pyramid Network (FPN) [60], and its variants like PAFPN [146] and NAS-FPN [136]. Although FPN was originally designed to be a two-stage method, the methods' purpose was a manner to use the FPN on single-stage detectors by re-moving RPN and adding a classification subnet and a bounding box regression subnet. The head component is responsible for the detection of the objects with the softmax classification layer, which produces probabilities for all classes and a regression layer to predict the relative offset of the bounding box positions with the ground truth. Figure 6: Labeled examples. The first-row consists of a bounding-box type of object detection approach label-example to identify individual tree-species in an urban environment. The second-row is a labeled-example of instance segmentation to detect rooftops in the same environment.

Despite the differences in object detectors (one or two-stage), their universal problem consists of dealing with a large gap between positive samples (foreground) and negative samples (background) during training, i.e class imbalance problem that can deteriorate the accuracy results [38]. In these detectors, the candidate bounding boxes can be represented into two main classes: positive samples, which are bounding boxes that match with the ground-truth, according to a metric; and negative samples, which do not match with the ground-truth. In this sense, a non-max suppression filter can be used to refine these dense candidates by removing overlaps to the most promising ones. The Libra-RCNN [147], ATSS [7], Guided Anchoring [61], FSAF [216], PAA [145], GFL [65], PISA [153] and VFNet [191] detectors explore different sampling strategies and new loss metrics to improve the quality of selected positive samples and reduce the weight of the large negative samples.

Another theme explored in the DL literature is the strategy of encoding the bounding boxes, which influences the accuracy of the one-stage detectors as they do not use region proposal networks [191]. In this report [191], the authors represent the bounding boxes like a set of representatives or key-points and find the farthest top, bottom, left, and right points. CenterNet [51] detects the object center point instead of using bounding boxes, while CornerNet [112] estimates the top-left corner and the bottom-right corner of the objects. SABL [165] uses a chunk based strategy to discretize horizontally and vertically the image and estimate the offset of each side (bottom, up, left, and right). The VFNet [191] method proposes a loss function and a star-shaped bounding box (described by nine sampling points) to improve the location of objects.

Regarding semantic segmentation and instance segmentation approaches, they are generally defined as a pixel-level classification problem [169]. The main difference between semantic and instance is that the former one is capable to identify pixels belonging to one class but can not distinguish objects of the same class in the image. However, instance segmentation approaches can not distinguish overlapping of different objects, since they are concerned with identifying objects separately. For example, it may be problematic to identify in an aerial urban image the location of the cars, trucks, motorcycle, and the asphalt pavement which consists of the background or region in which the other objects are located. To unify these two approaches, a method was recently proposed in [148], named panoptic segmentation. With panoptic segmentation, the pixels that are contained in uncountable regions (e.g. background) receive a specific value indicating it.

Considering the success of the RPN method for object detection, some variants of Faster R-CNN were considered to instance segmentation as Mask R-CNN [131], which in parallel to bounding box regression branch add a new branch to predict the mask of the objects (mask generation). The Cascade Mask R-CNN [31] and HTC [89] extend Mask R-CNN to refine in a cascade manner the object localization and mask estimation. The PointRend [154] is a point-based method that reformulates the mask generation branch as a rendering problem to iteratively select points around the contour of the object. Regarding semantic segmentation, methods like U-Net [163], SegNet [11], DeepLabV3+ [37], and Deep Dual-domain Convolutional Neural Network (DDCN) [139] have also been regularly used and adapted for recent remote sensing investigations [140]. Another important remote sensing approach that is been currently investigated is the segmentation of objects considering sparse annotations [91]. Still, as of today, the CGnet [35] and DLNet [47] are considered the state-of-art methods for semantic segmentation.


# Deep Learning in UAV Imagery

To identify works related to DL in UAV remote sensing applications, we performed a search in the Web of Science (WOS) and Google Scholar databases. WOS is one of the most respected scientific databases and hosts a high number of scientific journals and publications. We conducted a search using the following string in the WOS: ("TS = ((deep learning OR CNN OR convolutional neural network) AND (UAV OR unmanned aerial vehicle OR drone OR RPAS) AND (remote sensing OR photogrammetry)) AND LANGUAGE: (English) AND Types of Document: (Article OR Book OR Book Chapter OR Book Review OR Letter OR Proceedings Paper OR Review); Indexes=SCI-EXPANDED, SSCI, A%HCI, CPCI-S, CPCI-SSH, ESCI. Stipulated-time=every-years."). We considered DL, but added CNN, as it is one of the main DL-based architectures used in remote sensing applications [128]. As such, published materials that use these terms in their titles, abstracts or keywords were investigated and included. For such reasons, we opted for this string to achieve a generalist investigation.

We filtered the results to consider only papers that implemented approaches with UAV-based systems. A total of 190 papers were found in the WOS database, where 136 were articles, 46 proceedings, and 10 reviews. An additional search was conducted in the Google Scholar database to identify works not detected in the WOS. We adopted the same combination of keywords in this search. We performed a detailed evaluation of its results and selected only those that, although from respected journals, were not encountered in the WOS search. This resulted in a total of 34 articles, 16 proceedings, and 8 reviews. The entire dataset was composed of 232 articles + proceedings and 18 reviews from scientific journals indexed in those bases. These papers were then organized and revised. Fig. 7 demonstrates the main steps to map this research. The encountered publications were registered only in the last five years (from 2016 to 2021), which indicates how recent UAV-based approaches integrated with DL methods are in the scientific journals.

The review articles gathered at those bases were separated and mostly used in the cloud text analysis of Fig. 1, while the remaining papers (articles and proceedings) were organized according to their category. A total of 283.785 words were analyzed for the word-cloud, as we removed words with less than 5% occurrences to cut lesser-used words unrelated to the theme, and higher than 95% occurrences to remove plain and simple words frequently used in the English language. The published articles and proceedings were divided in terms of DL-based networks (classification: scene-wise classification, segmentation, and object detection and; regression), sensor types (RGB, multispectral, hyperspectral, and LiDAR); and; applications (environmental, urban, and agricultural context). We also provided, in a sub-sequent section, datasets from previously conducted research for further investigation by novel studies. These datasets were organized and their characteristics were also summarized accordingly.

Most of our research was composed of publications from peerreview publishers in the area of remote sensing journals (Fig. 8).

Even though the review articles encountered in the WoS and Google Scholar databases do mention, to some extent, UAVbased applications, none of them were dedicated to it. Towards the end of our paper, we examined state-of-the-art approaches, like real-time processing, data dimensionality reduction, domain adaptation, attention-based mechanisms, few-shot learning, open-set, semi-supervised and unsupervised learning, and others. This information provided an overview of the future opportunities and perspectives on DL methods applied in UAV-based images, where we discuss the implications and challenges of novel approaches.

The 232 papers (articles + proceedings) were investigated through a quantitative perspective, where we evaluated the number of occurrences per journal, the number of citations, year of publication, and location of the conducted applications according to country. We also prepared and organized a sampling portion in relation to the corresponding categories, as previously explained, identifying characteristics like architecture used, evaluation metric approach, task conducted, and type of sensor and mapping context objectives. After evaluating it, we adopted a qualitative approach by revising and presenting some of the applications conducted within the papers (UAV + DL) encountered in the scientific databases, summarizing the most prominent ones. This narrative over these applications was separated accordingly to the respective categories related to the mapping context (environmental, urban, and agricultural). Later on, when presenting future perspectives and current trends in DL, we mentioned some of these papers alongside other investigations proposed at computer vision scientific journals that could be potentially used for remote sensing and UAV-based applications.


## Sensors and Applications Worldwide

In the UAV-based imagery context, several applications were beneficiated from DL approaches. As these networks' usability is increasing throughout different remote sensing areas, researchers are also experimenting with their capability in substituting laborious-human tasks, as well as improving traditional measurements performed by shallow learning or conventional statistical methods. As of recently, several articles and proceedings were published in renowned scientific journals. In general terms, the articles collected at the scientific databases demonstrated a pattern related to its architecture (CNN or RNN), evaluation (classification or regression) approach (object detection, segmentation, or scene-wise classification), type of sensor (RGB, multispectral, hyperspectral or LiDAR) and mapping context (environmental, urban, or agricultural). These patterns can be viewed on a diagram (Fig. 9). The following observations can be extracted from this graphic:

1. The majority of networks in UAV-based applications still rely mostly on CNNs; Figure 7: The schematic procedure adopted to organize the revised material according to their respective categories as proposed in this review. 2. Even though object detection is the highest type of approach, there has been a lot of segmentation approaches in recent years; 3. Most of the used sensors are RGB, followed by multispectral, hyperspectral, and LiDAR, and; 4. There is an interesting amount of papers published within the environmental context, with forest-type related applications being the most common approach in this category, while both urban and agricultural categories were almost evenly distributed among opted approaches.

The majority of papers published on UAV-based applications implemented a type of CNN (91.2%). Most of these articles used established architectures (Fig. 5) and a small portion proposed their models and compared them against the state-of-the-art networks. In reality, this comparison appears to be a crucial concern regarding recent publications, since it is necessary to ascertain the performance of the proposed method in relation to well-known DL-based models. Still, the popularity of CNNs architecture in remote sensing images is not new, mainly because of reasons already stated in the previous sections. Besides that, even though presented in a small number of articles, RNNs (8.8%), mostly composed of CNN-LSTM architectures, are an emerging trend in this area and appear to be the focus of novel proposals. As UAV systems are capable of operating mostly according to the users' own desires (i.e., can acquire images from multiple dates in a more personalized manner), the same object is viewed through a type of time-progression approach. This is beneficial for many applications that include monitoring of stationary objects, like rivers, vegetation, or terrain slopes, for example.

Although classification (97.7%) tasks are the most common evaluation metrics implemented in these papers, regression (2.3%) is an important estimate and may be useful in future applications. The usage of regression metrics in remote sensing applications is worth it simply because it enables the estimation of continuous data. Applications that could benefit from regression analysis are present in environmental, urban, and agricultural contexts, as in many others, and it is useful to return predictions on measured variables. Classification, on the other hand, is more of a common ground for remote sensing approaches and it is implemented in every major task (object detection; pixel-wise semantic segmentation and scene-wise classification).

The aforementioned DL-based architectures were majorly applied in object detection (53.9%) and image segmentation (40.7%) problems, while (scene-wise) classification (5.4%) were the least common. This preference for object detection may be related to UAV-based data, specifically, since the high amount of detail of an object provided by the spatial resolution of the images is both an advantage and a challenge. It is an advantage because it increases the number of objects to be detected on the surface (thus, more labeled examples), and it is a challenge because it difficulties both the recognition and segmentation of these objects (higher detail implies more features to be extracted and analyzed). Classification (scene-wise), on the other hand, is not as common in remote sensing applications, and image segmentation is often preferred in some applications since assigning a class to each pixel of the image has more benefits for this type of analysis than rather only identifying a scene.

Following it, there is an interesting distribution pattern related to the application context. The data indicated that most of the applications were conducted in the environmental context (46.6%). This context includes approaches that aim to, in a sense, deal with detection and classification tasks on land use and change, environmental hazards and disasters, erosion estimates, wild-life detection, forest tree inventory, monitoring difficult to access regions, as others. Urban and agricultural categories (both 27.2% and 26.4%, respectively) were associated with car and traffic detection, buildings, street, and rooftop extraction, as well as plant counting, plantation-row detection, weed infestation identification, and others. Interestingly, all of the LiDAR data applications were related to environmental mapping, while RGB images were mostly used for urban, followed by the agricultural context. Multispectral and hyperspectral data, however, were less implemented in the urban context in comparison against the other categories. As these categories benefit differently from DLbased methods, a more detailed intake is needed to understand its problems, challenges, and achievements. In the following subsections, we explain these issues and advances while citing some suitable examples from within our search database.

Lastly, another important observation to be made regarding the categorization division used here is that there is a visible dichotomy between the types of sensor used. Most of the published papers in this area evaluating the performance of DLbased networks with RGB sensors (52.4%). This was, respectively, followed by multispectral (24.3%), hyperspectral (17.8%), and LiDAR (5.5%). The preference for RGB sensors in UAVbased systems may be associated with their low-cost and high market availability. As such, published articles may reflect on this, since it is a viable option for practical reasons when considering the replicability of the method. It should be noted that the number of labeled examples in public databases are mostly RGB, which helps improvements and investigation with this type of data. Moreover, data obtained from multispectral, hyperspectral, and LiDAR sensors are used in more specific applications, which contributes to this division.

Most of the object detection applications went on RGB types of data, while segmentation problems were dealt with both RGB, multispectral, hyperspectral, and LiDAR data. A possible explanation for this is that object detection often relies on the spatial, texture, pattern, and shape characteristics of the object in the image, as segmentation approaches are a diverse type of applications, which benefit from the amount of spectral and terrain information provided by these sensors. In object detection, DL-based methods may have potentialized the usage of RGB images, since simpler and traditional methods need additional spectral information to perform it. Also, apart from the spectral information, LiDAR, for example, offers important features of the objects for the networks to learn and refine the edges around them, specifically where their patterns are similar. Regardless, many of these approaches are related to the available equipment and nature of the application itself, so it is difficult to pinpoint a specific reason.


## Environmental Mapping

Environmental approaches with DNNs-based methods hold the most diverse applications with remote sensing data, including UAV-imagery. These applications adopt different sensors simply because of their divergent nature. To map natural habits and their characteristics, studies often relied on methods and procedures specifically related to its goals, and no "universal" approach could be proposed nor discovered. However, although DL-based methods have not reached this type of "universal" approach, they are changing some skepticism by being successfully implemented in the most unique scenarios. Although UAV-based practices still offer some challenges to both classification and regression tasks, DNNs methods are proving to be generally capable of performing such tasks. Regardless, there is still much to be explored.

Several environmental practices could potentially benefit from deep networks like CNNs and RNNs. For example, monitoring and counting wild-life [15,85,176], detecting and classifying vegetation from grasslands and heavily-forested areas [82,73], recognizing fire and smoke signals [110,205], analyzing land use, land cover, and terrain changes, which are often implemented into environmental planning and decision-making models [109,206], predicting and measuring environmental hazards [190,25], among others. What follows is a brief description of recent material published in the remote sensing scientific journals that aimed to solve some of these problems by integrating data from UAV embedded sensors with DL-based methods.

One of the most common approaches related to environmental remote sensing applications regards land use, land cover, and other types of terrain analysis. A recent study [66] applied semantic segmentation networks to map land use over a mining extraction area. Another one, [3], combined information from a Digital Surface Model (DSM) with UAV-based RGB images and applied a type of feature fusion as input for a CNN model. To map coastal regions, an approach [26], with RGB data registered at multiple scales, used a CNN in combination with a graphical method named conditional random field (CRF). Another research [150], with hyperspectral images in combination between 2D and 3D convolutional layers, was developed to determine the discrepancy of land cover in the assigned land category of cadastral map parcels.

With a semantic segmentation approach, road extraction by a CNN was demonstrated in another investigation [116]. Another study [64] investigated the performance of a FCN to monitor household upgrading in unplanned settlements. Terrain analysis is a diversified topic in any type of cartographic scale, but for UAV-based images, in which most data acquisitions are composed by a high-level of detail, DL-based methods are resulting in important discoveries, demonstrating the feasibility of these methods to perform this task. Still, although these studies are proving this feasibility, especially in comparison with other methods, novel research should focus on evaluating the performance of deep networks regarding their domain adaptation, as well as its generalization ability, like using data in different spatial resolutions, multitemporal imagery, etc.

The detection, evaluation, and prediction of flooded areas represents another type of investigation with datasets provided by UAV-embedded sensors. A study [62] demonstrated the importance of CNNs for the segmentation of flooded regions, where the network was able to separate water from other targets like buildings, vegetation, and roads. One potential application that could be conducted with UAV-based data, but still needs to be further explored, is mapping and predicting regions of possible flooding with a multitemporal analysis, for example. This, as well as many other possibilities related to flooding, water-bodies, and river courses [27], could be investigated with DL-based approaches.

For river analysis, an investigation [207] used a CNN architecture for image segmentation by fusing both the positional and channel-wise attentive features to assist in river ice monitoring. Another study [97] compared LiDAR data with point cloud generated by UAV mapping and demonstrated an interesting approach to DL-based methods applications for point cloud classification and a rapid Digital Elevation Model (DEM) generation for flood risk mapping. One type of application with CNN in UAV data involved measuring hailstones in open areas [174]. For this approach, image segmentation was used in RGB images and returned the maximum dimension and intermediate dimension of the hailstones. Lastly, on this topic, a comparison [92] with CNNs and GANs to segment both river and vegetation areas demonstrated that a type of "fusion" between these networks using a global classifier had an advantage of increasing the efficiency of the segmentation.

UAV-based forest mapping and monitoring is also an emerging approach that has been gaining the attention of the scientific community and, at some level, governmental bodies. Forest areas often pose difficulties for precise monitoring and investigation, since they can be hard to access and may be dangerous to some extent. In this aspect, images taken from UAV embedded sensors can be used to identify single tree-species in forested environments and compose an inventory. From the papers gathered, multiple types of sensors, RGB, both multi and hyperspectral, and LiDAR, were used for this approach. An application investigated the performance of a 3D-CNN method to classify tree species in a boreal forest, focusing on pine, spruce, and birch trees, with a combination between RGB and hyperspectral data [138].

Single-tree detection and species classification by CNNs were also investigated in [57] in which three types of palm-trees in the Amazon forest, considered important for its population and native communities, were mapped with this type of approach. Another example [90] includes the implementation of a Deep Convolutional Generative Adversarial Network (DCGAN) to discriminate between health diseased pinus-trees in a heavilydense forested park area. Another recent investigation [134] proposed a novel DL method to identify single-tree species in highly-dense areas with UAV-hyperspectral imagery. These and other scientific studies demonstrate how well DL-based methods can deal with such environments.

Although the majority of approaches encountered at the databases of this category relate to tree-species mapping, UAVacquired data were used for other applications in these natural environments. A recent study [208] proposed a method based on semantic segmentation and scene-wise classification of plants in UAV-based imagery. The method bases itself on a CNN that classifies individual plants by increasing the image scale while integrating features learned from small scales. This approach is an important intake in multi-scale information fusion. Also related to vegetation identification, multiple CNNs architectures were investigated in [74] to detect between plants and non-type of plants with UAV-based RGB images achieving interesting performance.


## Another application aside from vegetation mapping involves wild-life identification. Animal monitoring in open spaces and

grasslands is also something that received attention as DL-based object detection and semantic segmentation methods are providing interesting outcomes. A paper by [103] covers this topic and discusses, with practical examples, how CNNs may be used in conjunction with UAV-based images to recognize mammals in the African Savannah. This study relates the challenges related to this task and proposes a series of suggestions to overcome them, focusing mostly on imbalances in the labeled dataset. The identification of wild-life, also, was not only performed in terrestrial environments, but also in marine spaces, where a recent publication [70] implemented a CNN-based semantic segmentation method to identify cetacean species, mainly blue, humpback, and minke whales, in the ocean. These studies not only demonstrate that such methods can be highly accurate at different tasks but also imply the potential of DL approaches for UAVs in the current literature.


## Urban Mapping

For urban environments, many DL-based proposals with UAV data have been presented in the literature in the last years. The high-spatial-resolution easily provided by UAV embedded sensors are one of the main reasons behind its usage in these areas. Object detection and instance segmentation methods in those images are necessary to individualize, recognize, and map highly-detailed targets. Thus, many applications rely on CNNs and, in small cases, RNNs (CNN-LSTM) to deal with them. Some of the most common examples encountered in this category during our survey are the identification of pedestrians, car and traffic monitoring, segmentation of individual tree-species in urban forests, detection of cracks in concrete surfaces and pavements, building extraction, etc. Most of these applications were conducted with RGB type of sensors, and, in a few cases, spectral ones.

The usage of RGB sensors is, as aforementioned, a preferred option for small-budget experiments, but also is related to another important preference of CNNs, and that is that features like pixel-size, form, and texture of an object are essential to its recognition. In this regard, novel experiments could compare the performance of DL-based methods with RGB imagery with other types of sensors. As low-budget systems are easy to implement in larger quantities, many urban monitoring activities could benefit from such investigations. In urban areas, the importance of UAV real-time monitoring is relevant, and that is one of the current objectives when implementing such applications.

The most common practices on UAV-based imagery in urban environments with DL-based methods involve the detection of vehicles and traffic. Car identification is an important task to help urban monitoring and may be useful for real-time analysis of traffic flow in those areas. It is not an easy task, since vehicles can be occluded by different objects like buildings and trees, for example. A recent approach using RGB video footage obtained with UAV, as presented in [204], used an object detection CNN for this task. They also dealt with differences in traffic monitoring to motorcycles, where a frame-by-frame analysis enabled the neural network to determine if the object in the image was a person (pedestrian) or a person riding a motorcycle since differences in its pattern and frame-movement indicated it. Regarding pedestrian traffic, an approach with thermal cameras presented by [43] demonstrated that CNNs are appropriate to detect persons with different camera rotations, angles, sizes, translation, and scale, corroborating the robustness of its learning and generalization capabilities.

Another important survey in those areas is the detection and localization of single-tree species, as well as the segmentation of their canopies. Identifying individual species of vegetation in urban locations is an important requisite for urban-environmental planning since it assists in inventorying species and providing information for decision-making models. A recent study [49] applied object detection methods to detect and locate tree-species threatened by extinction. Following their intentions, a research [183] evaluated semantic segmentation neural networks to map endangered tree-species in urban environments. While one approach aimed to recognize the object to compose an inventory, the other was able to identify it and return important metrics, like its canopy-area for example. Indeed, some proposals that were implemented in a forest type of study could also be adopted in urban areas, and this leaves an open field for future research that intends to evaluate DL-based models in this environment. Urban areas pose different challenges for tree monitoring, so these applications need to consider their characteristics.

DL-based methods have also been used to recognize and extract infrastructure information. An interesting approach demonstrated by [24], based on semantic segmentation methods, was able to extract buildings in heavily urbanized areas, with unique architectural styles and complex structures. Interestingly enough, a combination of RGB with a DSM improved building identification, indicating that the segmentation model was able to incorporate appropriate information related to the objects' height. This type of combinative approach, between spatialspectral data and height, may be useful in other identification and recognition approaches. Also regarding infrastructure, another possible application in urban areas is the identification and location of utility poles [67]. This application, although being of rather a specific example, is important to maintain and monitor the conditions of poles regularly. These types of monitoring in urban environments is something that benefits from DL-based models approaches, as it tends to substitute multiple human inspection tasks. Another application involves detecting cracks in concrete pavements and surfaces [20]. Because some regions of civil structures are hard to gain access to UAV-based data with object detection networks may be useful to this task, returning a viable real-life application.

Another topic that is presenting important discoveries relates to land cover pixel segmentation in urban areas, as demonstrated by [18]. In this investigation, an unsupervised domain adaptation method based on GANs was implemented, working with different data from UAV-based systems, while being able to improve image segmentation of buildings, low vegetation, trees, cars, and impervious surfaces. As aforementioned, GANs or DCGANs are quickly gaining the attention of computer vision communities due to their wide area of applications and the way they function by being trained to differentiate between real and fake data [68]. Regardless, its usage in UAV-based imagery is still underexplored, and future investigations regarding not only land change and land cover but also other types of applications' accuracies may be improved with them. Nonetheless, apart from differences in angles, rotation, scales, and other UAV-based imagery-related characteristics, diversity in urban scenarios is a problem that should be considered by unsupervised approaches. Therefore, in the current state, DL-based networks still may rely on some supervised manner to guide image processing, specifically regarding domain shift factors.


## Agricultural Mapping

Precision agriculture applications have been greatly benefited from the integration between UAV-based imagery and DL methods in recent scientific investigations. The majority of issues related to these approaches involve object detection and feature extraction for counting plants and detecting plantation lines, recognizing plantation-gaps, segmentation of plant species and invasive species such as weeds, phenology, and phenotype detection, and many others. These applications offer numerous possibilities for this type of mapping, especially since most of these tasks are still conducted manually by human-vision inspection. As a result, they can help precision farming practices by returning predictions with rapid, unbiased, and accurate results, influencing decision-making for the management of agricultural systems.

Regardless, although automatic methods do provide important information in this context, they face difficult challenges. Some of these include similarity between the desired plant and invasive plants, hard-to-detect plants in high-density environments (i.e. presenting small spacing between plants and lines), plantationlines that do not follow a straight-path, edge-segmentation in mapping canopies with conflicts between shadow and illumination, and many others. Still, novel investigations aim to achieve a more generative capability to these networks in dealing with such problems. In this sense, approaches that implement methods in more than one condition or plantation are being the main focus of recent publications. Thus, varied investigation scenarios are currently being proposed, with different types of plantations, sensors, flight-altitudes, angles, spatial and spectral divergences, dates, phenological-stages, etc.

An interesting approach that has the potential to be expanded to different orchards was used in [6]. There, a low-altitude flight approach was adopted with side-view angles to map yield by counting fruits with the CNN-based method. Counting fruits is not something entirely new in DL-based approaches, some papers demonstrated the effectiveness of bounding-box and pointfeature methods to extract it [22,182,100] aside from several differences in occlusion, lightning, fruit size, and image corruption.

Today's deep networks demonstrate high potential in yieldprediction, as some applications are adapted to CNN architectures mainly because of its benefits in image processing. One of which includes predicting pasture-forage with only RGB images [33]. Another interesting example in crop-yield estimates is presented by [137], where a CNN-LSTM was used to predict yield with a spatial multitemporal approach. There the authors implemented this structure since RNNs are more appropriate to learn from temporal data, while a 3D-CNN was used to process and classify the image. Although used less frequently than CNNs in the literature, there is emerging attention to LSTM architectures in precision agriculture approaches, which appear to be an appropriate intake for temporal monitoring of these areas.

Nonetheless, one of the most used and beneficiated approaches in precision agriculture with DL-based networks is counting and detecting plants and plantation lines. Counting plants is essential to produce estimates regarding production rates, as well as, by geolocating it, determine if a problem occurred during the seedling process by identifying plantation-gaps. In this regard, plantation-lines identification with these gaps is also a desired application. Both object detection and image segmentation methods were implemented in the literature, but most approaches using image semantic segmentation algorithms rely on additional procedures, like using a blob detection method [107], for example. These additional steps may not always be desirable, and to prove the generality capability of one model, multiple tests at different conditions should be performed.

For plantation-line detection, segmentations are currently being implemented and often used to assist in more than one information extraction. In [143] semantic segmentation methods were applied in UAV-based multispectral data to extract canopy areas and was able to demonstrate which spectral regions were more appropriate to it. A recent application with UAV-based data was also proposed in [144], where a CNN model is presented to simultaneously count and detect plants and plantation-lines. This model is based on a confidence map extraction and was an upgraded version from previous research with citrus-tree counting [142]. This CNN works by implementing some convolutional layers, a Pyramid Pooling Module (PPM) [211], and a Multi-Stage Module (MSM) with two information branches that, concatenated at the end of the MSM processes, shares knowledge learned from one to another. This method ensured that the network learned to detect plants that are located at a plantationline, and understood that a plantation-line is formed by linear conjunction of plants. This type of method has also been proved successful in dealing with highly-dense plantations. Another research [4] that aimed to count citrus-trees with a boundingbox-based method also returned similar accuracies. However, it was conducted in a sparse plantation, which did not impose the same challenges faced at [142,144]. Regardless, to deal with highly dense scenes, feature extraction from confidence maps appears to be an appropriate approach.

However, agricultural applications do not always involve plant counting or plantation-line detection. Similar to wild-animal identification as included in other published studies [103,70], there is also an interest in cattle detection, which is still an onerous task for human-inspection. In UAV-based imagery, some approaches included DL-based bounding-boxes methods [14], which were also successfully implemented. DNNs used for this task are still underexplored, but published investigations [162] argue that one of the main reasons behind the necessity to use DL methods is based on occurrences of changes in terrain (throughout the seasons of the year) and the non-uniform distribution of the animals throughout the area. On this matter, one interesting approach should involve the usage of real-time object detection on the flight. This is because it is difficult to track animal movement, even in open areas such as pastures, when a UAV system is acquiring data. Another agricultural application example refers to the monitoring offshore aquaculture farms using UAV-underwater color imagery and DL models to classify them [16]. These examples reveal the widespread variety of agriculture problems that can be attended with the integration of DL models and UAV remote sensing data.

Lastly, a field yet to be also explored in the literature is the identification and recognition of pests and disease indicators in plants using DL-based methods. Most recent approaches aimed to identify invasive species, commonly named "weeds", in plantationfields. In a demonstration with unsupervised data labeling, [45] evaluated the performance of a CNN-based method to predict weeds in the plantation lines of different crops. This preprocessing step to automatically generate labeled data, which is implemented outside the CNN model structure, is an interesting approach. However, others prefer to include a "one-step" network to deal with this situation, and different fronts are emerging in the literature. Unsupervised domain adaptation, in which the network extracts learning features from new unviewed data, is one of the most current aimed models.

A recent publication [118] proposed it to recognize and count in-field cotton-boll status identification. Regardless, with UAVbased data examples, this is still an issue. As for disease detection, a study [104] investigated the use of image segmentation for vine-crops with multispectral images, and was able to separate visible symptoms (RGB), infrared symptoms (i.e. when considering only the infrared band) and in an intersection between visible and infrared spectral data. Another interesting example regarding pests identification with UAV-based image was demonstrated in [179] where superpixel image samples of multiple pest species were considered, and activation filters used to recognize undesirable visual patterns implemented alongside different DL-based architectures.


# Publicly Available UAV-Based Datasets

As mentioned, one of the most important characteristics of DLbased methods is that they tend to increase their learning capabilities as a number of labeled examples are used to train a network. In most of the early approaches to remote sensing data, CNNs were initialized with pre-trained weights from publicly available image repositories over the internet. However, most of these repositories are not from data acquired with remote sensing platforms. Still, there are some known aerial repositories with labeled examples, which were presented in recent years, such as the DOTA [197], UAVDT [50], VisDrone [9], WHU-RS19 [171], RSSCN7 [220], RSC11 [209], Brazilian Coffee Scene [151] datasets. These and others are gaining notoriety in UAVbased applications and could be potentially used to pre-train or benchmark DL methods. These datasets not only serve as an additional option to start a network but also may help in novel proposals to be compared against the evaluated methods.

Since there is a still scarce amount of labeled examples with UAV-acquired data, specifically in multispectral and hyperspectral data, we aimed to provide UAV-based datasets in both urban and rural scenarios for future research to implement and compare the performance of novel DL-based methods with them. Table 1 summarizes some of the information related to these datasets, as well as indicates recent publications in which previously conducted approaches were implemented, as well as the results achieved on them. They are available on the following webpage, which is to be constantly updated with novel labeled datasets from here on: Geomatics and Computer Vision/Datasets


# Perspectives in Deep Learning with UAV Data

There is no denying that DL-based methods are a powerful and important tool to deal with the numerous amounts of data daily produced by remote sensing systems. What follows in this section is a short commentary on the near perspectives of one of the most emerging fields in the DL and remote sensing communities that could be implemented with UAV-based imagery. These topics, although individually presented here, have the potential to be combined, as already performed in some studies, contributing to the development of novel approaches.

In general, DL architectures require low resolution input images (e.g., 512 × 512 pixels). High resolution images are generally scaled to the size required for processing. However, UAVs have the advantage of capturing images in higher resolution than most other types of sensing platforms aside from proximal sensing, and the direct application of traditional architectures may not take advantage of this feature. As such, processing images with DL while maintaining high resolution in deeper layers is a challenge to be explored. In real-time applications, such as autonomous navigation, this processing must be fast, which opens up a range of research related to reducing the complexity of architectures while preserving accuracy. Regarding DL, recently, some CNN architectures that try to maintain high resolution in deeper layers, such as HRNet, have been proposed [101]. These novel architectures can really take advantage of the high resolution from UAV images compared to commonly available orbital data.

To summarize, the topics addressed in this section compose some of the hot topics in the computer vision community, and the combination of them with remote sensing data can contribute to the development of novel approaches in the context of UAV mapping. In this regard, it is important to emphasize that not only these topics are currently being investigated by computer vision research, but that they also are being fastly implemented in multiple approaches aside from remote sensing. As other domains are investigated, novel ways of improving and adapting these networks can be achieved. Future studies in remote sensing communities, specifically on UAV-based systems, may benefit from these improvements and incorporate them into their applications.


## Real-Time Processing

Most of the environmental, urban, and agricultural applications presented in this study can benefit from real-time responses.

Although UAV and DL-based combinations speed up the processing pipeline, these algorithms are highly computer-intensive. Usually, they do require post-processing in data centers or dedicated Graphics Processing Units (GPUs) machines. Although DL is considered a fast method to extract information from data after its training, it still bottlenecks real-time applications mainly because of the number of layers intrinsic to the DL methods architecture. Research groups, especially from the IoT industry/academy, race to develop real-time DL methods because of it. The approach usually goes in two directions: developing faster algorithms and developing dedicated GPU processors.

DL models use 32-bit floating points to represent the weights of the neural network. A simple strategy known as quantization reduces the amount of memory required by DL models representing the weights, using 16, 8, or even 1 bit instead of 32-bits floating points. A 32-bit full precision ResNet-18 [75] achieves 89.2% top-5 accuracy on the ImageNet dataset [94], while the ResNet-18 [75] ported to XNOR-Net achieves 73.2% top-5 accuracy in the same dataset. The quantization goes beyond weights, in all network components, while the literature reports activation functions and gradient optimizations quantized methods. The survey conducted in [72] gives an important overview of quantization methods. Also, knowledge distillation [79] is another example of a training model using a smaller network, where a larger "teacher" network guides the learning process of a smaller "student" network.

Another strategy to develop fast DL models is to design layers with fewer parameters that are still capable of retaining predictive performance. MobileNets [86] and its variants are a good example of this idea. In specific tasks, such as object detection, it is possible to develop architectural enhancements for this approach, such as the Context Enhanced Module (CEM) and the Spatial Attention Module (SAM) [155]. When considering even smaller computational power, it is possible to find DL running on microcontroller units (MCU) where the memory and computational power are 3-4 orders of magnitude smaller than mobile phones.

On hardware, the industry has already developed embedded AI platforms that run DL algorithms. NVIDIA's Jetson is amongst the most popular choices and a survey [133] of studies using the Jetson platform and its applications demonstrate it. Also, a broader survey on this theme, that considers GPU, ASIC, FPGA, and MCUs of AI platforms, can be read in [95]. Regardless, research in the context of UAV remote sensing is quite limited, and there is a gap that can be fulfilled by future works. Several applications can be benefited by this technology, including, for example, agricultural spraying UAV, which can recognize different types of weeds in real-time, and simultaneously use the spray. Other approaches may include real-time monitoring of trees in both urban and forest environments, as well as the detection of other types of objects that benefit from a rapid intake.


## Dimensionality Reduction

Due to recent advances in capture devices, hyperspectral images can be acquired even in UAVs. These images consist of tens to hundreds of spectral bands that can assist in the classification of objects in a given application. However, two main issues arise from the high dimensionality: i) the bands can be highly correlated, and ii) the excessive increase in the computational cost of DL models. High-dimensionality could invoke a problem known as the Hughes phenomenon, which is also known as the curse of dimensionality, i.e., when the accuracy of a classification is reduced due to the introduction of noise and other implications encountered in hyperspectral or high-dimensional data [77]. Regardless, hyperspectral data may pose an hindrance for the DL-based approaches accuracies, thus being an important issue to be considered in remote sensing practices. The classic approach to address high dimensionality is by applying a Principal Component Analysis (PCA) [120]. Despite several proposals, PCA is generally not applied in conjunction with DL, but as a pre-processing step. Although this method may be one of the most known approaches to reduce dimensionality when dealing with hyperspectral data, different intakes were already presented in the literature. A novel DL approach, implemented with UAV-based imagery, was demonstrated by Miyoshi et al. [134]. There, the authors proposed a one-step approach, conducted within the networks' architecture, to consider a combination of bands of a hyperspectral sensor that were highly related to the labeled example provided in the input layer at the initial stage of the network. Another investigation [189] combines a band selection approach, spatial filtering, and CNN to simultaneously extract the spectral and spatial features. Still, the future perspective to solve this issue appears to be a combination of spectral band selection and DL methods in an end-to-end approach. Thus, both selection and DL methods can exchange information and improve results. This can also contribute to understanding how DL operates with these images, which was slightly accomplished at Miyoshi et al. [134].


## Domain Adaptation and Transfer Learning

The training steps of DL models are generally carried out on images captured in a specific geographical region, in a short-time period, or on single capture equipment (also known as domains). When the model is used in practice, it is common for spectral shifts to occur between the training and test images due to differences in acquisition, geographic region, atmospheric conditions, among others [187]. Domain adaptation is a technique for adapting models trained in a source domain to a different, but still related, target domain. Therefore, domain adaptation is also viewed as a particular form of transfer learning [187]. On the other hand, transfer learning [217,178] does include applications in which the characteristics of the domain's target space may differ from the source domain.

A promising research line for domain adaptation and transfer learning is to consider GANs [68,53]. For example, [19] proposed the use of GANs to convert an image from the source domain to the target domain, causing the source images to mimic the characteristics of the images from the target domain. Recent approaches seek to align the distribution of the source and target domains, although they do not consider direct alignment at the level of the problem classes. Approaches that are attentive to class-level shifts may be more accurate, as the category-sensitive domain adaptation proposed by [55]. Thus, these approaches reduce the domain shift related to the quality and characteristics of the training images and can be useful in practice for UAV remote sensing.


## Attention-Based Mechanisms

Attention mechanisms aim to highlight the most valuable features or image regions based on assigning different weights for them in a specific task. It is a topic that has been recently applied in remote sensing, providing significant improvements. As pointed out by [198], high-resolution images in remote sensing provide a large amount of information and exhibit minor intra-class variation while it tends to increase. These variations and a large amount of information make extraction of relevant features more difficult, since traditional CNNs process all regions with the same weight (relevance). Attention mechanisms, such as the one proposed by [198], are useful tools to focus the feature extraction in discriminative regions of the problem, be it image segmentation [46,175,214], scene-wise classification [218,125], or object detection [121,125], as others.

Besides, [175] argue that when remote sensing images are used, they are generally divided into patches for training the CNNs. Thus, objects can be divided into two or more sub-images, causing the discriminative and structural information to be lost. Attention mechanisms can be used to aggregate learning by focusing on relevant regions that describe the objects of interest, as presented in [175], through a global attention upsample module that provides global context and combines low and high-level information. Recent advances in computer vision were achieved with attention mechanisms for classification (e.g., Vision Transformer [48] and Data-efficient Image Transformers [184]) and in object detection (e.g., DETR [28]) that have not yet been fully evaluated in remote sensing applications. Some directions also point to the use of attention mechanisms directly in a sequence of image patches [48,184]. These new proposals can improve the results already achieved in remote sensing data, just as they have advanced the results on the traditional image datasets in computer vision (e.g., ImageNet [94]).


## Few-Shot Learning

Although recent materials demonstrated the feasibility of DLbased methods for multiple tasks, they still are considered limited in terms of high generalization. This occurs when dealing with the same objects in different geographical areas or when new object classes are considered. Traditional solutions require retraining the model with a robust labeled dataset for the new area or object. Few-shot learning aims to cope with situations in which few labeled datasets are available. A recent study [119], in the context of scene classification, pointed out that few-shot methods in remote sensing are based on transfer learning and meta-learning. Meta-learning can be more flexible than transfer learning, and when applied in the training set to extract metaknowledge, contributes significantly to few-shot learning in the test set. An interesting strategy to cope with large intraclass variation and interclass similarity is the implementation of the attention mechanism in the feature learning step, as previously described. The datasets used in the [119] study were not UAVbased; however, the strategy can be explored in UAV imagery.

In the context of UAV remote sensing, there are few studies on few-shot learning. Recently, an investigation [102] aimed for the detection of maize plants using the object detection method CenterNet. The authors adopted a transfer learning strategy using pre-trained models from other geographical areas and dates. Fewer images (in total, 150 images), when compared to the previous training (with 600 images), from the new area were used for fine-tuning the model. Based on the literature survey, there is a research-gap to be further explored in the context of object detection using few-shot learning in UAV remote sensing.

The main idea behind this is to consider less labeled datasets for training, which may help in some remote applications where data availability is scarce or presents few occurrences.


## Semi-Supervised Learning and Unsupervised Learning

With the increasing availability of remote sensing images, the labeling task for supervised training of DL models is expensive and time-consuming. Thus, the performance of DL models is impacted due to the lack of large amount of labeled training images. Efforts have been made to consider unlabeled images in training through unsupervised (unlabeled images only) and semi-supervised (labeled and unlabeled images) learning. In remote sensing, most semi-supervised or unsupervised approaches are based on transfer learning, which usually requires a supervised pre-trained model [127]. In this regard, a recent study [99] proposed a promising approach for unlabeled remote sensing images that define spatial augmentation criteria for relating close sub-images. Regardless, this is still an underdeveloped practice with UAV-based data and should be investigated in novel approaches.

Future perspectives point to the use of contrastive loss [10,181,80,76] and clustering-based approaches [30,29]. Recent publications have shown interesting results with the use of contrastive loss that has not yet been fully evaluated in remote sensing. For example, [76] proposed an approach based on contrastive loss that surpassed the performance of its supervised pre-trained counterpart. As for clustering-based methods, they often group images with similar characteristics [30]. On this matter, a research [30] presented an approach that groups the data while reinforcing the consistency between the cluster assignments produced for a pair of images (same images with two augmentations). An efficient and effective way to use a large number of unlabeled images can considerably improve the performance, mainly related to the generalizability of the models.


## Multitask Learning

Multitask learning aims to perform multiple tasks simultaneously. Several advantages are mentioned in [42], including fast learning and the minimization of overfitting problems. Recently, in the context of UAV remote sensing, there were some important researches already developed. A study [194] proposed a method to conduct three tasks (semantic segmentation, height estimation, and boundary detection), which also considered boundary attention modules. Another research [144] simultaneously detecting plants and plantation lines in UAV-based imagery. The proposed network benefited from the contributions of considering both tasks in the same structure, since the plants must, essentially belong to a plantation line. In short, improvements occurred in the detection task when line detection was considered at the same time. This approach can be further explored in several UAV-based remote sensing applications.


## Open-Set

The main idea of an open-set is to deal with unknown or unseen classes during the inference in the testing set [17]. As the authors mention, recognition in real-world scenarios is "open-set", different from neural networks' nature, which is in a "close-set". Consequently, the testing set is classified considering only the classes used during the training. Therefore, unknown or unseen classes are not rejected during the test. There are few studies regarding open-set in the context of remote sensing. Regarding semantic segmentation of aerial imagery, a study by [173] presented an approach considering the open-set context. There, an adaptation of a close-set semantic segmentation method, adding a probability threshold after the softmax, was conducted. Later, a post-processing step based on morphological filters was applied to the pixels classified as unknown to verify if they are inside pixels or from borders. Another interesting approach is to combine open-set and domain adaptation methods, as proposed by [2] in the remote sensing context.


## Photogrammetric Processing

Although not as developed as other practices, DL-based methods can be adopted for processing and optimizing the UAV photogrammetric processing task. This process aims to generate a dense point cloud and an orthomosaic, and it is based on Structure-from-Motion (SfM) and Multi-View Stereo (MVS) techniques. In SfM, the interior and exterior orientation parameters are estimated, and a sparse point cloud is generated. A matching technique between the images is applied in SfM. A recent survey on image matching [129] concluded that this thematic is still an open problem and pointed out the potential of DL is this task. The authors mentioned that DL techniques are mainly applied to feature detection and description, and further investigations on feature matching can be explored. Finally, they pointed out that a promising direction is the customization of modern feature matching techniques to attend SfM.

Regarding DL for UAV image matching, there is a lack of work indicating a potential for future exploration. In the UAV photogrammetric process, DL also can be used in filtering the DSM, which is essential to generate high-quality orthoimages. Previous work [63] showed the potential of using DL to filter the DSM and generate the DTM. Further investigations are required in this thematic, mainly considering UAV data. Besides, another task that can be beneficiated by DL is the color balancing between images when generating orthomosaic from thousands of images, corresponding to extensive areas.


# Conclusions

DL is still considered up to the time of writing, a "black-box" type of solution for most of the problems, although novel research is advancing in minimizing this notion at considerable proportions. Regardless, in the remote sensing domain, it already provided important discoveries on most of its implementations.

Our literature revision has focused on the application of these methods in UAV-based image processing. In this sense, we structured our study to offer more of a comprehensive approach to the subject while presenting an overview of state-of-the-art techniques and perspectives regarding its usage. As such, we hope that this literature revision may serve as an inclusive survey to summarize the UAV applications based on DNNs. Thus, in the evaluated context, this review concludes that:

1. In the context of UAV remote sensing, most of the published materials are based on object detection methods and RGB sensors; however, some applications, as in precision agriculture and forest-related, benefit from multi/hyperspectral data;

2. There is a need for additional labeled public available datasets obtained with UAVs to be used to train and benchmark the networks. In this context, we contributed by providing a repository with some of our UAV datasets in both agricultural and environmental applications;

3. Even though CNNs are the most adopted architecture, other methods based on CNN-LSTMs and GANs are gaining attention in UAV remote sensing and image applications, and future UAV remote sensing works may benefit from their inclusion;

4. DL, when assisted by GPU processing, can provide fast inference solutions. However there is still a need for further investigation regarding real-time processing using embedded systems on UAVs, and, lastly;

5. Some promising thematics, such as open-set, attentionbased mechanisms, few shot and multitask learning can be combined and provide novel approaches in the context of UAV remote sensing; also, these thematics can contribute significantly to the generalization capacity of the DNNs. interpretation of data; in the writing of the manuscript, or in the decision to publish the results.


## Abbreviations

The following abbreviations are used in this manuscript: 

## Figure 1 :
1Word-cloud of different literature-revision papers related to the "remote sensing" and "deep learning" themes.

## Figure 3 :
3A CNN type of architecture with convolution and deconvolution layers. This example architecture is formed by convolutional layers,

## Figure 4 :
4An example of a neural network based on the CNN-LSTM type of architecture. The input image is processed with convolutional

## Figure 5 :
5A DL time-series indicating some popular architectures implemented in image classification (yellowish color), object detection

## Figure 8 :
8The distribution of the evaluated scientific material according to data gathered at Web of Science (WOS) and Google Scholar databases. The y-axis on the left represents the number (n) of published papers, illustrated by solid-colored boxes. The y-axis on the right represents the number of citations that these publications, according to peer-review scientific journals, received since their publication, illustrated by dashed-lines of the same color to its corresponding solid-colored box.

## Figure 9 :
9Diagram describing proceedings and articles according to the defined categories using WOS and Google Scholar datasets.

## Table 1 :
1UAV-based datasets that are publically available from previous research.Reference Task 
Target Sensor 
GSD (cm) Best Method Result 
[49] 
Detection 
Trees 
RGB 
0.82 
RetinaNet 
AP = 92.64% 
[183] 
Segmentation Trees 
RGB 
0.82 
FC-DenseNet F1 = 96.0% 
[143] 
Segmentation Citrus 
Multispectral 12.59 
DDCN 
F1 = 94.4% 
[144] 
Detection 
Citrus 
RGB 
2.28 
[144] 
F1 = 96.5% 
[144] 
Detection 
Corn 
RGB 
1.55 
[144] 
F1 = 87.6% 
[142] 
Detection 
Citrus 
Multispectral 12.59 
[142] 
F1 = 95.0% 


Conflicts of InterestThe authors declare no conflict of interest. The funders had no role in the design of the study; in the collection, analyses,or
Hyperspectral Imaging: A Review on UAV-Based Sensors, Data Processing and Applications for Agriculture and Forestry. Remote Sensing. T Adão, J Hruška, L Pádua, J Bessa, E Peres, R Morais, J Sousa, 9Adão, T., Hruška, J., Pádua, L., Bessa, J., Peres, E., Morais, R. & Sousa, J. Hyperspectral Imaging: A Re- view on UAV-Based Sensors, Data Processing and Appli- cations for Agriculture and Forestry. Remote Sensing. 9 (2020), https://www.mdpi.com/2072-4292/9/11/1110

Deep Open-Set Domain Adaptation for Cross-Scene Classification based on Adversarial Learning and Pareto Ranking. R Adayel, Y Bazi, H Alhichri, N Alajlan, 10.3390/rs12111716Remote Sensing. 121716Adayel, R., Bazi, Y., Alhichri, H. & Alajlan, N. Deep Open-Set Domain Adaptation for Cross-Scene Classification based on Adversarial Learning and Pareto Ranking. Remote Sensing. 12, 1716 (2020,5), http://dx.doi.org/10.3390/rs12111716

Land Cover Classification from fused DSM and UAV Images Using Convolutional Neural Networks. Remote Sensing. H Al-Najjar, B Kalantar, B Pradhan, V Saeidi, A Halin, N Ueda, S Mansor, 11Al-Najjar, H., Kalantar, B., Pradhan, B., Saeidi, V., Halin, A., Ueda, N. & Mansor, S. Land Cover Classi- fication from fused DSM and UAV Images Using Con- volutional Neural Networks. Remote Sensing. 11 (2019), https://www.mdpi.com/2072-4292/11/12/1461

UAV-based high throughput phenotyping in citrus utilizing multispectral imaging and artificial intelligence. Y Ampatzidis, V Partel, Remote Sensing. 11Ampatzidis, Y. & Partel, V. UAV-based high throughput phenotyping in citrus utilizing multispectral imaging and artificial intelligence. Remote Sensing. 11 (2019)

Convolutional neural networks based potholes detection using thermal imaging. Aparna, Y Bhatia, R Rai, V Gupta, N Aggarwal, A Akula, Journal Of King Saud University -Computer And Information Sciences. Aparna, Bhatia, Y., Rai, R., Gupta, V., Aggarwal, N. & Akula, A. Convolutional neural networks based potholes detection using thermal imaging. Journal Of King Saud University -Computer And Information Sciences. (2019)

Deep learning techniques for estimation of the yield and size of citrus fruits using a UAV. O Apolo-Apolo, J Martínez-Guanter, G Egea, P Raja, M Pérez-Ruiz, European Journal Of Agronomy. 115126030Apolo-Apolo, O., Martínez-Guanter, J., Egea, G., Raja, P. & Pérez-Ruiz, M. Deep learning techniques for esti- mation of the yield and size of citrus fruits using a UAV. European Journal Of Agronomy. 115, 126030 (2020)

Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection. S Zhang, C Chi, Y Yao, Z Lei, S Li, ArXiv:1912.02424ArXiv PreprintZhang, S., Chi, C., Yao, Y., Lei, Z. & Li, S. Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection. ArXiv Preprint ArXiv:1912.02424. (2019)

Deep learning for classification of hyperspectral data: A comparative review. N Audebert, B Le Saux, S Lefevre, IEEE Geoscience And Remote Sensing Magazine. 7Audebert, N., Le Saux, B. & Lefevre, S. Deep learning for classification of hyperspectral data: A comparative review. IEEE Geoscience And Remote Sensing Magazine. 7, 159-173 (2019)

VisDrone-DET2018 : The Vision Meets Drone Object Detection in Image Challenge Results. B , P Wen, L Du, D Bian, X Ling, H Hu, Q Nie, Q Cheng, H Liu, C Liu, X Ma, W Wu, H Wang, L Schumann, A Brown, C Lagani, R , SpringerChamB, P., Wen, L., Du, D., Bian, X., Ling, H., Hu, Q., Nie, Q., Cheng, H., Liu, C., Liu, X., Ma, W., Wu, H., Wang, L., Schumann, A., Brown, C. & Lagani, R. VisDrone- DET2018 : The Vision Meets Drone Object Detection in Image Challenge Results. (Springer, Cham,2019)

Learning Representations by Maximizing Mutual Information Across Views. P Bachman, R Hjelm, W Buchwalter, Advances In Neural Information Processing Systems. 32Bachman, P., Hjelm, R. & Buchwalter, W. Learning Rep- resentations by Maximizing Mutual Information Across Views. Advances In Neural Information Processing Sys- tems. 32 pp. 15535-15545 (2019)

SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation. V Badrinarayanan, A Kendall, R Cipolla, IEEE Transactions On Pattern Analysis And Machine Intelligence. 39Badrinarayanan, V., Kendall, A. & Cipolla, R. SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation. IEEE Transactions On Pattern Analysis And Machine Intelligence. 39, 2481-2495 (2017)

A comprehensive survey of deep learning in remote sensing: Theories, tools and challenges for the community. J Ball, D Anderson, C Chan, ArXiv. 11Ball, J., Anderson, D. & Chan, C. A comprehensive sur- vey of deep learning in remote sensing: Theories, tools and challenges for the community. ArXiv. 11 (2017)

Weight quantization in Boltzmann machines. W Balzer, M Takahashi, J Ohta, K Kyuma, Neural Networks. 4Balzer, W., Takahashi, M., Ohta, J. & Kyuma, K. Weight quantization in Boltzmann machines. Neural Networks. 4, 405-409 (1991)

A study on the detection of cattle in UAV images using deep learning. J Barbedo, L Koenigkan, T Santos, P Santos, Sensors (Switzerland). 19Barbedo, J., Koenigkan, L., Santos, T. & Santos, P. A study on the detection of cattle in UAV images using deep learning. Sensors (Switzerland). 19, 1-14 (2019)

Counting Cattle in UAV Images-Dealing with Clustered Animals and Animal/Background Contrast Changes. J Barbedo, L Koenigkan, P Santos, A Ribeiro, Sensors. 20Barbedo, J., Koenigkan, L., Santos, P. & Ribeiro, A. Counting Cattle in UAV Images-Dealing with Clustered Animals and Animal/Background Contrast Changes. Sensors. 20 (2020), https://www.mdpi.com/1424- 8220/20/7/2126

. T Bell, N Nidzieko, D Siegel, R Miller, K Cavanaugh, N &amp; Nelson, Bell, T., Nidzieko, N., Siegel, D., Miller, R., Cavanaugh, K., Nelson, N. & . . .

The Utility of Satellites and Autonomous Remote Sensing Platforms for Monitoring Offshore Aquaculture Farms: A Case Study for Canopy Forming Kelps. M Griffith, Frontiers In Marine Science. Griffith, M. The Utility of Satel- lites and Autonomous Remote Sensing Platforms for Monitoring Offshore Aquaculture Farms: A Case Study for Canopy Forming Kelps. Frontiers In Marine Science. (2020)

Towards Open Set Deep Networks. A Bendale, T Boult, Proceedings Of The IEEE Conference On Computer Vision And Pattern Recognition (CVPR). Of The IEEE Conference On Computer Vision And Pattern Recognition (CVPR)6Bendale, A. & Boult, T. Towards Open Set Deep Net- works. Proceedings Of The IEEE Conference On Com- puter Vision And Pattern Recognition (CVPR). pp. 14 (2016,6)

Unsupervised domain adaptation using generative adversarial networks for semantic segmentation of aerial images. Remote Sensing. B Benjdira, Y Bazi, A Koubaa, K Ouni, 11Benjdira, B., Bazi, Y., Koubaa, A. & Ouni, K. Unsu- pervised domain adaptation using generative adversarial networks for semantic segmentation of aerial images. Re- mote Sensing. 11 (2019)

Unsupervised Domain Adaptation Using Generative Adversarial Networks for Semantic Segmentation of Aerial Images. Remote Sensing. B Benjdira, Y Bazi, A Koubaa, K Ouni, 11Benjdira, B., Bazi, Y., Koubaa, A. & Ouni, K. Unsuper- vised Domain Adaptation Using Generative Adversarial Networks for Semantic Segmentation of Aerial Images. Remote Sensing. 11 (2019), https://www.mdpi.com/2072- 4292/11/11/1369

Vision and deep learning-based algorithms to detect and quantify cracks on concrete surfaces from UAV videos. S Bhowmick, S Nagarajaiah, A Veeraraghavan, Sensors (Switzerland). 20Bhowmick, S., Nagarajaiah, S. & Veeraraghavan, A. Vi- sion and deep learning-based algorithms to detect and quantify cracks on concrete surfaces from UAV videos. Sensors (Switzerland). 20, 1-19 (2020)

Use of Very High Spatial Resolution Commercial Satellite Imagery and Deep Learning to Automatically Map Ice-Wedge Polygons across Tundra Vegetation Types. M Bhuiyan, C Witharana, A Liljedahl, Journal Of Imaging. 6Bhuiyan, M., Witharana, C. & Liljedahl, A. Use of Very High Spatial Resolution Commercial Satellite Im- agery and Deep Learning to Automatically Map Ice- Wedge Polygons across Tundra Vegetation Types. Jour- nal Of Imaging. 6 (2020), https://www.mdpi.com/2313- 433X/6/12/137

Article atss deep learningbased approach to detect apple fruits. L Biffi, E Mitishita, V Liesenberg, A Santos, D Gonçalves, N Estrabis, J Silva, L Osco, A Ramos, J Centeno, M Schimalski, L Rufato, S Neto, J Junior, W Gonçalves, Remote Sensing. 13Biffi, L., Mitishita, E., Liesenberg, V., Dos Santos, A., Gonçalves, D., Estrabis, N., Silva, J., Osco, L., Ramos, A., Centeno, J., Schimalski, M., Rufato, L., Neto, S., Junior, J. & Gonçalves, W. Article atss deep learning- based approach to detect apple fruits. Remote Sensing. 13, 1-23 (2021)

A survey on machine-learning techniques for UAV-based communications. P Bithas, E Michailidis, N Nomikos, D Vouyioukas, A Kanatas, Sensors (Switzerland). 19Bithas, P., Michailidis, E., Nomikos, N., Vouyioukas, D. & Kanatas, A. A survey on machine-learning techniques for UAV-based communications. Sensors (Switzerland). 19, 1-39 (2019)

Deep learning-based multi-feature semantic segmentation in building extraction from images of UAV photogrammetry. W Boonpook, Y Tan, B Xu, International Journal Of Remote Sensing. 42Boonpook, W., Tan, Y. & Xu, B. Deep learning-based multi-feature semantic segmentation in building extrac- tion from images of UAV photogrammetry. International Journal Of Remote Sensing. 42, 1-19 (2021)

Comparing the prediction performance of a Deep Learning Neural Network model with conventional machine learning models in landslide susceptibility assessment. D Bui, P Tsangaratos, V Nguyen, N Liem, P Trinh, CATENA. 188104426Bui, D., Tsangaratos, P., Nguyen, V., Liem, N. & Trinh, P. Comparing the prediction performance of a Deep Learn- ing Neural Network model with conventional machine learning models in landslide susceptibility assessment. CATENA. 188 pp. 104426 (2020)

Landscape Classification with Deep Neural Networks. D Buscombe, A Ritchie, Geosciences. 8Buscombe, D. & Ritchie, A. Landscape Classification with Deep Neural Networks. Geosciences. 8 (2018), https://www.mdpi.com/2076-3263/8/7/244

Adopting deep learning methods for airborne RGB fluvial scene classification. REMOTE SENSING OF ENVIRONMENT. P Carbonneau, S Dugdale, T Breckon, J Dietrich, M Fonstad, H Miyamoto, A Woodget, 1215Carbonneau, P., Dugdale, S., Breckon, T., Dietrich, J., Fonstad, M., Miyamoto, H. & Woodget, A. Adopting deep learning methods for airborne RGB fluvial scene classification. REMOTE SENSING OF ENVIRONMENT. 251 (2020,12,15)

End-to-End Object Detection with Transformers. Computer Vision -ECCV 2020. N Carion, F Massa, G Synnaeve, N Usunier, A Kirillov, S Zagoruyko, Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A. & Zagoruyko, S. End-to-End Object Detection with Transformers. Computer Vision -ECCV 2020. pp. 213- 229 (2020)

Unsupervised Learning of Visual Features by Contrasting Cluster Assignments. M Caron, I Misra, J Mairal, P Goyal, P Bojanowski, A Joulin, Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P. & Joulin, A. Unsupervised Learning of Visual Features by Contrasting Cluster Assignments. (2021)

Deep Clustering for Unsupervised Learning of Visual Features. M Caron, P Bojanowski, A Joulin, M Douze, Computer Vision -ECCV. Caron, M., Bojanowski, P., Joulin, A. & Douze, M. Deep Clustering for Unsupervised Learning of Visual Features. Computer Vision -ECCV 2018. pp. 139-156 (2018)

Cascade R-CNN: high quality object detection and instance segmentation. Z Cai, N Vasconcelos, IEEE Transactions On Pattern Analysis And Machine Intelligence. Cai, Z. & Vasconcelos, N. Cascade R-CNN: high quality object detection and instance segmentation. IEEE Trans- actions On Pattern Analysis And Machine Intelligence. (2019)

Delving Into High Quality Object Detection. Z Cai, N Vasconcelos, Cascade R-Cnn, IEEE/CVF Conference On Computer Vision And Pattern Recognition. Cai, Z. & Vasconcelos, N. Cascade R-CNN: Delving Into High Quality Object Detection. 2018 IEEE/CVF Confer- ence On Computer Vision And Pattern Recognition. pp. 6154-6162 (2018)

Deep learning applied to phenotyping of biomass in forages with uav-based rgb imagery. W Castro, J Junior, C Polidoro, L Osco, W Gonçalves, L Rodrigues, M Santos, L Jank, S Barrios, C Valle, R Simeão, C Carromeu, E Silveira, L Jorge, E Matsubara, Sensors (Switzerland). 20Castro, W., Junior, J., Polidoro, C., Osco, L., Gonçalves, W., Rodrigues, L., Santos, M., Jank, L., Barrios, S., Valle, C., Simeão, R., Carromeu, C., Silveira, E., Jorge, L. & Matsubara, E. Deep learning applied to phenotyping of biomass in forages with uav-based rgb imagery. Sensors (Switzerland). 20, 1-18 (2020)

CGNet: A Light-weight Context Guided Network for Semantic Segmentation. T Wu, S Tang, R Zhang, Y Zhang, ArXiv:1811.08201.ArXiv PreprintWu, T., Tang, S., Zhang, R. & Zhang, Y. CGNet: A Light-weight Context Guided Network for Semantic Seg- mentation. ArXiv Preprint ArXiv:1811.08201. (2018)

Cgnet: A light-weight context guided network for semantic segmentation. T Wu, S Tang, R Zhang, J Cao, Y Zhang, IEEE Transactions On Image Processing. 30Wu, T., Tang, S., Zhang, R., Cao, J. & Zhang, Y. Cgnet: A light-weight context guided network for semantic seg- mentation. IEEE Transactions On Image Processing. 30 pp. 1169-1179 (2020)

Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs. L Chen, G Papandreou, I Kokkinos, K Murphy, A Yuille, Chen, L., Papandreou, G., Kokkinos, I., Murphy, K. & Yuille, A. Semantic Image Segmentation with Deep Con- volutional Nets and Fully Connected CRFs. (2016)

L Chen, G Papandreou, I Kokkinos, K Murphy, A Yuille, Deeplab, Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs. IEEE Transactions On Pattern Analysis And Machine Intelligence. 40Chen, L., Papandreou, G., Kokkinos, I., Murphy, K. & Yuille, A. DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs. IEEE Transactions On Pattern Analysis And Machine Intelligence. 40, 834-848 (2018)

Foreground-Background Imbalance Problem in Deep Object Detectors: A Review. J Chen, Q Wu, D Liu, T Xu, 2020 IEEE Conference On Multimedia Information Processing And Retrieval (MIPR). Chen, J., Wu, Q., Liu, D. & Xu, T. Foreground- Background Imbalance Problem in Deep Object Detec- tors: A Review. 2020 IEEE Conference On Multimedia Information Processing And Retrieval (MIPR). pp. 285- 290 (2020)

A survey on object detection in optical remote sensing images. ISPRS Journal Of Photogrammetry And Remote Sensing. G Cheng, J Han, 10.1016/j.isprsjprs.2016.03.014117Cheng, G. & Han, J. A survey on object detection in optical remote sensing images. ISPRS Journal Of Pho- togrammetry And Remote Sensing. 117 pp. 11-28 (2016), http://dx.doi.org/10.1016/j.isprsjprs.2016.03.014

Remote sensing image scene classification: Benchmark and state of the art. G Cheng, J Han, X Lu, ArXiv. Cheng, G., Han, J. & Lu, X. Remote sensing image scene classification: Benchmark and state of the art. ArXiv. (2017)

Xception: Deep learning with depthwise separable convolutions. F Chollet, Proceedings Of The IEEE Conference On Computer Vision And Pattern Recognition. Of The IEEE Conference On Computer Vision And Pattern RecognitionChollet, F. Xception: Deep learning with depthwise sepa- rable convolutions. Proceedings Of The IEEE Conference On Computer Vision And Pattern Recognition. pp. 1251- 1258 (2017)

Multi-Task Learning with Deep Neural Networks: A Survey. M Crawshaw, Crawshaw, M. Multi-Task Learning with Deep Neural Networks: A Survey. (2020)

Using deep learning and low-cost rgb and thermal cameras to detect pedestrians in aerial images captured by multirotor uav. D Oliveira, M Wehrmeister, Sensors (Switzerland). 18Oliveira, D. & Wehrmeister, M. Using deep learning and low-cost rgb and thermal cameras to detect pedestri- ans in aerial images captured by multirotor uav. Sensors (Switzerland). 18 (2018)

S Qiao, L Chen, A Yuille, Detectors, ArXiv:2006.02334Detecting Objects with Recursive Feature Pyramid and Switchable Atrous Convolution. ArXiv PreprintQiao, S., Chen, L. & Yuille, A. DetectoRS: Detecting Objects with Recursive Feature Pyramid and Switchable Atrous Convolution. ArXiv Preprint ArXiv:2006.02334. (2020)

Deep learning with unsupervised data labeling for weed detection in line crops in UAV images. Dian Bah, M Hafiane, A Canals, R , Remote Sensing. 10Dian Bah, M., Hafiane, A. & Canals, R. Deep learning with unsupervised data labeling for weed detection in line crops in UAV images. Remote Sensing. 10, 1-22 (2018)

LANet: Local Attention Embedding to Improve the Semantic Segmentation of Remote Sensing Images. L Ding, H Tang, L Bruzzone, IEEE Transactions On Geoscience And Remote Sensing. 59Ding, L., Tang, H. & Bruzzone, L. LANet: Local Atten- tion Embedding to Improve the Semantic Segmentation of Remote Sensing Images. IEEE Transactions On Geo- science And Remote Sensing. 59, 426-435 (2021)

. M Yin, Z Yao, Y Cao, X Li, Z Zhang, S Lin, H Hu, Disentangled Non-Local Neural Networks. ECCV. Yin, M., Yao, Z., Cao, Y., Li, X., Zhang, Z., Lin, S. & Hu, H. Disentangled Non-Local Neural Networks. ECCV. (2020)

A Dosovitskiy, L Beyer, A Kolesnikov, D Weissenborn, X Zhai, T Unterthiner, M Dehghani, M Minderer, G Heigold, S Gelly, J Uszkoreit, N Houlsby, An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uszkoreit, J. & Houlsby, N. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. (2020)

Assessment of CNN-based methods for individual tree detection on images captured by RGB cameras attached to UAVS. A Santos, J Marcato Junior, M Araújo, D Di Martini, E Tetila, H Siqueira, C Aoki, A Eltner, E Matsubara, H Pistori, R Feitosa, V Liesenberg, W Gonçalves, Sensors (Switzerland). 19Santos, A., Marcato Junior, J., Araújo, M., Di Martini, D., Tetila, E., Siqueira, H., Aoki, C., Eltner, A., Matsubara, E., Pistori, H., Feitosa, R., Liesenberg, V. & Gonçalves, W. Assessment of CNN-based methods for individual tree detection on images captured by RGB cameras attached to UAVS. Sensors (Switzerland). 19, 1-11 (2019)

The unmanned aerial vehicle benchmark: Object detection and tracking. D Du, Y Qi, H Yu, Y Yang, K Duan, G Li, W Zhang, Q Huang, Q Tian, Lecture Notes In Computer Science (including Subseries Lecture Notes In Artificial Intelligence And Lecture Notes In Bioinformatics). 11214 LNCS pp. Du, D., Qi, Y., Yu, H., Yang, Y., Duan, K., Li, G., Zhang, W., Huang, Q. & Tian, Q. The unmanned aerial vehicle benchmark: Object detection and tracking. Lecture Notes In Computer Science (including Subseries Lecture Notes In Artificial Intelligence And Lecture Notes In Bioinfor- matics). 11214 LNCS pp. 375-391 (2018)

K Duan, S Bai, L Xie, H Qi, Q Huang, Q Tian, Centernet, Keypoint triplets for object detection. Proceedings Of The IEEE International Conference On Computer Vision. 2019-October pp. Duan, K., Bai, S., Xie, L., Qi, H., Huang, Q. & Tian, Q. CenterNet: Keypoint triplets for object detection. Pro- ceedings Of The IEEE International Conference On Com- puter Vision. 2019-October pp. 6568-6577 (2019)

H Zhang, H Chang, B Ma, N Wang, X Chen, Dynamic R-Cnn, ArXiv:2004.06002Towards High Quality Object Detection via Dynamic Training. ArXiv PreprintZhang, H., Chang, H., Ma, B., Wang, N. & Chen, X. Dy- namic R-CNN: Towards High Quality Object Detection via Dynamic Training. ArXiv Preprint ArXiv:2004.06002. (2020)

Domain Adaptation Using Representation Learning for the Classification of Remote Sensing Images. A Elshamli, G Taylor, A Berg, S Areibi, IEEE Journal Of Selected Topics In Applied Earth Observations And Remote Sensing. 10Elshamli, A., Taylor, G., Berg, A. & Areibi, S. Domain Adaptation Using Representation Learning for the Clas- sification of Remote Sensing Images. IEEE Journal Of Selected Topics In Applied Earth Observations And Re- mote Sensing. 10, 4198-4209 (2017)

Others Neural architecture search: A survey. T Elsken, J Metzen, F Hutter, J. Mach. Learn. Res. 20Elsken, T., Metzen, J., Hutter, F. & Others Neural archi- tecture search: A survey.. J. Mach. Learn. Res.. 20, 1-21 (2019)

Category-Sensitive Domain Adaptation for Land Cover Mapping in Aerial Scenes. B Fang, R Kou, L Pan, P Chen, Remote Sensing. 11Fang, B., Kou, R., Pan, L. & Chen, P. Category- Sensitive Domain Adaptation for Land Cover Map- ping in Aerial Scenes. Remote Sensing. 11 (2019), https://www.mdpi.com/2072-4292/11/22/2631

Multi-temporal unmanned aerial vehicle remote sensing for vegetable mapping using an attention-based recurrent convolutional neural network. Q Feng, J Yang, Y Liu, C Ou, D Zhu, B Niu, J Liu, B Li, Remote Sensing. 12Feng, Q., Yang, J., Liu, Y., Ou, C., Zhu, D., Niu, B., Liu, J. & Li, B. Multi-temporal unmanned aerial vehicle remote sensing for vegetable mapping using an attention-based recurrent convolutional neural network. Remote Sensing. 12 (2020)

Individual tree detection and species classification of Amazonian palms using UAV images and deep learning. Forest Ecology And Management. M Ferreira, D Almeida, D Papa, J Minervino, H Veras, A Formighieri, C Santos, M Ferreira, E Figueiredo, E Ferreira, 10.1016/j.foreco.2020.118397475118397Ferreira, M., Almeida, D., Papa, D., Minervino, J., Veras, H., Formighieri, A., Santos, C., Fer- reira, M., Figueiredo, E. & Ferreira, E. Individual tree detection and species classification of Amazo- nian palms using UAV images and deep learning. For- est Ecology And Management. 475, 118397 (2020), https://doi.org/10.1016/j.foreco.2020.118397

Weight discretization paradigm for optical neural networks. Optical Interconnections And Networks. E Fiesler, A Choudry, H Caulfield, Fiesler, E., Choudry, A. & Caulfield, H. Weight discretiza- tion paradigm for optical neural networks. Optical Inter- connections And Networks. 1281 pp. 164-173 (1990)

Explaining the unsuitability of the kappa coefficient in the assessment and comparison of the accuracy of thematic maps obtained by image classification. Remote Sensing Of Environment. G Foody, 10.1016/j.rse.2019.111630239111630Foody, G. Explaining the unsuitability of the kappa co- efficient in the assessment and comparison of the accu- racy of thematic maps obtained by image classification. Remote Sensing Of Environment. 239, 111630 (2020), https://doi.org/10.1016/j.rse.2019.111630

Feature Pyramid Networks for Object Detection. T Lin, P Dollár, R Girshick, K He, B Hariharan, S Belongie, IEEE Conference On Computer Vision And Pattern Recognition (CVPR). Lin, T., Dollár, P., Girshick, R., He, K., Hariharan, B. & Belongie, S. Feature Pyramid Networks for Object Detection. 2017 IEEE Conference On Computer Vision And Pattern Recognition (CVPR). pp. 936-944 (2017)

Region Proposal by Guided Anchoring. J Wang, K Chen, S Yang, C Loy, D Lin, IEEE Conference On Computer Vision And Pattern Recognition. 12Wang, J., Chen, K., Yang, S., Loy, C. & Lin, D. Region Proposal by Guided Anchoring. IEEE Conference On Computer Vision And Pattern Recognition. pp. 12 (2019)

Deep Convolutional Neural Network for Flood Extent Mapping Using Unmanned Aerial Vehicles Data. A Gebrehiwot, L Hashemi-Beni, G Thompson, P Kordjamshidi, T Langan, Sensors. 19Gebrehiwot, A., Hashemi-Beni, L., Thompson, G., Kordjamshidi, P. & Langan, T. Deep Convolutional Neural Network for Flood Extent Mapping Using Un- manned Aerial Vehicles Data. Sensors. 19 (2019), https://www.mdpi.com/1424-8220/19/7/1486

A deep learning approach to DTM extraction from imagery using rule-based training labels. ISPRS Journal Of Photogrammetry And Remote Sensing. C Gevaert, C Persello, F Nex, G Vosselman, 142Gevaert, C., Persello, C., Nex, F. & Vosselman, G. A deep learning approach to DTM extraction from imagery using rule-based training labels. ISPRS Journal Of Pho- togrammetry And Remote Sensing. 142 pp. 106 -123 (2018)

Monitoring household upgrading in unplanned settlements with unmanned aerial vehicles. C Gevaert, C Persello, R Sliuzas, G Vosselman, 10.1016/j.jag.2020.102117International Journal Of Applied Earth Observation And Geoinformation. 90102117Gevaert, C., Persello, C., Sliuzas, R. & Vossel- man, G. Monitoring household upgrading in un- planned settlements with unmanned aerial vehi- cles. International Journal Of Applied Earth Ob- servation And Geoinformation. 90, 102117 (2020), https://doi.org/10.1016/j.jag.2020.102117

Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection. X Li, W Wang, L Wu, S Chen, X Hu, J Li, J Tang, J Yang, ArXiv:2006.04388ArXiv PreprintLi, X., Wang, W., Wu, L., Chen, S., Hu, X., Li, J., Tang, J. & Yang, J. Generalized Focal Loss: Learning Quali- fied and Distributed Bounding Boxes for Dense Object Detection. ArXiv Preprint ArXiv:2006.04388. (2020)

U-Net Convolutional Networks for Mining Land Cover Classification Based on High-Resolution UAV Imagery. T Giang, K Dang, Q Toan Le, V Nguyen, S Tong, V Pham, Giang, T., Dang, K., Toan Le, Q., Nguyen, V., Tong, S. & Pham, V. U-Net Convolutional Networks for Min- ing Land Cover Classification Based on High-Resolution UAV Imagery. IEEE Access. 8 pp. 186257-186273 (2020)

Mapping utility poles in aerial orthoimages using atss deep learning method. M Gomes, J Silva, D Gonçalves, P Zamboni, J Perez, E Batista, A Ramos, L Osco, E Matsubara, J Li, J Junior, W Gonçalves, Sensors (Switzerland). 20Gomes, M., Silva, J., Gonçalves, D., Zamboni, P., Perez, J., Batista, E., Ramos, A., Osco, L., Matsubara, E., Li, J., Junior, J. & Gonçalves, W. Mapping utility poles in aerial orthoimages using atss deep learning method. Sensors (Switzerland). 20, 1-14 (2020)

. I Goodfellow, J Pouget-Abadie, M Mirza, B Xu, D Warde-Farley, S Ozair, A Courville, Y Bengio, Generative Adversarial Networks. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A. & Bengio, Y. Generative Adversarial Networks. (2014)

I Goodfellow, Y Bengio, A Courville, Deep Learning. MIT PressGoodfellow, I., Bengio, Y. & Courville, A. Deep Learning. (MIT Press,2016)

Drones and convolutional neural networks facilitate automated and accurate cetacean species identification and photogrammetry. P Gray, K Bierlich, S Mantell, A Friedlaender, J Goldbogen, D Johnston, Methods In Ecology And Evolution. 10Gray, P., Bierlich, K., Mantell, S., Friedlaender, A., Gold- bogen, J. & Johnston, D. Drones and convolutional neu- ral networks facilitate automated and accurate cetacean species identification and photogrammetry. Methods In Ecology And Evolution. 10, 1490-1500 (2019)

. X Lu, B Li, Y Yue, Q Li, J Yan, R-Cnn Grid, Plus, CoRR. abs/1906.05688Lu, X., Li, B., Yue, Y., Li, Q. & Yan, J. Grid R-CNN Plus: Faster and Better. CoRR. abs/1906.05688 (2019), http://arxiv.org/abs/1906.05688

A survey on methods and theories of quantized neural networks. Y Guo, ArXiv:1808.04752.ArXiv PreprintGuo, Y. A survey on methods and theories of quan- tized neural networks. ArXiv Preprint ArXiv:1808.04752. (2018)

Forest damage assessment using deep learning on high resolution remote sensing data. Remote Sensing. Z Hamdi, M Brandmeier, C Straub, 11Hamdi, Z., Brandmeier, M. & Straub, C. Forest damage assessment using deep learning on high resolution remote sensing data. Remote Sensing. 11, 1-14 (2019)

Evaluating techniques for mapping island vegetation from unmanned aerial vehicle (UAV) images: Pixel classification, visual interpretation and machine learning approaches. S Hamylton, R Morris, R Carvalho, N Roder, P Barlow, K Mills, L Wang, 10.1016/j.jag.2020.102085International Journal Of Applied Earth Observation And Geoinformation. 89102085Hamylton, S., Morris, R., Carvalho, R., Roder, N., Bar- low, P., Mills, K. & Wang, L. Evaluating techniques for mapping island vegetation from unmanned aerial vehicle (UAV) images: Pixel classification, visual interpretation and machine learning approaches. International Journal Of Applied Earth Observation And Geoinformation. 89, 102085 (2020), https://doi.org/10.1016/j.jag.2020.102085

Deep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, Proceedings Of The IEEE Computer Society Conference On Computer Vision And Pattern Recognition. 2016-December pp. Of The IEEE Computer Society Conference On Computer Vision And Pattern Recognition. 2016-December ppHe, K., Zhang, X., Ren, S. & Sun, J. Deep residual learn- ing for image recognition. Proceedings Of The IEEE Computer Society Conference On Computer Vision And Pattern Recognition. 2016-December pp. 770-778 (2016)

Momentum Contrast for Unsupervised Visual Representation Learning. K He, H Fan, Y Wu, S Xie, R Girshick, IEEE/CVF Conference On Computer Vision And Pattern Recognition (CVPR). He, K., Fan, H., Wu, Y., Xie, S. & Girshick, R. Momen- tum Contrast for Unsupervised Visual Representation Learning. 2020 IEEE/CVF Conference On Computer Vi- sion And Pattern Recognition (CVPR). pp. 9726-9735 (2020)

Hyperspectral Classification of Plants: A Review of Waveband Selection Generalisability. A Hennessy, K Clarke, M Lewis, Remote Sensing. 12113Hennessy, A., Clarke, K. & Lewis, M. Hyperspectral Classification of Plants: A Review of Waveband Selection Generalisability. Remote Sensing. 12, 113 (2020)

Improving neural networks by preventing co-adaptation of feature detectors. G Hinton, N Srivastava, A Krizhevsky, I Sutskever, R Salakhutdinov, CoRR. abs/1207.0580Hinton, G., Srivastava, N., Krizhevsky, A., Sutskever, I. & Salakhutdinov, R. Improving neural networks by preventing co-adaptation of feature detectors. CoRR. abs/1207.0580 (2012), http://arxiv.org/abs/1207.0580

Distilling the knowledge in a neural network. G Hinton, O Vinyals, J Dean, ArXiv:1503.02531ArXiv PreprintHinton, G., Vinyals, O. & Dean, J. Distilling the knowledge in a neural network. ArXiv Preprint ArXiv:1503.02531. (2015)

Learning deep representations by mutual information estimation and maximization. D Hjelm, A Fedorov, S Lavoie-Marchildon, K Grewal, P Bachman, A Trischler, Y Bengio, ICLR 2019. pp. 24 (2019,4Hjelm, D., Fedorov, A., Lavoie-Marchildon, S., Grewal, K., Bachman, P., Trischler, A. & Bengio, Y. Learning deep representations by mutual information estimation and maximization. ICLR 2019. pp. 24 (2019,4)

Long Short-Term Memory. S Hochreiter, J Schmidhuber, Neural Computation. 9Hochreiter, S. & Schmidhuber, J. Long Short-Term Mem- ory. Neural Computation. 9 (1997)

Mapping of land cover with opensource software and ultra-high-resolution imagery acquired with unmanned aerial vehicles. N Horning, E Fleishman, P Ersts, F Fogarty, M Zillig, Remote Sensing In Ecology And Conservation. 6Horning, N., Fleishman, E., Ersts, P., Fogarty, F. & Wohlfeil Zillig, M. Mapping of land cover with open- source software and ultra-high-resolution imagery ac- quired with unmanned aerial vehicles. Remote Sensing In Ecology And Conservation. 6, 487-497 (2020)

Segmentation for Object-Based Image Analysis (OBIA): A review of algorithms and challenges from remote sensing perspective. M Hossain, D Chen, 10.1016/j.isprsjprs.2019.02.009ISPRS Journal Of Photogrammetry And Remote Sensing. 150Hossain, M. & Chen, D. Segmentation for Object-Based Image Analysis (OBIA): A review of algorithms and chal- lenges from remote sensing perspective. ISPRS Journal Of Photogrammetry And Remote Sensing. 150, 115-134 (2019), https://doi.org/10.1016/j.isprsjprs.2019.02.009

Deep Recurrent Neural Networks for Winter Vegetation Quality Mapping via Multitemporal SAR Sentinel-1. D Ho Tong Minh, D Ienco, R Gaetano, N Lalande, E Ndikumana, F Osman, P Maurel, IEEE Geoscience And Remote Sensing Letters. 15Ho Tong Minh, D., Ienco, D., Gaetano, R., Lalande, N., Ndikumana, E., Osman, F. & Maurel, P. Deep Recurrent Neural Networks for Winter Vegetation Quality Mapping via Multitemporal SAR Sentinel-1. IEEE Geoscience And Remote Sensing Letters. 15, 464-468 (2018)

Identification of animal individuals using deep learning: A case study of giant panda. J Hou, Y He, H Yang, T Connor, J Gao, Y Wang, Y Zeng, J Zhang, J Huang, B Zheng, S Zhou, 108414Hou, J., He, Y., Yang, H., Connor, T., Gao, J., Wang, Y., Zeng, Y., Zhang, J., Huang, J., Zheng, B. & Zhou, S. Identification of animal individuals using deep learning: A case study of giant panda. Biological Conservation. 242 pp. 108414 (2020)

Mobilenets: Efficient convolutional neural networks for mobile vision applications. A Howard, M Zhu, B Chen, D Kalenichenko, W Wang, T Weyand, M Andreetto, H Adam, ArXiv:1704.04861ArXiv PreprintHoward, A., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M. & Adam, H. Mobilenets: Efficient convolutional neural networks for mobile vision applications. ArXiv Preprint ArXiv:1704.04861. (2017)

Vasudevan, V. & Others Searching for mobilenetv3. A Howard, M Sandler, G Chu, L Chen, B Chen, M Tan, W Wang, Y Zhu, R Pang, Proceedings Of The IEEE International Conference On Computer Vision. Of The IEEE International Conference On Computer VisionHoward, A., Sandler, M., Chu, G., Chen, L., Chen, B., Tan, M., Wang, W., Zhu, Y., Pang, R., Vasudevan, V. & Others Searching for mobilenetv3. Proceedings Of The IEEE International Conference On Computer Vision. pp. 1314-1324 (2019)

Deep High-Resolution Representation Learning for Visual Recognition. J Wang, K Sun, T Cheng, B Jiang, C Deng, Y Zhao, D Liu, Y Mu, M Tan, X Wang, W Liu, B Xiao, IEEE Transactions On Pattern Analysis And Machine Intelligence. pp. Wang, J., Sun, K., Cheng, T., Jiang, B., Deng, C., Zhao, Y., Liu, D., Mu, Y., Tan, M., Wang, X., Liu, W. & Xiao, B. Deep High-Resolution Representation Learning for Vi- sual Recognition. IEEE Transactions On Pattern Analysis And Machine Intelligence. pp. 1-1 (2020)

Hybrid task cascade for instance segmentation. K Chen, J Pang, J Wang, Y Xiong, X Li, S Sun, W Feng, Z Liu, J Shi, W Ouyang, C Loy, D Lin, IEEE Conference On Computer Vision And Pattern Recognition. 10Chen, K., Pang, J., Wang, J., Xiong, Y., Li, X., Sun, S., Feng, W., Liu, Z., Shi, J., Ouyang, W., Loy, C. & Lin, D. Hybrid task cascade for instance segmentation. IEEE Conference On Computer Vision And Pattern Recognition. pp. 10 (2019)

Recognition of diseased Pinus trees in UAV images using deep learning and AdaBoost classifier. Biosystems Engineering. G Hu, C Yin, M Wan, Y Zhang, Y Fang, 10.1016/j.biosystemseng.2020.03.021Hu, G., Yin, C., Wan, M., Zhang, Y. & Fang, Y. Recognition of diseased Pinus trees in UAV im- ages using deep learning and AdaBoost classifier. Biosystems Engineering. 194 pp. 138-151 (2020), https://doi.org/10.1016/j.biosystemseng.2020.03.021

Semantic Segmentation of Remote Sensing Images with Sparse Annotations. Y Hua, D Marcos, L Mou, X Zhu, D Tuia, IEEE Geoscience And Remote Sensing Letters. Hua, Y., Marcos, D., Mou, L., Zhu, X. & Tuia, D. Seman- tic Segmentation of Remote Sensing Images with Sparse Annotations. IEEE Geoscience And Remote Sensing Let- ters. (2021)

Segmentation of Vegetation and Flood from Aerial Images Based on Decision Fusion of Neural Networks. L Ichim, D Popescu, Remote Sensing. 12Ichim, L. & Popescu, D. Segmentation of Vegetation and Flood from Aerial Images Based on Decision Fu- sion of Neural Networks. Remote Sensing. 12 (2020), https://www.mdpi.com/2072-4292/12/15/2490

Land Cover Classification via Multitemporal Spatial Data by Deep Recurrent Neural Networks. D Ienco, R Gaetano, C Dupaquier, P Maurel, IEEE Geoscience And Remote Sensing Letters. 14Ienco, D., Gaetano, R., Dupaquier, C. & Maurel, P. Land Cover Classification via Multitemporal Spatial Data by Deep Recurrent Neural Networks. IEEE Geoscience And Remote Sensing Letters. 14, 1685-1689 (2017)

. ImageNet ImageNet Object Localization Challenge. ImageNet ImageNet Object Localization Challenge. (2018), https://www.kaggle.com/c/imagenet-object- localization-challenge

Embedded Development Boards for Edge-AI: A Comprehensive. H Imran, U Mujahid, S Wazir, U Latif, K Mehmood, ArXiv:2009.00803Report. ArXiv PreprintImran, H., Mujahid, U., Wazir, S., Latif, U. & Mehmood, K. Embedded Development Boards for Edge-AI: A Com- prehensive Report. ArXiv Preprint ArXiv:2009.00803. (2020)

Image-to-Image Translation with Conditional Adversarial Networks. P Isola, J Zhu, T Zhou, A Efros, Isola, P., Zhu, J., Zhou, T. & Efros, A. Image-to- Image Translation with Conditional Adversarial Net- works. (2018)

Accuracy Assessment of Deep Learning Based Classification of LiDAR and UAV Points Clouds for DTM Creation and Flood Risk Mapping. G Jakovljevic, M Govedarica, F Alvarez-Taboada, V Pajic, Geosciences. 9Jakovljevic, G., Govedarica, M., Alvarez-Taboada, F. & Pajic, V. Accuracy Assessment of Deep Learning Based Classification of LiDAR and UAV Points Clouds for DTM Creation and Flood Risk Mapping. Geosciences. 9 (2019), https://www.mdpi.com/2076-3263/9/7/323

Deep learning for hyperspectral image classification with few labeled samples. S Jia, S Jiang, Z Lin, N Li, M Xu, S Yu, Survey, Neurocomputing. 448Jia, S., Jiang, S., Lin, Z., Li, N., Xu, M. & Yu, S. A survey: Deep learning for hyperspectral image classification with few labeled samples. Neurocomputing. 448 pp. 179-204 (2021)

Deep Unsupervised Embedding for Remotely Sensed Images Based on Spatially Augmented Momentum Contrast. J Kang, R Fernandez-Beltran, P Duan, S Liu, A Plaza, IEEE Transactions On Geoscience And Remote Sensing. Kang, J., Fernandez-Beltran, R., Duan, P., Liu, S. & Plaza, A. Deep Unsupervised Embedding for Remotely Sensed Images Based on Spatially Augmented Momen- tum Contrast. IEEE Transactions On Geoscience And Remote Sensing. pp. 1-13 (2020)

Fast implementation of real-time fruit detection in apple orchards using deep learning. Computers And Electronics In Agriculture. H Kang, C Chen, 10.1016/j.compag.2019.105108168105108Kang, H. & Chen, C. Fast implementation of real-time fruit detection in apple orchards using deep learning. Computers And Electronics In Agriculture. 168, 105108 (2020), https://doi.org/10.1016/j.compag.2019.105108

Effects of Varying Resolution on Performance of CNN based Image Classification An Experimental Study. S Kannojia, G Jaiswal, International Journal Of Computer Sciences And Engineering. 6Kannojia, S. & Jaiswal, G. Effects of Varying Resolution on Performance of CNN based Image Classification An Experimental Study. International Journal Of Computer Sciences And Engineering. 6, 451-456 (2018)

Automatic Plant Counting and Location Based on a Few-Shot Learning Technique. A Karami, M Crawford, E Delp, IEEE Journal Of Selected Topics In Applied Earth Observations And Remote Sensing. 13Karami, A., Crawford, M. & Delp, E. Automatic Plant Counting and Location Based on a Few-Shot Learning Technique. IEEE Journal Of Selected Topics In Applied Earth Observations And Remote Sensing. 13 pp. 5872- 5886 (2020)

Detecting mammals in UAV images: Best practices to address a substantially imbalanced dataset with deep learning. Remote Sensing Of Environment. B Kellenberger, D Marcos, D Tuia, 216Kellenberger, B., Marcos, D. & Tuia, D. Detecting mam- mals in UAV images: Best practices to address a sub- stantially imbalanced dataset with deep learning. Remote Sensing Of Environment. 216 pp. 139 -153 (2018)

Vine disease detection in UAV multispectral images using optimized image registration and deep learning segmentation approach. M Kerkech, A Hafiane, R Canals, Computers And Electronics In Agriculture. 174Kerkech, M., Hafiane, A. & Canals, R. Vine disease detec- tion in UAV multispectral images using optimized image registration and deep learning segmentation approach. Computers And Electronics In Agriculture. 174 (2020)

A survey of the recent architectures of deep convolutional neural networks. A Khan, A Sohail, U Zahoora, A Qureshi, 10.1007/s10462-020-09825-6Artificial Intelligence Review. 53Khan, A., Sohail, A., Zahoora, U. & Qureshi, A. A survey of the recent architectures of deep convolutional neural networks. Artificial Intelligence Review. 53 pp. 5455- 5516 (2020), https://doi.org/10.1007/s10462-020-09825- 6

Deep Learning for Change Detection in Remote Sensing Images: Comprehensive Review and Meta-Analysis. L Khelifi, M Mignotte, IEEE AccessKhelifi, L. & Mignotte, M. Deep Learning for Change Detection in Remote Sensing Images: Comprehensive Review and Meta-Analysis. IEEE Access. 8 pp. 126385- 126400 (2020)

Corn Plant Counting Using Deep Learning and UAV Images. B Kitano, C Mendes, A Geus, H Oliveira, J Souza, IEEE Geoscience And Remote Sensing Letters. pp. Kitano, B., Mendes, C., Geus, A., Oliveira, H. & Souza, J. Corn Plant Counting Using Deep Learning and UAV Images. IEEE Geoscience And Remote Sensing Letters. pp. 1-5 (2019)

ImageNet Classification with Deep Convolutional Neural Networks. A Krizhevsky, I Sutskever, G Hinton, Proceedings Of The 25th International Conference On Neural Information Processing Systems. Of The 25th International Conference On Neural Information Processing Systems1Krizhevsky, A., Sutskever, I. & Hinton, G. ImageNet Classification with Deep Convolutional Neural Networks. Proceedings Of The 25th International Conference On Neural Information Processing Systems -Volume 1. pp. 1097-1105 (2012)

Deep Learning Classification of Land Cover and Crop Types Using Remote Sensing Data. N Kussul, M Lavreniuk, S Skakun, A Shelestov, IEEE Geoscience And Remote Sensing Letters. 14Kussul, N., Lavreniuk, M., Skakun, S. & Shelestov, A. Deep Learning Classification of Land Cover and Crop Types Using Remote Sensing Data. IEEE Geoscience And Remote Sensing Letters. 14, 778-782 (2017)

A deep learning approach to identify smoke plumes in satellite imagery in near-real time for health risk communication. Alexandra Larsen, A Hanigan, I Reich, B Qin, Y Cope, M Morgan, G Rappold, A , Journal Of Exposure Science & Environmental Epidemiology. 31Alexandra Larsen, A., Hanigan, I., Reich, B., Qin, Y., Cope, M., Morgan, G. & Rappold, A. A deep learning approach to identify smoke plumes in satellite imagery in near-real time for health risk communication. Journal Of Exposure Science & Environmental Epidemiology. 31 pp. 170-176 (2020)

A Comprehensive Analysis of Deep Regression. S Lathuilière, P Mesejo, X Alameda-Pineda, R Horaud, IEEE Transactions On Pattern Analysis And Machine Intelligence. 42Lathuilière, S., Mesejo, P., Alameda-Pineda, X. & Ho- raud, R. A Comprehensive Analysis of Deep Regression. IEEE Transactions On Pattern Analysis And Machine Intelligence. 42, 2065-2081 (2020)

Detecting Objects as Paired Keypoints. H Law, J Deng, Cornernet, International Journal Of Computer Vision. 128Law, H. & Deng, J. CornerNet: Detecting Objects as Paired Keypoints. International Journal Of Computer Vision. 128, 642-656 (2020)

Deep learning. Y Lecun, Y Bengio, G Hinton, Nature. 521Lecun, Y., Bengio, Y. & Hinton, G. Deep learning. Nature. 521, 436-444 (2015)

Deep learning for remote sensing image classification: A survey. Y Li, H Zhang, X Xue, Y Jiang, Q Shen, Wiley Interdisciplinary Reviews: Data Mining And Knowledge Discovery. 8Li, Y., Zhang, H., Xue, X., Jiang, Y. & Shen, Q. Deep learning for remote sensing image classification: A sur- vey. Wiley Interdisciplinary Reviews: Data Mining And Knowledge Discovery. 8, 1-17 (2018)

Deep learning for hyperspectral image classification: An overview. S Li, W Song, L Fang, Y Chen, P Ghamisi, J Benediktsson, IEEE Transactions On Geoscience And Remote Sensing. 57Li, S., Song, W., Fang, L., Chen, Y., Ghamisi, P. & Benediktsson, J. Deep learning for hyperspectral image classification: An overview. IEEE Transactions On Geo- science And Remote Sensing. 57, 6690-6709 (2019)

Road extraction from unmanned aerial vehicle remote sensing images based on improved neural networks. Y Li, B Peng, L He, K Fan, Z Li, L Tong, Sensors (Switzerland). 19Li, Y., Peng, B., He, L., Fan, K., Li, Z. & Tong, L. Road extraction from unmanned aerial vehicle remote sens- ing images based on improved neural networks. Sensors (Switzerland). 19 (2019)

Rotating machinery fault diagnosis based on convolutional neural network and infrared thermal imaging. Y Li, X Du, F Wan, X Wang, H Yu, Chinese Journal Of Aeronautics. 33LI, Y., DU, X., WAN, F., WANG, X. & YU, H. Rotating machinery fault diagnosis based on convolutional neural network and infrared thermal imaging. Chinese Journal Of Aeronautics. 33, 427-438 (2020)

Unsupervised domain adaptation for in-field cotton boll status identification. Computers And Electronics In Agriculture. Y Li, Z Cao, H Lu, W Xu, 178105745Li, Y., Cao, Z., Lu, H. & Xu, W. Unsupervised do- main adaptation for in-field cotton boll status identifi- cation. Computers And Electronics In Agriculture. 178 pp. 105745 (2020)

DLA-MatchNet for Few-Shot Remote Sensing Image Scene Classification. L Li, J Han, X Yao, G Cheng, L Guo, IEEE Transactions On Geoscience And Remote Sensing. pp. Li, L., Han, J., Yao, X., Cheng, G. & Guo, L. DLA- MatchNet for Few-Shot Remote Sensing Image Scene Classification. IEEE Transactions On Geoscience And Remote Sensing. pp. 1-10 (2020)

Linear Versus Nonlinear PCA for the Classification of Hyperspectral Data Based on the Extended Morphological Profiles. G Licciardi, P Marpu, J Chanussot, J Benediktsson, IEEE Geoscience And Remote Sensing Letters. 9Licciardi, G., Marpu, P., Chanussot, J. & Benediktsson, J. Linear Versus Nonlinear PCA for the Classification of Hyperspectral Data Based on the Extended Morpho- logical Profiles. IEEE Geoscience And Remote Sensing Letters. 9, 447-451 (2012)

Feature-Attentioned Object Detection in Remote Sensing Imagery. C Li, C Xu, Z Cui, D Wang, T Zhang, J Yang, IEEE International Conference On Image Processing (ICIP). Li, C., Xu, C., Cui, Z., Wang, D., Zhang, T. & Yang, J. Feature-Attentioned Object Detection in Remote Sensing Imagery. 2019 IEEE International Conference On Image Processing (ICIP). pp. 3886-3890 (2019)

cite arxiv:1405.0312Comment: 1) updated annotation pipeline description and figures; 2) added new section describing datasets splits. T Lin, M Maire, S Belongie, L Bourdev, R Girshick, J Hays, P Perona, D Ramanan, C Zitnick, P Dollár, Microsoft, Coco, Common Objects in Context. 3updated author listLin, T., Maire, M., Belongie, S., Bourdev, L., Gir- shick, R., Hays, J., Perona, P., Ramanan, D., Zit- nick, C. & Dollár, P. Microsoft COCO: Common Ob- jects in Context. (2014), http://arxiv.org/abs/1405.0312, cite arxiv:1405.0312Comment: 1) updated annotation pipeline description and figures; 2) added new section describing datasets splits; 3) updated author list

Unsupervised Representation Learning for Remote Sensing Image Classification. D Lin, K Fu, Y Wang, G Xu, X Sun, Gans, IEEE Geoscience And Remote Sensing Letters. 14Lin, D., Fu, K., Wang, Y., Xu, G. & Sun, X. MARTA GANs: Unsupervised Representation Learning for Re- mote Sensing Image Classification. IEEE Geoscience And Remote Sensing Letters. 14, 2092-2096 (2017)

J Lin, W Chen, Y Lin, J Cohn, C Gan, S Han, Mcunet, ArXiv:2007.10319Tiny deep learning on iot devices. ArXiv PreprintLin, J., Chen, W., Lin, Y., Cohn, J., Gan, C. & Han, S. Mcunet: Tiny deep learning on iot devices. ArXiv Preprint ArXiv:2007.10319. (2020)

RADet: Refine Feature Pyramid Network and Multi-Layer Attention Network for Arbitrary-Oriented Object Detection of Remote Sensing Images. Y Li, Q Huang, X Pei, L Jiao, R Shang, Remote Sensing. 12Li, Y., Huang, Q., Pei, X., Jiao, L. & Shang, R. RADet: Refine Feature Pyramid Network and Multi-Layer At- tention Network for Arbitrary-Oriented Object Detection of Remote Sensing Images. Remote Sensing. 12 (2020), https://www.mdpi.com/2072-4292/12/3/389

Deep Learning for Generic Object Detection: A Survey. L Liu, W Ouyang, X Wang, W Fieguth, J Chen, X Liu, M Pietikäinen, International Journal Of Computer Vision. Liu, L., Ouyang, W., Wang, X., Fieguth, W., Chen, J., Liu, X. & Pietikäinen, M. Deep Learning for Generic Object Detection: A Survey. International Journal Of Computer Vision. pp. 261-318 (2019)

A MultiKernel Domain Adaptation Method for Unsupervised Transfer Learning on Cross-Source and Cross-Region Remote Sensing Data Classification. W Liu, R Qin, IEEE Transactions On Geoscience And Remote Sensing. 58Liu, W. & Qin, R. A MultiKernel Domain Adaptation Method for Unsupervised Transfer Learning on Cross- Source and Cross-Region Remote Sensing Data Classifi- cation. IEEE Transactions On Geoscience And Remote Sensing. 58, 4279-4289 (2020)

Deep learning in remote sensing applications: A metaanalysis and review. ISPRS Journal Of Photogrammetry And Remote Sensing. L Ma, Y Liu, X Zhang, Y Ye, G Yin, B Johnson, 152Ma, L., Liu, Y., Zhang, X., Ye, Y., Yin, G. & Johnson, B. Deep learning in remote sensing applications: A meta- analysis and review. ISPRS Journal Of Photogrammetry And Remote Sensing. 152 pp. 166 -177 (2019)

Image Matching from Handcrafted to Deep Features: A Survey. J Ma, X Jiang, A Fan, J Jiang, J Yan, 10.1007/s11263-020-01359-2International Journal Of Computer Vision. 129Ma, J., Jiang, X., Fan, A., Jiang, J. & Yan, J. Image Matching from Handcrafted to Deep Features: A Survey. International Journal Of Computer Vision. 129, 23-79 (2021,1), https://doi.org/10.1007/s11263-020-01359-2

Breast Cancer Detection Using Infrared Thermal Imaging and a Deep Learning Model. S Mambou, P Maresova, O Krejcar, A Selamat, K Kuca, Sensors. 18Mambou, S., Maresova, P., Krejcar, O., Selamat, A. & Kuca, K. Breast Cancer Detection Using Infrared Ther- mal Imaging and a Deep Learning Model. Sensors. 18 (2018), https://www.mdpi.com/1424-8220/18/9/2799

K He, G Gkioxari, P Dollár, R Girshick, R-Cnn Mask, IEEE International Conference On Computer Vision (ICCV). He, K., Gkioxari, G., Dollár, P. & Girshick, R. Mask R- CNN. 2017 IEEE International Conference On Computer Vision (ICCV). pp. 2980-2988 (2017)

Kehtarnavaz, N. & Terzopoulos, D. Image Segmentation Using Deep Learning: A Survey. S Minaee, Y Boykov, F Porikli, A Plaza, Minaee, S., Boykov, Y., Porikli, F., Plaza, A., Kehtar- navaz, N. & Terzopoulos, D. Image Segmentation Using Deep Learning: A Survey. (2020)

Survey on optimized implementation of deep learning models on the NVIDIA Jetson platform. S Mittal, Journal Of Systems Architecture. Mittal, S. A Survey on optimized implementation of deep learning models on the NVIDIA Jetson platform. Journal Of Systems Architecture. 97 pp. 428-442 (2019)

A Novel Deep Learning Method to Identify Single Tree Species in UAV-Based Hyperspectral Images. G Miyoshi, M Arruda, L Osco, J Marcato Junior, D Gonçalves, N Imai, A Tommaselli, E Honkavaara, W Gonçalves, Remote Sensing. 12Miyoshi, G., Arruda, M., Osco, L., Marcato Ju- nior, J., Gonçalves, D., Imai, N., Tommaselli, A., Honkavaara, E. & Gonçalves, W. A Novel Deep Learn- ing Method to Identify Single Tree Species in UAV- Based Hyperspectral Images. Remote Sensing. 12 (2020), https://www.mdpi.com/2072-4292/12/8/1294

Topology of deep neural networks. G Naitzat, A Zhitnikov, L Lim, Journal Of Machine Learning Research. 21Naitzat, G., Zhitnikov, A. & Lim, L. Topology of deep neural networks. Journal Of Machine Learning Research. 21 pp. 1-40 (2020)

Nas-fpn: Learning scalable feature pyramid architecture for object detection. G Ghiasi, T Lin, Q Le, Proceedings Of The IEEE Conference On Computer Vision And Pattern Recognition. Of The IEEE Conference On Computer Vision And Pattern RecognitionGhiasi, G., Lin, T. & Le, Q. Nas-fpn: Learning scalable feature pyramid architecture for object detection. Pro- ceedings Of The IEEE Conference On Computer Vision And Pattern Recognition. pp. 7036-7045 (2019)

Crop yield prediction using multitemporal UAV data and spatiotemporal deep learning models. P Nevavuori, N Narra, P Linna, T Lipping, Remote Sensing. 12Nevavuori, P., Narra, N., Linna, P. & Lipping, T. Crop yield prediction using multitemporal UAV data and spatio- temporal deep learning models. Remote Sensing. 12, 1-18 (2020)

Pölönen, I. & Honkavaara, E. ree Species Classification of Drone Hyperspectral and RGB Imagery with Deep Learning Convolutional Neural Networks. S Nezami, E Khoramshahi, O Nevalainen, Remote Sensing. 12Nezami, S., Khoramshahi, E., Nevalainen, O., Pölönen, I. & Honkavaara, E. ree Species Classification of Drone Hy- perspectral and RGB Imagery with Deep Learning Con- volutional Neural Networks. Remote Sensing. 12 (2020)

Dynamic multicontext segmentation of remote sensing images based on convolutional networks. K Nogueira, M Dalla Mura, J Chanussot, W Schwartz, J Santos, IEEE Transactions On Geoscience And Remote Sensing. 57Nogueira, K., Dalla Mura, M., Chanussot, J., Schwartz, W. & Dos Santos, J. Dynamic multicontext segmentation of remote sensing images based on convolutional net- works. IEEE Transactions On Geoscience And Remote Sensing. 57, 7503-7520 (2019)

Facing erosion identification in railway lines using pixel-wise deep-based approaches. K Nogueira, G Machado, P Gama, C Silva, R Balaniuk, J Santos, Remote Sensing. 12Nogueira, K., Machado, G., Gama, P., Silva, C., Balaniuk, R. & Santos, J. Facing erosion identification in railway lines using pixel-wise deep-based approaches. Remote Sensing. 12, 1-21 (2020)

Activation functions: Comparison of trends in practice and research for deep learning. C Nwankpa, W Ijomah, A Gachagan, S Marshall, ArXiv:1811.03378.ArXiv PreprintNwankpa, C., Ijomah, W., Gachagan, A. & Marshall, S. Activation functions: Comparison of trends in prac- tice and research for deep learning. ArXiv Preprint ArXiv:1811.03378. (2018)

A convolutional neural network approach for counting and geolocating citrus-trees in UAV multispectral imagery. L Osco, M Arruda, J Marcato Junior, N Silva, A Ramos, É Moryia, N Imai, D Pereira, J Creste, E Matsubara, J Li, W Gonçalves, 10.1016/j.isprsjprs.2019.12.010ISPRS Journal Of Photogrammetry And Remote Sensing. 160Osco, L., Arruda, M., Marcato Junior, J., Silva, N., Ramos, A., Moryia, É., Imai, N., Pereira, D., Creste, J., Matsubara, E., Li, J. & Gonçalves, W. A convolutional neural network approach for counting and geolocating citrus-trees in UAV multispectral imagery. ISPRS Journal Of Photogrammetry And Remote Sensing. 160, 97-106 (2020), https://doi.org/10.1016/j.isprsjprs.2019.12.010

Semantic segmentation of citrus-orchard using deep neural networks and multispectral UAV-based imagery. L Osco, K Nogueira, A Marques Ramos, M Faita Pinheiro, D Furuya, W Gonçalves, L Castro Jorge, J Marcato Junior, J Santos, Precision Agriculture.Osco, L., Nogueira, K., Marques Ramos, A., Faita Pin- heiro, M., Furuya, D., Gonçalves, W., Castro Jorge, L., Marcato Junior, J. & Santos, J. Semantic segmentation of citrus-orchard using deep neural networks and multispec- tral UAV-based imagery. Precision Agriculture. (2021)

. L Osco, M Arruda, D Gonçalves, A Dias, J Batistoti, M Souza, F Gomes, A Ramos, L Castro Jorge, V Liesenberg, J Li, L Ma, J Junior, W Gonçalves, Cnn, Approach to Simultaneously Count Plants and Detect Plantation-Rows from UAV Imagery. Osco, L., Arruda, M., Gonçalves, D., Dias, A., Batistoti, J., Souza, M., Gomes, F., Ramos, A., Castro Jorge, L., Liesenberg, V., Li, J., Ma, L., Junior, J. & Gonçalves, W. A CNN Approach to Simultaneously Count Plants and Detect Plantation-Rows from UAV Imagery. (2020)

Probabilistic Anchor Assignment with IoU Prediction for Object Detection. European Conference On Computer Vision (ECCV). K Kim, H Lee, 22Kim, K. & Lee, H. Probabilistic Anchor Assignment with IoU Prediction for Object Detection. European Confer- ence On Computer Vision (ECCV). pp. 22 (2020)

Path Aggregation Network for Instance Segmentation. S Liu, L Qi, H Qin, J Shi, J Jia, Proceedings Of IEEE Conference On Computer Vision And Pattern Recognition (CVPR). Of IEEE Conference On Computer Vision And Pattern Recognition (CVPR)11Liu, S., Qi, L., Qin, H., Shi, J. & Jia, J. Path Aggre- gation Network for Instance Segmentation. Proceedings Of IEEE Conference On Computer Vision And Pattern Recognition (CVPR). pp. 11 (2018)

Towards balanced learning for object detection. J Pang, K Chen, J Shi, H Feng, W Ouyang, D Lin, Libra R-Cnn, Proceedings Of The IEEE Computer Society Conference On Computer Vision And Pattern Recognition. Of The IEEE Computer Society Conference On Computer Vision And Pattern RecognitionPang, J., Chen, K., Shi, J., Feng, H., Ouyang, W. & Lin, D. Libra R-CNN: Towards balanced learning for object detection. Proceedings Of The IEEE Computer Society Conference On Computer Vision And Pattern Recognition. 2019-June pp. 821-830 (2019)

A Kirillov, K He, R Girshick, C Rother, P Panoptic Dollár, Segmentation, IEEE/CVF Conference On Computer Vision And Pattern Recognition (CVPR). Kirillov, A., He, K., Girshick, R., Rother, C. & Dollár, P. Panoptic Segmentation. 2019 IEEE/CVF Conference On Computer Vision And Pattern Recognition (CVPR). pp. 9396-9405 (2019)

Deep learning classifiers for hyperspectral imaging: A review. ISPRS Journal Of Photogrammetry And Remote Sensing. M Paoletti, J Haut, J Plaza, A Plaza, 10.1016/j.isprsjprs.2019.09.006158Paoletti, M., Haut, J., Plaza, J. & Plaza, A. Deep learning classifiers for hyperspectral imag- ing: A review. ISPRS Journal Of Photogramme- try And Remote Sensing. 158, 279-317 (2019), https://doi.org/10.1016/j.isprsjprs.2019.09.006

Discrepancy Analysis for Detecting Candidate Parcels Requiring Update of Land Category in Cadastral Map Using Hyperspectral UAV Images: A Case Study in Jeonju. S Park, A Song, South Korea. Remote Sensing. 12Park, S. & Song, A. Discrepancy Analysis for Detecting Candidate Parcels Requiring Update of Land Category in Cadastral Map Using Hyperspectral UAV Images: A Case Study in Jeonju, South Korea. Remote Sensing. 12 (2020), https://www.mdpi.com/2072-4292/12/3/354

Do deep features generalize from everyday objects to remote sensing and aerial scenes domains. O Penatti, K Nogueira, J Santos, IEEE Computer Society Conference On Computer Vision And Pattern Recognition Workshops. 2015-October pp. Penatti, O., Nogueira, K. & Dos Santos, J. Do deep fea- tures generalize from everyday objects to remote sensing and aerial scenes domains?. IEEE Computer Society Con- ference On Computer Vision And Pattern Recognition Workshops. 2015-October pp. 44-51 (2015)

Hyperspectral image analysis using deep learning -A review. H Petersson, D Gustafsson, D Bergström, 6th International Conference On Image Processing Theory, Tools And Applications. 2016Petersson, H., Gustafsson, D. & Bergström, D. Hyper- spectral image analysis using deep learning -A review. 2016 6th International Conference On Image Processing Theory, Tools And Applications, IPTA 2016. (2017)

Prime sample attention in object detection. Y Cao, K Chen, C Loy, D Lin, IEEE Conference On Computer Vision And Pattern Recognition. 9Cao, Y., Chen, K., Loy, C. & Lin, D. Prime sample atten- tion in object detection. IEEE Conference On Computer Vision And Pattern Recognition. pp. 9 (2020)

Image Segmentation As Rendering. A Kirillov, Y Wu, K He, R Girshick, Pointrend, Proceedings Of The IEEE/CVF Conference On Computer Vision And Pattern Recognition (CVPR). Of The IEEE/CVF Conference On Computer Vision And Pattern Recognition (CVPR)pp. 10 (2020,6Kirillov, A., Wu, Y., He, K. & Girshick, R. PointRend: Image Segmentation As Rendering. Proceedings Of The IEEE/CVF Conference On Computer Vision And Pattern Recognition (CVPR). pp. 10 (2020,6)

Towards real-time generic object detection on mobile devices. Z Qin, Z Li, Z Zhang, Y Bao, G Yu, Y Peng, J Sun, Thundernet, Proceedings Of The IEEE International Conference On Computer Vision. Of The IEEE International Conference On Computer VisionQin, Z., Li, Z., Zhang, Z., Bao, Y., Yu, G., Peng, Y. & Sun, J. ThunderNet: Towards real-time generic object detection on mobile devices. Proceedings Of The IEEE International Conference On Computer Vision. pp. 6718- 6727 (2019)

M Rastegari, V Ordonez, J Redmon, A Farhadi, Xnor-Net, Imagenet classification using binary convolutional neural networks. European Conference On Computer Vision. Rastegari, M., Ordonez, V., Redmon, J. & Farhadi, A. Xnor-net: Imagenet classification using binary convolu- tional neural networks. European Conference On Com- puter Vision. pp. 525-542 (2016)

Designing Network Design Spaces. I Radosavovic, R Kosaraju, R Girshick, K He, P Dollar, Radosavovic, I., Kosaraju, R., Girshick, R., He, K. & Dollar, P. Designing Network Design Spaces. 2020

IEEE/CVF Conference On Computer Vision And Pattern Recognition (CVPR). IEEE/CVF Conference On Computer Vision And Pattern Recognition (CVPR). pp. 10425-10433 (2020)

Res2Net: A New Multi-Scale Backbone Architecture. S Gao, M Cheng, K Zhao, X Zhang, M Yang, P Torr, IEEE Transactions On Pattern Analysis And Machine Intelligence. 43Gao, S., Cheng, M., Zhao, K., Zhang, X., Yang, M. & Torr, P. Res2Net: A New Multi-Scale Backbone Archi- tecture. IEEE Transactions On Pattern Analysis And Ma- chine Intelligence. 43, 652-662 (2021)

. H Zhang, C Wu, Z Zhang, Y Zhu, H Lin, Z Zhang, Y Sun, T He, J Mueller, R Manmatha, M Li, A Smola, Resnest, Split-Attention NetworksZhang, H., Wu, C., Zhang, Z., Zhu, Y., Lin, H., Zhang, Z., Sun, Y., He, T., Mueller, J., Manmatha, R., Li, M. & Smola, A. ResNeSt: Split-Attention Networks. (2020)

Deep Residual Learning for Image Recognition. K He, X Zhang, S Ren, J Sun, IEEE Conference On Computer Vision And Pattern Recognition (CVPR). He, K., Zhang, X., Ren, S. & Sun, J. Deep Residual Learning for Image Recognition. 2016 IEEE Conference On Computer Vision And Pattern Recognition (CVPR). pp. 770-778 (2016)

Aggregated Residual Transformations for Deep Neural Networks. S Xie, R Girshick, P Dollár, Z Tu, K He, IEEE Conference On Computer Vision And Pattern Recognition (CVPR). Xie, S., Girshick, R., Dollár, P., Tu, Z. & He, K. Ag- gregated Residual Transformations for Deep Neural Net- works. 2017 IEEE Conference On Computer Vision And Pattern Recognition (CVPR). pp. 5987-5995 (2017)

Detection of cattle using drones and convolutional neural networks. A Rivas, P Chamoso, A González-Briones, J Corchado, Sensors (Switzerland). 18Rivas, A., Chamoso, P., González-Briones, A. & Cor- chado, J. Detection of cattle using drones and convolu- tional neural networks. Sensors (Switzerland). 18, 1-15 (2018)

U-net: Convolutional networks for biomedical image segmentation. O Ronneberger, P Fischer, T Brox, Lecture Notes In Computer Science (including Subseries Lecture Notes In Artificial Intelligence And Lecture Notes In Bioinformatics). 9351Ronneberger, O., Fischer, P. & Brox, T. U-net: Convo- lutional networks for biomedical image segmentation. Lecture Notes In Computer Science (including Subseries Lecture Notes In Artificial Intelligence And Lecture Notes In Bioinformatics). 9351 pp. 234-241 (2015)

An overview of gradient descent optimization algorithms. S Ruder, Ruder, S. An overview of gradient descent optimization algorithms. (2017)

Side-Aware Boundary Localization for More Precise Object Detection. J Wang, W Zhang, Y Cao, K Chen, J Pang, T Gong, J Shi, C Loy, D Lin, European Conference On Computer Vision (ECCV). 21Wang, J., Zhang, W., Cao, Y., Chen, K., Pang, J., Gong, T., Shi, J., Loy, C. & Lin, D. Side-Aware Boundary Lo- calization for More Precise Object Detection. European Conference On Computer Vision (ECCV). pp. 21 (2020)

M Sandler, A Howard, M Zhu, A Zhmoginov, L Chen, MobileNetV2: Inverted Residuals and Linear Bottlenecks. Proceedings Of The IEEE Computer Society Conference On Computer Vision And Pattern Recognition. Sandler, M., Howard, A., Zhu, M., Zhmoginov, A. & Chen, L. MobileNetV2: Inverted Residuals and Linear Bottlenecks. Proceedings Of The IEEE Computer Society Conference On Computer Vision And Pattern Recognition. pp. 4510-4520 (2018)

Deep learning in neural networks: An overview. J Schmidhuber, Schmidhuber, J. Deep learning in neural networks: An overview. Neural Networks. 61 pp. 85 -117 (2015)

Evolution of Image Segmentation using Deep Convolutional Neural Network: A Survey. Knowledge-Based Systems. F Sultana, A Sufian, P Dutta, 106062Sultana, F., Sufian, A. & Dutta, P. Evolution of Image Seg- mentation using Deep Convolutional Neural Network: A Survey. Knowledge-Based Systems. 201-202 pp. 106062 (2020)

Kehtarnavaz, N. & Terzopoulos, D. Image Segmentation Using Deep Learning: A Survey. S Minaee, Y Boykov, F Porikli, A Plaza, Minaee, S., Boykov, Y., Porikli, F., Plaza, A., Kehtar- navaz, N. & Terzopoulos, D. Image Segmentation Using Deep Learning: A Survey. (2020)

A comprehensive and systematic look up into deep learning based object detection techniques: A review. V Sharma, R Mir, Computer Science Review. 38100301Sharma, V. & Mir, R. A comprehensive and system- atic look up into deep learning based object detection techniques: A review. Computer Science Review. 38 pp. 100301 (2020)

High-resolution satellite scene classification using a sparse coding based multiple feature combination. G Sheng, W Yang, T Xu, H Sun, International Journal Of Remote Sensing. 33Sheng, G., Yang, W., Xu, T. & Sun, H. High-resolution satellite scene classification using a sparse coding based multiple feature combination. International Journal Of Remote Sensing. 33, 2395-2412 (2012)

Deep Learning Meets Hyperspectral Image Analysis: A Multidisciplinary Review. A Signoroni, M Savardi, A Baronio, S Benini, Journal Of Imaging. 5Signoroni, A., Savardi, M., Baronio, A. & Benini, S. Deep Learning Meets Hyperspectral Image Analysis: A Multidisciplinary Review. Journal Of Imaging. 5 (2019), https://www.mdpi.com/2313-433X/5/5/52

Towards Open-Set Semantic Segmentation Of Aerial Images. Da Silva, C Nogueira, K Oliveira, H Santos, J , 2020 IEEE Latin American GRSS ISPRS Remote Sensing Conference (LAGIRS). Da Silva, C., Nogueira, K., Oliveira, H. & Santos, J. Towards Open-Set Semantic Segmentation Of Aerial Im- ages. 2020 IEEE Latin American GRSS ISPRS Remote Sensing Conference (LAGIRS). pp. 16-21 (2020)

Quantifying hail size distributions from the sky -application of drone aerial photogrammetry. Atmospheric Measurement Techniques. J Soderholm, M Kumjian, N Mccarthy, P Maldonado, M Wang, 13Soderholm, J., Kumjian, M., McCarthy, N., Maldonado, P. & Wang, M. Quantifying hail size distributions from the sky -application of drone aerial photogrammetry. At- mospheric Measurement Techniques. 13, 747-754 (2020), https://amt.copernicus.org/articles/13/747/2020/

Semantic Segmentation of High Resolution Remote Sensing Image Based on Batch-Attention Mechanism. IGARSS 2019 -2019 IEEE International Geoscience And Remote Sensing Symposium. Y Su, Y Wu, M Wang, F Wang, J Cheng, Su, Y., Wu, Y., Wang, M., Wang, F. & Cheng, J. Semantic Segmentation of High Resolution Remote Sensing Image Based on Batch-Attention Mechanism. IGARSS 2019 - 2019 IEEE International Geoscience And Remote Sensing Symposium. pp. 3856-3859 (2019)

FSSCaps-DetCountNet: fuzzy soft sets and CapsNet-based detection and counting network for monitoring animals from aerial images. D Sundaram, A Loganathan, 10.1117/1.JRS.14.026521Journal Of Applied Remote Sensing. 14Sundaram, D. & Loganathan, A. FSSCaps-DetCountNet: fuzzy soft sets and CapsNet-based detection and count- ing network for monitoring animals from aerial images. Journal Of Applied Remote Sensing. 14, 1 -30 (2020), https://doi.org/10.1117/1.JRS.14.026521

Going deeper with convolutions. C Szegedy, W Liu, Y Jia, P Sermanet, S Reed, D Anguelov, D Erhan, V Vanhoucke, A Rabinovich, Proceedings Of The IEEE Conference On Computer Vision And Pattern Recognition. Of The IEEE Conference On Computer Vision And Pattern RecognitionSzegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V. & Rabinovich, A. Going deeper with convolutions. Proceedings Of The IEEE Conference On Computer Vision And Pattern Recognition. pp. 1-9 (2015)

A survey on deep transfer learning. International Conference On Artificial Neural Networks. C Tan, F Sun, T Kong, W Zhang, C Yang, C Liu, Tan, C., Sun, F., Kong, T., Zhang, W., Yang, C. & Liu, C. A survey on deep transfer learning. International Confer- ence On Artificial Neural Networks. pp. 270-279 (2018)

Automatic Recognition of Soybean Leaf Diseases Using UAV Images and Deep Convolutional Neural Networks. E Tetila, B Machado, G Menezes, A Da Silva Oliveira, M Alvarez, W Amorim, N De Souza Belete, G Da Silva, H Pistori, IEEE Geoscience And Remote Sensing Letters. 17Tetila, E., Machado, B., Menezes, G., Da Silva Oliveira, A., Alvarez, M., Amorim, W., De Souza Belete, N., Da Silva, G. & Pistori, H. Automatic Recognition of Soy- bean Leaf Diseases Using UAV Images and Deep Convo- lutional Neural Networks. IEEE Geoscience And Remote Sensing Letters. 17, 903-907 (2020)

A Survey of Semantic Segmentation. M Thoma, Thoma, M. A Survey of Semantic Segmentation. (2016)

. Y Tian, D Krishnan, P Isola, Contrastive Multiview, Coding, CoRR. abs/1906.05849Tian, Y., Krishnan, D. & Isola, P. Contrastive Multiview Coding. CoRR. abs/1906.05849 (2019), http://arxiv.org/abs/1906.05849

Apple detection during different growth stages in orchards using the improved YOLO-V3 model. Y Tian, G Yang, Z Wang, H Wang, E Li, Z Liang, Computers And Electronics In Agriculture. 157Tian, Y., Yang, G., Wang, Z., Wang, H., Li, E. & Liang, Z. Apple detection during different growth stages in orchards using the improved YOLO-V3 model. Computers And Electronics In Agriculture. 157, 417-426 (2019)

Applying fully convolutional architectures for semantic segmentation of a single tree species in urban environment on high resolution UAV optical imagery. D Torres, R Feitosa, P Happ, L La Rosa, J Junior, J Martins, P Bressan, W Gonçalves, V Liesenberg, Sensors (Switzerland). 20Torres, D., Feitosa, R., Happ, P., La Rosa, L., Junior, J., Martins, J., Bressan, P., Gonçalves, W. & Liesenberg, V. Applying fully convolutional architectures for semantic segmentation of a single tree species in urban environ- ment on high resolution UAV optical imagery. Sensors (Switzerland). 20, 1-20 (2020)

Training data-efficient image transformers & distillation through attention. H Touvron, M Cord, M Douze, F Massa, A Sablayrolles, H Jégou, Touvron, H., Cord, M., Douze, M., Massa, F., Sablay- rolles, A. & Jégou, H. Training data-efficient image trans- formers & distillation through attention. (2020)

Scale-Aware Trident Networks for Object Detection. Y Li, Y Chen, N Wang, Z Zhang, IEEE/CVF International Conference On Computer Vision (ICCV). Li, Y., Chen, Y., Wang, N. & Zhang, Z. Scale-Aware Trident Networks for Object Detection. 2019 IEEE/CVF International Conference On Computer Vision (ICCV). pp. 6053-6062 (2019)

Survey of deep-learning approaches for remote sensing observation enhancement. G Tsagkatakis, A Aidini, K Fotiadou, M Giannopoulos, A Pentari, P Tsakalides, Sensors (Switzerland). 19Tsagkatakis, G., Aidini, A., Fotiadou, K., Giannopoulos, M., Pentari, A. & Tsakalides, P. Survey of deep-learning approaches for remote sensing observation enhancement. Sensors (Switzerland). 19, 1-39 (2019)

Domain Adaptation for the Classification of Remote Sensing Data: An Overview of Recent Advances. IEEE Geoscience And Remote Sensing Magazine. D Tuia, C Persello, L Bruzzone, 4Tuia, D., Persello, C. & Bruzzone, L. Domain Adapta- tion for the Classification of Remote Sensing Data: An Overview of Recent Advances. IEEE Geoscience And Remote Sensing Magazine. 4, 41-57 (2016)

Computer aided diagnosis of obesity based on thermal imaging using various convolutional neural networks. Biomedical Signal Processing And Control. U , S , K , S , 63102233U, S., K., P. & K, S. Computer aided diagnosis of obesity based on thermal imaging using various convolutional neural networks. Biomedical Signal Processing And Con- trol. 63 pp. 102233 (2021)

CNN based hyperspectral image classification using unsupervised band selection and structure-preserving spatial features. R Vaddi, P Manoharan, Infrared Physics & Technology. 110103457Vaddi, R. & Manoharan, P. CNN based hyperspectral image classification using unsupervised band selection and structure-preserving spatial features. Infrared Physics & Technology. 110 pp. 103457 (2020)

A spatially explicit deep learning neural network model for the prediction of landslide susceptibility. D Dao, A Jaafari, M Bayat, D Mafi-Gholami, C Qi, H Moayedi, T Phong, H Ly, T Le, P Trinh, C Luu, N Quoc, B Thanh, B Pham, CATENA. 188104451Dao, D., Jaafari, A., Bayat, M., Mafi-Gholami, D., Qi, C., Moayedi, H., Phong, T., Ly, H., Le, T., Trinh, P., Luu, C., Quoc, N., Thanh, B. & Pham, B. A spatially explicit deep learning neural network model for the prediction of landslide susceptibility. CATENA. 188 pp. 104451 (2020)

Var-ifocalNet: An IoU-aware Dense Object Detector. H Zhang, Y Wang, F Dayoub, N Sünderhauf, ArXiv:2008.13367ArXiv PreprintZhang, H., Wang, Y., Dayoub, F. & Sünderhauf, N. Var- ifocalNet: An IoU-aware Dense Object Detector. ArXiv Preprint ArXiv:2008.13367. (2020)

Very Deep Convolutional Networks for Large-Scale Image Recognition. K Simonyan, A Zisserman, International Conference On Learning Representations. 14Simonyan, K. & Zisserman, A. Very Deep Convolutional Networks for Large-Scale Image Recognition. Interna- tional Conference On Learning Representations. pp. 14 (2015)

Estimating land surface temperature from satellite passive microwave observations with the traditional neural network, deep belief network, and convolutional neural network. S Wang, J Zhou, T Lei, H Wu, X Zhang, J Ma, H Zhong, Remote Sensing. 12Wang, S., Zhou, J., Lei, T., Wu, H., Zhang, X., Ma, J. & Zhong, H. Estimating land surface temperature from satel- lite passive microwave observations with the traditional neural network, deep belief network, and convolutional neural network. Remote Sensing. 12 (2020)

Boundary-Aware Multitask Learning for Remote Sensing Imagery. Y Wang, W Ding, R Zhang, H Li, IEEE Journal Of Selected Topics In Applied Earth Observations And Remote Sensing. 14Wang, Y., Ding, W., Zhang, R. & Li, H. Boundary-Aware Multitask Learning for Remote Sensing Imagery. IEEE Journal Of Selected Topics In Applied Earth Observations And Remote Sensing. 14 pp. 951-963 (2021)

Recent advances in deep learning for object detection. X Wu, D Sahoo, S Hoi, Neurocomputing. 396Wu, X., Sahoo, D. & Hoi, S. Recent advances in deep learning for object detection. Neurocomputing. 396 pp. 39 -64 (2020)

Deep learning of sea surface temperature patterns to identify ocean extremes. J Xavier Prochaska, P Cornillon, D Reiman, Remote Sensing. 13Xavier Prochaska, J., Cornillon, P. & Reiman, D. Deep learning of sea surface temperature patterns to identify ocean extremes. Remote Sensing. 13, 1-18 (2021)

DOTA: A Large-Scale Dataset for Object Detection in Aerial Images. G Xia, X Bai, J Ding, Z Zhu, S Belongie, J Luo, M Datcu, M Pelillo, L Zhang, Proceedings Of The IEEE Computer Society Conference On Computer Vision And Pattern Recognition. Of The IEEE Computer Society Conference On Computer Vision And Pattern RecognitionXia, G., Bai, X., Ding, J., Zhu, Z., Belongie, S., Luo, J., Datcu, M., Pelillo, M. & Zhang, L. DOTA: A Large- Scale Dataset for Object Detection in Aerial Images. Pro- ceedings Of The IEEE Computer Society Conference On Computer Vision And Pattern Recognition. pp. 3974-3983 (2018)

Attention-Mechanism-Containing Neural Networks for High-Resolution Remote Sensing Image Classification. Remote Sensing. R Xu, Y Tao, Z Lu, Y Zhong, 10Xu, R., Tao, Y., Lu, Z. & Zhong, Y. Attention-Mechanism- Containing Neural Networks for High-Resolution Re- mote Sensing Image Classification. Remote Sensing. 10 (2018), https://www.mdpi.com/2072-4292/10/10/1602

T Yang, A Howard, B Chen, X Zhang, A Go, M Sandler, V Sze, H Adam, Netadapt, Platform-aware neural network adaptation for mobile applications. Proceedings Of The European Conference On Computer Vision (ECCV). Yang, T., Howard, A., Chen, B., Zhang, X., Go, A., San- dler, M., Sze, V. & Adam, H. Netadapt: Platform-aware neural network adaptation for mobile applications. Pro- ceedings Of The European Conference On Computer Vi- sion (ECCV). pp. 285-300 (2018)

A review on image classification of remote sensing using deep learning. C Yao, X Luo, Y Zhao, W Zeng, X Chen, 3rd IEEE International Conference On Computer And Communications. Yao, C., Luo, X., Zhao, Y., Zeng, W. & Chen, X. A review on image classification of remote sensing using deep learning. 2017 3rd IEEE International Conference On Computer And Communications, ICCC 2017. 2018- Janua pp. 1947-1955 (2018)

Deep learning in environmental remote sensing: Achievements and challenges. Remote Sensing Of Environment. Q Yuan, H Shen, T Li, Z Li, S Li, Y Jiang, H Xu, W Tan, Q Yang, J Wang, J Gao, L Zhang, 10.1016/j.rse.2020.111716241111716Yuan, Q., Shen, H., Li, T., Li, Z., Li, S., Jiang, Y., Xu, H., Tan, W., Yang, Q., Wang, J., Gao, J. & Zhang, L. Deep learning in environmental remote sensing: Achievements and challenges. Remote Sensing Of Environment. 241, 111716 (2020), https://doi.org/10.1016/j.rse.2020.111716

A review of deep learning methods for semantic segmentation of remote sensing imagery. Expert Systems With Applications. X Yuan, J Shi, L Gu, 10.1016/j.eswa.2020.114417169114417Yuan, X., Shi, J. & Gu, L. A review of deep learning methods for semantic segmentation of remote sensing imagery. Expert Systems With Applications. 169, 114417 (2021), https://doi.org/10.1016/j.eswa.2020.114417

Deep learning for remote sensing data: A technical tutorial on the state of the art. IEEE Geoscience And Remote Sensing Magazine. L Zhang, L Zhang, B Du, 4Zhang, L., Zhang, L. & Du, B. Deep learning for remote sensing data: A technical tutorial on the state of the art. IEEE Geoscience And Remote Sensing Magazine. 4, 22- 40 (2016)

Real-time traffic analysis using deep learning techniques and UAV based video. H Zhang, M Liptrott, N Bessis, J Cheng, 16th IEEE International Conference On Advanced Video And Signal Based Surveillance, AVSS 2019. Zhang, H., Liptrott, M., Bessis, N. & Cheng, J. Real-time traffic analysis using deep learning techniques and UAV based video. 2019 16th IEEE International Conference On Advanced Video And Signal Based Surveillance, AVSS 2019. pp. 1-5 (2019)

Forest Fire Susceptibility Modeling Using a Convolutional Neural Network for Yunnan Province of China. G Zhang, M Wang, K Liu, 10.1007/s13753-019-00233-1International Journal Of Disaster Risk Science. 10Zhang, G., Wang, M. & Liu, K. Forest Fire Suscep- tibility Modeling Using a Convolutional Neural Net- work for Yunnan Province of China. International Jour- nal Of Disaster Risk Science. 10, 386-403 (2019), https://doi.org/10.1007/s13753-019-00233-1

How Well Do Deep Learning-Based Methods for Land Cover Classification and Object Detection Perform on High Resolution Remote Sensing Imagery?. X Zhang, L Han, L Han, L Zhu, Remote Sensing. 12Zhang, X., Han, L., Han, L. & Zhu, L. How Well Do Deep Learning-Based Methods for Land Cover Classifi- cation and Object Detection Perform on High Resolution Remote Sensing Imagery?. Remote Sensing. 12 (2020), https://www.mdpi.com/2072-4292/12/3/417

ICENET: A semantic segmentation deep network for river ice by fusing positional and channelwise attentive features. X Zhang, J Jin, Z Lan, C Li, M Fan, Y Wang, X Yu, Y Zhang, Remote Sensing. 12Zhang, X., Jin, J., Lan, Z., Li, C., Fan, M., Wang, Y., Yu, X. & Zhang, Y. ICENET: A semantic segmentation deep network for river ice by fusing positional and channel- wise attentive features. Remote Sensing. 12, 1-22 (2020)

Identifying and mapping individual plants in a highly diverse high-elevation ecosystem using UAV imagery and deep learning. C Zhang, P Atkinson, C George, Z Wen, M Diazgranados, F Gerard, 10.1016/j.isprsjprs.2020.09.025ISPRS Journal Of Photogrammetry And Remote Sensing. 169Zhang, C., Atkinson, P., George, C., Wen, Z., Diazgrana- dos, M. & Gerard, F. Identifying and mapping individual plants in a highly diverse high-elevation ecosystem using UAV imagery and deep learning. ISPRS Journal Of Pho- togrammetry And Remote Sensing. 169, 280-291 (2020), https://doi.org/10.1016/j.isprsjprs.2020.09.025

Feature significancebased multibag-of-visual-words model for remote sensing image scene classification. L Zhao, P Tang, L Huo, 10.1117/1.JRS.10.035004Journal Of Applied Remote Sensing. 10Zhao, L., Tang, P. & Huo, L. Feature significance- based multibag-of-visual-words model for re- mote sensing image scene classification. Journal Of Applied Remote Sensing. 10, 1 -21 (2016), https://doi.org/10.1117/1.JRS.10.035004

Dirichletderived multiple topic scene classification model for high spatial resolution remote sensing imagery. B Zhao, Y Zhong, G Xia, L Zhang, IEEE Transactions On Geoscience And Remote Sensing. 54Zhao, B., Zhong, Y., Xia, G. & Zhang, L. Dirichlet- derived multiple topic scene classification model for high spatial resolution remote sensing imagery. IEEE Transac- tions On Geoscience And Remote Sensing. 54, 2108-2123 (2016)

Pyramid Scene Parsing Network. H Zhao, J Shi, X Qi, X Wang, J Jia, Zhao, H., Shi, J., Qi, X., Wang, X. & Jia, J. Pyramid Scene Parsing Network. (2017)

Object Detection With Deep Learning: A Review. Z Zhao, P Zheng, S Xu, X Wu, IEEE Transactions On Neural Networks And Learning Systems. 3011Zhao, Z., Zheng, P., Xu, S. & Wu, X. Object Detection With Deep Learning: A Review. IEEE Transactions On Neural Networks And Learning Systems. 30, 3212-3232 (2019,11)

A Review of Remote Sensing Image Object Detection Algorithms Based on Deep Learning. Z Zheng, L Lei, H Sun, G Kuang, IEEE 5th International Conference On Image, Vision And Computing, ICIVC 2020. Zheng, Z., Lei, L., Sun, H. & Kuang, G. A Review of Re- mote Sensing Image Object Detection Algorithms Based on Deep Learning. 2020 IEEE 5th International Confer- ence On Image, Vision And Computing, ICIVC 2020. pp. 34-43 (2020)

Robust Building Extraction for High Spatial Resolution Remote Sensing Images with Self-Attention Network. D Zhou, G Wang, G He, T Long, R Yin, Z Zhang, S Chen, B Luo, Sensors. 20Zhou, D., Wang, G., He, G., Long, T., Yin, R., Zhang, Z., Chen, S. & Luo, B. Robust Building Extrac- tion for High Spatial Resolution Remote Sensing Im- ages with Self-Attention Network. Sensors. 20 (2020), https://www.mdpi.com/1424-8220/20/24/7241

Deep Learning in Remote Sensing: A Comprehensive Review and List of Resources. IEEE Geoscience And Remote Sensing Magazine. X Zhu, D Tuia, L Mou, G Xia, L Zhang, F Xu, F Fraundorfer, 5Zhu, X., Tuia, D., Mou, L., Xia, G., Zhang, L., Xu, F. & Fraundorfer, F. Deep Learning in Remote Sensing: A Comprehensive Review and List of Resources. IEEE Geo- science And Remote Sensing Magazine. 5, 8-36 (2017)

Feature selective anchorfree module for single-shot object detection. C Zhu, Y He, M Savvides, Proceedings Of The IEEE Computer Society Conference On Computer Vision And Pattern Recognition. Of The IEEE Computer Society Conference On Computer Vision And Pattern RecognitionZhu, C., He, Y. & Savvides, M. Feature selective anchor- free module for single-shot object detection. Proceedings Of The IEEE Computer Society Conference On Computer Vision And Pattern Recognition. 2019-June pp. 840-849 (2019)

A comprehensive survey on transfer learning. F Zhuang, Z Qi, K Duan, D Xi, Y Zhu, H Zhu, H Xiong, Q He, Proceedings Of The IEEE. 109Zhuang, F., Qi, Z., Duan, K., Xi, D., Zhu, Y., Zhu, H., Xiong, H. & He, Q. A comprehensive survey on transfer learning. Proceedings Of The IEEE. 109, 43-76 (2020)

Attention-Based Deep Feature Fusion for the Scene Classification of High-Resolution Remote Sensing Images. Remote Sensing. R Zhu, L Yan, N Mo, Y Liu, 11Zhu, R., Yan, L., Mo, N. & Liu, Y. Attention-Based Deep Feature Fusion for the Scene Classification of High- Resolution Remote Sensing Images. Remote Sensing. 11 (2019), https://www.mdpi.com/2072-4292/11/17/1996

Deep Learning Based Feature Selection for Remote Sensing Scene Classification. Q Zou, L Ni, T Zhang, Q Wang, IEEE Geoscience And Remote Sensing Letters. 12Zou, Q., Ni, L., Zhang, T. & Wang, Q. Deep Learning Based Feature Selection for Remote Sensing Scene Clas- sification. IEEE Geoscience And Remote Sensing Letters. 12, 2321-2325 (2015)

Remote Sensing Scene Classification. Q Zou, L Ni, T Zhang, Q Wang, IEEE Transactions On Geoscience And Remote Sensing Letters. 12Zou, Q., Ni, L., Zhang, T. & Wang, Q. Remote Sensing Scene Classification. IEEE Transactions On Geoscience And Remote Sensing Letters. 12, 2321-2325 (2015)