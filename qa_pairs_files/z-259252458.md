# Networking Architecture and Key Supporting Technologies for Human Digital Twin in Personalized Healthcare: A Comprehensive Survey

CorpusID: 259252458 - [https://www.semanticscholar.org/paper/334f7825967278d3b357c46497f6c1708021571c](https://www.semanticscholar.org/paper/334f7825967278d3b357c46497f6c1708021571c)

Fields: Engineering, Computer Science, Medicine

## (s13) C. The Universal Framework of HDT
(p13.0) HDT is capable of revolutionizing the current healthcare sector. As shown in Fig. 3, we summarize the universal framework of HDT from [13], [40]- [42], which consists of six fundamental components, i.e., data acquisition; digital modelling and virtualization; communication; computation; data management; and data analysis and decision making. 1) Data Acquisition: Since HDT is a data-driven model, a reliable data acquisition process is vital for HDT. HDT requires both physiological and psychological data of each physical twin (PT), possibly acquired through multiple sources, to establish high-fidelity digital representation of virtual twin (VT). Specifically, it includes medical data from medical institutions, such as electronic health records (EHR) including biomedical examinations and medical images, physiological data (e.g., heart rate, blood pressure and the concentration of biomarkers) obtained through smart personal medical devices, and data from users' social media, such as posts, comments or messages on Facebook, Instagram and Twitter, which can be used to estimate emotions and psychologies.
## (s14) E. Design Requirements and Challenges
(p14.0) It is worth noting that HDT is a complex system with many correlated components, presenting many similarities to conventional DTs. Especially when considering specific use cases of HDT in various PH applications, such as real-time healthcare monitoring, personalized diagnosis and personalized prescription, it is obvious that such application scenarios pose a number of stringent design requirements and challenges for HDT, as discussed below.

(p14.1) 1) Sophisticated and High-Quality Data: Data are essential for HDT. The data for HDT should be sophisticated, which means that the data should be large-scale, real-time, multisource and multi-modal, and possess deep values. Specifically, HDT needs massive data gathering from multi-source to build a high-fidelity VT of a human. The multi-source and multi-modal data involves not only human data, but also environmental data, providing more accurate information for the construction of HDT through mutual supports, supplements and corrections, for satisfying different HDT requirements. Based on this, the VT in the digital space needs real-time data to timely update itself to keep synchronized with the PT. Besides, HDT needs data with deep values, where HDT could gain deep insights from the collected data for providing accurate and forward-looking feedback. However, missing or inaccurate data poses a serious risk to the evolution of HDT and can often lead to misleading information and suggestions from VTs. Such scenarios are undesirable in HDT systems since the outcome can be disastrous, thereby undermining the essence of HDT. Therefore, to ensure that each VT is an accurate replica of its PT, high-quality and noise-free data must be also effectively shared among each PT-VT pair for appropriate model evolution and subsequent decision making.

(p14.2) Although some routine healthcare data (such as step number, heart rate and body temperature) and medical data (e.g., medical images) can be easily captured by common sensing devices such as accelerators, gyroscopes, pressure sensors or through manual processes, there exist many physical states that are difficult to capture. For instance, irritation measured through skin rubbing count and polyphagia measured through food intake count, which are two essential health insights when predicting the risk of diabetes [45], are difficult to be captured in physical states. Therefore, specific biomedical sensors must be designed to retrieve these information. Additionally, in HDT, since data collection frequencies of various data are inherently different, and the data may be collected from multiple sources, asynchronous data acquisition and multimodal data fusion are required to be addressed when establishing HDT.

(p14.3) 2) Extreme Ultra-Reliable and Low-Latency Communication (xURLLC): PT and VT will generate and exchange high volume and multidimensional data to maintain synchronization. This synchronization is expected to be supported by xURLLC, with data transmission rate of ≥ 100 Gbps, reliability of ≥ 99.99999% and latency of ≤ 1 ms [46]. Specifically, when adopting HDT in time-critical healthcare applications, e.g., remote surgery [47], xURLLC is required to support real-time update of the VT as well as timely receptions of feedbacks from such a VT to facilitate timely decision optimizations at the paired PT. Furthermore, important interaction technologies such as tangible XR [48] -a technology that combines XR and tactile internet to transmit not only large capacity contents such as video and threedimensional computer graphics but also haptic signals, such as feelings of touch -also requires the supports of xURLLC [49]. However, current networking technologies, i.e., fifth generation (5G) mobile networks, characterized by ultra-reliable and low-latency communications (URLLC), cannot meet these stringent requirements. Therefore, future communication technologies are necessary to provide xURLLC services to support HDT applications. Nevertheless, xURLLC is still inevitable to the high signaling overhead (e.g., clock synchronization and handover costs), which may considerably deteriorate the network efficiency in general, leading to the demand of further integrating the deterministic network technologies, e.g., timesensitive networking (TSN) [50].

(p14.4) 3) Ultra-Low Round-Trip Time (RTT): In specific applications, e.g., surgery simulation and massage simulation, is imperative to support immersive interactions. For example, one of the most significant challenges in haptic communication is achieving an RTT of 1 ms [51]. RTT is great affected by queuing and processing delays at the intermediate nodes and packet transmission time. However, the packet size transmitted between PTs and VTs are typically large, involving massive multimodal information (e.g., text, audio, video, image, and haptic) to achieve a profoundly immersive experience, which poses a great challenge for achieving ultra-low RTT. Migrating the VT to the vicinity of users (e.g., the corresponding PT or doctors) can be a promising solution. Nevertheless, this will trigger other issues, such as the deployment of migrated VT and timely synchronization updates between the VT and its distant PT. Overall, guaranteeing the ultra-low RTT is essential in HDT applications, and novel network traffic scheduling schemes for HDT may be developed with a careful consideration of this metric. 4) Data Privacy, Security and Integrity: Healthcare-related data with individual private information/metadata (e.g., name and address) are privacy-sensitive and have no or limited tolerance for privacy leakages [52], [53]. Appropriate mechanisms must be developed to ensure that such data are not intercepted or modified by unauthorized users while being stored and transmitted over the network. In other words, key technologies should provide secure and reliable communications among PTs and VTs with sufficient data storage privacy. Authentication of data sources is also a necessity to ensure that all sources are reliable, while fake data are detected and removed through reliable security measures to guarantee integrity. 5) Data Storage: HDT relies on multi-source real-time data from the physical world. Each HDT application can generate up to a few gigabytes of data in a single day. Storage of such massive data may be required for VT update process and analytics. Therefore, key technologies are required to provide appropriate mechanisms to store the huge amount of data.

(p14.5) 6) Advanced Computing Power: In HDT, tasks such as synchronization, model evolution and analytics are expected to be time-sensitive and computation-intensive. To ensure a real-time computation process, massive computation resources are required by HDT to keep high-fidelity. This prompts HDT to be deployed on the network side instead of local devices (which are commonly resource-limited). Furthermore, this paradigm requires optimal computation resource scheduling mechanisms on the network side to guarantee the efficient resource utilization. 7) AI-Driven Analytics: AI is a core key technology for enabling HDT to have the ability to deliver PH services. AIdriven analytical models provide insights at different scales for HDT using real-time and historical collected data, thereby providing decisions or predictions to individuals and updating the VT model. Additionally, AI can support HDT from all aspects (e.g., intelligent computation, intelligent communication network and intelligent data management). However, one limitation of current AI solutions is that they rely on blackbox models and may be inappropriate for problems requiring explicit explanations (e.g., clinical applications). Therefore, the interpretability of AI is an imperative issue that extremely depends on the implementability of HDT. Moreover, the everchanging of human conditions impel AI models to dynamically validate their effectiveness and update for more precisely abstracting the real status of the human body. However, this process is highly complex, which requires the assistance of a strong computation capability.
## (s16) III. KEY TECHNOLOGIES FOR DATA ACQUISITION LAYER
(p16.0) Unlike conventional DT, the data collected in HDT mainly originates from individuals with complex mobility. This includes the acquisition of diverse physiological and psychological data, which are obtained through various biomedical sensors [54]. Further elaboration is provided below.

(p16.1) Collecting human physiological data for building HDT can be enabled by wearable and implantable devices. Smart wearable devices with biomedical sensors (e.g., smart watches, smart socks and smart garments) are developing rapidly in recent years. These wearable devices offer an exciting opportunity for measuring human physiological signals in a nonintrusive and real-time manner by leveraging flexible electronic packaging and semiconductor technology [55]. Nevertheless, smart wearable devices are limited to monitoring only specific types of physiological parameters that are readily accessible from outside the human body (e.g., body temperature, heart rate and step number). Smart in-body biomedical devices with implantable biomedical sensors that are placed directly inside human bodies promise an entirely new realm of applications. Besides, the development of nanotechnology and its application in medicine, through nanomaterials and nanodevices, enables in-body biomedical devices to have diverse clinical applications, such as biomarker concentration monitoring, network tomography inference of human tissues and monitoring of oxygen levels in the surrounding tissues.

(p16.2) In addition to physiological data, the high-fidelity digital model of humans also needs psychological data. Softwarebased soft sensors collect data mainly from social networks, such as Instagram, Twitter and Facebook, where humans sometimes post information about their feelings and emotions [34]. Asides from data obtained through various sensing devices (from pervasive sensing and social networks sensing), electronic health records (EHRs), which record individual health-related data generated by various medical institutions, is another important source of data for HDT applications. All different data acquisition approaches for HDT are visually illustrated in Fig. 7.

(p16.3) In this section, we provide a review of data acquisition solutions for HDT. First, we discuss wearable biomedical sensing, implantable biomedical sensing and social network sensing in Section III-A, which allows HDT to collect realtime physiological and psychological information of PTs. Besides, EHRs is another crucial data source accurately reflecting PTs' health information, which can be used to build the prototype of VTs and improve diagnosis accuracy and patient outcomes as reviewed in Section III-B. Finally, in Section III-C, we provide a brief summary of the reviewed papers, and discuss some opening issues that should be considered in data acquisition for HDT. The roadmap of Section III is illustrated in Fig. 6. 
## (s18) B. Electronic Health Record
(p18.0) EHRs are real-time, patient-centred records consisting of medical imaging including computed tomography (CT) scan, X-ray, magnetic resonance images (MRI) and ultrasound. It also contains medical and treatment histories, allergies, diagnoses, etc. [97]. EHR can be adopted in HDT to improve diagnosis accuracy and patient outcomes.
## (s21) A. On-Body Communication
(p21.0) The HDT on-body communication is generally realized through an essential component, called the wireless body area network (WBAN) [105]- [107], where on or in-body sensors are connected and are responsible for the transmission of collected data to the gateway through WBAN. The structure of on-body communication can be divided into two types. In the first type, sensors directly communicate with the gateway, forming a star topology, as shown in Fig. 9 (a). In the second type, sensors are connected to a body's central processor in the first level for preprocessing to reduce the amount of raw data while saving energy, and then the preprocessed data are forwarded to a gateway in the second level, and thus forming a two-level communication topology, as shown in Fig. 9 (b).

(p21.1) Since body sensors are typically low-power, resourceconstrained and low bit-rate, they require an energy-efficient and low-range wireless link. Table V exemplifies the information of some human body physiological parameters as well as corresponding data rates. This defines baseline requirements for wireless connectivity. Given the above requirements, the majority of existing implementations in healthcare applications rely on Bluetooth low energy (BLE) or ZigBee to wirelessly transmit the data collected by the sensors to a gateway.

(p21.2) 1) Bluetooth Low Energy: BLE has many lucrative features that can be important to on-body communications, such as low-power, low-rate and low-range [109]. It operates in 2.4 GHz frequency band while the time needed for connection setup and data transfer is less than 3 ms. Furthermore, BLE offers a data rate of up to 1 Mbps which makes it a suitable choice for on-body communication. For example, in the HDT-based personalized elderly type 2 diabetes proposed by Thamotharan et al. in [77], BLE was used to transmitted vital signs, blood glucose levels, activity levels, and other information to the mobile phone. BLE, however, does not support multicast communication, which may be important for some HDT applications.

(p21.3) 2) ZigBee: It is developed atop the IEEE 802.15.4 standard for low-power, short-range and low-rate data connectivity [110]. Unlike BLE, ZigBee supports various network topologies and a huge number of sensors, making it a more robust solution. Furthermore, ZigBee is known to be not only a secure key technology that offers three levels of security mode to prevent unauthorized access of data by attackers, but also capable of supporting multicast [110]. However, ZigBee shares the frequency bands with other types of radio technologies (e.g., WiFi and Bluetooth), and therefore, suffers from unintentional interference. Additionally, ZigBee communications   are vulnerable to radio jamming attacks due to the openness of the wireless medium. When a malicious device emits a highpower jamming signal, all ZigBee devices in its proximity will be unable to work [111]. Therefore, its architecture requires a significant upgrade to be suitable for adoption in HDT. Since conveying information using electrical or electromagnetic waves is impossible in small dimensions [112], radio technologies (e.g., BLE and ZigBee) cannot be used inside the human body, and this drives the emergence of molecular communication (MC).

(p21.4) 3) Molecular Communication: MC is a bio-inspired communication method with the ability to mimic the communication mechanism of living cells [113]. As shown in Fig. 10, MC relies on the use of molecules for the transmissions and receptions of information. Specifically, a transmitter releases small particles, called information particles, which are typically a few nanometers to a few micrometres in size. An example is when releasing molecules or lipid vesicles into an aqueous medium (e.g., blood), tiny information particles propagate freely until such particles arrive at a receiver. Subsequently, the receiver detects and decodes the information encoded in these particles. Despite its numerous advantages, it is not clear how MC can establish interfaces for interconnecting human bodies and the external environment. Such interfaces are expected to possess the ability to convert chemical (or molecular) signals into equivalents (e.g., electrical and optical signals) acceptable by conventional communication mechanisms [114]. Besides this interface issue, multiple-input and multiple-output (MIMO) MC may be required to ensure realtime health parameters detection in HDT, while guaranteeing the protection of data security [83].

(p21.5) It is worth noting that, other wireless technologies, such as narrowband IoT (NB-IoT) and IPv6 over low-power wireless personal area networks (6LoWPAN) may also be alternatives for on-body communication in HDT. A review of these technologies can be found in [80].
## (s22) B. Beyond-Body Communication
(p22.0) HDT should be supported by the bidirectional real-time synchronization between any PT-VT pair to ensure high fidelity of VT [115]. This synchronization is, however, data-driven and delay-sensitive. Furthermore, data captured through sensing devices in the physical world are often complex, massive, heterogeneous, multiscale, and with high noise. In addition to real-time synchronization, interacting with VTs involves more complex information that needs to be transmitted between the PT and users in the physical world. Multimodal information, such as 3D virtual items, text, images, haptic feedback, smells, among others, needs to be transmitted in HDT under various applications to enhance the immersive experience. These specific characteristics place a significant burden on current communication networks. For instance, a massive number of PTs simultaneously interact with their respective VTs in the same area, which poses great challenges to bandwidth-limited communication to support the delivery of high-resolution contents [116]. To address these issues, we provide a review of cutting-edge communication solutions that can enable beyond-body communication for HDT.
## (s23) V. KEY TECHNOLOGIES FOR COMPUTATION LAYER
(p23.0) Building HDT requires the assistance of powerful computing systems. For example, achieving a profoundly immersive experience through real-time rendering of PT, enabling interaction-driven optimization through fast data analysis (e.g., the responsive facial expression during interaction [137]), all of these require the support of unparalleled computing power. However, the current central architecture based computation paradigm cannot meet the fast-responsive and computationintensive requirements of HDT. Edge computing is capable of providing real-time and supplementary computing capability, and thus attracts a lot of attentions in HDT applications.

(p23.1) HDT generally relies on extensively complex AI algorithms to continuously update each VT for enhancing reliable diagnoses, predictions and accurate decisions to support counterpart PT in the physical environment. To achieve this, HDT requires accurate massive data and intensive computation power, which can hardly be met by resource-constrained mobile and IoT devices. One may consider to enable task offloading that allows high computation-demanding tasks to be offloaded to more powerful cloud computing systems such as AWS, AliCloud and Azure, to mitigate the computation pressure on the mobile devices.

(p23.2) However, cloud computing suffers from many limitations: i) high communication cost due to the high distance between cloud servers and users; ii) network congestion due to the massive amount of data that are simultaneously transmitted over the network; iii) user data security and privacy issue due to centralized storage. These motivate the continuous emergence of edge computing as a promising, practical and efficient solution because of its ability to bring computing capabilities near users, thereby alleviating the need to transmit data to the central cloud for computation. Fig. 12 presents the edge computing paradigm for HDT.

(p23.3) In this section, we firstly discuss the role of mobile edge computing in HDT, and its benefits, i.e., addressing the mobility issue of HDT and reducing the response time, in Section V-A. Although mobile edge computing can be an ideal solution for replacing the traditional centric cloud computing, it hard to resolve computation burden brought by long-term operations and large scalability of HDT under several scenarios. In response, we further introduce an effective computing paradigm,  called edge-cloud collaboration, in Section V-B. Finally, we summarize the reviewed papers in Section V-C, and discuss several opening issues therein.
## (s37) A. Data Pre-Processing
(p37.0) As previously mentioned, physical data in HDT have the characteristics of heterogeneity, multiscale and high noises. Hence, it is necessary to enable pre-processing such that issues like missing data, data redundancy, data conflicts and errors can be properly handled [13]. Generally, data pre-processing in HDT includes data cleaning, data reduction and data fusion.
## (s38) B. Data Storage
(p38.0) HDT is expected to produce massive amounts of data including the demographics of PTs, clinical and medication history data, real-time personal health data obtained through pervasive sensing, genetic data, diagnostic trajectory, data analysis results and social and geographical relocation data. This requires massive storage to support various operations in HDT [13]. Fortunately, the development of big data storage frameworks such as the MySQL database, HBase and NoSQL database has opened many opportunities to overcome this challenge in HDT.
## (s42) C. Data Security and Privacy
(p42.0) HDT environments may suffer from various security threats. Data security and privacy are important aspects of HDT implementations that require careful considerations [52], [53]. Next, we discuss the main requirements of HDT from data security and privacy perspectives.

(p42.1) -Confidentiality: It implies that both obtained health data and information, transmitted among PTs and VTs, are only accessible by authorized end-users, and is usually achieved through the use of encryption and decryption algorithms. -Data access control: It defines a privacy policy intending to prevent unauthorized access to user information. Data access mechanisms are often set up with different access rights. -Data integrity: It requires that data accuracy (i.e., correctness and consistency) throughout the whole transmission process (e.g, data sharing) cannot be changed by unauthorized users. -Data authentication: It ensures proper authentications of participating users. In the absence of a reliable data authentication scheme, a malicious user may appear to be legitimate, thereby exchanging false and misleading data in the system. Hereafter, we particularly survey some key technologies for protecting security and privacy of HDT.

(p42.2) 1) Cybersecurity: It has been revealed that cyber-attacks are the most frequent causes of medical data breaches. An adversary can violate HDT privacy and security requirements by introducing ransomware attacks, stealing users' information and blackmailing patients. For example, attackers may launch attacks on wireless personal area networks (WPANs), such as replay attacks on BLE, and eavesdropping on ZigBee [200], [201], to compromise the HDT resulting in organ hijacking. Some typical cyber-attacks in the context of HDT are elaborated as follows.

(p42.3) -Denial of service (DoS): Attackers can flood WPANs with excessive traffics or requests, resulting in DoS attacks that can overload or disrupt the network's operations [202]. This can cause devices such as wearable biomedical devices and smartphones in the data acquisition layer of HDT to disconnect, and the affected users may become unable to receive or send information. -Battery exhaustion attacks: WPAN devices, including wearable and implantable biomedical devices, are usually battery operated devices that enter sleep mode when inactive. Battery exhaustion attacks force continuous fraudulent connection requests to drain the battery and cause the device to become unavailable [202]. -Man in the middle (MITM) attacks: An attacker may insert itself into the communication (e.g., BLE and ZigBee) channel between two legitimate devices (e.g., between personal devices or devices and gateways), while maintaining the facade that they are communicating with other directly [202]. For instance, both legitimate generic access profile central and peripheral devices will be associated with the impostor device to monitor the messages between the two legitimate devices. -Data modification: In HDT, an attacker may launch data modification attack, thereby causing malicious behaviour of HDT including denial of required treatments for the concerned patient. -Data injection: In HDT, malicious data may be injected to alter the normal execution process. Such an attack can drive HDT into an unsafe state, making the system susceptible to data loss, DoS and data integrity attacks. -Eavesdropping: In HDT, eavesdropping attacks can be passive or active. An attacker quietly monitors message transmission and gathers useful information for the desired purpose in passive attacks. In contrast, active attacks occur when fraudulent nodes participate in communications, posing as legitimate ones to obtain important information, such as healthcare-related data and personal information, for misuse [202]. a) Intrusion detection system: Intrusion detection system (IDS) is a critical security system aimed to manage attacks on networks while recognizing malicious actions in computer network traffics. IDS plays an imperative role in supporting data security by discovering, deciding and detecting unauthorized usage, duplication, modification and demolition of data and data frameworks [203]. For instance, Chen et al. proposed effective algorithms for detecting lowrate DoS attacks in ZigBee networks of HDT in [204]. They accomplish this by combining Hilbert-Huang transforms with trust evaluation approaches, thereby enhancing the security of ZigBee networks in HDT. Since most of the available IDS solutions can only detect attacks, but cannot measure the attack severity. To this end, Ramos et al. in [205] proposed a node security quantification probabilistic model, based on the message security value and the damage level, to quantitatively evaluate the impact of compromised nodes on the integrity of data sent via 6LoWPAN networks. Additionally, traditional IDS-based security solutions usually suffer from a high false positive rate (FPR) and often need manual modifications, making it very difficult to scale when adopted in HDT [206]. The recently proposed ML-based IDSs well address this issue. Schneble et al. in [206] designed and implemented a massively distributed, FL-based intrusion detection system (FLIDS), which can achieve high accuracy, low FPR and communication cost, along with sufficient flexibility and scalability, making it suitable for the detection of attacks in HDT-enabled healthcare systems. Thamilarasu et al. in [207] developed a novel mobile agent-driven IDS for HDT using ML to secure the network of connected personal biomedical devices. The proposed IDS was hierarchical, autonomous and adopted regression algorithms to detect network level intrusion and anomalies in sensor data. b) Cyber resilience: Cyber resilience is the ability to prevent, withstand and recover from cybersecurity incidents (i.e., cyber attacks), which is a critical enabler of trustworthy in the operation of HDT. Vulnerability tolerance is a fundamental requirement of cyber resilience in HDT. Exploitable HDT vulnerabilities are critical security threats to healthcare organizations and can affect massive users [170]. One fundamental technology for cyber resilience in HDT is the software vulnerability detection technique. Existing conventional vulnerability detection techniques can be categorized into static and dynamic ones. Static techniques such as rule-based detection, code detection and symbolic execution, often result in many false positives, while dynamic techniques such as fuzz testing and taint analysis frequently suffer from low code coverage problems [208]. To deal with these limitations, ML techniques have been widely adopted in software vulnerability detection. Lee et al. in [209] proposed an improved ML-based static binary analysis technique to learn representations from code context. The obtained results showed that software vulnerabilities can be detected with an accuracy of 91% of the assembly code. Zhou et al. in [210] introduced a graph neural network-based model for graph-level classification through learning on a rich set of code semantic representations to localize the vulnerable functions among the source codes. Besides these, Zhang et al. in [170] proposed a novel end-to-end scheme by adopting bidirectional long-short-term memory (LSTM) network with a selfattention mechanism for cyber resilience. The mechanism can explore a bi-directional relationship among some key codes, thereby recognizing potentially vulnerable functions in software projects for HDT. Similarly, a novel end-toend vulnerability tolerance scheme was proposed in [48] to recognize and fix HDT vulnerabilities. A new CodeBERTbased neural network was applied to better understand risky code while capturing cybersecurity semantics [48]. The technique has been demonstrated to have great potential in the cyber resilience of HDT through extensive evaluations.

(p42.4) 2) Privacy-Preserving Mechanism: In HDT, network security is not sufficient to enhance operations, since medical data are also privacy-sensitive. Several common privacy threats in HDT are listed in the following.  Fig. 16. Cryptography-based privacy-preserving mechanism for HDT.
## (s44) Data Acquisition
(p44.0) -Attackers may eavesdrop data on the public communication channel compromising data transmitted in plaintext. -Since repeated keys are commonly used by users, it is possible that an attacker may break into the data storage server (e.g., cloud server) by brute force attacks based on key dictionaries collected from other data leakages. -Honest-but-curious provider of data storage or computing services (e.g., cloud server) may also try to compromise the data privacy of HDT. As visually illustrated in Fig. 16, the main privacypreserving mechanisms for HDT include cryptographic techniques, anonymization techniques, differential privacy and FL, which are reviewed in detail hereafter. a) Cryptography: Cryptography is a critical enabling technology for HDT to protect the privacy of personal health data in all segments. Cryptography techniques can be classified into several categories based on different criteria, such as symmetric-key cryptography, asymmetric-key cryptography, homomorphic encryption and quantum cryptography.

(p44.1) • Symmetric-key cryptography and asymmetric-key cryptography: Symmetric-key cryptography uses the same key for both encryption and decryption, while asymmetric-key cryptography uses a pair of keys, i.e., a public key for encryption and a private key for decryption. They can be used to secure the transmission and storage of sensitive healthcare-related data in HDT.

(p44.2) As a data source of HDT, the IoMT device introduced in Section III monitors the health parameters of the human body and generates health-related data. These data must be kept safe from possible misuse and modification. The resource-constrained characteristic of IoMT devices, however, means it is very difficult to carry out data encryption with high-level cryptographic techniques. To overcome this bottleneck, efficient lightweight cryptographic techniques have been recently explored to support IoMT devices [211], [212]. Chaudhary et al. in [211] proposed a novel block cipher-based technique by performing matrix rotation, XoR operation and expansion function to encrypt data. Noura et al. in [212] designed a flexible lightweight cipher using a one-round simple cipher scheme with a dynamic key approach and introduced the concept of dynamic chaining and block mixing. Apart from the health data, the plaintext of query requests in HDT should also be kept secret from the honestbut-curious data storage server (e.g., cloud server) and other devices. Zheng et al. in [213] designed an efficient and privacy-preserving similarity querybased healthcare monitoring scheme, called PSim-DTH. Under such proposed scheme, the healthcare centers encrypt the data of each patient (e.g., EHR data) before outsourcing such data to the cloud. Then, the counterpart VT of a patient can launch similarity range queries to the cloud server. The cloud server is expected to return data records that are similar to the patient, as the query results, to the VT. Additionally, to speed up similarity query efficiency while guaranteeing data privacy, the authors adopted a partition-based tree (PB-tree) to index the healthcare data and introduced matrix encryption to present a privacy-preserving PBtree-based similarity range query (PSRQ) algorithm. • Homomorphic encryption: This is a special type of encryption that allows computations to be performed on encrypted data without first decrypting it. The homomorphic encryption has been utilized in healthcare system for protecting the security and privacy of healthcare-related data, and such paradigm can be also applied in segments of HDT, such as in the communication layer, computation and data management layer. For example, Zhang et al. [214] proposed a FL mechanism for deep learning of medical models in IoT-based healthcare systems. They further employed homomorphic encryption to protect local models from inference attacks on private healthcare-related data. Shaikh et al. [215] utilized the fully homomorphic encryption techniques to secure the ECG signals, which helps the medical provider to record ECG signals confidentially and to prevent mistreatment. • Post-quantum cryptography: Post-quantum cryptography can enable the HDT by providing a secure method for protecting the privacy-sensitive healthcare-related data that is exchanged between PTs and VTs. With the emergence of quantum computing, current cryptographic methods that are used to secure sensitive data, such as EHRs, could be vulnerable to attacks in the future. Fortunately, the post-quantum cryptography is developed to resist quantum computers and quantum computing-based attacks. This means that post-quantum cryptography can provide a high level of security and privacy for HDT in PH applications. For example, Mirtskhulava et al. [216] proposed a blockchain scheme with hash-based post-quantum digital signatures for securing EHRs. Xu et al. [217] proposed a post-quantum public-key searchable encryption scheme on blockchain (PPSEB) for E-healthcare scenario to enable data sharing while ensuring security and privacy. PPSEB employed a lattice-based cryptographic primitive to ensure the security of the search process and achieve the forward security to avoid key leakage of medical information.

(p44.3) b) Anonymization: Anonymization captures the process of removing identity information from health data to mitigate the risks of identifying the actual source or owner of such health records. Majeed in [218] proposed an anonymization scheme to enhance the data privacy of EHR. The proposed scheme aimed at preventing identity disclosure even in the presence of pertinent background knowledge by adopting a fixed interval approach, which classified the quasi-identifiers of the EHR data in fixed intervals, while replacing the original values with their averages. Aminifar et al. in [219] investigated the process of anonymizing data in a health data sharing application to address the problem associated with record-linkage and attribute-linkage attack models. To ensure anonymization, the authors studied anonymization as a constrained optimization problem, where k-anonymity, l-diversity and tcloseness privacy models were jointly studied. Recently, ML has been demonstrated as a useful tool to enhance the anonymization of health-related data. A common example of an ML-based anonymization solution in the literature is generative adversarial networks (GANs)-based anonymization. Angulo et al. in [220] proposed an HDT architecture to support patients with lung cancer. The proposed architecture adopted GANs to ensure anonymization of healthcare data (e.g., CT images of a patient). Through GANs, fake health data (e.g., thyroid-related and cardiogram data) were also generated in [221] by converting the original raw data, including static data and dynamic data, into images to facilitate their usage for GANs anonymization process. c) FL: FL is a distributive AI paradigm which has opened up new opportunities to ensure privacy in HDT by ensuring that raw data of participants are not transmitted during any data sharing process. The centralized AI paradigm has the potential to suffer from privacy leakage because sensitive health data are transmitted through public networks and processed by a honest-but-curious cloud server. In contrast to centralized AI, FL promotes distributed learning on end devices, where only gradients are transmitted to the central global model, thus preserving the privacy [222]. Note that we have already surveyed the applications of FL in HDT in section V-B, and therefore the details are not repeated again for conciseness.

(p44.4) 3) Distributed Ledger Technology: Distributed ledger technology (DLT) is a type of digital database that allows for the secure and transparent recording and storage of data across multiple nodes or participants in a network. Unlike traditional databases, which are typically centralized and controlled by a single entity, DLT is decentralized and distributed, with data stored on multiple nodes in a network. One of the most wellknown technologies of DLT is blockchain, and hereafter, we introduce the applications of blockchain in HDT in detail.

(p44.5) Blockchain is widely recognized as a distributed and decentralized peer-to-peer (P2P) data storage mechanism, where transactions are validated and appended to the chain if a consensus is reached among a group of validators. Once the information is stored in the blockchain, it cannot be modified [223]- [225]. As a result, blockchain becomes a suitable technology to enhance security in HDT-enabled PH applications and systems.
## (s47) A. Diagnosis
(p47.0) One of the key requirements in PH service is personalized monitoring and diagnosis. By leveraging AI, HDT can provide personalized and precise diagnosis services [233], [234]. For instance, an ML-based human heart VT was proposed in [235] for the detection of heart diseases. Implantable devices, such as pacemakers and implantable cardioverter defibrillators, were used to capture data related to heart conditions. The captured data were then transmitted to the cloud to support the creation and storage of heart VT. A decision tree based on an ML algorithm, was used to categorize the conditions of patients according to real-time data obtained from the VT as well as the previously stored health data in the cloud. The decision tree classifier achieved an accuracy of 79%, which was comparable with the traditional medical treatment. Martinez et al. in [141] designed an edge-assisted cardio twin platform for realtime detection of IHD. The system adopted CNN to classify myocardial infractions (a type of IHD) and non-myocardial infractions. The adopted CNN framework was able to generate features from the ECG and performs the classification task. The system achieved an accuracy of 85.77% while achieving timeliness of 4.84 ms to complete the classification of each sample. Similarly, an HDT solution was proposed in [236] for patients in an IoT context-aware environment. The HDT solution was necessary to aid the monitoring of real-time health status as well as detection of body metrics anomalies by building a novel ECG heart rhythms classifier model that diagnoses heart disease and detects heart problems. The results showed that LSTM achieves the best performance in terms of accuracy, precision, recall and F1 score. Another typical example is the diagnosis of the aortic abdominal aneurysm (AAA), a increasingly growing dilation of the aorta with a risk of potentially lethal rupture. Because of the high mortality rate of around 80%, any successful treatment of AAA usually depends on how early it was detected. In [237], the authors designed a cardiovascular VT for the detection and diagnosis of AAA, in which HDT was modelled through the adoption of the LSTM-based inverse analysis. The CNN classifier was trained to extract features from the blood pressure waveform to detect AAA. The results showed that the accuracy of the customized CNN in detecting AAA achieves 99.91%, while the classification of its severity can achieve 97.79%, which are surprisingly higher than those by traditional clinics.

(p47.1) Compared to conventional DT, the provision of explanations or justifications to verify the reliability of machine-enabled predictions and decisions is particularly crucial in the field of diagnosis. This is because the predictions or decisions made by machines can directly impact the safety and well-being of individuals, and reliable explanations or justifications are essential for ensuring the credibility and confidence of the results [77]. To this end, a new concept, called explainable AI, has been proposed recently [238]. Explainable AI is capable of providing decision outputs based on the set of inputs while also providing a set of supporting evidence. This technique has been integrated into HDT. For example, in the HDT-based personalized elderly type 2 diabetes management framework developed by Thamotharan et al. in [77], the local interpretable model-agnostic explanations (LIME) was used to explain the factors that may lead to hyper and hypo events in a patient, thereby helping personalization and improving patient behavior. Besides, Pitroda et al. in [239] developed a lung disease identification model using the explainable AI technique. A customized CNN with the ability to obtain reasonable performance in terms of classification accuracy was trained. Then, a layer-wise relevance propagation (LRP)based method was proposed to quantitatively interpret the performance of the CNN model.
## (s49) C. Surgery
(p49.0) According to WHO, more than 2.5% of patients die during surgery or after surgery. This high mortality rate can be attributed to in-surgery and post-surgery reactions, low precision of the used technologies as well as lack of suitable experience of surgeons [247]. Fortunately, AI-enabled HDT can be applied in preoperative, intraoperative, and postoperative management for improve surgical accuracy and precision [52].

(p49.1) AI-assisted preoperative planning can be an essential method to guarantee surgical success. By the traditional way, surgeons prepare themselves for a surgical procedure by looking at medical records and images, such as CT and ultrasound of the concerned patient. This medical imaging-based preoperative planning routine includes anatomical classification, detection, segmentation and registration [248]. To ensure more accurate identification and classification of colon lesions and anatomical landmarks in colonoscopy images, Jheng et al. in [249] developed a CNN-based algorithm to classify benign or malignant lesions of thyroid cancer in ultrasound images. Rubinstein et al. in [250] applied an unsupervised learning approach to detect and localize prostate cancer foci in dynamic positron emission tomography (PET) images. To achieve this, they trained a deeply stacked convolutional autoencoder to extract statistical, kinetic biological and deep features from 4D PET images. Torosdagli et al. in [251] developed a fully convolutional DenseNet-based automated image analysis software for mandible segmentation of cone-beam computed tomography (CBCT) images. A UDS-Net-based method was proposed in [252] to segment teeth from dental CBCT images. The proposed method consists of a U-Net with a dense block, comprising multiple densely connected convolutional layers and spatial dropout. Furthermore, a novel 3D deep supervised densely network (3D-DSD Net) was proposed in [253]. The proposed 3D-DSD Net consists of a U-Net with a dense block and additional skip connections, to execute CT data segmentation tasks of the small organs in the temporal bone.

(p49.2) Besides all above, several HDT-based preoperative planning platforms have also been developed. For instance, an HDTbased remote surgical rehearsal platform was introduced in [100] to improve surgical simulation experiences. This work proposed a novel robust auxiliary classifier GAN (rAC-GAN)based intelligent prediction model to predict the pathology of lung cancer with pulmonary embolism, and combined mixed reality (MR) to project surgical navigation images. Furthermore, an HDT-based laparoscopic surgery assisting tool integrating AR and ML was developed in [254].

(p49.3) AI can enable surgical robots to achieve superhuman performance. Learning from demonstration (LfD) is a prevalent paradigm for allowing robots to autonomously and intelligently perform tasks using learned strategies [255]. The paradigm is beneficial for surgical procedures, where surgical robots can intelligently execute specific tasks or motions by learning from surgeons' demonstrations without tedious programming procedures. For instance, LfD has been shown to be a promising solution for aiding surgical robotic systems to automatically execute soft tissue manipulation [256]. Humanrobot interaction (HRI) is another essential part of surgical robotic systems. With the assistance of AI, the HRI enables surgeons to control the surgical robot with touchless manipulation [257]. A dense CNN-based model was developed in [258] for 9-direction/36-direction gaze estimation. Then, with the help of the proposed model, doctors can easily control the robot by specifying the starting point and ending point of the surgical robot using eye gazing. Fujii et al. in [259] performed real-time gaze gesture recognition with the hidden Markov model (HMM), allowing the laparoscope to pan, tilt and zoom during surgery, whilst immune to aberrant or unintentional eye movements.
## (s50) D. Rehabilitation
(p50.0) Due to the increasing aging population, rehabilitation of diseases like stroke poses a huge healthcare burden, resulting in a demand for new rehabilitation methods. One of the most promising solutions for this problem is HDT with AI assistance [36].

(p50.1) AI could assist HDT in predicting patient movements to improve the performances of lower and upper limb rehabilitation. For the upper limb rehabilitation, a multi-stream LSTM duelling-based motion prediction model was proposed in [260]. Specifically, the multi-stream LSTM duelling was employed to predict the trajectories with a multi-joint motion of the human arm and then utilized the predicted angles as input to control the trajectory of the exoskeleton robot, thereby ensuring synchronization between the robotic and human arms. For lower limb rehabilitation, Alekseyev et al. [261] have developed an HDT-based rehabilitation system, featuring two measuring modules located in the heel area, relying on a micromechanical sensor with a three-axis accelerometer and a gyroscope. The measurement data is analyzed using AI algorithms to assess the level of recovery in walking skills.

(p50.2) AI can assist HDT in providing therapists with quantitative analysis of patients' rehabilitation status to improve practices [262]. As an example, Lee et al. in [263] designed an intelligent decision support system for stroke rehabilitation assessments. The design was able to automatically identify salient features of assessment using RL to assess the quality of motion while generating a summarized patient-specific analysis as an explanation of its prediction. A novel rehabilitation assessment paradigm was proposed in [264], where a domain expert and an AI-based system were integrated to collaborate in executing complex decision-making tasks, such as stroke rehabilitation assessment. The results presented in this work showed that accuracy of decision-making can be significantly increased via AI assistance.
## (s57) E. Effective and Efficient Interface Design
(p57.0) Interface design for the networking architecture supporting HDT in PH is critical to the integration of all layers across the data acquisition layer to the data analysis and decision making layer. It is expected to be human-centered, multi-modal, secure, efficient, scalable, interactive and standardized. Firstly, the interface design for data acquisition should prioritize the comfort of patients and ensure seamless integration among multiple heterogeneous medical sensing hardware and communication approaches. For example, a skin-integrated wireless haptic interface [265] can be designed as a comfortable and user-friendly way to enable data interaction between a PT-VT pair. Secondly, the interface design should consider multimodal input and output design, including audio, gesture, video signals, and the ability to handle large volumes of data while maintaining high levels of accuracy and reliability. Thirdly, the interface design should consider efficiency and scalability, especially in handling massive and complex computing tasks in PH services, which usually involves collaborations among multiple parts of "human". This requires the interface design to consider parallel processing and distributed computing for optimizing the performance of the computing layer in HDT. Fifthly, the interface between the data analysis and decisionmaking layer and users be intuitive, such that users are able to interpret and perceive feedback of VTs easily (e.g., drug response and future disease progression). Last but not least, designing a standardized interface for HDT is important to simplify the management of resources required for HDT implementation. The standardized interface can provide a unified way for users to access various resources, improving the efficiency and effectiveness of PH service delivery.

(p57.1) Use-case: Suppose that there is a scenario in which a doctor uses a patient's HDT as a testbed for prescribing personalized medications. The doctor inputs a virtual candidate drug into the VT, and the VT visualizes the drug-disease interactions through the carefully designed user interface. By doing so, the doctor can vividly and intuitively understand the performance of the tested drug through the interactive interface, making informed decisions with ease.
## (s59) G. Full-Fledged Explainable AI for HDT
(p59.0) The role of AI in HDT should not be underestimated. Particularly, decision explanation is a crucial factor in HDT. While AI has shown its strong muscle for providing reliable data analysis in the existing literature, it is generally referred to as a black box model, due to its inability to offer details and understandable explanations for its decisions. This explainability feature is, however, essential in the healthcare domain to ensure trust and confidence in decisions. In other words, transparency in AI-based data analysis is required. To support medical personnel and improve their efficiency, HDT should provide full-fledged explainable recommendations. This will assist medical professionals in reaching safe and reliable decisions to provide PH services to each individual. Although explainable AI has recently started to attract some attentions [238], more efforts are needed to investigate how this concept can be integrated to facilitate decision makings in HDT systems and applications. The current explainable AI solutions are also lacking in precision and detail, making the need for more in-depth research in this area a necessity.

(p59.1) Use-case: Take the remote monitoring and management of a patient with chronic conditions by HDT as an example, where HDT with AI can alert the patient or its healthcare professionals when the health status is abnormal for intervention. The lack of transparency in AI-based decision-making can make it difficult to understand the reasons behind the recommendations, and thereby results in reliability concerns. Therefore, the integration of full-fledged explainable AI with HDT can help improve the transparency and trustworthiness of AI-based recommendations, so that healthcare professionals can follow the reasons to infer the pathology. Ultimately, the integration of the full-fledged explainable AI will help medical professionals make more informed decisions and provide better care to patients with chronic conditions, even in remote settings.
## (s60) H. Generalized AI for HDT
(p60.0) HDT-enabled PH systems may integrate a variety of AI algorithms such as KNN and SVM that need to be trained by labelled data. However, most health-related data in HDT are unlabelled. To improve performance, new AI algorithms that can efficiently perform training using unlabeled data are required to facilitate real-time and reliable decisions in HDT. Furthermore, the development of training-specific AI models for each task is time-consuming. The development of general artificial intelligence (GAI) through transfer learning [266] and meta-learning [267] opens several opportunities of alleviating the need for redundant computation.

(p60.1) Use-case: Consider that a patient with a chronic disease, such as diabetes, is being monitored through its HDT. The HDT collects a large amount of health-related data from various sources, such as wearable biomedical devices and electronic health record, but a significant portion of these data are unlabelled. In order to provide the patient with realtime, accurate and reliable recommendations, the HDT needs to incorporate AI algorithms which can be efficiently trained by using these unlabelled data. In addition, instead of developing training-specific AI models for each task (e.g., tasks like glucose level prediction and providing healthy lifestyle recommendations), HDT should incorporates GAI for reducing redundant computations.
## (s62) J. Metaverse
(p62.0) As a disruptive next-generation technology, Metaverse may revolutionize human lifestyles. Metaverse users are telepresent and immersed in a virtual world as human-like avatars, acting as VTs of their corresponding PTs. In addition to VTs of HDTs, the next-generation DT-enabled environment will also include other DTs, such as city DTs, unmanned aerial vehicle DTs, and satellite DTs. With an expected emergence of a massive diversity of DT objects in the Metaverse, malicious DTs and activities have become inevitable. For instance, VTs with a large volume of sensitive individual medical data may be at risk from malicious DTs, which can launch attacks to compromise VTs in the virtual world, causing significant destruction. To prevent this, HDT requires effective security and privacy mechanisms to protect VTs in such complex Metaverse environments. Recently, researchers have made the first attempt to use HDT technology to simulate the cognitive patterns of malicious hackers for proactive cybersecurity defense in the Metaverse [269].

(p62.1) Use-case: Envision that in the Metaverse, a user with type 1 diabetes has a VT in the virtual world. Such VT monitors the user's blood sugar levels and insulin dosage in realtime, providing constant feedback to the user's healthcare professionals in the physical world. However, due to the lack of supervision, the VT may be compromised by a malicious DT in the Metaverse, which gains access to the user's medical data and begins tampering with the blood sugar readings. This potentially leads to fatal consequences for the user if it is not detected and corrected quickly. To prevent such attacks, the HDT in the Metaverse should be equipped with advanced security and privacy mechanisms. These mechanisms tailored to HDT in Metaverse detect anomalies, such as unexpected changes in the VT's behavior or data.
