# A Survey on Event-based News Narrative Extraction

CorpusID: 256900869 - [https://www.semanticscholar.org/paper/0ff9e62181e9eb0817407ecd383b9a4d7263076b](https://www.semanticscholar.org/paper/0ff9e62181e9eb0817407ecd383b9a4d7263076b)

Fields: Computer Science

## (s5) TDT Query
(p5.0) Initial Query (("event* thread*" OR "link* news article*" OR "article network" OR "event* map" OR "narrative* map" OR "gener* information map" OR "information map gener*" OR "information map extract*" OR "event* timeline* analysis" OR "topic anatomy" OR ("event graph" AND "text") OR "extract* story chain*" OR "find* story chain*" OR "story* gener*" OR "topic retrospection" OR "track new events" OR ("connect* the dots" AND "algorithm*") OR "discover* event episodes" OR "event* track*" OR "topic* chain*" OR ("building" AND "timeline*") OR "evolutionary theme* pattern*" OR "evolutionary topic* pattern*" OR "metro map*" OR "generate timeline*" OR "extract timeline*") AND ("news*" OR "intel* analys*" OR "journalism" OR "social media*" OR "information overload" OR "sensemaking" OR "sense making" OR "information map*" OR "storyline generation" OR "event* evolution" OR "evolution graph*"))  to obtain a computational representation of the narrative and then use it to analyze the narrative [79,95]. However, they do not provide new insight into the extraction task itself, unless they include a novel extraction method as well.

(p5.1) Moreover, we exclude interactive narratives, as these are a fundamentally different type of narratives where the story can be changed through user feedback and actions [19], which would not make sense in the context of news narratives.
## (s9) Overview
(p9.0) We found a total of 54 articles focusing on event-based news narrative extraction in our review. We present the articles based on the resolution level that they use: events as sentences, events as documents, and events as clusters. Figure 2 summarizes the identified approaches categorized by event resolution and some relevant subsets of these categories. In the sentence-level resolution, query-based approaches include an information retrieval step in addition to the narrative extraction itself. For example, these approaches require the user of the method to define a search query (e.g., "COVID" or "Terrorism") to find related documents in the data set through similarity-based techniques or other methods before extracting the narrative from the queried subset. In contrast, pre-filtered approaches assume that the data set has been already filtered and do not require an explicit query. In the document-level resolution, Connect the Dots approaches refer to the line of works derived from Shahaf and Guestrin's seminal method of the same name on storyline extraction [96]. In the cluster-level resolution, event threading and evolution methods refer to a series of works based on Nallapati et al. 's event threading concept [76] or Yang et al. 's event evolution concept [126]. Works that fall under the "Others" do not fit in any of the defined subsets.
## (s10) News Narra�ve Extrac�on
(p10.0) Events   Table 1 summarizes the reviewed articles. In particular, we include the following columns in this table: event resolution, number of stories, structure, type of approach, and event representation. We now provide a brief description of these elements and their possible values.

(p10.1) Event resolution refers to the abstraction level at which the events are extracted. As mentioned in the scope definition, we consider three levels: sentences, documents, and clusters. Sentence-level works represent events as either a single sentence (e.g., the most important sentence or a headline) or a set of sentences (e.g., a sample of representative sentences).

(p10.2) Document-level works represent events directly as a single document (e.g., a full news article). Cluster-level works represent events as sets of documents (e.g., multiple news articles that talk about the same basic event). Structure represents whether the extraction method generates a linear structure of events (e.g., a timeline [96,124]) or a graph-like structure (e.g., a directed acyclic graph [51] or tree [67]). Figure 3 exemplifies these concepts.

(p10.3) Number of stories refers to whether the method is designed to handle a single storyline or multiple storylines. Recall that our definition of a story as a sequence of events. Most timeline extraction methods extract a single story, but some of them extract parallel timelines, where each timeline represents a different story from the data [56,130]. In contrast,
## (s13) Event Resolution
(p13.0) Narrative Structure "The first debate between President Obama and Mitt Romney, so long anticipated, quickly sunk into an unenlightening recitation of tired talking points and mendacity." "Mr. Romney wants to restore the Bush-era tax cut that expires at the end of this year and largely benefits the wealthy" "BP's shares fall 2% amid fears that the cost of cleanup and legal claims will hit the London-based company hard"

(p13.1) "Aides say Clinton is angered as Gore Tries to break away" most graph-based works are designed to represent multiple storylines, due to their inherent more complex nature compared to timelines. However, there are some works that represent a single story, but provide extra information by exploiting graph structures. For example, appending additional nodes with related events to the central story [65].
## (s14) Events as Sentences
(p14.0) We start with works that use a sentence-level resolution. Most of these methods fall under the umbrella of timeline summarization [37]. However, not all of them fit with traditional TLS work. We split the discussion into three parts:
## (s18) Others.
(p18.0) Here we present works that use a sentence-level resolution but differ from the majority of the other works that follow the traditional timeline summarization approach. In particular, we consider works on extracting disaster storylines from news and works that present variations on the traditional TLS task.

(p18.1) Disaster Storylines Zhou et al. 's works [133,134] present a framework to construct spatio-temporal storylines for disaster management from news data based on how the disaster location moves over time (e.g., a typhoon moving through different areas). This approach generates timelines for two levels of representation: a global level that follows the progress of the disaster through each location and a local level that focuses on a specific location. To extract the storyline, a series of snippets (i.e., event sentences) are extracted from the news articles using named entity recognition methods and grouped together based on a similarity graph. Then, a set of representative sentences is selected by finding the minimum dominating set [102] using a greedy algorithm. Next, an integer linear programming approach is used to select the optimal sequence for the main route of the disaster by maximizing the coherence of the story chain, subject to a series of structural, chronological, and length constraints. In this method, coherence is defined based on consecutive content similarity rather than word influence. However, the key difference is that this formulation includes a smoothness constraint, which is specifically designed to track the moving location of disasters through time. Smoothness is based on simulating the natural trajectory of a disaster. In particular, the constraints set a maximum distance for consecutive events (i.e., avoiding jumps to locations too far away) and seek to avoid acute angles that could be formed by two consecutive connections (i.e., avoiding sharp turns in the trajectory of the disaster). Once the main storyline has been constructed, the next step is to analyze the local level storylines. For each main storyline event, a set of similar articles are selected and used to construct a multi-view graph that represents the event relationships based on content similarity.
## (s19) Events as Documents
(p19.0) Here we present works that use a document-level resolution. We split the discussion into two parts: methods that build upon the Connect the Dots approach by Shahaf and Guestrin [96]-a seminal work in the field of news narrative extraction-and others. We further divide the presentation based on whether the methods are linear or graph-based. We note that the works cataloged as others did not have a discernible pattern beyond using a document-level resolution. [96] proposed the Connect the Dots algorithm to extract temporal chains of documents (i.e., timelines). In particular, they use an optimization approach that seeks to maximize the overall coherence of the timeline. Coherence measures the smoothness of a storyline, a coherent story should not have drastic changes in content or topic. To implement this metric, they propose an approach based on word influence-a measure of word relevance computed through random walks on a word-document graph-and word activations-which measure whether a specific word is active at a given point in the storyline. To extract the story chains, they used linear programming to maximize coherence subject to structural and temporal constraints. However, since linear programming provides non-integer solutions, it required additional heuristics to find the best chain by defining a rounding method. The linear programming approach used in the original Connect the Dots implementation was computationally expensive. Thus, Shahaf and Guestrin [97] proposed a new method to reduce computational costs and avoid the approximate solutions from the linear program. In particular, they used a best-first search algorithm based on an extension heuristic-given a chain of documents, adding a new document to the chain will at most keep the same level of coherence-and the original linear program to individually evaluate each chain.
## (s20) Connect the Dots Approaches. Linear Representations Shahaf and Guestrin
(p20.0) Expanding upon the Connect the Dots method, Zhu and Oates [135] propose an algorithm to extract story chains from newswire articles that connect two user-defined endpoints based on the following characteristics: relevance (the articles on the chain should be relevant to the endpoints), coherence (the transition between events should be smooth), low Furthermore, the model adds a named entity bias that assigns a higher weight to named entities compared to other terms. This is modeled through a co-occurrence frequency matrix for entity pairs, which is then used to compute a relevance score for each document in the data set based on the named entities. In turn, these elements are used to modify the cluster and document weights in the correlation graph.

(p20.1) Camacho Barranco et al. [18] propose a storyline extraction algorithm that takes a set of user-defined articles as a seed and generates a timeline of articles based on a series of evaluation metrics. First, the authors propose a temporal criterion to filter candidate documents based on a range between the latest publication date of the seed articles and a maximum threshold away from the earliest publication date of the seed articles (i.e., in the interval [ min − ℎ ℎ , max ]).

(p20.2) Next, there is a topical criterion that measures how much a candidate article can deviate from the seed articles based on KLD and LDA topics. Having defined their basic framework, the authors then formalize an optimization problem to extract the storylines by selecting article connections based on different criteria: incoherence, similarity, overlap, and uniformity. Incoherence is based on the average pairwise Soergel distance between documents-measured using TF-IDF information for the entities of the document-with a temporal factor to penalize temporally distant articles.

(p20.3) Similarity is used as a penalty factor to enforce diversity in non-adjacent articles of the storyline, implemented as a negative exponential factor based on the Soergel distance. Both of these metrics are weighted by a relevance factor of the documents and are smoothed using modified Gaussian distributions to measure event overlap. Next, an overall overlap factor for the storyline is computed, assigning a penalty based on the difference between publication dates and a user-defined threshold. The overlap factor ensures that the breakpoints occur at sufficiently distinct dates. The uniformity penalty seeks to avoid the case where the optimal solution selects purely irrelevant events as optimal by penalizing uniform weights. The objective function to minimize consists of the sum of the product between incoherence and similarity, multiplied by the overlap and uniformity penalties.

(p20.4) Graph-based Representations Metro Maps [98,99] are an extension of the Connect the Dots approach that represents more than a single storyline using a directed acyclic graph of events. In particular, the metro maps method is a structured summarization approach that captures the evolution of multiple stories and their interactions. The stories are represented using a metro map metaphor, where each metro line represents a story and stations represent key events.

(p20.5) Metro lines intersect in specific stations, representing how storylines connect with each other. This representation is extracted by solving an optimization problem. In particular, the goal is to maximize connectivity, subject to coverage and coherence constraints. Coverage is computed based on how well specific terms or keywords are represented in the selected events and is defined using a submodular function that encourages diversity (e.g., if a term is already covered, adding a document that covers it provides little extra coverage). These keywords depend on the specific corpus or domain of application. Coherence is defined following Shahaf et al.'s previous work [96,97]. Finally, connectivity is defined as the number of stories that intersect which is used to ensure that the final metro map is connected. The optimization problem is solved in phases. First, a series of coherent candidate metro lines are selected based on a divide-and-conquer approach, which constructs long lines from shorter ones and encodes them in a graph. Then, the method extracts a set of coherent lines that maximize coverage using an approximation algorithm based on the submodularity of the coverage function (otherwise finding these lines is an NP-hard problem). Finally, connectivity is increased using a local search approach that substitutes lines without sacrificing coverage.

(p20.6) Similar to the metro maps metaphor, the Narrative Maps model [51] provides a framework to extract and represent narratives based on a route map metaphor. The narrative and its stories are shown as a series of routes through landmarks, which represent the events. In computational terms, the narrative is modeled through a directed acyclic graph of events. The events are represented through neural embeddings of article headlines. The graph is extracted by solving an optimization problem defined following a linear programming formulation similar to the Connect the Dots approach. The optimization problem is based on maximizing coherence subject to coverage constraints. Coherence measures how much sense it makes to connect two events together and is defined as the geometric mean of the content similarity of events-using cosine or angular similarity-and their topical similarity-based on JS similarity of their topic distributions based on clustering. Coverage is measured by the average percentage of topical clusters covered by the selected events based on their topic distributions. Once the optimal map has been found, the main storyline is extracted by normalizing the coherence values of the edges into probabilities and finding the maximum likelihood path.
## (s21) Others. Linear Representations
(p21.0) Guha et al. [40] propose an event threading approach based on a graph decomposition method that generates document timelines. In particular, they propose decomposing a directed acyclic graph into disjointed node paths that ensure that as many nodes as possible participate in at least one path (i.e., they

(p21.1) seek to maximize a notion of coverage). The first step is to construct the graph, they propose doing this based on important terms (or even entities) in the document collection and their co-occurrence. Furthermore, documents are modeled following a bag of words approach, although the method is also designed to handle TF-IDF representations.

(p21.2) Once the graph is constructed, the next step is to solve the event thread extraction problem. To do this, they propose three formulations: an exact algorithm, a maximum approach, and a dynamic programming approach. The first method is an exact algorithm based on minimum cost flow, which has a high computational cost and is impractical. The second is an approximation algorithm based on maximum matching in bipartite graphs that solves the thread extraction problem for a fixed maximum size. The third method is based on an approximation algorithm that uses dynamic programming to solve the thread extraction problem for a range of thread sizes.

(p21.3) Laban and Hearst [56] present newsLens, a system to build and visualize long-ranging news stories. In particular, their system groups news articles based on their topics-based on a graph clustering approach-and then selects a sample of headlines from salient dates-based on the frequency of publications. In more detail, the first step in their extraction approach is to construct a keyword graph for a starting time period using TF-IDF representations of the articles. Next, a local topic graph is created based on a user-defined threshold for the number of shared keywords between articles. After the initial time period, a sliding window approach with a user-defined length is used to handle the rest of the data. For each time period, a local topic graph is created and compared with the graph from the previous period to check for three types of relationships: linking (connecting a topic from the current graph to a pre-existing topic), splitting (dividing a pre-existing topic into new topics in the current period), or merging (combining separate topics from the previous step into a single one of the current period). However, this approach is not able to handle stories that have long-time gaps between publications. To handle these cases, the content similarity of non-overlapping stories is analyzed and merged if above a specific threshold. Afterward, their method assigns a name to the storyline by extracting noun phrases from the news articles and scoring them based on multiple criteria (e.g., length, type of noun, abstractness, and frequency). Finally, salient dates are selected based on local frequency changes, and representative headlines are sampled randomly from these dates to generate the final timeline visualization.
## (s22) Manuscript submitted to ACM
(p22.0) Graph Representations Uramoto and Takeda [112] proposed a graph-based approach to model the relationships between news articles. In particular, they use a directed graph based on temporal ordering and event similarity. This is the earliest article that fits with our definitions of event-based narrative representations for news narratives that we found. In particular, the authors use the concepts of genus and differentia words. For adjacent articles, genus words are computed using the intersection of their word sets and represent already known information in the story. In contrast, differentia words are built from the set difference between the articles (in temporal order) and represent new knowledge in the story. Thus, differentia words are more important when trying to find coherent sequences of articles. The events are represented with a variation of TF-IDF that assigns more weight to differentia words.
## (s24) Event Threading and Evolution.
(p24.0) Nallapati et al. [76] use a directed graph model to represent to capture the structure and dependencies of events in a news topic. They call this extraction process event threading. They represent each event as a cluster of news articles. Event threading is a supervised method that consists of two phases: clustering documents and modeling dependencies. The clustering process starts with a cluster for each document in the data set and merges them iteratively based on similarity until the similarities fall below a predefined threshold. The authors evaluate three types of cluster similarity on the average link, complete link, or single link of the clusters based on document similarities. Document similarities are based on content similarity (e.g., cosine similarity), common locations, and common entities. Furthermore, there is an exponential decay term based on the temporal distance to penalize larger temporal distances between documents. Next, dependency modeling uses surface-level features of the document clusters, such as word distributions and time-ordering of the news articles. Based on this information, the authors propose several link extraction criteria (complete-link, simple threshold, nearest parent, best similarity, and maximum spanning tree). These approaches rely on temporal order, similarity information, or structural information.

(p24.1) SToRe (Storyline-based Topic Retrospection) is a topic retrospective system [63][64][65] that extracts the main storyline from a given news topic and provides a summary of the topic based on this storyline. In particular, the extraction process consists of four phases: event identification, topic structure identification, main storyline construction, and storyline-based summarization. In the event identification phase, similar news articles will be clustered together to represent a single event using self-organizing maps. In the topic structure identification step, the events are linked together based on whether their similarity exceeds a specific threshold. To compute similarity, the events are represented with a vector of term weights using the concepts of genus and differentia words [112]. Then, cosine similarity is used to compare the event vectors. Next, in the main storyline construction step, an MST is extracted from the constructed topic structure. The MST is based on the relevance of each event with respect to the topic. The MST is used to generate a timeline of events, and it is further extended with small side branches of other relevant events based on a specific threshold. Finally, in the storyline-based summarization, a summary is generated for each event based on the news articles contained in its cluster using accumulated weight summary [39].

(p24.2) Manuscript submitted to ACM Yang et al. [126,127] use directed acyclic graphs to represent the evolution of events in online news. They call their approach event evolution graphs, which represent temporal and causal relationships between events. Events are defined as sets of news articles and are represented as the average of the TF-IDF vectors of each article they contain. We note that the proposed method assumes that events and their corresponding articles are already computed. In practice, this would require a clustering step before constructing the graph. These events are linked together based on their similarity and a user-specified threshold, which is computed based on content similarity (e.g., cosine similarity), temporal proximity, and document distributional proximity (which penalizes bursty periods with many articles about the same event). The latter two terms are represented through exponential decay factors. Furthermore, users are able to reduce the temporal granularity of the event evolution graph, which merges specific events that occur in short time frames.

(p24.3) Qiu et al. [87] propose another event evolution graph extraction method. Their construction method follows an iterative approach based on content similarity and temporal order. In particular, documents are first grouped into clusters using the OHC method [88] in the first time period, which gives rise to the initial events. Next, the PRAC method [89] is used to build classifiers and determine whether the documents of the next time period are continuations of a cluster identified in the previous period. If so, a new event node is created using the identified cluster as its parent. This process is repeated until the last time period. Next, twigs-paths that die before the end of the timeline-are removed based on a user-set tolerance, and equivalent event nodes are merged to reduce graph complexity.

(p24.4) TSCAN (Topic Summarization and Content ANatomy) [20,21] is a method to analyze news data that produces a global summary and constructs an event evolution graph. We focus on the event graph component of this method.

(p24.5) First, news articles are grouped into themes obtained through a matrix factorization approach with TF-IDF document representations. Next, the news articles of each theme are temporally segmented using an energy value threshold based on eigenvalues from the matrix representation. In practice, this generates clusters of documents based on frequency, which are associated with the nodes of the event evolution graph. The evolution graph is a directed acyclic graph,
## (s27) Content References
(p27.0) Another criterion to consider in news narrative extraction is the use of content references. As mentioned before, some news articles make explicit references to previous works in their body. Note that this differs from explicit date-based references discussed before, which rely on explicit temporal information. This approach also differs from general content similarity because of its goal of identifying specific references rather than global similarity.

(p27.1) Manuscript submitted to ACM One way to identify these references is to compare the lead of a news article with the additional information paragraphs of another article [108]. Other approaches identify references based on sentence co-occurrence without considering article structure [130]. Alternatively, a set of core features [17,48] (e.g., relevant keywords or main event descriptors) could be identified and used to detect references in other articles. Once identified, these references can be used to identify relevant events based on reference-based metrics (e.g., bibliographic coupling).

(p27.2) Temporal Features Temporal information, such as the temporal distance between events or specific date references, has been used. In particular, temporal distance is commonly used to penalize events that would otherwise be similar in content. For example, consider two articles describing separate protests in a city, one during the year 2000 and another

(p27.3) in the year 2010. These two articles would likely be very similar in terms of content, including both surface-level features and topic distributions. However, given the temporal separation between them, they would likely refer to different events. Thus, a common strategy is to define an exponentially decreasing term of the form 0 exp −Δ (or similar), where 0 and are pre-defined constants [47,48,66,67,76,117,124,126,127,130], although there are other approaches, such as kernels to perform temporal proximity projections [116,124] or overlap-based measures [20,21].

(p27.4) However, we note that the use of a temporal penalty is not always desired. Some events are continuations of stories that did not have anything new to report for a long time. For example, the investigation results of a flight accident might come much after the accident itself has been covered, leading to temporal gaps in story coverage [56,117]. Thus, it is necessary to distinguish between continuations and completely new storylines when the time gap is high enough.
## (s35) Narrative Structure
(p35.0) The choice of the core structure is an important aspect of narrative representation. Using a linear structure provides a simple approach to represent a narrative with a single storyline, but it does not appropriately model the nuances of narratives with multiple stories. In contrast, graph-based structures allow the modeling of different interactions between storylines (e.g., convergent and divergent stories) [51]. Linear representations are implicitly directed, but graph-based representations may or may not be directed. Directed graphs usually exploit the underlying temporal relationships to determine the direction of the connections between elements. When the connection between basic units is guided by temporal constraints it naturally gives rise to directed acyclic graphs. Directed acyclic graphs provide the most flexibility while also accounting for the temporal nature of a narrative. However, not all directed graph models are acyclic, as some use specific types of relationships that allow the creation of cycles (e.g., same-event relations).

(p35.1) A representation that falls between linear and fully graph-based representations is the tree-based representation [66,67,131,133,134]. Such models allow for more flexible structures than linear representations. In particular, they are able to model story divergence (i.e., multiple storylines splitting off from the root or other nodes). Unlike graph-based models, they are not able to model story convergence (e.g., two stories joining into a final event), as that would break the tree structure. Tree-based structures have not been deeply explored in the literature and could provide an intermediate approach between linear and graph-based representations in terms of complexity, allowing easier understanding by users while retaining some flexibility. However, the inability to model story convergence might limit their applications.
## (s40) Practical Applications
(p40.0) Event-based news narrative extraction has several practical applications beyond journalistic analysis tasks. Most of these applications seek to help with the issue of information overload in different contexts [101]. We briefly discuss some potential applications explored or mentioned in some of the reviewed works.
## (s41) Recent Trends and Open Challenges
(p41.0) Timeline Summarization Variations Recent works have proposed some variations on the traditional timeline summarization task. In particular, Duan et al. [28] proposed the comparative TLS task and Yu et al. [130] proposed the Multi-TLS task. These two works highlight the fact that simple linear representations of narratives are naturally limiting unless applied to the most simple of narratives. Thus, the creation of similar tasks to address some of the shortcomings of these representations is a natural progression. However, it raises the question of whether these extensions would benefit from borrowing elements from the methods that use more complex representations discussed in this survey. A natural extension would be to consider a graph-based representation that allows for multiple storylines and comparisons without further modifications. This approach would address both the comparative TLS and MLTS tasks.

(p41.1) In this context, we note that most of the reviewed articles with a sentence-level event resolution used a linear structure (see Table 1). The only exceptions were the disaster storyline extraction systems [131,133,134] with their local tree representation. However, these methods are designed with a specific news topic in mind-disaster news-and are able to leverage specific characteristics of the topic (e.g., the disaster moves over time). Thus, it would not be possible to directly adapt it to other types of news without addressing this issue.

(p41.2) Furthermore, we note that there are no inherent limitations to sentence-level representations that prevent them from being extended beyond linear narratives, which makes the lack of graph-based approaches an opportunity for future research. Finally, while we did not find such a suitable graph-based approach in the traditional news domain, there is one example from the social media domain-which has its own set of challenges in terms of narrative extraction-that can be found in Ansah et al. [5]. This work proposes a tree-based narrative representation with sentence-level event representation using tweets. This approach extends the traditional TLS by allowing divergent storylines to emerge instead of just a single timeline. Such an approach could be adapted to traditional news narrative extraction.
## (s42) Multi-resolution Methods
(p42.0) Currently, all the narrative extraction approaches that we reviewed work on a singular resolution level (sentences, documents, or clusters). Existing attempts at multiple resolution levels only change the scope of the data [100,101] (i.e., applying the method again on a new subset of the data), they do not seek to change the underlying event resolution. Another perspective corresponds to the multi-level presentations of disaster storylines by Zhou et al. and Yuan et al. [131,133,134], which use global and local levels to represent the narrative. However, the underlying event representation remains the same and no efforts have been made to make a model that handles multiple levels of event resolution. Developing models that provide a multi-resolution approach remains an open challenge.

(p42.1) Interactivity Most works on news narrative extraction provide surface-level interactions [100,101,106] such as re-arranging elements and changing the layout, showing details on demand (e.g., all details about a news article), zooming, or performing basic filtering, highlighting, and searching. However, there is still a need for better interaction models that give users more control and feedback when exploring and manipulating the narrative. Some models [96,97] allow more in-depth refinement by letting the user specify elements that need to be changed and then evaluating all possible replacement and insertion actions. Building upon this feature-based feedback, Shahaf et al. [98] designed a method to learn a personalized coverage function that can be optimized to find a personalized narrative.

(p42.2) Another approach by Bögel et al. [14] allows parametric interaction to modify the extracted graph in real time, helping the user understand how the narrative changes based on the parameters. However, this approach requires the users to understand the underlying model parameters. In this context, semantic interactions could be useful to aid users modify the model without deep understanding of the underlying parameters. Semantic interactions [119] are used in sensemaking applications to directly reflect the analytical thought process of analysts about data (e.g., by using information about how analysts organize documents or highlight text), as opposed to parametric interaction that manipulates model parameters (e.g., sliders and keyword weights). Thus, capturing a user model through semantic interaction could lead to a better narrative model.
## (s43) Misinformation in News
(p43.0) Recent works have highlighted the need for future work to model source bias, information validity, transparency, and credibility as an effort to model and counter misinformation [51,56]. Existing narrative representations could be enhanced by including additional attributes in their representations and extraction algorithms.
## (s44) CONCLUSIONS
(p44.0) This literature review focused on narrative extraction and its related tasks of representation and analysis, synthesizing findings from 54 studies and identifying recurring types of representational structures, extraction criteria, and evaluation metrics. We further analyzed the articles and identified a series of recent trends, open challenges, and potential research directions. In terms of limitations, we highlight the lack of benchmark data sets, the need for better evaluation metrics that are capable of handling complex narratives properly, the high computational costs of most methods, and the lack of standardized benchmark tasks for user-based evaluations.

(p44.1) In terms of open challenges, we note the need for better interaction models that allow users to explore the narrative with more control. Finally, we note that current models do not handle misleading or false content, a rising challenge as misinformation compounds with information overload to make understanding the information landscape even harder.

(p44.2) As with other literature reviews, this work has some limitations related to the inclusion and exclusion of relevant pieces of work. In particular, we used the Scopus and Web of Science databases as our initial sources. Previous studies have shown that Scopus and Web of Science are inclusive and extensive sources for literature reviews [33]. Regardless, multiple studies were not included in our initial results and thus we had to include them through other means, such as extracting relevant citations from reviewed works. Moreover, the choice of keywords might have caused some studies that use different terminology to not show up in our searches. 
