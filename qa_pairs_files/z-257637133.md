# A Survey on Causal Inference for Recommendation

CorpusID: 257637133 - [https://www.semanticscholar.org/paper/301b07ecba0864c5bad4039d6a0bc93687417443](https://www.semanticscholar.org/paper/301b07ecba0864c5bad4039d6a0bc93687417443)

Fields: Computer Science

## (s8) Recommendation Techniques.
(p8.0) RSs are usually classified into the following three categories [1,171]: content-based, collaborative filtering (CF), and hybrid. Content-based recommendation learns to recommend primarily based on comparisons across items' and users' auxiliary information [171], such as items' human-set tags, images, texts, and users' sex. Collaborative filtering recommender systems recommend items according to user/item historical interactions,
## (s12) Causal Recommendation
(p12.0) To address this issue, early approaches tend to predict the missing data directly [130] but have accentuated the problem of high bias [112,143]. Recently, many researchers have resorted to the propensity score ( ) in causality to recover the data distribution. For example, ExpoMF [74] first predicts the exposure matrix and then uses the exposures (i.e., propensity scores) to guide the model of the interaction matrix, which is inspired by the separation between propensity scores and potential outcomes in the PO framework. Similarly, Wang et al. [138] propose SERec to integrate social exposure into collaborative filtering. A refreshing work is that Wang et al. [144] aim to overcome the confounder issue with propensity score. They regard correlations among the interacted items as bringing indirect evidence for confounders and propose the deconfounded recommenders. They first build an exposure model to estimate the propensity score and then use this exposure model to estimate a substitute for the unobserved confounders, conditional on which the final outcome model (specifically in [144], a rating model based on matrix factorization) is trained. In addition, inspired by [24,59], Chen et al. [13] propose IOBM (Interactional Observation-Based Model)to estimate propensity score in interaction settings, which learns low-dimensional embeddings as a substitute for unobservable confounders . Specifically, it learns individual embeddings to capture the potential outcome information from specific exposure events. Based on individual embeddings, the interactional embeddings, which uncovers the hidden relationship among single exposure events and utilizes query context information to apply attention, are learned through the bidirectional LSTM model.
## (s19) IOBM [SIGIR'21]
(p19.0) Interactions between observations/clicks: are incorporated to predict propensity scores with the bidirectional LSTM model.  former originates from common causes, whereas the latter originates from common outcomes [23]. The former stems from the systematic bias introduced during the treatment assignment, while the latter comes from the systematic bias during the collection of units into the sample [18].
## (s22) Doubly Robust.
(p22.0) Doubly Robust (DR) [22,26,56,143] is another powerful and effective causal method account for the MNAR issue. To understand DR, let us consider the two common-used approaches to mitigate against MNAR: direct method (DM) [7] and IPS [114]. The former designs a model (linear regression, deep neural network, etc.) to directly learn the missing outcomes based on the observed data, which has low variance due to the advantage of supervised learning but suffers from high bias caused by unmet IID assumptions, denoted as [114]: where^( , ) is the estimated outcomes. The latter, though unbiased theoretically, often causes training losses to oscillate stemming from the inverse of propensity with high variance [134]. What DR does is to combine the direct method and IPS, which takes advantage of both and overcomes their limitations:

(p22.1) DR uses the estimated outcomes to decrease the variance of IPS. It is also doubly robust in that it is consistent with the policy reward value if either the propensity scores or the imputed outcomes are accurate for all user-item pairs [114,143].
## (s24) Causal Effect for Uplift. Uplift, in terms of the causal effect of recommendations, refers to the increase in user
(p24.0) interactions purely caused by recommendations. Typical evaluations of recommender systems regard the positive user interactions as a success, such as clicks, purchases, and high rates. However, these interactions may have remained even without recommendations, which can be illustrated by the conclusion of [124] that more than 75% of click-throughs would still occur in the absence of recommendations. Therefore, the industry looks favorably on the uplift as the recommendation metric in expectation of higher reward.

(p24.1) It is a natural application to introduce the causality concepts such as ATE and CATE for uplift modeling since the definition of uplift is a counterfactual problem and consistent with the objective of causal effect estimation [161,173].
## (s25) Causal Effect beyond Uplift.
(p25.0) There are some other impressive recommendation works with causal effect [8,84,107,136,163,169]. For example, [84] adapts a Bayesian model to infer the causal impact of new track releases, which may be an essential consideration in the design of music recommendation platforms. [169] minimizes the distance between the traditional attention weights in the recommendation method and the ITE to reflect the true impact of the features on the interactions. [107] and [8] frames causal inference as a domain adaptation problem and leverages ITE with a large sample of biased data and a small sample of unbiased data to eliminate the bias problems, which are described in more detail in 6.1.
## (s38) DICE [WWW'21]
(p38.0) Counterfactual inference with separate structures Fig. 15. Separate-learning-counterfactual-inference, a common pattern of SCM-based causal inference for recommender systems, learns causal effect with a separate structure or multi-task framework and performs counterfactual inference during testing. Though a popular tool, instrumental variable seems to find little application in recommender systems because of the difficulty of finding variables that satisfy the conditions of instrumental variables. As already cited above, Sharma et al. [124] utilize an instantaneous shock in direct traffic as an instrumental variable to evaluate the recommendation effect. Si et al. [126] propose a model-agnostic framework named IV4Rec that effectively decomposes the embedding vectors into two parts: the causal part indicating a user's personal preference for an item, and the non-causal part merely reflects the statistical dependencies between users and items such as exposure mechanism and display position,  [162] Intervention on the treatment MF, LightGCN, etc. Data insufficiency 2021 CauSeR [42].

(p38.1) Intervention on the treatment SR-GNN [153] Popularity bias in SBRSs 2021 MCT [135] Back-door criterion, CATE (self-designed) Disability employment 2021 DecRS [140] Intervention on the treatment FM, NFM [44] Bias amplification 2021 PDA [176] Intervention with users' search behaviors as the instrumental variable. More specifically, it modifies the traditional IV method, using the residual of the least square regression as the causal embedding instead of discarding it. The causal graph is illustrated in Fig. 17.
## (s40) GENERAL COUNTERFACTUALS-BASED METHODS
(p40.0) Some causal recommender approaches are established based on the general concept of counterfactuals, the world that does not exist but can be reasoned with some fundamental law and human intuition. In this section, we will introduce related strategies from the perspective of recommender issues they try to address, including domain adaptation, data augmentation, fairness, and explanation.  [157] "Minimum" counterfactuals (self-designed) 2021 CASR [147] "Minimum" counterfactuals NARM [69], STAMP [79], SASRec [60] 2021 CauseRec [170] Counterfactuals (self-designed, sequential recommendation) 2021 POEM [76] Counterfactuals GCN 2022
## (s41) Domain Adaptation
(p41.0) RSs are trained and evaluated offline with the supervision of previously-collected data, which usually suffers from selection bias and confounding bias. It results in a gap between the training goal and the true recommendation objective, and, therefore, a sub-optimal recommender algorithm. To address this issue, we hope to evaluate the training policy on the unbiased data, which is collected from the randomized treatment policy. However, uniform data is always expensive and small-scale. To take full advantage of the uniform data, researchers train the recommender systems with a small amount of unbiased data and a large amount of biased data, with the hope of learning the counterfactual distribution of the biased data, which is both a counterfactual problem and a domain adaptation problem.

(p41.1) [107] and [8] train recommender policies on biased and unbiased data, and add regulation terms to the loss function so that the distance of parameters between the two policies in the inspiration of individual treatment effect is controllable. [166] trains an unbiased imputation model to impute the labels of all observed and unobserved events in biased and unbiased data, and learns the final CTR model by combining the two data with the propensity-free doubly robust method. Further, [77] propose KDCRec (Knowledge Distillation framework for Counterfactual Recommendation)
