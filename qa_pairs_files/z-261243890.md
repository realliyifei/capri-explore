# Computation-efficient Deep Learning for Computer Vision: A Survey

CorpusID: 261243890 - [https://www.semanticscholar.org/paper/a87947f88519dba980d0f16cdfb78ed09a8e02f0](https://www.semanticscholar.org/paper/a87947f88519dba980d0f16cdfb78ed09a8e02f0)

Fields: Engineering, Computer Science

## (s5) Micro-architecture
(p5.0) The micro-architecture refers to the individual layers, modules, and neural operators of backbones. These basic components are the foundation for constructing deep networks. Many works seek to attain higher computational efficiency by improving them. Notably, these works usually serve as off-the-shelf plug-in components that can be employed together with other techniques.

(p5.1) 1) Split-transform-merge Strategy. Typically, deep networks consist of multiple successively stacked layers with dense connection, where all the input neurons is connected to every output neuron. Formally, ℓ-th layer f ℓ with inputs x ℓ−1 and outputs x ℓ can be expressed by

(p5.2) However, such dense layers tend to computationally intensive. To address this issue, researchers have proposed to replace the dense connection with particularly designed topologies [1,3,61], which dramatically reduces the computational complexity, yet yields a competitive or stronger representation ability. Among existing works, one of the most popular designs is the split-transform-merge strategy, as shown in the following (as a fundamental component, a residual connection [4] is added here):
## (s8) 3) Model Scaling.
(p8.0) On top of designing a single efficient model, it is also important to obtain a family of models that can adapt to varying computational budgets. An important principle for addressing this issue is compound scaling [29,82], which indicates that simultaneously increasing the depth, width and input resolution of a given base model will yield a family of efficient network architectures. Dollár et al. [137] further study how to design a proper model scaling rule in terms of the actual runtime. In addition, TinyNets [138] extend this idea to the shrinking of the model size.
## (s13) Efficient 3D ConvNets
(p13.0) The most straightforward approach to modeling temporal relationships may be introducing 3D convolutional layers [160,161], such that one can directly perform convolution in the space formed by frame height, width, and video duration. However, 3D convolution is computationally expensive, and many efficient backbones have been proposed to alleviate this problem.
## (s14) 1) Marrying 2D and 3D Convolution.
(p14.0) A basic idea is to avoid designing a pure 3D ConvNets, i.e., most of the feature extraction process may be accomplished by the efficient 2D convolution, while 3D convolution is only introduced at several particular positions. From the lens of macro-architecture, this goal can be attained by sequentially mixing 2D and 3D blocks, either first using 3D and later 2D or first 2D and later 3D [162,163]. At the micro-architecture level, the group-wise or depth-width 3D convolution can be integrated in to the transform module of 2D split-transform-merge architecture (Eq. (2)) [164,165].
## (s15) 4) Long/Short-term Separable Networks.
(p15.0) Another important idea is modeling long/short-term temporal dynamics with separate network architectures. An representative work in this direction is SlowFast [176], which incorporate a lower temporal resolution slow pathway and a higher temporal resolution fast pathway. Many recent works [172,177] further extend this idea.
## (s18) Point-based Models
(p18.0) A fundamental type of 3D geometric data structure is the cloud of 3D points, where each point is represented by its three coordinates. PointNet [186] is the pioneering work that leveraging deep learning to process 3D point clouds. It adopts point-wise feature extraction with shared MLPs to maintain the permutation invariance. PointNet++ [187] improves PointNet by facilitating capturing local geometric structures. On top of them, a number of works focus on how to aggregating local information effectively without increasing computational cost significantly. Representative approaches include introducing graph neural networks [188,189], projecting 3D points to regular grids to perform convolution [190,191,192,193], aggregating the features of adjacent points using the weights determined by the local geometric structure [194,195,196], and self-attention [197,198]. In particular, recent works have revealed that point-based models can achieve state-of-the-art computational efficiency with proper training and model scaling techniques [199].
## (s20) Multi-view-based Models
(p20.0) Multi-view projective analysis is another effective solution for understanding 3D shapes, where the 3D objects are projected into 2D images from varying visual angles and processed by 2D backbone networks [209]. This idea can be implemented for recognition [210,211], retrieval [212,213] and pose estimation [214]. An important challenge for these methods is how to fuse the multi-view features. Existing works have proposed to leverage LSTM [213] or graph convolutional network [210].
## (s27) Spatial-wise Dynamic Networks
(p27.0) It has been found that different spatial locations in an image contribute unequally to the performance of vision tasks [234]. However, most existing deep models process different spatial locations with the same computation, leading to redundant computation on less important regions. To this end, spatial-wise dynamic networks are proposed to exploit the spatial redundancy in image data to achieve an improved efficiency. Based on the granularity of adaptive inference, we categorize relative works into pixel level, region level, and resolution level.
## (s28) Pixel-level Dynamic Networks
(p28.0) A typical approach to spatial-wise adaptive inference is dynamically deciding whether to compute each pixel in a convolution block based on a binary mask [235,236,237]. This form is similar to that in layer skipping and channel skipping (Sec. 3.1), except that the gating module is required to output a spatial mask. Each element of this spatial mask determines the computation of a feature pixel. In this way, the mask generators learn to locate the most discriminative regions in image features, and redundant computation on less informative pixels can be skipped.

(p28.1) The limitation of such pixel-level dynamic computation is that the acceleration is currently not supported by most deep learning libraries. The memory access cost can be heavier than static convolutions, and the computation parallelism is reduced due to sparse convolution. As a result, although the computation can be significantly reduced, the practical efficiency of these methods usually lags behind their theoretical efficiency. To this end, researchers have also proposed "coarse-grained" spatial-wise dynamic networks [39,238], which means that an element of a spatial mask can decide a patch rather than a pixel. In this way, more contiguous memory access is realized for realistic speedup. Moreover, the scheduling strategies are also proven to have a considerable effect on the inference latency [39]. It is also promising to co-design algorithm, scheduling, and hardware devices to better harvest the theoretical efficiency of spatial-wise dynamic networks.
## (s30) Resolution-level Dynamic Networks
(p30.0) Most existing vision models process different images with the same resolution. However, the input complexity could vary, and not all images require a high-resolution representation. Ideally, low-resolution representations should be sufficient for those "easy" samples with large objects and canonical features. The early work [249] proposes to adaptively zoom input images in the face detection task. The recent resolution adaptive network (RANet) [217] builds a multi-scale architecture, in which inputs are first processed with a low resolution and a small sub-network. Large sub-networks and high-resolution representations are conditionally activated based on early predictions. Instead of using a specialized structure, dynamic resolution network [250] rescales each image with the resolution predicted by a small model and feeds the rescaled image to common CNNs.

(p30.1) Note that different spatial locations are still processed equally in the aforementioned methods. We categorize the relative works in this section since they mainly utilize the spatial redundancy of image inputs for efficient inference.
## (s32) Dynamic Recurrent Models
(p32.0) Different video frames are unequally informative. To this end, extensive studies propose to dynamically activate computation when updating the hidden state in recurrent models. For example, LiteEval [251] establishes two different sized LSTM [252]. In each time step, a gating module is used to decide which LSTM should be executed for processing the current frame. AdaFuse [253] dynamically skips the computation of some convolution channels, and these channels are filled with the hidden state from the previous step. Moreover, the numerical precision [254] and image resolution [255] of different frames can also be dynamically decided.
## (s33) Dynamic Key Frame Sampling
(p33.0) An alternative to skipping computation in recurrent networks is sampling key frames and then feeding the sampled frames rather than the whole video to a standard model. Reinforcement learning is a popular technique for training frame samplers [261,262,263].

(p33.1) A recent trend is simultaneously achieving dynamic inference from multiple perspectives. For example, AdaFocus and its variants [38,264,265,266] makes use of both spatial and temporal redundancy in video data. Dynamic architecture with 3D convolution [267] is also an interesting topic.
## (s35) Object Detection
(p35.0) Object detection aims to answer two fundamental questions in computer vision: what visual objects are contained in the images, and where are them [8]? The classification and localization results obtained by object detection usually serve as the basis of other vision tasks, e.g., instance segmentation, image captioning, and object tracking. The algorithms for object detection can be roughly categorized into two-stage (Sec. 4.1.1) and one-stage (Sec. 4.1.2). In the following, we will discuss them respectively from the lens of computational efficiency.
## (s38) 3) Transformer-based Methods. In recent years, N. Carion et al.
(p38.0) propose an end-to-end Transformerbased detection network, DETR [285]. DETR views detection as a set prediction problem, where the results are obtained based on several object queries. Deformable DETR [286] addresses the long convergence issue of DETR by introducing a deformable mechanism to self-attention.
## (s42) Others
(p42.0) In recent years, some new ideas have been proposed to facilitate efficient semantic segmentation. For example, processing deep features with self-attention layers [306,307,308], designing segmentation models with NAS [309,310,311], adjusting the architecture of the decoder conditioned on the inputs [233]. More recently, a considerable number of papers seek to design efficient semantic segmentation models on top of ViTs [312,313,314,315,316]. These works mainly focus on achieving a state-of-the-art performance with as less computational cost as possible.
## (s44) Two-stage Approaches
(p44.0) From the lens of efficiency, a notable milestone of deep-learning-based instance segmentation is the proposing of Mask R-CNN [318]. Mask R-CNN is developed by introducing mask segmentation branches on the basis of Faster R-CNN [272]. It enjoys high computational efficiency by directly obtaining the regions of interest from the feature maps. In contrast, MaskLab [319] improved Faster R-CNN by adding the semantic segmentation and direction prediction paths. To improve the accuracy of Mask R-CNN, MS R-CNN [320] predicts the quality of the predicted instance masks and prioritizes more accurate mask predictions during validation. PANet [321] introduces a path augmentation mechanism to facilitate the bottom-up information interaction of feature maps. HTC [322] proposes a hybrid task cascade framework to learn more discriminative features progressively while integrating complementary features in the meantime.
## (s45) End-to-end Approaches
(p45.0) Another liner of works focus on realizing efficient end-to-end instance segmentation. SOLO [45,46] achieves this by introducing the "instance categories", which assigns categories to each pixel within an instance according to the instance's location and size, thus converting instance segmentation into a pure dense classification problem. YOLACT [323] and BlendMask [324] propose to first generate a set of prototype masks, and then combines them with per-instance mask coefficients or attention scores. Inspired by SSD [41] and Reti-naNet [281], TensorMask [325] build an efficient sliding-window-based instance segmentation framework.
## (s58) Hardware-aware Model Design
(p58.0) As the practical latency of models can be influenced by many factors other than theoretical computation, the commonly used FLOPs is an inaccurate proxy for network efficiency. Ideally, one should develop efficient models based on specific hardware properties. However, hand-designing networks for different hardware devices can be laborious. Therefore, automatically searching for efficient architectures is emerging as a promising direction. Compared to the traditional NAS methods [31,414], this line of works can generate appropriate models which satisfy different hardware constraints and gain realistic efficiency in practice. For example, ProxylessNAS [54] establishes a latency prediction function based on realistic tests on targeted hardware, and the predicted latency is then directly used as a regularization item in the NAS objective. A similar idea is also implemented by MnasNet [53] to search for efficient models on mobile devices. The following works FBNet [159], FBNet-v2 [415] and OFA [416] have improved NAS techniques.
## (s63) Developing Task-specialized Models
(p63.0) In addition to the architectural advancements in backbone models, tailoring deep learning methodologies to specific computer vision tasks of interest has been demonstrated as crucial. Two research challenges of particular significance in this domain can be identified. Firstly, the exploitation of representations extracted by backbones to efficiently obtain task-specific features is essential, for example, multi-scale features for object detection and multi-path fused features for semantic segmentation. A potential solution to this challenge could involve designing specialized, efficient decoders (e.g., utilizing NAS [311,437]). Secondly, it is important to streamline the multi-stage design of visual tasks (e.g., two-stage object detection [273] and instance segmentation [318] algorithms) to achieve end-to-end paradigms with minimal performance compromises. Additionally, the removal of time-consuming components, such as non-maximum suppression (NMS) [8], is crucial. A promising area for future research may involve the development of an efficient, unified, and end-to-end learnable interface for a majority of prevalent computer vision tasks [438].
## (s65) Leveraging Large-scale Training Data
(p65.0) Contemporary large visual backbone models have exhibited remarkable scalability in response to the increasing volumes of training data [6], that is, the model's performance consistently enhances as more train-ing data becomes accessible. However, it is generally arduous for computationally efficient models with a reduced number of parameters to capitalize on this high-data regime to the same extent as their larger counterparts. For example, the improvements attained by pre-training light-weighted models on expansive ImageNet-22K/JFT datasets are typically inferior to those observed in larger models [6,7,74]. This challenge is similarly experienced by self-supervised learning algorithms, where the methods effective for larger models frequently produce limited gains for smaller models [440,441]. As a result, a propitious avenue of research involves the exploration of effective scalable supervised and unsupervised learning algorithms for light-weighted models, allowing them to reap the benefits of an unlimited amount of data without incurring the expense of acquiring annotations. Some recent works on novel training algorithms have started to preliminarily explore this direction [82,442,443,444,445].
