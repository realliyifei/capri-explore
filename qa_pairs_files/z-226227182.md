# Deep Learning in Computer-Aided Diagnosis and Treatment of Tumors: A Survey

CorpusID: 226227182 - [https://www.semanticscholar.org/paper/ed0c052a5e9d24042ed5d420d296d50c84394ff1](https://www.semanticscholar.org/paper/ed0c052a5e9d24042ed5d420d296d50c84394ff1)

Fields: Engineering, Computer Science, Medicine

## (s0) Introduction
(p0.0) Cancer is a leading cause of death and a notable public health problem worldwide. According to Global Cancer Statistics [1], by 2018, there will be an estimation of 18.1 million new cancer cases and 9.6 million deaths caused by cancer. Thus to diagnose early and treat compatibly becomes one of the most important research topics in medicine. Previously, people devote to the simple medical method to approach the above goal, which depends on the information obtained by the doctor's perception and the experiences gained by years. While the perception can be influenced by objective factors (e.g., sensory threshold, fatigue, and prior knowledge.) and the acquisition of experience often costs more time, and such experience is often subjective. With the tremendous development of artificial intelligence, considerable attention has been paid to plentiful applications based on artificial intelligence that was used for Computer-Aided Diagnosis and Treatment of Tumors because this technique could assist solve the above two issues. Since Hinton et al. [2] prove that traditional statistical methods are not necessary to extract features as long as computing resources are sufficient, deep neural networks have been asked to learn useful latent features from big data. After that, deep learning has become a new force in Computer-Aided Diagnosis and Treatment of Tumors.
## (s1) Classic Deep Learning Models and Improvements
(p1.0) This section reviews classic deep learning models which widely used in Computer-Aided Diagnosis and Treatment of Tumors. Thus to mainly introduce Convolutional Neural Network (CNN [3]), Fully Convolutional Network (FCN [7]), Region-CNN (R-CNN [4]) and their improved models.
## (s3) CNN
(p3.0) Convolutional Neural Network (CNN [3]) was widely used in medical tasks as the foundational deep learning method. The structure of CNN with details shows in Figure 1. There are three integral parts named the convolutional layer, the pooling layer, and the Fully Connected layer (FC). Followed by the pooling layer, there will be an activate function that could enhance the ability to fit nonlinear problems.

(p3.1) Stem from CNN's unique structure -the convolutional layer realizes the local region connection and weight sharing, the pooling layer achieves dimension reduction, and the fully connected layer implements the task of the classifier. There are four ways to improve the CNN except for exchange activation function.
## (s4) DeepMedic
(p4.0) DeepMedic is an efficient 11-layers deep, multi-scale, 3D CNN architecture, which is an improved model specific to brain MRI images from BRATS 2015 and ISLES 2015 [29]. Figure 2 is the structure of DeepMedic. The baseline of DeepMedic is a CNN, followed by Conditional Random Fields (CRF).

(p4.1) It proposes a solution with parallel convolutional pathways for multi-scale processing, which efficiently incorporate both local and contextual information and improves the segmentation results. At last, the author uses CRF to achieve space regularization.

(p4.2) The most valuable contribution of DeepMedic is densetraining, which can balance the distribution of training samples from different segmentation classes, which is a massive problem in medical datasets because, in clinical practice, there are many tiny objects. Meanwhile, DeepMedic could make a dense prediction over multiple adjacent pixels at one time, thus saving computing costs. In recent years, there are several works based on DeepMedic, which shows in Table 2. Segmentation [57], [58], [59], [60], [43] Prediction [58] DeepMedic is a trial variant of CNN that it focuses on the segmentation of medical tasks. Also, because of the original use for brain MRI, the most common application scenario is still the segmentation of brain MRI, which shows in Table 2.

(p4.3) The majority of the researches in the table is segmentation due to the improvement in the last layer. This structure makes the DeepMedic better in the brain's segmentation. Except for the work of Kamnitsas et al. [58], they predict the population survival using SVM after the specific lesion was segmented.

(p4.4) In general, DeepMedic's improvements to medical data are groundbreaking and widely used in brain tumor segmentation tasks, but its bright spot is also its shortcoming. That is, its applications are limited to brain segmentation. In this respect, u-net, which will be introduced later, breaks the stereotype that the improvement of the deep learning model based on medical data is just an appendage of deep learning and will not affect the development in the field of computer science.
## (s6) FCN
(p6.0) As an improved method, Fully Convolutional Network (FCN [7]) exchanged the fully connected layer into a deconvolution layer. The structure of the FCN is shown in Figure 3, which is an encoder-decoder model. The form of FCN provides a foundation for the future development of semantic segmentation. In this way, FCN allows end-to-end pixel-level classification, the original size of the feature map in up-sampling, and several roughnesses of the up-sampling. Above all, FCN can accept input images of any size and do well in medical image segmentation at medical tasks.
## (s7) U-Net
(p7.0) As the extension of FCN, U-Net is arguably the advanced deep learning model that improved based on medical data. U-Net inherits all advantages form FCN but improves the number of deconvolution layer and skip connection layer [8]. Also, it has a symmetrical U-shape shown in Figure 4. The left side of U-Net is a contractive path, which extracts features by convolution and max pooling. Also, the right side is an expansive path, which combines the feature map from the left side using concat and sampling the feature map.
## (s8) R-CNN Series
(p8.0) Region-CNN (R-CNN) series is a two-stage method that selects proposals on the image first and fixes bounding boxes based on the proposal. As a primitive model, R-CNN [4] is divided into three parts, finding the candidate box, using CNN to extract feature vectors, and using Support Vector Machine (SVM [76]) to classify feature vectors. Figure 5 shows the specific method, which locates 2000 candidate boxes of objects in the input picture and extracts feature vectors of images in each candidate box, next, classifies and identifies objects in each candidate box.
## (s10) In-Vitro Diagnosis (IVD)
(p10.0) In-Vitro Diagnosis (IVD) is the first stage of tumor diagnosis, which is mainly responsible for the detection and screening of tumor markers or tumor characteristics. Early detection of cancer often determines the prognosis of patients' quality of life or even life. It is the crucial reason why deep learning is needed at this stage. IVD uses three kinds of data, which will introduce as follow.

(p10.1) 1. Images or videos of cells in blood and tissue fluid generated from microscope to discover if there exists Circulating Tumor Cell (CTC). 2. Indicators in biophysics and biochemistry from Flow Cytometer (FCM) to discover the specified subset of cells. The main clinical problems at this stage are the early screening of tumors, identifying tumor stages and subtypes, monitoring the efficacy of therapy, and predicting prognosis of tumors. All of these medical tasks can be seen as a classification task in computer science. Of course, segmentation and object detection can also accomplish the above tasks if it is necessary. Now, with the development of CNN, there is a practical approach to solve the above problems in deep learning. Table 6 summarizes recent work for CNN in IVD. 3.1.1. Image data diagnosis in IVD In detection, the work of Falk et al. [67] is excellent by using U-Net, which enables non-machine-learning experts to analyze their data and could save manual annotation effort in a wide variety of quantification tasks. Also, this work supports single-cell segmentation with conditional adaptability. Furthermore, the datasets in this work (such as F1-MSC, F2-GOWT1, F3-SIM, F4-HeLa, DIC1-HeLa, PC1-U373, and PC2-PSC) are from the International Symposium on Biomedical Imaging (ISBI) Cell Tracking Challenge 2015. Figure 6 shows the pipeline of this work. Firstly, training the U-net on the local machine, a dedicated remote server, or a cloud service. After that, the adaptation of U-Net to newly annotated data by using transfer learning. This work performance well in follows tests.
## (s15) MRI diagnosis in ID
(p15.0) MRI has good discrimination of soft tissue and no ionizing radiation damage to the human body, so it is good at imaging tumors in the brain, bladder, rectum, reproductive system, and other parts.

(p15.1) In segmentation, we have to introduce the work written by Drozdzal et al. [66], which combines Fully Convolutional Networks (FCNs) with Fully Convolutional Residual Networks (FC-ResNets [93]) to segment medical images, such as electron microscopy (EM) image, CT of the liver, and MRI of the prostate. The results reveal that this model is working well in both 2D and 3D medical images, which means that it could achieve accurate segmentations on a variety of image modalities and different anatomical regions. Details are shown in Figure 10, which uses the FCN to obtain pre-normalized images, and then iteratively refined employing the FC-ResNet to generate a segmentation prediction.
## (s16) CT diagnosis in ID
(p16.0) CT is of high diagnostic value for tumors of the central nervous system, head and neck, chest and abdomen, and pelvic cavity. It is widely used in the diagnosis and treatment of computer-assisted tumors.

(p16.1) In segmentation, Guo et al. [70] employs U-Net which refined by Gaussian Mixture Model (GMM) and morphological operations to segment 3D pancreas tumor. To finish the morphological operations, the authors adopt a model named LO-GISMOS, which is a graph-based framework that translates geometric constraints of interacting surfaces and objects into graph arcs and the likelihood of segmentation surface positioning into graph node/arc costs. The details are shown in Figure 12, which combines U-Net (to integrate intra-slice and adjacent-slice contexts) and LOGISMOS (to regulate the 3D shape) for 3D tumor segmentation.

(p16.2) In prediction, Ardila et al. [91] built an end-to-end approach based on CNN for CT images, which outputs overall malignancy prediction for the case, a risk bucket score (LUMAS) and localization for predicted cancerous nodules. The pipeline shows in Figure 13, which contains three parts based on CNN. There is a full-volume model (to perform end-to-end analysis of LDCT), cancer Region of Interest (ROI) detection model (to detect 3D cancer candidate regions), and cancer risk prediction model (to operate on outputs from above two models). This work achieved an outstanding result, about 94.4% area under the curve on National Lung Cancer Screening Trial cases (NLST).
## (s23) Contour on PET
(p23.0) Ground Truth Figure 14: The pipeline of the work from Zhong et al. [71] which designed two independent 3D U-Net for PET and CT to produce high-quality regions costs for subsequent graph-based co-segmentation in lung's dataset. work, the researchers focus on lung cancer PET-CT and generate high-quality voxel-level tumor confidences that were further used to locate the tumor boundary with the powerful cosegmentation model.

(p23.1) In prediction, Zhang et al. [52] propose a CNN to predict the pancreas tumor growth pattern that incorporates both the population trend and personalized data. Figure 15 shows the structure. The deep features extracted by CNN are combined with the time intervals and the clinical factors to feed a process of feature selection and after that, selected a robust feature subset by the Support Vector Machine Recursive Feature Elimination (SVM RFE). Finally, a SVM predictive model was used to predict the tumor's spatiotemporal growth and progression. 
## (s24) Mammography diagnosis in ID
(p24.0) Now, mammography only uses for breast screening. Thus most of the researchers focus on the detection and classification of early cancer. As Figure 16 shown, Ribli et al. [81] adopt Faster R-CNN by optimized both the object detection and classifier part to detect and classify malignant or benign lesions on mammogram without any human intervention. Also, the mammogram images come from the public INbreast database. This research could realize computer-aided detection in mammographic screening.
## (s25) Ultrasound (US) diagnosis in ID
(p25.0) Ultrasound (US) is the most widely used tumor screening method, thanks to its non-radioactive, multi-directional crosssectional imaging, real-time dynamic, easy to operate, fast, and other characteristics. However, ultrasound needs the assistance of deep learning because of its disadvantages of lack of specificity, focus on local areas, and is easily influenced by doctors' experience.

(p25.1) For instance, Li et al. [77] employs Faster R-CNN to add a spatial constrained layer before the output layer of CNN, as the pipeline is shown in Figure 17, which concatenated and normalized the conv3 and conv5 layer and then add a spatial constrained layer before the output layer. This work is more suitable for thyroid papillary carcinoma detection in ultrasound images, and the property of classification is better than SVM. This work could improve the ability of screening cancer in thyroid papillary carcinoma images fast.

(p25.2) As a summary, Image Diagnosis runs through the whole process of tumor diagnosis and treatment. Its data is easy to obtain and the data is huge. It is an essential part of the current research on computer-assisted tumor diagnosis and treatment thanks to the rapid development of computer vision. As can be seen from this section, the research on individual organs (especially large organs or organs that are easy to inspect) has reached a saturation point, and the future trend is nothing more than improvement in accuracy and speed. However, targeted studies are still needed for small organ tumors, such as pancreas and ovary. These small organ tumors are high malignancy and a short course of the disease (which means the data is scarcity). Besides, there is still little research on multi-modal data (although such multi-modal databases like TCIA has existed).
## (s31) Inception v3
(p31.0) Improved model for CNN Figure 19: The pipeline of work from Coudray et al. [96] which mainly including data preprocessing and model training by CNN. the structure of this work. Also, the author validated their work on independent datasets of frozen tissues, formalin-fixed paraffin-embedded tissues, and biopsies obtained at the New York University (NYU) Langone Medical Center. Furthermore, the trained network in this work could predict gene mutations using images as the only input in LUAD, which is meant to assist pathologists in the detection of cancer subtype or gene mutations. The Average area Under the Curve (AUC) of classification is 0.97, and AUCs of prediction is from 0.733 to 0.856. In prediction, Bychkov et al. [53] combines CNN and Long Short-Term Memory (LSTM [10]) to predict colorectal cancer outcome based on images of Haematoxylin and Eosin (H & E) stained Tumour Tissue Microarray (TMA), which was shown in Figure 20. Also, this work can directly predict five-year disease-specific survival without any intermediate tissue classification. This work shows that extract more prognostic information from the tissue morphology of colorectal cancer than an experienced human observer.
## (s38) From Data Types
(p38.0) The data types in recent researches seem to be quite comprehensive, but more often than not, people tend to focus on the Image Diagnosis data. Even this tendency extends to a few kinds of medical images, such as MRI and CT. Histology images and cancer-associated genomic regions have been partially concerned. However, some problems limit the progress of the research. For individual histology images, it can be up to 2G in size, which requires advanced servers for researchers. Also, lots of primary hospitals have no conditions for genetic testing. Besides, the data from stages of In-Vitro Diagnosis (IVD) and Treatment Plan have the same predicaments -there is not exist a sophisticated system to store the data of tumor diagnosis and treatment in bulks.

(p38.1) Meanwhile, the multi-disciplinary collaboration of medical tasks makes the multi-type datasets of the same task have a strong correlation, and taking data groups as research objects will gradually become a trend. Such as the integration of genomics and histopathology mentioned in this review [96].
## (s42) Adversarial Study
(p42.0) Given the existing problems in tumor diagnosis and treatment in the whole industry, this paper has made a prospect and put forward the vacancy of existing research. However, in essence, some critical studies have never been done before, and it is worth noting. Adversarial study is one of such field.

(p42.1) Any research in deep learning is bound to encounter the question of whether the results are credible. In such an information age, information security and ethics are worth discussing. It remains to be seen whether researchers will be able to achieve consistent results in simple information confrontation experiments in the field of tumor diagnosis and treatment, not to mention that the diagnosis and treatment of tumors are vital and should be treated with caution. As far as we know, this field is almost blank except the recent work [26], which is a very terrible blank, but also a blank with infinite opportunities.

(p42.2) As a summary, Computer-Aided Diagnosis and Treatment of Tumors are highly cross-disciplinary that ask researchers know medicine and computer science, but few people are proficient in both, and not everyone can find a partner with expertise. This problem has led to a situation in the field where computer scientists do not know how to make medical advances in combination with specific conditions, and doctors do not know which deep learning methods can better achieve their goals. It is also the reason why a large number of studies have been conducted which cannot guide clinical tumor treatment. For now, this paper could quickly guide doctors to choose a proper deep learning method, and computer researchers may learn more about tumor diagnosis and treatment. In clinical practice, the international standard for tumor diagnosis and treatment refer to the National Comprehensive Cancer Network (NCCN) Clinical Practice Guidelines in Oncology. (see: https://www.nccn.org/professionals/ physician_gls/default.aspx). If researchers want to further improve the fit between their works and the medical task, clicking on it would be a good start. with sparse transformers, ArXiv Preprint ArXiv:1904.10509.
