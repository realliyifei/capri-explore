# A Review of Causality for Learning Algorithms in Medical Image Analysis

CorpusID: 249626188 - [https://www.semanticscholar.org/paper/b732f91b7b0a317d8ee9d5c7b6efe9801442a106](https://www.semanticscholar.org/paper/b732f91b7b0a317d8ee9d5c7b6efe9801442a106)

Fields: Computer Science, Medicine

## (s4) Causal Inference in medical imaging
(p4.0) While causal discovery using medical images is limited to some applications involving f-MRI scans, causal inference is significantly more active as an area of research. Highlighting its importance, (Castro et al., 2020a) argue that causal inference can be used to alleviate some of the most prominent problems in medical imaging. They argue that acquisition and annotation of medical images can exhibit bias from the annotators and curators of the datasets. As such, causality aware methods can learn to account for such biases and reduce their effects. Moreover, as the training datasets represent a limited population with specific characteristics, medical imaging algorithms are susceptible to population, selection and prevalence biases if not properly controlled for these variations. These biases could for example arise when an algorithm is trained by a vast majority on data that come from a given geographical region X, then it implicitly learns the prevalence of diseases for that group; if it is deployed in a different region with a population that is characterized by different genotype and phenotype characteristics, the biases that the algorithm has learned could lead to mis-or under-diagnosis of diseases.

(p4.1) In our exploration of the use of causal inference in medical imaging literature we identified five main sub-fields of research that leverage causal insights. We found that causal inference is overwhelmingly used to contribute to fairness, safety and explainability of the existing approaches. There are some albeit limited uses in generative modeling of medical images, domain generalization and out-of-distribution detection. As we will expand in the following sections, we believe these areas are ready for more applications of causal inference.

(p4.2) We note that all the works mentioned below have causality as a key part of their proposed methodologies. We extended our survey not only to peer reviewed publications but also to notable preprints that appear to have produced significant discussion in the machine learning medical imaging community.
## (s10) Discussion and Conclusion
(p10.0) We have identified a wide range of possible applications of causality in medical imaging. However, we have not yet observed an enthusiastic uptake of causal reasoning and causal considerations from the community. We believe that introducing causal reasoning in medical imaging applications would benefit both the performance and robustness of the algorithms but most of all would provide the required scrutiny and security that doctors demand from their tools. A model that is able to be probed causally and does not operate as a black box can be trusted more easily by healthcare professionals since they will be able to understand its inner workings; enabling safe human-machine decision making (Budd et al., 2021). Moreover it would ameliorate the legal hurdle of accountability that developers of medical ML applications face, as we would be able to explain the processes and logic of the models. As machine learning algorithms in medical imaging make their way towards clinical practice we hope to see more causal machine learning solutions being trialed.

(p10.1) Furthermore, as medical and medical imaging applications move away from large hospitals, towards first responders, remote community doctors and even astronauts, we need tools that are robust to extreme circumstance differences. Causally enabled ML has shown great promise in its ability to adapt as it does not depend on correlations that might or might not exist in the new domain, but, like humans, it taps into the underlying causal relationships that are very hard to shift. That being said, causal ML is not a panacea; our theoretical capabilities restrict absolute certainty to a limited number of well defined conditions that Causal Diagrams have to obey. When shifting focus to real life scenarios, we are forced to accept trade offs and be considerate about the limitations of our approaches.

(p10.2) Causally enabled ML for medical imaging is a very promising research field that the authors of this survey believe is vital for next generation of tools for medical imaging. We are very excited about what the future of this research might bring and we hope to have inspired researchers and practitioners with this review to consider the causal ML route for medical imaging research and application development.
