# OVERVIEW OF TASKS AND INVESTIGATION OF SUBJECTIVE EVALUATION METHODS IN ENVIRONMENTAL SOUND SYNTHESIS AND CONVERSION

CorpusID: 201646191 - [https://www.semanticscholar.org/paper/0f47ae1f2852c6d06305ef2c4bae00e3d0b6255a](https://www.semanticscholar.org/paper/0f47ae1f2852c6d06305ef2c4bae00e3d0b6255a)

Fields: Engineering, Computer Science, Environmental Science

## (s2) Environmental Sound Synthesis Using Sound Event and Scene Labels
(p2.0) When providing movies or games with background sounds or sound effects, we need to listen to many sounds in a large sound database and select the most suitable one for the scene or sound event, which is a time-consuming part of movie or game production. To address this issue, a statistical method for synthesizing an environmental sound well representing a sound event or scene, which utilizes the sound event or scene labels as below as an input, has been proposed [10]. Figures 1 and 2 illustrate the processes of environmental sound synthesis using the sound event or scene labels as the inputs of the systems, where we call these research tasks sound event synthesis (SES) and sound scene synthesis (SSS), respectively. Another issue is that the construction of an environmental sound dataset is very time-consuming compared with the construction of a speech or music dataset [11]. In recent studies, environmental sound analysis based on deep neural networks has required a large number of sounds to achieve a reasonable performance. To overcome this problem of a shortage of environmental sound datasets, SES and SSS can be applied for data augmentation in environmental sound analysis.

(p2.1) To generate environmental sounds by a statistical approach, Kong et al. [10] have proposed a method of environmental sound synthesis utilizing a conditional SampleRNN [12] with sound scene labels represented as one-hot vectors.

(p2.2) A method of evaluating synthesized environmental sounds is an important subject in this research area. When we apply SES or SSS to data augmentation for sound event detection or acoustic scene classification, it is reasonable to evaluate the methods of SES or SSS via their event detection or scene classification performance with augmented data. On the other hand, in the case of utilizing the sound synthesized by SES or SSS itself, it has not been investigated in detail how the synthesis method should be evaluated. In this paper, we focus on the subjective evaluation method for environmental sound synthesis in Sec. 3.
## (s3) Environmental Sound Synthesis Using Onomatopoeic Words
(p3.0) The SES and SSS discussed in Sec. 2.1 control synthesized environmental sounds only using the sound event or scene labels; thus, they cannot control synthesized sounds without types of sound or scenes. For instance, when synthesizing the sound of a car horn, it cannot be determined in advance whether SES will synthesize a horn sound with a continuous high tone (e.g, peeeeeeeeee) or one with an intermittent low tone (e.g, beep beep beep). To control synthesized environmental sounds more finely, we can apply environmental sound synthesis using onomatopoeic words as an input of the system, as shown in Fig. 3. For SES using onomatopoeic words, Ikawa et al. [16] have proposed a method that converts onomatopoeic words to wave forms of environmental sounds using an encoder-decoder model. 
## (s5) Environmental Sound Synthesis/Conversion Using Multimedia
(p5.0) Some researchers have addressed environmental sound synthesis and conversion using multimedia information as an input such as images. For instance, Zhou et al. have proposed a method for synthesizing environmental sounds from images that is based on Sam-pleRNN [5].
