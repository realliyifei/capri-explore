# Dietary Patterns and Cancer Risk: An Overview with Focus on Methods

CorpusID: 258974619 - [https://www.semanticscholar.org/paper/f887380f0a2c3ae66f4ceda349a7a7732e6c99de](https://www.semanticscholar.org/paper/f887380f0a2c3ae66f4ceda349a7a7732e6c99de)

Fields: Medicine, Agricultural And Food Sciences

## (s0) INTRODUCTION
(p0.0) There were an estimated 18.1 (9.3 in men and 8.8 in women) million new cancer cases and 9.9 (5.5 in men and 4.4 in women) million cancer deaths worldwide in 2020.Breast and lung cancers were the most common cancers worldwide (12.5% and 12.2% of the total number of new cases diagnosed in 2020, excluding non-melanoma skin cancer), followed by colorectal cancer (10.7% of new cases).With the burden growing in almost every country, preventing cancer is one of the most significant public health challenges of the 21st century.It has been estimated that 30-50% of cancer cases could be prevented by tackling risk factors relating to diet, nutrition, and physical activity [117].According to the World Cancer Research Fund Prevention Recommendations, changing dietary patterns (i.e., eating whole grains, vegetables, fruit, and limiting consumption of red and processed meat, fast-food products, and sugary drinks), reducing alcohol consumption, increasing physical activity, and achieving and maintaining a healthy body weight can impact people's likelihood of developing cancer and other noncommunicable diseases over their lifetimes [19].Tailored statistical methods are essential to support the collection of a sound evidence base for cancer prevention.

(p0.1) Traditionally, research in nutritional epidemiology has focused on specific foods/food groups or single nutrients.However, dietary determinants of non-communicable diseases differ from those of undernutrition and nutrient deficiencies, which result from insufficient intake or absorption of a particular nutrient.Multiple dietary determinants act interactively and cumulatively affect disease risk over decades.In addition, when one component of the diet changes, it is typically substituted by another [118].Consequently, nutritional epidemiologic investigations of non-communicable diseases have integrated the single-nutrient and the singlefood approaches (named single-component approach) with the overall diet evaluation through dietary patterns.Dietary patterns can be broadly defined as the foods, food groups, or nutrients included; their combination and variety; and the frequency and quantity with which they are habitually consumed.

(p0.2) Dietary patterns can be identified by using evidencebased investigator-defined approaches (also named "a priori" dietary patterns) or by using data-driven approaches, which rely on either response independent (also named "a posteriori" dietary patterns) or response dependent (also named "mixed-type" dietary patterns) multivariate statistical methods.A priori dietary patterns express adherence to benchmark diets, including those suggested by dietary guidelines, using simple mathematical expressions, like sums or ratios.A posteriori dietary patterns are mostly derived with variants of principal component analysis (PCA), exploratory factor analysis (EFA), or cluster analysis (CA).The mixed-type dietary patterns -which combine elements of both previous approaches -are traditionally identified by using the reduced rank regression, which directly allows them to explain the most variability in (intermediate) response variables [67,68,89,85,33,92,70,47,135,107].
## (s1) RELIABLY MEASURE DIETARY INTAKES
(p1.0) Measuring diet in free-living populations is challenging.Diet is a complex exposure, with numerous and (sometimes) poorly characterized components consumed in varying amounts and combinations by individuals.Diet is also a time-varying exposure, with dietary habits and food composition changing over time [104].
## (s5) Study Designs in Nutritional Epidemiology
(p5.0) One of the major remarks against nutritional epidemiology is that it mostly relies on observational data, which is deemed inferior to experimental data in determining causality.While randomized controlled trials (RCTs) with hard clinical endpoints occupy the highest position in this hierarchy, RCTs are usually not the most suitable/feasible study design to answer nutritional epidemiologic questions regarding long-term effects on health/disease (e.g., cancer) of specific foods or nutrients [104].Unlike classic drug trials, in RCTs of dietary interventions typically [104,108]:

(p5.1) • blinding is not feasible, leading to the possibility that the intervention effect is due to knowledge of treatment assignment instead of the dietary component of the intervention; • higher dropout rates are more likely, especially if the intervention is very demanding, including if it lasts for long periods.When substantial, this high dropout will reduce power in the presence of random losses to followup.But, if the dropout is differential to treatment and outcome, it may also introduce systematic bias in the effect estimate, usually in unpredictable directions; • insufficient adherence of participants to their assigned intervention (i.e., noncompliance) is a major issue, which may become severe in trials of longer duration; • choosing the control group, when present, is more complicated.Indeed:

(p5.2) 1. when one control group is selected, this group is asked to follow its usual diet; when more than one control group is selected, different dietary regimens are compared, and each is designed to differ from the others in some respect; this makes results interpretation more difficult in dietary interventions trials;

(p5.3) 2. since decreasing the intake of one nutrient/food usually entails increasing the intake of another nutrient/food to compensate for the reduction in calories in isocaloric trials, the choice of the comparison group can influence the observed effect of dietary intervention, further complicating its interpretation.

(p5.4) In the absence of evidence from large RCTs on hard endpoints, nutritional epidemiologists typically rely on prospective cohort studies, the strongest available observational design, to infer causality.Being prospective, cohort studies are less affected by the typical biases (i.e., reverse causation, recall bias, and selection bias) of retrospective or crosssectional study designs.

(p5.5) Reverse causation describes the situation in which the outcome affects the exposure rather than the other way around.This is a common concern with cross-sectional and retrospective case-control studies as they assess exposure and outcome simultaneously (although in case-control studies, exposure information concerns the past).Prospective cohort studies can minimize the possibility of reverse causation because participants are followed forward in time; these studies can also examine the extent of reverse causation from subclinical disease by lagged analyses [104].

(p5.6) Compared to retrospective case-control studies, prospective cohort studies begin with a disease-free population at baseline that is followed up to ascertain incident cases that develop over time and can minimize both selection bias (controls not being representative of the underlying population that gave rise to cases) and recall bias (knowledge of disease status affecting recall of diet) [104].
## (s6) Confounding
(p6.0) A major challenge when working with observational data is confounding.A confounder is a variable associated with both the exposure (i.e., diet) and the outcome (i.e., cancer), and, when unaccounted for, introduces bias into the exposure-outcome relation.The main reason why randomized trials are considered superior in inferring causality is that, as far as the sample size is large enough, the random allocation of participants to treatment groups nullifies measured and unmeasured confounding.

(p6.1) To account for this bias in an observational study design, researchers must identify all relevant confounders based on existing evidence/theory on the association between dietary habits and the disease (e.g., cancer type) under consideration.Once data are collected, the investigator can statistically adjust for confounders in a multiple regression model, including the main exposure (i.e., diet) and/or restrict the analysis to a specific subgroup to minimize residual confounding.Sensitivity analyses further strengthen results by suggesting the magnitude of unmeasured confounding needed to neutralize an effect completely [104].A prospective design additionally allows for up-to-date tracking of confounders and, in this way, limits the risk of residual confounding.While updated information may reduce measurement errors in the assessment of confounders, additional information can be collected when needed.

(p6.2) Although there are several ways to account for confounding in prospective cohort studies, the critical assumption of no unmeasured or residual confounding needed to infer causality cannot be empirically verified in observational epidemiology [53].For this reason, prospective cohort studies are often seen as providing statistical associations but not causality.However, when satisfied, the Hill criteria [54] supports the possibility of inferring causality from observational data when randomized trials of hard endpoints are not feasible [104].

(p6.3) In addition, evidence from prospective cohort studies should be integrated with results from randomized trials of intermediate responses, in vitro and in vivo studies, to arrive at a consensus on diet and a health/disease (e.g., cancer).The inference of causality is strengthened when these different types of studies provide consistent evidence in the context of the larger evidence base.

(p6.4) In conclusion, when randomized trials of hard endpoints are unfeasible, well-conducted prospective cohort studies can be used to infer causality with a high degree of certainty.Sources of bias, including confounding, can be minimized by relying on high-quality study design, careful statistical analysis and interpretation, and replications of the findings across different populations.Corroborating data from multiple study types and populations can enhance the weight of evidence [104].
## (s7) DIFFERENT TYPES OF EXPOSURES: FOOD ITEMS, FOOD GROUPS, NUTRIENTS, AND BIOMARKERS
(p7.0) Given the complex nature of the human diet, another way of inferring causality is to consider different types of exposure (i.e., food items, food groups, nutrients, and biomarkers, if any) simultaneously within the same study [62,58].This is one of the unique features of nutritional epidemiology, where dietary information is disentangled into different sets of potentially related variables.

(p7.1) While food items are available from the dietary assessment tools, and they are several (i.e., from 50 to 200, depending on the dietary assessment and/or variety of the collected diet), a smaller set of food groups -between 20 and 40 -may be created by the researchers to summarize key components of the overall diet by summing up food items based on similarities in nutrient content, consumption at meal, or culinary use.Examples of food groups include citrus and non-citrus fruit to summarize fruit consumption, raw and cooked vegetables to summarize vegetable consumption, or whole and refined grains to summarize grain consumption.

(p7.2) Measurements for food items and groups depend on how foods are recorded in the dietary assessment tool (directly as raw frequencies per day or week or in pre-specified consumption categories roughly converted into frequencies for the analysis).Generally, food items/groups are expressed as counts, including frequency fractions to account for data collection in consumption categories (e.g., 1-2 times/week converted into 1.5 times/week).Nutrients are continuous variables derived from country-specific food composition databases.As derived by laboratory processing of collected blood or urine samples, biomarkers are continuous variables too.Differently from the previous dietary components, biomarkers are not generally used alone to represent diet but are typically used jointly with other sources of dietary information to validate them.

(p7.3) In conclusion, analyses in nutritional epidemiology can rely on different sets of potentially correlated variables (i.e., food items, food groups, nutrients, biomarkers, if any) expressed in different scales to provide a comprehensive representation of dietary exposure's complexity.
## (s9) AN INTEGRATED APPROACH TO THE ANALYSIS OF DIETARY DATA IN RELATION TO DISEASE RISK
(p9.0) From the public health perspective, examining dietary patterns would parallel the real world more closely.As is often stated by our colleagues in nutrition: "We don't eat nutrients, we eat foods."[60].This statement can be amended to say that we eat foods and eat them in certain combinations or "patterns" [63].This is why dietary patterns should come first, followed and integrated by evidence on single foods or food groups and then by nutrient-based research findings.
## (s10) HOW TO DEFINE DIETARY PATTERNS: AVAILABLE APPROACHES
(p10.0) Dietary patterns are combinations of dietary components (food items, food groups, or nutrients) intended to summarize the total diet or key aspects of the diet in freeliving individuals.The majority of published reviews organize the statistical methods for dietary pattern analysis into three categories that are described in the following [67,68,89,85,33,92,70,47,135,107]:

(p10.1) • a priori, investigator-driven, investigatordefined, or dietary indexes/scores: patterns are specified by researchers a priori based upon scientific evidence or theory for specific diseases and, generally, include foods or nutrients supported by current nutrition guidelines, recommendations, and/or a specific dietary composition that is considered healthful; • a posteriori, exploratory, empirically-derived, data-driven, or "data-driven, responseindependent": the patterns emerge a posteriori from an analysis of dietary data -generally based on multivariate statistics -(i.e., data-driven) and the patterns are derived independent of their potential relationship to a health outcome (i.e., responseindependent); • mixed-type, hybrid, or "data-driven, responsedependent": the patterns emerge from an analysis of dietary data -generally based on multivariate statistics -(i.e., data-driven) expressly used to examine the relationship between dietary patterns and a health outcome (i.e., response-dependent).

(p10.2) Note that previous names are simply shorthand notations to refer to how the patterns are derived.Data-driven does not mean that a method is more evidence-based, and investigator-defined does not mean a method includes more subjectivity.Each method is built on evidence and includes some degree of subjectivity [70].

(p10.3) All approaches allow assessing and/or ranking and quantifying adherence of study participants to these patterns, which is needed to evaluate their association with disease (e.g., cancer) risk within a multiple regression model, including confounding variables.
## (s11) A PRIORI OR INVESTIGATOR-DEFINED APPROACHES
(p11.0) A priori or "investigator-defined" methods compare subjects' diet against a pre-specified evidence-based benchmark diet and express how individuals adhere to the benchmark diet with a score [67,85,92].Benchmark diets are built upon scientific evidence/theory for specific diseases or include foods or nutrients supported by current dietary guidance, recommendations, and/or a specific dietary composition (for instance, Mediterranean, vegetarian, vegan, or gluten-free diets) that is considered healthful.The subject's dietary intake (from food items/groups or nutrients) is scored on the basis of each component of the benchmark diet following the adopted scoring system; single scores are then combined into a total score using the proper mathematical expression (e.g., sum or ratio).Typical examples in the literature include the Diet Quality Index, Healthy Eating Index, Recommended Food Score, Dietary Approaches to Stop Hypertension Index, World Cancer Research Fund Index, Mediterranean Diet Score, and total Plant-based Diet Index [135].Using these indices answers the question "How close is the population to meeting a certain benchmark diet, expressed as a dietary recommendation or a specific dietary composition?"For this reason, they are sometimes called measures of diet quality [70].

(p11.1) Among major advantages, "investigator-defined" dietary patterns generally characterize overall diet, they are intuitively appealing, analytically simple to compute (e.g., primarily sums), easily reproducible and comparable.In indexbased summary analysis, the dimensions of the pattern and how those dimensions are scaled are specified (and thus standardized) by the researcher based on external evidence regarding what constitutes a healthy diet [124].Results can be meaningful, interpretable and are generally well associated with health outcomes, including cancer [101,38,46].

(p11.2) The major limitation of "investigator-defined" dietary patterns is that scores are defined on, thus reduced to, current knowledge and understanding of diet-disease association.In addition, it is challenging to translate the inherently qualitative concept of diet quality and its variants into quantitative mathematical formulas.While dietary scores are multidimensional in design, the end product is generally one number -the summary score -that may provide little information about the contributing components.This is especially true for individuals with a middle-range score, who might have different dietary behaviors.Construct and content validity should be assessed for newly developed "investigator-defined" dietary patterns.Subjectivity is introduced in the interpretation of the guidelines (if any) and in the construction of the scores (which foods are selected for inclusion in each component).However, a big effort in standardizing index construction has been recently made within the Dietary Pattern Pooling Project sponsored by the US National Institutes of Health [74].No research has established the preferable scoring system for specific situations.The summation of equally weighted dietary component scores implies that each component is equally important and additively related to health.This might not be nutritionally meaningful and may be different for different diseases.More than one "investigator-defined" dietary pattern is sometimes available to measure the same benchmark diet, with differences in dietary components included, structure (e.g., sum or ratio), processing of dietary variables, component weighting (i.e., equal weights or not), and cut-off points (i.e., population-specific or absolute).The different (recognized) variants of Mediterranean diet have prevented so far a meaningful recommendation in favor of Mediterranean diet to fight against cancer, although a strong evidence of an effect on cancer risk was recognized and the association was judged causal [19,84].
## (s12) A POSTERIORI OR "DATA-DRIVEN, RESPONSE-INDEPENDENT" APPROACHES
(p12.0) In nutritional epidemiological settings, data-driven methods estimate dietary patterns directly on dietary data [89,47], and do not explicitly refer to a priori information in the identification of dietary patterns.To highlight this aspect, these methods are also indicated as exploratory approaches.Variability in dietary habits might be explored in the overall population, with no further reference to disease outcomes.In this case, we have "data-driven, response-independent" methods.Among these "data-driven, response-independent" methods, the most used in nutritional epidemiology are PCA, EFA, and CA [135].
## (s13) Principal Component Analysis and Factor Analysis
(p13.0) The aim of PCA and EFA is to reduce the dimensionality of the data by transforming an original, more extensive set of correlated food groups/nutrients into a smaller and more easily interpretable set of uncorrelated variables, called principal components or factors.Both approaches answer the following question: "What are the major components/factors in a population under study, i.e., those contributing most to the variation of nutrient/food group intakes reported by study participants?"[70].

(p13.1) To answer this question, PCA uses the singular value decomposition and identifies principal components based on the covariance/correlation matrix of the input variables (nutrients or food groups).The resulting components are linear combinations of the original variables with suitable weights (loadings) that explain as much of the variation in the original variables as possible [47].EFA starts from the same covariance/correlation matrix and shares the data reduction rationale of PCA, but it is based on a statistical model where the random vector of observations (i.e., individual's dietary data) is explained in terms of some latent common and specific factors.The definition of a statistical model allows rotation of the factor loading matrix, improving the interpretation of the identified factors.EFA may use different estimation methods for model parameter estimation, including PCA and maximum likelihood.Therefore, a principal component factor analysis is defined as an EFA where the PCA method is adopted for parameter estimation.Principal component factor analysis is the more common method used so far to derive a posteriori dietary patterns in nutritional epidemiology [33].

(p13.2) The most followed approaches to select the appropriate number of principal components/factors are eigenvalue greater than 1 criterion (when the correlation matrix is adopted), visual inspection of the scree-plot, and a sensible interpretation of the dietary patterns.A fixed threshold (generally 5%) can also be decided, and only the components/factors whose explained variance exceeds the chosen threshold are incorporated in the analysis [47].

(p13.3) Following both approaches, individuals are ranked based on the degree to which their diets conform to each of the identified factors; this is done by adopting continuously scaled scores either obtained by simple matrix algebra (PCA) or by different estimating procedures (EFA).

(p13.4) Scores are further entered into a regression model for disease (e.g., cancer) risk estimation.In this case, scores categorization into quantiles improves results interpretation because scores, although continuous, have a restricted scale and no measurement unit.Unlike most a priori indexes, any one principal component/factor does not represent the entire eating pattern for any individual or group because the principal components/factors are not mutually exclusive.However, each person's overall eating pattern can be inferred by assessing his/her multiple principal component/factor scores [70].The simultaneous inclusion of all dietary patterns in the same regression model without additional multicollinearity issues is granted by scores being uncorrelated by design (PCA) or by additional orthogonal rotation (EFA).
## (s14) Cluster Analysis
(p14.0) While PCA and EFA work on data matrix columns (i.e., food groups/nutrients), CA [9] is traditionally used in nutritional epidemiology to explore data matrix rows (i.e., individuals), to identify groups of participants (clusters) with a specific dietary behavior, based on a pre-specified measure of similarity/difference in food group/nutrient intake among individuals [28].So, CA replies to the following question: "Are there groups of individuals characterized by distinct dietary patterns?"[70].

(p14.1) On the opposite of PCA and EFA, where the subjects can belong to more than one principal component/factor, CA provides one group belonging indicator for each subject.The group belonging indicator is then entered into a multiple regression model with confounding factors to estimate adjusted disease (e.g., cancer) risk related to specific group belongings.

(p14.2) Hard clustering, where study participants are grouped into mutually exclusive clusters, and individuals only belong to one cluster, is by far the most followed approach in nutritional epidemiology [47].Among available methods, K-means and Ward's minimum-variance method are widely used, with one paper only [75] comparing previous approaches with the flexible beta one.

(p14.3) The K-means algorithm partitions observations into K clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or centroids) by minimizing within-cluster variances (squared Euclidean distances).The advantages of K-means clustering include its simple interpretation, low computation complexity, fast calculation speed, and suitability for large samples.

(p14.4) Ward's minimum-variance method is an agglomerative hierarchical clustering algorithm, with the number of clusters changing at each step [49].Indeed, at each step, one has to find the pair of clusters that leads to a minimum increase (i.e., a weighted squared distance between cluster centers) in total within-cluster variance after merging.Thus, the calculation is slow, and the Ward's approach is hard to apply in large samples [135].

(p14.5) Among the advantages of hard CA, distinct subgroups of individuals -where everyone belongs only to one specific dietary pattern group -are easy to interpret and relate to disease (e.g., cancer) risk.The dendrogram from Ward's method shows the clustering process and results visually [47].

(p14.6) Among limitations, uncertainty in individuals' classification is removed, and each individual is assigned to a cluster with a probability of 1 or 0 [49].Second, subjective decisions are required at several steps and include selection of input variables (i.e., nutrients, food groups, or factor scores) and data preprocessing, similarity measure, clustering algorithm, initial values, and number of clusters [47].While some objective methods for selecting appropriate clustering algorithms and the number of clusters exist, the reproducibility of results cannot ensure their ability in representing actual dietary behavior and its relation with cancer risk [75].Third, sensitivity of the CA to outliers is also an issue.Fourth, formal comparison of results from different clustering algorithms is not as easy as with PCA/EFA, where congruence coefficients between factor loadings are recognized as the preferred method to compare different solutions [16].Fifth, the CA output is just a group belonging indicator, and there is no PCA-based or FA-based loading matrix to provide an immediate representation of how food groups/nutrients interact within each dietary pattern.So, when the CA is completed, further analyses to compare dietary, sociodemographic, or socio-economic profiles across clusters must be used to interpret the identified patterns [56].Sixth, a major drawback of both K-means and Ward's method is their tendency to create spherical clusters of equal volume [49], which leads to biased clustering solutions when this assumption is not met by the data.In addition, another limitation of Ward's method is its tendency to create clusters with an equal number of observations, which is an unrealistic scenario in nutritional epidemiology [49].Seventh, the reference category to estimate the effect of each dietary pattern on disease (e.g., cancer) risk is not as naturally identified as in regression models based on PCA/EFA-based dietary patterns.As one group has to be chosen as the reference group to express disease risk related to the remaining groups, what are the main characteristics this reference group should show?Should it be the bigger one or the one with a more balanced diet?No consensus exists on this issue.Floating absolute risk method has been used once to analyze the association between CA-based patterns and breast and ovarian cancers, to overcome this issue [32].

(p14.7) The term finite mixture model refers to a convex combination of a finite number of probability distributions, each of these commonly designated as mixture component.Mixture models can therefore be viewed as model-based clustering, where clusters are groups of individuals in the data (with a similar dietary behavior) induced by mixture components.Classification uncertainty is taken into account by estimating individual probabilities of belonging to each identified cluster, based on available data.For this reason, this approach provides an example of soft clustering, where subjects are assigned to each class with a weight equal to posterior membership probability for that class.The unknown true parameter vector (including parameters of each mixture component and the mixture weights) as well as the unknown allocation variables are estimated by the maximum likelihood method using the Expectation-Maximization (EM) algorithm [94,49] in the frequentist framework.As an alternative to the EM algorithm, the mixture model parameters can be deduced using posterior sampling as indicated by Bayes' theorem.This is still regarded as an incomplete data problem whereby membership of data points is the missing data.A two-step iterative procedure known as Gibbs sampling can be used.In both cases, a "hard" clustering solution can then be obtained by simply assigning each observation to the cluster to which it belongs with the highest probability, following Bayes' Theorem.

(p14.8) In finite mixture models, the number of components is still pre-specified to be equal to K. Covariates can be accommodated [41,99] or not [49] within the model to describe dependence of main dietary variables on other lifestyle or anthropometric variables.In the former case we have the general multivariate mixture model, also denoted by regression mixture model.In the latter case, standard mixture models are assumed and fitted.Both approaches have been applied in nutritional epidemiology in the frequentist framework [96,94,111,41,99,49,20,21].

(p14.9) The paper by Greve et al. [49] shows the higher flexibility of Gaussian mixture models as implemented by Fraley and Raftery [44] in comparison with K-means and Ward's hierarchical clustering on simulated and real-life data.Even on simulated data with spherical clusters of equal volume, the clustering solutions obtained from this Gaussian mixture model were more similar to the true cluster structure than those obtained from the K-means algorithm or Ward's method in more than 72% of all simulated data sets.For simulated data sets with clusters of variable volume, shape and orientation, the Gaussian mixture model achieved a higher agreement with the true cluster structure in more than 90% of data sets [49].The decomposition of the variancecovariance matrix proposed in this approach enables the researchers to place constraints on the geometrical properties of the clusters and thus to specify a desired degree of flexibility in terms of cluster volume, shape, and orientation.The choice of the number of clusters and of the available models (i.e., different parameterizations of the variance-covariance matrix) is transformed into a model selection problem.The final model is then identified according to information criteria after the finite mixture model is fitted by setting different values for the number of clusters or imposing different restrictions on the variance-covariance matrix [49].

(p14.10) Because finite mixture models has many parameters, large samples are generally required, especially when the number of selected clusters is moderate-to-high.Thus, a restricted mixture model is proposed that reduces the number of parameters and is suitable for small-to moderately-sized samples [99].This regression mixture model has been shown to generalize the one by Fahey et al., also applied in nutritional epidemiology [41], and includes in the same model the Gaussian and binomial distributions for modeling different forms of food group consumption within the exponential family.

(p14.11) The finite mixture model method can also be used to classify the population according to the factor scores derived from EFA-based CFA.This so called two-step classification approach combines the advantages of both finite mixture models on food items to identify mutually exclusive clusters and CFA to understand which foods are eaten in combination [111].

(p14.12) Among major advantages, finite mixture models are more oriented towards capturing real-life dietary behavior because they can account for the within-cluster correlation between dietary variables [49], allow the variances of dietary components to vary within and between clusters, and enable covariate adjustment (e.g., age, sex, non-alcohol or total energy intake) for food intake simultaneously with the fitting process [41,99,20,111].

(p14.13) Among major issues, the observed data may violate the distributional hypotheses, which are per se difficult to adhere to in a multivariate setting.When there are many 0 values -indicating non consumption -the need to deal with them increases the models complexity, as does the high number of parameters to be estimated [41,99].In addition, sensitivity to the initial values, convergence to local extremum, and slow convergence speed have been reported for most approaches [135].Finally, although finite mixture models improve on selection of the optimal number of clusters compared to traditional CA approaches, still this selection is not made simultaneously within an overall parameters' estimation process [94,49,20,21].
## (s15) Treelet Transform
(p15.0) A composite of hierarchical CA and traditional PCA, treelet transform [72] provides an improvement over traditional PCA and an important contribution to clustering methodology.For clustering methodology, it provides a framework which actively searches for the correct underlying correlation structure of the data.Its improvement over PCA happens especially when the correlation matrix is believed to be sparse, as in the analysis of dietary patterns, and is generally worth note [123].

(p15.1) Firstly introduced in nutritional epidemiology in 2011 [48], treelet transform is a dimensionality reduction technique aimed at converting a set of observations of possibly correlated variables into orthogonal components.Similarly to PCA/EFA, identifying the optimal number of retained components is based on scree-plot inspection (and related percentage of explained variance) and interpretability, and interpretation/labelling of components are based on loadings.Scores are determined for each component of the treelet transform and measure adherence to a given component.Unlike PCA scores which are always uncorrelated, treelet transform scores generally have a small degree of correlation.

(p15.2) Treelet transform combines the quantitative pattern extraction of PCA with the interpretational advantages of hierarchical clustering of variables.The two variables showing the highest covariance/correlation are identified in the treelet transform, and a PCA is performed on them.They are then replaced with the score of their first principal component, and a merge is indicated in the cluster tree.This operation is re-iterated until all variables have joined the cluster tree.In this way, the treelet transform produces a hierarchical grouping of variables that may reveal the data structure's intrinsic characteristics.

(p15.3) By combining PCA and hierarchical clustering, treelet transform introduces sparsity into principal components (i.e., making many loadings equal to 0), thus potentially simplifying the interpretation.While EFA achieves this structure in a post-hoc analysis with the use of factor rotation and loading truncations (in which the factor loadings with absolute values smaller than an arbitrary threshold are ignored) [65], treelet transform directly derives sparse components that, similarly to PCA components, account for a large part of the variation in the original data and can be used analogously; treelet transform leads to an associated cluster tree that provides a concise visual representation of loading sparsity patterns and the general dependency structure of the data [48].

(p15.4) Alongside the cluster tree, treelet transform yields a coordinate system for the data at each level of the cluster tree.Selecting a cluster tree level (cut-level) amounts to choosing the level of detail desired in the data dimensionality reduction [2].As pointed out in one of the Discussions in the original paper, the use of treelet transform leads to a tradeoff between the amount of variability explained and sparsity.The objective is to "make the results as sparse as possible but not any sparser" [2].Treelet transform has been used to derive dietary patterns using nutrients [2], food items [106], and food groups [48,93].

(p15.5) Treelet transform works best for dimensionality reduction and/or feature selection when sample sizes are relatively small, and the data are sparse, with unknown groupings of correlated variables.Unlike PCA and its subjective choice of components to retain, treelet transform has a fast and efficient algorithm for determining the optimal number of dietary patterns to be retained and assessing dietary pattern internal reproducibility [107].Each derived component can involve only a small number of input dietary data, so pattern structure is generally simpler than in PCA; the corresponding cluster tree for all variables also supports pattern interpretation.Not only treelet transform provides a concise visual representation of loading sparsity patterns, but it also shows the data's general dependency structure [48].

(p15.6) In line with other CA techniques, a degree of subjectivity exists in choosing the cut-level of the cluster tree before extracting components.When the cut-level is close to the root, most variables are included in the components, with potential interpretation issues; the information is comparable to PCA output when all variables contribute to treelet components.As the cut-level moves away from the root, the component loadings become sparse (as many are equal to 0), and the components possibly become more interpretable [107]; however, this may lead to components that do not capture dietary complexity and are therefore not informative [2].Cross-validation can be used to identify an optimal cut-level.Once the cut-level is chosen, the loadings computed are invariant to the number of retained components; hence, the number of components is an a priori parameter to be specified in the cross-validation step.In addition, if the correlation of some nutrients/food groups is too strong, then the sparsity hypothesis may not hold [57].It also remains debatable whether patterns derived by treelet transform are more effective than those from PCA/EFA or CA methods in exploring the relationship with health outcomes, including cancer [106].
## (s17) Reduced Rank Regression
(p17.0) Reduced rank regression was formally introduced in nutritional epidemiology in 2004 to combine the advantages of the a priori and a posteriori approaches [55].A posteriori pattern method can be applied to investigate if major consumption patterns of a specific population have relevance for health outcomes; a priori patterns can help clarify if adherence to specific benchmark diets is related to reduced disease risk.Reduced rank regression fills a gap as it more directly relates the step of data-driven pattern identification to the health/disease outcome of interest.In detail, after about 20 years, researchers in nutritional epidemiology are still increasingly interested in identifying specific dietary patterns related to established and new pathways in the development of major chronic diseases, including cancer [127].So, reduced rank regression replies to the following question: "What combinations of dietary components explain the most variation in a set of intermediate health markers?And then, in further analysis, does that pattern explain the disease outcome of interest?"[70].

(p17.1) The method has similarities with PCA, but it uses two different sets of variables: a set of independent variables or predictors, generally dietary variables, and a set of response variables, expected to be associated with the disease under examination based on a priori knowledge [47].Food groups are generally used as predictors.Nutrient intakes, contaminants, and endogenous biomarkers or intermediate disease phenotypes are generally used as response variables according to the specific research question [135].

(p17.2) The identified dietary patterns are projections of the principal components obtained from the covariance/correlation matrix of the responses onto the space of predictors.They can be interpreted as those linear functions of the original dietary variables that maximally explain variation in the response variables.Reduced rank regression can therefore be interpreted as a PCA applied to responses and subsequent linear regression of principal components on predictors, although it is somewhat more efficient and sophisticated than this two-step procedure [127].

(p17.3) Reduced rank regression starts from a linear function of responses called response score that will then be projected onto the space of predictors to produce a factor score, that is, a linear function of predictors.Both scores form an inseparable pair reflecting the same latent variable in different sets of original variables.Because the first aim of this method is to explain a high proportion of response variation, the evaluation of factors extracted by reduced rank regression should be based on response scores rather than factor scores.However, similarly to PCA and EFA, factor scores represent the comprehensive variables used in subsequent statistical analysis, to assess the association between the identified dietary patterns and disease outcome [55].

(p17.4) Given that linear functions of predictors are defined as principal components of the responses, there will be as many dietary patterns as were selected responses.This is different from PCA, in which the analysis cab identify as many principal components as predictors.Still, similar to PCA, only a subset of patterns might be informative [47].In reduced rank regression, only one or a few principal components of responses might account for most of the responses' variation, and the corresponding pattern would be the strongest candidate to be selected [127].

(p17.5) The exploratory nature of the approach hampers the generalization of the results from one population to others.However, compared to PCA and EFA, reduced rank regression allows the use of the same set of response variables in different study populations and thus improves results comparison across different populations [33].In addition, the so-called simplified patterns (i.e., scores are calculated based on only those food items strongly contributing to the pattern, to which all contribute with equal weight) ease the step of external validation of pattern-disease associations.Such validation is highly recommended given that pattern identification (using informative responses) is usually carried out within the same study in which the pattern-disease association is evaluated [127].

(p17.6) Major challenges in performing reduced rank regression include the choice of predictors and response variables to work on, the number of response variables to consider and their relationship, the number of principal components to retain, and their labelling.Most studies try to cover the whole diet including all available food items or food groups and very few studies investigated the influences of the selection or building of food groups on the extraction of dietary patterns [127].The value of the application of reduced rank regression is considerably dependent on a good selection of response variables.If responses with no or little intercorrelation are selected for analysis, they will unlikely be well reflected by a single response score.Instead, it is more likely that only a fraction of responses is accounted for -in the worst-case scenario, single response scores (and consequently single reduced rank regression patterns) reflect only a single response variable.In this case, more than a dietary pattern have to be retained and these dietary patterns might reflect different pathways relevant to disease risk [127].Confounding for responses is a second crucial issue.The derived pattern may considerably differ depending on an adequate consideration of confounders [127].So far, medication and anthropometric characteristics have been considered in some studies as confounding factors, but there could be scenarios where the role of confounding factors is less obvious.
## (s18) Partial Least Squares
(p18.0) A method similar to reduced rank regression is partial least squares, a regression model of multiple predictor variables on multiple response variables, sometimes used in nutritional epidemiology in comparison with PCA and reduced rank regression (e.g., [55,29,81]).

(p18.1) The partial least squares method is a compromise between PCA and reduced rank regression [55,29,81].Indeed, while PCA selects factors that explain as much predictor variation as possible and reduced rank regression extracts factors that explain as much response variation as possible, partial least squares balances the two goals of explaining predictor variation and explaining response variation [92].So, partial least squares replies to the following question: "What combinations of dietary components explain the most variation in dietary components and in a set of intermediate health markers?And then, in further analysis, does that pattern explain the disease outcome of interest?"[70].

(p18.2) The three methods are similar in terms of their mathematical foundation and their technique of deriving factors.For each method, the coefficient vectors of the extracted linear functions are eigenvectors of a covariance matrix.PCA uses the covariance matrix of predictors, whereas reduced rank regression starts from the covariance matrix of responses.Partial least squares uses the matrix of covariances between predictors and responses.However, as the number of factors cannot be greater than the rank of the corresponding covariance matrix, partial least squares can extract as many dietary patterns as were the selected predictor variables, like in PCA, but differently from reduced rank regression.The eigenvalue belonging to an eigenvector quantifies the percentage of variation explained by the corresponding linear function of the original variables (i.e., predictors or responses depedenign on the method).The factors obtained by PCA, partial least squares, and reduced rank regression usually are sorted by decreasing eigenvalues.While the first factor of PCA is the linear function of predictors that maximizes the explained variation in predictors, it is, in general, not optimal in terms of response variation.In contrast, the first factor of reduced rank regression explains more variation in response than any other linear function of predictors, but possibly explains only a moderate fraction of predictor variation.The first factor from partial least squares maximizes the covariance between linear combinations of predictors and responses [55].

(p18.3) Due to the orthogonality of eigenvectors, successive extracted factors from all three methods are uncorrelated.Therefore, the variation in the original variables (i.e., predictors or responses, depending on the method), can be decomposed into percentages of variation explained by the obtained factors.These uncorrelated factors can simultaneously be chosen as independent variables in a regression model for predicting disease (e.g., cancer) risk without confounding each other [55].

(p18.4) Similarly to reduced rank regression, major challenges in performing partial least squares include the choice of both predictors and response variables to work on, the number of response variables and food groups to consider and their relationships, as well as the number of factors to retain, and their labelling.
## (s21) NOVEL STATISTICAL APPROACHES IN THE ANALYSIS OF A POSTERIORI DIETARY PATTERNS
(p21.0) Maximum likelihood may be used in EFA, and is generally used in finite mixture models in nutritional epidemiology.However, in some applications and especially for the EFA, in order to regularize the factor loadings, priors or penalties are used to induce sparsity [76,15,40].This might be particularly interesting in the identification of a posteriori dietary patterns.Sparse factor loadings can be used to identify specific subsets of nutrients and interpret them as interacting subsets, helping elucidate the name chosen for a dietary pattern.In contrast to the frequentist approach, Bayesian methods model sparsity through the introduction of shrinkage and sparse priors on EFA.Sparse latent factor models therefore exploit sparsity-inducing priors as an integral part of the identification of dietary patterns.In the Bayesian approach to sparsity, two main priors have been widely used and developed.

(p21.1) The first one is the Bayesian LASSO prior, introduced by Park and Casella (2008) [95], and developed in different settings [15,100].Based on the LASSO penalty of Tibshirani (1996) [121], the Bayesian LASSO prior is a conditional Laplace prior for the loadings λ pj with p = 1, . . ., P variables and j = 1, . . ., J factors

(p21.2) where ψ p is the diagonal element of the covariance error matrix and τ > 0 is the scale hyper parameter.In this modeling setting, the posterior mode of λ pj is the LASSO estimate with the penalty equal to 2τ ψ p , which regulates the amount of shrinkage.Posterior inference is developed via Gibbs sampling.This approach's major limitation lies in the lack of unimodality for the posterior distribution of λ pj .Indeed, the posterior distribution of the factor loadings could present a bimodality, and this problem leads to point estimates less meaningful [95].This problem can also occur considering the prior error variance ψ p as proper.

(p21.3) The second approach is focused on a mixture prior [15] defined by the random variable δ pj assigned to each element of the loadings λ pj , p = 1, . . ., P , k = 1, . . ., K, of the factor loadings matrix Λ:

(p21.4) The priors for the factor loadings belong to the class of absolutely continuous spike and slab priors where ζ 2 pj is a small constant, thus representing the spike of the factors, respectively, and so the distributions are concentrated on zero.Instead, c 2 λpj are large constants ( 1), thus representing the slab part of the mixture of the factor loadings.This prior was used on identifying sparse latent factor models in dietary pattern analysis on 102 food items in young American adults [65].This paper illustrates the potential of using EFA in a Bayesian perspective, by shrinking some loadings and improving dietary pattern interpretation, while potentially allowing for the incorporation of covariates that may provide important information when exploring dietary patterns or measurement error.Sparse latent factor models exploit sparsity-inducing priors as an integral part of the identification of dietary patterns.Indeed, prior distributions over individual probabilities are chosen to have substantial probability mass at zero to induce shrinkage of negligible loadings to zero.On the other hand, they ensure that the probability mass is spread over a wide range of plausible values so that important loadings escape shrinkage and take nonzero values [65].In addition, the proposed sparse latent factor analysis robustly derives dietary patterns while simultaneously controlling for potential interaction with other variables, including total energy intake.Covariates are directly included as additional regressors in the model, instead of proposing preprocessing of input data to account for them (e.g., residual method for energy intake) or separate EFAs by relevant covariates to be ad-hoc combined.While controlling for influence of covariates, their information is also jointly used to derive dietary patterns [65].Other possible extensions rely on the spike and slab with a LASSO prior [100,3], but to our knowledge they have not been applied in nutritional epidemiology so far.

(p21.5) In many circumstances, researchers aim to provide insight into dietary patterns that emerge based on a given characteristic of the sample, for example a socio-demographic characteristic (e.g., age, education, or income) and a method called Focused Principal Component Analysis (FPCA) [14] is available.This method derives principal components, so it is a data-driven approach, but it is more similar to a "datadriven, response-dependent" method, where, however, the response is generally a confounding factor.

(p21.6) Unlike in PCA, dietary patterns focusing on a particular variable of interest (i.e., a population characteristic) are formed, and are presented exclusively in graphical format.Applying FPCA to dietary data makes it possible to view the correlation between each dietary variable and a given variable of interest, at the same time as enabling detection of correlations between the different dietary variables themselves.So, FPCA replies to the following research question: "How to represent the relation between food/nutrient consumption and one selected population characteristic, without loosing the relationship that the different food groups/nutrients have with each other?".

(p21.7) The FPCA method considers a set of P variables measured on n subjects.The variables are n-dimensional column vectors x p .The correlation matrix of each column vector x p can be geometrically represented thus by the P points p p on the unit hypersphere of an n-dimensional Euclidean space.The correlation of x 1 and x 2 is close to 0 if and only if p 1 and p 2 lie on perpendicular radii; on the opposite the correlation of x 1 and x 2 is close to 1 if p 1 and p 2 are neighbours; finally the correlation of x 1 and x 2 is close to −1 if p 1 and p 2 are diametrically opposed [43].The smaller the radius, the stronger the correlation.
## (s22) CROSS-STUDY REPRODUCIBILITY OF DIETARY PATTERNS: NOVEL STATISTICAL APPROACHES
(p22.0) Compared to most a priori dietary patterns -especially indexes of overall diet quality -which can be more easily used across different study populations, the a posteriori approach estimates population-specific dietary patterns.Indeed, if the patterns are derived by explaining the variability among diets of one population, it is unlikely the same patterns would be found in another population.While their reproducibility is necessarily more limited, a posteriori dietary patterns reflect the actual dietary practices in the population under study and provide crucial information [37].Dietary patterns should reveal those latent characteristics of interest, including socio-demographic and socio-economic factors, ethnic background, religion, and several other environmental factors, like food supply, ability to purchase/prepare foods, advertisements for foods, and the efforts of the government and the nutrition community to foster healthy diets [63], which are at the origin of actual dietary practices.Common latent characteristics may end up in common dietary patterns across studies.
## (s23) CONCLUSIONS
(p23.0) Diet is a complex exposure, which calls for multiple approaches to examine its relationship with non-communicable diseases, including cancer.Evidence on the effect of diet is enhanced when results from multiple study types (i.e., observational studies, randomized trials of intermediate responses, in vitro and in vivo studies) and from multiple forms of dietary exposure (i.e., food items/groups, nutrients, biomarkers, and dietary patterns) are consistent.

(p23.1) Being complementary to the traditional singlecomponent analysis, the dietary pattern approach has been proposed in nutritional epidemiology to exploit the collinearity of nutrients and foods.This approach is not effective if the effect is "caused" by a specific nutrient, because the effect of the nutrient would be diluted.It may be useful when traditional single-component analyses have identified few dietary associations with the disease (e.g., breast cancer).On the other hand, when many dietary associations have been demonstrated for the disease (e.g., coronary heart disease or colorectal cancer), dietary pattern analysis may also prove to be useful because it allows to examine the effects of this overall, but likely well-structured, dietary exposure.In addition, a dietary pattern can be used as a covariate when examining a specific nutrient/food group, to determine whether its effect is independent of the overall dietary pattern.Furthermore, dietary pattern analysis can be useful in evaluating dietary guidelines [56].

(p23.2) As methods to assess dietary patterns have been refined and the evidence base has been strengthened, the advantages that dietary patterns offer as an approach for informing public health recommendations have increasingly been recognized [18].

(p23.3) In the future, like all of nutritional epidemiology, patterns research will be advanced by using methods of dietary capture and analysis that better estimate usual intakes and by considering how they may change over time.In addition, continued clarification of the most useful treatment of input variables for EFA and CA, continued development of best practices for standardizing statistical procedures in a posteriori dietary patterns, refinement of indices, and progress in methods to correct for measurement error would advance the field [70].
## (s24) Gwhere
(p24.0) ip ∼ Bern(υ (s) p ), υ(s)  p ∼ Bern(1, β(s) ),β (s) ∼ Γ(a, b),with the hyperparameters (a, b) used for varying the overall weight of each local component (deviated food item) of its corresponding subpopulation.For the global clustering process, the RPC adopts an overfitted finite mixture model[125], with an upper bound equal to 50 for the number of clusters K:P r(Ci = h) = π h , π • = (π 1 , . . ., π K ) ∼ Dir1 Dir indicates a Dirichlet distribution.The RPC replicates this scheme to specify the model for the local clustering: P r(L ip = l|s i = s) = λ
