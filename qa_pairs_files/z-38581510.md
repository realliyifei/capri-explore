# Is literature search training for medical students and residents effective? a literature review

CorpusID: 38581510 - [https://www.semanticscholar.org/paper/d6846801ed5086c7cff1079c31f2c2147068a3e5](https://www.semanticscholar.org/paper/d6846801ed5086c7cff1079c31f2c2147068a3e5)

Fields: Education, Medicine

## (s0) INTRODUCTION
(p0.0) Librarians have been teaching users how to search online medical literature databases for almost twenty years. In the early years, classes were usually standalone sessions on how to access resources and conduct database searches. More recently, literature searching skills have been integrated into the curriculum in undergraduate and graduate medical education, often as part of learning about the practice of evidence-based medicine (EBM). Lessons on literature searching are taught using a variety of pedagogical methods including lectures, hands-on workshops, and online tutorials [1].
## (s4) Validated instruments
(p4.0) Most instruments used to measure searching skills were created locally for the purpose of measuring the impact of a locally developed intervention. Therefore, most of the instruments described in this review were used only once, and few efforts were made to test the instruments' reliability or validity. Only one of the instruments included in this review, the Fresno test, was utilized in more than one study. It and four additional instruments or methods reported here included measurements of reliability and validity.

(p4.1) The University of Michigan MEDLINE Search Assessment (UMMSA) tool is a matrix that assigns points for the inclusion of various required search elements [6]. With UMMSA, points are assigned for elements such as identifying appropriate Medical Subject Headings (MeSH), exploding MeSH, adding subheadings, focusing one or more MeSH terms, and limiting properly. To establish reliability and validity, the authors ran several tests. One test established inter-rater reliability among multiple faculty search raters. Construct validity was established by verifying the expected significant differences in scores between novices and experienced searchers and the similarity between experienced searchers and experts. The tool was also analyzed to show internal consistency among the test items. Because this article focused only on validation of the tool and did not include results, it was excluded from the rest of the review.
## (s8) Resource usage
(p8.0) Three studies reported the impact of the intervention on actual database usage. One study logged clickthroughs from the electronic medical record system to determine how often students were accessing electronic resources to make evidence-based notes in the patient chart [27]. The use of electronic resources increased significantly, from an average of 0.12 clickthroughs per week to 0.66 click-throughs per week. Also, prior to the intervention, only 13% of the clickthroughs were to critically appraised resources. Following the intervention the percentage increased to 59%. In another study, Ovid search logs were examined to determine how many searches were conducted by students in intervention and control groups over the course of a 6-week clerkship [23]. Logs revealed that students participating in an online EBM course conducted an average of 12.4 MEDLINE and 1.6 Cochrane searches during the clerkship, compared to 2.6 MEDLINE and 0.2 Cochrane searches in the control group. The differences in searching rates of both databases were statistically significant.

(p8.1) The third study measured how often residents would use electronic resources to answer questions on an exam of clinical vignettes [18]. The intervention group participated in formalized EBM training sessions during an elective month, while the control group received no formalized EBM training. Residents were given an exam with fifteen clinical questions and asked to complete the exam without accessing any resources. Then, they were asked to retake the exam, but the second time, they were allowed to consult online resources. Logging software was used to capture how often the residents accessed various online resources. When allowed to access resources, both the intervention and control group consulted online resources with similar frequency (mean of sixteen times for the intervention group and seventeen times for the control group). The intervention group chose evidence-based resources significantly more often than the control group. However, both groups improved their scores from the first test (without access to resources), and the final scores of the intervention and control group were not significantly different, implying that the residents performed better after consulting online resources, regardless of the types of resources accessed.
## (s9) Patient notes
(p9.0) One study examined the content of patient intake notes in an electronic medical records system to measure whether an EBM workshop would alter students' behavior [27]. In the inpatient portion of an internal medicine clerkship, students wrote history and physical notes for two to three patients per week. All student write-ups were expected to include references to the literature. Notes were evaluated before and after a mandatory EBM resources tutorial to measure impact on the quantity and quality of references included in the notes. No significant differences were found in the number of citations included in the notes pre-and postintervention. Post-intervention notes showed an increase in citations to evidence-based resources, but the increase was not statistically significant. Although the quantity of citations did not increase, the quality of the notes improved. Students were better able to incorporate the evidence into their notes about the patients' problems.
## (s10) CONCLUSIONS
(p10.0) All of the studies in this review reported a significant increase in at least one measure of literature searching skills, regardless of the type of intervention provided. However, the differences between the studies make it difficult to draw meaningful conclusions or generalize the findings to other groups and populations. The studies varied considerably in study design, subjects, settings, timing, interventions, and measurements. The lack of articles demonstrating little or no improvement in skills after intervention may be attributable to the fact that studies with negative results are unlikely to be documented for publication.

(p10.1) Most of the studies that measured learning of literature searching skills tested students soon after the intervention, when retention would be highest. The few reported studies that measured the durability of literature searching skills learning over time reported less favorable results, and none of the studies had rigorous experimental design. The need to design literature searching skills interventions that demonstrate durable learning presents an opportunity for future research. Other research opportunities include the measurements of literature searching and use in physician practice, especially outside of academic medicine and the impact of literature searching and use on patient care outcomes.

(p10.2) Literature searching skills instruction appears to be moving away from stand-alone workshops that focus on specific MEDLINE interfaces and toward Just curriculum-integrated instruction that ties literature searching to evidence-based practice. The elements measured by the Fresno test reinforce the idea that literature searching is an important and integral part of a self-directed learning process that ultimately leads to better answers to clinical questions. A recent review of evidence-based practice instructional models and adult learning theories resulted in a proposed hierarchy of evidence-based teaching and learning [28]. Based on the findings of that review, the most effective EBM courses would be interactive and clinically integrated. If librarians want to be part of this type of instruction, we need to redouble our efforts to become embedded members of the clinical team to ensure that the use of information resources is a seamless part of providing clinical care.
