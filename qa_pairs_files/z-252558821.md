# A Review on Machine Learning Styles in Computer Vision-Techniques and Future Directions

CorpusID: 252558821 - [https://www.semanticscholar.org/paper/59694d8b594ac2bb0f91dd4a0d681133f976939a](https://www.semanticscholar.org/paper/59694d8b594ac2bb0f91dd4a0d681133f976939a)

Fields: Computer Science

## (s4) II. BACKGROUND STUDY A. EVOLUTION OF MACHINE LEARNING STYLES
(p4.0) In July 1970, an initial investigation was done to test whether a perceptual learning process learns the visual symbols & transfer procedure was used with deaf first-grade children. This experimental study's authors found evidence for distinctive feature learning [11]. Based on Vygotsky's theories, Sir James Britton and others in England developed Collaborative Learning(Co-Learning) in the 1970s as an active learning method. According to Britton, a student's learning comes from a community of learners composed of other students [12]. Then, A theoretical rationale elaborates upon the concepts of meta goals. Meta-learning was provided in April 1975. In 1979, Seltzer Donald S. explained how robots could learn from different methods. This author explained how sensory information is used for improved Robot learning. Then, in 1980, scientists presented an adaptive model for self-supervised learning that uses a single pattern training technique to recognize vowel sounds on a computer [13].

(p4.1) In 1987 Littlestone Nick published his first paper on online learning. In this, online learning of various classes of boolean functions from examples is studied. Board later rediscovered semi-supervised learning in 1989. With the learning algorithm only having access to incomplete information, several unrelated concepts were learned at once. In 1990, Suddarth & Kergosien developed multi-task learning, the main concept of which is sharing what is known by various tasks while activities are trained concurrently. Then in the same year Transduction term was coined by Vladimir Vapnik. After this, in July 1994, the first paper on Co-learning on recursive functions was published. In the same year, Macoun & Richard developed a constructivist learning model helpful for ethics education.

(p4.2) The first study on ensemble learning, which discussed a decorrelation network training technique for enhancing the efficacy of regression learning with ensemble neural networks, was published in 1996. Then, on June 24, 1999, the authors published a study on association rule learning. They claimed that induced rules were not primarily designed for categorization and that the new measures employed for association rule learning were support and confidence. After that, the first papers on multi-view and multi-instance learning were published in 2003. Then in 2006 CELEBRATE project developed and demonstrated a federated learning object brokerage system architecture by Massart & David. Later in Dec 2013, Marcus& Ebert published the first paper on few-shot learning when datasets with few labels are available.
## (s8) 1) SUPERVISED LEARNING
(p8.0) A machine learning task called supervised learning converts every input item to the required class label value. An object is mapped by the computer with the intended output after training. It includes a broad selection of algorithms for various supervised learning issues. Over time, applications in computer vision and machine learning have increased dramatically, with society as the only gainer. Supervised learning VOLUME 10, 2022 is broadly divided into two categories, i.e., Classification and Regression. Objects will be categorized based on recognized class categories in classification to solve various real-world challenges. In Regression, however, the correlation between dependent and independent variables is calculated and displayed using scatter plots [6]. Figure 6 depicts the Supervised Learning process flow, where the input is labeled data from which features are extracted, and the model is trained. The trained model will be applied to the test dataset to forecast the result.
## (s9) Advantages of Active Learning-
(p9.0) • To minimize the need for labeling issues such as image annotation, recognition, object detection, segmentation, and posture estimation.   algorithms that learn from other machine learning algorithms. Usually refers to the use of machine learning algorithms capable of combining predictions from different machine learning algorithms in the most effective way possible. Multitask learning algorithms capable of learning across several related prediction tasks are also referred to as meta-learning. There is meta-learning within the framework of supervised learning [41]. Figure 10 shows the work flow of meta learning style.
## (s14) 2) UNSUPERVISED LEARNING
(p14.0) Unsupervised learning majorly works on unlabelled data objects. This type of learning is frequently employed for feature extraction, spotting important patterns and structures, matching together related objects, and practical purposes [51]. Anomaly detection, clustering, density estimation, feature learning, dimensionality reduction, and association rule discovery are some of the most popular unsupervised learning tasks. Figure 12 shows the workflow of an unsupervised learning process for computer vision applications.
## (s15) a: SELF-SUPERVISED LEARNING
(p15.0) In some ways, self-supervised learning is a sort of unsupervised learning because it adheres to the condition that no labels are assigned. Self-supervised learning, on the other hand, instead of looking for high-level patterns for clustering, tries to tackle tasks typically addressed by supervised learning (e.g., image classification) without any labeling provided. Figure 13 displays the working of self-supervised learning from input data till the final output generation. Instead of recommending new self-supervised learning techniques, this learning aims to examine how current selfsupervised learning strategies might be applied to address domain adaption problems [53]. The primary task can learn a domain invariant feature representation thanks to the pretext  job connecting the source and destination domains. In the source domain, the primary job has labels; however, in the destination domain, there is no labeling requirement. In other words, we develop unsupervised domain adaptation through self-supervised learning. The forwarded data flow is represented by solid lines in the diagram, while the optional data flow is indicated by dotted lines [53]. Through multitask learning, the pretext and main task (such as object identification, classification, or semantic segmentation) are simultaneously learned. Advantages of Self-Supervised learning-• The frequency of labeling needed may be reduced with the use of self-supervised learning.
## (s18) c: ASSOCIATION RULE LEARNING
(p18.0) An unsupervised learning method called association rule learning looks at how one data item depends on another and then maps to make it more profitable. It seeks to uncover exciting connections or interactions between the dataset's variables [58]. A technique of machine learning based on rules called association rule learning can be used to find ''IF-THEN'' sentences or other meaningful correlations between variables in large datasets. One example is that if a consumer purchases a computer or laptop (one thing), they will also purchase anti-virus software (another item) simultaneously. IOT services, medical diagnosis, usage behavior analytics, web usage VOLUME 10, 2022 mining, cutting-edge phone applications, cybersecurity applications, and bioinformatics are a few examples of contemporary uses for association rules. The order of events within or across transactions is rarely considered by association rule learning, in contrast to sequence mining. Commonly, the ''support'' and ''confidence'' metrics are employed to evaluate the value of association rules [2].

(p18.1) Association rule algorithms measure the frequency of complementary occurrences, or associations, across an extensive collection of things or activities. The idea is to uncover relationships that occur more frequently than a random selection of alternatives would reveal. This rule-based strategy is a quick and effective way to mine non-numeric, classified datasets. It is shown with the help of market basket analysis in the figure15.

(p18.2) Example: One well-known application of this methodology is the analysis of retail sales to ascertain the best way to arrange items in a store. Newborn baby diapers may be sold 10,000 times at a business with a million transactions annually, but razor blades may be sold 100,000 times. At first inspection, there is no statistically significant correlation between newborn diapers and razors. On the other hand, rule mining would go further into transaction frequency and find that 5,000 sales involve both products.

(p18.3) The association system introduces a new rule indicating that 50% of all buyers buying newborn diapers also purchase razor blades, which might be helpful to information for marketing efforts rather than just knowing that 1% of customers purchase diapers and 10% buy razor blades.

(p18.4) Moreover, when additional data is analyzed, the rule-based Method improves performance and develops new rules. With a sizable enough dataset, it enables the computer to simulate the human brain's feature extraction and abstract association abilities from unstructured input.

(p18.5) Application Areas of Association Rule learning-1) Basket data analysis -Association mining can help you determine what your customers desire, whether you're planning product placement in a storefront, running a marketing campaign, or producing a business catalog [58].
## (s20) 3) REINFORCEMENT LEARNING
(p20.0) Using input from its actions and experiences, an agent is trained in an interactive environment to achieve this machine learning technique's reward and punishment mechanisms. The agent receives rewards for successful attempts and punishment for unsuccessful ones. The agent attempts to minimize inappropriate actions and maximize appropriate ones by learning from their experiences and activities [64]. When a series of decisions are required, reinforcement learning is used. The mathematical foundation of Markov decision processes is used in most reinforcement learning contexts. Reinforcement learning is utilized in computer vision applications for object detection, video analysis, gaming, and animation. Figure 16 shows the work flow of reinforcement learning process to achieve the reward.
## (s21) 4) HYBRID LEARNING STYLES a: SEMI-SUPERVISED LEARNING
(p21.0) These algorithms are trained on data that are both labeled and unlabeled. There is a lot of labeled data and a lot of unlabeled data. Figure 17 shows how semi-supervised learning works with labeled and unlabeled data.

(p21.1) The basic approach entails clustering similar data first. Using an unsupervised learning method and then applying it VOLUME 10, 2022  to existing data. The rest of the unlabeled data is labeled using the labeled information [58].
## (s22) c: ROBOT LEARNING
(p22.0) Robot learning is a field of study that combines machine learning and robotics. It investigates learning algorithms that allow a robot to learn new skills or adapt to its surroundings. Numerous analytical systems, such as robots, are integrated with visual sensors from which they know the status of their surroundings by solving matching computer vision challenges in multiple applications. These tasks' solutions are utilized to make decisions regarding possible future actions [78].
## (s23) B. ADVANCED LEARNING STYLES 1) TRANSFER LEARNING
(p23.0) The system's capacity to recognize and apply information and abilities acquired during previous tasks to new ones. There is a need for Transfer learning to minimize the model training time and usage of the resources to solve similar kinds of functions.

(p23.1) In this, if you train a simple classifier to predict whether an image contains a particular set of objects, you could use the same knowledge the model gained during its training to recognize different but related groups of new things [79].

(p23.2) As shown in Figure 19, transfer learning takes a pre-trained model and dataset as input. It works on data and trains the model on that data to perform the machine learning tasks. Then that trained model knowledge will be used to solve similar problems. There are two types of transfer learning: one is positive transfer learning, and another is negative transfer learning. In positive transfer learning, pre-trained models can improve the performance of new tasks and the accuracy of results generated. At the same time, the negative transfer is when the implementation of new tasks degrades due to the previously trained knowledge transfer of the model.

(p23.3) Transfer learning is used in various domains like Medical applications, Biometrics, transportation, recommendation systems, and urban computing applications like traffic monitoring, health care, social security, etc. Pre-training a neural network on the source domain is a way to transfer learning that is frequently employed. for instance, ImageNet, a library of over 14 million annotated pictures divided into more than 20000 categories, then fine-tune it using examples from the target domain.

(p23.4) Machine learning models that deal with natural language processing incorporate transfer learning. Examples include teaching a model to recognize various linguistic components or embedding pre-trained layers that comprehend certain terminology or dialects. To translate models into different languages, transfer learning is used. Models' features are developed and trained using the English language. Table 15. Summarizes the different strategies used in transfer learning. Despite having the same source and target domains, the source and target tasks are different. The algorithms take advantage of the inductive biases of the source domain to enhance the target job. In the case of transductive transfer learning, the related domains are different even though the source and target tasks are comparable. For unsupervised transfer learning, the main focus is on unsupervised tasks in the target domain where the source and target domains are similar, but the tasks are different. The reusable aspects of a computer vision algorithm will be applied to a new model through transfer learning in computer vision for image and video data processing. Deep learning, a kind of machine learning that aims to emulate and duplicate the processes of the human brain, is reliant on artificial neural networks. Due to the intricacy of the models, neural network training consumes a large number of resources. To increase process efficiency and decrease resource demand, transfer learning is applied.
## (s24) 2) ENSEMBLE LEARNING
(p24.0) To achieve better results, ensemble learning employs strategies that expand models and combine them. Different models used as inputs for ensemble methods in this learning are referred to as base models, which provide better prediction accuracy than a single trained model. Figure 20 shows the framework of Ensemble learning. Ensemble Learning has three methods as follows-   a learning scheme where each model gives an equally weighted prediction. 3. Stacking -The input data is divided into training and testing. The training dataset is trained using different classifiers and will be taken as input to create a meta classifier. The result of the meta classifier is the final trained model. It will then be applied to the testing dataset to check the classifier's (meta) prediction accuracy [85]. Advantages of Ensemble learning-• Compared to most other ML styles, ensemble approaches are more accurate predictors than individual models.
## (s26) 3) FEW SHOT LEARNING
(p26.0) Few-Shot Learning is a type of meta-learning in which a learner works on multiple similar tasks during the metatraining phase so that it may generalize successfully to unknown (but related) tasks with only a few examples [89] shown in figure 21. This Learning is commonly used to represent many tasks and train task-specific classifiers; on top of this, representation is a practical approach to the Few-Shot Learning problem.  The difficulty of wanting to recognize objects from classes that our model has not seen during training is known as zero-shot learning shown in figure 22. The data for zero-shot learning comprises the following: 1. Observed/Seen classes: These are classes for which we labeled images during training.

(p26.1) 2. Unobserved/Unseen classes: These classes do not have any tagged images throughout the training phase. Types of Zero-Shot Learning-1) Inductive Zero-Shot: We can get tagged image data from classes that have been observed in this. The key objective is to translate semantic knowledge into visible image space so that the model can identify objects from unobserved classes during testing.
## (s27) 5) ONLINE LEARNING
(p27.0) Online learning involves instruction using data that is made available in a stepwise order. The whole training data samples are always available in batch sampling-based learning, which is different from this method. It is useful when algorithms need to change their behavior in response to changing data patterns from all incoming input. For online learning to succeed, three essential needs must be met [90]. Figure 23 shows On the Left: The user is pointing to an object, and on the Right: Process Flow.

(p27.1) 1. The neural system's flexibility allows for the rapid assimilation of new information without requiring an entire training cycle; 2. Near-real-time processing throughout the entire system; 3. The natural presentation of fresh object information is made possible by a subsystem for human-machine interaction. Advantages of Online learning-• Low cost required • Flexible to implement • Covers time and mass audiences Disadvantage of Online learning-• Less Accuracy achieved or success rate is low. Advantages of Zero-shot learning-• A strong and promising learning paradigm is called zeroshot learning, in which the classes that training instances cover and the classes that we want to classify are not related.

(p27.2) • To improve the generalization ability of the model • To improve scalability and robustness Disadvantages of Zero-shot learning-• Extensive smoothing • Sparsely labeled Using skin color segmentation, one instance of the VPLclassifier, and a search for pointing movements (upper branch), the scene is examined for objects that can be identified (lower branch). The ''online loop'' (right ellipse) starts when a story about an object is recounted. After establishing the position of the pertinent entity, pictures are taken. The database is expanded with views that have been artificially warped (scale/shear transformation, translatory offset). The candidate regions are categorized by the VPL classifier. The result is either a class number for a previously taught material or a reserved class label for ''unknown.'' The VPL is a neural classification architecture that performs exceptionally well when being trained and retrained online with minimal data. Three processing stages called ''VPL'' combine pixel-level feature extraction with LLM-networks, PCA, and vector quantization are used for classification [88]. The following is how the VPL is defined: Using vector quantization, the input space is divided at the first level (''V'') (VQ). For VQ, the suggested algorithm is applied. In the second level (''P'') of each of the generated reference vectors, the neural Method computes the principal components (PCs) for the training data gathered in the Voronoi tessellation cells.
## (s28) 6) FEDERATED LEARNING
(p28.0) Federated Learning means fed a large number of cases. FL is a machine learning approach in which numerous participating clients who maintain their training data locally train a single shared global model.

(p28.1) It is a distributed learning approach that builds a universal or customized model using decentralized datasets on edge devices. Model performance in FL, however, falls well short of centralized training in the field of computer vision because there isn't any investigation in a variety of tasks with a common FL framework. FL works well in complex computer vision applications such as object recognition, picture segmentation, and image classification [90].

(p28.2) The FL figure 24 shows the Federated learning workflow stepwise-1) On the Common Server, train a global model. 2) Using local datasets, deploy global models to edge devices (local models).

(p28.3) 3) Use the local datasets from each edge device to improve the model (local models). 4) Post updates to locally trained models on a shared server. 5) Calculate the average of the update values and apply it to the overall model. 6) Repetition of steps 2 through 5 FL has been used, for instance, to train prediction models for mobile keyboards without sending confidential typing information to servers [91].
## (s31) A. IMBALANCED DATA
(p31.0) If a different number of images for each of the classes is existing in the input dataset. This problem is called as class imbalance. Similarly, if a set of images is not evenly distributed in the input dataset is called imbalanced data. Transfer learning, Multi-task learning and Federated learning help to overcome this unbalanced distribution of data problem. As in case of transfer learning once the model has been trained on sample dataset can be applied to solve the similar problems with the same model. In case of the Multi-task learning model can be trained with a small number of dataset. The same knowledge generated can be applied to solve all related tasks. From supervised learning Logistic regression algorithm is very useful to tackle this issue as it resample's the original training dataset to decrease the overall level of class imbalance. The authors proposed a monitoring scheme that can infer the composition of training data for each Federated Learning(FL) round, and design a new loss function -Ratio Loss to mitigate the impact of the imbalance [110].
## (s34) D. DETECTION AND CLASSIFICATION OF BLUR IMAGES
(p34.0) In order to restore images, blur identification is frequently required. Authors proposed a classification technique utilizing ensemble Support Vector Machine (SVM) structure, a novel blur type classification method for digital images. Each image is considered to be prone to no more than one of the three types of blur: haze, motion, and defocus. In the VOLUME 10, 2022  suggested method, the Radial Basis Function (RBF) kernel parameters of the SVMs are additionally optimized using the SVM-Recursive Feature Elimination (SVM-RFE) method, which is used to rank the 35 blur features that were first derived from the spatial and transform domains of the picture. Additionally, the Support Vector Rate (SVR) is used to calculate the ideal number of features for classifiers to use. To categorize the various types of blurred images, the bagging random sampling method is used to build an ensemble SVM classifier based on a weighted voting mechanism [111]. In this way supervised learning SVM ensemble and SVM multiclass algorithms useful to solve blur images problem.   
