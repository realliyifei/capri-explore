# Brain entropy, fractal dimensions and predictability: A review of complexity measures for EEG in healthy and neuropsychiatric populations

CorpusID: 239214453 - [https://www.semanticscholar.org/paper/6b2d68ce7c9b17ebf7a8e294fa9d0fe5d335f1a3](https://www.semanticscholar.org/paper/6b2d68ce7c9b17ebf7a8e294fa9d0fe5d335f1a3)

Fields: Psychology, Medicine

## (s3) | Predictability
(p3.0) Methods that primarily capture the predictability of a dynamical system focus on evaluating the correlation present in the temporal evolution of its associated time series. Based on their algorithms, these methods can be further categorized into two subgroups (see Figure 1): (A) Spatial dimensionality requires a reconstruction of the 'state space' (see below) of the time series before estimating its predictability, and (B) temporal dimensionality characterizes the predictability of a dynamical system directly from the signal time series. In the context of EEG signals, these methods allow for the extraction of information underlying their cortical dynamics, where lower complexity of these dynamics (i.e., more predictable) may be driven by factors like a loss of neural connectivity and less activations of neural networks in diseased states like neurodegeneration (Jeong, 2002).
## (s4) | Spatial dimensionality
(p4.0) Complex systems can be mathematically modelled by a set of differential equations, referred to as dynamic variables. These variables can be represented in a coordinate system called the state space where each isolated point in the space (a state vector) represents a system state. As it is beyond the scope of this paper to describe the reconstruction of the state space from the time series, readers can find these details in Deyle and Sugihara (2011). Extending from the concept of state space, the phase space is another coordinate system that captures the evolution of the states over time. Each point of the phase space represents a system state at a given time instant. If the dynamical system being modelled is a real-world signal (e.g., biological signal), after a long enough time, the evolution of the dynamic variables will reach an equilibrium where the dynamical system is bounded by a subset of the states with physical significance called the attractor (see Figure 2). The geometry of the attractor constructed from a biological signal captures the unique information about the dynamic nature of the underlying physiological system, beyond what traditional signal F I G U R E 1 Complexity measures can be structured broadly into indices of predictability and regularity. Measures of predictability capture either spatial or temporal dimensionality of the dynamical system, and measures of regularity reflect the complexity of the system's output either on single scales or multiscales. analysis in time and frequency domains can describe. As such, most of the spatial dimensionality indices described below actually refer to characterizations of the geometric shape of the reconstructed attractor (hence the 'spatial dimensionality' denomination).

(p4.1) One of the important geometric features of an attractor is its dimensionality (referred to as fractal dimensionality), which is different and more informative than the usual concept of (topological) dimensionality. Mathematically, fractal dimensions (FDs) define the minimum number of coordinates needed to locate any point within the phase space and can be interpreted as a measure of the structural complexity of a dynamical system. Correlation dimension (CD, also referred to as D2) is one such FD index (Grebogi et al., 1986). By estimating the probability of any two pairs of points on the attractor separated by a distance smaller than a predefined value, CD sets the lower bound to the actual number of dimensions of the attractor, which in turn indicates the number of independent variables needed to model the system (Ding et al., 1993;Grebogi et al., 1986). Generally, the larger the CD of a biological signal, the more complex the dynamics of the underlying physiological system.

(p4.2) The complexity of a system can also be measured by a set of Lyapunov exponents (LEs) which describe the system's predictability and stability. Mathematically, LE is quantified as the rate of exponential separation with time of two initially neighbouring points on the attractor (Wolf et al., 1985). Positive and negative values of LE correspond to whether the trajectories of the states exponentially diverge or converge over time. Visually, it characterizes the stretching and shrinking of the phase space respectively. While a system can have multiple LEs, the predictability of the system is mainly determined by the largest LE value (L1). Similar to CD, a larger L1 is suggestive of a more complex signal.

(p4.3) Another important measure also derived from the quantification of the reconstructed attractor is the Kolmogorov-Sinai entropy (KSE, Sinai, 1959). Although originating from information theory (which will be discussed later), KSE can be defined, with respect to the spatial dimensionality perspective, as the rate at which two points that were initially close in the phase space move apart. This definition strongly aligns with that of LE since both measures seek to quantify the changes in volume (stretching/shrinking) of the phase space over time (Kamizawa et al., 2014). In fact, KSE is related to the sum of all positive LEs, which intuitively translates to the total amount of divergence of the temporal trajectories of the states (Pesin, 1977). Generally, a more positive KSE reflects a less predictable system.
## (s5) | Temporal dimensionality
(p5.0) While the methods under the spatial dimensionality group estimate the complexity of the signals by quantifying the characteristics of the attractor, the methods under the temporal dimensionality group directly treat the time series itself as a geometric figure.

(p5.1) For instance, the Higuchi's fractal dimension (HFD) is another common FD index. However, unlike CD, which approximates the FD of a physiological system indirectly from the phase-space reconstruction, HFD calculates the FD directly from the time series (Higuchi, 1988) and is therefore faster and more efficient. Additionally, contrary to other indices such as CD, that assumes signal stationarity (a condition usually not fulfilled by neurophysiological signals), HFD, which does not share this assumption, provides in this context a more accurate estimation of FD (Accardo et al., 1997;Spasic et al., 2011).
## (s9) | Mood and anxiety disorders
(p9.0) Relatedly, several researchers have long underscored the association between enhanced cortical dynamics, healthy cognitive functioning and emotional regulation (Aftanas, Lotova, Koshkarov, Pokrovskaja, et al., 1997;Carlino et al., 2012;Gregson et al., 1993;Lamberts et al., 2000;Martinez-Rodrigo et al., 2019;McIntosh et al., 2008). As cognitive and emotional dysregulation are transdiagnostic markers of mood and anxiety disorders (Holtzheimer & Mayberg, 2011), one might expect lower neural complexity in these patient populations as compared with their healthy counterparts. However, as with the literature on schizophrenia, conflicting trends in mood and anxiety disorders also appear to challenge the unidirectional notion of complexity as being adaptive.

(p9.1) Depression is a disorder characterized by dysthymia and anhedonia, reinforced by inflexible cognitive patterns manifesting primarily as negative ruminations (Holtzheimer & Mayberg, 2011). Studies have reported overall lower values of complexity in the EEG signals of individuals with depression as compared with healthy controls (see Table 2). This may be explained by maladaptive emotion regulation (ER) styles (e.g., selfblaming and rumination, Bornas et al., 2013) and a tendency to fixate on negative emotional states (Holtzheimer & Mayberg, 2011), both of which have been associated with lower EEG complexity.
## (s11) Psychological state/condition EEG complexity Measures
(p11.0) Autistic spectrum disorder (ASD) Healthy controls > ASD MMSE (Bosl et al., 2011;Catarino et al., 2011) SampEn, FuzzyEn (Kang et al., 2019) Mild > severe ASD MSE (Hadoush et al., 2019) Attention deficit hyperactivity disorder (ADHD)
## (s16) | Practical considerations
(p16.0) Other crucial considerations when choosing a complexity metric include the length of the time series and the signal-to-noise ratio (Bravi et al., 2011). For instance, it may be difficult to achieve reliable complexity estimates with CD and L1 due to their underlying assumptions of noise-free and lengthy data (for reconstructing the phase space), as these assumptions are not realistic in clinical applications. On the other hand, LZC may be more robust for short and noisy data (Fernandez et al., 2013). As for HFD, while it has been said to be more accurate for measuring FD as compared with other algorithms and is computationally simpler and faster, its values may be positively skewed by the amount of noise in data (Fernandez et al., 2013). In fact, LZC and HFD have been frequently used as measures of anaesthesia and sedation depth due to their reliability in assessing short data segments, thus making it appropriate for real-time monitoring of patient outcomes (Ferenets et al., 2006;Zhang et al., 2001). In general, it is recommended that researchers report the length of the recordings, as well as the sampling rate (both of which determine the number of data points) to facilitate reproducibility and comparisons of complexity analyses.

(p16.1) Regarding entropy measures, it is important to note that ApEn and SampEn (which are essentially irregularity statistics) have been criticized to be unreflective of a system's complexity. Although MSE was proposed to address this specific limitation (Costa et al., 2002), it requires a substantially longer time series to be accurate. Instead, other versions of MSE (e.g., MMSE) have been proposed to work better with short-term signals (Karmakar et al., 2020), but their performances have not yet been established with physiological signals. Additionally, while entropy-based indices such as ApEn and SampEn are among the most common indices, their sensitivity to the selection of computational parameters have prompted development of more robust approaches, such as FuzzyEn, which uses a fuzzy function instead of a single value of parameter, as well as entropy profiling where variations of parameter values are used to capture the complete profile of entropy (Karmakar et al., 2020;Udhayakumar et al., 2017). Note, however, that entropy profiling has not yet been investigated in the context of EEG signals.
## (s17) | Conclusions
(p17.0) With the constant introduction of new complexity estimators (Tripathy et al., 2017) and modified versions of existing ones (Bai et al., 2015), it has become increasingly difficult for researchers to choose an optimal measure specific to the psychological state of interest. It may seem convenient to use a wide range of them, but this is a practice fraught with issues such as results fishing, cherrypicking and biased interpretations. By enhancing the ease for researchers in navigating the plethora of complexity measures and clarifying their underlying theoretical meanings and their differences, we hope to facilitate new developments in the field. Apart from the inexplicit boundaries between measures of randomness and meaningful complexity, rigorous investigations that consider key factors such as experimental task demands and symptom trajectories are important for well-grounded conclusions to be made about neural complexity. Future meta-analyses of EEG complexity data could be useful in understanding the source of the discrepancies in existing literature and determine the reliability of change in neural complexity with pathology, healthy aging or consciousness states. We may also gain some clarity by investigating complexity-based approaches in relationship with other EEG analysis approaches, such as time/ frequency or connectivity analysis. In summary, as witnessed by the recent rise in related publications, the complexity analysis of EEG signals offers encouraging prospects for both research and clinical endeavours to further our understanding of normal and abnormal neurophysiological functioning.
