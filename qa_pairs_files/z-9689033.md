# Auditory distance perception in humans: a review of cues, development, neuronal bases, and effects of sensory loss

CorpusID: 9689033 - [https://www.semanticscholar.org/paper/3ea3bfb3fe32da086674990e70b1853077c279cf](https://www.semanticscholar.org/paper/3ea3bfb3fe32da086674990e70b1853077c279cf)

Fields: Psychology, Medicine

## (s0) Perceiving distance using sound
(p0.0) Knowledge about the processing of auditory distance cues has been advanced by the development of binaural technology that allows simulation of different acoustical environments via headphone presentation (Zahorik, 2002a). Such technology allows realistic simulation of sounds presented from different distances for various listener positions. It also allows auditory distance cues to be manipulated independently in a controlled way. This technology was used in many of the studies described below.

(p0.1) On average, perceived distance to sound sources in peripersonal space tends to be overestimated, while distance to sounds in extrapersonal space is generally underestimated for normally sighted and hearing humans (Fontana & Rocchesso, 2008;Kearney, Gorzel, Rice, & Boland, 2012;Parseihian, Jouffrais, & Katz, 2014;Zahorik, 2002a;Zahorik, Brungart, & Bronkhorst, 2005;Zahorik & Wightman, 2001). This is illustrated in Fig. 1, which shows distance judgments for noise bursts presented at virtual distances (via a headphone simulation) between 0.3 and 14 m. More veridical judgments are made when close sound sources are presented laterally relative to the listener (Kopčo & Shinn-Cunningham, 2011). This is contrary to azimuthal localization, which is generally more accurate for sources near the midline (Middlebrooks & Green, 1991). Auditory distance judgments are generally most accurate for sound sources approximately 1 m from the listener. Zahorik et al. (2005) demonstrated that systematic biases in distance estimates occur across a wide range of stimulus conditions, acoustic environments, and psychophysical procedures. Based on previous findings, they showed that compressive power functions of the form r′ = kr a gave good fits to distance judgments, where r′ is the judged distance, r is the actual distance, and k and a are adjustable parameters (with a < 1). Such systematic biases are perhaps surprising, given that humans have a tacit knowledge of physical sound propagation losses with increasing distance. This is indicated by the ability to compensate for these losses with fairly accurate adjustment of vocal output level, suggesting that auditory distance processes are to an extent separate from vocal compensation processes (Zahorik & Kelly, 2007). It also is noteworthy that such biases do not occur for visual depth perception, where under natural full-cue conditions distance estimates are highly accurate (Da Silva, 1985).

(p0.2) In addition to being biased, auditory distance estimates appear to be considerably less precise than visual distance estimates. This reduction in precision, or distance Bblur,^is evident in the considerable variability often observed in (unaveraged) auditory distance estimates. For example, Anderson and Zahorik (2014) reported that the average standard deviation of sound source distance estimates was approximately 1.6 times the distance of the target. This corresponds to nearly twice the variability observed for comparable estimates of distance to visual targets .

(p0.3) There are multiple acoustic cues available for perceiving the distance between a listener and a sound source. The number of cues available and their reliability can vary substantially depending upon the stimulus, the properties of the environment, and the direction of the sound source. Two types of auditory distance cues can be distinguished. Absolute cues allow distance to be judged based on single presentations of sounds to independent groups of listeners (Mershon, Ballenger, Little, McMurtry, & Buchanan, 1989). Relative cues allow sounds at different distances to be discriminated. In addition, there is now a considerable body of work showing that visual information and nonperceptual factors can influence estimates of perceived distance. Zahorik, et al. (2005) and Coleman (1963) previously reviewed the auditory distance cues used by humans, and Naguib and Wiley (2001) summarized the use of auditory distance cues by humans and animals. In the following sections, we summarize work that has investigated the cues used for auditory distance perception by normally sighted and hearing humans.
## (s2) Development of auditory distance processing
(p2.0) Infants' perception of auditory distance has generally been assessed by measuring how their actions match spatial information conveyed by proximal sensory stimulation, such as reaching to grasp sound-producing objects (Ashmead, Clifton, & Perris, 1987;Clifton, Perris, & Bullinger, 1991;Litovsky & Clifton, 1992) or moving to avoid approaching objects (Freiberg, Tually, & Crassini, 2001). Such actions suggest that the sound-producing object is perceived in spatial terms relative to the location of the infant (van der Meer, Ramstad, & Van der Weel, 2008). The literature on developmental aspects of auditory distance perception has not been reviewed previously and is discussed in this section. Clifton et al. (1991) showed that infants were able to distinguish between objects in near and far space on the basis of sound by 6 months of age. Sounds were presented in the dark either within reach at 15 cm, or out of reach at 60 cm. Infants reached more frequently towards the location of the sound when positioned within reach than when out of reach. This was replicated in a follow-up study by Litovsky and Clifton (1992), who further demonstrated that infants correctly discriminated between near and far sounds regardless of whether or not sound level was roved to prevent it from providing a useful cue. This suggests that infants use other cues than sound level when judging distance, in contrast to adults tested in the same study, who relied primarily on level cues and whose performance worsened when level was roved.

(p2.1) Using a conditioned head turn technique, Morrongiello, Hewitt, and Gotowiec (1991) showed that by 6 months of age infants were better at discriminating approaching than receding stimuli. They also demonstrated that responses on trials where changes in distance occurred were greater than responses on trials using non-moving sounds that increased or decreased in sound level, suggesting that distance cues other than changes in level were utilized. Freiberg et al.

(p2.2) (2001) used a more direct auditory looming paradigm to assess relative distance perception using sound level cues. They hypothesized that if infants used changing sound level to perceive changes in distance to the sound source, then they would engage in more defensive avoidance behavior for auditory stimuli that increased rather than decreased in level. Consistent with this hypothesis, avoidance behavior, as measured by amount of backward body pressure exerted by the infant, was associated with level increases but not decreases.

(p2.3) Two studies have investigated whether infants are able to coordinate auditory and visual distance information (Morrongiello & Fenwick, 1991;Walker-Andrews & Lennon, 1985). Walker-Andrews and Lennon (1985) showed 5-month-old infants two videos side by side of automobiles approaching or receding. The videos were paired with a soundtrack of a lawn mower either increasing or decreasing in level. Infants looked preferentially at the video that matched the soundtrack for approaching stimuli only. A second study, also using a preferential-looking procedure, showed that 9month-old infants were able to coordinate visual and auditory depth information for both approaching and receding stimuli (Morrongiello & Fenwick, 1991). Visual information of a drum-beating toy was presented on two screens with auditory information that matched one of the screens. The toy was shown moving horizontally in depth or stationary. Fivemonth-old infants only reliably looked preferentially at the stationary toy paired with the stationary sound stimulus, suggesting that they did not recognize that changes in sound level indicated that the distance of an object was changing. Nine-month-old infants preferentially looked at the screen that matched the auditory stimulus for which the depth changed. The authors suggested that the extended time period between perceiving auditory distance at approximately 6 months  and coordinating it with visual depth was due to younger infants having difficulty recognizing that increases and decreases in sound level accompany an object moving in depth, possibly because sounds can vary in level independent of source distance. The discrepancy between their findings and those of Walker-Andrews and Lennon (1985) was attributed to the increased salience of visual depth cues in the prior study, recruiting the attention of 5month-old infants and aiding coordination of audiovisual depth. Overall, these studies suggest that by 9 months of age, infants are able to coordinate visual depth information with auditory distance cues and hence could use visual information in order to calibrate auditory space.

(p2.4) Infants younger than 11 months are able to discriminate increments in sound level of 3 dB and decrements of 6 dB (Bull, Eilers, & Oller, 1984;Sinnott & Aslin, 1985;Tarquinio, Zelazo, & Weiss, 1990). This suggests that changes in level are potentially usable as a distance cue. By 3 years of age, children increase their vocal intensity as the distance from a listener increases (Johnson et al., 1981), indicating that they have at least limited knowledge of the intensity losses due to sound propagation. Further work is needed to determine more closely how auditory distance perception develops, using conditions where individual distance cues are controlled and tested independently of other cues. One possible avenue of further research is to investigate how auditory distance is calibrated for normally sighted, early-and late-onset blind individuals, by investigating the accuracy of absolute auditory distance judgments longitudinally from infancy to adulthood, to establish how internal representations of auditory space are generated and maintained when visual calibration cues are unavailable. The internal representation of auditory distance and its calibration are discussed in more detail in the following section.

(p2.5) Internal representation of distance to a sound source: calibration of auditory peripersonal and extrapersonal space and perceptually guided locomotion For normally sighted listeners, the calibration of auditory distance is thought to be achieved primarily using visual signals, as localizing a sound generally involves directing the gaze toward the sound source to identify it and to obtain further information about it (Lewald, 2002a). Indeed, Perrott, Saberi, Brown, and Strybel (1990) hypothesized that BThe primary function of the auditory spatial system may be to provide information that allows the individual to redirect the eyes in order to bring the fovea into line with an acoustically active object.^As a result, auditory space is constantly updated using visual and motor feedback when developing an internal spatial representation of the surroundings to align auditory and visual spatial representations (Lewald, 2013). For listeners with severe visual losses, an alternative method of calibrating auditory space involves using sensory-motor feedback, such as touching the sound source. A computational sensorimotor model has been developed demonstrating that auditory space can be learned using motor actions without the need for visual cues (Aytekin, Moss, & Simon, 2008). These approaches have emphasized sound localization in azimuth, and calibration of auditory distance judgments has not received as much scientific study. Questions remain regarding how well internal representations of auditory distance can effectively guide the locomotor system in the absence of visual cues, and how the calibration of auditory distance differs in peripersonal space and beyond it.

(p2.6) Visual information can be used to calibrate auditory distance as it provides more accurate spatial information than audition (Da Silva, 1985;Loomis et al., 1998). Auditory distance judgments are more accurate when visual range information regarding the whole scene is available, even if the sound source itself is visually occluded (Calcagno et al., 2012;Zahorik, 2001). Anderson and Zahorik (2014) presented participants with virtual sound sources, simulated using binaural room impulse responses (BRIRs) measured using distances of 0.3 to 9.8 m between a loudspeaker and a KEMAR in a concert hall. They showed that auditory distance judgments were more accurate and less variable when matched to a congruent visual stimulus consisting of a photograph of the measurement loudspeaker taken from the position of the head of the KEMAR.

(p2.7) For accurate distance judgments, the auditory system has to scale appropriately the internal representation of the available distance cues so that the perceptual distance matches the external distance as closely as possible. For example, a reduction of 6 dB in sound level in an anechoic environment should correspond to a doubling of the internal representation of source distance. As described earlier, the distances of remote sounds are systematically underestimated (Fontana & Rocchesso, 2008;Kearney et al., 2012;Zahorik, 2002a;Zahorik et al., 2005), suggesting that internal auditory distance representations in extrapersonal space are not well calibrated (visual cues may be insufficient to accurately calibrate auditory distance in far space) or that the auditory cues do not permit accurate judgments of distance in far space.

(p2.8) In peripersonal space, auditory distance can be calibrated using vision and by touching the sound source. However, auditory distance judgments for sounds presented within this region show overestimation of sound source distance (Zahorik, 2002a;Zahorik & Wightman, 2001), suggesting that auditory distance representations are not well calibrated in peripersonal space either. Internal representations of auditory distance are integrated with tactile information in the space immediately surrounding the head (Farnè & Làdavas, 2002;Graziano, Reiss, & Gross, 1999) or hand (Canzoneri, Magosso, & Serino, 2012;Serino et al., 2007;Serino et al., 2011). In a study by Serino et al. (2007), participants were given an electrical stimulus on their right index finger, paired with a burst of white noise either close to the hand or at a distance of 125 cm. Normally sighted participants showed faster reaction times to tactile stimulation when the concurrent sounds were close than when they were far, indicating the existence of a peri-hand space in which auditory distance cues are integrated with tactile information. Integration of distance information within peripersonal space helps to protect the body from injury (Graziano & Cooke, 2006), as it is within this area that the individual can reach or act on objects, or avoid approaching threats (Canzoneri et al., 2012). Further work is needed to investigate which auditory distance cues are integrated with tactile information in peripersonal space and how they are weighted in this process.
## (s4) Effects of hearing loss and hearing aid processing on auditory distance perception
(p4.0) In contrast to investigations of the effects of hearing loss on localization in azimuth (see Keating & King, 2013 for a review), there are relatively few psychophysical studies and no neuronal studies of how auditory distance perception is affected by hearing loss. Effects of hearing aid processing, which potentially may distort available auditory distance cues, also have received relatively little attention. Adverse effects of hearing impairment or hearing-aid processing on auditory distance perception may be compensated to some extent by visual depth information for normally sighted listeners. However, considerable difficulties may occur in situations where vision is degraded, and although hearing loss is an important consideration for blind listeners, this area of enquiry is currently under-researched. The effect of sensory loss and hearing aid processing on auditory distance perception is especially important for older people, because visual and auditory losses are more prevalent in this group. Akeroyd et al. (2007) compared the effectiveness of level and DRR distance cues combined with DRR alone for normal-hearing and hearing-impaired participants. They measured distance discrimination for sentence pairs at virtual distances between 1 and 8 m. Hearing-impaired participants generally performed as well as normally hearing participants when both cues were available, although hearing-impaired participants performed more poorly for simulated distances greater than 5 m. Hearing-impaired participants performed more poorly when the level cue was made unavailable by fixing the overall level of the sounds, suggesting deficits in the ability to discriminate distance using DRR. The scores obtained with DRR cues alone were correlated with selfreported auditory distance perception abilities.

(p4.1) Most modern hearing aids include amplitude compression that applies high gain for low-level sounds and low gain for high-level sounds. This increases the audibility of low-level sounds without making intense sounds uncomfortably loud (Moore, 2008). However, alterations to sound level due to hearing aid processing may alter the cues utilized to perceive distance accurately (Simon & Levitt, 2007). Amplitude compression alters level cues and can affect DRR cues by reducing gain for high-level direct sound while providing high gain for low-level reverberant sound. However, for continuous speech, the reverberant tail only occurs in isolation, during pauses in speech. Thus, adverse effects of hearing aid processing might be expected to be small or negligible. This was found in a study by Akeroyd (2010), who investigated distance discrimination for continuous speech using the design of Akeroyd et al. (2007) described above, with level and DRR cues both available. Akeroyd (2010) did not find any adverse effects of hearing-aid compression produced by the participants' own hearing aids. As the participants were experienced hearing aid users, it is possible that they acclimatized to the effects of their own hearing aids on sound level. It also is possible that no adverse effects were found, because the amount of amplitude compression was small or because the gain changed too slowly to affect the DRR. Effects of hearing-aid compression might be observed for absolute distance judgments rather than the relative distance task utilized in the study (Akeroyd, 2010).

(p4.2) Hearing aid compression may affect the use of ILD distance cues (Simon & Levitt, 2007) even for continuous speech, and although this has not yet been directly assessed, there is evidence that compression distorts ILD cues for localization in azimuth. Musa-Shufani et al. (2006) tested normally hearing and hearing-impaired participants with narrow-band one-third octave wide noise signals centered at 500 and 4000 Hz in a localization task. Hearing aids were simulated with linear processing or fixed amounts of fast or slow compression. Fast compression was found to increase JNDs in ILD compared with linear processing.
## (s7) Perceiving distance using sound
(p7.0) Knowledge about the processing of auditory distance cues has been advanced by the development of binaural technology that allows simulation of different acoustical environments via headphone presentation (Zahorik, 2002a). Such technology allows realistic simulation of sounds presented from different distances for various listener positions. It also allows auditory distance cues to be manipulated independently in a controlled way. This technology was used in many of the studies described below.

(p7.1) On average, perceived distance to sound sources in peripersonal space tends to be overestimated, while distance to sounds in extrapersonal space is generally underestimated for normally sighted and hearing humans (Fontana & Rocchesso, 2008;Kearney, Gorzel, Rice, & Boland, 2012;Parseihian, Jouffrais, & Katz, 2014;Zahorik, 2002a;Zahorik, Brungart, & Bronkhorst, 2005;Zahorik & Wightman, 2001). This is illustrated in Fig. 1, which shows distance judgments for noise bursts presented at virtual distances (via a headphone simulation) between 0.3 and 14 m. More veridical judgments are made when close sound sources are presented laterally relative to the listener (Kopčo & Shinn-Cunningham, 2011). This is contrary to azimuthal localization, which is generally more accurate for sources near the midline (Middlebrooks & Green, 1991). Auditory distance judgments are generally most accurate for sound sources approximately 1 m from the listener. Zahorik et al. (2005) demonstrated that systematic biases in distance estimates occur across a wide range of stimulus conditions, acoustic environments, and psychophysical procedures. Based on previous findings, they showed that compressive power functions of the form r′ = kr a gave good fits to distance judgments, where r′ is the judged distance, r is the actual distance, and k and a are adjustable parameters (with a < 1). Such systematic biases are perhaps surprising, given that humans have a tacit knowledge of physical sound propagation losses with increasing distance. This is indicated by the ability to compensate for these losses with fairly accurate adjustment of vocal output level, suggesting that auditory distance processes are to an extent separate from vocal compensation processes (Zahorik & Kelly, 2007). It also is noteworthy that such biases do not occur for visual depth perception, where under natural full-cue conditions distance estimates are highly accurate (Da Silva, 1985).

(p7.2) In addition to being biased, auditory distance estimates appear to be considerably less precise than visual distance estimates. This reduction in precision, or distance Bblur,^is evident in the considerable variability often observed in (unaveraged) auditory distance estimates. For example, Anderson and Zahorik (2014) reported that the average standard deviation of sound source distance estimates was approximately 1.6 times the distance of the target. This corresponds to nearly twice the variability observed for comparable estimates of distance to visual targets .

(p7.3) There are multiple acoustic cues available for perceiving the distance between a listener and a sound source. The number of cues available and their reliability can vary substantially depending upon the stimulus, the properties of the environment, and the direction of the sound source. Two types of auditory distance cues can be distinguished. Absolute cues allow distance to be judged based on single presentations of sounds to independent groups of listeners (Mershon, Ballenger, Little, McMurtry, & Buchanan, 1989). Relative cues allow sounds at different distances to be discriminated. In addition, there is now a considerable body of work showing that visual information and nonperceptual factors can influence estimates of perceived distance. Zahorik, et al. (2005) and Coleman (1963) previously reviewed the auditory distance cues used by humans, and Naguib and Wiley (2001) summarized the use of auditory distance cues by humans and animals. In the following sections, we summarize work that has investigated the cues used for auditory distance perception by normally sighted and hearing humans.
## (s9) Development of auditory distance processing
(p9.0) Infants' perception of auditory distance has generally been assessed by measuring how their actions match spatial information conveyed by proximal sensory stimulation, such as reaching to grasp sound-producing objects (Ashmead, Clifton, & Perris, 1987;Clifton, Perris, & Bullinger, 1991;Litovsky & Clifton, 1992) or moving to avoid approaching objects (Freiberg, Tually, & Crassini, 2001). Such actions suggest that the sound-producing object is perceived in spatial terms relative to the location of the infant (van der Meer, Ramstad, & Van der Weel, 2008). The literature on developmental aspects of auditory distance perception has not been reviewed previously and is discussed in this section. Clifton et al. (1991) showed that infants were able to distinguish between objects in near and far space on the basis of sound by 6 months of age. Sounds were presented in the dark either within reach at 15 cm, or out of reach at 60 cm. Infants reached more frequently towards the location of the sound when positioned within reach than when out of reach. This was replicated in a follow-up study by Litovsky and Clifton (1992), who further demonstrated that infants correctly discriminated between near and far sounds regardless of whether or not sound level was roved to prevent it from providing a useful cue. This suggests that infants use other cues than sound level when judging distance, in contrast to adults tested in the same study, who relied primarily on level cues and whose performance worsened when level was roved.

(p9.1) Using a conditioned head turn technique, Morrongiello, Hewitt, and Gotowiec (1991) showed that by 6 months of age infants were better at discriminating approaching than receding stimuli. They also demonstrated that responses on trials where changes in distance occurred were greater than responses on trials using non-moving sounds that increased or decreased in sound level, suggesting that distance cues other than changes in level were utilized. Freiberg et al.

(p9.2) (2001) used a more direct auditory looming paradigm to assess relative distance perception using sound level cues. They hypothesized that if infants used changing sound level to perceive changes in distance to the sound source, then they would engage in more defensive avoidance behavior for auditory stimuli that increased rather than decreased in level. Consistent with this hypothesis, avoidance behavior, as measured by amount of backward body pressure exerted by the infant, was associated with level increases but not decreases.

(p9.3) Two studies have investigated whether infants are able to coordinate auditory and visual distance information (Morrongiello & Fenwick, 1991;Walker-Andrews & Lennon, 1985). Walker-Andrews and Lennon (1985) showed 5-month-old infants two videos side by side of automobiles approaching or receding. The videos were paired with a soundtrack of a lawn mower either increasing or decreasing in level. Infants looked preferentially at the video that matched the soundtrack for approaching stimuli only. A second study, also using a preferential-looking procedure, showed that 9month-old infants were able to coordinate visual and auditory depth information for both approaching and receding stimuli (Morrongiello & Fenwick, 1991). Visual information of a drum-beating toy was presented on two screens with auditory information that matched one of the screens. The toy was shown moving horizontally in depth or stationary. Fivemonth-old infants only reliably looked preferentially at the stationary toy paired with the stationary sound stimulus, suggesting that they did not recognize that changes in sound level indicated that the distance of an object was changing. Nine-month-old infants preferentially looked at the screen that matched the auditory stimulus for which the depth changed. The authors suggested that the extended time period between perceiving auditory distance at approximately 6 months  and coordinating it with visual depth was due to younger infants having difficulty recognizing that increases and decreases in sound level accompany an object moving in depth, possibly because sounds can vary in level independent of source distance. The discrepancy between their findings and those of Walker-Andrews and Lennon (1985) was attributed to the increased salience of visual depth cues in the prior study, recruiting the attention of 5month-old infants and aiding coordination of audiovisual depth. Overall, these studies suggest that by 9 months of age, infants are able to coordinate visual depth information with auditory distance cues and hence could use visual information in order to calibrate auditory space.

(p9.4) Infants younger than 11 months are able to discriminate increments in sound level of 3 dB and decrements of 6 dB (Bull, Eilers, & Oller, 1984;Sinnott & Aslin, 1985;Tarquinio, Zelazo, & Weiss, 1990). This suggests that changes in level are potentially usable as a distance cue. By 3 years of age, children increase their vocal intensity as the distance from a listener increases (Johnson et al., 1981), indicating that they have at least limited knowledge of the intensity losses due to sound propagation. Further work is needed to determine more closely how auditory distance perception develops, using conditions where individual distance cues are controlled and tested independently of other cues. One possible avenue of further research is to investigate how auditory distance is calibrated for normally sighted, early-and late-onset blind individuals, by investigating the accuracy of absolute auditory distance judgments longitudinally from infancy to adulthood, to establish how internal representations of auditory space are generated and maintained when visual calibration cues are unavailable. The internal representation of auditory distance and its calibration are discussed in more detail in the following section.

(p9.5) Internal representation of distance to a sound source: calibration of auditory peripersonal and extrapersonal space and perceptually guided locomotion For normally sighted listeners, the calibration of auditory distance is thought to be achieved primarily using visual signals, as localizing a sound generally involves directing the gaze toward the sound source to identify it and to obtain further information about it (Lewald, 2002a). Indeed, Perrott, Saberi, Brown, and Strybel (1990) hypothesized that BThe primary function of the auditory spatial system may be to provide information that allows the individual to redirect the eyes in order to bring the fovea into line with an acoustically active object.^As a result, auditory space is constantly updated using visual and motor feedback when developing an internal spatial representation of the surroundings to align auditory and visual spatial representations (Lewald, 2013). For listeners with severe visual losses, an alternative method of calibrating auditory space involves using sensory-motor feedback, such as touching the sound source. A computational sensorimotor model has been developed demonstrating that auditory space can be learned using motor actions without the need for visual cues (Aytekin, Moss, & Simon, 2008). These approaches have emphasized sound localization in azimuth, and calibration of auditory distance judgments has not received as much scientific study. Questions remain regarding how well internal representations of auditory distance can effectively guide the locomotor system in the absence of visual cues, and how the calibration of auditory distance differs in peripersonal space and beyond it.

(p9.6) Visual information can be used to calibrate auditory distance as it provides more accurate spatial information than audition (Da Silva, 1985;Loomis et al., 1998). Auditory distance judgments are more accurate when visual range information regarding the whole scene is available, even if the sound source itself is visually occluded (Calcagno et al., 2012;Zahorik, 2001). Anderson and Zahorik (2014) presented participants with virtual sound sources, simulated using binaural room impulse responses (BRIRs) measured using distances of 0.3 to 9.8 m between a loudspeaker and a KEMAR in a concert hall. They showed that auditory distance judgments were more accurate and less variable when matched to a congruent visual stimulus consisting of a photograph of the measurement loudspeaker taken from the position of the head of the KEMAR.

(p9.7) For accurate distance judgments, the auditory system has to scale appropriately the internal representation of the available distance cues so that the perceptual distance matches the external distance as closely as possible. For example, a reduction of 6 dB in sound level in an anechoic environment should correspond to a doubling of the internal representation of source distance. As described earlier, the distances of remote sounds are systematically underestimated (Fontana & Rocchesso, 2008;Kearney et al., 2012;Zahorik, 2002a;Zahorik et al., 2005), suggesting that internal auditory distance representations in extrapersonal space are not well calibrated (visual cues may be insufficient to accurately calibrate auditory distance in far space) or that the auditory cues do not permit accurate judgments of distance in far space.

(p9.8) In peripersonal space, auditory distance can be calibrated using vision and by touching the sound source. However, auditory distance judgments for sounds presented within this region show overestimation of sound source distance (Zahorik, 2002a;Zahorik & Wightman, 2001), suggesting that auditory distance representations are not well calibrated in peripersonal space either. Internal representations of auditory distance are integrated with tactile information in the space immediately surrounding the head (Farnè & Làdavas, 2002;Graziano, Reiss, & Gross, 1999) or hand (Canzoneri, Magosso, & Serino, 2012;Serino et al., 2007;Serino et al., 2011). In a study by Serino et al. (2007), participants were given an electrical stimulus on their right index finger, paired with a burst of white noise either close to the hand or at a distance of 125 cm. Normally sighted participants showed faster reaction times to tactile stimulation when the concurrent sounds were close than when they were far, indicating the existence of a peri-hand space in which auditory distance cues are integrated with tactile information. Integration of distance information within peripersonal space helps to protect the body from injury (Graziano & Cooke, 2006), as it is within this area that the individual can reach or act on objects, or avoid approaching threats (Canzoneri et al., 2012). Further work is needed to investigate which auditory distance cues are integrated with tactile information in peripersonal space and how they are weighted in this process.
## (s11) Effects of hearing loss and hearing aid processing on auditory distance perception
(p11.0) In contrast to investigations of the effects of hearing loss on localization in azimuth (see Keating & King, 2013 for a review), there are relatively few psychophysical studies and no neuronal studies of how auditory distance perception is affected by hearing loss. Effects of hearing aid processing, which potentially may distort available auditory distance cues, also have received relatively little attention. Adverse effects of hearing impairment or hearing-aid processing on auditory distance perception may be compensated to some extent by visual depth information for normally sighted listeners. However, considerable difficulties may occur in situations where vision is degraded, and although hearing loss is an important consideration for blind listeners, this area of enquiry is currently under-researched. The effect of sensory loss and hearing aid processing on auditory distance perception is especially important for older people, because visual and auditory losses are more prevalent in this group. Akeroyd et al. (2007) compared the effectiveness of level and DRR distance cues combined with DRR alone for normal-hearing and hearing-impaired participants. They measured distance discrimination for sentence pairs at virtual distances between 1 and 8 m. Hearing-impaired participants generally performed as well as normally hearing participants when both cues were available, although hearing-impaired participants performed more poorly for simulated distances greater than 5 m. Hearing-impaired participants performed more poorly when the level cue was made unavailable by fixing the overall level of the sounds, suggesting deficits in the ability to discriminate distance using DRR. The scores obtained with DRR cues alone were correlated with selfreported auditory distance perception abilities.

(p11.1) Most modern hearing aids include amplitude compression that applies high gain for low-level sounds and low gain for high-level sounds. This increases the audibility of low-level sounds without making intense sounds uncomfortably loud (Moore, 2008). However, alterations to sound level due to hearing aid processing may alter the cues utilized to perceive distance accurately (Simon & Levitt, 2007). Amplitude compression alters level cues and can affect DRR cues by reducing gain for high-level direct sound while providing high gain for low-level reverberant sound. However, for continuous speech, the reverberant tail only occurs in isolation, during pauses in speech. Thus, adverse effects of hearing aid processing might be expected to be small or negligible. This was found in a study by Akeroyd (2010), who investigated distance discrimination for continuous speech using the design of Akeroyd et al. (2007) described above, with level and DRR cues both available. Akeroyd (2010) did not find any adverse effects of hearing-aid compression produced by the participants' own hearing aids. As the participants were experienced hearing aid users, it is possible that they acclimatized to the effects of their own hearing aids on sound level. It also is possible that no adverse effects were found, because the amount of amplitude compression was small or because the gain changed too slowly to affect the DRR. Effects of hearing-aid compression might be observed for absolute distance judgments rather than the relative distance task utilized in the study (Akeroyd, 2010).

(p11.2) Hearing aid compression may affect the use of ILD distance cues (Simon & Levitt, 2007) even for continuous speech, and although this has not yet been directly assessed, there is evidence that compression distorts ILD cues for localization in azimuth. Musa-Shufani et al. (2006) tested normally hearing and hearing-impaired participants with narrow-band one-third octave wide noise signals centered at 500 and 4000 Hz in a localization task. Hearing aids were simulated with linear processing or fixed amounts of fast or slow compression. Fast compression was found to increase JNDs in ILD compared with linear processing.
## (s13) Concluding remarks and suggestions for further research
(p13.0) Despite the advances in our understanding of auditory distance perception, this area remains relatively underresearched compared with sound localization in azimuth. There are currently gaps in our understanding of the effects of partial visual loss, dual loss, occluding objects, background noise, and multiple sources on perceived distance to sounds, and accuracy of distance judgements for sounds located behind or vertically relative to the listener. These areas require further study and are discussed below.

(p13.1) Very little is currently known regarding the effects of partial non-correctable visual loss on auditory distance perception, and perceptual processing in this population remains underresearched relative to that for those with total visual losses (Occelli, Spence, & Zampini, 2013). Kolarik et al.(2013b) found no difference in auditory distance discrimination using level, DRR, or both cues between a partially sighted group and a normally sighted group, whereas enhanced performance was found for those with full visual loss. The possibility that partial visual loss may affect auditory distance perception is suggested by work indicating that partial sensory loss can affect abilities in unimpaired modalities (Bavelier, Dye, & Hauser, 2006;Després, Candas, & Dufour, 2005;Dufour & Gérard, 2000;Hoover, Harris, & Steeves, 2012). However, reports of the effects of partial visual loss on localization in azimuth have been conflicting. Enhanced auditory localization in azimuth was reported for participants who had lost one eye (Hoover et al., 2012) or were myopic (Després et al., 2005;Dufour & Gérard, 2000). However, Lessard et al. (1998) found no evidence of sensory compensation among a partially sighted group for localization in azimuth.

(p13.2) The consequences of auditory impairment for spatial awareness are of high importance to those with severe visual loss, due to their increased reliance on auditory cues (Simon & Levitt, 2007). However, we are not aware of any studies that have assessed auditory distance perception for those with dual losses. DRR sensitivity for distance discrimination is enhanced following severe visual loss (Kolarik et al., 2013b) but is reduced following hearing impairment (Akeroyd et al., 2007). Research is needed to establish whether compensation associated with blindness provides a Bbuffer^for diminished hearing abilities associated with ageing or whether hearing loss degrades auditory distance discrimination for both normally sighted and blind individuals.
