# A Survey of Blockchain Data Management Systems

CorpusID: 244714223 - [https://www.semanticscholar.org/paper/0f38b3d717e0fcc6eacc9c6e78b252227440e04e](https://www.semanticscholar.org/paper/0f38b3d717e0fcc6eacc9c6e78b252227440e04e)

Fields: Business, Computer Science

## (s2) Hybrid Blockchain
(p2.0) Different with standard blockchain systems, hybrid blockchain systems are not public to all nodes but still offer blockchain features such as integrity, transparency, and security. The hybrid blockchain members can decide who can participate in the blockchain or which transactions are public. The blockchain architecture of a hybrid blockchain can have either one single listed chain as a standard blockchain system or several alliance chains. For the alliance chains, each chain corresponds to a set of ledgers, so each peer node in the blockchain may maintain multiple sets of ledgers. The structure of each chain is the same as a standard blockchain.

(p2.1) Similar to a standard blockchain system, a hybrid blockchain system also maintains transactions with the data structure of blocks. Each block mainly includes three parts: the relevant data of the block, the data related to its previous block, and the block metadata. The data of the block generally includes block hash and account number. Block metadata mainly includes the block creation time and signature.

(p2.2) For the blockchain storage engine, hybrid blockchain usually adopts a combination of databases and file systems. For instance, the storage engine of Hyperledger Fabric [13] is composed of LevelDB and a file system. The storage engine of Ripple [6] is composed of a relational database (SQLite) and a key-value store.
## (s10) Optimization for Query
(p10.0) Engine. Current blockchain systems lack a complete and efficient query system, the query efficiency is low and the provided query interfaces are limited. The underlying data storage system of most standard blockchain systems uses Log-structured Merge Tree (LSM-tree) based key-value stores, which sacrifice read performance in exchange for write performance. Moreover, the unstructured data storage system based on the Key-Value model does not support complex queries, which has become the main bottleneck to restrict query functions.

(p10.1) Xu et al. [96] propose a novel framework, called vChain, to alleviate the storage and computation cost of blockchain systems. The scheme employs verifiable queries to guarantee data integrity. To support verifiable Boolean range queries, they propose an accumulator-based authenticated data structure that enables dynamic aggregation over arbitrary query attributes. Two new types of indexes are developed to aggregate intra-block and inter-block data records for efficient query verification. They also propose an inverted prefix tree to accelerate the processing of a large number of subscription queries simultaneously. Although verifiable query ensures data integrity, it also brings high ADS maintenance costs.

(p10.2) By analyzing the performance of the existing techniques, Zhang et al. [103] propose a novel ADS, called 2 − , which is not only gas-efficient but also effective in supporting authenticated queries. To further reduce the ADS maintenance cost without sacrificing query performance, they also propose an optimized structure, 2 * − , by designing a two-level index structure. Zhang et al. [102] apply an authenticated query process, in which both the smart contract and the off-chain SP maintain an authenticated data structure (ADS) named Merkle inverted index. The Merkle inverted index is an inverted index in which each keyword corresponds to a Merkle B-tree (MBtree) that indexes the corresponding object IDs. The smart contract maintains only the root digest of each MB-tree in the Merkle inverted index. This idea comes with the observation that for the on-chain ADS, only the root digests are used during the authenticated keyword search, which reduced the storage burden.
## (s13) Data distribution
(p13.0) Xu et al. [98] 2018 Decrease in decentralization Dai et al. [19] 2018 Increase query complexity Guo et al. [35] 2019 Increase query complexity Jiang et al. [41] 2020 Increase query complexity Excessive data load
## (s21) Optimization for Hybrid Blockchain Data Structure
(p21.0) As mentioned, hybrid blockchain systems have the same data structures as standard blockchain systems. Therefore, the technologies on data structure optimization for standard blockchain systems are also applicable to hybrid blockchain systems. Moreover, several studies [36,37] are proposed specifically to improve the hybrid blockchain performance.

(p21.1) Gupta et al. [36] discuss the problem of how to efficiently handle temporal queries on Hyperledger Fabric. The temporal nature of the data inserted by the Hyperledger Fabric transactions can be leveraged to support various use cases. They present two models to overcome these limitations and improve the performance of temporal queries on Fabric. The first model creates a copy of each event inserted by a Fabric transaction and stores temporally close to events together on Fabric. The second model keeps the event count intact but tags some metadata to each event inserted on Fabric, and temporally close events share the same metadata.

(p21.2) Further, Gupta et al. [37] present a variant based on these two models to better handle skew data patterns. The variant significantly outperforms the approaches presented in [36] when Fabric contains skew data. They also discuss the performance tradeoffs among the variant across various dimensions such as data storage, query performance, event insertion time, etc. Same as the Standard Blockchain system, improving query efficiency also increases the complexity of the entire system model, requiring more resources to complete the entire transaction processing.
## (s23) Optimization for Excessive Data Load.
(p23.0) Like the standard blockchain, some research papers aim to optimize the excessive data storage problem for hybrid blockchain. They also adopt data sharding and data coding methods. Some up-mentioned methods for the standard blockchain method are still applicable to the hybrid blockchain. Further, there are some other designs for the special application execution environment of the hybrid blockchain.

(p23.1) Qi et al. [79] use erasure coding to reduce the storage pressure of the permissioned blockchain. Specifically, two ideas are designed to achieve scalability and speed up reading performance: i) a four-phase re-encoding protocol based on PBFT to promise the availability of all blocks; ii) a multiple replication manner to ensure efficient access of blocks.

(p23.2) Zheng et al. [105] propose Meepo to use multiple execution environments per organization. Meepo also uses the idea of data sharding which includes two main processes: cross-epoch and cross-call. After the consensus of each block ends, each shard begins to communicate across shards. This process is so-called cross-epoch. While cross-call is sharing the message from one shard to another, resulting from cross-shard transactions, such as cross-shard payment. Meepo aggregates cross-calls into several cross-epochs in order and proposes a partial cross-call merging strategy to improve the smart contract flexibility in sharding environments.

(p23.3) Bandara et al. [8] propose Rahasak, in which all blocks, transactions and asset information are stored in a distributed database. Every blockchain peer comes with a distributed database node; these nodes are connected as a ring cluster. After executing a transaction, state update in a peer is distributed and replicated with other peers via underlying distributed databases' sharding algorithm. However, this approach causes the loss of the immutability of the blockchain itself and further incurs more security problems.
## (s27) Optimization for DAG-based Blockchain Architecture
(p27.0) Wang et al. [88] present Re-Tangle, a novel DAG-based blockchain acceleration architecture that explores the opportunity of performing massive parallel operations with low energy cost. Specifically, ReRAM (Resistive Random Access Memory), an emerging non-volatile memory with computation capacity, is utilized to optimize the Tangle working process for DAG-based blockchain systems. Re-Tangle consists of a random walking module and a transaction validation module, which transfers Tangle functions into ReRAM-based logic analog computation units. In the random walking module, Re-Tangle maintains an exponentiation translator to reduce its design complexity and improves its computation efficiency for exponentiation calculation. In the transaction validation module, Re-Tangle leverages a highly parallel modular unit to accelerate the validation of different tags in a transaction. Although the use of a ReRAM-based accelerator can significantly improve overall transaction speed and reduce resource consumption, it has not really landed yet, so currently the solution is practical.
## (s28) Optimization for data storage engine
(p28.0) Unique address checking is one essential process to guarantee that each transaction from each user account (wallet) is associated with a unique private/public key pair, in which the public and private keys will be utilized as the address and for the signature of the transaction, respectively. Currently, DAG-based blockchain systems usually adopt a database-based approach that relies on the time and space consuming database query process to perform the unique address checking process. To address this problem, several approaches have been proposed.

(p28.1) Shafeeq et al. [82] design a cuckoo filter embedded into IOTA lightweight clients to help accelerate this address checking process. This design is based on the assumption that the addresses can be reused after a snapshot, which is performed periodically to reduce Tangle size. They build a Bloom filter for addresses in the current Tangle to promise uniqueness. However, this assumption is unrealistic and makes this design hard to be deployed in practice.

(p28.2) Wang et al. [90] propose a method called ABACUS to utilize a two-level partitioned bloom filter to perform address checking. Partitioned bloom filters are responsible for storing all spent addresses according to their prefixes, and one SBF (Sub Bloom Filter) of each partitioned bloom filter is kept in memory as a write buffer. However, this approach focuses on optimizing bloom filter update operations so as to speed up unique address checking. Besides, ABACUS assumes all the address checking processes are performed within the paying account and ignores the temporal locality of the addresses.

(p28.3) Zhu et al. [108] propose a Hotness aware and Fine-grained Bloom Filter (HF-BF) for unique address checking in DAG-based blockchains. They divide the whole address space into several subspaces according to the address prefix. For each subspace, a Bloom Filter Group (BFG) that consists of u Bloom Filter units (BFUs) corresponding with K hash functions is used to perform the unique address checking. A BFU is a fine-grained bloom filter composed of a bit array for K hash functions. To manage the large storage footprint of BFUs and decrease the number of I/Os for checking addresses as much as possible, they design an adaptive BFU management scheme to schedule active BFUs between memory and disk. This solution has certain security risks. Since the address is not stored, once an error occurs in the blockchain network, the transaction cannot be traced back.
## (s30) BLOCKCHAIN-ASSISTED DATABASES
(p30.0) With decentralization, non-tampering, and data consistency, blockchain systems are proposed to assist the design of databases from four aspects: data security protection, scalability, secure query, and authentication. Table 6 provides a summary of these studies.

(p30.1) • Data security protection. Benefiting from its safety and immutability, many works choose to use the blockchain as the underlying storage to solve the data security problem. In the blockchain environment, data can be shared safely, and the built-in consensus mechanism ensure that the use of data is subject to certain rules.

(p30.2) Chen et al. [14] propose an improved P2P file database based on IPFS blockchain. They address the low-throughput problem for individual users in IPFS by introducing the role of content service providers. Considering data reliability and availability, storage overhead, and other issues for service providers, they provide a novel zigzag-based storage model to improve the throughput of the block storage model. They chose Bitcoin as the underlying blockchain at the bottom layer of the storage model. All transactions are processed in the upper layer, and then are sent and stored to the blockchain layer. Verified transactions are added to the underlying blockchain, while unverified transactions are discarded. In this environment, the blockchain system is only used as storage. Once the verification service is completed by the node as the service provider, the centralization and non-tampering characteristics of the blockchain system are erased, and the overall security of the system cannot be guaranteed.

(p30.3) El-Hindi et al. [27] utilize blockchains as a storage layer and introduce a database layer on top to extend blockchains by classical data management techniques (e.g., sharding). Further, BlockchainDB provides a standardized key/value-based query interface to facilitate the adoption of blockchains for data sharing. Thus, by using BlockchainDB, we can not only improve the performance and scalability Table 6. A brief overview of existing works of using blockchain-assist database.
## (s31) Target problem Authors
(p31.0) Year Weakness of blockchains for data sharing but also decrease the implementation complexity. On the other hand, the database layer used for expansion will bring additional storage resource consumption. AliNSF et al. [3] propose the design and implementation of a new blockchain-based naming and storage system, called Blockstack. Unlike previous blockchain-based systems, Blockstack separates its control and data planes: it keeps only minimal metadata (namely, data hashes and state transitions) in the blockchain and uses external data stores for actual bulk storage. Grabis et al. [34] elaborate a method for efficient distributed storage and sharing of personal data assets within a community of users. The access to these data is controlled using a blockchain and smart contracts that define access conditions. Yang et al. [100] propose the smart toy edge computing-oriented data exchange accounting system based on the blockchain. Through smart contracts, each node in a data-exchange P2P network makes consensus and endorsements for each other, queries the transaction record and checks the payment bill from its local blockchain peer. Same as [100], there are also some other works [2,28,45,80] that use the storage of data on the blockchain and the use of smart contracts for secure cloud data sharing.
