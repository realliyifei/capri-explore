# A review of some recent advances in causal inference

CorpusID: 10281344 - [https://www.semanticscholar.org/paper/9b0421577994a4a74729de5eecde4e0b020bd6ac](https://www.semanticscholar.org/paper/9b0421577994a4a74729de5eecde4e0b020bd6ac)

Fields: Mathematics, Computer Science, Biology

## (s2) Problem formulation
(p2.0) It is relatively straightforward to make "standard" predictions based on observational data (see the "observational world" in Figure 1), or to estimate causal effects from randomized controlled experiments (see the "experimental world" in Figure 1). But we want to estimate causal effects from observational data. This means that we need to move from the observational world to the experimental world. This step is fundamentally impossible without causal assumptions, even in the large sample limit with perfect knowledge about the observational distribution (cf. Section 2 of [43]). In other words, causal assumptions are needed to deduce the post-intervention distribution from the observational distribution. In this paper, we assume that the data were generated from a (known or unknown) causal structure which can be represented by a directed acyclic graph (DAG).
## (s5) Post-intervention distributions and causal effects
(p5.0) Now how does the framework of the SEM allow us to move between the observational and experimental worlds? This is straightforward, since an intervention at some variable X i simply means that we change the generating mechanism of X i , that is, we change the corresponding structural equation g i (·) (and leave the other structural equations unchanged). For example, one can let X i ← i where i has some given distribution, or X i ← x i for some fixed value x i in the support of X i . The latter is often denoted as Pearl's do-intervention do(X i = x i ) and is interpreted as setting the variable X i to the value x i by an outside intervention, uniformly over the entire population [43].

(p5.1) Example 4. In the prisoners example (see Examples 1 and 3), the quantity P (R = 1|do(P = 1)) represents the rearrest probability when all prisoners are forced to participate in the program, while P (R = 1|do(P = 0)) is the rearrest probability if no prisoner is allowed to participate in the program. We emphasize that these quantities are generally not equal to the usual conditional probabilities P (R = 1|P = 1) and P (R = 1|P = 0), which represent the rearrest probabilities among prisoners who choose to participate or not to participate in the program.

(p5.2) In the gene expression example (see Example 2), let X i and X j represent the gene expression level of genes i and j. Then E(X j |do(X i = x i )) represents the average expression level of gene j after setting the gene expression level of gene i to the value x i by an outside intervention.

(p5.3) Truncated factorization formula. A do-intervention on X i means that X i no longer depends on its former parents in the DAG, so that the incoming edges into X i can be removed. This leads to a so-called truncated DAG. The post-intervention distribution factorizes according to this truncated DAG, so that we get:
## (s6) Causal structure learning
(p6.0) The material in the previous section can be used if the causal DAG is known. In settings with big data, however, it is rare that one can draw the causal DAG. In this section, we therefore consider methods for learning DAGs from observational data. Such methods are called causal structure learning methods.

(p6.1) Recall from Section 2.2 that DAGs encode conditional independencies via d-separation. Thus, by considering conditional independencies in the observational distribution, one may hope to reverse-engineer the causal DAG that generated the data. Unfortunately, this does not work in general, since the same set of d-separation relationships can be encoded by several DAGs. Such DAGs are called Markov equivalent and form a Markov equivalence class.

(p6.2) A Markov equivalence class can be described uniquely by a completed partially directed acyclic graph (CPDAG) [3,9]. The skeleton of the CPDAG is defined as follows. Two nodes X i and X j are adjacent in the CPDAG if and only if, in any DAG in the Markov equivalence class, X i and X j cannot be d-separated by any set of the remaining nodes. The orientation of the edges in the CPDAG is as follows. A directed edge X i → X j in the CPDAG means that the edge X i → X j occurs in all DAGs in the Markov equivalence class. An undirected edge X i − X j in the CPDAG means that there is a DAG in the Markov equivalence class with X i → X j , as well as a DAG with X i ← X j .

(p6.3) It can happen that a distribution contains more conditional independence relationships than those that are encoded by the DAG via d-separation. If this is not the case, then the distribution is called faithful with respect to the DAG. If a distribution is both Markov and faithful with respect to a DAG, then the conditional independencies in the distribution correspond exactly to d-separation relationships in the DAG, and the DAG is called a perfect map of the distribution.

(p6.4) Problem setting. Throughout this section, we consider the following setting. We are given n i.i.d. observations of X, where X = (X 1 , . . . , X p ) is generated from a SEM. We assume that the corresponding causal DAG G is a perfect map of the distribution of X. We aim to learn the Markov equivalence class of G.

(p6.5) In the following three subsections we discuss so-called constraint-based, score-based and hybrid methods for this task. The discussed algorithms are available in the R-package pcalg [29]. In the last subsection we discuss a class of methods that can be used if one is willing to impose additional restrictions on the SEM that allow identification of the causal DAG (rather than its CPDAG).
## (s8) Score-based methods
(p8.0) Score-based methods learn the CPDAG by (greedily) searching for an optimally scoring DAG, where the score measures how well the data fits to the DAG, while penalizing the complexity of the DAG.

(p8.1) A prominent example of such an algorithm is the greedy equivalence search (GES) algorithm [10]. GES is a grow-shrink algorithm that consists of two phases: a forward phase and a backward phase. The forward phase starts with an initial estimate (often the empty graph) of the CPDAG, and sequentially adds single edges, each time choosing the edge addition that yields the maximum improvement of the score, until the score can no longer be improved. The backward phase starts with the output of the forward phase, and sequentially deletes single edges, each time choosing the edge deletion that yields a maximum improvement of the score, until the score can no longer be improved. A computational advantage of GES over the traditional DAG-search methods is that it searches over the space of all possible CPDAGs, instead of over the space of all possible DAGs.

(p8.2) The GES algorithm requires the scoring criterion to be score equivalent, meaning that every DAG in a Markov equivalence class gets the same score. Moreover, the choice of scoring criterion is crucial for computational and statistical performances. The socalled decomposability property of a scoring criterion allows fast updates of scores during the forward and the backward phase. For example, (penalized) log-likelihood scores are decomposable, since (2) implies that the (penalized) log-likelihood score of a DAG can be computed by summing up the (local) scores of each node given its parents in the DAG. Finally, the so-called consistency property of a scoring criterion ensures that the true CPDAG gets the highest score with probability approaching one (as the sample size tends to infinity).

(p8.3) GES was shown to be consistent when the scoring criterion is score equivalent, decomposable and consistent. For multivariate Gaussian or multinomial distributions, penalized likelihood scores such as BIC satisfy these assumptions.
## (s9) Hybrid methods
(p9.0) Hybrid methods learn the CPDAG by combining the ideas of constraint-based and scorebased methods. Typically, they first estimate (a supergraph of) the skeleton of the CPDAG using conditional independence tests, and then apply a search and score technique while restricting the set of allowed edges to the estimated skeleton. A prominent example is the Max-Min Hill-Climbing (MMHC) algorithm [66].

(p9.1) The restriction on the search space of hybrid methods provides a huge computational advantage when the estimated skeleton is sparse. This is why the hybrid methods scale well to thousands of variables, whereas the unrestricted score-based methods do not. However, this comes at the cost of inconsistency or at least at the cost of a lack of consistency proofs. Interestingly, empirical results have shown that a restriction on the search space can also help to improve the estimation quality [66].
## (s10) Learning SEMs with additional restrictions
(p10.0) Now that we have looked at various different methods to estimate the CPDAG, we close this section by discussing a slightly different approach that allows estimation of the causal DAG rather than its CPDAG. Identification of the DAG can be achieved by imposing additional restrictions on the generating SEM. Examples of this approach include the LiNGAM method for linear SEMs with non-Gaussian noise [54,55], methods for nonlinear SEMs [24] and methods for linear Gaussian SEMs with equal error variances [46].

(p10.1) We discuss the LiNGAM method in some more detail. A linear SEM can be written as X = BX + or equivalently X = A with A = (I − B) −1 . The LiNGAM algorithm of [54] uses independent component analysis (ICA) to obtain estimatesÂ andB = I −Â −1 of A and B. Ideally, rows and columns ofB can be permuted to obtain a lower triangular matrix and hence an estimate of the causal DAG. This is not possible in general in the presence of sampling errors, but a lower triangular matrix can be obtained by setting some small non-zero entries to zero and permuting rows and columns ofB.

(p10.2) A more recent implementation of the LiNGAM algorithm, called DirectLiNGAM was proposed by [55]. This implementation is not based on ICA. Rather, it estimates the variable ordering by iteratively finding an exogenous variable. DirectLiNGAM is suitable for settings with a larger number of variables.
