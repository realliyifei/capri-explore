# Unlocking the potential of deep learning for marine ecology: overview, applications, and outlook *

CorpusID: 238226987 - [https://www.semanticscholar.org/paper/81cbc4a42e2d1296a33311bca0f578d685a2fe2a](https://www.semanticscholar.org/paper/81cbc4a42e2d1296a33311bca0f578d685a2fe2a)

Fields: Computer Science, Environmental Science

## (s0) Introduction
(p0.0) Marine ecosystems are complex, highly diverse, and productive, providing renewable resources to a growing human population. At the same time, the oceans are particularly sensitive to and impacted by anthropogenic stressors [Antão et al., 2020]. As such, the scientific community strives to deliver up-to-date information about the state of marine ecosystems so that management decisions are well-informed. Ideally, such decisions use ecosystem-based management (EBM) approaches to preserve ecosystem health and productivity while allowing appropriate human use. EBM is especially relevant in densely populated coastal areas. During this period of rapid environmental change, EBM requires researchers to track ecological change and critical events when, and not well after, they occur. Fortunately, technological developments in observation methods have provided ecologists with a range of new tools for obtaining vast amounts of data from marine ecosystems over the last couple of decades. These include high-end cameras, echo sounders, and hydrophones, combined with various sensors to measure environmental parameters. Researchers can attach such technologies to cabled observatories or static rigs to assess temporal dynamics, or remotely or autonomously operated vehicles to evaluate spatial variability. However, because these technologies can produce an unprecedented amount of data, which has traditionally required manual processing, ecologists may be reluctant to adopt them as an alternative or supplement to traditional sampling techniques. For example, using traditional gear (e.g., nets and traps) to assess the abundance of fish has been an established sampling technique for centuries and is still used today. These methods are efficient for manual data handling and straightforward: as soon as the fish are caught, counted, and the data punched, it can be analyzed by the researchers. On the other hand, detecting and counting fish with cameras is less destructive to animals and habitat, provides a temporal dimension to the collected data, allows researchers to observe behaviour of animals and habitat use, and often provides a more representative estimate of species diversity and relative abundance [Bacheler et al., 2017]. However, extracting all of this information from videos manually is a laborious task. Thus, automating this step would undoubtedly encourage more fish biologists to use cameras for data collection.

(p0.1) Many diverse fields of research are undergoing rapid change due to advances in the use of artificial intelligence (AI) for data interpretation. AI offers fast and accurate analysis of the large volumes of data collected by sensors, cameras, and other observation technologies. Off-the-shelf algorithms can now, with high precision, find, count, and classify organisms from digital images and real-time video, [Knausgård et al., 2021, Lopez-Guede et al., 2020 and detect cryptic patterns in noisy images or acoustic data [Weinstein, 2018]. An increasing number of marine ecologists embrace this opportunity, yet initiating collaborations across ecological and data science disciplines can be challenging for several reasons. First, transferring the necessary information to start a project between an ecologist and a computer scientist can be a steep learning curve because knowledge barriers and field-specific jargon can cloud otherwise fruitful discussions and halt progression. Secondly, ecologists unfamiliar with AI may not be aware of the opportunities available to address a particular problem. Before an ecologist approaches an AI expert, they may need to know about the possibilities and limitations of AI for the task at hand, how to prepare and annotate data sets, and what information to provide the computer scientist to enable identification of the best AI method for the task at hand. Meanwhile, before advising on the possibilities, the computer scientist may find it challenging to understand the underlying ecological question, the data and its inherent variability/noisiness, how it is categorized, and what level of accuracy is needed. Thus, substantial investment in the interdisciplinary partnership is required in order to achieve a common understanding.
## (s17) Deep Neural Networks
(p17.0) All neural networks are function approximators; they mimic the function presented in the training data and adapt to this function through an optimization process. During training, the neural networks' weights, which are many real-valued and connected neurons followed by activations, are updated to match the training data. In more detail, the real-valued difference between the predicted output,Ŷ , and the expected output, Y , is referred to as the loss, which guides the training. For example, Y can be a list of image categories where each value in the vector relates a category to an image, andŶ is then the neural network's predicted image categories. If the neural network is able to correctly predict image categories,Ŷ will be identical to Y and the loss will be zero. The goal of the training process is, generally speaking, to minimize the loss. However, the loss minimization should be done with care since a small loss may indicate that DL has learned specific patterns for each example rather than general trends in the data (i.e., overfitting). To check for overfitting, a separate validation and testing data set is normally employed to independently evaluate the algorithm's performance.

(p17.1) A properly trained network has active or inactive neurons that jointly match the training data and minimize the loss. This is analogous to a series of virtual dials that can be turned completely on, completely off, or somewhere in between, indicating the relevance for each feature. During training, the loss for each neuron is propagated backward through the network so that each neuron's contribution matches the product of the weight and a hyper-parameterized learning rate. Hence, each neuron's influence of the loss is matched with a corresponding adjustment of weights, and its adjustment is kept small by the learning rate. When the loss is propagated backwards, the dials are turned slightly in the direction that decreases the loss.

(p17.2) A neural network is considered shallow if it has one layer of input neurons, one layer of hidden neurons, and one output layer. The same network would be considered deep if it had more than one hidden layer, and very deep if it had more than 10 hidden layers. Any neuron that is not at the input layer combines a weighted sum from active neurons in the previous layer. The sum is then followed by an activation function for the next layer of neurons. Despite popular belief, the depth of the DL may not be proportional to the difficulty of the problem that it can solve. It is not always true that deeper networks solve more complicated issues than shallower networks. Some problems can be solved with shallow networks, but in many cases very deep models empirically outperform the shallow ones for image and sound categorisations. For example, a type of neural network called Residual Networks (sometimes abbreviated to ResNets) often has 18, 34, 50, or 101 layers. Usually, the deeper networks perform better image classification, but occasionally the most shallow network, with 18 layers, is sufficient and even more accurate than the deeper networks [Aloysius and Geetha, 2017].

(p17.3) A notable limitation of DL is its dependency on vast amounts of training data. The data requirement typically becomes a significant problem in supervised learning, as a successful application in most cases depends on large quantities of human-classified training examples. This challenge is extensively presented in the marine biology domain, as the limited capacity of trained experts makes extensive and quality-assured labeled training databases hard to acquire. A beneficial property of deep unsupervised learning is its independence of labeled data. However, due to the unsupervised nature, the application area is rather limited in the marine biology domain and has mostly been confined to finding anomalies through re-identification [Dargan et al., 2019, Ferreira et al., 2020a and data clustering.

(p17.4) Deep semi-supervised learning has emerged in recent years to mitigate the limitations of supervised and unsupervised learning. Semi-supervised approaches combine training on a small amount of labeled data with a subsequent training phase using large amounts of unlabeled data. In applications where there is often a lack of human-classified training data, semi-supervised learning is especially useful.
## (s20) Individual identification
(p20.0) A Siamese Neural Network (SNN) [Koch et al., 2015] is a type of DL model that contains two identical sub-networks with the same layers, hyper parameters, and weights. The neuron weight updates are mirrored and so can be used to find the similarity of the inputs by comparing vector features. An SNN allows us to detect if two images are the same, e.g., two faces are of the same person or two fish photos are of the same fish taken at a different time. Hence, an SNN can classify a new class without re-training the entire network. Other features include robustness to class imbalance (i.e., data is unequally distributed between classes) and learning efficiency in the semantic similarities between images. However, SNNs need more training data and longer computational time than competing networks.

(p20.1) When training an SNN, a typical loss function used to detect differences in input is a so-called triple loss, in which the baseline input is compared both with a positive and a negative example. A perfectly trained SNN should have a zero loss for the positive example and a loss for the negative example. For example, when detecting individual marine animals, a comparison between pictures of the same animal should have a small loss, while a comparison between pictures of two different individuals of the same species should have a much larger loss. This approach can be used to identify if two pictures include the same individual and verify whether an image consists of an individual that is not part of the training data. Figure 2 provides examples of classification, object detection, and segmentation and how they are typically evaluated.  Figure 2: Examples of classification, object detection, and pixel-wise segmentation with illustrations of the techniques applied to fish images or audio files.
## (s25) Data
(p25.0) There is no universally right answer as to how much data is needed -generally, the more data, the better. Learning an intricate pattern requires more data than learning a simpler one. For example, for a DL to classify an image as either a sea trout or another fish species with clear morphological differences, such as a cod, it may achieve a near-perfect separator with relatively few samples. However, more data are likely to be required for a model to learn to distinguish sea trout from a closely related species with similarities in appearance, such as salmon, simply because that is a more complex task to learn. Mitigation for the lack of data means using an existing model with weights pre-trained using other data sources, such as the ImageNet database [Deng et al., 2009a]. The typical approach is to first train with an available, sizeable dataset and subsequently train with a smaller but more relevant dataset. In this way, the learning algorithms find the general image patterns from a big dataset (e.g., shapes, species patterns, face patterns) and the individual differences from the smaller dataset.

(p25.1) For a classification or object detection task, the dataset needs to be labeled (sometimes referred to as annotated), usually by a human expert (e.g., an ecologist). The labeled data is often referred to as the Y vector. An accurate classifier algorithm should correctly map the input, known as the X vectors (e.g., images) to the appropriate Y vector (the labels). These predicted labels are often referred to as theŶ vector, regardless of whether the predictions are correct (Ŷ matches Y ), or incorrect (Ŷ does not match Y ).

(p25.2) The labels for a classification task are distinct for each input variable, such as a species of fish for each image. This requires manual categorization and labelling of a large set of images. For object detection and semantic segmentation, the labels must also indicate where in the image the object of interest is located. In the case of audio input for RNN and CNN classification, the start and stop times of all events of interest must be labelled in order to segment the data into relevant categories. If object detection is used on spectrograms of audio, the frequency bands must also be labelled, encasing the contours of interest in the spectrogram. As is the case with images, existing labeled datasets also exist for audio, which can be used for training when data is otherwise limited (e.g., the DCLDE 2015 data set for baleen whale social calls [Huang et al., 2016]).

(p25.3) A labeled dataset is divided into three separate datasets, as illustrated in Figure 1: training, validation, and testing. The training set is used to train the model, meaning that it tries to find an approach to map the training set's input vector X with the training set's correct labels Y . The validation set follows and is first used to check whether the algorithm can map the validation set's input vector X with the validation set's correct labels Y , which is separate from the training set vectors. Finally, the test set is then employed to blindly verify that the data set with its own input vector X maps to the labeled data set Y . This test is the final check of how well the algorithm can classify.  Figure 4: Established and emerging cases for deep learning in marine biology, from individuals to ecosystems. Data input type icons represent images/video (cases 1, 2, 4, and 6), audio (cases 3 and 5), and large-scale environmental monitoring data that is often stored on remote servers (i.e., "the cloud"; case 7). Kelp forest photo (bottom) credit: Frithjof Moy/Havforskningsinstituttet.
## (s35) Emerging cases
(p35.0) A common theme of the established cases mentioned above is that they replace tasks currently conducted by humans -where using DL can reduce costs, labour, and sometimes improved accuracy compared to human analysts. However, DL has the capacity to be applied to solve more complex tasks, detecting patterns in visual and acoustic data that are difficult for humans to reliably detect or discriminate. In this section, we illustrate novel research avenues in which we predict DL will be successfully applied in the near future. Methods for individual identification are needed to answer many questions in animal behavior and ecology, such as growth, movement, and survival inferred from capturerecapture studies [Clutton-Brock and Sheldon, 2010]. Currently, the most common approach is to mark animals with various physical identifiers to recognise individuals upon re-sight or re-capture, such as leg rings on birds, number scratching or paint on reptiles, or lip tattoos on larger carnivores. In marine and freshwater systems, capture-recapture studies on fish are most often performed using external number tags or radio-frequency identification (RFID) tags [Pine et al., 2003]. However, trapping and tagging surveys are often costly, logistically challenging to conduct, and are intrusive to the animals.
## (s39) Case 7: carbon cycling by fish
(p39.0) The ocean sinks approximately one third of greenhouse gas emissions out of the atmosphere, including carbon dioxide. The ocean carbon sink is driven by a physical and a biological pump. As well as plankton and bacteria, fishes contribute to the biological pump, with recent estimates suggesting 16 percent of sinking carbon could be due to fishes . However, the role of fish in the biological pump is not well understood . The data on fishes required to improve our understanding relates to metabolic use and excretion of consumed carbon and other nutrients; properties of carbon and nutrient outputs and their fate in the environment; habitat use and connectivity of ecosystems; and physical interactions with extrinsic carbon and nutrients in the environment. As well as advancing knowledge of the role of fishes, this knowledge could inform effective management approaches to maintaining or restoring ecosystem carbon function. As an emerging field, zoogeochemistry has the advantage that much of the relevant data are already published for other purposes. For example, metabolic rates and behavioral data is already published for many commercially important species through fisheries and climate change research. Using AI in this field has the potential to expedite a better understanding of fishes ecological functions, effects of human disturbance, and therefore potential management of important carbon sink habitats. Here we present a few of the options available to apply DL to zoogeochemistry research.

(p39.1) In habitats where visual sampling is possible, video images could be used with object detection, classification, and tracking to identify the presence or absence, behavior, and features of particles from fishes and their short-term fate (e.g., defecation, spawning, and whether material reaches and settles on the sea floor). This could inform estimates of the volume of carbon transferred into or out of a habitat by fishes, and the short-term fate of the carbon or nutrient they release. Methods that use AI computer vision to determine the connectivity of fish populations can also be of value in estimating carbon flow . The long term fate of carbon and nutrients depends on physical, chemical, and biological conditions of the environment. Graph networks have recently been used to simulate the physical behavior of materials [Sanchez-Gonzalez et al., 2020]. This technology has potential application to estimating the probable fate of carbon and nutrient outputs through simulations that combine oceanographic data with features of the carbon released by fishes. With many variables to consider, recent approaches to assessing carbon contained in sediments in different habitats include a combination of survey (acoustic and image-based) and bathymetry data, modeling, and remote ground-truthing [Hunt et al., 2020, Wilson et al., 2018. The current approach is manual, but there is potential for AI application to link habitats to carbon fates and make spatial and temporal estimates on cycling and sinking of carbon and nutrients. Graph networks [Sanchez-Gonzalez et al., 2020] could be applied to generate probable long-term fates of carbon and nutrient outputs using simulations based on video observations and environmental parameters such as season, temperature, currents, and maps of habitat type.
## (s40) Discussion
(p40.0) We are entering a new era in ocean research and management thanks to new technological developments in observational methods combined with AI-supported data analysis. Data collection, processing, and interpretation are at the core of ecological studies and biodiversity monitoring. Scientists are increasingly relying on indirect observations from various sensors generating large and complex data sets, especially in the aquatic environment. Thus, we envision that within a decade, marine researchers will firmly integrate AI and ML in data collection and analysis within most sub-fields of applied marine biology. This development will only continue to accelerate with new generations of biologists better educated in computer science and informatics [Weinstein, 2018].
