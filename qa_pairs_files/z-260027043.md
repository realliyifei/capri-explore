# The Effectiveness of Evidence-Based Teaching Practices in Biomedical Sciences on Students' Learning Experience: A Systematic Literature Review

CorpusID: 260027043 - [https://www.semanticscholar.org/paper/dc01ab0e5d5dbbff4c15d4a8d2ef22d5dd077659](https://www.semanticscholar.org/paper/dc01ab0e5d5dbbff4c15d4a8d2ef22d5dd077659)

Fields: Education, Medicine

## (s1) Method
(p1.0) The protocol for this systematic review was developed using preferred reporting items for systematic review and meta-analyses (PRISMA-P) (Shamseer et al., 2015). This framework allowed for transparency, accuracy, completeness, and documentation of this systematic review.
## (s5) Critical Appraisal
(p5.0) The rigour of the studies was established using the Mixed Methods Appraisal Tool (MMAT) (Hong, Gonzalez-Reyes, & Pluye, 2018) as it supports critical appraisal for all types of study designs. As this review would include heterogeneous study designs, MMAT was considered appropriate for this systematic review. Risk of bias was assessed for individual studies by screening information on research questions, methodology, recruitment of participants, sampling strategy, integration of qualitative and quantitative data, and outcome data as relevant to individual studies. Each criterion was assigned a response of either 'yes', 'no', or 'inconclusive'. A study was considered to be at moderate risk if it received two or more 'no' responses, while a study was considered to be at low risk if it received two or more 'yes' responses.
## (s13) Students' Performance
(p13.0) The EBTPs implemented in the studies had significant effects on students' performance, which was determined by evaluating either pass and fail rates or grades for the enrolled units. Postintervention, statistically significant results were noted in the mean test scores denoting significant improvement in performance. One study, that implemented a pre-lecture screencast with a multiple-choice question (MCQ) quiz, showed improvement in average grades for MCQ quizzes from the first attempt to last attempt (Kinsella, Mahon, & Lillis, 2017). However, there was no noticeable impact on academic achievement when compared to the previous year. Possible reasons suggested by the authors are the learners' varied levels of prior knowledge, and pre-lecture screencasts not being a part of continual assessment. These factors may have deterred students from engaging with the screencast resources. Two studies revealed a significant increase in knowledge retention (Kulak & Newton, 2015;Raupach et al., 2016). Of equal importance was the difference in the academic achievement noted in strongly-performing and poorly-performing students that was found in a study conducted by Carrasco, Behling, and Lopez (2019). The strongly-performing students benefitted from group work, while poorlyperforming students benefitted from individual work when preparing for Readiness Assurance Test exercises (Carrasco et al., 2019).

(p13.1) Similarly, Green, Cates, White, and Farchione (2016) investigated the effect of collaborative practical tests on students' understanding of gross anatomy. The findings revealed that there was no correlation between collaborative practical tests and the final exam mark, suggesting that collaborative practical testing is not effective in improving individual student exam marks. A negative outcome was also revealed in a study by Grosas, Raju, Schuett, Chuck, and Millar (2016) that implemented formative assessment process as an EBTP. Formative assessments caused minimal improvement in the final exam performance and the researchers concluded that the ineffective feedback provided in the assessments did not empower students to improve their achievement. Additionally, another study by Carlson, Chandra, Hobbs, and Steele (2019) that used clay modelling as an active learning strategy did not reveal any significant improvement in exam performance, while indicating that time restrictions, group dynamics, and task instructions could be factors hindering the desired outcome.
## (s14) Positive Attitudes
(p14.0) The purpose of implementing EBTPs is to maximise learning experiences for students. This can be achieved by creating engaging learning materials, creating opportunities for students to engage with peers and instructors, constructively aligning assessment tasks to the desired learning outcomes, providing opportunities for critical thinking, and, most importantly, making explicit the connections between the content and future professions. To that end, the EBTPs explored in this review created positive environments that were conducive to student learning. Students' perceptions gathered through survey responses revealed positive attitudes towards various aspects of learning components: teamwork (Brown, 2016;Huitt et al., 2015;Tarhan & Ayyildiz, 2015); usefulness of resources in learning (Fyfe, Fyfe, Dye, & Radley-Crabb, 2018); learning experiences (Abraham, Vashe, & Torke, 2015;Chen, Kelly, Hayes, Van Reyk, & Herok, 2016;Derfoufi et al., 2015;Gorres-Martens et al., 2016;Kulak & Newton, 2015;Matsuda, Azaiza, & Salani, 2017;Muthukrishnan et al., 2019;Youngwanichsetha, Kritcharoen, Chunuan, Kala, & Phumdoung, 2020); interest in biochemistry (Tarhan & Ayyildiz, 2015); accessibility to the instructor (Gonzalez & Gadbury-Amyot, 2016), cognitive load (Gross, Wright, & Anderson, 2017); engagement in scientific inquiry (Brown, 2016); experiment instructions (King et al., 2016); relevance of the teaching practices (King et al., 2016); exam experience (Ahlstrom & Holmberg, 2021); empathy towards older persons (Lucchetti, Duarte, Assis, Laurindo, Lucchetti, 2019); enjoyment (Kukolja Taradi & Taradi, 2016), and use of technology (Hardie et al., 2020).
