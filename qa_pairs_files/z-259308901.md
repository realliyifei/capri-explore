# A Survey on Blockchain-Based Federated Learning and Data Privacy

CorpusID: 259308901 - [https://www.semanticscholar.org/paper/305d1350ae97aba97cf00ed5c490f521235de1a7](https://www.semanticscholar.org/paper/305d1350ae97aba97cf00ed5c490f521235de1a7)

Fields: Computer Science

## (s1) II. MOTIVATION
(p1.0) The primary motivation behind this study is the pressing issues surrounding data privacy and sharing. Security concerns regarding federated learning have been arisen. These concerns stem from the potential for malicious clients or central servers to attack the global model or access user privacy data.

(p1.1) Qu et al. [29] tackled the data privacy issue by implementing federated learning, where only the models and not the raw data are shared. This ensures the data's efficiency and usefulness while maintaining privacy. A fully decentralized federated learning system is proposed. The system employs blockchain technology as the underlying architecture and the proof-of-work (PoW) consensus process. The decentralized system offers resistance to poisoning attacks. Incentives are provided and accuracy is enhanced through member selections.

(p1.2) Data leakage during storage, transmission, and sharing is a significant challenge faced by data owners and providers. This challenge is particularly prominent in the context of Industrial Internet of Things (IIoT) applications [34]. To address attacks on global models or user privacy data, Li et al. [17] proposed the Blockchain-based Federated Learning framework with Committee consensus (BFLC), a decentralized, blockchain-based federated learning framework. However, the Committee consensus mechanism (CCM) used in the framework may result in a large amount of communication overhead between nodes. This could lead to slow training times and increased energy consumption.

(p1.3) Lu et al. [19] proposed a solution to data-sharing challenges by combining federated learning with permissioned blockchain. The permissioned blockchain in this system creates secure connections between end IoT devices. These connections are established through encrypted records maintained by supernodes, such as base stations and roadside units. This ensures data privacy and accessibility. The proposed architecture does not store raw data. It uses permissioned blockchain to access related data and controls data accessibility. This addresses storage constraints and privacy concerns.
## (s10) B. Differential Privacy-based Approaches
(p10.0) Zhao et al. [42] designed a blockchain-based federated learning model for home appliance manufacturers to develop their services and products. First, customers train a model using a collection of home appliance data. Then, they send the trained model to the blockchain to trace clients' or manufacturers' activities and prevent the probability of cyber threats. Finally, as a miner, one of the clients uploads the model to the blockchain. The authors recommended using differential privacy techniques on features to provide clients' privacy by adding ε-DP noise to features.

(p10.1) In another study, Qi et al. [27] proposed a federated learning-based Traffic Flow Prediction (TFP) system. They have integrated GRU neural networks with blockchain and FL-based TFP schemes. Rather than directly sending individual data, the participating vehicles use their data to perform local model training and share local model updates, thus protecting privacy. Blockchain prevents the security risks of the central server and clients. This is achieved by replacing the central server with a group of trusted nodes. The nodes manage all the local model updates. In addition, they apply differential privacy by adding Gaussian noise to local model updates, thereby protecting the client's data. The proposed model was compared with LSTM, stacked autoencoder (SAE), and SVM, in which the proposed model could accurately predict traffic flow better than the other models. Moreover, the proposed model effectively mitigates poisoning attacks since the accuracy of blockchain does not reduce even if the number of malicious clients increases. The proposed model faces a challenge in that the convergence rate of the SAE model is faster. This is because the SAE model does not need to complete a model aggregation step. The SAE model has a centralized learning paradigm, which contributes to its faster convergence rate.

(p10.2) Wan et al. [37] proposed a novel blockchain-based federated learning framework to avoid data falsification beyond 5G networks (B5G) enabling edge computing. They also added a differential privacy identifier to Wasserstein Generative Adversarial Network (WGAN) [3] to distinguish if synthetic data complies with differential privacy. Lastly, a time delay analysis was conducted on a single epoch of the proposed model, which was then used to determine the optimal rate for generating blockchain blocks. The trained local parameters of edge devices are regenerated by the WGAN generator and then assessed by DP-identifier and WGAN discriminator during the FL training process. With better data utility, this technique ensures that the resulting synthetic model parameters fulfill DP. Blockchain-enabled FL's convergence latency has been seen to be quadratic to the block production rate. As a result, the experimental findings lead to an optimum block generation rate.

(p10.3) Shayan et al. [33] introduced Biscotti, a blockchain-based system for federated learning. It uses cryptography and blockchain technology to enable secure and private federated learning across multiple organizations. The system allows organizations to store and process data locally. The system also allows machine learning models to be trained across all participating organizations. Biscotti comprises four main components: blockchain ledger, consensus protocol, smart contracts, and off-chain storage. The system provides a variety of security measures such as data privacy and access control. The measures are put in place to ensure that data is secure and only accessible to authorized parties. Additionally, the system utilizes various techniques to facilitate efficient and secure data exchange, such as differential privacy and distributed data aggregation.

(p10.4) Salim et al. [32] proposed a differential privacy blockchain-based explainable FL (DP-BFL) architecture using Social Media 3.0 networks. This architecture allows internet-enabled devices to participate in training global models while preserving data privacy. After local training, participants upload their deferentially private local model updates to the blockchain system. These local updates are then evaluated and verified by the miners of the blockchain system. DP-BFL ensures that the privacy of the participants as well as a good performance of the global model, is achieved by mitigating the impact of malicious participants' local updates.

(p10.5) Qu et al. [28] proposed a novel approach to block-chain-enabled adaptive asynchronous federated learning (FedTwin). The approach enables adaptive and asynchronous training in digital twin networks. The approach addresses the challenges of centralized processing, data falsification, privacy leakage, and lack of incentive mechanisms in digital twin networks. FedTwin uses a proof-of-federalism consensus algorithm for efficient and secure synchronization of digital twin networks (DTN), enabling a personalized incentive mechanism. The approach also uses privacy-preserving local digital twin (DT) training with falsification filtering. The approach uses adaptive asynchronous global aggregation of DTN with a roll-back mechanism. The authors evaluate the performance of FedTwin on a real-world dataset, which shows its superior performance for DTN.

(p10.6) Zhao et al. [42] designed a blockchain-based federated learning model for home appliance manufacturers to develop their services and products. First, customers train a model using a collection of home appliance data. Then, they send the trained model to the blockchain to trace clients' or manufacturers' activities and prevent the probability of cyber threats. Finally, as a miner, one of the clients uploads the model to the blockchain. The authors recommended using differential privacy techniques on features to provide clients' privacy by adding ε-DP noise to features.

(p10.7) In another study, Qi et al. [27] proposed a federated learning-based Traffic Flow Prediction (TFP) system. They have integrated GRU neural networks with blockchain and FL-based TFP schemes. Rather than directly sending individual data, the participating vehicles use their data to perform local model training and share local model updates, thus protecting privacy. Blockchain prevents the security risks of the central server and clients. This is achieved by replacing the central server with a group of trusted nodes. The nodes manage all the local model updates. In addition, they apply differential privacy by adding Gaussian noise to local model updates, thereby protecting the client's data. The proposed model was compared with LSTM, stacked autoencoder (SAE), and SVM, in which the proposed model could accurately predict traffic flow better than the other models. Moreover, the proposed model effectively mitigates poisoning attacks since the accuracy of blockchain does not reduce even if the number of malicious clients increases. The proposed model faces a challenge in that the convergence rate of the SAE model is faster. This is because the SAE model does not need to complete a model aggregation step. The SAE model has a centralized learning paradigm, which contributes to its faster convergence rate.

(p10.8) Wan et al. [37] proposed a novel blockchain-based federated learning framework to avoid data falsification beyond 5G networks (B5G) enabling edge computing. They also added a differential privacy identifier to Wasserstein Generative Adversarial Network (WGAN) [3] to distinguish if synthetic data complies with differential privacy. Lastly, a time delay analysis was conducted on a single epoch of the proposed model, which was then used to determine the optimal rate for generating blockchain blocks. The trained local parameters of edge devices are regenerated by the WGAN generator and then assessed by DP-identifier and WGAN discriminator during the FL training process. With better data utility, this technique ensures that the resulting synthetic model parameters fulfill DP. Blockchain-enabled FL's convergence latency has been seen to be quadratic to the block production rate. As a result, the experimental findings lead to an optimum block generation rate.

(p10.9) Shayan et al. [33] introduced Biscotti, a blockchain-based system for federated learning. It uses cryptography and blockchain technology to enable secure and private federated learning across multiple organizations. The system allows organizations to store and process data locally. The system also allows machine learning models to be trained across all participating organizations. Biscotti comprises four main components: blockchain ledger, consensus protocol, smart contracts, and off-chain storage. The system provides a variety of security measures such as data privacy and access control. The measures are put in place to ensure that data is secure and only accessible to authorized parties. Additionally, the system utilizes various techniques to facilitate efficient and secure data exchange, such as differential privacy and distributed data aggregation.

(p10.10) Salim et al. [32] proposed a differential privacy blockchain-based explainable FL (DP-BFL) architecture using Social Media 3.0 networks. This architecture allows internet-enabled devices to participate in training global models while preserving data privacy. After local training, participants upload their deferentially private local model updates to the blockchain system. These local updates are then evaluated and verified by the miners of the blockchain system. DP-BFL ensures that the privacy of the participants as well as a good performance of the global model, is achieved by mitigating the impact of malicious participants' local updates.

(p10.11) Qu et al. [28] proposed a novel approach to block-chain-enabled adaptive asynchronous federated learning (FedTwin). The approach enables adaptive and asynchronous training in digital twin networks. The approach addresses the challenges of centralized processing, data falsification, privacy leakage, and lack of incentive mechanisms in digital twin networks. FedTwin uses a proof-of-federalism consensus algorithm for efficient and secure synchronization of digital twin networks (DTN), enabling a personalized incentive mechanism. The approach also uses privacy-preserving local digital twin (DT) training with falsification filtering. The approach uses adaptive asynchronous global aggregation of DTN with a roll-back mechanism. The authors evaluate the performance of FedTwin on a real-world dataset, which shows its superior performance for DTN.
## (s11) C. Secure Multi-party Computation-based Approaches
(p11.0) Lu et al. [19] proposed a collaborative architecture enabled by blockchain to share data among multiple parties. The architecture also minimizes the risk of data leakage and grants data owners greater control over access to shared data. By using federated learning to construct data models and share them instead of raw data, the authors transformed data sharing into a machine learning problem, thereby, enhancing the usage of computing resources and the effectiveness of the data-sharing system. To safeguard data privacy, the authors integrated differential privacy into federated learning. The effectiveness of the proposed model was evaluated for data categorization using benchmark, open real-world datasets. However, three potential threats were identified: data quality, data security, and data authority management. To address these threats, the authors integrated federated learning to achieve differential privacy. They employed a permissioned blockchain to eliminate centralized trust. They ensured the quality of shared data to prevent invalid sharing. They facilitated secure data management by allowing data providers to upload data only through permissioned blockchain.

(p11.1) Li et al. [17] proposed BFLC, a Blockchain-based Federated Learning framework with Committee consensus. To address the integrating storage optimization, analysis of hostile node threats, and community node administration issues, FL is performed by participating nodes using blockchain. The blockchain maintains global models and local updates without the use of a centralized server. The authors employ a novel delegated consensus mechanism, which addresses the missions of gradient selection and block generation while accounting for the communication cost of FL. In the experiment, BFLC demonstrated higher accuracy compared to basis FL and stand-alone framework [22] in various malicious proportion settings. The author incorporated real-world datasets into the BFLC framework, enabling them to obtain global models that closely resemble the centralized training approach in federated learning. However, the need for a trusted blockchain system raises unexplored aspects of ensuring trustworthiness, which may pose challenges and require further investigation in order to address potential vulnerabilities and maintain the integrity of the BFLC framework.
## (s12) Paper
(p12.0) Privacy Approach Challenges Wang et al. [38] BPFL-A combination of Multi-Krum and homomorphic encryption Efficient model combination and complex homomorphic encryption management. Zhoa et al. [42] DP-Laplace noise Optimizing noise level and selecting privacy parameters. Miao et al. [25] PBFL-Fully homomorphic encryption and cosine similarity Scheme on a balanced distribution of client data and not on cases where the client data is non-IID Sun et al. [35] Homomorphic encryption (BCP-based) for gradient

(p12.1) Blockchain-based audit approach for encrypted gradients may have limited scalability due to the increased processing times and delay Li et al. [17] BFLC-Blockchain-based Federated Learning framework with Committee consensus CCM approach has increased energy consumption due to a large amount of communication overhead involved during model updates between nodes Lu et al. [19] PBFL-Privacy-preserving data sharing the mechanism for distributed multiple parties Improving the utility of data models mapped from raw data is necessary Qu et al. [29] BFL-Decentralized paradigm for big data-driven cognitive computing (D2C) Improves on Markov decision process (MDP) rather than addressing privacy issues with blockchain that is assumed tamper-proof Wan et al. [37] BFL-Wasserstein generative adversarial network (WGAN)

(p12.2) Need for efficient communication and computation methods, privacy and security concerns in federated learning, and the problem of non-iid data distribution in edge computing environments Shayan et al. [33] Biscotti: a fully decentralized peer-to-peer (P2P) approach to multi-party ML Requiring large honest samples for Multi-Krum, limited scalability for large deep learning models, and vulnerability to privacy attacks. Qi et al. [27] BFL-Traffic Flow Prediction (TFP) Slower convergence rate due to its decentralized learning paradigm and model aggregation step, as opposed to the SAE model's centralized learning. Ur Rehman et al. [36] BFL-Reputation-aware fine-grained A reputation-aware federated learning system that exchanges information securely and privately while maintaining data privacy and integrity. Arachchige et al. [2] PriModChain -Differential privacy, Federated ML, Ethereum blockchain, and Smart contracts.
## (s15) B. Model accuracy and Latency
(p15.0) BCFL models require maintaining and improving the accuracy and efficiency of the model. The mini-batching at the client during each training epoch and increasing multi-client parallelism to reach a target test-set accuracy framework can be adopted. The learning performance of Federated Learning has not been discussed in details. It is necessary to verify the multi-key encryption protocol because of the way it secures the federated ML model data. The accuracy and latency of PrimodChain [2] systems still need optimization.

(p15.1) BCFL models require maintaining and improving the accuracy and efficiency of the model. The mini-batching at the client during each training epoch and increasing multi-client parallelism to reach a target test-set accuracy framework can be adopted. The learning performance of Federated Learning has not been discussed in details. It is necessary to verify the multi-key encryption protocol because of the way it secures the federated ML model data. The accuracy and latency of PrimodChain [2] systems still need optimization.
## (s16) C. Unexplored Complexity
(p16.0) The work presented by Wang et al. [39] provides only theoretical analysis, and BEMA robustness against Byzantine attacks cannot be guaranteed. A Byzantine attack occurs when an attacker adheres to the system protocol but disseminates malicious information to innocent system participants, with the goal of diminishing system performance and manipulating or influencing the system's output. More evaluation is still needed as the learning strategies and security concerns are not fully investigated. The existing research on multiparty learning has mainly focused on homogeneous local models. However, there is still a lack of research on multiparty learning over heterogeneous local models. This is despite the fact that such a scenario may be more practical and useful in real-world applications.

(p16.1) The work presented by Wang et al. [39] provides only theoretical analysis, and BEMA robustness against Byzantine attacks cannot be guaranteed. A Byzantine attack occurs when an attacker adheres to the system protocol but disseminates malicious information to innocent system participants, with the goal of diminishing system performance and manipulating or influencing the system's output. More evaluation is still needed as the learning strategies and security concerns are not fully investigated. The existing research on multiparty learning has mainly focused on homogeneous local models. However, there is still a lack of research on multiparty learning over heterogeneous local models. This is despite the fact that such a scenario may be more practical and useful in real-world applications.
## (s18) E. Scalability
(p18.0) The blockchain-based audit approach for encrypted gradients in federated learning provides privacy while assessing gradient quality. However, scalability can be a challenge due to the consensus requirement in blockchain technology. Adding new blocks necessitates agreement among all network nodes, resulting in time-consuming and expensive audits, particularly for large federated learning systems. Two approaches to mitigate scalability limitations are (1) off-chain computation [10], which performs audits on a subset of nodes, and (2) compression, which reduces the size of encrypted gradients before blockchain storage. These techniques aim to improve efficiency without compromising quality. Continued research seeks to enhance scalability and make this approach more practical.

(p18.1) The blockchain-based audit approach for encrypted gradients in federated learning provides privacy while assessing gradient quality. However, scalability can be a challenge due to the consensus requirement in blockchain technology. Adding new blocks necessitates agreement among all network nodes, resulting in time-consuming and expensive audits, particularly for large federated learning systems. Two approaches to mitigate scalability limitations are (1) off-chain computation [10], which performs audits on a subset of nodes, and (2) compression, which reduces the size of encrypted gradients before blockchain storage. These techniques aim to improve efficiency without compromising quality. Continued research seeks to enhance scalability and make this approach more practical.
## (s23) II. MOTIVATION
(p23.0) The primary motivation behind this study is the pressing issues surrounding data privacy and sharing. Security concerns regarding federated learning have been arisen. These concerns stem from the potential for malicious clients or central servers to attack the global model or access user privacy data.

(p23.1) Qu et al. [29] tackled the data privacy issue by implementing federated learning, where only the models and not the raw data are shared. This ensures the data's efficiency and usefulness while maintaining privacy. A fully decentralized federated learning system is proposed. The system employs blockchain technology as the underlying architecture and the proof-of-work (PoW) consensus process. The decentralized system offers resistance to poisoning attacks. Incentives are provided and accuracy is enhanced through member selections.

(p23.2) Data leakage during storage, transmission, and sharing is a significant challenge faced by data owners and providers. This challenge is particularly prominent in the context of Industrial Internet of Things (IIoT) applications [34]. To address attacks on global models or user privacy data, Li et al. [17] proposed the Blockchain-based Federated Learning framework with Committee consensus (BFLC), a decentralized, blockchain-based federated learning framework. However, the Committee consensus mechanism (CCM) used in the framework may result in a large amount of communication overhead between nodes. This could lead to slow training times and increased energy consumption.

(p23.3) Lu et al. [19] proposed a solution to data-sharing challenges by combining federated learning with permissioned blockchain. The permissioned blockchain in this system creates secure connections between end IoT devices. These connections are established through encrypted records maintained by supernodes, such as base stations and roadside units. This ensures data privacy and accessibility. The proposed architecture does not store raw data. It uses permissioned blockchain to access related data and controls data accessibility. This addresses storage constraints and privacy concerns.
## (s32) B. Differential Privacy-based Approaches
(p32.0) Zhao et al. [42] designed a blockchain-based federated learning model for home appliance manufacturers to develop their services and products. First, customers train a model using a collection of home appliance data. Then, they send the trained model to the blockchain to trace clients' or manufacturers' activities and prevent the probability of cyber threats. Finally, as a miner, one of the clients uploads the model to the blockchain. The authors recommended using differential privacy techniques on features to provide clients' privacy by adding ε-DP noise to features.

(p32.1) In another study, Qi et al. [27] proposed a federated learning-based Traffic Flow Prediction (TFP) system. They have integrated GRU neural networks with blockchain and FL-based TFP schemes. Rather than directly sending individual data, the participating vehicles use their data to perform local model training and share local model updates, thus protecting privacy. Blockchain prevents the security risks of the central server and clients. This is achieved by replacing the central server with a group of trusted nodes. The nodes manage all the local model updates. In addition, they apply differential privacy by adding Gaussian noise to local model updates, thereby protecting the client's data. The proposed model was compared with LSTM, stacked autoencoder (SAE), and SVM, in which the proposed model could accurately predict traffic flow better than the other models. Moreover, the proposed model effectively mitigates poisoning attacks since the accuracy of blockchain does not reduce even if the number of malicious clients increases. The proposed model faces a challenge in that the convergence rate of the SAE model is faster. This is because the SAE model does not need to complete a model aggregation step. The SAE model has a centralized learning paradigm, which contributes to its faster convergence rate.

(p32.2) Wan et al. [37] proposed a novel blockchain-based federated learning framework to avoid data falsification beyond 5G networks (B5G) enabling edge computing. They also added a differential privacy identifier to Wasserstein Generative Adversarial Network (WGAN) [3] to distinguish if synthetic data complies with differential privacy. Lastly, a time delay analysis was conducted on a single epoch of the proposed model, which was then used to determine the optimal rate for generating blockchain blocks. The trained local parameters of edge devices are regenerated by the WGAN generator and then assessed by DP-identifier and WGAN discriminator during the FL training process. With better data utility, this technique ensures that the resulting synthetic model parameters fulfill DP. Blockchain-enabled FL's convergence latency has been seen to be quadratic to the block production rate. As a result, the experimental findings lead to an optimum block generation rate.

(p32.3) Shayan et al. [33] introduced Biscotti, a blockchain-based system for federated learning. It uses cryptography and blockchain technology to enable secure and private federated learning across multiple organizations. The system allows organizations to store and process data locally. The system also allows machine learning models to be trained across all participating organizations. Biscotti comprises four main components: blockchain ledger, consensus protocol, smart contracts, and off-chain storage. The system provides a variety of security measures such as data privacy and access control. The measures are put in place to ensure that data is secure and only accessible to authorized parties. Additionally, the system utilizes various techniques to facilitate efficient and secure data exchange, such as differential privacy and distributed data aggregation.

(p32.4) Salim et al. [32] proposed a differential privacy blockchain-based explainable FL (DP-BFL) architecture using Social Media 3.0 networks. This architecture allows internet-enabled devices to participate in training global models while preserving data privacy. After local training, participants upload their deferentially private local model updates to the blockchain system. These local updates are then evaluated and verified by the miners of the blockchain system. DP-BFL ensures that the privacy of the participants as well as a good performance of the global model, is achieved by mitigating the impact of malicious participants' local updates.

(p32.5) Qu et al. [28] proposed a novel approach to block-chain-enabled adaptive asynchronous federated learning (FedTwin). The approach enables adaptive and asynchronous training in digital twin networks. The approach addresses the challenges of centralized processing, data falsification, privacy leakage, and lack of incentive mechanisms in digital twin networks. FedTwin uses a proof-of-federalism consensus algorithm for efficient and secure synchronization of digital twin networks (DTN), enabling a personalized incentive mechanism. The approach also uses privacy-preserving local digital twin (DT) training with falsification filtering. The approach uses adaptive asynchronous global aggregation of DTN with a roll-back mechanism. The authors evaluate the performance of FedTwin on a real-world dataset, which shows its superior performance for DTN.

(p32.6) Zhao et al. [42] designed a blockchain-based federated learning model for home appliance manufacturers to develop their services and products. First, customers train a model using a collection of home appliance data. Then, they send the trained model to the blockchain to trace clients' or manufacturers' activities and prevent the probability of cyber threats. Finally, as a miner, one of the clients uploads the model to the blockchain. The authors recommended using differential privacy techniques on features to provide clients' privacy by adding ε-DP noise to features.

(p32.7) In another study, Qi et al. [27] proposed a federated learning-based Traffic Flow Prediction (TFP) system. They have integrated GRU neural networks with blockchain and FL-based TFP schemes. Rather than directly sending individual data, the participating vehicles use their data to perform local model training and share local model updates, thus protecting privacy. Blockchain prevents the security risks of the central server and clients. This is achieved by replacing the central server with a group of trusted nodes. The nodes manage all the local model updates. In addition, they apply differential privacy by adding Gaussian noise to local model updates, thereby protecting the client's data. The proposed model was compared with LSTM, stacked autoencoder (SAE), and SVM, in which the proposed model could accurately predict traffic flow better than the other models. Moreover, the proposed model effectively mitigates poisoning attacks since the accuracy of blockchain does not reduce even if the number of malicious clients increases. The proposed model faces a challenge in that the convergence rate of the SAE model is faster. This is because the SAE model does not need to complete a model aggregation step. The SAE model has a centralized learning paradigm, which contributes to its faster convergence rate.

(p32.8) Wan et al. [37] proposed a novel blockchain-based federated learning framework to avoid data falsification beyond 5G networks (B5G) enabling edge computing. They also added a differential privacy identifier to Wasserstein Generative Adversarial Network (WGAN) [3] to distinguish if synthetic data complies with differential privacy. Lastly, a time delay analysis was conducted on a single epoch of the proposed model, which was then used to determine the optimal rate for generating blockchain blocks. The trained local parameters of edge devices are regenerated by the WGAN generator and then assessed by DP-identifier and WGAN discriminator during the FL training process. With better data utility, this technique ensures that the resulting synthetic model parameters fulfill DP. Blockchain-enabled FL's convergence latency has been seen to be quadratic to the block production rate. As a result, the experimental findings lead to an optimum block generation rate.

(p32.9) Shayan et al. [33] introduced Biscotti, a blockchain-based system for federated learning. It uses cryptography and blockchain technology to enable secure and private federated learning across multiple organizations. The system allows organizations to store and process data locally. The system also allows machine learning models to be trained across all participating organizations. Biscotti comprises four main components: blockchain ledger, consensus protocol, smart contracts, and off-chain storage. The system provides a variety of security measures such as data privacy and access control. The measures are put in place to ensure that data is secure and only accessible to authorized parties. Additionally, the system utilizes various techniques to facilitate efficient and secure data exchange, such as differential privacy and distributed data aggregation.

(p32.10) Salim et al. [32] proposed a differential privacy blockchain-based explainable FL (DP-BFL) architecture using Social Media 3.0 networks. This architecture allows internet-enabled devices to participate in training global models while preserving data privacy. After local training, participants upload their deferentially private local model updates to the blockchain system. These local updates are then evaluated and verified by the miners of the blockchain system. DP-BFL ensures that the privacy of the participants as well as a good performance of the global model, is achieved by mitigating the impact of malicious participants' local updates.

(p32.11) Qu et al. [28] proposed a novel approach to block-chain-enabled adaptive asynchronous federated learning (FedTwin). The approach enables adaptive and asynchronous training in digital twin networks. The approach addresses the challenges of centralized processing, data falsification, privacy leakage, and lack of incentive mechanisms in digital twin networks. FedTwin uses a proof-of-federalism consensus algorithm for efficient and secure synchronization of digital twin networks (DTN), enabling a personalized incentive mechanism. The approach also uses privacy-preserving local digital twin (DT) training with falsification filtering. The approach uses adaptive asynchronous global aggregation of DTN with a roll-back mechanism. The authors evaluate the performance of FedTwin on a real-world dataset, which shows its superior performance for DTN.
## (s33) C. Secure Multi-party Computation-based Approaches
(p33.0) Lu et al. [19] proposed a collaborative architecture enabled by blockchain to share data among multiple parties. The architecture also minimizes the risk of data leakage and grants data owners greater control over access to shared data. By using federated learning to construct data models and share them instead of raw data, the authors transformed data sharing into a machine learning problem, thereby, enhancing the usage of computing resources and the effectiveness of the data-sharing system. To safeguard data privacy, the authors integrated differential privacy into federated learning. The effectiveness of the proposed model was evaluated for data categorization using benchmark, open real-world datasets. However, three potential threats were identified: data quality, data security, and data authority management. To address these threats, the authors integrated federated learning to achieve differential privacy. They employed a permissioned blockchain to eliminate centralized trust. They ensured the quality of shared data to prevent invalid sharing. They facilitated secure data management by allowing data providers to upload data only through permissioned blockchain.

(p33.1) Li et al. [17] proposed BFLC, a Blockchain-based Federated Learning framework with Committee consensus. To address the integrating storage optimization, analysis of hostile node threats, and community node administration issues, FL is performed by participating nodes using blockchain. The blockchain maintains global models and local updates without the use of a centralized server. The authors employ a novel delegated consensus mechanism, which addresses the missions of gradient selection and block generation while accounting for the communication cost of FL. In the experiment, BFLC demonstrated higher accuracy compared to basis FL and stand-alone framework [22] in various malicious proportion settings. The author incorporated real-world datasets into the BFLC framework, enabling them to obtain global models that closely resemble the centralized training approach in federated learning. However, the need for a trusted blockchain system raises unexplored aspects of ensuring trustworthiness, which may pose challenges and require further investigation in order to address potential vulnerabilities and maintain the integrity of the BFLC framework.
## (s34) Paper
(p34.0) Privacy Approach Challenges Wang et al. [38] BPFL-A combination of Multi-Krum and homomorphic encryption Efficient model combination and complex homomorphic encryption management. Zhoa et al. [42] DP-Laplace noise Optimizing noise level and selecting privacy parameters. Miao et al. [25] PBFL-Fully homomorphic encryption and cosine similarity Scheme on a balanced distribution of client data and not on cases where the client data is non-IID Sun et al. [35] Homomorphic encryption (BCP-based) for gradient

(p34.1) Blockchain-based audit approach for encrypted gradients may have limited scalability due to the increased processing times and delay Li et al. [17] BFLC-Blockchain-based Federated Learning framework with Committee consensus CCM approach has increased energy consumption due to a large amount of communication overhead involved during model updates between nodes Lu et al. [19] PBFL-Privacy-preserving data sharing the mechanism for distributed multiple parties Improving the utility of data models mapped from raw data is necessary Qu et al. [29] BFL-Decentralized paradigm for big data-driven cognitive computing (D2C) Improves on Markov decision process (MDP) rather than addressing privacy issues with blockchain that is assumed tamper-proof Wan et al. [37] BFL-Wasserstein generative adversarial network (WGAN)

(p34.2) Need for efficient communication and computation methods, privacy and security concerns in federated learning, and the problem of non-iid data distribution in edge computing environments Shayan et al. [33] Biscotti: a fully decentralized peer-to-peer (P2P) approach to multi-party ML Requiring large honest samples for Multi-Krum, limited scalability for large deep learning models, and vulnerability to privacy attacks. Qi et al. [27] BFL-Traffic Flow Prediction (TFP) Slower convergence rate due to its decentralized learning paradigm and model aggregation step, as opposed to the SAE model's centralized learning. Ur Rehman et al. [36] BFL-Reputation-aware fine-grained A reputation-aware federated learning system that exchanges information securely and privately while maintaining data privacy and integrity. Arachchige et al. [2] PriModChain -Differential privacy, Federated ML, Ethereum blockchain, and Smart contracts.
## (s37) B. Model accuracy and Latency
(p37.0) BCFL models require maintaining and improving the accuracy and efficiency of the model. The mini-batching at the client during each training epoch and increasing multi-client parallelism to reach a target test-set accuracy framework can be adopted. The learning performance of Federated Learning has not been discussed in details. It is necessary to verify the multi-key encryption protocol because of the way it secures the federated ML model data. The accuracy and latency of PrimodChain [2] systems still need optimization.

(p37.1) BCFL models require maintaining and improving the accuracy and efficiency of the model. The mini-batching at the client during each training epoch and increasing multi-client parallelism to reach a target test-set accuracy framework can be adopted. The learning performance of Federated Learning has not been discussed in details. It is necessary to verify the multi-key encryption protocol because of the way it secures the federated ML model data. The accuracy and latency of PrimodChain [2] systems still need optimization.
## (s38) C. Unexplored Complexity
(p38.0) The work presented by Wang et al. [39] provides only theoretical analysis, and BEMA robustness against Byzantine attacks cannot be guaranteed. A Byzantine attack occurs when an attacker adheres to the system protocol but disseminates malicious information to innocent system participants, with the goal of diminishing system performance and manipulating or influencing the system's output. More evaluation is still needed as the learning strategies and security concerns are not fully investigated. The existing research on multiparty learning has mainly focused on homogeneous local models. However, there is still a lack of research on multiparty learning over heterogeneous local models. This is despite the fact that such a scenario may be more practical and useful in real-world applications.

(p38.1) The work presented by Wang et al. [39] provides only theoretical analysis, and BEMA robustness against Byzantine attacks cannot be guaranteed. A Byzantine attack occurs when an attacker adheres to the system protocol but disseminates malicious information to innocent system participants, with the goal of diminishing system performance and manipulating or influencing the system's output. More evaluation is still needed as the learning strategies and security concerns are not fully investigated. The existing research on multiparty learning has mainly focused on homogeneous local models. However, there is still a lack of research on multiparty learning over heterogeneous local models. This is despite the fact that such a scenario may be more practical and useful in real-world applications.
## (s40) E. Scalability
(p40.0) The blockchain-based audit approach for encrypted gradients in federated learning provides privacy while assessing gradient quality. However, scalability can be a challenge due to the consensus requirement in blockchain technology. Adding new blocks necessitates agreement among all network nodes, resulting in time-consuming and expensive audits, particularly for large federated learning systems. Two approaches to mitigate scalability limitations are (1) off-chain computation [10], which performs audits on a subset of nodes, and (2) compression, which reduces the size of encrypted gradients before blockchain storage. These techniques aim to improve efficiency without compromising quality. Continued research seeks to enhance scalability and make this approach more practical.

(p40.1) The blockchain-based audit approach for encrypted gradients in federated learning provides privacy while assessing gradient quality. However, scalability can be a challenge due to the consensus requirement in blockchain technology. Adding new blocks necessitates agreement among all network nodes, resulting in time-consuming and expensive audits, particularly for large federated learning systems. Two approaches to mitigate scalability limitations are (1) off-chain computation [10], which performs audits on a subset of nodes, and (2) compression, which reduces the size of encrypted gradients before blockchain storage. These techniques aim to improve efficiency without compromising quality. Continued research seeks to enhance scalability and make this approach more practical.
