# An Overview of Human Activity Recognition Using Wearable Sensors: Healthcare and Artificial Intelligence

CorpusID: 232417727 - [https://www.semanticscholar.org/paper/ddbf23d95ef88abf02d7baf0bb2e91496e6ccff9](https://www.semanticscholar.org/paper/ddbf23d95ef88abf02d7baf0bb2e91496e6ccff9)

Fields: Engineering, Computer Science, Medicine

## (s0) Introduction
(p0.0) Human activity recognition has been actively researched in the past decade, thanks to the increasing number of deployed smart devices such as smartphones and IoT devices. Based on the type of data being processed, a HAR system can be classified into vision-based and sensor-based. This paper targets wearable-sensor HAR systems in healthcare, which are the most prevalent type of sensor-based HAR systems [1]. More importantly, wearable-sensor HAR systems do not suffer from severe privacy issues like vision-based HAR systems, making wearablesensor HAR systems suitable for healthcare applications. In a wearable-sensor HAR system, a user wears portable mobile devices that have built-in sensors. The user's activities can then be classified by measuring and characterizing sensor signals when the user is conducting daily activities.

(p0.1) HAR for healthcare has many potential use cases, including (1) Moving gait diagnosis from expensive motion labs to the community. Gait analysis can be used in many healthcare applications, such as stroke detection, gait modification (to prevent failing), and certain disease early detection. (2) Cognitive behavior monitoring and intervention for children and adults with attentiondeficit/hyperactivity disorder (ADHD). We can leverage sensors to investigate whether fidgeting positively or negatively affects attention. (3) Stroke-patient hospital direction. When a patient is in an ambulance, a life-and-death question is whether the patient has extensive brain hemorrhage. If so, the patient should be directed to a hospital that can treat such cases. UCSF has developed a device based on an accelerometer sensor to help make this critical decision. (4) Epilepsy and Parkinson's disease study. Doctors have collected a significant amount of data on electrophysiology and episodic memory in rodents and human patients. The analysis of such sensing data can be used for various disease identification and treatment purpose. (5) An expensive device, called Vision RT, is used to ensure radiation therapy is delivered safely to cancer patients (due to patient motion). It is worth exploiting sensors to detect the patient's movement while taking radiation therapy for the less affluent communities.

(p0.2) However, building practical wearable-sensor HAR systems for healthcare applications not only has challenges (e.g., sensor setup, data collection, and AI model selection) that are faced by traditional wearable-HAR systems, but also challenges that are unique to the healthcare domain. For example, in addition to the overall AI model accuracy (averaging results of all users), clinicians are concerned about the model stability (i.e., the model has approximately the same accuracy for each user) and model interpretability (e.g., to discover patient movement patterns that are specific to some symptoms).
## (s1) Human Activity Recognition: A Primer
(p1.0) Given the short time-length data of wearable sensors, a HAR system needs to recognize the activity from which the data is generated. Thanks to the rapid advancement of AI technology, AI algorithms/models are increasingly adopted for recognizing the activity from the sensor data. Figure 1 illustrates the general data flow for an AI-based HAR system, which can be divided into two stages: model training and model deployment.

(p1.1) In the model training stage, an AI model is trained and tailored for the specific application. To achieve an accurate AI model, the following steps are often applied. First, raw sensor data from different activities should be collected. The quality of collected data significantly affects the AI model performance. The collected data is required to be diverse, representative, and large in the number of samples. Afterward, the raw data is divided into fixed-length or dynamic-length segments (i.e., time windows) [4]. Then, feature extraction is used to extract potentially useful features from the data segmentation, and feature selection is adopted to remove irrelevant features [5]. To alleviate the overfitting problem of the trained model, the set of processed features are divided into a training set, a validation set, and a test set. During the AI model training, we use the training set to tune the AI model and the validation set to measure the model's accuracy. After we finish the model training, we use the test set to evaluate the trained model. The trained model is deployed to real-world applications if its accuracy is satisfactory. Otherwise, the whole model training stage is performed repetitively by exploring different configurations, such as applying other feature extraction methods and changing AI models.

(p1.2) In the model deployment stage, the same data processing (e.g., segmentation, feature extraction, and selection) is applied to the new and unseen sensor data, and the trained model is executed on the processed data. It is possible that the  trained model may not work as expected in a real deployment, probably due to the model over-fitting or the lack of generality in the collected dataset [6]. In this situation, the system designer needs to revert to the model training stage.
## (s3) Case 1: Identification of Early Mobility Activity for ICU Patients
(p3.0) Due to long periods of inactivity and immobilization, patients become weak when recovering from major illnesses in ICU [7]. If ICU patients' activities can be accurately recognized, clinicians can provide an optimal personalized dose of mobilities for ICU patients' different illness conditions. Therefore, doctors and researchers are extremely interested in ICU patients' early mobilization, which is an effective and safe intervention to improve functional outcomes [8]. However, early mobility activity (EMA) research is limited by the lack of accurate, effective, and comprehensive methods to recognize patients' activities in ICU.

(p3.1) We propose a wearable sensor-based HAR system for recognizing the EMA of ICU patients [2]. In our system, Each ICU patient wears two accelerometer devices: one on the chest and the other on the thigh, as shown in Figure 2(a). Each device continuously collects 3-axis accelerometer data at a sampling rate of 32 Hz. Figure 3(a) plots the accelerometer data when an ICU patient sits on the cardiac chair to achieve an optimal resting position. This project aims to classify 20 types of ICU-related activities (e.g., reposition, percussion).

(p3.2) This project has two main challenges in designing the HAR system for ICU patients. (1) Label Noise. Because the time lengths for accomplishing an early mobility activity are different for ICU patients with varying health conditions, it is laborious and time-consuming work for clinicians to annotate sensor data for each second in the real world. Therefore, our EMA sensor data are annotated for each minute by a medical expert after data collection. However, one-minute length is exceedingly long for some early mobility activities such as Reposition, which the patient needs less than 20 seconds to accomplish. This annotation process introduces the label noise in our EMA dataset, which decreases the accuracy of the model. (2) Sensor Orientation. In the actual data collection process and possible future applications, we cannot guarantee that the orientations of all accelerometers are the same, and different orientations of the accelerometers lead to different meanings of XYZ coordinate values. Therefore, without careful feature extraction and selection, the AI model generalizes poorly to different patients, affecting the system performance in practice.

(p3.3) To tackle these challenges and improve the accuracy of recognizing ICU patient's activities, we explore the following techniques. (1) We propose a segment voting process to handle the label noise. Specifically, each one-minute sensor data is divided into multiple fixed half-overlapped sliding segments (time windows). We train our AI model using the segments. To predict each one-minute sensor data activity, we apply our trained model to each segment. The final prediction result for the one-minute data is the activity that has the majority vote among the prediction of all segments. Our segmenting method improves the model accuracy by ∼4.08% and reduces the model instability by ∼9.77% [2]. Our experiments also demonstrate that the number of sensors contributes to eliminating label noise in our dataset. As shown in Figure 3(a), the increase in the number of sensors conveys more information, and thus improves the system's accuracy. (2) We identify and extract features that are not sensitive to sensor orientations to tackle the sensor orientation problem. Our features improve both the accuracy and the stability of AI models compared to the model trained on commonly used features.
## (s7) Sensor
(p7.0) Sensors play an essential role in wearable HAR systems. Different HAR systems adopt various sensor configurations regarding the type of sensors, the sensor position and orientation, and the number of sensors.

(p7.1) Sensor Types There are several types of sensors. Each sensor captures a different raw movement signal. The most commonly-used wearable sensors in HAR systems are accelerometer, gyroscope, and electrocardiography (ECG). The accelerometer sensor captures the acceleration signal that is useful for recognizing movements such as walking, running, and jumping. Gyroscopes capture the rotation movements used commonly in recognizing swinging, turning, and repositioning. ECG captures the heart rate and rhythm, which helps distinguish between intensive and light exercises.

(p7.2) However, many activities include both directional and rotational movements. Therefore, using one sensor type is not adequate. As a result, multiple types of sensors (e.g., accelerometer and gyroscope) are used in various application scenarios to maximize accuracy. However, using multiple types of sensors is challenging due to the increased complexity of the system in terms of synchronization issues [15].

(p7.3) Sensor Position and Orientation Different positions and orientations of devices affect the data features and thus the model accuracy in predicting different activities [16]. However, there have not yet been systematic comparisons of the number, type, and location of sensors to determine whether an optimal array design can capture data across a wide range of human activities and disease states. In many cases, the device position and orientation are decided by the empirical experience of clinicians.
## (s8) Number of Sensors
(p8.0) Generally, a large number of sensors require demanding storage and computation capability. On the other hand, more sensors can collect more diverse data, which is beneficial for improving model performance [17]. Therefore, to decide the optimal number of sensors, researchers need to carefully consider many factors such as cost, power consumption, and accuracy target as well as the feasibility of long-term use in the community to collect real-world information [18].
## (s9) Feature Extraction and Selection
(p9.0) In addition to the hardware setup, feature extraction and selection significantly affect the overall system performance. Before applying feature engineering to the data, the input data needs to be segmented.

(p9.1) Data Segmentation HAR systems collect data constantly via wearable sensors to identify possible activities. Data segmentation is applied to divide comparatively long time data into short fragments (time windows) that are suitable for AI models to learn. There are two types of data segmentation: fixed-length and dynamic-length [4]. For fixed-length segmentation, if the time window is too short, the extracted features from the fragments are insufficient to capture the activity; on the other hand, if the time window is too long, a fragment is likely to contain multiple activities. The system accuracy deteriorates in both cases. In comparison, a dynamic-length data segmentation adopts an adaptive length of fragments corresponding to the characteristics of input data. Ideally, dynamic data segmentation generates fragments, in which each fragment only contains a single and complete activity. However, dynamic data segmentation is much more complex than fixed data segmentation, and thus are not as widely adopted by existing works as fixed-length segmentation.

(p9.2) Feature Extraction Feature extraction is then applied to extract important features from the data fragments [5]. It can be broadly classified into time-domain and frequency-domain methods. In time-domain feature extraction, metrics such as median, variance, mean, and skewness are calculated over the amplitude variations of data over time. Time-domain features are lightweight to compute and thus are friendly to low-profile embedded devices and real-time applications. In comparison, frequency-domain features calculate the frequency variations of data over time. They include metrics such as spectral entropy, spectral power, and peak frequency. The computation overhead of frequency-domain features is generally much greater than time-domain features. In reality, most existing HAR systems adopt both time-domain features and frequency-domain features, in the consideration of the tradeoff among factors such as system accuracy, computation overhead, and power consumption.

(p9.3) Feature Selection Feature selection is often adopted in order to reduce system complexity. It measures the importance of features and then removes irrelevant features. Feature selection is roughly divided into three methods: filter methods, wrapper methods, and embedded/hybrid methods [5]. Filter methods select a subset of features by exploiting inherent characteristics of features, whereas wrapper methods use classifiers to estimate the useful features. On the other hand, the embedded/hybrid methods combine the results from filter methods and wrapper methods [1]. By carefully selecting features, the AI model accuracy can be significantly improved. However, in healthcare HAR systems, pursuing high accuracy is not the sole goal, as the features are often manually decided by medical experts for identifying patients. Therefore, healthcare HAR systems require feature extraction and selection that is meaningful for clinicians and meanwhile achieves high prediction accuracy.
## (s16) Privacy
(p16.0) Wearable sensor-based HAR systems do not suffer from severe privacy issues as camera-based vision systems. However, since HAR applications continuously capture user data and recognize user activities, they may leak users' personal information if data are not secured. Therefore, secure data sharing and safe data storage are imperative for healthcare applications. To alleviate sensitive information during model training, adversarial loss functions are leveraged to guard against privacy leakage [26]. In addition, federated learning is a promising solution, which trains a global model without exposing local devices' private data [27].
