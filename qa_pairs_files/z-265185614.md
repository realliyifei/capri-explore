# On the trajectory of discrimination: A meta-analysis and forecasting survey capturing 44 years of field experiments on gender and hiring decisions

CorpusID: 265185614 - [https://www.semanticscholar.org/paper/0a22fa31bc721b3dc7ad7d9b9e3543d84abb3b6e](https://www.semanticscholar.org/paper/0a22fa31bc721b3dc7ad7d9b9e3543d84abb3b6e)

Fields: Business, Psychology, Sociology

## (s1) Competing theories of stability and change in gender discrimination
(p1.0) One of our key research questions was whether there is a time trend in gender discrimination in job application outcomes.Different patterns of cultural evolution in discrimination based on applicant gender are possible.Biased selection decisions may have remained stable over time, such that there is significant discrimination against women in recent as well as older field audits.This persistence-of-bias account posits that the continuing existence of many stereotypes and sexist beliefs (Eagly et al., 2000;Glick & Fiske, 2001) means behavioral discrimination should continue largely undiminished.Indirectly relevant meta-analytic evidence suggests that in many Western societies, racial and ethnic discrimination in selection for jobs has persisted across all observed time periods (Quillian & Lee, 2023;Quillian et al., 2017).If racial discrimination in hiring remains pervasive, this increases the plausibility that gender bias in candidate selection, which theoretically derives from some of the same implicit and explicit mental processes (Greenwald & Banaji, 1995) and situational forces (Larwood, Szwajkowski, & Rose, 1988), remains widespread as well.More direct evidence is provided by recent work demonstrating that gender stereotypes remain deeply ingrained in the minds of many in the form of automatic associations (Charlesworth & Banaji, 2022) and are reflected in widely consumed cultural products such as music (Boghrati & Berger, 2023).If gender stereotypes are "in the air" in the surrounding culture and conditioned in people's minds, it is reasonable to expect that stereotype-based discrimination in selection decisions against female and male candidates is commonplace as well.Substantial preceding research thus provides a strong a priori empirical reason to expect similar robust biases in hiring against female applicants, all the way up to the present.

(p1.1) Alternatively, discrimination against female candidates may have faded away over time, such that recent studies will reveal little gender disparity in selection.This fading-of-bias account acknowledges that unfair discrimination was common in past generations, contributing to inequalities that have carried over into the present.For example, gender gaps in representation in senior leadership positions today are attributable in part to upstream biases in selection decades ago that limited the present-day pool of available talent just below the executive level.Yet from this perspective, today's organizational decision makers have become better at correcting for societal stereotypes when it comes to deciding who to hire (Tetlock & Mitchell, 2009), and given empirical evidence of changes in at least some gender norms and behaviors (Badura, Grijalva, Newman, Yan, & Jeon, 2018;Hora, Badura, Lemoine, & Grijalva, 2021;Koenig, Eagly, Mitchell, & Ristikari, 2011) may also be less biased in the first place.A more nuanced view posits that gender discrimination is uncommon in hiring decisions, which are publicly visible and carefully monitored for bias by individuals and organizations, but still visible in compensation decisions that occur behind a shroud of confidentiality (Ceci et al., 2023).Regardless, from this perspective, contemporary selection processes are in the aggregate no longer substantially impacted by applicant gender.
## (s16) Robustness tests
(p16.0) We carried out several robustness and sensitivity analyses (detailed model statistics for the analyses below are available in the R output document on the Open Science Framework at https://osf.io/ha3n4).First, three studies reported two outcomes (e.g., callbacks and interview invites) based on the same sample.This violated the assumption of independent sampling errors in the meta-analysis models (e.g., Hedges, Tipton, & Johnson, 2010).Since only six effect sizes of the 244 effect sizes came from the same sample, we decided to conduct a sensitivity analysis where we selected for each of the three studies one of the two effect sizes based on which of the two measures was more inclusive (e.g., if a study reported both callbacks and interview invites, we selected callbacks).The results of these multilevel meta-analyses did not differ substantively from those of the multilevel meta-analyses based on all data.Specifically, the overall average odds of male applicants to receive a callback remained significantly lower than the average odds of equally qualified female applicants (-0.911, z = -3.08,p =.002).The moderation of the effect of gender on callbacks by job type remained significant as well (0.253, z = 4.82, p <.001).Finally, the time trend suggesting a decrease in pro-male gender discrimination over time remained significant excluding (-0.010, z = -2.45,p =.014) or including (-0.015, z = -3.01,p =.003) control variables.

(p16.1) Second, although we preregistered to use publication year as the time variable, we noticed during the coding that the time between data collection and publication of an audit study varied substantially across studies (ranging from 0 to 11 years).Because the year in which applications were sent out more accurately reflects gender discrimination at any given point in time, we used data collection year as time variable in the primary analyses.However, we conducted supplemental analyses with publication year as the time variable and found comparable results.Replicating the main analyses, the time trend suggesting a decrease in pro-male gender discrimination over time remained significant excluding (-0.011, z = -2.67,p =.008) or including (-0.016, z = -3.17,p =.002) the control variables.

(p16.2) Third, we examined whether any one study had a particularly large effect on our results (see Section S8 in Supplementary Online Materials for detailed analyses).A leave-one-out analysis (Viechtbauer, 2010) indicated that the overall discrimination patterns and the moderation by job type remained for the most part robust.The decrease in discrimination over time was robust to the exclusion of most studies, except for one large sample study conducted in 1978 and published four years later (Firth, 1982).Exclusion of this study caused the time trend effect to be closer to zero for the models without (-0.005,SE = 0.004) and with control variables (-0.008,SE = 0.006) and made the effect nonsignificant.This is not surprising given the number of audit studies before 1990 was relatively small, such that removing the field audit with the largest sample size from the earliest time period can affect the overall estimate of the time trend (for a similar conclusion for race studies, see Quillian et al., 2017).We return to this issue in the General Discussion.

(p16.3) Finally, field audits aim to occlude from evaluators that they are involved in a research study by sending ostensibly real job applications to actual businesses.However, this does not completely rule out the possibility of some evaluators realizing their judgments are under scrutiny by researchers.Further, the chances of this occurring are not necessarily constant across all types of field audits.Specifically, paired audit designs may entail the greatest risk of experiment discovery among employers since they receive highly similar applications from members of both historically advantaged and underrepresented groups (e.g., men and women).However, the present meta-analysis finds no significant difference in results for audits that sent female and male applications to the same versus different employers (0.12, SE = 0.068, z = 1.74, p =.08).
## (s18) Additional exploratory analyses
(p18.0) In addition to controlling for author gender in our meta-analytic models (see above), we also examined whether author gender would moderate the extent to which a study would report gender bias on the part of prospective employers.However, author gender did not influence the amount of gender discrimination reported across all studies and years (-0.06,z = 0.60, p =.549).

(p18.1) In addition to categorizing jobs into female-typed, male-typed, and gender-balanced jobs, we also examined additional job grouping variables.First, we examined whether gender discrimination would vary as a function of whether a job requires physical strength (0 = no, 1 = yes; rated by four human coders; Fleiss kappa = 0.76, p <.001).Results suggest that job physicality significantly moderated the effect of gender on callbacks (0.26, z = 2.08, p =.038), such that the average odds of a male (vs.female) applicant to receive a callback was significantly higher for physical jobs (odds ratio: 1.17, 95% confidence interval: 0.92, 1.49) compared to non-physical jobs (odds ratio: 0.91, 95% confidence interval: 0.85, 0.96).However, note that the proportion of jobs that require physical strength (4.92%) is small in the present sample and should thus be seen as a tentative result requiring confirmatory tests involving larger samples of jobs.Second, we explored whether gender discrimination varied as a function of whether a job required nurturance (0 = no, 1 = yes; rated by four human coders; Fleiss kappa = 0.74, p <.001).We found that job nurturance did not moderate the effect of gender on callbacks (0.09, z = 0.85, p =.394).Similar to job physicality, the proportion of jobs that require nurturance (6.97%) is small, rendering any conclusions tentative.Effect sizes are grouped together depending on the year the applications were sent out and were combined using a univariate random-effects model.The top panel (Fig. 5A) shows the average odds ratio before 2009 and 2009 and thereafter, which corresponds to the theoretical crossover point of the time trend in Fig. 3.The bottom panel (Fig. 5B) compares the odds ratios using more granular time periods, including the post-#MeToo years of 2018-2020.Odds ratios above 1 indicate a greater preference for male applicants and odds ratios below 1 indicate greater preference for female applicants.Error bars indicate the 95% confidence interval around the average odds ratio that is based on a normal distribution.The size of the symbols is proportional to the number of effect sizes in the respective bin.

(p18.2) Finally, we examined the potential influence of several country-level factors that could affect gender discrimination.First, in addition to including a country's gender inequality as a control variable, we tested whether the GII (described earlier) would moderate the present results; however, this was not the case (-0.713, z = 1.38, p =.168).Second, we examined whether a country's education level would affect the results, using the United Nation's Education Index (United Nations Development Programme, 2020).Similar to the GII, we matched the closest available Education Index value to each country and study year.However, education did not moderate the effect of applicant gender on discrimination (-0.291, z = 0.430, p =.667).Third, we tested whether gender discrimination may be influenced by economic prosperity, using GDP per capita data (log) retrieved from The World Bank (https://data.worldbank.org/),but found no significant effect (-0.065, z = 0.716, p =.474).Fourth, we examined whether gender discrimination is influenced by the Human Development Index (HDI)-a summary measure of average achievement in human development, including longevity and standard of living among other factors (United Nations Development Programme, 2020).However, we found no significant moderating effect of HDI (0.036, z = 0.077, p =.939).Lastly, we examined whether culture would influence gender discrimination using the WEIRD index developed by Muthukrishna et al. (2020).However, we did not find any moderating effect (-1.465, z = 1.417, p =.157).
## (s20) Study 2: Forecasting challenge
(p20.0) The (to us) rather surprising meta-analytic findings give rise to the related question of whether empirical patterns of gender discrimination map on to the beliefs of laypeople and academics.Accuracies and inaccuracies in perceptions of group inequalities hold important implications for the efficient allocation of limited resources to combat them (Byrd & Thompson, 2022;Ceci et al., 2023;Kraus, Hudson, & Richeson, 2022).Consider for example that gender biases in hiring may be systematically overestimated by scientists, the general public, or both.If so, workplace interventions will tend to focus on making selection contexts fairer, rather than conducting systematic audits for wage inequalities between women and men or reforming the promotion processes in organizations.

(p20.1) To complement the meta-analytic investigation (Study 1), we carried out an accompanying forecasting survey examining whether scientists and laypeople could accurately estimate both time-trends and the current pervasiveness of gender biases in selection settings.Previous research has demonstrated that academics sometimes perform well in anticipating the results of scientific studies, based on limited information such as article abstracts and study materials (Camerer et al., 2016;Dreber et al., 2015;Forsell et al., 2019).Accuracy on the part of scientific forecasters has been observed even for fairly complex results such as different conceptual replications testing the same research question (Landy et al., 2020), experimental designs involving complex interactions (Tierney et al., 2020;2022), and cross-cultural similarities and differences (Tierney et al., 2021).Based on this earlier work, one straightforward prediction is that at least for academics, forecasts and realized results for gender discrimination over the years will be closely aligned.
## (s22) Forecasters
(p22.0) The nationally representative sample of laypeople was recruited through Prolific Academic and included 499 participants with ages between 18 and 78 (mean 35).When asked for their gender, 248 selected 'female', 244 selected 'male', 6 selected 'other', and 1 did not respond.In terms of overall political views, 85 participants reported to be at least somewhat conservative, 95 reported to be in the 'middle of the road' and 318 reported to be at least somewhat liberal.The sample was designed to be as representative as possible of the U.S. population on the dimensions of age, sex, and ethnicity using census data from the U.S. Census Bureau.Although the Prolific sample reflects the general population of the United States on these dimensions, it is not nearly as ideologically diverse as would be ideal.A sample with more left-leaning than right-leaning Americans is typical of such onsite data collection sites (Levay, Freese, & Druckman, 2016).

(p22.1) Forecasters from the academic sample were recruited through social media, professional listservs, direct email, and doctoral seminars.In the academic sample (N = 312), the age of the participants ranged from 21 to 76 (mean 38).When asked for their gender, 116 participants selected 'female', 195 selected 'male', and 1 selected 'other'.Most academics reported being at least somewhat liberal in their overall political views (2 4 7), while 38 chose 'middle of the road' and 27 reported being at least somewhat conservative.The largest subgroups of academic forecasters were from the fields of psychology (139, including subfields such as social and clinical psychology), economics (64, including subfields such as behavioural economics) and management (41, including subfields such as organizational behaviour and marketing).Of the remaining 65 participants, 35 were distributed over 16 different fields, and 33 did not provide an academic field or responded with 'N/A'.Career stages included Assistant Professor (69), Associate Professor (57), Professor (63), Graduate Student (64), Postdoctoral Scholar ( 27), Teaching Faculty (12), Research Assistant (11), other academic position (6), and Professor Emeritus (1); two participants did not respond to this item.Forecasters were provided a copy of the draft empirical report in advance and asked if they would like to opt-in to consortium authorship and if so to provide their names and affiliations.Colleagues listed as members of the Gender Audits Forecasting Collaboration in the Appendix A both made forecasts and indicated they would like to be part of the consortium credit.Not all forecasters elected to be listed as consortium authors, thus the number of names in the Appendix A differs from the sample size for Study 2.
## (s27) Individual differences in accuracy
(p27.0) Further analyses examined whether individual forecaster characteristics moderate the accuracy of their predictions.These included whether they were a trained scientist or layperson, their political orientation, and their endorsement of system justifying beliefs, among other potential moderators.Of particular interest was whether ideological beliefs, on either side of the spectrum, introduce systematic error that undermines the wisdom of the crowd effect typically observed in forecasting settings (Dreber et al., 2015).
## (s28) Scientists versus laypeople.
(p28.0) For each survey-taker, the accuracy of each forecasting question is quantified as the squared difference between the prediction and the observed estimate in the meta-analysis.We estimate the mean squared prediction error of each forecaster for the nine verifiable predictions and then test if this differs between scientists and laypeople using an independent samples t-test.We find that the mean squared prediction error is significantly smaller for the academic forecasters compared to the layperson sample (means = 2.86 vs. 7.27, t (8 0 3) = -10.3,p <.001).This is because laypeople gave more extreme and therefore less accurate estimates than the academics (see Fig. 7).

(p28.1) Political orientation.To assess the political orientation of each forecaster, we averaged their responses to the three questions about their overall, social, and economic political orientation.We estimate an OLS regression with the mean squared prediction error of each forecaster as the dependent variable and the political orientation variable as the independent variable.The OLS regression is estimated with clustered standard errors, and the test is carried out as a t-test on the coefficient of the political orientation variable in the OLS regression.We find no statistically significant effect of political orientation on forecasting accuracy in the academic sample (coefficient = 0.048, t = 0.25, p =.80) or in the layperson sample (coefficient = − 0.33, t = -1.52,p =.13).

(p28.2) General system justification.For the academic sample, we find that individual differences in system justification are associated with a reduction in error (coefficient = -0.46,t = -2.48,p =.014).For the U.S. layperson sample, with increasing endorsement of the items on the general system justification scale, the error likewise decreases (coefficient = -0.83,t = -2.65,p =.008).Since a negative coefficient reflects fewer errors, this means high system justification scores are associated with greater accuracy in forecasting.Note however that these associations are only statistically significant according to the conventional p <.05 threshold, not under the stricter p <.005 threshold (Benjamin et al., 2018) we also pre-registered for the forecasting analyses (see S10 Fig. 7. Observed versus forecasted results of the gender audits meta-analysis.Observed and mean forecasted log odds ratios from the academic and U.S. nationally representative samples.Positive log odds ratios denote higher callback rates for male candidates than for female candidates, and negative log odds ratios denote higher callback rates for female candidates than for male candidates.Note that there is no observed meta-analytic result for female typed jobs for the period 1987-1997 due to a lack of relevant field audits during that span of years.
## (s32) Limitations and non-implications
(p32.0) Our most important data limitation is the comparatively smaller number of audits before 2000, and especially before 1980, compared to more recent years where more precise estimates are possible (see Quillian et al., 2017, for a similar temporal distribution of audits of racial bias).Of particular concern, Study 1′s leave-one-out analysis finds that omitting a single large early study renders the overall time trend nonsignificant.Although readers can judge for themselves, we believe a large effect size for discrimination against female job applicants in a rare well-powered study from 1978 is highly representative of the widespread discrimination against women during that period (Avent-Holt & Tomaskovic-Devey, 2012; Blau & Kahn, 1997;Eversley & Habell-Pallán, 2015;Snipp & Cheung, 2016;Stanley & Jarrell, 1998) and important data to include in the meta-analysis.The study in question features by far the largest sample from before 1980, to the point that arbitrarily deleting it from the meta-analysis excludes 93% of pre-1980 applications without any real justification.An argument must also be followed where it leads.Deleting the large 1978 study and rejecting the conclusion of a time trend necessitates also concluding little to no discrimination against female applicants for stereotypically male-typed and gender-balanced jobs prior to 1980.Rejecting the time trend also does not question another key finding: contrary to popular and scientific beliefs, there is no evidence of recent discrimination in callback rates against female job candidates in the nations sampled.If there is no time trend, both scientists and laypeople are even more inaccurate in their theories of bias against female candidates, not only misestimating present day discrimination, but also past discrimination and cultural trajectories over time as well.

(p32.1) Although we believe the data does support a downward time trend, pinpointing exactly when anti-female discrimination in selection decisions reached zero in the societies in question may not be possible due to data limitations.Our sample of pre-1980 observations is neither large in absolute terms nor in comparison to recent large-scale audit studies.In general, we face rapidly mounting uncertainty in meta-analyzing the literature the further we go back in time.The available set of field audits suggest that selection bias against women for male-typed and genderbalanced jobs faded away in 2009, but this conclusion may be unduly affected by one older study.The actual year could be earlier, or later, and likely differs across societies based on unmeasured moderators we are unable to capture or test due to inadequate sample sizes of older audit studies within each nation.Although drawing strong inferences about past discrimination is challenging, as discussed in greater depth below, the scientific community is well positioned to do rigorous new work testing the robustness and direction of current gender biases in selection decisions.

(p32.2) At the same time, we warn against interpreting our meta-analytic results to conclude equality of treatment of female applicants has been achieved with regard to historically male-typed and gender-balanced jobs, and that current efforts to increase the proportion of female employees in such roles are no longer needed.Our data did not examine the consequences of abandoning current policies, and doing so risks increasing gender bias in the future.If organizations decide to discontinue their diversity, equity, and inclusion (DEI) efforts with regard to gender, or individuals stop making the effort to override their own sexist biases, one potential result is a slide back to discrimination against qualified female applicants.A point estimate for gender discrimination close to zero in some contemporary societies also does not mean that all the industries and organizations within those societies are free of bias.It is not possible to make generic recommendations given the large heterogeneity observed in the effect sizes, and the decision to pursue inclusive hiring needs to be made on an organization-by-organization basis.Firms that experience an upward trend in hiring women may experience backlash against this increased diversity among members of historically privileged groups (Craig & Richeson, 2014;Danbold & Huo, 2015;Dover, Major, & Kaiser, 2016).Further, given the continuing discrimination against male applicants for female-typed occupations, it is important to work to improve the social acceptability and presence of men in jobs such as social worker, nursing, preschool educator, and receptionist.Even without gender bias in selection into jobs, implicit barriers remain in place that could reduce female representation in male-typed jobs and male representation in female-typed job.For example, if male nurses and secretaries are perceived to violate prescriptive gender norms and suffer backlash effects, then there should be relative fewer male applicants for such roles even in those organizations that would not have been averse to hiring them.
