# Deep Learning Approaches to Lexical Simplification: A Survey

CorpusID: 258833368 - [https://www.semanticscholar.org/paper/a9429423352c9b15531d32a43b5cd560519a3214](https://www.semanticscholar.org/paper/a9429423352c9b15531d32a43b5cd560519a3214)

Fields: Linguistics, Computer Science

## (s0) Introduction
(p0.0) LS improves the readability of any given text with the aim of helping vocabulary and literacy development. LS achieves this by replacing complex words in a sentence with simpler alternatives. LS returns a simplified sentence which can be passed to a TS system for further syntactic and grammatical simplification. The replaced complex words are those words which a general or targeted population found to be hard to read, interpret, or understand. Previous LS systems have been designed to simplify complex words for children, second language learners, individuals with reading disabilities or low-literacy (Paetzold and Specia, 2017b). LS therefore provides both developers and users with a degree of personalization that is unattainable through seq2seq or generative TS systems (Yeung and Lee and Yeung, 2018a).

(p0.1) Deep learning, and latterly, LLM and prompt learning, have revolutionized the way we approach many NLP tasks, including LS. Previous LS systems have relied upon lexicons, rule-based, statistical, n-gram, and word embedding models to identify and then simplify complex words (Paetzold and Specia, 2017b). These approaches would identify a complex word, for example, "bombardment" as being in need of simplification and would suggest "attack" as a suitable alternative ( Figure  1), hereby referred to as a candidate substitution.
## (s2) Evaluation Metrics
(p2.0) All sub-tasks of the LS pipeline are evaluated using precision, accuracy, recall, and F1-score. Several additional metrics have also been used: potential, mean average precision (MAP), and accuracy at top-k. Potential is the ratio of predicted candidate substitutions for which at least one of the top-k candidate substitutions generated was among the gold labels (Saggion et al., 2022). MAP evaluates whether the returned top-k candidate substitutions match the gold labels as well as whether they have the same positional rank. Accuracy at top-k = [1, 2, or 3] is the ratio of instances where at least one of the candidate substitutions at k is among the gold labels.
## (s3) Deep Learning Approaches
(p3.0) Prior to deep learning approaches, lexicon, rulebased, statistical, n-gram, and word embedding models were state-of-the-art for SG, SS, and SR. As previously mentioned, Paetzold and Specia (2017b) have provided a comprehensive survey detailing these approaches, their performances, as well as their impact on LS literature. The following sections provide an extension of the work carried out by Paetzold and Specia (2017b). We introduce new deep learning approaches for LS and begin our survey of the LS pipeline at the SG phase. The recent developments in the CWI step of the pipeline have been extensively surveyed by North et al. (2022b).
## (s4) Substitute Generation
(p4.0) In 2017, word embedding models were state-ofthe-art for SG. Word embedding models, such as Word2Vec (Mikolov et al., 2013), were used alongside more traditional approaches, such as querying a lexicon, or generating candidate substitutions based on certain rules (Paetzold and Specia, 2017b). Word embedding models conducted SG by converting potential candidate substitutions into vectors, hence word embeddings, and then calculating which of these vectors had the highest cosine similarity, or lowest cosine distance, with the vector of the target complex word. These vectors were then converted back into their word forms and were considered the top-k candidate substitutions.
## (s5) Substitute Selection and Ranking
(p5.0) Traditional approaches to SS are still implemented post SG. Methods such as POS-tag and antonym filtering, semantic or sentence thresholds have been used to remove inappropriate candidate substitutions after having been generating from the above deep learning approaches (Saggion et al., 2022). Nevertheless, the majority of modern deep learning approaches have minimal SS, with SS often being simultaneously conducted during SG or SR. For instance, the metric used to generate the top-k can-didate substitutions, by it either similarity between word embeddings, or a pre-train LLM's prediction score, tends not to suggest candidate substitutions that are deemed as being inappropriate by other SS methods. Likewise, SR techniques that rank candidate substitutions in order of their appropriateness will in turn move inappropriate simplifications further down the list of top-k candidate substitutions to the point that they are no longer considered.
## (s9) English
(p9.0) Personalized-LS Lee and Yeung (2018b) constructed a dataset of 12,000 English words for personalized LS. These words were ranked on a fivepoint Likert scale. 15 native Japanese speakers were tasked with rating the complexity of each word. These complexity rating were then applied to BenchLS, in turn personalizing the dataset for Japanese speakers.

(p9.1) WCL Maddela and Xu (2018) introduced the Word Complexity Lexicon (WCL). The WCL is a dataset made up of 15,000 English words annotated with complexity ratings. Annotators were 11 nonnative English speakers using a six-point Likert scale.

(p9.2) LCP-2021* The dataset provided at the LCP-2021 shared-task (CompLex) , was developed using crowd sourcing. 10,800 complex words in context were selected from three corpora covering the Bible, biomedical articles, and European Parliamentary proceedings. Their lexical complexities were annotated using a 5-point Likert scale.
## (s12) Discussion and Conclusion
(p12.0) Since the 2017 survey on LS (Paetzold and Specia, 2017b), deep learning approaches have provided new headway within the field. MLM is now the go to method for SG, with the majority of recent LS studies having employed a MLM objective. The casual language model: GPT-3, surpasses the performance of all other approaches when subjected to prompt learning, especially when an ensemble of prompts are taken into consideration (Table 3). The prediction scores of MLM or casual language modeling have replaced various SS and SR techniques. LS systems that employ minimal SS and no SR apart from ranking their LLM's prediction scores, have outperformed more technical, featureoriented, and unsupervised ranking methods (Table  3). However, an exception is made with regards to equivalence score (Li et al., 2022), which has been shown to be effective at SR.

(p12.1) Future LS systems will make use of new advances in deep learning. We believe prompt learning and models, such as GPT-3, will become increasingly popular, given their state-of-the-art performance at SG. Using an ensemble of various prompts for SS and SR may advance LS performance. In addition, the creation of new metrics similar to equivalence score will likewise be beneficial.
