# Camouflaged Object Detection and Tracking: A Survey

CorpusID: 229018344 - [https://www.semanticscholar.org/paper/24327d7766a03f2dcac854b50b2f86e0c32fe5fa](https://www.semanticscholar.org/paper/24327d7766a03f2dcac854b50b2f86e0c32fe5fa)

Fields: Engineering, Computer Science, Environmental Science

## (s2) Intensity/Color Features
(p2.0) The feature plays an essential role in the detection of camouflaged objects. Here, techniques developed based on the intensity/color values of the frames are mainly discussed. Boult et al. [5] developed a background subtraction technique with two thresholds to detect the camouflaged target. Here, a higher threshold value is used to detect pixels that are certainly in the foreground. The lower one is considered to detect uncertain pixels (i.e., pixels that are either part of the background or camouflaged part of the object). Then, the quasi connected component is taken into consideration to get the camouflaged target. In this case, detection accuracy is also highly dependent on thresholds. The selection of proper threshold value itself is a problem. For slow-moving objects, this method fails to detect objects.

(p2.1) On the other hand, Hung and Jiang [15] devised a method to track a camouflaged object using sequential execution of weighted region consolidation and active contour. An iterative weighted region consolidation operator is used to fill the gaps introduced by camouflage. Then, an active contour model is built during tracking to capture the actual shape of the target. The performance of this method relies on the inter-frame difference. If the object has slow motion, it is challenging to localize the object using an iterative weighted region consolidation operator. Hence, tracking may fail for sequences containing slow-moving and uniform colored objects.

(p2.2) In [4] Boot et al. discussed that we usually learn something general about target recognition, which allow us to guide our eyes to the target more efficiently and recognize it faster and farther from fixation. They described that the background contains regular patterns. Deviations from this regularity signify the presence of a camouflaged target. However, this does not happen for all kinds of camouflaged objects. If the background and object contain similar regular patterns, it becomes challenging to extract the object from its surrounding. To detect a camouflaged object, Chandesa et al. [8] proposed an algorithm based on particle filter. Here, the Gaussian mixture model of particle distribution is considered to investigate camouflage's effect on the particle set representing the object. This method works well on the occluded object but not for the camouflaged object. Though this method works well, it needs object information (a priori) to execute the algorithm. In [9], Conte et al. proposed an algorithm to detect partially camouflaged people. Here, background subtraction is used to detect different parts of a person. Then grouping is performed based on a model of the shape of targets. This method is unable to provide satisfactory results for objects other than humans. In [51], a camouflaged model is proposed using a global model for the background and integration of global and local models for the foreground. Here, both the models helped to detect camouflaged objects.

(p2.3) Discussion: In general, intensity or color features are elementary and computationally efficient for fast, camouflaged object detection and tracking. The intensity or color feature can detect camouflaged objects where camouflage is occurred due to texture similarity with the background. In contrast, these features cannot detect camouflaged objects where camouflage occurs due to color similarity with the environment.
## (s3) Motion Features
(p3.0) Motion is considered as an essential feature to detect an object. Several techniques have been developed based on the motion of the objects. McKee et al. [27] concluded from their experiments that stereopsis is generally useful on breaking camouflage when both the observer and the scene are non-dynamic. Here, motion is a helpful feature for breaking camouflage on a static background. If the background is non-static, the motion feature fails to extract camouflaged objects from its surrounding. In this direction, Ternovskiy and Jannson [42] have proposed a motion prediction approach to detect the target in the camouflage environment. This method is suitable for the sequences where changes occur due to the object and camera movement only. If changes occur due to illumination variation, this method considers changes occurring due to object movement. Hence, this method can not work correctly in such a situation. On the other hand, for breaking camouflage, Huimin et al. [24] developed a computational model of visual moving image filtering in which Reichardt's elementary motion detectors [32] are employed for detecting motion information. As this method relies on motion (due to object movement) information, motion due to other conditions like illumination variation, environmental condition changes, etc. produces more false alarms. All these techniques mentioned above are context-dependent and may not work well for various types of camouflaged objects.

(p3.1) In [14], Yin et al. developed an algorithm to track a mobile object with a camouflage color based on the optical flow model. Here, the optical flow model is used to detect motion patterns of the object and the background. The motion patterns are clustered and detect the camouflaged object based on the optical flow's magnitude and location. After that, the Kalman filter is used to improve the detection accuracy. However, the accuracy of this model depends on the results of the optical flow. For slow-moving objects and objects with camera motion, this method fails to provide excellent results.

(p3.2) Discussion: motion plays a vital role in detecting camouflaged objects in the literature. Motion features help to detect camouflaged objects while camouflage occurs due to color/texture similarity with the background. However, motion features also fail to detect a camouflaged object with prolonged movement or stop/go motion.
## (s4) Texture Features
(p4.0) Sometimes, the object's color is similar to the background, but they have different texture patterns. The texture is considered to discriminate against the object from its surrounding. Galun et al. [11] developed a technique to detect camouflaged objects using a bottom-up aggregation framework that combines structural characteristics of texture elements with filter responses. It adaptively identifies the shape of texture elements and characterizes them by their size, aspect ratio, orientation, brightness, etc. Then various statistical measures of these properties are taken into account to distinguish between different textures. The said approach is applied to images containing various kinds of textures. This method works well for images containing different textures for objects and backgrounds. However, if the object and background contain a similar texture, this technique may fail to produce good results. In [3], Nagabhushan and Bhajantri proposed a technique for multiple camouflage breaking using co-occurrence matrix [33] and Canny edge detector [7]. The co-occurrence matrix is used to analyze the given image's texture, whereas the Canny edge detector is considered to detect the edges. A combination of both co-occurrence matrix and the Canny edge detector enhances the separability between objects containing different textures. Though this method provides good results for synthetic images, it is not applied to real-life data. Also, background information needs to be known before executing this method.

(p4.1) Neider and Zelinsky discussed in [29] the detection of camouflaged targets by looking through the distracters or by scrutinizing the target-similar background. In [3], Bhajantri and Nagabhushan proposed a technique to detect the camouflaged defect. Here, co-occurrence matrix-based texture features are computed within a small image region. The defective portion is detected by cluster analysis and watershed segmentation. The accuracy of this method depends on the texture feature. It may not work well for sequences where objects and background contain similar kind of texture. Sengottuvelan et al. [34] developed a technique to detect the camouflaged portion of the object and extract it from the environment in a given image. Here, the grey level co-occurrence matrix (glcm) based texture feature and dendrogram are used to detect the camouflaged object. This technique is very timeconsuming due to the given image's division into several blocks or smaller regions. It does not work for images containing shading effects and object & background containing similar textures.

(p4.2) Liming and Weidong [21] proposed a technique based on weighted structural similarity (wssim) to design and evaluate camouflage texture. Here they used weighted structural similarity and original image feature to create a camouflage image. It can be used for breaking the camouflage. In [30], Owens et al. introduced several background matching algorithms that attempt to make the object look like whatever is behind it. It is impossible to match the background from every possible viewpoint exactly. But the proposed models are forced to make trade-offs between different perceptual factors, such as conspicuousness of occlusion boundaries and the amount of texture distortion.
## (s5) Gradient Features
(p5.0) When the object has a similar color, texture as the background, it is challenging to detect objects using these features. For those sequences, gradient information is useful to extract the object from the background region. In this direction, various methods have been developed to detect the camouflaged object. In [31,[37][38][39][40][41], Tankus and Yeshurum proposed a Darg operator (context-free) to enhance an area whose shading corresponds to a convex (or concave) 3D object to separate such area from a flat background having similar features (like color and texture). Darg is applied directly to the grey-level function of the image. It responds to smooth three-dimensional convex or concave patches in objects and is not limited by any particular light source or reflectance function. Results obtained using the Darg operator are highly dependent on threshold values. The selection of a suitable threshold is a major issue. Further, this method does not work well for an environment containing concave background and dark-colored objects.
## (s6) Combination of Various Features
(p6.0) Camouflage occurs when the visual characteristics of the objects are too similar to the background. The objective of a camouflage detection system is to separate the camouflaged object from the background. In such cases, features generated from single-cue (like color or texture or shape or motion) is not sufficient to extract camouflaged objects from the background because the underlying phenomenon for the occurrence of camouflage is not known. In this context, the integration of features generated from multi-cue (color, texture, shape, motion, etc.) may increase the separability between the camouflaged objects and background. Various algorithms have been proposed based on integrating different features like color, texture, motion, shape, etc.

(p6.1) In this direction, to detect camouflaged objects, Harville et al. [13] proposed a foreground segmentation technique using both color and depth information. Information loss occurs due to a 3D scene's projection into a 2D picture. Here, depth information is considered to reduce the information loss due to 3D to 2D projection. The use of depth information increases detection accuracy and also increases the computational cost. In [17], Pong and Bowdenb proposed the use of the stochastic process to handle camouflage. This algorithm assumes that camouflage occurs when the new observation can not be associated with an existing task. The performance of this method depends on the color and motion of the object. Here, color is used to distinguish the camouflaged object and its surrounding, whereas motion is considered to separate out moving objects and the static part of the frame. Hence, both this information helps to detect moving camouflaged objects. Sometimes, this method may fail for an object, which is very similar to the background, and it contains more static objects. In [6], Brady and Kersten proposed a computational approach to combine low-level features with high-level models to detect and recognize an object when camouflage is present. Here, bootstrapped learning is considered to build the shape of the object, and it depends on the result of object detection. If object detection is not perfect, then recognition may not always be correct, and it fails to track correctly. Furthermore, in [23], Losa et al. proposed a particle filter based on structural similarity measure for tracking camouflaged objects. Here, the structural similarity measure reflects the distance between two frames by comparing their luminance, contrast, and spatial characteristics. Here, the used measure is sensitive to relative rather than absolute changes in the frame. However, this technique may not be robust to significant alteration of the tracked object. However, Jiang [16] proposed a model to track the object in a video sequence by locating a list of object features that are ranked according to their ability to differentiate against the background. Here, a mixture of color, texture, and object motion is considered multidimensional to represent the object. Multi-features representation increases the separability between the objects and their surrounding. Experimental results show that this model works well for detecting the camouflaged object.

(p6.2) Recently, Mondal et al. developed a camouflaged object tracking algorithm using a probabilistic neural network and fuzzy energy-based active contour [28]. Here, multi-features like color, texture, and shape are integrated to increase the discrimination between camouflaged objects and their background. The camouflaged object is detected by modifying the probabilistic neural network, and finally, it is tracked by the proposed fuzzy energy-based active contour model. The experiments showed that this method could provide good tracking results under a camouflaged environment.

(p6.3) Discussion: Color features work while camouflage occurs due to texture similarity with the background. Texture features are effective, while camouflage occurs due to color similarity. The motion of the camouflaged object can detect it while the object with good motion. These features, e.g., color, texture, and motion, can detect the camouflaged object in a specific environment. A combination of various features, e.g., color, texture, motion, etc. effectively work without constraints.
## (s7) Deep Features
(p7.0) As the color of the camouflaged object is similar to the background, detection of it is challenging. In [19], the authors considered the image enhancement technique to increase the discrimination between object and background. The region proposal network (rpn) is considered to estimate the required target's accurate positioning. The deep neural network is used to identify extracted RoI. Finally, the detection of a camouflaged object is done. In this direction, Fang et al. [47] proposed strong semantic dilation network to detect camouflaged people. The authors claimed that full use of semantic information in convolutional neural networks and dilated convolutions are also added to enlarge the receptive field to find camouflage people. The authors presented impressive results on a standard dataset.

(p7.1) Discussion: All the features, e.g., color, texture, motion, and gradient, are handcrafted and may not use for all types of camouflaged objects. On the contrary, the in-depth feature is learned by the network from the extensive training images. The deep feature is more generic than the hand-crafted features. It works better than hand-crafted features.
## (s8) Other Techniques
(p8.0) Some other approaches that exist in the literature are discussed in this section. Marouani et al. [26] developed aircraft recognition technique in the presence of camouflage. It works on low-level matching between segments of the projection of a 3D model of the objects of interest. In [36], Guilan and Shunqing discussed the use of spectral pattern recognition techniques to distinguish color camouflage from green vegetation background. Here, the considered spectral feature is the basic characteristic for recognizing the target. Experimentally, they concluded that the considered feature is optimum for recognition than other state-of-the-art features. However, it cannot provide good results for camouflaged objects in the background other than green vegetation.

(p8.1) Beiderman et al. [2] presented a novel approach where the secondary speckle pattern is monitored for a time, to extract the temporal/spectral signature of the objects. Special image processing algorithms allow obtaining a unique signature of the object region that can be used to classify, recognize, and identify objects. This approach can detect and recognize camouflaged objects.

(p8.2) Pan et al. [31] developed an algorithm to detect the camouflaged portion of the object in a complex background with the help of Darg operator. The main drawback of this method is the selection of proper threshold value. Liu and Huang [22] developed a novel foreground object detection scheme that integrates the topdown information based on the expectation-maximization (em) framework. Here, top-down information is incorporated into the object model in a generalized em framework. A foreground model is constructed based on the object model and the state of each target. The author concluded that the method is giving good results for detecting camouflaged objects. Recently, Malathi and Bhuyan [25] developed a background subtraction scheme to detect the camouflaged object. Here, pixels corresponding to the background are quantized into codebooks, sufficient to represent a background. Codebooks extracted for each of the cameras are combined to extract the foreground from the background. To detect the camouflaged target in complex background, Zhou and Cun-chao [43] proposed a novel spectralpolarimetric image fusion algorithm based on Shearlet transform. Kernel fuzzy c-means clustering algorithm is applied to a fused spectral-polarimetric image to separate camouflaged object from its background.

(p8.3) In [18], Kim proposed a fully autonomous feature selection and camouflaged object detection method based on the online analysis of spectral and spatial features for hyper-spectral images. Here, a statistical distance metric is considered to generate candidate feature bands, and entropy-based spatial grouping property is used to reduce useless feature bands. Camouflaged objects are detected by optical spectral-spatial feature analysis with less computational complexity. Mangale and Khambete [50] fused Thermal infrared and visible spectrum imaging modality to detect camouflaged objects. The authors presented impressive results. Li et al. [52] proposed a camouflaged object detection model in wavelet transformed feature space. In this method, the likelihood of each wavelet coefficient being foreground is estimated by formulating foreground and background models for each wavelet band. This method effectively aggregates the likelihoods from different wavelet bands based on the wavelet transforms' characteristics detects camouflaged objects.
