# TOWARDS IDENTIFYING AND MANAGING SOURCES OF UNCERTAINTY IN AI AND MACHINE LEARNING MODELS -AN OVERVIEW MICHAEL KLÄS UNCERTAINTY IN AI AND MACHINE LEARNING -AN OVERVIEW

CorpusID: 53858126 - [https://www.semanticscholar.org/paper/c47a41eb92f9c3f4455567b6ab3cec1d4aef36c8](https://www.semanticscholar.org/paper/c47a41eb92f9c3f4455567b6ab3cec1d4aef36c8)

Fields: Computer Science, Mathematics

## (s0) Motivation
(p0.0) Data-driven models (Solomatine & Ostfeld, 2008), (Solomatine, See, & Abrahart, 2009), such as those provided by the application of AI and machine learning, are becoming components of increasing importance for complex software-intensive systems.

(p0.1) In particular, embedded systems that collaborate in an open context need to process various kinds of sensor input to recognize and interpret their situation in order to handle changes in their environment and collaborate with previously unknown agents. Unlike traditionally engineered software components, which are developed by software engineers who define their functional behavior using code or models, the behavior of datadriven components is automatically generalized by algorithms from a given data sample. This whitepaper provides a brief motivation and first overview of the state of the art in identifying and quantifying sources of uncertainty for data-driven components as well as means for analyzing their impact.

LLM judge: YES

## (s3) Data Quality
(p3.0) In realistic settings, data is limited in its accuracy and potentially affected by various kinds of quality issues; therefore, datadriven models are not applied under optimal conditions. For example, the accuracy of a recognition model in identifying a specific object depends on a number of quality characteristics of the input image, such as resolution, light conditions, focus, etc. The delta between the level of uncertainty that can be explained by model fit and the actual level of uncertainty observed in a test situation can be attributed to data quality (Kläs & Vollmer, 2018). Distinguishing between uncertainty related to model fit and uncertainty related to data quality can therefore help to explain variation in the accuracy of the model outcomes within a test dataset and thus provide more specific uncertainty estimates for a concrete application.

LLM judge: YES

## (s6) Scope Compliance
(p6.0) Even if both model-fit-and data-quality-related uncertainty is managed, the outcome of a data-driven model can become unreliable due to the fact that the model is applied in a setting for which it was not intended.

(p6.1) Data-driven models are created with a specific application scope in mind. An application scope can be defined as a (potentially infinite) set of entities or events satisfying a set of common properties and can thus be considered as a statistical population.

(p6.2) In statistics, populations are usually characterized by temporal, spatial, and factual aspects. Using traffic sign recognition as an example, one possible application scope could be the set of all valid traffic signs erected in Germany as perceived by passenger cars in 2016.

(p6.3) Given a dataset that is representative for the intended application scope, the uncertainty in the model outcomes can be determined with a certain level of statistical confidence for this application scope. In real applications, however, test datasets are not always representative; for example, due to sample selection bias (which is a subcategory of dataset shift (Sugiyama, Lawrence, & Schwaighofer, 2009)), which falsifies the statistical results (Zadrozny, 2004).

LLM judge: YES

