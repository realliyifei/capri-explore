# Survey Instrument for Measuring Level of Preparedness amongst Healthcare Personnel in Radiation Emergency

CorpusID: 233642058
 
tags: #Medicine, #Environmental_Science

URL: [https://www.semanticscholar.org/paper/f51bd67a03f02307ff626458738a1ec52fe1b306](https://www.semanticscholar.org/paper/f51bd67a03f02307ff626458738a1ec52fe1b306)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | False |
| By Annotator      | (Not Annotated) |

---

Survey Instrument for Measuring Level of Preparedness amongst Healthcare Personnel in Radiation Emergency
2021

Siti Hasliah Salleh 
Perdana Centre
Razak Faculty of Technology and Informatics
Universiti Teknologi Malaysia Kuala Lumpur
Jalan Sultan Yahya Petra
54100Kuala LumpurMalaysia

Nor Ashikin 
Mohamed Yusof 
Perdana Centre
Razak Faculty of Technology and Informatics
Universiti Teknologi Malaysia Kuala Lumpur
Jalan Sultan Yahya Petra
54100Kuala LumpurMalaysia

Fadillah Ismail 
Faculty of Technology Management and Business
Universiti Tun Hussein Onn Malaysia
86400Parit Raja, Batu Pahat, JohorMalaysia

Survey Instrument for Measuring Level of Preparedness amongst Healthcare Personnel in Radiation Emergency

Journal of Advanced Research in Social and Behavioural Sciences Journal homepage
22202110.37934/arsbs.22.1.1120Received: 14 May 2020 Revised: 17 January 2021 Accepted: 18 January 202111Disaster preparednesscontent validitykappa analysisreadinesswillingnessability
Drills and exercises are globally practiced to investigate the level of preparedness towards disaster events. However, these activities are rarely conducted because they require substantial investment, specifically to budget and time. A self-reported survey may serve as an alternative approach, although it may not be as effective as drills and exercises. As part of the survey development process, this article discusses preliminary validation of a survey instrument to measure the level of preparedness towards radiation emergency amongst healthcare personnel. Prior to this validation process, extensive literature reviews pointed out that the instrument consists of three constructs of preparedness, namely readiness, willingness, and ability. A total of seven subject matter experts were invited to judge the contents for verification purposes. Randolph Kappa analysis was then conducted to analyse their judgment to allow irrelevant items to be filtered from the rest prior to any improvements. Initially, the survey instrument consisted of 69 items; however, the analysis omitted 16 of them. The following values for each preparedness construct were: Readiness (0.77), Willingness (0.70), and Ability (0.73). These findings indicate that contents of the instrument are valid. Further analysis should be fulfilled to complete validation process to ensure its practicality prior to using it as an evaluation tool.

## Introduction

In Malaysia, drills and exercises are recognized as important mechanisms in measuring the preparation of agencies towards disaster. It has been highlighted in the Document No. 20: Policy and Mechanism on National Disaster Management (hereinafter is referred to as the Document No. 20) [1], which generally contains systematic coordination among the agencies involved in disaster response, and various relief and rehabilitation activities. The implementation of these activities is expected to allow the players such as Emergency Medical Services (hereinafter is referred to as the EMS) to provide response as planned. The responder, or the team of responders is deemed capable of discharging his duties in any real disaster if they perform well the drill and exercise [2]. On another note, the drill and exercise can also identify and highlight any weaknesses in the contents or implementation of the response plan for future improvement [3].

However, it has been argued that the existing drill and exercise may not be accurate [4][5][6] considering that most of the exercises are conducted with an advanced warning. Specifically, the participants are selected to prepare themselves for the exercise, while the equipment and facilities are excellently organised in advance. Hence, it is expected that these advance preparations will bring about a perfect exercise which leads to a limited number of deficiencies that can be identified. In this case, the result is essentially biased even though having a zero-weakness exercise is such an expectancy. Therefore, the drills and exercises are believed to cause unpreparedness to the hospital. On the other hand, a drill or exercise can become a failure if the activity is fully successful or totally founder [1]. In other words, the activity in a total failure drill or exercise will demoralise the participants.

In considering the above weaknesses, a self-reported survey may serve as an alternative approach but not outweigh the benefits of drills and exercises. Besides providing information on current level of preparedness, this approach is also able to assist the management in identifying the suitable training programs, followed by specifically designing or modifying the training contents in accordance to the individual's inadequacies, capabilities, or specific needs. This self-reported survey instrument however will only be useful if the instrument is valid [4].

Therefore, this study aimed to validate a self-developed survey instrument for measuring the level of preparedness among healthcare personnel towards radiation emergencies. It focuses on the content validation, which is one of the crucial approaches in the instrument validation process. The outcome of this writing may have important contribution to the body of knowledge in general, especially in developing a valid self-reported measurement instrument. It is also valuable to the stakeholders as an alternative approach in measuring the level of preparedness towards disaster.


## Scale Development

Test content involves evaluating the relationship between test's content and the construct intended to measure [4][5][6]. This process should be firstly conducted before testing the instrument with samples of target population [4]. Zamanzadeh et al., [7] states that panel of experts are the relevant individuals who will carry the responsibility. It is recommended to have at least three, but not more than ten experts to review the contents [7].

There were two methods that typically used to quantify experts' degree of agreement regarding the content relevance of an instrument, as such: (1) proportion agreement such as Content Validity Index; and (2) multi-rater kappa coefficient of agreement [8]. For Content Validity Index, the rating scale should use four-point Likert scale including '1 = not relevant', '2 = somewhat relevant', '3 = quite relevant' and '4 = very relevant' [7,8]. Percentage of agreement is calculated by collapsing the scale into two groups. In specific, item that ranked 1 or 2 is considered as 'content invalid', while ratings of 3 and 4 are considered to be "content valid" [7,8].

Based on these two new categories rating scale, percentage of agreement for individual items, as well as grouped items according to construct is calculated. However, scholars such as [13] cautioned about the method of proportion agreement. They believed the method of collapsing rating scale could create potential inflation of agreement due to chance. The judgment made may also cause loss of important information when the original ordinal scale is no longer available [9]. Due to these limitations, they alternatively proposed multi-rater kappa coefficient of agreement [8].

Historically, Harpe [9] introduced measurement of agreement between two raters thus called inter-rater kappa. It is then enhanced to cater the needs of rating between more than two raters. In reducing deficiency of CVI approach, the inter-rater kappa was enhanced with the intention to measure agreement between more than three raters [8]. The Kappa values ranged from +1.00 to -1.00, where value of +1.00 reveals complete agreement across raters and value of -1.00 reveals otherwise [8].

The positive value indicates multi-rater agreement occurring more frequently than expected by chance; the negative value indicates otherwise [8]. There are essentially several rules of thumb for minimum acceptable Kappa value, however 0.60 was recommended by many researchers [8]. Based on their judgments, instrument is usually revised because of item modification, addition, and exclusion [4].

Besides that, item content can be tested quantitatively using Rasch measurement model [10] specifically to hierarchical ordering of scale items. By using the hierarchical order, items and persons are placed on the same hierarchical map according to their relative difficulty level for agreement and performance level respectively [10]. Therefore, gaps in the representativeness of the content may indicate insufficient test items to enable subjects of that particular level to adequately display their performance [10].


## Methodology


## Design and Sample

The purpose of the scale is to measure the level of preparedness of EMS personnel in facing radiation emergency. Hence, the current research adopted a quantitative approach to validate the contents. Particularly, the instrument employed by the present study was sent to seven experts from various backgrounds. The first expert was an emergency physician consultant and disaster medicine specialist. The second expert was an academic specialized in disaster preparedness. The third expert was an academic specialized in measurement and evaluation. The remaining four experts were academics practiced in the emergency department.

The researcher sent the instrument validation form to the experts in two versions. The first was the printed version which was sent by hand, while the second was the softcopy which was sent through email. Accordingly, the experts marked their preferences of items validity based on 3-point Likert scale represented as (1) irrelevant, (2) moderate but require amendment, and (3) relevant. Principally, the present study omitted items that were marked as irrelevant by at least 50% of the experts, whereas items with moderate value were deemed acceptable but subjected to modification. The experts were given an ample time to respond within two weeks. All experts returned the forms after obtaining the first reminder from the researcher.

In the case of the current research, the common content analysis known as Fleiss' multi-rater kappa was employed because it involved more than two experts [11][12][13]. Nevertheless, it should be noted that this approach has a limitation because it is only appropriate for fix-marginal validity studies in which the raters are well informed about the number of items that should be distributed into each construct [11,13]. As a result, Randolph Kappa analysis was recommended because it was more appropriate for the present study [11].

In other words, Randolph Kappa was considered to be more appropriate and advantageous compared to Fleiss Kappa because the present study did not fix the number of items that should be included but still able to fulfil the minimum requirement to measure a construct. According to the rule of thumb, constructs with Kappa value higher than 0.70 indicate that the contents are valid, whereas a construct with lower value suggests that the contents are inappropriate to measure the construct [11,13]. In the case of this study, the calculation was manually performed using Randolph Kappa equation [11] on Microsoft Office Excel 2016.

Next, the feedbacks from subject matter experts were then re-assessed for verification purposes. Accordingly, the moderated draft instrument was re-sent to the experts for reconfirmation once the modification was completed. Moreover, a considerable amount of communications and discussions took place at this stage between different parties. For example, several discussions were carried out on the objective of items, choices of terminologies, and the construction of sentences. The modifications were necessary for response to the fear that the respondents may be unfamiliar with some technical terms as well as the possibility of having different interpretations or understanding on certain terminologies, which may consequently affect their answers and data input of the research. Moreover, the two ways communications were continued until everyone was satisfied. Accordingly, the experts returned the draft of the RWA scale together with written comments. More importantly, the inputs provided by the experts were dully considered and adopted as part of the process in strengthening the RWA scale whenever applicable.


## Construct of Preparedness

The current research adapted the RWA framework developed by Khan et al., [14]. Historically, the establishment of the framework was for the purpose of enhancing the preparedness amongst individual or organisation as a response towards possible catastrophes and public health emergencies [14]. However, the discussion of the conceptual framework only focuses on three constructs, namely Ready, Willing, and Able but merely stating their itemised details. Therefore, this has motivated the current research to extend the framework with more itemised details.

In Malaysia context, these constructs are actually considered by the EMS and even all other categories of responders. For instance, [15] studied about healthcare providers' readiness to provide disaster response in Malaysia, [16] studied all three constructs amongst medical doctors' disaster preparedness in Terengganu, and Aniza et al., [17] studied ability of emergency nurses and community health nurses in disaster management. Accordingly, the following subsections will discuss related components of RWA namely readiness, willingness and ability to provide response. Readiness is described as the support received by healthcare personnel, particularly in the form of opportunities that enable them to perform well in emergency medical response operation [14,18]. In this case, opportunity refers to environmental factors that influence his performance which is beyond the direct control of the personnel. In addition, it should be noted that a number of factors are able to fundamentally influence individual's readiness in discharging one's duties which include the influence from the organisation, department, individual, and family [19][20][21].

Next, willingness is defined as the tendency of healthcare personnel to enthusiastically participate in emergency medical response operation [22,23]. In the context of the present study, willingness is reflected by the anxiety of personnel towards radiation emergency. In other words, the willingness of personnel to provide a response and render assistance in a disaster is essentially dependent on his personal perceptions on the risk associated with radiation emergency as well as the capability to react in the emergency [21].

The final construct is known as ability which refers to the physiological and cognitive capabilities of healthcare personnel to competently perform certain tasks that come with specific requirements [14,20,22]. In the case of Malaysia, a report published on public health preparedness and response competency model developed by Centers for Disease Control and Prevention states that healthcare personnel must have four spheres of competency which include leadership, communication and management of information, planning, and protection on safety and health [23]. Table 1 shows the frequency of judgment for construct Ready which initially consists of 22 items. More than three experts rated six items represented as number 12,13,14,19,20, and 21 as irrelevant, thus causing them to be immediately removed. The calculation was conducted based on Randolph Kappa analysis which presents the value of 0.77 for the remaining 16 items. Theoretically, the given value was considered good which further indicates the validity of the contents in measuring the readiness to handle radiation emergency. Other than that, the experts preferred for all negative toned sentences and words to sound more positive. For example, item number 6 originally appeared as "'the ED / ERT of my hospital does not have a specific SOP in handling radiation emergency victims". However, the amendment caused the item statement to appear as 'the ED / ERT of my hospital have a specific SOP in handling radiation emergency victims'. Meanwhile, four experts agreed that items number 17, 18, and 20 presented in Table 1 are unable to indicate how readiness influences preparedness. For instance, items number 17 and 22 were respectively written as 'My family members always interrupt me while I am at work' and 'The safety of my dependents at home is assured'. According to the experts, poor choices of words have downplayed the elements of readiness in these sentences. As a result, item number 17 was improved to appear as 'My family members allow me to provide a response in radiation emergency', while item number 22 was amended into 'My dependents could survive without me, in case I am out of town for three days'. Table 2 presents the frequency of judgment for the construct Willing. As a whole, the experts agreed to drop item number 6 due to its low value. Nonetheless, items number 1, 11, and 15 were maintained because only one expert found them irrelevant. Hence, a total of 15 items were calculated and managed to obtain Randolph Kappa value of 0.70 which indicate the sufficiency to measure their willingness towards preparedness. Generally, all experts agreed with the definition of "Willingness". However, some of the item statements were found to be unclear. In this case, the statements were not clearly written even though the words indicating the willingness to provide response were already included. Hence, such weakness may weaken the assessment of willingness and eventually lead to ineffective results. Regarding this matter, the experts suggested that several items of construct Willing must be paraphrased to achieve better clarity and understanding. A clear explanation for this was that they failed to see how some item statements are able to reflect or be linked to willingness; for example, the relationship between the terminology "complimentary treatment" and the objective of item number 15. Specifically, item number 15 originally appeared as 'I will be given complimentary treatment if I fall sick due to working in radiation emergency". In this case, the lack of better words or poor construction of sentences has downplayed the real intention of the statements even though the term "complimentary treatment" served as a motivation for the EMS team members to render their services during a radiation emergency. The item sentences appeared as 'the availability of complimentary treatment if I fall sick makes me more willing to respond to radiation emergency' after being paraphrased. Table 3 describes the findings of the construct Able. In this case, the items manage to obtain a value of 0.73 from the Randolph Kappa analysis. As can be observed, nine items represented as number 4, 5, 6, 8, 12, 13, 15, 17, and 20 receive at least three negative responses which led to their omission because the experts equally found them to be irrelevant in measuring "Able". Meanwhile, items number 10, 24 and 25 were retained because only one expert rated them as irrelevant. Other than that, 19 other items were considered moderate, still relevant, and conclusively adequate to measure the ability towards preparedness. 2. Victims exposed to radiation level of 10 rem (100mSv) and above are not required to undergo blood examination.  Nevertheless, four experts considered several items of Able construct as very general which may cause confusion amongst respondents and eventually pose several issues in measuring specific action of a radiation emergency. In this case, one expert referred to item number 2 that initially appeared as 'Victims exposed to a radiation level of 10 rem (100mSv) and above is not required to undergo blood examination' as an example of generality for the lack of specific range of radiation level. Hence, the experts recommended that the items should have the exact value of the range of radiation. Consequently, item number 2 was written as 'Victims exposed to a radiation level of 1,500 mSv are required to undergo blood examination'. Meanwhile, item number 29 was written as 'Pediatric victims should be assisted to take a bath for the purpose of radiation decontamination', and in this case, the experts suggested that the item statements should specify the individual that is responsible to assist pediatric victims in bathing. As a result, the item statement appeared as 'Pediatric victims should be assisted by the caretaker to take a bath for the purpose of radiation decontamination'.


## Results and Discussion


## Ready


## Willing


## Able


## Conclusions

Generally, it is imperative for any research instrument to go through content validity test and the present study successfully satisfied it through Kappa Analysis. The RWA scale has a minimum Kappa value of 0.70 for the item to be considered valid. Specifically, the scale covered threedimensional aspects of preparedness, namely psychological, physical, and surrounding environment which are respectively represented in the construct as Ready, Willing, and, Able. More importantly, the scale was developed and designed to measure the level of preparedness amongst EMS in ensuring that the items can be modified to cater or reflect the specific needs according to their circumstances.

## Fig. 1 .
1RWA framework for EMS preparedness towards radiation emergency

## 7


## Table 1
1Frequency of judgment by experts on 'ready' construct Item Frequency Not relevant Moderate Relevant 1. My hospital has a specific plan in handling radiation emergency victims. 7 2. My hospital notifies the staff to prepare for handling radiation emergency victims at all times.1 
6 



## Table 2
2Frequency of judgment by experts on 'willing' constructItem 
Frequency 
Not relevant Moderate Relevant 
1. Handling radiation emergency victims is one of my prioritized 
tasks. 

1 
1 
5 

2. I am willing to handle radiation emergency victims. 
1 
6 
3. I always avoid handling victims in rare emergency cases. 
7 
4. I will volunteer myself to work in radiation emergency response 
operations. 

1 
6 

5. I am willing to sacrifice my time off if I am asked to report for 
duty. 

1 
6 

7. I am not confident to provide response in a radiation emergency 
operation. 

7 

8. Handling radiation emergency victims could cause cancer for me. 
7 
9. I am worried that handling radiation emergency victims could 
jeopardize my family's health. 

7 

10. The risk of handling radiation emergency victims could not be 
minimized even if I comply with the established SOP. 


## Table 3
3Frequency of judgment by experts on 'able' construct Item Frequency Not relevant Moderate Relevant 1. All radiation emergency victims can be treated as general emergency patients.1 
6 



## 3 .
3Prompt treatments are supposed to be provided to patients who are internally contaminated by radiation. 7 7. My performance is affected if my colleagues are not focused in performing their tasks. 10. I panic when dealing with rare emergency cases. 1 6 11. I respect patients with different religions and races. 7 14. I depend on patients' data to deliver valid information. 1 6 16. I am aware of my colleagues' area of duty. 1 6 18. I have been delivering wrong information about patients. 1 6 19. I deliver information that is easily understood by colleagues. 1 6 21. If given a chance, I want to participate in planning a radiation emergency response operation. 22. I don't have time to attend training related to radiation emergency response. I have to wear all of the PPEs (glove, head cover, goggle, mask, gown, apron, shoe cover) before handling any radiation emergency victims. 31. I have to report to the person in charge if there are colleagues getting ill after handling radiation emergency victims.7 

9. Working in teams could accelerate treatment process. 
1 
6 
1 
6 

1 
6 

23. I have adequate knowledge about radiation emergency 
response operation. 

7 

24. I perform my task according to the department's plan. 
1 
6 
25. 1 
6 

26. I have to ensure no radioactive material contaminated my 
body/clothes after handling contaminated victims. 

7 

27. Decontamination process for victims with radiation 
contamination should be conducted in isolated areas. 

7 

28. Victims with radiation contamination should be 
decontaminated first, even though their health condition is critical. 

1 
6 

29. Pediatric victims should be assisted to take a bath for the 
purpose of radiation decontamination. 

1 
6 

30. Contaminated gloves can be removed together with the 
uncontaminated gloves. 

1 
6 

1 
6 


AcknowledgementThis article is part findings of PhD research project funded by Ministry of Higher Education under the MyBrain15 sponsorship.
National Security Council Directive No. 20: the policy and mechanism on national disaster and relief management (amd. 2012). Prime Minister Department. MalaysiaNational Security CouncilNational Security Council. National Security Council Directive No. 20: the policy and mechanism on national disaster and relief management (amd. 2012). Prime Minister Department, Malaysia; 2012.

Disaster nursing and emergency preparedness. T G Veenema, Springer Publishing CompanyVeenema TG. Disaster nursing and emergency preparedness. Springer Publishing Company; 2018

What is the value of health emergency preparedness exercises? A scoping review study. Elena Skryabina, Gabriel Reedy, Richard Amlot, Peter Jaye, Paul Riley, 10.1016/j.ijdrr.2016.12.010International journal of disaster risk reduction. 21Skryabina, Elena, Gabriel Reedy, Richard Amlot, Peter Jaye, and Paul Riley. "What is the value of health emergency preparedness exercises? A scoping review study." International journal of disaster risk reduction 21 (2017): 274- 283. https://doi.org/10.1016/j.ijdrr.2016.12.010.

Evaluation of hospital preparedness for public health emergencies in Sichuan (China). Rong Tang, Queensland University of TechnologyPhD dissTang, Rong. "Evaluation of hospital preparedness for public health emergencies in Sichuan (China)." PhD diss., Queensland University of Technology, 2015.

Reliability and Validity of Measurement. I.-C A Chiang, R S Jhangiani, P C Price, BCcampusChiang, I.-C. A., Jhangiani, R. S., & Price, P. C. Reliability and Validity of Measurement. (2015). BCcampus.

Content Validity Index and Intra-and Inter-Rater Reliability of a New Muscle Strength/Endurance Test Battery for Swedish Soldiers. Larsson, PloS one. 107Larsson et al. Content Validity Index and Intra-and Inter-Rater Reliability of a New Muscle Strength/Endurance Test Battery for Swedish Soldiers." PloS one 2015;10:7.

. 10.1371/journal.pone.0132185https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4503674/. https://doi.org/10.1371/journal.pone.0132185.

Design and implementation content validity study: development of an instrument for measuring patient-centered communication. Vahid Zamanzadeh, Akram Ghahramanian, Maryam Rassouli, Abbas Abbaszadeh, Hamid Alavi-Majd, Ali-Reza Nikanfar, 10.15171/jcs.2015.017Journal of caring sciences. 42165Zamanzadeh, Vahid, Akram Ghahramanian, Maryam Rassouli, Abbas Abbaszadeh, Hamid Alavi-Majd, and Ali-Reza Nikanfar. "Design and implementation content validity study: development of an instrument for measuring patient-centered communication." Journal of caring sciences 4, no. 2 (2015): 165. https://doi.org/10.15171/jcs.2015.017.

Evaluating the face and content validity of a Teaching and Learning Guiding Principles Instrument (TLGPI): A perspective study of Malaysian teacher educators. Azwani Masuwai, Noor Shah Masuwai, Saad, Geografia-Malaysian Journal of Society and Space. 123Masuwai, Azwani Masuwai, and Noor Shah Saad. "Evaluating the face and content validity of a Teaching and Learning Guiding Principles Instrument (TLGPI): A perspective study of Malaysian teacher educators." Geografia- Malaysian Journal of Society and Space 12, no. 3 (2017).

How to analyze Likert and other rating scale data. Spencer E Harpe, 10.1016/j.cptl.2015.08.001Currents in pharmacy teaching and learning. 7Harpe, Spencer E. "How to analyze Likert and other rating scale data." Currents in pharmacy teaching and learning 7, no. 6 (2015): 836-850. https://doi.org/10.1016/j.cptl.2015.08.001.

An examination of the structural validity of the Physical Self-Description Questionnaire-Short Form (PSDQ-S) using the Rasch Measurement Model. Ted Brown, Tore Bonsaksen, Sammy King Fai Hui, 10.1080/2331186X.2019.1571146Cogent Education. 611571146Brown, Ted, Tore Bonsaksen, and Sammy King Fai Hui. "An examination of the structural validity of the Physical Self-Description Questionnaire-Short Form (PSDQ-S) using the Rasch Measurement Model." Cogent Education 6, no. 1 (2019): 1571146. https://doi.org/10.1080/2331186X.2019.1571146.

Measurement of Learning and Performance in Football. 10.3390/ijerph17134629Int. J. Environ. Res. Public Health. 174629Measurement of Learning and Performance in Football. Int. J. Environ. Res. Public Health 2020;17: 4629. https://doi.org/10.3390/ijerph17134629.

Kappa coefficient: a popular measure of rater agreement. T A N G Wan, H U Jun, W U Pan, Zhang Hui, H E Hua, Shanghai archives of psychiatry. 2762Wan, T. A. N. G., H. U. Jun, Pan WU Hui ZHANG, and H. E. Hua. "Kappa coefficient: a popular measure of rater agreement." Shanghai archives of psychiatry 27, no. 1 (2015): 62.

Testing inter-rater reliability in rubrics for large scale undergraduate independent projects. A Chong, L Romkey, Proceedings of the Canadian Engineering Education Association (CEEA). the Canadian Engineering Education Association (CEEA)Chong A, Romkey L. Testing inter-rater reliability in rubrics for large scale undergraduate independent projects. Proceedings of the Canadian Engineering Education Association (CEEA).

. 10.24908/pceea.v0i0.6465https://doi.org/10.24908/pceea.v0i0.6465.

Public health emergency preparedness: a framework to promote resilience. Yasmin Khan, O&apos; Tracey, Adalsteinn Sullivan, Shannon Brown, Jennifer Tracey, Mélissa Gibson, Bonnie Généreux, Brian Henry, Schwartz, 10.1186/s12889-018-6250-7BMC public health. 181Khan, Yasmin, Tracey O'Sullivan, Adalsteinn Brown, Shannon Tracey, Jennifer Gibson, Mélissa Généreux, Bonnie Henry, and Brian Schwartz. "Public health emergency preparedness: a framework to promote resilience." BMC public health 18, no. 1 (2018): 1-16. https://doi.org/10.1186/s12889-018-6250-7.

Health emergency and disaster preparedness in Malaysia. Harpal Singh, Shamala Subramaniam, Southeast Asian journal of tropical medicine and public health. 4011Singh, Harpal, and Shamala Subramaniam. "Health emergency and disaster preparedness in Malaysia." Southeast Asian journal of tropical medicine and public health 40 (2009): 11.

A survey on knowledge, attitude & confidence level of disaster management among doctors in Terengganu. Muhamad Mustafa, Sukri, Universiti Sains MalaysiaPhD dissMustafa, Muhamad Sukri. "A survey on knowledge, attitude & confidence level of disaster management among doctors in Terengganu." PhD diss., Universiti Sains Malaysia, 2015.

Disaster Management: Identifying Knowledge of Emergency Nurses and Community Health Nurses and its Predictors in Malaysia. Aniza Ismail, Hasanain Faisal Ghazi, M S Ismail, A Nurul&apos;ain, Malaysian Journal of Public Health Medicine. 163Ismail, Aniza, Hasanain Faisal Ghazi, M. S. Ismail, and A. Nurul'Ain. "Disaster Management: Identifying Knowledge of Emergency Nurses and Community Health Nurses and its Predictors in Malaysia." Malaysian Journal of Public Health Medicine 16, no. 3 (2016): 66-74.

Chronic Disease After Natural Disasters: Public Health, Policy, and Provider Perspectives. Suneja, Thomas E Amit, Jeffrey Chandler, Michael Schlegelmilch, Irwin E May, Redlener, Suneja, Amit, Thomas E. Chandler, Jeffrey Schlegelmilch, Michael May, and Irwin E. Redlener. "Chronic Disease After Natural Disasters: Public Health, Policy, and Provider Perspectives." (2018).

Nurses' readiness for emergencies and public health challenges-the case of Saudi Arabia. Mohammed Ali Sultan, Amir Salem, Eric Khorram-Manesh, Jarle Carlström, Hadi Jaber Al Løwe Sørensen, Fabian Sulayyim, Taube, 10.3390/su12197874Sustainability. 12197874Sultan, Mohammed Ali Salem, Amir Khorram-Manesh, Eric Carlström, Jarle Løwe Sørensen, Hadi Jaber Al Sulayyim, and Fabian Taube. "Nurses' readiness for emergencies and public health challenges-the case of Saudi Arabia." Sustainability 12, no. 19 (2020): 7874. https://doi.org/10.3390/su12197874.

Emergency Healthcare Providers' Perceptions of Preparedness and Willingness to Work during Disasters and Public Health Emergencies. Mohammed Ali Sultan, Jarle Salem, Eric Løwe Sørensen, Luc Carlström, Amir Mortelmans, Khorram-Manesh, 10.3390/healthcare8040442In Healthcare. 84442Multidisciplinary Digital Publishing InstituteSultan, Mohammed Ali Salem, Jarle Løwe Sørensen, Eric Carlström, Luc Mortelmans, and Amir Khorram-Manesh. "Emergency Healthcare Providers' Perceptions of Preparedness and Willingness to Work during Disasters and Public Health Emergencies." In Healthcare, vol. 8, no. 4, p. 442. Multidisciplinary Digital Publishing Institute, 2020. https://doi.org/10.3390/healthcare8040442.

Towards a comprehensive public health response to population ageing. Hon Beard, R Prof John, David E Bloom, 10.1016/S0140-6736(14Lancet. 3859968Beard, Hon Prof John R., and David E. Bloom. "Towards a comprehensive public health response to population ageing." Lancet (London, England) 385, no. 9968 (2015): 658. https://doi.org/10.1016/S0140-6736(14)61461-6.

Developing tools to promote culturally competent compassion, courage, and intercultural communication in healthcare. Irena Papadopoulos, Sue Shea, Georgina Taylor, Alfonso Pezzella, Laura Foley, 10.1186/s40639-016-0019-6Journal of Compassionate Health Care. 31Papadopoulos, Irena, Sue Shea, Georgina Taylor, Alfonso Pezzella, and Laura Foley. "Developing tools to promote culturally competent compassion, courage, and intercultural communication in healthcare." Journal of Compassionate Health Care 3, no. 1 (2016): 1-10. https://doi.org/10.1186/s40639-016-0019-6.

Healthcare leadership styles, competencies and affinity for technology in the digital era. Zahra Ghafari, Ghafari, Zahra. "Healthcare leadership styles, competencies and affinity for technology in the digital era." (2019).