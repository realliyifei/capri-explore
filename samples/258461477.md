# Revolutionizing Agrifood Systems with Artificial Intelligence: A Survey

CorpusID: 258461477
 
tags: #Engineering, #Agricultural_And_Food_Sciences, #Computer_Science

URL: [https://www.semanticscholar.org/paper/44b7981a24787d87a713c5dc1467282a5b08d97c](https://www.semanticscholar.org/paper/44b7981a24787d87a713c5dc1467282a5b08d97c)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | True |
| By Annotator      | (Not Annotated) |

---

Revolutionizing Agrifood Systems with Artificial Intelligence: A Survey


Tao Chen 
Liang Lv 
Yue Yang 
Zeyang Zhao 
Chen Wang 
Xiaowei Guo 
Hao Chen 
Qingye Wang 
China 
Yufei Xu 
Qiming Zhang 
Tao Chen 
Liang Lv 
Di Wang 
Jing Zhang 
Yue Yang 
Zeyang Zhao 
Chen Wang 
Xiaowei Guo 
Hao Chen 
Qingye Wang 
Yufei Xu 
Qiming Zhang 
Bo Du 
Liangpei Zhang 
Dacheng Tao 

DI WANG
China University of Geosciences
China


JING ZHANG
Wuhan University
China


The University of Sydney
Australia


University of Geosciences
China


DU and LIANGPEI ZHANG
The University of Sydney
BOAustralia


DACHENG TAO
Wuhan University
China


The University of Sydney
Australia

Revolutionizing Agrifood Systems with Artificial Intelligence: A Survey
CCS Concepts: • Applied computing → Agriculture• Computer systems organization → Neural networks• Computing methodologies → Computer visionArtificial intelligenceMachine learning Additional Key Words and Phrases: Agrifood Systems, Artificial Intelligence, Machine Learning, Computer Vision, Remote Sensing ACM Reference Format:
With the world population rapidly increasing, transforming our agrifood systems to be more productive, efficient, safe, and sustainable is crucial to mitigate potential food shortages. Recently, artificial intelligence (AI) techniques such as deep learning (DL) have demonstrated their strong abilities in various areas, including language, vision, remote sensing (RS), and agrifood systems applications. However, the overall impact of AI on agrifood systems remains unclear. In this paper, we thoroughly review how AI techniques can transform agrifood systems and contribute to the modern agrifood industry. Firstly, we summarize the data acquisition methods in agrifood systems, including acquisition, storage, and processing techniques. Secondly, we present a progress review of AI methods in agrifood systems, specifically in agriculture, animal husbandry, and fishery, covering topics such as agrifood classification, growth monitoring, yield prediction, and quality assessment. Furthermore, we highlight potential challenges and promising research opportunities for transforming modern agrifood systems with AI. We hope this survey could offer an overall picture to newcomers in the field and serve as a starting point for their further research.

support billions of jobs and feed the global population. To this end, it is urgent to enhance food security and improve crop yield through dynamic monitoring of growth situations, optimized harvesting schedules, and reduced waste in current agrifood systems. Achieving this requires a smarter system that can handle the large amounts of data generated by agrifood systems and make accurate predictions. Recent advances in artificial intelligence (AI) 1 techniques have demonstrated their ability to handle large-scale data in various fields [32,168,169,184], including natural language processing, computer vision, medical imaging, remote sensing (RS), and more. Different AI techniques have been explored and have shown promise in building stronger and smarter agrifood systems from various perspectives. For instance, AI can monitor agriculture growth by jointly analyzing temperature, soil, water, and gas conditions [141], help distinguish crop diseases with hyperspectral data [28], predict yield through RS techniques [73], monitor pasture [25], and identify fishing areas [192]. Early methods relied on traditional machine learning (ML) techniques to process the captured data and have demonstrated superior performance in improving agrifood systems. However, they may be vulnerable to dealing with large-scale data captured under varying conditions, limiting their potential for further improving agrifood systems. Recently, deep learning-based (DL) methods have been devised to leverage the strong representation ability of deep neural networks to encode knowledge from large-scale data, enabling more accurate analysis and improving agrifood systems. Overall, incorporating AI techniques can lead to higher efficiency in agrifood systems with comprehensive analysis of the crops or animals' situation. Such a smart system can enhance food safety and better supply chain management by providing early detection of crop diseases and predicting yield.

Although there are many benefits to using AI techniques in agrifood systems, it comes with several challenges that need to be resolved for better agrifood systems. The first challenge is collecting potential data that can help monitor the development of different kinds of crops, animal husbandry, and fishery. In the agrifood system, data can be captured from various sources, such as satellites, unmanned aerial vehicles (UAVs), and different sensors like the global positioning system (GPS) or cameras. Each of these data sources has its own properties that make them suitable for different applications. For example, data from satellites can help monitor growth, while images captured using UAVs are suitable for crop classification. It's essential to select the appropriate data sources for different agrifood applications. After determining the appropriate data source for a specific application, the second challenge is designing proper methods to efficiently exploit the data for prediction. For instance, support vector machine (SVM) based methods [36] are typically incorporated with RS data for rough agriculture classification. With the development of DL methods, specific models are leveraged for more classification tasks, such as recognizing different crops following the segmentation pipeline [185].

In addition, long short-term memory (LSTM) models are involved with spatial models to jointly process spatial and temporal data [198], such as soil or climate conditions that change over time, for more accurate prediction of crop yield. Similarly, for animal husbandry, convolutional neural networks (CNNs) are devised to help distinguish diseases in different animal husbandry by taking their photos as input [43]. They can also be used to analyze the animal's behavior and emotion, which are highly related to their health and living status. In addition to animal husbandry and crop monitoring, AI techniques can also help with food storage and meat partition instructions to reduce waste. By analyzing the water condition, AI techniques can also be applied in the fishery to determine the appropriate region for different kinds of fish and distinguish between different fish categories. However, as agriculture and animal husbandry growth take longer, data storage and processing pose additional challenges for allowing AI to transform agrifood systems.

In summary, the use of AI techniques in agrifood systems has brought significant benefits in terms of improving food security, reducing waste, and enhancing supply chain management. However, there are also challenges to be resolved, such as data collection, designing appropriate methods to leverage the data, and dealing with data storage and processing. Despite these challenges, recent progress in AI techniques, such as DL, has shown great potential in solving these issues and improving the performance of smart agrifood systems. This comprehensive survey of the recent progress of AI in agrifood systems aims to inspire further research in this area and encourage the application of the most advanced AI techniques, such as large-scale foundation models, to address the challenges and unleash the potential of AI for better agrifood systems.


## Contributions of the Survey

There are several excellent existing surveys regards using AI techniques in agrifood systems, a detailed discussion and comparison of which is provided below. Here, we specifically focus on applying the most recent AI techniques in agrifood systems from the data acquisition and method selection perceptive, respectively. An overview with discussions focusing on advanced research, potential challenges, and future research directions is provided in this survey. The contributions of this survey can be summarized as follows. 1) We discuss how AI has transformed agrifood systems in various agrifood applications covering agriculture, animal husbandry, and fishery. 2) We first review data acquisition in agrifood systems, including data sources, data storage, and data processing, and then review the recent progress in applying AI techniques in agrifood systems, covering a wide range of related topics. 3) We thoroughly discuss the potential challenges and future opportunities in applying AI in agrifood systems.


## Relationship to Related Surveys

1.2.1 Remote sensing. Several existing surveys have examined the intersection of RS and agriculture [67,74,144,177]. While all of these surveys provide detailed descriptions of the characteristics and applications of RS technology in agriculture, each survey has its own emphasis. For instance, [144] covers the history of RS and its impact on agriculture, as well as various vegetation indices that can be computed from RS images. Meanwhile, [74] reviews and analyzes literature to identify recent developments in agriculture RS from temporal and geographical attributes. In contrast, this survey focuses on RS as a crucial data source for AI models in agrifood systems. Other surveys have focused on specific RS data sources [95,101,136] or specific applications within agriculture [6,199]. Additionally, some surveys have reviewed specific AI models, such as CNNs, in the context of agriculture RS [71].


### Internet of Things.

Internet of Things (IoT) represents an intelligent network that enables cyber-physical interactions by connecting numerous things with the capacity to perceive, compute, execute, and communicate with the internet. As discussed in the recent surveys, IoT technologies have greatly advanced various areas [147,156,191], such as smart cities, smart homes, and smart health care. Smart agriculture with IoT technologies has also been discussed in [38]. However, they mostly focus on the integration of IoT devices and corresponding areas while neglecting the possibility of AI techniques along with the development of these devices. Recently, [201] discusses the possibilities AI techniques brought in the IoT area, while ignoring the development of integration of AI and the IoT (AIoT) in the agrifood systems. Instead, this survey covers a wide range of topics for the integration of IoT devices and AI techniques in different agrifood areas, including agriculture, animal husbandry, and fishery.

1.2.3 Agriculture. As AI techniques continue to evolve within the field of agriculture, scholars have taken various perspectives in reviewing these methods. For example, [165] has focused on addressing the growing pressure on global agricultural production by exploring strategies for sustainable development in environment-friendly agriculture. They primarily review different learning methods for crops, including supervised learning, transfer learning, and few-shot Manuscript submitted to ACM learning. Notably, traditional learning methods and other agricultural sectors such as animal husbandry and fisheries are not addressed in their analysis. [68] conducts a comprehensive analysis of data resources, agriculture sectors, and learning methods in their paper. However, their work does not encompass the recent advancements in AI within the agriculture industry since 2018. [195] provides an overview of decision support systems in agriculture, focusing on their systematic application in areas such as agricultural mission planning, water resources management, climate change adaptation, and food waste control. Compared to previous surveys that cover a broad range of topics in agriculture, some researchers have chosen to focus on specific areas within the field of agriculture. For example, [98] analyzes over 30 datasets for diverse agricultural topics, discussing the main characteristics and applications of each dataset, and highlighting key considerations for creating high-quality public agricultural datasets. Crop-related methods are reviewed in [52,93,190] while [77] reviews DL methods in fruit growing, recognition, and yield estimation. Satellite RS technology has become a widely used tool for agrifood monitoring due to its vast observation range and timely data updates. Satellite images provide essential multi-source, multi-temporal, and multi-resolution data for monitoring agricultural production, animal husbandry, and fishery. RS satellites are typically classified as active or passive based on their onboard sensor data acquisition methods. Passive ones usually refer to optical RS satellites, which offer rich spectral and textural features but can be severely impacted by cloudy, rainy, and foggy weather conditions. While active RS technology mainly involves the synthetic aperture radar (SAR), which can operate all around the clock, detecting land surface information by receiving reflected echoes from actively emitted microwaves.  SAR distinguishes different features by analyzing their backscattering characteristics. Because the emitted microwaves are sensitive to moisture, SAR is often used to retrieve soil and vegetation moisture levels [158]. When combined with optical images, it allows for more accurate and refined crop classification [1,148] or monitoring [11,17]. Additionally, SAR can identify surface deformation information, making it useful for crop canopy monitoring. Currently, the most popular SAR satellite is the Sentinel-1, which is favored due to its free accessibility.

Images obtained by optical sensors can mainly be divided into three types: multispectral, hyper-spectral, and panchromatic, as shown in Fig. 1. Hyperspectral sensors receive abundant spectral information, allowing the extraction of a continuous spectral curve of a broad wavelength range for each pixel. Thus, the obtained images are appropriate for distinguishing vegetation with similar visual characteristics. This is very useful in fine-grained vegetation classification Manuscript submitted to ACM [13,111,166]. Multispectral images are most commonly used for agricultural classification and yield prediction. Moderateresolution imaging spectroradiometer (MODIS), Landsat-8, and Sentinel-2 are the three most popular medium-resolution multispectral satellites for agrifood monitoring [51,66,89,94,97,138,142] since their data are easy to acquire and rich in vegetation-sensitive bands. SPOT-5 2.5 [31] QuickBird 0.61 [31] world-view3 0.31 [1,26] AVIRIS*(airborne) 20 [13,111,166] * denotes containing hyperspectral sensor.

Some very high resolution (VHR) satellites such as SPOT5 [31], QuickBird [31], and RapidEye [11] are suitable for finegrained classification and field-level monitoring. However, due to their commercial availability and high cost, these satellites have relatively fewer applications in agrifood monitoring. Table 1 provides details of some common optical RS satellites and their resolutions.

2.1.2 Unmanned Aerial Vehicles. UAV platforms can provide ultra-high spatial resolution images for agrifood systems [162].

Compared to traditional airborne and satellite platforms, UAV images offer finer spatial, spectral, and temporal resolutions, making them more suitable for precision agriculture. UAV platforms offer great flexibility in terms of acquisition operation, flight cycle, flight altitude, and geographic coverage [95]. They are also able to significantly reduce the impact of atmospheric disturbances on the generated images and eliminate cloud cover issues that commonly affect optical satellites and high-altitude airborne optical sensors. UAVs are compatible with a wide range of sensors, such as digital RGB, multispectral and hyperspectral [210]. Nowadays, UAV data are widely used for crop classification, crop monitoring, yield prediction, animal husbandry monitoring, and more in agrifood systems [7,42,58,73,112,130,167,171,194]. Fig. 2 shows the various types of sensors that UAVs can carry.

UAVs can also be equipped with multiple types of sensors at the same time, allowing for lower costs and obtaining diverse monitoring data. Therefore, many studies simultaneously utilize UAV multi-source data [105,116,119,214]. For instance, [119] combines RGB and multispectral images to improve early-season maize strain calculations, while [116] jointly utilizes RGB and hyperspectral imagery to assess the quantity and quality of pasture, and so on.


### Onsite devices.

Onsite devices such as ground height spectrometers, handheld spectrometers, handheld GPS, multispectral cameras, thermal imaging cameras as well as digital cameras have been used for various specific-purpose agricultural studies, such as breeding selection [58] and yield estimation [53,73,196]. For example, [53] uses a highresolution RGB camera mounted on a land-based imaging platform to acquire images for one season to estimate wheat yields, While [58] manually takes high-resolution images of wheat above the canopy from budding to flowering for breeding selection.


### Other sensors.

Some specialized devices, such as the time domain reflectometer for monitoring soil moisture dynamics of the surface, near-surface, and root zone [7] and the RSX-1 gamma radiation detector for measuring the amount of radiation in the soil [2], are also employed in agrifood systems. The observed data usually is adopted as the ground truth values for training and improving AI models.

2.1.5 Laboratory conditions. Due to various factors such as field environment, equipment, experimental operation, and data analysis, much experimental data cannot be obtained directly in the field or through RS and other approaches.

At this time, representative research data can be obtained by analyzing collected field samples in the laboratory. For example, in the laboratory, [7,73,158] perform soil organic matter content measurements, [86] uses the Kjeldahl method to measure the Nitrogen content for wheat leaves, while [42,196,213] obtain the dry weight of wheat by desiccation. and other sensors can collect data at any time and in any location, which are cached directly on the onboard disk or sent to a remote data center. In laboratory settings, data are typically recorded manually or by using specialized instruments.


## Data


### Data processing.

Proper preprocessing of data is essential before utilizing it, especially when it comes to optical satellite images. Radiometric calibration and correction, atmospheric correction, and geometric correction are the most crucial steps involved in this stage. Initially, digital numbers of original images are transformed to surface reflectances, and the influences of atmosphere and earth curvature during observations are removed. Clouds, shadows, water, and snow may also be eliminated if necessary. Ortho rectification is conducted to correct the influence of topography, and image mosaicking is required if the study area spans different tiles. Band selection and clipping are usually implemented, and sometimes, the geographic coordinate system needs to be converted. Resampling, multi-temporal interpolation, image fusion, and different index calculations are conducted for specific applications in agrifood systems. Preprocessing SAR images requires additional steps compared to optical data, as speckle noise caused by systematic errors must be removed through multi-looking correction or filtering. For UAV data, standard photogrammetric procedures are used to preprocess RGB images, which involves aligning and merging images and then producing a series of products, such as the digital elevation model with the help of ground control points. When dealing with multispectral data, radiometric and lens corrections are also necessary. Preprocessing hyperspectral data requires further treatments to address sensor, atmosphere, and solar light issues. Preprocessing data obtained from handheld cameras is similar to UAV images, while data from other onsite devices will require specific processing depending on the circumstances. For instance, spectral data obtained from a spectrometer typically requires denoising and smoothing. In some cases, such as data obtained in laboratory conditions, preprocessing may not be necessary since the data is measured as a reference of the predicted value in AI models.


# PROGRESS REVIEW OF AI METHODS IN AGRIFOOD SYSTEMS

This section will provide an overview of AI methods used in agrifood systems. Firstly, we will briefly categorize existing AI methods into two groups, i.e., traditional ML and DL. Secondly, we will conduct a comprehensive literature review on the application of AI methods in various agricultural sectors such as crops, animal husbandry, and fisheries. Given that the same AI techniques can be used for diverse applications in agriculture, we will organize the review according to an application taxonomy that encompasses both traditional ML and DL approaches for various applications. CNNs, and LSTM networks. CNNs are good at handling tasks with 2D images such as multi-crop classification, the latter two models are popular in tasks involving temporal data, such as predicting crop yields or tracking locations for moving animals. Apart from them, the recent emergence of Vision Transformers (ViT) has attracted significant attention among researchers in many fields like crop classification and weed extraction. These powerful models have been employed for a range of agricultural tasks, where researchers often utilize different task heads to generate the required output based on the specific problem formulation. Accordingly, these models can be categorized from a fundamental task perspective.

For example, classification models aim to predict the class of given images, while segmentation models seek to predict the labels of each pixel. Detection models need to generate the objects' locations as well as the corresponding classes while tracking models estimate the trajectory of an arbitrary target object. These models are capable of formulating tasks related to crops, animals, and fishery, and have demonstrated effectiveness in addressing a range of problems in these domains.


## AI Methods in Agriculture

3.2.1 Agrifood classification. RS technologies have been widely applied to agriculture, they provide multi-source, multi-temporal, and multi-resolution data for large-scale, all-weather automated monitoring of crops. As shown in Fig In the early years, most of the methods utilized band algebra and band transformation (e.g., difference vegetation index, enhanced vegetation index (EVI), normalized difference vegetation index (NDVI) [16,121,198]) to extract features for classification. However, these methods often result in noisy and inaccurate classification due to manual threshold setting and subjective expert experience. In order to utilize the abundant inter-classes, sample-wise and temporal relationships introduced by RS images, traditional ML methods [137] have been applied in agrifood classification as they can explore the latent and complex information between samples belonging to different categories. At first, researchers usually use a single ML classifier for classification. [111] uses C4.5 DT for hyper-spectral soy-bean mapping. Although the rules generated by C4.5 are easy to understand, this algorithm has low efficiency and cannot handle large datasets due to the limitation of its structure. [79] adopts multilayer perceptron (MLP) for multi-temporal crop classification, but its performance is limited by the small number of latent layers. Most of the traditional ML methods can capture complex nonlinear features with relatively simple structures but some cannot cope with large datasets, and some are easy to trapped by local optimal values. These problems of using a single classifier may lead to a high erroneous recognition rate. Therefore, researchers try to integrate multiple classifiers to comprehensively utilize the advantages of different classifiers [5,121]. The idea of integrating multiple classifiers has later extended to the field of ensemble learning (EL), which is nowadays one of the most representative and effective methods. Typical EL methods like RF [161], XGBoost [88] and GBDT [94] are widely applied in agriculture classification and outperform other single classifier-based methods. [146] summarizes current state-of-theart techniques for sugarcane mapping and monitoring, where RF, SVM, and classification and regression tree are compared and RF shows the best performance.

On the other hand, researchers are continuously working on constructing strong and robust feature extractors for classification. Recently, DL methods have gained increasing attention in crop classification and identification tasks, e.g., multi-type crop classification [82,207], sorghum identification [172], soybean and maize crop [182] mapping and so on. Most of the neural networks applied in agriculture classification are semantic segmentation networks, as crop classification and identification tasks need pixel-level labels. [59] verifies the effectiveness of four semantic segmentation models including DeeplabV3+ [18], PSPNet [208], SegNet [10], and U-Net [131] on identifying tobacco planting areas through UAV images. State-of-the-art networks such as ViT [130] and TransUNet [114] are also applied in multi-type crop classification. However, few studies have specifically designed networks for agriculture classification tasks that prioritize the characteristics of different classes of crops. Moreover, deep neural networks, known as black-box models, have the drawback of hard to interpret their predictions. To address this issue, studies on explainable AI technology have gradually increased in recent years. Explainable AI might make a big difference in designing deep neural networks, especially for agrifood-related tasks.

Generally, RS agrifood classification based on ML and DL methods can handle input images in various resolutions, so it can satisfy diverse research scales such as field-level, provincial-level, and even country-level. These methods can meet the requirements of different classification tasks. Nevertheless, there is still a large room for advancing RS agrifood classification, by leveraging more powerful neural networks and learning methods.


### Agrifood growth monitoring.

Crop growth state is a crucial component of agricultural data, as it provides insights into the yield of the crop. RS technologies offer a macroscopic, timely, and dynamic approach to monitoring regional crop growth, giving them great advantages. By using RS data, macro estimations of real-time seedling situations, environmental dynamics, and crop distribution can be conducted. This helps to facilitate a timely understanding of crop distributions, growth conditions, fertilization markets, as well as the dynamics of diseases, pests, and weeds. Ultimately, RS provides an accurate data platform for crop production managers and decision-makers, enabling them to take various management measures that optimize crop production.

Crop growth is affected by many factors, such as light, temperature, soil, water, gas (CO2), fertilizer, diseases, insect pests, disastrous weather, management measures, and so on. In the early stages of crop growth, it is mainly reflected by the quality of crop seedlings, while in the middle and late stages of crop growth and development, it mainly reflects the development of crop plants and the specific characteristics of high and low yields. Although the growth of crops is an extremely complex physiological and ecological process that involves many factors, it still can be characterized by some metrics that can reflect its growth state or are closely related to its growth characteristics. In the past, relevant crop growth state factors and environmental attribute factors were mainly monitored and collected manually, and then comprehensively analyzed by experts according to their experiences or using statistical models containing multiple variables. The obtained results may be subjective and inaccurate, which could not meet the requirements of intelligent and precise agriculture (Fig. 4).

As an important subset of AI, ML techniques have proven to be a promising solution for addressing the spatial analysis of big data and solving nonlinear problems, especially when the extent of theoretical knowledge of a problem is incomplete [80] or when statistical presuppositions are unreliable or not known [33]. At present, ML technologies have made considerable achievements in the field of crop growth monitoring, and some typical examples of agrifood growth monitoring based on RS imagery and statistical ML algorithms are presented in Table 2, and other applications will be described in detail below.

Environmental monitoring: The environment of crop growth encompasses the external natural conditions of the living space of crops, including the effects of various natural environmental conditions and other biological organisms.

Among these factors, soil moisture and the contents of soil organic matter (SOM), cation exchange capacity (CEC), Mg, K, and pH are key factors that significantly impact crop growth.

Monitoring soil moisture using RS information is crucial for precision agriculture management, particularly in regions with limited water resources. Compared to ground measurement methods, RS-based monitoring provides a more cost-effective means and has been increasingly used in large-scale soil moisture monitoring tasks [8,132,141]. Currently, RS-based soil moisture monitoring methods mainly rely on physical-based models, such as radiative transfer models, or statistical ML models. Physical-based models establish the functional relationship between soil moisture content and various spectral indices obtained from RS. These models require accurate parameters such as soil characteristics, land cover characteristics, vegetation biochemistry, and biophysics. Common methods include thermal inertia, crop surface temperature, gravity soil moisture measurement, soil water balance calculation [60], and so on. Although physical-based models can provide accurate information for soil moisture, obtaining parameter quantities makes it difficult to monitor the spatial and temporal distribution of soil moisture over vast areas. Additionally, collecting soil moisture data and laboratory measurements through sampling points is expensive, time-consuming, and labor-intensive [141], which are unsuitable to apply in a large range area.

Compared to physical models, statistical ML models learn the complex interactions between the plant-soil-atmosphere continuum by establishing the relationship between spectral signals and plant characteristics, and then fitting the soil moisture in the study area. Predictors such as canopy reflectance can be directly associated with soil moisture as the target variable through regression models. The most widely used ML models include decision trees, ordinary least squares (OLS), RF, SVM, artificial neural networks (ANN), genetic algorithm, and EL.

However, most space-borne and airborne sensors have limitations such as low spatial resolution, limited surface penetration, and vulnerability to vegetation when conducting soil moisture research. On the other hand, UAVs and other equipment offer several advantages, such as convenience, low operating cost, a flexible configuration of high-resolution imaging systems, and highly flexible flight plans, making them a promising tool for precision agricultural management.

For instance, [7] jointly utilizes UAV data and physical and hydraulic soil information to estimate soil moisture in the root zone. They adopt various algorithms such as ANN, generalized linear model (GLM), gradient elevator, RF, and the EL methods that are included in an automatic machine learning (AutoML) platform. [22] employs multi-modal data fusion and four ML algorithms (partial least squares regression (PLSR), KNN, RF, and back-propagation neural network (BPNN)) to estimate field soil water content. They also discuss in depth the impact of various factors, such as soil depth, canopy coverage, and crop varieties, on the estimation results. Apart from using satellite images and UAV images, SAR images have also been widely used to estimate soil moisture in crop areas. [17] collects quad polarization's RADARSAT-2 data and 240 sample plots in the study area to compare the performance of three advanced ML models (namely, SVM, RF, and gradient boosting regression tree (GBRT)) in estimating soil moisture. Their results demonstrate that combining polarization decomposition parameters with ML and feature selection methods can effectively estimate Manuscript submitted to ACM soil moisture with high accuracy. This method is useful in monitoring soil moisture across the entire farmland during the growing season.

Other than soil water content, various soil chemical characteristics such as SOM, CEC, Mg, K, and pH also play a crucial role in affecting crop yield. In a study of [73], linear regression and five ML models, namely, RF, neural network (NN), SVM, gradient lifting model, and Cubist are used to predict the soil properties of seven farmlands near Ohio.

While [205] uses NDVI time series data and stepwise linear regression, PLSR, SVM, and ANN models to map soil organic carbon in Honghu City, where the ANN demonstrates the best performance.

Crop growth state monitoring: Nitrogen, phosphorus, potassium, and other essential elements are crucial for crop growth and play a vital role in plant nutrition. These elements often affect crop yield due to insufficient supply in the soil. However, traditional crop nutrition diagnosis relies on destructive on-site sampling and slow laboratory analysis [163]. In addition, the nutrient concentration measured at each point may differ significantly from the actual nutrient content in the farmland [12]. What's more, variations in crop nutrient content can lead to changes in crop morphology and leaf color, suggesting that spectral information of crops can be variable [47]. These findings provide a theoretical basis for monitoring crop growth using RS technology, as it allows for non-destructive and continuous monitoring of crop nutrient status.

Commonly used crop monitoring and simulation methods include radiation transfer, process-based, and empirical statistical models. [62] notes that radiation transfer and process-based crop models are considered universal because they are developed based on physical laws, and ecological and physiological principles. However, obtaining high-resolution inputs and parameters for these models can be challenging [37]. In contrast, [15] highlights that empirical methods directly link crop variables with RS indicators, which is particularly useful for growth processes with limited information about potential mechanisms. Moreover, empirical study [177] has shown promise that the ML/DL methods based on AI technology are proved to have similar simulation abilities compared to radiation transfer models in properly simulating reality.

Due to uncertain factors such as cloudy weather and rainy days, satellite images during critical growth stages may not be available. Furthermore, the fixed revisit cycle of satellites is another important limited factor. In recent years, UAV RS technology has proven to be a fast, real-time, high-resolution, and non-destructive on-site monitoring means.

With a multi-spectral UAV camera that captures data from multiple bands, rich ground spectral information can be obtained. In addition, these UAVs are easy to operate, making them an ideal tool for precision agriculture at farmland scales.

Several studies have shown the potential of using UAV RS technology combined with ML methods for crop nutrient estimation. [171] evaluates the nutrient elements in rice crops at different growth stages using univariate regression models, multivariate calibration methods, PLSR, and several ML methods, including ANN, RF, and SVM, based on UAV hyperspectral images. Their experiments have demonstrated that PLSR models and ML methods can yield improved outcomes in circumstances where multiple growth stages are involved or there is a lack of phenological information.

[97] compares the availability of the multi-view information from a single high-overlap image obtained by UAV, the single-view information from the lowest point image, and the mosaic orthophoto, by SVM, ELM, and RF. They find that high-overlapping multi-view images can produce the highest estimation accuracy of leaf and plant nitrogen concentrations.

Biomass estimation: Biomass is an essential indicator of crop vegetation health and development. However, direct measurement of biomass is expensive and destructive. RS provides an efficient way to monitor and estimate large areas of AGB due to the diversity of platforms and sensors and the improvement of spatial and spectral resolution. To investigate the ability to model the input-output nonlinear mapping between RS data and biomass, many studies have used various representative algorithms in the field of AI [11,45,49,110,214]. For instance, [213] proposes a wheat biomass estimation method that combined the HJ-CCD vegetation index and RF, and demonstrates the accuracy and robustness of the model at each stage of wheat growth. [214] uses OLS, RF, BPNN, and SVM models to study the performance of 3D point cloud based on multi-source UAVs at multiple spatial scales for estimating the AGB of crops.

[49] adopts UAV data and OLS, SVM, ANN, and RF to estimate corn biomass. [11] combines radar and optical earth detection to estimate the leaf area index and biomass of three crops (soybean, corn, and rape) in Manitoba, Canada, using SVM, RF, GBDT, XGBoost models, and a deep neural network. The results suggest that GBDT and XGBoost models have great accuracy in parameter estimation, while the deep neural network has better potential in estimating crop parameters than traditional ML algorithms.

Weed extraction: Weeds compete with crops for essential resources such as nutrients, water, sunlight, and space, which can hinder field ventilation and ultimately reduce crop yield and quality. Additionally, weeds can serve as intermediate hosts or habitats for pathogenic microorganisms and pests, leading to the occurrence of diseases and pests in the crop field. As a result, it is crucial to leverage RS technology and AI algorithms to accurately map weeds in fields and develop corresponding measures to remove them.

[122] proposes a system for generating weed maps using images captured by UAVs. The system utilizes the Hough transform to detect crop row information, improving the accuracy of weed classification. The methods employed include clustering, semi-supervised and supervised learning. Recently, DL methods begin to be employed in the agrifood system. DL is a specialized subset of ML that focuses on more intricate image analysis. Different from ML models that require feature engineering in the pre-processing phase, DL models can directly extract deep inherent features from raw data and deliver high performances without the need for extensive pre-processing [61]. It learns representations through multiple layers, beginning with low-level features in the early layers, and gradually learning more complex and semantic concepts through a hierarchical structure. Finally, diverse outputs such as the predicted category information (via classification networks) and spatial location information (via segmentation networks) of the target object can be obtained, as shown in Fig. 5.

Manuscript submitted to ACM [174] introduces an enhanced bionic optimization-based transfer neural network to identify weed density and crop growth. They obtain an accuracy of 99.39% in RGB images and 99.53% for multispectral image data for the classification of three types of crops and weeds. To further improve the identification capability, [130] employs the advanced ViT model combined with high-resolution UAV images to classify crops and weeds. These studies demonstrate the advantages of DL models in weed extraction, which can promote the development of precision agriculture.

Crop diseases and pest monitoring: Crop diseases and insect pests have become the primary factors that reduce agricultural production, causing a large loss in crop yields worldwide. Traditionally, experts have visually identified pathogen and plant disease symptoms, but the accuracy relies on personal experience and is not suitable for large-scale detections [103]. Nowadays, RS technology for pest monitoring mainly relies on empirical models and ML algorithms [155,200]. The empirical model is relatively simple, but it is vulnerable to external conditions and lacks universality.

ML methods take into account training errors and generalization abilities, overcoming the affection of environment changes [9]. [5] proposes an innovative classification framework involving feature selection, novelty detection, and EL to detect plant diseases with high accuracy. [96] collects hyperspectral data of three types of strawberry plants with mobile platforms. They utilize 32 spectral vegetation indices to train stepwise discriminant analysis, fisher discriminant analysis, and KNN algorithms. All the classification accuracies of these models are beyond 70%. While [140] applies three feature extraction methods (histogram of oriented gradients (HOG), speeded-up robust features (SURF), and gray level co-occurrence matrix (GLCM)) and two supervised learning classifiers (ANN and SVM) to detect strawberry powdery mildew. They find that ANN and SURF have the highest detection accuracy. These examples demonstrate the potential of ML models in detecting crop diseases and pests.

After surveying five sub-directions in the field of agrifood growth monitoring, it can be concluded that, in the future, with the massive agricultural data, applying advanced AI methods in the process from sowing to harvesting for dynamically monitoring field environmental conditions, crop growths, weeds, diseases, and insect pests is an extraordinarily valuable direction, wherein ML and DL technologies demonstrate the advantages of high accuracy, strong robustness, and distinguish adaptability. By building a monitoring and warning system, effective supervision and diagnosis of crops can be realized, thereby providing real-time, accurate, intelligent, and automatic solutions for remote dynamic management of crop growth, and improving agrifood growth environments as well as increasing agricultural productivity. At the same time, the combination of RS and AI technology has shown excellent performance in monitoring the growth state of crops, since plentiful and diverse data that is generated by multiple satellites with various types of sensors, including high-resolution data, hyperspectral data, and multispectral data, and the derived multi-type features, have been continuously supplied into AI models for comprehensive analyses. In a nutshell, integrating technologies such as AI, agriculture, and RS can significantly enhance the efficiency and sustainability of crop monitoring, and provide a promising solution to precision agriculture.


### Agrifood yield prediction.

Crop yield is the economically valuable fraction of AGB that accumulates during a growth cycle [54]. The yield is determined by the interaction among crop genetics (G), environmental conditions (E), and manual management practices (M) -(G x E x M), which are highly variable in both temporal and spatial dimensions [128]. Accurately predicting crop yield is a crucial and challenging task in precision agriculture, especially given the rapidly increasing global population and the frequency of extreme weather events. Efficient and accurate yield prediction is critical for developing food policies and ensuring the security of food supply [3,92]. Furthermore, government, dealers, and farmers can use the predictions to make strategic decisions [100].

Current mainstream methods for predicting spatial crop yields can be categorized into two groups: crop simulation models based on growth processes, and statistical ML models [105]. Physical crop models are developed to estimate yield by simulating crop growth and environmental effects such as crop density, light use efficiency, soil nutrient content, and water balance, based on crop growth processes and physiological characteristics [206]. Although physical crop models are well-suited to quantify potential yields, they require large amounts of field data related to biotic and abiotic factors for model calibration. As a result, they lack the ability to provide large-scale estimates of actual yields [70,133].

Statistical ML models do not simulate the biophysical processes of crops but instead, predict yields by establishing a mapping between yield-related factors and historical yield records. This approach allows yield predictions without relying on complex crop growth parameters [176]. The general flow chart of statistical ML-based yield prediction has been shown in Figure 6. Additionally, biophysical indicators that reflect crop growth, such as AGB or net primary productivity (NPP), also can be incorporated as the model input [29,30].

By feeding the ML model with the vegetation indices of RS images, such as the NDVI and EVI, we can realize the yield prediction on a large scale. Linear models are the most basic ML methods. For instance, [66] inputs various combinations of MODIS-NDVI, MODIS-EVI, NOAA-NDVI, and spectral vegetation indices derived from multispectral and 3D point cloud data into MLR models. [107] combines EVI data and vegetation optical depth derived from soil moisture active and passive L-band to predict county-level yields of corn, soybeans, and wheat in the Midwestern U.S.


## Manuscript submitted to ACM

Corn Belt using the regularized linear regression algorithm. [42] constructs a wheat yield prediction framework by combining various vegetation indices and multiple methods, such as linear regression, MLR, and stepwise multiple linear regression. Moreover, some other linear models including OLS [135,176], least absolute shrinkage selection operator (LASSO) [108,202,211], and PLSR [105,106] have also been used for yield prediction.

Although linear models are able to perform efficient yield prediction, the complex relationships between yields and some factors, such as crop genetics, environmental factors, and human management practices [128], are not always linear. In such cases, linear models may not perform well. To tackle these issues, various nonlinear ML models have been developed to predict crop yields. For instance, [69] constructs multiple ML models, including Cubist, MLP, support vector regression (SVR), GPR, KNN, and Multivariate

Adaptive Regression Splines, to predict wheat yield in the Australian wheat belt, and finds that SVR achieves the highest prediction accuracy. In another study, [48] develops a yield prediction model framework using the GEE platform to test the performance of KNN, NN, DT, SVM, and GPR models for winter wheat production in China. [108] uses SVR-Linear, SVR-RBF, and MLP models simultaneously to predict the national production of barley, soft wheat, and durum wheat in Algeria during the current season. Other commonly used ML models, such as ANN [42], bayesian neural networks (BNN) [66,99], have also been used to improve the accuracy of crop yield prediction. Nevertheless, since these methods rely on a single model, they may suffer from an overfitting issue when training data is limited.

To improve the generalization ability of ML models, EL techniques have become increasingly popular in recent years. By combining multiple base models, EL methods can compensate for errors and deficiencies in individual models, leading to more robust and accurate predictions [206]. Bagging and Boosting are the two most commonly used EL techniques in ML.

Among bagging approaches, the RF employing multiple decision trees has been widely adopted for crop yield prediction [41,48,72,105]. [41] develops yield prediction models for wheat, barley, and oilseed rape based on MODIS-EVI time series data and the RF algorithm, respectively. The cross-validation results demonstrate that the RF model yields accurate predictions. [72] simulates maize yields using Sentinel-2-generated vegetation indices and ML algorithms (MLR, RF, SVM), with RF achieving the highest accuracy.

In contrast to Bagging methods, many variants of Boosting techniques have also been applied in crop yield prediction.

For instance, [206] integrates vegetation indices, canopy cover, and climate data obtained from Landsat and UAV imagery to predict almond yields in the Central Valley of California, using Stochastic Gradient Boosting. Similarly, [69] and [202] employ the XGBoost algorithm to predict the yields of maize and wheat, respectively. Additionally, GBRT [108], light gradient boosting machine (LightGBM) [203], and adaptive boosting (AdaBoost) [176] have also been applied in the context of yield prediction.

However, ML algorithms still suffer from the issues of overfitting, long-time training, and limited representation ability. These issues affect their performances, especially in large-range prediction tasks.

Recently, by automatically extracting the inherent deep features of targets, DL technology presents powerful representation ability [81]. It has exhibited superior performances compared to existing process-based crop simulation models or ML methods on large-scale crop yield prediction tasks yield [105,113,203], where CNN and LSTM are the most commonly utilized architectures. [113] proposes a yield prediction model for wheat and barley based on 2D-CNN architecture and UAV data, achieving reliable prediction accuracy. Nonetheless, yield prediction often requires the processing of time-series data. To this end, [39] create 3D-CNN models that simultaneously considered temporal, spectral, and spatial information to predict rice yield in the eastern Arkansas and Terai regions of Nepal, respectively. They find that using data from multiple timestamps yielded predictive performance similar to that of 2D-CNN architectures. However, if training with different datasets including multiple rice cultivars and growing environments, especially when there are significant cultivar-or environment-specific differences in the temporal patterns of vegetation indices, the 3D-CNN architecture generates more accurate prediction [35]. In addition, some crop growth cannot be fully captured by RS images since real-world crop growth is determined by many factors. In this case, it may be insufficient to mine deep spatial and spectral features within the image based on CNN alone. To further integrate spatial-spectral depth features and spatial consistency, [124] combines multi-kernel learning techniques to integrate two types of heterogeneous information into a 3D-CNN model to improve the yield prediction accuracy in three types of winter wheat growing areas.

The LSTM model, as a variant of the recurrent neural network, is particularly well-suited for processing temporal data due to the use of hidden states to capture information from previous states. In [203]    Currently, numerous ML or DL models are demonstrating great success in crop yield prediction using RS images.

However, most studies focus on prediction at large scales, e.g., the county as the smallest scale, with few conducted at the smaller scales, e.g., the farm scale. This is because spatiotemporal reference data based on pixel-level yields is more challenging to obtain, and thus researchers often prioritize making large-scale yield predictions to characterize crop harvests. Nevertheless, farm-scale or pixel-level yield prediction is more useful than county-scale in understanding how crop yields respond to environmental changes and manual management.

In addition to RS images, AI technologies also have the potential for agrifood yield prediction through natural images.

To this end, with the sparse R-CNN detection framework [151], we separately evaluate the performance of different backbones networks, i.e., ResNet-101 [55] and ViTAEv2-S [204], on the global wheat detection dataset 3  3.2.4 Agrifood quality assessment. Crop quality assessment involves evaluating various quality attributes of crops and grading them accordingly. ML techniques are highly relevant for both tasks as they have an excellent capacity to handle multidimensional data by incorporating several predictor features. Fig. 9 depicts a whole framework of agrifood quality assessment taking the example of strawberries.

In the existing literature, [27] uses long-range Fourier transform infrared spectroscopy to capture the spectral characteristics of volatile organic compounds (esters, alcohols, ethylene, etc.) generated by strawberries after different storage times for detecting abundance changes. Then, they perform PCA to distinguish fresh, slightly spoilage, and spoilage categories. [102] compares seven types of features and uses SVM to classify fruits into two groups: good and damaged. Recent developments have shown that DL models, compared to traditional ML models, perform better in fruit grading due to their ability to extract high-level features from raw input data. [153] evaluates the ability of CNN-based architectures (AlexNet [78], GoogLeNet [154], VGGNet [23], Xception [143], and MobileNet [57]) for binary classification and grading strawberry fruit into four levels using RGB images. In a word, AI techniques have demonstrated their potential in the quality inspection of agricultural products, leading the industry towards intelligence and automation.

3.2.5 Other topics. In order to increase crop yield and fully leverage the genetic potential of beneficial crop productions, it is essential to perform a breeding selection by closely monitoring various phenotypic characteristics including biomass, yield, disease resistance, and ground cover. However, traditional breeding methods rely on labor-intensive manual surveys, which are not only costly and inefficient but also limit the scope of modern precision agriculture.

In recent years, the development of UAVs and sensors has opened up new opportunities for low-cost and rapid data acquisitions. ML algorithms can automatically extract phenotypic features from image data, and numerous studies have demonstrated that advanced RS techniques integrated with ML methods can effectively predict valuable crop traits with high accuracy. For example, [137] uses UAVs to obtain high-throughput vegetation indices and then adopts four typical ML algorithms including PLSR [90], SVM [36], ANN [186], and RF to establish oat biomass estimation models,

showing the potential of aerial RS for AGB estimation in oat breeding nurseries.


## Artificial Intelligence Methods in Animal Husbandry

3.3.1 Pasture monitoring and evaluation. The countries with a developed animal husbandry industry typically have vast grassland areas. Due to its contribution to carbon storage, grasslands are mainly used for animal feed production and play an important role in maintaining the ecological system [40]. Therefore, the yield of pasture directly affects animal husbandry productions, and the relevant monitoring is important for the utilization and management of pastures, and the improvement of ecological environments [180]. In recent years, big data-based grassland monitoring has become a hot-spot research topic.

Accurately and effectively modeling the AGB of grasslands is a crucial and fundamental task for monitoring and managing grasslands in pastoral areas. AGB can be estimated using both traditional (or ground-based) and RS methods.

Traditional methods include visual inspection, cutting and drying, plate lifter, and in situ spectroscopy. However, these methods are time-consuming and only applicable in small-scale monitoring [180].

With the advancement of RS temporal and spatial resolutions, large-scale, efficient, and real-time monitoring of pasture biomass has become in reality. In the past four decades, many methods have been developed for estimating pasture biomass based on satellite RS data. These methods can be divided into three main categories: vegetation index-based, biophysical simulation models, and ML algorithms. Nevertheless, according to our literature surveying, up to now, statistical ML methods have not been particularly used in this field.

Biochemical parameters of grassland forages are crucial indicators for measuring vegetation growth status, forage feed value, grass and animal husbandry nutrient balance, and carbon cycling [44,157]. One of the key parameters that have been identified as significant for crop growth and yield is phosphorus, due to its essential role as a source of nutrients. Inadequate availability of this nutrient has been observed to have a detrimental effect on crop growth and yield. To this end, [44] constructs 39 models using hyperspectral data and multiple factors to estimate the phosphorus content of the grasslands in the eastern alpine region of the Tibetan Plateau.


### Animal individual monitoring.

In addition to monitoring animal husbandry behavior at the group level using remote sensing images, modern animal husbandry also requires monitoring individual animals to ensure their health and growth and prevent the spread of disease.

Animal individual recognition: To conduct individual animal monitoring in animal husbandry, it is necessary to recognize and distinguish each animal on the farm. This recognition is achieved by identifying subtle differences between individuals, such as the length of a cow's face, the shape of a sheep's paw, or the patterns on a dairy cow's coat. Early methods for individual recognition [50] involve directly capturing images of the animals and using CNNs for recognition.

However, these methods may not be suitable for deployment on edge devices due to the heavy computational load. To address this issue, a lightweight CNN has been introduced in [85] for easy deployment and fast inference. To further improve recognition accuracy, some methods require the model not only to recognize individual animals but also to distinguish their postures [188] or segment them from the background [185,215]. Moreover, for specific animal species, distinct parts of the animals, such as the face of pigs, can be utilized for better recognition [50].

Animal sickness detection: Monitoring the health of individual animals is crucial for ensuring their growth in animal husbandry. Facial expression is a general indicator of an animal's discomfort, and automated recognition of facial expressions can help detect sickness. For instance, [115] uses facial expression analysis of sheep to evaluate their health status by feeding their facial images into CNNs. However, capturing the facial images of each individual can be challenging and time-consuming. To overcome this issue, several methods [170] use images captured from the front of the animals as input and require the networks to jointly detect the animal's face location and evaluate their health status.

In addition to evaluating an animal's health status based on facial expression, specific techniques are designed to diagnose particular illnesses. For instance, to diagnose lameness, some methods [178] first detect and track animals through a series of contiguous frames, then collect their trajectory for analysis. To improve the accuracy of diagnosis, it is beneficial to estimate the poses [183,188] and their temporal correspondence based on optical flow [181], e.g., as shown in [64]. Furthermore, [160] adopts 3D convolutions to process contiguous frames for better analysis of temporal information. RS technology has also been used to predict the spatial incidence of schistosomiasis in sheep [152]. In this study, the RF and AdaBoost models are identified as the best models. Apart from using RGB images of individual animals for evaluation, other clues can be utilized to aid diagnosis. For example, thermal images can be used to help identify cow mastitis, while fecal images can be used to evaluate the health of cattle's digestive systems.

Animal behavior monitoring: Animals, like humans, exhibit unique behavior patterns that are specific to each individual. Collecting and analyzing these patterns can aid in their growth and well-being. Spatial and temporal information can be used to recognize drinking, feeding, and lying behaviors, often based on stacked RGB frames or optical flow maps. Here we show some examples in Fig. 10, which are extracted from the AP-10K dataset [188]. The behaviors of cattle can be recognized through their poses estimated by the ViTPose model [183]. Additionally, these techniques can be used to analyze an animal's engagement with various objects, identifying their preferences and improving their mood for better growth. Moreover, monitoring behavior can prevent harm by identifying patterns Manuscript submitted to ACM Table 4. Summary of recent methods investigating fishery-related tasks using AI technologies


## Reference

Data type Model/Algorithms Novelty/Targeted problem [21] GF-2 HDCUNet,FCN-8s,SegNet,U-Net Misjudgment of suspended matter [192] Landsat TM,OLI,GF-1 SVM Water surface geometric features in remote sensing images [193] Landsat TM/OLI RCSANet Feature relation between image pixels [117] Sentinel-1 Segmentation algorithm Novel data [87] GF-2/GF-1 Semi-SSN,FCN8s,Unet,SegNet,HDCUNet Difficulty in labeling [145] NOAA-17,METOP-1,METOP-2 DEEPFISHNETS,BILSTM,SVM, GBDT,RF,KNN,NB,ANN Hybrid prediction architecture [139] GF-1 HCN,DS-HCN,DeepLab Difficulty in labeling [76] IKONOS LM,GAM,Bagging,RF,Boosted trees,SVM Multidimensional variable combination [84] Drone image YOLOv3 Reduce data volume [197] Video Mask R-CNN Novel data [19] MOD09GA,Landsat-7, Landsat-8,GSW,JRC XGBoost,DNN,RF Multidimensional variable combination [164] Camera photograph VNN Southern Rock Lobster biometric solution [109] Mobile phone photo CNN Fish species identification of aggressive behavior during interactions between individuals. Research on these behaviors has been conducted in [43,159].


### Other topics.

Automatic techniques of animal product generation are increasingly important aspects of modern animal husbandry. For example, image processing techniques can be used to determine the optimal storage conditions for meat. While [123] uses visible and NIR hyperspectral images to determine whether meat is fresh or not. This approach can accurately identify the freshness of the meat, ensuring food safety. In addition, AI methods have been also utilized for monitoring animal husbandry fences and poultry houses [216].

3.3.4 Summary. AI technologies including statistical ML and DL methods have been widely utilized in the animal husbandry system. We conduct a statistical analysis of various AI models used in animal husbandry researches across 69 articles, among them, about 30% of the articles use the RF model, 25% of them adopt SVM and ANN models, and about 10% of them resort to deep learning models.


## Artificial Intelligence Methods in Fishery

3.4.1 Fishing area identification and prediction. The identification and prediction of fishing areas have become increasingly important in the era of large-scale fishery exploitations. The availability of dynamic marine ecological data is crucial for ensuring the safety of fisheries, forecasting fishing opportunities, assessing fisheries resources, and managing fishing operations. Table 4 summarizes typical works on fishery-related tasks with AI algorithms.

The scale of the farming area is a critical factor in determining fishery production [21,117,192]. Obtaining a quick and accurate estimation of the large-scale regional farming area can provide an overall understanding of the farming status. To achieve this, [21] proposes a new semantic segmentation network, i.e., the hybrid dilated convolution U-Net (HDCUNet), which combines U-Net with hybrid expanded convolution to extract coastal aquaculture areas from GF-2

images. This approach solves the issue of misclassifying floating objects on the water surface as aquaculture areas and achieves an overall accuracy of 99.2%. In recent studies, with the RS images, researchers have focused on the geometric features to extract aquaculture pond areas [192,193]. Concretely, [192] involves extracting water surfaces from satellite images and performing boundary tracking for each water segment. The geometric features such as perimeter, curvature, and contour-based regularity of the water surface objects are then evaluated using SVM to extract aquaculture ponds. [193] considers the same directional correlation between pixels of aquaculture ponds. For this purpose, based on the extracted features by the FCN, they separately use row and column self-attentions to extract aquaculture ponds from high spatial resolution RS images. In addition to optical RS images, other waveband data such as SAR images are also leveraged in some studies. For example, [117] extracts aquaculture ponds based on backscatter intensity, size, and shape features.

The rational increase of potential fishing areas [87,139,145] is a crucial factor in maintaining the continuous growth of marine fisheries. To achieve this, [139] proposes an automatic raft-by-pixel labeling method using a fully convolutional dual-scale network structure that captures intricate details without downsampling. In contrast, [87] utilizes pseudo-labels generated by conditional generative adversarial nets to improve extraction accuracy, particularly in expanding sample size. They perform interactive tagging experiments on three RS images with different resolutions to simulate a real-life scenario where the spatial resolution of the images to be processed does not match the available sample's spatial resolution, achieving an overall accuracy of 90.6%. For predicting potential fishing areas, [145] proposes a network structure named hybrid ensemble deepfishnets that integrates deep convolutional networks and filter bat recurrent neural networks, achieving remarkable performance.

3.4.2 Fish production forecast. The ongoing advancement of spatial observation technology has substantially bolstered the capacity to conduct interdisciplinary research on AI within the fisheries domain. Presently, it is feasible to acquire copious amounts of synchronous and dynamic information regarding fish culture areas, which has enhanced the ability to conduct comprehensive studies. Environmental data from potential fishery culture areas can also be collected and analyzed qualitatively to determine the distribution characteristics of fish organisms. These data can then be used to support yield prediction and optimization of fish products, ultimately improving the sustainability and efficiency of fishery management practices. Overall, these advancements in observation technology and research methods have improved our understanding of fish production and are essential for effective fisheries management.

In [76], habitat variables from IKONOS data are combined with ML and statistical models to estimate the species richness and biomass of fish communities around two coral reefs in Zanzibar. The Bagging model is found to be the most accurate, with a root mean squared error (RMSE) of 0.73. Additionally, yield predictions have been made for specific species, such as sea cucumbers. For example, [84] uses the object detector YOLOv3 [129] to detect sea cucumbers from UAV images of Hideaway Bay, Queensland, Australia, providing the first example of applying a DL model to quantify the number and density of sea cucumbers over a large area. Besides RS data, other types of data have also been utilized in fishery research. [197] creates a benchmark of a large-scale underwater video dataset for training the mask R-CNN model, which is used to detect and classify underwater organisms with an mAP of 0.628. In [19], ML algorithms are used to simulate the effects of environmental variables on fish catches, finding that the catches of aquatic biological clocks in Poyang Lake are highly susceptible to hydrometeorological conditions (R = 0.9). The results of this study can provide strong support for guiding fisheries conservation and management and have achieved the goal of increasing yield.

Overall, these studies showcase the potential of utilizing various types of data and AI techniques in fishery research for a better understanding and management of aquatic resources.

Besides, real-time detection techniques have been developed to facilitate the capture and monitoring of underwater fish or crabs. However, the collection and labeling of large-scale datasets is a labor-intensive task. To address this issue, synthetic data techniques have been incorporated. For example, researchers in [104] use synthetic data to improve the accuracy of detecting western rock lobsters.


### Fish product classification.

Unlike crops and animal husbandry products, fishery products are typically alive and cannot be easily labeled using tools like radio frequency identification. As a result, supply chains of fishery products rely on individual recognition techniques, such as those used for lobsters [164]. In addition, CNNs are employed to distinguish between different fish categories [109].


# CHALLENGES

Despite the great potential of AI technology in agrifood systems, challenges still exist. In this context, we summarize five challenges related to agricultural characteristics, external factors, data acquisition and processing, model design and maintenance, and ethical risks.

Agricultural characteristics Agricultural production has unique characteristics such as regionality and seasonality. These characteristics pose new challenges for the application of AI in agriculture. For example, AI models should consider the wide range of agrifood products produced in different regions, while the long growth cycle of crops can limit the real-time performance of technologies. Therefore, it is essential to consider the characteristics of agricultural activities when designing AI solutions.

External factors Agricultural activities are affected by multiple natural conditions, such as water resources, soil nutrients, terrains, and climates. Climate factors, including light and precipitation, are considered major impact factors on agrifood industries. However, developing AI models that are robust across different climates, especially in regions with extreme or unpredictable weather, can be challenging. Furthermore, some adverse conditions, such as weak network infrastructure in rural areas of developing countries, can limit the integration of AI, IoT, and agriculture.

Data acquisition and processing Agricultural practices are long and complex processes, and relying solely on a single data resource may not lead to effective judgments and expected outcomes. In the agrifood system, data is often heterogeneous as it is obtained from various sources and stored in multiple databases with diverse formats, following a series of preprocessing procedures. Attaining high efficiency in the acquisition, integration, and collaboration of multimodal data has emerged as a major challenge in the implementation of agricultural AI.

Model design and maintenance Designing algorithms with a large amount of data for complex agrifood systems is typically a time-consuming process. Additionally, the resulting AI models can be sophisticated and have high computational complexity, making deployment difficult for farmers. Furthermore, maintaining and updating these models is crucial to meet continuous new demands throughout the long growth cycle. This poses a new challenge for AI service providers.

Ethical risks In addition to accuracy, efficiency, and practicality, it is important to consider the ethical risks associated with adopting AI models. AI solutions are frequently employed in critical decision-making scenarios that involve access to private data. Improper use of such data can result in various legal issues, such as privacy breaches and malicious attacks. Lack of transparency can undermine the trust of farmers and consumers, leading to their reluctance to adopt AI solutions and hindering the development of AI technologies. Therefore, constructing trustworthy AI systems is an urgent and significant issue that demands immediate attention and resolution. Fig. 12. AI models enable reading agrifood product information. The results are obtained by DeepSolo [187] with ViTAEv2-S [204].


# OPPORTUNITIES


## Foundation Models Contribute Modern Agricultural Systems

5.1.1 Large-scale data pre-training. DL models designed for specific agrifood tasks have shown impressive performance, but they require large amounts of task-specific data and careful model design. Recently, large foundation models are attracting increasing attention because of their great potential across various domains [20,91,204]. Typically, these models are pre-trained on large-scale data [32], either supervised or unsupervised, and possess exceptional generalization ability due to their extracted representative features. As a result, they can adapt well to various tasks by fine-tuning with only a fraction of task-specific data. For instance, the pre-trained chatGPT model [14,118] can perform translation or math tasks with just a few prompt sentences. To more intuitively demonstrate the capabilities of large models, we finetune different ImageNet pre-trained models on the grocery store dataset [75], which is used for agrifood image recognition. Fig. 11 (a) depicts that, under the same finetuning setting, the performance of ViTAE-B [184] is superior to classical ViT-B [32] and ResNet-50 [55], and the accuracy can be further increased when enlarging the model capacity. While the heatmaps in Fig. 11 (b) indicate the advanced ViTAE model can accurately perceive the agrifood information inside images. The desirable property of large models reduces the need for collecting and annotating a large amount of data in agrifood systems while achieving better performance. Additionally, the long-term Manuscript submitted to ACM cycle and large-span properties of agrifood data provide a wealth of information that can be leveraged for pre-training large models, making them well-suited for use in agrifood systems.


## 5.1.2

The collaboration of multiple sources data. Foundation models possess an important property that allows them to use multiple types of data jointly to achieve more accurate predictions [126]. Agrifood data comes from various sources, such as satellites, UAVs, and other sensors. However, current approaches typically rely on a single data type as input and overlook the complementary between diverse data sources. Foundation models have the potential to learn from these data jointly, which could improve prediction accuracy for tasks such as crop yield prediction or pasture monitoring. By using visual images from UAVs, RS images from satellites, and soil and climate conditions from sensors as inputs, foundation models can provide more accurate and comprehensive results.


### Unifying different tasks.

Current methods tend to design one method for each specific task. Although they have obtained superior performance in agrifood systems, such a modeling pipeline introduces extra deployment costs as we need to design and adapt different models for different tasks. It also should be noted that foundation models have the potential to unify different tasks using a single model [189]. For example, (OFA) [173] jointly model detection, segmentation, and (VQA) tasks within one model. Such a joint modeling pipeline can help the foundation model efficiently leverage the labeling information provided by different tasks and obtain better performance in different tasks.


### Cross-domain foundation models.

Except for the applications discussed in this paper, the large-scale foundation models can provide more opportunities for a better agrifood system. For example, large-scale models can be used to predict future climates and help farmers make better decisions regarding the harvesting and seeding time [127].

The medical foundation model contributes to the discovery of better fertilizer and helps identify sick animals. The biology-related foundation models [24] may help the researchers by alleviating their cost of finding better hybrid plants by predicting the properties of specific hybrid plants given the parent plants growth situation.


## Trustworthy AI Technologies Rebuild Our Agrifood systems

5.2.1 Safe and traceable technology. As one of the foundation systems in society, the security and trustworthiness of AI techniques are essential for modern and safe agrifood systems. For example, the techniques like blockchain [209] and smart sensors [201] can be used to monitor the growth of agrifood, detect contaminants, and predict food safety risks. They can also be used to enhance supply chain management by providing a secure and transparent record of food production and distribution and reducing the risk of fraud. Text detection and recognition AI models [34,56,187] enable reading product information of agrifood (as shown in Fig. 12) and provide means for tracing agrifood. These changes will improve public trust in modern agrifood systems.


### Interpretable AI.

Although AI technologies such as DL have greatly benefited the agrifood system and contributed to modern agrifood systems like precision agriculture technology, understanding the decision mechanism behind AI is still worth further exploration. For example, although DL can make accurate predictions about the crop yield, it

can not explain which key elements it chooses and how it balances them in making the predictions. Such a black-box property may restrict their further applications in agrifood systems and make it hard for researchers to improve these models. The interpretable AI technologies, instead, focus on revealing the dark secrets behind the AI technologies and help AI make explainable decisions regarding the key elements and the logic it considers in prediction. With such interpretable AI technologies, users can gradually put more trust in the AI systems with informed decisions and improve the prediction results, establishing a trustworthy relationship between the model and the user.


### Robust models.

Apart from the above opportunities, the robustness of the AI models is also an important topic in agrifood systems. Due to the influence of weather change or location variants, the captured data may have significantly different distributions from the data used in training. Making the models robust to data with different distributions can greatly simplify the deployment of AI technologies in agrifood systems and improve the reliability of the prediction results made by AI. Apart from algorithm development, hardware systems have also experienced rapid development. AIoT in the agrifood system can also present several key opportunities [201]. For example, the fog and cloud computational systems can provide timely feedback and analysis according to the data captured from edge devices. In this case, advanced IoT devices can help users to make more informed predictions. Besides, the advanced sensors can monitor the health of animals or agriculture in real-time, which can be used to further improve food security and contribute to the development of traceable AI in agrifood systems. Fig. 13 portrays a promising vision of integrating modern AI technologies, including large foundation models, into the IoT ecosystem. This involves utilizing the vast amount of agrifood data collected by edge devices to either pre-train foundation models or automatically label them using well-trained foundation models on cloud servers. Subsequently, the acquired knowledge of these large foundation models can be distilled and transferred to smaller models, thereby enabling their deployment on edge devices. This process creates a closed-loop evolution framework for the agrifood system.


## IoT Technologies Reshape the Agrifood systems


# CONCLUSION

In this survey, we systematically investigate the implications of AI technologies on reshaping the agrifood industry.

First, we provide an overview of the agriculture data involved in applying AI models, covering the perspectives of source, storage, and processing. Next, we summarize the existing AI methods, including traditional ML methods and recent popular DL models, which are widely used in agrifood systems. We then conduct a detailed review of various AI applications in diverse agricultural fields, such as planting, husbandry, and fishery. Our focus lies primarily on the utilization of AI for identification, monitoring, and prediction tasks while also covering a range of subtopics within these stages. Finally, we discuss the opportunities and challenges of integrating AI and agriculture fields. We hope this survey could reveal the immense potential of AI in agrifood systems, stimulate discussions on the reasonable use of AI technologies in agriculture, and inspire further research and practical implementation of AI in agriculture, with the goal of enhancing the productivity, efficiency, safety, and sustainability of our agrifood systems.

Manuscript submitted to ACM

## Fig. 1 .
1Example of optical images: Hyperspectral, Multi-spectral, and Panchromatic.

## Fig. 2 .
2UAVs equipped with multiple sensors simultaneously.


the research purpose, RS-based agrifood classification mainly includes 1) multi-type crop classification which aims at identifying all the crop types in study areas; 2) single-type crop identification and characterization which aims at identifying only the interested crop type; and 3) single-type cropland classification which aims at classifying all types of crops into cropland. Generally, the methods for these tasks consist of feature extraction and classification processes. Recently, an increasing number of ML and DL methods have been proposed for agrifood classification and delivered good performances.

## Fig. 3 .
3Illustration of 3 common agrifood classification tasks.

## Fig. 4 .
4Comparison of (a) traditional methods and (b) learning-based AI methods in Agrifood growth monitoring.

## Fig. 5 .
5Comparison of classification and segmentation networks in weed extraction.

## Fig. 6 .
6The general flowchart of yield prediction.

## Fig. 8 .
8Detection results of Sparse R-CNN [151] using the ViTAEv2-S [204] backbone on the Global Wheat Detection dataset.

## Fig. 9 .
9The general flowchart of agrifood quality inspection.


. Experimental results show that, when employing the ResNet-101, although the network has a parameter amount of up to 125.4M, it still performs worse than using the lightweight ViTAE-S, i.e., 41.2 mean average precision (mAP) v.s. 45.2 mAP. Some detection results of ViTAEv2-S are visualized in Fig. 8. The number and size of detected wheat instances can be used as indicators for yield prediction.

## Fig. 10 .
10Pose estimation lays the foundation for skeleton-based action recognition and behavior analysis. (a) Eating. (b) Walking.

## Fig. 11 .
11Performances of large vision models on Grocery Store dataset. (a) Larger ViTAE models deliver higher accuracy than existing classical models. (b) ViTAE model assigns high responsibilities to the region of agrifood.

## Fig. 13 .
13Combining AI and IoT creates a closed-loop evolution framework for the agrifood system.

## Table 1 .
1Details of existing optical remote sensing satellites.Satellite/Sensor 
Resolution(m) 
Reference 

Sentinel-3 
1200 
[46] 

MODIS 
250/500/1000 
[4, 46, 51, 63, 66, 150, 211] 

Sentinel-2 
10/20/60 
[72, 89, 212] 

HJ-1A*, HJ-1B 
30 
[65, 213] 

EO-1* 
30 
[13] 

Landsat 4-5 
30 
[134] 

Landsat 7 
15 
[19, 142] 

Landsat 8 
15 
[83, 142, 182, 205] 

ASTER Terra 
15 
[121] 

GF-1 
2 (PAN), 8 (PMS) 
[87] 

GF-2 
1 (PAN), 4 (PMS) 
[21] 

GF-6 
2 (PAN), 8 (PMS) 
[149] 

RapidEye 
5 
[11] 

PlanetScope 
3 
[120] 




performance. Researchers thus have increasingly focused on exploring the use of deep neural networks in various applications in agriculture, resulting in numerous methods for tackling diverse tasks. In the context of computer vision, deep neural networks typically comprise a backbone and task-specific heads that specialize in different tasks. In agricultural applications that involve structural data, such as images, the most commonly used backbones are CNNs, 3D3.1 Brief Categorization of Existing Methods 

3.1.1 Traditional machine learning methods. There are a large number of long-standing traditional ML methods popular, 
such as k-nearest neighbor (KNN), Decision Tree (DT), gaussian process regression (GPR), SVM, RF, extreme gradient 

boosting (XGBoost), etc. In the field of agriculture, traditional methods primarily focus on crop classification, growth 

monitoring, yield prediction, and quality assessment, and various learning tasks have been formulated within these 

four research perspectives. For example, decision trees, SVMs, and gradient-boosting decision trees (GBDT) have been 

employed by researchers to identify a range of crops, including coffee, wheat, corn, rice, etc. Besides, SVM, principal 

component analysis (PCA), LDA, and KNN are common techniques used to analyze various types of images for tasks 

such as soil moisture monitoring, crop diseases monitoring, and biomass estimation. Apart from crops, traditional 

ML methods also play important roles in various topics in animal husbandry including pasture monitoring, animal 

recognition, and animal behavior monitoring. For fishery, they are improving fishing area identification and production 

forecast domains. 

3.1.2 Deep learning methods. With the continuous increase of computing resources and data scales, DL has emerged 
as a powerful tool for deep feature extraction from raw images, surpassing traditional ML approaches in terms of 



## Table 2 .
2Summary of agrifood growth monitoring methods based on remote sensing and machine learning.Author 
Year 
Field 
Description 
Reference 

Babaeian et al. 
2021 
EM 
AutoML platform embedded with many machine learning models is used to 
detect soil moisture content 
[7] 

Wang et al. 
2021 
CGSM 
UR, MC, PLSR, ANN, RF, and SVM are used to evaluate the nutrient elements 
in whole rice crop growth stages based on the UAV hyperspectral image 
[171] 

Zhou et al. 
2016 
BE 
A wheat biomass estimation method based on the combination of HJ-CCD 
vegetation index and RF is proposed 
[213] 

Bahrami et al. 
2021 
BE 
SVM, RF, GBDT, XGBoost, and a DNN are used to estimate leaf area index and 
biomass of three crops based on radar and optical earth detection. 
[11] 

Geng et al. 
2021 
BE 
RF, SVM, ANN, and XGBoost are used to estimate seasonal corn biomass based on 
field observation data and MODIS reflectance data from 2012 to 2019 
[11] 

Perez-Ortiz et al. 
2015 
WE 
A system is proposed for drawing weed maps using UAVs images which add 
Hough transform to detect crop row information to improve the accuracy 
[122] 

Reedha et al. 
2022 
WE 
ViT model is used to classify weeds and crops combined with high-resolution 
images obtained by UAV 
[130] 

Alsuwaidi et al. 
2018 
CDAP 

An classification framework which integrates adaptive feature selection, 
novelty detection and integrated learning is proposed to detect plant diseases 
and stress conditions and classify crop types based on hyperspectral data 

[5] 

Shin et al. 
2020 
CDAP 
Three feature extraction methods (HOG, SURF, and GLCM) and two classifiers 
(ANN and SVM) are used to detect strawberry powdery mildew 
[140] 

EM=Environmental monitoring; CGSM=Crop growth state monitoring; BE=Biomass estimation; WE=Weed extraction; CDAP=Crop diseases and pest monitoring. 



## Table 3 .
3Summary of yield prediction methods based on RS images and AI technologies.Author 
Model 
Crop 
RS datatype 
RS variable 
Period 

[66] 
MLR, BNN 
barley, canola, 
spring wheat 
MODIS, AVHRR 
NDVI, EVI 
2000-2011 

[42] 
LR, MLR, SMLR, 
PLSR, ANN, RF 
wheat 
UAV 
LAI, Leaf Dry Matter 
2018-2019 

[69] 
RF, XGBoost, Cubist, MLP 
SVR, GP, KNN, MARS 
wheat 
MOD13Q1 
NDVI 
2009-2015 

[48] 
KNNR, NN, DT, SVM, GPR, RF, 
Boost Trees, Bagging Trees 
winter wheat 
MOD13Q1 
NDVI, EVI 
2001-2014 

[72] 
Multiple Regression, RF, SVM 
corn 
Sentinel-2 
Green Normalized Difference 
Vegetation Index 
2016-2018 

[202] 
LASSO, RF, XGBoost, LSTM 
maize 

MOD13A2, 
Contiguous Solar-induced 
Chlorophyll Fluorescence 

EVI, SIF 
2001-2015 

[113] 
2D-CNN 
wheat, barley 
UAV 
NDVI 
2017 

[203] 
LSTM, LASSO, LightGBM 
maize 
Landsat 5, Landsat 7 

NDVI, EVI, Green Normalized 
Difference Vegetation Index, 
Green Chlorophyll 
Vegetation Index, 
Wide Dynamic 
Range Vegetation Index, 
Simple Ratio 

2010-2012 

[63] 
FFNN, 1D-CNN, LSTM, 
1D-CNN+LSTM, LSTM+1D-CNN 
rice 
MOD09A1 

NDVI, OSAVI, EVI, 
Renormalized Difference 
Vegetation Index, 
Modified Triangular 
Vegetation Index 

2011-2017 

[112] 
CNN-LSTM, ConvLSTM, 3D-CNN 
wheat, barley, 
oats 
UAV 
-
2018 




, Landsat imagery and MODIS imagery are combined into the LSTM for yield prediction in maize-growing areas of China, where the LSTM outperforms LASSO and LightGBM algorithms. Similarly, [135] uses multivariate OLS linear regression, RF, and LSTM models to predict soybean yields in southern Brazil, using a combination of MODIS multi-class products, and finds that the LSTM model performs the best. obtain sequence features. Both hybrid models outperform the single models. [112] has indicated that CNN and LSTM can be connected and combined in an improved manner, where CNN-LSTM, ConvLSTM, and 3D-CNN architectures are developed for wheat, barley, and oat yield prediction. [175] creates a two-branch DL model to predict winter wheat yields at the county level in major production areas of China, where the first branch composes of an LSTM network with meteorological and RS data inputs, and the other branch exploits CNNs to model static soil features. [125] constructs a spatial-spectral-temporal neural network by connecting the top of a 3D CNN and several stacked bidirectional LSTM units. They predict winter wheat and maize yields in three regions of China using multispectral and multitemporal MODIS images. The results demonstrate that both types of crop predictions outperform CNN and LSTM models.Several recent studies have explored the feasibility of using spatiotemporal DL architectures to process RS time series 

data for crop yield time series modeling and prediction. In [63], the performances of five different network structures 

((FFNN), 1D-CNN, LSTM, 1D-CNN+LSTM, and LSTM+1D-CNN hybrid models) for the early prediction of rice yield 

are evaluated. In these models, the CNN module is used to extract spatial features, and the LSTM module is used to 

Manuscript submitted to ACM 
Ground truth 
ResNet-50 

ViTAEv2-S 
RVSA 

Ground truth 

ResNet-50 

ViTAEv2-S 

RVSA 
Ground truth ResNet-50 
ViTAEv2-S 
RVSA 

Flue-cured tobacco 

Maize 

Barley rice 

Barley Remote Sensing Dataset 

Fig. 7. Segmentation results on Barley Remote Sensing Dataset using ResNet-50 [55], ViTAEv2-S [204] and RVSA [169] as the 
backbone of UperNet [179], respectively. 



## Table 3
3summarizes some work on crop yield prediction using RS images with a series of AI technologies including linear, non-linear, ensemble ML models and deep networks. Besides classification, segmentation can also be used for yield prediction. For this purpose, on the barley RS dataset 2 , we utilize the UperNet[179] as the segmentation framework to segment the regions of flue-cured tobacco, maize, and barley rice, where three different backbone networks includingResNet-50 [55], ViTAEv2-S [204] and RVSA [169] are employed. To reduce the domain gap and improve performance, 

ResNet-50 and ViTAEv2-S are pre-trained on a large-scale RS dataset following [168]. We show the segmentation 

results in terms of the mean intersection over union (mIOU) in the upper-left of Fig. 7. Compared to classical ResNet-50, 

the models with advanced vision transformer structures deliver higher accuracy. Among them, RVSA performs the 

best since it is designed specifically for RS tasks by considering the characteristics of RS targets. Fig. 7 also provides 

the segmentation maps of three typical areas, demonstrating that the advanced vision transformer model generates 

fewer misclassified results. The segmentation map provides a direct measure for area estimation, which is useful for 

large-scale yield prediction. 

2 https://tianchi.aliyun.com/dataset/dataDetail?dataId=74952 

We have compiled a comprehensive list of abbreviations used in this paper, which can be found inTable 5at the end of this manuscript.Manuscript submitted to ACMRevolutionizing Agrifood Systems with Artificial Intelligence: A Survey
Manuscript submitted to ACM
https://www.kaggle.com/competitions/global-wheat-detection/overview Manuscript submitted to ACM
A ABBREVIATIONIn this appendix, we summarize the abbreviations used in the paper inTable 5.
Sentinel SAR-optical fusion for crop type mapping using deep learning and Google Earth Engine. Jarrett Adrian, Vasit Sagan, Maitiniyazi Maimaitijiang, ISPRS J PHOTOGRAMM. 175Jarrett Adrian, Vasit Sagan, and Maitiniyazi Maimaitijiang. 2021. Sentinel SAR-optical fusion for crop type mapping using deep learning and Google Earth Engine. ISPRS J PHOTOGRAMM 175 (2021), 215-235.

Impact of spatial resolution on the quality of crop yield predictions for site-specific crop management. Al Dhahi, Shammari, M Brett, Chen Whelan, Wang, G V Robert, Mario Bramley, Thomas Fa Fajardo, Bishop, AGR FOREST METEOROL. 310108622Dhahi Al Shammari, Brett M Whelan, Chen Wang, Robert GV Bramley, Mario Fajardo, and Thomas FA Bishop. 2021. Impact of spatial resolution on the quality of crop yield predictions for site-specific crop management. AGR FOREST METEOROL 310 (2021), 108622.

. Nikos Alexandratos, Jelle Bruinsma, World agriculture towards 2030/2050: the 2012 revision. Technical Report. ESA Working paperNikos Alexandratos and Jelle Bruinsma. 2012. World agriculture towards 2030/2050: the 2012 revision. Technical Report. ESA Working paper.

Modeling managed grassland biomass estimation by using multitemporal remote sensing data-A machine learning approach. Iftikhar Ali, Fiona Cawkwell, Edward Dwyer, Stuart Green, IEEE J-STARS. 10Iftikhar Ali, Fiona Cawkwell, Edward Dwyer, and Stuart Green. 2016. Modeling managed grassland biomass estimation by using multitemporal remote sensing data-A machine learning approach. IEEE J-STARS 10, 7 (2016), 3254-3264.

Feature-ensemble-based novelty detection for analyzing plant hyperspectral datasets. Ali Alsuwaidi, Bruce Grieve, Hujun Yin, IEEE J-STARS. 11Ali AlSuwaidi, Bruce Grieve, and Hujun Yin. 2018. Feature-ensemble-based novelty detection for analyzing plant hyperspectral datasets. IEEE J-STARS 11, 4 (2018), 1041-1055.

Remote sensing techniques for soil organic carbon estimation: A review. Theodora Angelopoulou, Nikolaos Tziolas, REMOTE SENS-BASEL. 11676Athanasios Balafoutis, George Zalidis, and Dionysis BochtisTheodora Angelopoulou, Nikolaos Tziolas, Athanasios Balafoutis, George Zalidis, and Dionysis Bochtis. 2019. Remote sensing techniques for soil organic carbon estimation: A review. REMOTE SENS-BASEL 11, 6 (2019), 676.

Estimation of root zone soil moisture from ground and remotely sensed soil information with multisensor data fusion and automated machine learning. Sidike Ebrahim Babaeian, Nahian Paheding, Siddique, K Vijay, Markus Devabhaktuni, Tuller, REMOTE SENS ENVIRON. 260112434Ebrahim Babaeian, Sidike Paheding, Nahian Siddique, Vijay K Devabhaktuni, and Markus Tuller. 2021. Estimation of root zone soil moisture from ground and remotely sensed soil information with multisensor data fusion and automated machine learning. REMOTE SENS ENVIRON 260 (2021), 112434.

Ground, proximal, and satellite remote sensing of soil moisture. Morteza Ebrahim Babaeian, Sadeghi, B Scott, Carsten Jones, Harry Montzka, Markus Vereecken, Tuller, REV GEOPHYS. 57Ebrahim Babaeian, Morteza Sadeghi, Scott B Jones, Carsten Montzka, Harry Vereecken, and Markus Tuller. 2019. Ground, proximal, and satellite remote sensing of soil moisture. REV GEOPHYS 57, 2 (2019), 530-616.

Evaluation of Citrus Gummosis disease dynamics and predictions with weather and inversion based leaf optical model. Mrunalini R Badnakhe, S Surya, Adinarayana Durbha, Rajendra M Jagarlapudi, Gade, COMPUT ELECTRON AGR. 155Mrunalini R Badnakhe, Surya S Durbha, Adinarayana Jagarlapudi, and Rajendra M Gade. 2018. Evaluation of Citrus Gummosis disease dynamics and predictions with weather and inversion based leaf optical model. COMPUT ELECTRON AGR 155 (2018), 130-141.

Segnet: A deep convolutional encoder-decoder architecture for image segmentation. Vijay Badrinarayanan, Alex Kendall, Roberto Cipolla, IEEE T PATTERN ANAL. 39Vijay Badrinarayanan, Alex Kendall, and Roberto Cipolla. 2017. Segnet: A deep convolutional encoder-decoder architecture for image segmentation. IEEE T PATTERN ANAL 39, 12 (2017), 2481-2495.

Deep learning-based estimation of crop biophysical parameters using multi-source and multi-temporal remote sensing observations. Hazhir Bahrami, Saeid Homayouni, Abdolreza Safari, Sayeh Mirzaei, Masoud Mahdianpari, Omid Reisi Gahrouei, AGRONOMY-BASEL. 111363Hazhir Bahrami, Saeid Homayouni, Abdolreza Safari, Sayeh Mirzaei, Masoud Mahdianpari, and Omid Reisi Gahrouei. 2021. Deep learning-based estimation of crop biophysical parameters using multi-source and multi-temporal remote sensing observations. AGRONOMY-BASEL 11, 7 (2021), 1363.

Crop nitrogen monitoring: Recent progress and principal developments in the context of imaging spectroscopy missions. Katja Berger, Jochem Verrelst, Jean Baptiste Feret, Zhihui Wang, Matthias Wocher, Markus Strathmann, Martin Danner, Wolfram Mauser, Tobias Hank, REMOTE SENS ENVIRON. 242111758Katja Berger, Jochem Verrelst, Jean Baptiste Feret, Zhihui Wang, Matthias Wocher, Markus Strathmann, Martin Danner, Wolfram Mauser, and Tobias Hank. 2020. Crop nitrogen monitoring: Recent progress and principal developments in the context of imaging spectroscopy missions. REMOTE SENS ENVIRON 242 (2020), 111758.

Evaluation of deep learning CNN model for land use land cover classification and crop identification using hyperspectral remote sensing images. Kavita Bhosle, Vijaya Musande, J INDIAN SOC REMOTE. 47Kavita Bhosle and Vijaya Musande. 2019. Evaluation of deep learning CNN model for land use land cover classification and crop identification using hyperspectral remote sensing images. J INDIAN SOC REMOTE 47, 11 (2019), 1949-1958.

Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, NIPS2021. 33Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. NIPS2021 33 (2020), 1877-1901.

Integrating satellite and climate data to predict wheat yield in Australia using machine learning approaches. Yaping Cai, Kaiyu Guan, David Lobell, B Andries, Shaowen Potgieter, Jian Wang, Tianfang Peng, Senthold Xu, Yongguang Asseng, Liangzhi Zhang, You, AGR FOREST METEOROL. 274Yaping Cai, Kaiyu Guan, David Lobell, Andries B Potgieter, Shaowen Wang, Jian Peng, Tianfang Xu, Senthold Asseng, Yongguang Zhang, Liangzhi You, et al. 2019. Integrating satellite and climate data to predict wheat yield in Australia using machine learning approaches. AGR FOREST METEOROL 274 (2019), 144-159.

Corn and soybean mapping in the United States using MODIS time-series data sets. Jiyul Chang, C Matthew, Kyle Hansen, Mark Pittman, Charlene Carroll, Dimiceli, AGRON J. 99Jiyul Chang, Matthew C Hansen, Kyle Pittman, Mark Carroll, and Charlene DiMiceli. 2007. Corn and soybean mapping in the United States using MODIS time-series data sets. AGRON J 99, 6 (2007), 1654-1664.

Estimating soil moisture over winter wheat fields during growing season using machine-learning methods. Lin Chen, Minfeng Xing, Binbin He, Jinfei Wang, Jiali Shang, Xiaodong Huang, Min Xu, IEEE J-STARS. 14Lin Chen, Minfeng Xing, Binbin He, Jinfei Wang, Jiali Shang, Xiaodong Huang, and Min Xu. 2021. Estimating soil moisture over winter wheat fields during growing season using machine-learning methods. IEEE J-STARS 14 (2021), 3706-3718.

Encoder-decoder with atrous separable convolution for semantic image segmentation. Yukun Liang Chieh Chen, George Zhu, Florian Papandreou, Hartwig Schroff, Adam, ECCV2018Liang chieh Chen, Yukun Zhu, George Papandreou, Florian Schroff, and Hartwig Adam. 2018. Encoder-decoder with atrous separable convolution for semantic image segmentation. In ECCV2018. 801-818.

Remote sensing modeling of environmental influences on lake fish resources by machine learning: A practice in the largest freshwater lake of China. Tan Chen, Chunqiao Song, Chenyu Fan, Xin Gao, Kai Liu, Zhen Li, Jian Cheng, Pengfei Zhan, FRONT ENV SCI-SWITZ. 1233Tan Chen, Chunqiao Song, Chenyu Fan, Xin Gao, Kai Liu, Zhen Li, Jian Cheng, and Pengfei Zhan. 2022. Remote sensing modeling of environmental influences on lake fish resources by machine learning: A practice in the largest freshwater lake of China. FRONT ENV SCI-SWITZ (2022), 1233.

Xi Chen, Xiao Wang, Soravit Changpinyo, Piotr Piergiovanni, Daniel Padlewski, Sebastian Salz, Adam Goodman, Basil Grycner, Lucas Mustafa, Beyer, arXiv:2209.06794Pali: A jointly-scaled multilingual language-image model. arXiv preprintXi Chen, Xiao Wang, Soravit Changpinyo, AJ Piergiovanni, Piotr Padlewski, Daniel Salz, Sebastian Goodman, Adam Grycner, Basil Mustafa, Lucas Beyer, et al. 2022. Pali: A jointly-scaled multilingual language-image model. arXiv preprint arXiv:2209.06794 (2022).

Research on a novel extraction method using Deep Learning based on GF-2 images for aquaculture areas. Bo Cheng, Chenbin Liang, Xunan Liu, Yueming Liu, Xiaoxiao Ma, Guizhou Wang, INT J REMOTE SENS. 41Bo Cheng, Chenbin Liang, Xunan Liu, Yueming Liu, Xiaoxiao Ma, and Guizhou Wang. 2020. Research on a novel extraction method using Deep Learning based on GF-2 images for aquaculture areas. INT J REMOTE SENS 41, 9 (2020), 3575-3591.

Estimation of soil moisture content under high maize canopy coverage from UAV multimodal data and machine learning. Minghan Cheng, Xiyun Jiao, Yadong Liu, Mingchao Shao, Xun Yu, Yi Bai, Zixu Wang, Siyu Wang, Nuremanguli Tuohuti, Shuaibing Liu, AGR WATER MANAGE. 264107530Minghan Cheng, Xiyun Jiao, Yadong Liu, Mingchao Shao, Xun Yu, Yi Bai, Zixu Wang, Siyu Wang, Nuremanguli Tuohuti, Shuaibing Liu, et al. 2022. Estimation of soil moisture content under high maize canopy coverage from UAV multimodal data and machine learning. AGR WATER MANAGE 264 (2022), 107530.

Xception: Deep learning with depthwise separable convolutions. François Chollet, CVPR2017. François Chollet. 2017. Xception: Deep learning with depthwise separable convolutions. In CVPR2017. 1251-1258.

AlphaFold2 and the future of structural biology. Patrick Cramer, NAT STRUCT MOL BIOL. 28Patrick Cramer. 2021. AlphaFold2 and the future of structural biology. NAT STRUCT MOL BIOL 28, 9 (2021), 704-705.

Predicting pasture biomass using a statistical model and machine learning algorithm implemented with remotely sensed imagery. Daniele De Rosa, Bruno Basso, Matteo Fasiolo, Johannes Friedl, Bill Fulkerson, David W Peter R Grace, Rowlings, COMPUT ELECTRON AGR. 180105880Daniele De Rosa, Bruno Basso, Matteo Fasiolo, Johannes Friedl, Bill Fulkerson, Peter R Grace, and David W Rowlings. 2021. Predicting pasture biomass using a statistical model and machine learning algorithm implemented with remotely sensed imagery. COMPUT ELECTRON AGR 180 (2021), 105880.

Remote sensing-based estimation of rice yields using various models: A critical review. Daniel Marc, G Dela Torre, Jay Gao, Cate Macinnis-Ng, GEO-SPAT INF SCI. 24Daniel Marc G dela Torre, Jay Gao, and Cate Macinnis-Ng. 2021. Remote sensing-based estimation of rice yields using various models: A critical review. GEO-SPAT INF SCI 24, 4 (2021), 580-603.

Analyzing strawberry spoilage via its volatile compounds using longpath fourier transform infrared spectroscopy. Daming Dong, Chunjiang Zhao, Wengang Zheng, Wenzhong Wang, Xiande Zhao, Leizi Jiao, SCI REP-UK. 3Daming Dong, Chunjiang Zhao, Wengang Zheng, Wenzhong Wang, Xiande Zhao, and Leizi Jiao. 2013. Analyzing strawberry spoilage via its volatile compounds using longpath fourier transform infrared spectroscopy. SCI REP-UK 3, 1 (2013), 1-7.

Estimating soil moisture content under grassland with hyperspectral data using radiative transfer modelling and machine learning. Veronika Döpper, Alby Duarte Rocha, Katja Berger, Tobias Gränzig, Jochem Verrelst, Birgit Kleinschmit, Michael Förster, INT J APPL EARTH OBS. 110102817Veronika Döpper, Alby Duarte Rocha, Katja Berger, Tobias Gränzig, Jochem Verrelst, Birgit Kleinschmit, and Michael Förster. 2022. Estimating soil moisture content under grassland with hyperspectral data using radiative transfer modelling and machine learning. INT J APPL EARTH OBS 110 (2022), 102817.

Crop condition and yield simulations using Landsat and MODIS. C Paul, Jerry L Doraiswamy, Thomas J Hatfield, Bakhyt Jackson, Akhmedov, H John, Alan J Prueger, Stern, REMOTE SENS ENVIRON. 92Paul C Doraiswamy, Jerry L Hatfield, Thomas J Jackson, Bakhyt Akhmedov, John H Prueger, and Alan J Stern. 2004. Crop condition and yield simulations using Landsat and MODIS. REMOTE SENS ENVIRON 92, 4 (2004), 548-559.

Application of MODIS derived parameters for regional crop yield assessment. C Paul, Doraiswamy, R Thomas, Steven Sinclair, Bakhyt Hollinger, Alan Akhmedov, John Stern, Prueger, REMOTE SENS ENVIRON. 97Paul C Doraiswamy, Thomas R Sinclair, Steven Hollinger, Bakhyt Akhmedov, Alan Stern, and John Prueger. 2005. Application of MODIS derived parameters for regional crop yield assessment. REMOTE SENS ENVIRON 97, 2 (2005), 192-202.

Interactive multiscale classification of high-resolution remote sensing images. Jefersson Alex Dos Santos, Philippe Henri Gosselin, Sylvie Philipp Foliguet, Ricardo Torres, Alexandre Xavier Falcao, IEEE J-STARS. 6Jefersson Alex dos Santos, Philippe Henri Gosselin, Sylvie Philipp Foliguet, Ricardo da S Torres, and Alexandre Xavier Falcao. 2013. Interactive multiscale classification of high-resolution remote sensing images. IEEE J-STARS 6, 4 (2013), 2020-2034.

. Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, n. d.Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. [n. d.].

An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. 2020An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. In ICLR2020.

Assessment of advanced random forest and decision tree algorithms for modeling rainfall-induced landslide susceptibility in the Izu-Oshima Volcanic Island. Jie Dou, P Ali, Yunus, Tien Dieu, Abdelaziz Bui, Mehebub Merghadi, Zhongfan Sahana, Chi-Wen Zhu, Khabat Chen, Yong Khosravi, Binh Thai Yang, Pham, Japan. SCI TOTAL ENVIRON. 662Jie Dou, Ali P Yunus, Dieu Tien Bui, Abdelaziz Merghadi, Mehebub Sahana, Zhongfan Zhu, Chi-Wen Chen, Khabat Khosravi, Yong Yang, and Binh Thai Pham. 2019. Assessment of advanced random forest and decision tree algorithms for modeling rainfall-induced landslide susceptibility in the Izu-Oshima Volcanic Island, Japan. SCI TOTAL ENVIRON 662 (2019), 332-346.

I3CL: Intra-and Inter-Instance Collaborative Learning for Arbitrary-shaped Scene Text Detection. Bo Du, Jian Ye, Jing Zhang, Juhua Liu, Dacheng Tao, INT J COMPUT VISION. Bo Du, Jian Ye, Jing Zhang, Juhua Liu, and Dacheng Tao. 2022. I3CL: Intra-and Inter-Instance Collaborative Learning for Arbitrary-shaped Scene Text Detection. INT J COMPUT VISION (2022), 1-17.

Remote estimation of grain yield based on UAV data in different rice cultivars under contrasting climatic zone. Bo Duan, Shenghui Fang, Yan Gong, Yi Peng, Xianting Wu, Renshan Zhu, FIELD CROP RES. 267108148Bo Duan, Shenghui Fang, Yan Gong, Yi Peng, Xianting Wu, and Renshan Zhu. 2021. Remote estimation of grain yield based on UAV data in different rice cultivars under contrasting climatic zone. FIELD CROP RES 267 (2021), 108148.

Remote estimation of rice LAI based on Fourier spectrum texture from UAV image. Bo Duan, Yating Liu, Yan Gong, Yi Peng, Xianting Wu, Renshan Zhu, Shenghui Fang, PLANT METHODS. 15Bo Duan, Yating Liu, Yan Gong, Yi Peng, Xianting Wu, Renshan Zhu, and Shenghui Fang. 2019. Remote estimation of rice LAI based on Fourier spectrum texture from UAV image. PLANT METHODS 15, 1 (2019), 1-12.

Inversion of the PROSAIL model to estimate leaf area index of maize, potato, and sunflower fields from unmanned aerial vehicle hyperspectral data. Zhaoliang Sibo Duan, Hua Li, Bohui Wu, Lingling Tang, Enyu Ma, Chuanrong Zhao, Li, INT J APPL EARTH OBS. 26Sibo Duan, Zhaoliang Li, Hua Wu, Bohui Tang, Lingling Ma, Enyu Zhao, and Chuanrong Li. 2014. Inversion of the PROSAIL model to estimate leaf area index of maize, potato, and sunflower fields from unmanned aerial vehicle hyperspectral data. INT J APPL EARTH OBS 26 (2014), 12-20.

An overview of Internet of Things (IoT) and data analytics in agriculture: Benefits and challenges. Olakunle Elijah, Igbafe Tharek Abdul Rahman, Orikumhi, Yen Chee, Leow, Hindia, IEEE INTERNET THINGS. 5Olakunle Elijah, Tharek Abdul Rahman, Igbafe Orikumhi, Chee Yen Leow, and MHD Nour Hindia. 2018. An overview of Internet of Things (IoT) and data analytics in agriculture: Benefits and challenges. IEEE INTERNET THINGS 5, 5 (2018), 3758-3773.

Rice-yield prediction with multi-temporal sentinel-2 data and 3D CNN: A case study in Nepal. Ruben Fernandez Beltran, Tina Baidar, Jian Kang, Filiberto Pla, REMOTE SENS-BASEL. 131391Ruben Fernandez Beltran, Tina Baidar, Jian Kang, and Filiberto Pla. 2021. Rice-yield prediction with multi-temporal sentinel-2 data and 3D CNN: A case study in Nepal. REMOTE SENS-BASEL 13, 7 (2021), 1391.

Estimating pasture quality of Mediterranean grasslands using hyperspectral narrow bands from field spectroscopy by Random Forest and PLS regressions. Mónica Jesús Fernández Habas, Alma María García Carriere Cañada, José Ramón Leal Moreno, María P González Murillo, Dugo, Abellanas Begoña, Pedro J Gómez Oar, Pilar Fernández Giráldez, Rebollo, COMPUT ELECTRON AGR. 192106614Jesús Fernández Habas, Mónica Carriere Cañada, Alma María García Moreno, José Ramón Leal Murillo, María P González Dugo, Begoña Abellanas Oar, Pedro J Gómez Giráldez, and Pilar Fernández Rebollo. 2022. Estimating pasture quality of Mediterranean grasslands using hyperspectral narrow bands from field spectroscopy by Random Forest and PLS regressions. COMPUT ELECTRON AGR 192 (2022), 106614.

An approach to forecast grain crop yield using multi-layered, multi-farm data sets and machine learning. Patrick Filippi, J Edward, Jones, S Niranjan, Wimalathunge, Dsn Pallegedara, Liana E Somarathna, Pozza, U Sabastine, Ugbaje, G Thomas, Stacey E Jephcott, Paterson, M Brett, Thomas Fa Whelan, Bishop, PRECIS AGRIC. 20Patrick Filippi, Edward J Jones, Niranjan S Wimalathunge, Pallegedara DSN Somarathna, Liana E Pozza, Sabastine U Ugbaje, Thomas G Jephcott, Stacey E Paterson, Brett M Whelan, and Thomas FA Bishop. 2019. An approach to forecast grain crop yield using multi-layered, multi-farm data sets and machine learning. PRECIS AGRIC 20, 5 (2019), 1015-1029.

Wheat growth monitoring and yield estimation based on multi-rotor unmanned aerial vehicle. Zhaopeng Fu, Jie Jiang, Yang Gao, Brian Krienke, Meng Wang, Kaitai Zhong, Qiang Cao, Yongchao Tian, Yan Zhu, Weixing Cao, REMOTE SENS-BASEL. 12508Zhaopeng Fu, Jie Jiang, Yang Gao, Brian Krienke, Meng Wang, Kaitai Zhong, Qiang Cao, Yongchao Tian, Yan Zhu, Weixing Cao, et al. 2020. Wheat growth monitoring and yield estimation based on multi-rotor unmanned aerial vehicle. REMOTE SENS-BASEL 12, 3 (2020), 508.

Deep learning-based hierarchical cattle behavior recognition with spatiotemporal information. Alvaro Fuentes, Sook Yoon, Jongbin Park, Dong Sun Park, COMPUT ELECTRON AGR. 177105627Alvaro Fuentes, Sook Yoon, Jongbin Park, and Dong Sun Park. 2020. Deep learning-based hierarchical cattle behavior recognition with spatio- temporal information. COMPUT ELECTRON AGR 177 (2020), 105627.

Modeling alpine grassland forage phosphorus based on hyperspectral remote sensing and a multi-factor machine learning algorithm in the east of Tibetan Plateau. Jinlong Gao, Baoping Meng, Tiangang Liang, Qisheng Feng, Jing Ge, Jianpeng Yin, Caixia Wu, Xia Cui, Mengjing Hou, Jie Liu, China. ISPRS J PHOTOGRAMM. 147Jinlong Gao, Baoping Meng, Tiangang Liang, Qisheng Feng, Jing Ge, Jianpeng Yin, Caixia Wu, Xia Cui, Mengjing Hou, Jie Liu, et al. 2019. Modeling alpine grassland forage phosphorus based on hyperspectral remote sensing and a multi-factor machine learning algorithm in the east of Tibetan Plateau, China. ISPRS J PHOTOGRAMM 147 (2019), 104-117.

Forest biomass estimation from airborne LiDAR data using machine learning approaches. J Colin, Jungho Gleason, Im, REMOTE SENS ENVIRON. 125Colin J Gleason and Jungho Im. 2012. Forest biomass estimation from airborne LiDAR data using machine learning approaches. REMOTE SENS ENVIRON 125 (2012), 80-91.

Evaluating the feasibility of using Sentinel-2 and Sentinel-3 satellites for high-resolution evapotranspiration estimations. Radoslaw Guzinski, Héctor Nieto, REMOTE SENS ENVIRON. 221Radoslaw Guzinski and Héctor Nieto. 2019. Evaluating the feasibility of using Sentinel-2 and Sentinel-3 satellites for high-resolution evapotranspi- ration estimations. REMOTE SENS ENVIRON 221 (2019), 157-172.

Integrated narrow-band vegetation indices for prediction of crop chlorophyll content for application to precision agriculture. Driss Haboudane, R John, Nicolas Miller, Pablo J Zarco Tremblay, Louise Tejada, Dextraze, REMOTE SENS ENVIRON. 81Driss Haboudane, John R Miller, Nicolas Tremblay, Pablo J Zarco Tejada, and Louise Dextraze. 2002. Integrated narrow-band vegetation indices for prediction of crop chlorophyll content for application to precision agriculture. REMOTE SENS ENVIRON 81, 2-3 (2002), 416-426.

Prediction of winter wheat yield based on multi-source data and machine learning in China. Jichong Han, Zhao Zhang, Juan Cao, Yuchuan Luo, Liangliang Zhang, Ziyue Li, Jing Zhang, REMOTE SENS-BASEL. 12236Jichong Han, Zhao Zhang, Juan Cao, Yuchuan Luo, Liangliang Zhang, Ziyue Li, and Jing Zhang. 2020. Prediction of winter wheat yield based on multi-source data and machine learning in China. REMOTE SENS-BASEL 12, 2 (2020), 236.

Modeling maize above-ground biomass based on machine learning approaches using UAV remote-sensing data. Liang Han, Guijun Yang, Huayang Dai, Bo Xu, Hao Yang, Haikuan Feng, Zhenhai Li, Xiaodong Yang, PLANT METHODS. 15Liang Han, Guijun Yang, Huayang Dai, Bo Xu, Hao Yang, Haikuan Feng, Zhenhai Li, and Xiaodong Yang. 2019. Modeling maize above-ground biomass based on machine learning approaches using UAV remote-sensing data. PLANT METHODS 15, 1 (2019), 1-19.

Towards on-farm pig face recognition using convolutional neural networks. Melvyn L Mark F Hansen, Lyndon N Smith, Smith, G Michael, Emma M Salter, Marianne Baxter, Bruce Farish, Grieve, COMPUT IND. 98Mark F Hansen, Melvyn L Smith, Lyndon N Smith, Michael G Salter, Emma M Baxter, Marianne Farish, and Bruce Grieve. 2018. Towards on-farm pig face recognition using convolutional neural networks. COMPUT IND 98 (2018), 145-152.

Estimation of crop evapotranspiration from MODIS data by combining random forest and trapezoidal models. Pengyu Hao, Liping Di, Liying Guo, AGR WATER MANAGE. 259107249Pengyu Hao, Liping Di, and Liying Guo. 2022. Estimation of crop evapotranspiration from MODIS data by combining random forest and trapezoidal models. AGR WATER MANAGE 259 (2022), 107249.

A survey of deep learning techniques for weed detection from images. Ferdous Asm Mahmudul Hasan, Dean Sohel, Hamid Diepeveen, Laga, Jones, COMPUT ELECTRON AGR. 184106067ASM Mahmudul Hasan, Ferdous Sohel, Dean Diepeveen, Hamid Laga, and Michael GK Jones. 2021. A survey of deep learning techniques for weed detection from images. COMPUT ELECTRON AGR 184 (2021), 106067.

Detection and analysis of wheat spikes using convolutional neural networks. Joshua P Md Mehedi Hasan, Hamid Chopin, Stanley J Laga, Miklavcic, PLANT METHODS. 14Md Mehedi Hasan, Joshua P Chopin, Hamid Laga, and Stanley J Miklavcic. 2018. Detection and analysis of wheat spikes using convolutional neural networks. PLANT METHODS 14, 1 (2018), 1-13.

Harvest index: a review of its use in plant breeding and crop physiology. Hay, ANN APPL BIOL. 126RKM Hay. 1995. Harvest index: a review of its use in plant breeding and crop physiology. ANN APPL BIOL 126, 1 (1995), 197-216.

Deep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, CVPR2016. 770-778Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In CVPR2016. 770-778.

Visual Semantics Allow for Textual Reasoning Better in Scene Text Recognition. Yue He, Chen Chen, Jing Zhang, Juhua Liu, Fengxiang He, Chaoyue Wang, Bo Du, 36Yue He, Chen Chen, Jing Zhang, Juhua Liu, Fengxiang He, Chaoyue Wang, and Bo Du. 2022. Visual Semantics Allow for Textual Reasoning Better in Scene Text Recognition. 36 (2022).

G Andrew, Menglong Howard, Bo Zhu, Dmitry Chen, Weijun Kalenichenko, Tobias Wang, Marco Weyand, Hartwig Andreetto, Adam, arXiv:1704.04861Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprintAndrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. 2017. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861 (2017).

Pixel size of aerial imagery constrains the applications of unmanned aerial vehicle in crop breeding. Pengcheng Hu, Wei Guo, C Scott, Yan Chapman, Bangyou Guo, Zheng, ISPRS J PHOTOGRAMM. 154Pengcheng Hu, Wei Guo, Scott C Chapman, Yan Guo, and Bangyou Zheng. 2019. Pixel size of aerial imagery constrains the applications of unmanned aerial vehicle in crop breeding. ISPRS J PHOTOGRAMM 154 (2019), 1-9.

Depth semantic segmentation of tobacco planting areas from unmanned aerial vehicle remote sensing images in plateau mountains. Liang Huang, Xuequn Wu, Qiuzhi Peng, Xueqin Yu, J SPECTROSC. 2021Liang Huang, Xuequn Wu, Qiuzhi Peng, and Xueqin Yu. 2021. Depth semantic segmentation of tobacco planting areas from unmanned aerial vehicle remote sensing images in plateau mountains. J SPECTROSC 2021 (2021), 1-14.

Recent advances in crop water stress detection. O Samuel, Chandra A Ihuoma, Madramootoo, COMPUT ELECTRON AGR. 141Samuel O Ihuoma and Chandra A Madramootoo. 2017. Recent advances in crop water stress detection. COMPUT ELECTRON AGR 141 (2017), 267-275.

Machine learning and deep learning. Christian Janiesch, Patrick Zschech, Kai Heinrich, ELECTRON MARK. 31Christian Janiesch, Patrick Zschech, and Kai Heinrich. 2021. Machine learning and deep learning. ELECTRON MARK 31, 3 (2021), 685-695.

Retrieving LAI, chlorophyll and nitrogen contents in sugar beet crops from multi-angular optical remote sensing: Comparison of vegetation indices and PROSAIL inversion for field phenotyping. Sylvain Jay, Fabienne Maupas, Ryad Bendoula, Nathalie Gorretta, FIELD CROP RES. 210Sylvain Jay, Fabienne Maupas, Ryad Bendoula, and Nathalie Gorretta. 2017. Retrieving LAI, chlorophyll and nitrogen contents in sugar beet crops from multi-angular optical remote sensing: Comparison of vegetation indices and PROSAIL inversion for field phenotyping. FIELD CROP RES 210 (2017), 33-46.

Predicting rice yield at pixel scale through synthetic use of crop and deep learning models with satellite data in South and North Korea. Seungtaek Jeong, Jonghan Ko, Jong Min Yeom, SCI TOTAL ENVIRON. 802149726Seungtaek Jeong, Jonghan Ko, and Jong Min Yeom. 2022. Predicting rice yield at pixel scale through synthetic use of crop and deep learning models with satellite data in South and North Korea. SCI TOTAL ENVIRON 802 (2022), 149726.

Single-stream long-term optical flow convolution network for action recognition of lameness dairy cow. Bo Jiang, Xuqiang Yin, Huaibo Song, COMPUT ELECTRON AGR. 175105536Bo Jiang, Xuqiang Yin, and Huaibo Song. 2020. Single-stream long-term optical flow convolution network for action recognition of lameness dairy cow. COMPUT ELECTRON AGR 175 (2020), 105536.

Method for mapping rice fields in complex landscape areas based on pre-trained convolutional neural network from HJ-1 A/B data. Tian Jiang, Xiangnan Liu, Ling Wu, ISPRS INT J GEO-INF. 7418Tian Jiang, Xiangnan Liu, and Ling Wu. 2018. Method for mapping rice fields in complex landscape areas based on pre-trained convolutional neural network from HJ-1 A/B data. ISPRS INT J GEO-INF 7, 11 (2018), 418.

Crop yield forecasting on the Canadian Prairies by remotely sensed vegetation indices and machine learning methods. D Michael, Johnson, W William, Alex J Hsieh, Andrew Cannon, Frédéric Davidson, Bédard, AGR FOREST METEOROL. 218Michael D Johnson, William W Hsieh, Alex J Cannon, Andrew Davidson, and Frédéric Bédard. 2016. Crop yield forecasting on the Canadian Prairies by remotely sensed vegetation indices and machine learning methods. AGR FOREST METEOROL 218 (2016), 74-84.

The potential of remote sensing and artificial intelligence as tools to improve the resilience of agriculture production systems. Jinha Jung, Murilo Maeda, Anjin Chang, Mahendra Bhandari, Akash Ashapure, Juan Landivar Bowles, CURR OPIN BIOTECH. 70Jinha Jung, Murilo Maeda, Anjin Chang, Mahendra Bhandari, Akash Ashapure, and Juan Landivar Bowles. 2021. The potential of remote sensing and artificial intelligence as tools to improve the resilience of agriculture production systems. CURR OPIN BIOTECH 70 (2021), 15-22.

Deep learning in agriculture: A survey. Andreas Kamilaris, Francesc X Prenafeta Boldú, COMPUT ELECTRON AGR. 147Andreas Kamilaris and Francesc X Prenafeta Boldú. 2018. Deep learning in agriculture: A survey. COMPUT ELECTRON AGR 147 (2018), 70-90.

Estimating wheat yields in Australia using climate records, satellite image time series and machine learning methods. Elisa Kamir, François Waldner, Zvi Hochman, ISPRS J PHOTOGRAMM. 160Elisa Kamir, François Waldner, and Zvi Hochman. 2020. Estimating wheat yields in Australia using climate records, satellite image time series and machine learning methods. ISPRS J PHOTOGRAMM 160 (2020), 124-135.

Image masking for crop yield forecasting using AVHRR NDVI time series imagery. H Jude, Kastens, L Terry, Kastens, L A Dietrich, Kevin P Kastens, Price, A Edward, Re Yang Martinko, Lee, REMOTE SENS ENVIRON. 99Jude H Kastens, Terry L Kastens, Dietrich LA Kastens, Kevin P Price, Edward A Martinko, and Re Yang Lee. 2005. Image masking for crop yield forecasting using AVHRR NDVI time series imagery. REMOTE SENS ENVIRON 99, 3 (2005), 341-356.

Review on Convolutional Neural Networks (CNN) in vegetation remote sensing. Teja Kattenborn, Jens Leitloff, Felix Schiefer, Stefan Hinz, ISPRS J PHOTOGRAMM. 173Teja Kattenborn, Jens Leitloff, Felix Schiefer, and Stefan Hinz. 2021. Review on Convolutional Neural Networks (CNN) in vegetation remote sensing. ISPRS J PHOTOGRAMM 173 (2021), 24-49.

Monitoring within-field variability of corn yield using Sentinel-2 and machine learning techniques. Ahmed Kayad, Marco Sozzi, Simone Gatto, Francesco Marinello, Francesco Pirotti, REMOTE SENS-BASEL. 112873Ahmed Kayad, Marco Sozzi, Simone Gatto, Francesco Marinello, and Francesco Pirotti. 2019. Monitoring within-field variability of corn yield using Sentinel-2 and machine learning techniques. REMOTE SENS-BASEL 11, 23 (2019), 2873.

Integration of high resolution remotely sensed data and machine learning techniques for spatial prediction of soil properties and corn yield. Sami Khanal, John Fulton, Andrew Klopfenstein, Nathan Douridas, Scott Shearer, COMPUT ELECTRON AGR. 153Sami Khanal, John Fulton, Andrew Klopfenstein, Nathan Douridas, and Scott Shearer. 2018. Integration of high resolution remotely sensed data and machine learning techniques for spatial prediction of soil properties and corn yield. COMPUT ELECTRON AGR 153 (2018), 213-225.

Remote sensing in agriculture-accomplishments, limitations, and opportunities. Sami Khanal, Kushal Kc, P John, Scott Fulton, Erdal Shearer, Ozkan, REMOTE SENS-BASEL. 123783Sami Khanal, Kushal Kc, John P Fulton, Scott Shearer, and Erdal Ozkan. 2020. Remote sensing in agriculture-accomplishments, limitations, and opportunities. REMOTE SENS-BASEL 12, 22 (2020), 3783.

A hierarchical grocery store image dataset with visual and semantic labels. Marcus Klasson, Cheng Zhang, Hedvig Kjellström, WACV2019. IEEE. Marcus Klasson, Cheng Zhang, and Hedvig Kjellström. 2019. A hierarchical grocery store image dataset with visual and semantic labels. In WACV2019. IEEE, 491-500.

Predictive mapping of reef fish species richness, diversity and biomass in Zanzibar using IKONOS imagery and machine-learning techniques. Anders Knudby, Ellsworth Ledrew, Alexander Brenning, REMOTE SENS ENVIRON. 114Anders Knudby, Ellsworth LeDrew, and Alexander Brenning. 2010. Predictive mapping of reef fish species richness, diversity and biomass in Zanzibar using IKONOS imagery and machine-learning techniques. REMOTE SENS ENVIRON 114, 6 (2010), 1230-1241.

Deep learning-Method overview and review of use for fruit detection and yield estimation. Anand Koirala, B Kerry, Zhenglin Walsh, Cheryl Wang, Mccarthy, COMPUT ELECTRON AGR. 162Anand Koirala, Kerry B Walsh, Zhenglin Wang, and Cheryl McCarthy. 2019. Deep learning-Method overview and review of use for fruit detection and yield estimation. COMPUT ELECTRON AGR 162 (2019), 219-234.

Imagenet classification with deep convolutional neural networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton, Commun. ACM. 60Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2017. Imagenet classification with deep convolutional neural networks. Commun. ACM 60, 6 (2017), 84-90.

Deep learning classification of land cover and crop types using remote sensing data. Nataliia Kussul, Mykola Lavreniuk, Sergii Skakun, Andrii Shelestov, IEEE GEOSCI REMOTE S. 14Nataliia Kussul, Mykola Lavreniuk, Sergii Skakun, and Andrii Shelestov. 2017. Deep learning classification of land cover and crop types using remote sensing data. IEEE GEOSCI REMOTE S 14, 5 (2017), 778-782.

Machine learning in geosciences and remote sensing. J David, Lary, H Amir, Alavi, H Amir, Annette L Gandomi, Walker, GEOSCI FRONT. 7David J Lary, Amir H Alavi, Amir H Gandomi, and Annette L Walker. 2016. Machine learning in geosciences and remote sensing. GEOSCI FRONT 7, 1 (2016), 3-10.

Deep learning. Yann Lecun, Yoshua Bengio, Geoffrey Hinton, NATURE. 521Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. NATURE 521, 7553 (2015), 436-444.

DOCC: Deep one-class crop classification via positive and unlabeled learning for multi-modal satellite imagery. Lei Lei, Xinyu Wang, Yanfei Zhong, Hengwei Zhao, Xin Hu, Chang Luo, INT J APPL EARTH OBS. 105102598Lei Lei, Xinyu Wang, Yanfei Zhong, Hengwei Zhao, Xin Hu, and Chang Luo. 2021. DOCC: Deep one-class crop classification via positive and unlabeled learning for multi-modal satellite imagery. INT J APPL EARTH OBS 105 (2021), 102598.

An adversarial generative network for crop classification from remote sensing timeseries images. Jingtao Li, Yonglin Shen, Chao Yang, REMOTE SENS-BASEL. 1365Jingtao Li, Yonglin Shen, and Chao Yang. 2020. An adversarial generative network for crop classification from remote sensing timeseries images. REMOTE SENS-BASEL 13, 1 (2020), 65.

SeeCucumbers: Using Deep Learning and Drone Imagery to Detect Sea Cucumbers on Coral Reef Flats. Y Q Joan, Stephanie Li, Karen E Duce, Wei Joyce, Xiang, Drones. 528Joan YQ Li, Stephanie Duce, Karen E Joyce, and Wei Xiang. 2021. SeeCucumbers: Using Deep Learning and Drone Imagery to Detect Sea Cucumbers on Coral Reef Flats. Drones 5, 2 (2021), 28.

Individual dairy cow identification based on lightweight convolutional neural network. Shijun Li, Lili Fu, Yu Sun, Ye Mu, Lin Chen, Ji Li, He Gong, PLOS ONE. 16260510Shijun Li, Lili Fu, Yu Sun, Ye Mu, Lin Chen, Ji Li, and He Gong. 2021. Individual dairy cow identification based on lightweight convolutional neural network. PLOS ONE 16, 11 (2021), e0260510.

Weixing Cao, and Qiang Cao. 2022. Improving Estimation of Winter Wheat Nitrogen Status Using Random Forest by Integrating Multi-Source Data Across Different Agro-Ecological Zones. Yue Li, Yuxin Miao, Jing Zhang, Davide Cammarano, Songyang Li, Xiaojun Liu, Yongchao Tian, Yan Zhu, FRONT PLANT SCI. 13Yue Li, Yuxin Miao, Jing Zhang, Davide Cammarano, Songyang Li, Xiaojun Liu, Yongchao Tian, Yan Zhu, Weixing Cao, and Qiang Cao. 2022. Improving Estimation of Winter Wheat Nitrogen Status Using Random Forest by Integrating Multi-Source Data Across Different Agro-Ecological Zones. FRONT PLANT SCI 13 (2022).

Semi-/Weakly-Supervised Semantic Segmentation Method and Its Application for Coastal Aquaculture Areas Based on Multi-Source Remote Sensing Images-Taking the Fujian Coastal Area (Mainly Sanduo) as an Example. Chenbin Liang, Bo Cheng, Baihua Xiao, Chenlinqiu He, Xunan Liu, Ning Jia, Jinfen Chen, REMOTE SENS-BASEL. 131083Chenbin Liang, Bo Cheng, Baihua Xiao, Chenlinqiu He, Xunan Liu, Ning Jia, and Jinfen Chen. 2021. Semi-/Weakly-Supervised Semantic Segmentation Method and Its Application for Coastal Aquaculture Areas Based on Multi-Source Remote Sensing Images-Taking the Fujian Coastal Area (Mainly Sanduo) as an Example. REMOTE SENS-BASEL 13, 6 (2021), 1083.

Synergistic use of multi-temporal RADARSAT-2 and VEN S data for crop classification based on 1D convolutional neural network. Chunhua Liao, Jinfei Wang, Qinghua Xie, Ayman Al Baz, Xiaodong Huang, Jiali Shang, Yongjun He, REMOTE SENS-BASEL. 12832Chunhua Liao, Jinfei Wang, Qinghua Xie, Ayman Al Baz, Xiaodong Huang, Jiali Shang, and Yongjun He. 2020. Synergistic use of multi-temporal RADARSAT-2 and VEN S data for crop classification based on 1D convolutional neural network. REMOTE SENS-BASEL 12, 5 (2020), 832.

Continuous monitoring of cotton stem water potential using sentinel-2 imagery. Yukun Lin, Zhe Zhu, Wenxuan Guo, Yazhou Sun, Xiaoyuan Yang, Valeriy Kovalskyy, REMOTE SENS-BASEL. 121176Yukun Lin, Zhe Zhu, Wenxuan Guo, Yazhou Sun, Xiaoyuan Yang, and Valeriy Kovalskyy. 2020. Continuous monitoring of cotton stem water potential using sentinel-2 imagery. REMOTE SENS-BASEL 12, 7 (2020), 1176.

Estimating biomass of winter oilseed rape using vegetation indices and texture metrics derived from UAV multispectral images. Yinuo Liu, Shishi Liu, Jing Li, Xinyi Guo, Shanqin Wang, Jianwei Lu, COMPUT ELECTRON AGR. 166105026Yinuo Liu, Shishi Liu, Jing Li, Xinyi Guo, Shanqin Wang, and Jianwei Lu. 2019. Estimating biomass of winter oilseed rape using vegetation indices and texture metrics derived from UAV multispectral images. COMPUT ELECTRON AGR 166 (2019), 105026.

Swin transformer v2: Scaling up capacity and resolution. Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. the IEEE/CVF conference on computer vision and pattern recognitionZe Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, et al. 2022. Swin transformer v2: Scaling up capacity and resolution. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 12009-12019.

Greater sensitivity to drought accompanies maize yield increase in the US Midwest. B David, Lobell, J Michael, Wolfram Roberts, Noah Schlenker, Braun, B Bertis, Little, M Roderick, Graeme L Rejesus, Hammer, Science. 344David B Lobell, Michael J Roberts, Wolfram Schlenker, Noah Braun, Bertis B Little, Roderick M Rejesus, and Graeme L Hammer. 2014. Greater sensitivity to drought accompanies maize yield increase in the US Midwest. Science 344, 6183 (2014), 516-519.

Deep learning in plant diseases detection for agricultural crops: a survey. Management, Engineering, and Technology (IJSSMET). Mohamed Loey, Ahmed ElSawy, and Mohamed Afify11International Journal of Service ScienceMohamed Loey, Ahmed ElSawy, and Mohamed Afify. 2020. Deep learning in plant diseases detection for agricultural crops: a survey. International Journal of Service Science, Management, Engineering, and Technology (IJSSMET) 11, 2 (2020), 41-58.

Remote Sensing and Machine Learning Modeling to Support the Identification of Sugarcane Crops. Carlos Lozano Garzon, Germán Bravo Córdoba, Harold Castro, Geovanny González-Rodríguez, David Niño, Haydemar Nuñez, Carolina Pardo, Aurelio Vivas, Yuber Castro, Jazmin Medina, IEEE Access. 10Carlos Lozano Garzon, Germán Bravo Córdoba, Harold Castro, Geovanny González-Rodríguez, David Niño, Haydemar Nuñez, Carolina Pardo, Aurelio Vivas, Yuber Castro, Jazmin Medina, et al. 2022. Remote Sensing and Machine Learning Modeling to Support the Identification of Sugarcane Crops. IEEE Access 10 (2022), 17542-17555.

Yuhong He, and Jiali Shang. 2020. Recent advances of hyperspectral imaging technology and applications in agriculture. Bing Lu, Phuong D Dao, Jiangui Liu, REMOTE SENS-BASEL. 122659Bing Lu, Phuong D Dao, Jiangui Liu, Yuhong He, and Jiali Shang. 2020. Recent advances of hyperspectral imaging technology and applications in agriculture. REMOTE SENS-BASEL 12, 16 (2020), 2659.

Field detection of anthracnose crown rot in strawberry using spectroscopy technology. Jinzhu Lu, Reza Ehsani, Yeyin Shi, Jaafar Abdulridha, Ana I De Castro, Yunjun Xu, COMPUT ELECTRON AGR. 135Jinzhu Lu, Reza Ehsani, Yeyin Shi, Jaafar Abdulridha, Ana I de Castro, and Yunjun Xu. 2017. Field detection of anthracnose crown rot in strawberry using spectroscopy technology. COMPUT ELECTRON AGR 135 (2017), 289-299.

Weixing Cao, and Tao Cheng. 2022. An assessment of multi-view spectral information from UAV-based color-infrared images for improved estimation of nitrogen nutrition status in winter wheat. Ning Lu, Yapeng Wu, Hengbiao Zheng, Xia Yao, Yan Zhu, PRECIS AGRIC. Ning Lu, Yapeng Wu, Hengbiao Zheng, Xia Yao, Yan Zhu, Weixing Cao, and Tao Cheng. 2022. An assessment of multi-view spectral information from UAV-based color-infrared images for improved estimation of nitrogen nutrition status in winter wheat. PRECIS AGRIC (2022), 1-22.

A survey of public datasets for computer vision tasks in precision agriculture. Yuzhen Lu, Sierra Young, COMPUT ELECTRON AGR. 178105760Yuzhen Lu and Sierra Young. 2020. A survey of public datasets for computer vision tasks in precision agriculture. COMPUT ELECTRON AGR 178 (2020), 105760.

Corn yield prediction and uncertainty analysis based on remotely sensed variables using a Bayesian neural network approach. Yuchi Ma, Zhou Zhang, Yanghui Kang, Mutlu Özdoğan, REMOTE SENS ENVIRON. 259112408Yuchi Ma, Zhou Zhang, Yanghui Kang, and Mutlu Özdoğan. 2021. Corn yield prediction and uncertainty analysis based on remotely sensed variables using a Bayesian neural network approach. REMOTE SENS ENVIRON 259 (2021), 112408.

Global crop forecasting. B Robert, Forrest G Macdonald, Hall, Science. 208Robert B MacDonald and Forrest G Hall. 1980. Global crop forecasting. Science 208, 4445 (1980), 670-679.

Perspectives for remote sensing with unmanned aerial vehicles in precision agriculture. H Wouter, Kathy Maes, Steppe, Trends in plant science. 24Wouter H Maes and Kathy Steppe. 2019. Perspectives for remote sensing with unmanned aerial vehicles in precision agriculture. Trends in plant science 24, 2 (2019), 152-164.

Comparison of features for strawberry grading classification with novel dataset. Oka Mahendra, F Hilman, Rika Pardede, R Budiarianto Suryo Sustika, Kusumo, 2018 International Conference on Computer, Control, Informatics and its Applications (IC3INA). IEEE. Oka Mahendra, Hilman F Pardede, Rika Sustika, and R Budiarianto Suryo Kusumo. 2018. Comparison of features for strawberry grading classification with novel dataset. In 2018 International Conference on Computer, Control, Informatics and its Applications (IC3INA). IEEE, 7-12.

Plant disease detection by imaging sensors-parallels and specific demands for precision agriculture and plant phenotyping. Anne Katrin Mahlein, Plant disease. 100Anne Katrin Mahlein. 2016. Plant disease detection by imaging sensors-parallels and specific demands for precision agriculture and plant phenotyping. Plant disease 100, 2 (2016), 241-251.

Automatic detection of Western rock lobster using synthetic data. Ammar Mahmood, Mohammed Bennamoun, Senjian An, Ferdous Sohel, Farid Boussaid, Renae Hovey, Gary Kendrick, ICES Journal of Marine Science. 77Ammar Mahmood, Mohammed Bennamoun, Senjian An, Ferdous Sohel, Farid Boussaid, Renae Hovey, and Gary Kendrick. 2020. Automatic detection of Western rock lobster using synthetic data. ICES Journal of Marine Science 77, 4 (2020), 1308-1317.

Soybean yield prediction from UAV using multimodal data fusion and deep learning. Maitiniyazi Maimaitijiang, Vasit Sagan, Paheding Sidike, Sean Hartling, Flavio Esposito, Felix B Fritschi, REMOTE SENS ENVIRON. 237111599Maitiniyazi Maimaitijiang, Vasit Sagan, Paheding Sidike, Sean Hartling, Flavio Esposito, and Felix B Fritschi. 2020. Soybean yield prediction from UAV using multimodal data fusion and deep learning. REMOTE SENS ENVIRON 237 (2020), 111599.

2022. Field-level crop yield estimation with PRISMA and Sentinel-2. Michael Marshall, Mariana Belgiu, Mirco Boschetti, Monica Pepe, Alfred Stein, Andy Nelson, ISPRS J PHOTOGRAMM. 187Michael Marshall, Mariana Belgiu, Mirco Boschetti, Monica Pepe, Alfred Stein, and Andy Nelson. 2022. Field-level crop yield estimation with PRISMA and Sentinel-2. ISPRS J PHOTOGRAMM 187 (2022), 191-210.

Synergistic integration of optical and microwave satellite data for crop yield estimation. Anna Mateo Sanchis, Maria Piles, Jordi Muñoz-Marí, Jose E Adsuara, REMOTE SENS ENVIRON. 234111460Adrián Pérez-Suay, and Gustau Camps-VallsAnna Mateo Sanchis, Maria Piles, Jordi Muñoz-Marí, Jose E Adsuara, Adrián Pérez-Suay, and Gustau Camps-Valls. 2019. Synergistic integration of optical and microwave satellite data for crop yield estimation. REMOTE SENS ENVIRON 234 (2019), 111460.

Yield forecasting with machine learning and small data: What gains for grains?. Michele Meroni, François Waldner, Lorenzo Seguini, Hervé Kerdiles, Felix Rembold, AGR FOREST METEOROL. 308108555Michele Meroni, François Waldner, Lorenzo Seguini, Hervé Kerdiles, and Felix Rembold. 2021. Yield forecasting with machine learning and small data: What gains for grains? AGR FOREST METEOROL 308 (2021), 108555.

Fish Recognition Model for Fraud Prevention using Convolutional Neural Networks. Rhayane Monteiro, Morgana Ribeiro, Calebi Viana, Mario Wedney De Lima Moreira, Glacio Araújo, Rodrigues, Rhayane Monteiro, Morgana Ribeiro, Calebi Viana, Mario Wedney de Lima Moreira, Glacio Araújo, and Joel JPC Rodrigues. 2021. Fish Recognition Model for Fraud Prevention using Convolutional Neural Networks. (2021).

High-throughput non-destructive biomass determination during early plant development in maize under field conditions. Juan Manuel Montes, Frank Technow, S Baldev, Franz J Dhillon, Albrecht E Mauch, Melchinger, CROP RES. 121Juan Manuel Montes, Frank Technow, Baldev S Dhillon, Franz J Mauch, and Albrecht E Melchinger. 2011. High-throughput non-destructive biomass determination during early plant development in maize under field conditions. FIELD CROP RES 121, 2 (2011), 268-273.

Extreme learning machines for soybean classification in remote sensing hyperspectral images. Ramón Moreno, Francesco Corona, Amaury Lendasse, Manuel Graña, Lênio S Galvão, Neurocomputing. 128Ramón Moreno, Francesco Corona, Amaury Lendasse, Manuel Graña, and Lênio S Galvão. 2014. Extreme learning machines for soybean classification in remote sensing hyperspectral images. Neurocomputing 128 (2014), 207-216.

Crop yield prediction using multitemporal UAV data and spatio-temporal deep learning models. Petteri Nevavuori, Nathaniel Narra, Petri Linna, Tarmo Lipping, REMOTE SENS-BASEL. 124000Petteri Nevavuori, Nathaniel Narra, Petri Linna, and Tarmo Lipping. 2020. Crop yield prediction using multitemporal UAV data and spatio-temporal deep learning models. REMOTE SENS-BASEL 12, 23 (2020), 4000.

Crop yield prediction with deep convolutional neural networks. Petteri Nevavuori, Nathaniel Narra, Tarmo Lipping, COMPUT ELECTRON AGR. 163104859Petteri Nevavuori, Nathaniel Narra, and Tarmo Lipping. 2019. Crop yield prediction with deep convolutional neural networks. COMPUT ELECTRON AGR 163 (2019), 104859.

HSI-TransUNet: a transformer based semantic segmentation model for crop mapping from UAV hyperspectral imagery. Bowen Niu, Quanlong Feng, Boan Chen, Cong Ou, Yiming Liu, Jianyu Yang, COMPUT ELECTRON AGR. 201107297Bowen Niu, Quanlong Feng, Boan Chen, Cong Ou, Yiming Liu, and Jianyu Yang. 2022. HSI-TransUNet: a transformer based semantic segmentation model for crop mapping from UAV hyperspectral imagery. COMPUT ELECTRON AGR 201 (2022), 107297.

Automated sheep facial expression classification using deep transfer learning. Alam Noor, Yaqin Zhao, Anis Koubâa, Longwen Wu, Rahim Khan, Y O Fakheraldin, Abdalla, COMPUT ELECTRON AGR. 175105528Alam Noor, Yaqin Zhao, Anis Koubâa, Longwen Wu, Rahim Khan, and Fakheraldin YO Abdalla. 2020. Automated sheep facial expression classification using deep transfer learning. COMPUT ELECTRON AGR 175 (2020), 105528.

Machine learning estimators for the quantity and quality of grass swards used for silage production using drone-based imaging spectrometry and photogrammetry. Raquel Alves Oliveira, Roope Näsi, Oiva Niemeläinen, Laura Nyholm, Katja Alhonoja, Jere Kaivosoja, Lauri Jauhiainen, Niko Viljanen, Somayeh Nezami, Lauri Markelin, REMOTE SENS ENVIRON. 246111830Raquel Alves Oliveira, Roope Näsi, Oiva Niemeläinen, Laura Nyholm, Katja Alhonoja, Jere Kaivosoja, Lauri Jauhiainen, Niko Viljanen, Somayeh Nezami, Lauri Markelin, et al. 2020. Machine learning estimators for the quantity and quality of grass swards used for silage production using drone-based imaging spectrometry and photogrammetry. REMOTE SENS ENVIRON 246 (2020), 111830.

Large-scale assessment of coastal aquaculture ponds with Sentinel-1 time series data. Marco Ottinger, Kersten Clauss, Claudia Kuenzer, REMOTE SENS-BASEL. 9440Marco Ottinger, Kersten Clauss, and Claudia Kuenzer. 2017. Large-scale assessment of coastal aquaculture ponds with Sentinel-1 time series data. REMOTE SENS-BASEL 9, 5 (2017), 440.

Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, L Carroll, Pamela Wainwright, Chong Mishkin, Sandhini Zhang, Katarina Agarwal, Alex Slama, Ray, arXiv:2203.02155Training language models to follow instructions with human feedback. arXiv preprintLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. arXiv preprint arXiv:2203.02155 (2022).

Improved crop row detection with deep neural network for early-season maize stand count in UAV imagery. Yan Pang, Yeyin Shi, Shancheng Gao, Feng Jiang, Arun Narenthiran Veeranampalayam, Laura Sivakumar, Joe Thompson, Chao Luck, Liu, COMPUT ELECTRON AGR. 178105766Yan Pang, Yeyin Shi, Shancheng Gao, Feng Jiang, Arun Narenthiran Veeranampalayam Sivakumar, Laura Thompson, Joe Luck, and Chao Liu. 2020. Improved crop row detection with deep neural network for early-season maize stand count in UAV imagery. COMPUT ELECTRON AGR 178 (2020), 105766.

Next generation mapping: Combining deep learning, cloud computing, and big remote sensing data. Leandro Parente, Evandro Taquary, Ana Paula Silva, Carlos SouzaJr, Laerte Ferreira, REMOTE SENS-BASEL. 112881Leandro Parente, Evandro Taquary, Ana Paula Silva, Carlos Souza Jr, and Laerte Ferreira. 2019. Next generation mapping: Combining deep learning, cloud computing, and big remote sensing data. REMOTE SENS-BASEL 11, 23 (2019), 2881.

Object-based image classification of summer crops with machine learning methods. M José, Pedro A Peña, César Gutiérrez, Johan Hervás Martínez, Six, E Richard, Francisca López Plant, Granados, REMOTE SENS-BASEL. 6José M Peña, Pedro A Gutiérrez, César Hervás Martínez, Johan Six, Richard E Plant, and Francisca López Granados. 2014. Object-based image classification of summer crops with machine learning methods. REMOTE SENS-BASEL 6, 6 (2014), 5019-5041.

A semi-supervised system for weed mapping in sunflower crops using unmanned aerial vehicles and a crop row detection method. Maria Pérez Ortiz, J M Peña, Pedro Antonio Gutiérrez, Jorge Torres Sánchez, César Hervás Martínez, Francisca López Granados, APPL SOFT COMPUT. 37Maria Pérez Ortiz, JM Peña, Pedro Antonio Gutiérrez, Jorge Torres Sánchez, César Hervás Martínez, and Francisca López Granados. 2015. A semi-supervised system for weed mapping in sunflower crops using unmanned aerial vehicles and a crop row detection method. APPL SOFT COMPUT 37 (2015), 533-544.

Classification of fresh and frozen-thawed pork muscles using visible and near infrared hyperspectral imaging and textural analysis. Hongbin Pu, Dawen Sun, Ji Ma, Junhu Cheng, MEAT SCI. 99Hongbin Pu, Dawen Sun, Ji Ma, and Junhu Cheng. 2015. Classification of fresh and frozen-thawed pork muscles using visible and near infrared hyperspectral imaging and textural analysis. MEAT SCI 99 (2015), 81-88.

Exploiting Hierarchical Features for Crop Yield Prediction Based on 3-D Convolutional Neural Networks and Multikernel Gaussian Process. Mengjia Qiao, Xiaohui He, Xijie Cheng, Panle Li, Haotian Luo, Zhihui Tian, Hengliang Guo, IEEE J-STARS. 14Mengjia Qiao, Xiaohui He, Xijie Cheng, Panle Li, Haotian Luo, Zhihui Tian, and Hengliang Guo. 2021. Exploiting Hierarchical Features for Crop Yield Prediction Based on 3-D Convolutional Neural Networks and Multikernel Gaussian Process. IEEE J-STARS 14 (2021), 4476-4489.

Crop yield prediction from multi-spectral, multi-temporal remotely sensed imagery using recurrent 3D convolutional neural networks. Mengjia Qiao, Xiaohui He, Xijie Cheng, Panle Li, Haotian Luo, Lehan Zhang, Zhihui Tian, INT J APPL EARTH OBS. 102102436Mengjia Qiao, Xiaohui He, Xijie Cheng, Panle Li, Haotian Luo, Lehan Zhang, and Zhihui Tian. 2021. Crop yield prediction from multi-spectral, multi-temporal remotely sensed imagery using recurrent 3D convolutional neural networks. INT J APPL EARTH OBS 102 (2021), 102436.

Learning transferable visual models from natural language supervision. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, PMLRInternational conference on machine learning. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. 2021. Learning transferable visual models from natural language supervision. In International conference on machine learning. PMLR, 8748-8763.

Skilful precipitation nowcasting using deep generative models of radar. Suman Ravuri, Karel Lenc, Matthew Willson, Dmitry Kangin, Remi Lam, Piotr Mirowski, Megan Fitzsimons, Maria Athanassiadou, Sheleem Kashem, Sam Madge, NATURE. 597Suman Ravuri, Karel Lenc, Matthew Willson, Dmitry Kangin, Remi Lam, Piotr Mirowski, Megan Fitzsimons, Maria Athanassiadou, Sheleem Kashem, Sam Madge, et al. 2021. Skilful precipitation nowcasting using deep generative models of radar. NATURE 597, 7878 (2021), 672-677.

Climate variation explains a third of global crop yield variability. K Deepak, James S Ray, Graham K Gerber, Paul C Macdonald, West, NAT COMMUN. 6Deepak K Ray, James S Gerber, Graham K MacDonald, and Paul C West. 2015. Climate variation explains a third of global crop yield variability. NAT COMMUN 6, 1 (2015), 1-9.

Joseph Redmon, Ali Farhadi, YOLOv3: An Incremental Improvement. arXiv e-prints. Joseph Redmon and Ali Farhadi. 2018. YOLOv3: An Incremental Improvement. arXiv e-prints (2018).

Transformer neural network for weed and crop classification of high resolution UAV images. Reenul Reedha, Eric Dericquebourg, REMOTE SENS-BASEL. 14592Raphael Canals, and Adel HafianeReenul Reedha, Eric Dericquebourg, Raphael Canals, and Adel Hafiane. 2022. Transformer neural network for weed and crop classification of high resolution UAV images. REMOTE SENS-BASEL 14, 3 (2022), 592.

U-net: Convolutional networks for biomedical image segmentation. Olaf Ronneberger, Philipp Fischer, Thomas Brox, MICCAI2015. SpringerOlaf Ronneberger, Philipp Fischer, and Thomas Brox. 2015. U-net: Convolutional networks for biomedical image segmentation. In MICCAI2015. Springer, 234-241.

The optical trapezoid model: A novel approach to remote sensing of soil moisture applied to Sentinel-2 and Landsat-8 observations. Morteza Sadeghi, Ebrahim Babaeian, Markus Tuller, Scott B Jones , REMOTE SENS ENVIRON. 198Morteza Sadeghi, Ebrahim Babaeian, Markus Tuller, and Scott B Jones. 2017. The optical trapezoid model: A novel approach to remote sensing of soil moisture applied to Sentinel-2 and Landsat-8 observations. REMOTE SENS ENVIRON 198 (2017), 52-68.

MODIS-based corn grain yield estimation model incorporating crop phenology information. Toshihiro Sakamoto, Anatoly A Gitelson, Timothy J Arkebauer, REMOTE SENS ENVIRON. 131Toshihiro Sakamoto, Anatoly A Gitelson, and Timothy J Arkebauer. 2013. MODIS-based corn grain yield estimation model incorporating crop phenology information. REMOTE SENS ENVIRON 131 (2013), 215-231.

Statistical learning algorithms for identifying contrasting tillage practices with Landsat Thematic Mapper data. Pijush Samui, H Prasanna, Thomas Gowda, Oommen, A Terry, Howell, H Thomas, Dana O Marek, Porter, INT J REMOTE SENS. 33Pijush Samui, Prasanna H Gowda, Thomas Oommen, Terry A Howell, Thomas H Marek, and Dana O Porter. 2012. Statistical learning algorithms for identifying contrasting tillage practices with Landsat Thematic Mapper data. INT J REMOTE SENS 33, 18 (2012), 5732-5745.

Satellite-based soybean yield forecast: Integrating machine learning and weather data for improving crop yield prediction in southern Brazil. A Raí, Telmo Schwalbert, Geomar Amado, Corassa, Luan Pierre Pott, Ignacio A Pv Vara Prasad, Ciampitti, AGR FOREST METEOROL. 284107886Raí A Schwalbert, Telmo Amado, Geomar Corassa, Luan Pierre Pott, PV Vara Prasad, and Ignacio A Ciampitti. 2020. Satellite-based soybean yield forecast: Integrating machine learning and weather data for improving crop yield prediction in southern Brazil. AGR FOREST METEOROL 284 (2020), 107886.

Remote sensing for precision agriculture: Sentinel-2 improved features and applications. Joel Segarra, Maria Luisa Buchaillot, Jose Luis Araus, Shawn C Kefauver, AGRONOMY-BASEL. 10641Joel Segarra, Maria Luisa Buchaillot, Jose Luis Araus, and Shawn C Kefauver. 2020. Remote sensing for precision agriculture: Sentinel-2 improved features and applications. AGRONOMY-BASEL 10, 5 (2020), 641.

Above-ground biomass estimation in Oats using UAV remote sensing and machine learning. Prakriti Sharma, Larry Leigh, Jiyul Chang, Maitiniyazi Maimaitijiang, Melanie Caffé, SENSORS-BASEL. 22601Prakriti Sharma, Larry Leigh, Jiyul Chang, Maitiniyazi Maimaitijiang, and Melanie Caffé. 2022. Above-ground biomass estimation in Oats using UAV remote sensing and machine learning. SENSORS-BASEL 22, 2 (2022), 601.

Identification and mapping of soybean and maize crops based on Sentinel-2 data. Bao She, Yuying Yang, Zhigen Zhao, Linsheng Huang, Dong Liang, Dongyan Zhang, INT J AGR BIOL ENG. 13Bao She, Yuying Yang, Zhigen Zhao, Linsheng Huang, Dong Liang, and Dongyan Zhang. 2020. Identification and mapping of soybean and maize crops based on Sentinel-2 data. INT J AGR BIOL ENG 13, 6 (2020), 171-182.

Automatic raft labeling for remote sensing images via dual-scale homogeneous convolutional neural network. Tianyang Shi, Qizhi Xu, Zhengxia Zou, Zhenwei Shi, REMOTE SENS-BASEL. 101130Tianyang Shi, Qizhi Xu, Zhengxia Zou, and Zhenwei Shi. 2018. Automatic raft labeling for remote sensing images via dual-scale homogeneous convolutional neural network. REMOTE SENS-BASEL 10, 7 (2018), 1130.

Effect of directional augmentation using supervised machine learning technologies: A case study of strawberry powdery mildew detection. Jaemyung Shin, K Young, Brandon Chang, Heung, Gordon W Tri Nguyen Quang, Ahmad Al Price, Mallahi, BIOSYST ENG. 194Jaemyung Shin, Young K Chang, Brandon Heung, Tri Nguyen Quang, Gordon W Price, and Ahmad Al Mallahi. 2020. Effect of directional augmentation using supervised machine learning technologies: A case study of strawberry powdery mildew detection. BIOSYST ENG 194 (2020), 49-60.

Development of a deterministic downscaling algorithm for remote sensing soil moisture footprint using soil and vegetation classifications. Yongchul Shin, P Binayak, Mohanty, WATER RESOUR RES. 49Yongchul Shin and Binayak P Mohanty. 2013. Development of a deterministic downscaling algorithm for remote sensing soil moisture footprint using soil and vegetation classifications. WATER RESOUR RES 49, 10 (2013), 6208-6228.

Subfield maize yield prediction improves when in-season crop water deficit is included in remote sensing imagery-based models. Guanyuan Shuai, Bruno Basso, REMOTE SENS ENVIRON. 272112938Guanyuan Shuai and Bruno Basso. 2022. Subfield maize yield prediction improves when in-season crop water deficit is included in remote sensing imagery-based models. REMOTE SENS ENVIRON 272 (2022), 112938.

Karen Simonyan, Andrew Zisserman, arXiv:1409.1556Very deep convolutional networks for large-scale image recognition. arXiv preprintKaren Simonyan and Andrew Zisserman. 2014. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 (2014).

Applications of remote sensing in precision agriculture: A review. P Rajendra, Ram L Sishodia, Ray, K Sudhir, Singh, REMOTE SENS-BASEL. 123136Rajendra P Sishodia, Ram L Ray, and Sudhir K Singh. 2020. Applications of remote sensing in precision agriculture: A review. REMOTE SENS-BASEL 12, 19 (2020), 3136.

HE-DFNETS: A Novel Hybrid Deep Learning Architecture for the Prediction of Potential Fishing Zone Areas in Indian Ocean Using Remote Sensing Images. M Sivasankari, Fekadu Ashine Anandan, Chamato, COMPUT INTEL NEUROSC. 2022M Sivasankari, R Anandan, and Fekadu Ashine Chamato. 2022. HE-DFNETS: A Novel Hybrid Deep Learning Architecture for the Prediction of Potential Fishing Zone Areas in Indian Ocean Using Remote Sensing Images. COMPUT INTEL NEUROSC 2022 (2022).

Remote sensing applications in sugarcane cultivation: A review. Clement Jaturong Som Ard, Emma Atzberger, Francesco Izquierdo-Verdiguier, Markus Vuolo, Immitzer, REMOTE SENS-BASEL. 134040Jaturong Som Ard, Clement Atzberger, Emma Izquierdo-Verdiguier, Francesco Vuolo, and Markus Immitzer. 2021. Remote sensing applications in sugarcane cultivation: A review. REMOTE SENS-BASEL 13, 20 (2021), 4040.

A review of Internet of Things for smart home: Challenges and solutions. Risteska Biljana, Stojkoska, V Kire, Trivodaliev, J CLEAN PROD. 140Biljana L Risteska Stojkoska and Kire V Trivodaliev. 2017. A review of Internet of Things for smart home: Challenges and solutions. J CLEAN PROD 140 (2017), 1454-1464.

Using of multi-source and multi-temporal remote sensing data improves crop-type mapping in the subtropical agriculture region. Chuanliang Sun, Yan Bian, Tao Zhou, Jianjun Pan, SENSORS-BASEL. 192401Chuanliang Sun, Yan Bian, Tao Zhou, and Jianjun Pan. 2019. Using of multi-source and multi-temporal remote sensing data improves crop-type mapping in the subtropical agriculture region. SENSORS-BASEL 19, 10 (2019), 2401.

Mapping plastic greenhouses with two-temporal sentinel-2 images and 1d-cnn deep learning. Haoran Sun, Lei Wang, Rencai Lin, Zhen Zhang, Baozhong Zhang, REMOTE SENS-BASEL. 132820Haoran Sun, Lei Wang, Rencai Lin, Zhen Zhang, and Baozhong Zhang. 2021. Mapping plastic greenhouses with two-temporal sentinel-2 images and 1d-cnn deep learning. REMOTE SENS-BASEL 13, 14 (2021), 2820.

Multilevel deep learning network for county-level corn yield estimation in the us corn belt. Jie Sun, Zulong Lai, Liping Di, Ziheng Sun, Jianbin Tao, Yonglin Shen, IEEE J-STARS. 13Jie Sun, Zulong Lai, Liping Di, Ziheng Sun, Jianbin Tao, and Yonglin Shen. 2020. Multilevel deep learning network for county-level corn yield estimation in the us corn belt. IEEE J-STARS 13 (2020), 5048-5060.

Sparse r-cnn: End-to-end object detection with learnable proposals. Peize Sun, Rufeng Zhang, Yi Jiang, Tao Kong, Chenfeng Xu, Wei Zhan, Masayoshi Tomizuka, Lei Li, Zehuan Yuan, Changhu Wang, CVPR2021Peize Sun, Rufeng Zhang, Yi Jiang, Tao Kong, Chenfeng Xu, Wei Zhan, Masayoshi Tomizuka, Lei Li, Zehuan Yuan, Changhu Wang, et al. 2021. Sparse r-cnn: End-to-end object detection with learnable proposals. In CVPR2021. 14454-14463.

Sharanagouda Shiddanagouda Patil, Chander Prakash Swarnkar, and Dhirendra Singh. 2022. Exploration of machine learning models to predict the environmental and remote sensing risk factors of haemonchosis in sheep flocks of Rajasthan. Pinaki Prasad Kuralayanapalya Puttahonnappa Suresh, Sengupta, Susan Siju, Mohan Jacob, Kumar Garudanagiri, Sathyanarayana, ACTA TROP. 106542Kuralayanapalya Puttahonnappa Suresh, Pinaki Prasad Sengupta, Siju Susan Jacob, Mohan Kumar Garudanagiri Sathyanarayana, Sharanagouda Shid- danagouda Patil, Chander Prakash Swarnkar, and Dhirendra Singh. 2022. Exploration of machine learning models to predict the environmental and remote sensing risk factors of haemonchosis in sheep flocks of Rajasthan, India. ACTA TROP (2022), 106542.

Evaluation of deep convolutional neural network architectures for strawberry quality inspection. Rika Sustika, Agus Subekti, F Hilman, Endang Pardede, Oka Suryawati, Sandra Mahendra, Yuwana, Int. J. Eng. Technol. 7Rika Sustika, Agus Subekti, Hilman F Pardede, Endang Suryawati, Oka Mahendra, and Sandra Yuwana. 2018. Evaluation of deep convolutional neural network architectures for strawberry quality inspection. Int. J. Eng. Technol 7, 4 (2018), 75-80.

Going deeper with convolutions. Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich, CVPR2015Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. 2015. Going deeper with convolutions. In CVPR2015. 1-9.

Spectroscopic detection of rice leaf blast infection from asymptomatic to mild stages with integrated machine learning and feature selection. Long Tian, Ziyi Bowen Xue, Dong Wang, Xia Li, Qiang Yao, Yan Cao, Weixing Zhu, Tao Cao, Cheng, REMOTE SENS ENVIRON. 257112350Long Tian, Bowen Xue, Ziyi Wang, Dong Li, Xia Yao, Qiang Cao, Yan Zhu, Weixing Cao, and Tao Cheng. 2021. Spectroscopic detection of rice leaf blast infection from asymptomatic to mild stages with integrated machine learning and feature selection. REMOTE SENS ENVIRON 257 (2021), 112350.

Structural health monitoring framework based on Internet of Things: A survey. Bin C Arcadius Tokognon, Guiyun Gao, Yan Tian, Yan, IEEE INTERNET THINGS. 4C Arcadius Tokognon, Bin Gao, Guiyun Tian, and Yan Yan. 2017. Structural health monitoring framework based on Internet of Things: A survey. IEEE INTERNET THINGS 4, 3 (2017), 619-635.

Progress in hyperspectral remote sensing science and technology in China over the past three decades. Qingxi Tong, Yongqi Xue, Lifu Zhang, IEEE J-STARS. 7Qingxi Tong, Yongqi Xue, and Lifu Zhang. 2013. Progress in hyperspectral remote sensing science and technology in China over the past three decades. IEEE J-STARS 7, 1 (2013), 70-91.

A deep learning multi-layer perceptron and remote sensing approach for soil health based crop yield estimation. Akshar Tripathi, Reet Kamal Tiwari, Surya Prakash Tiwari, INT J APPL EARTH OBS. 113102959Akshar Tripathi, Reet Kamal Tiwari, and Surya Prakash Tiwari. 2022. A deep learning multi-layer perceptron and remote sensing approach for soil health based crop yield estimation. INT J APPL EARTH OBS 113 (2022), 102959.

Assessment of dairy cow heat stress by monitoring drinking behaviour using an embedded imaging system. Yu Chi Tsai, Jih Tay Hsu, Shih Torng Ding, Dan Jeric Arcega Rustia, Tate Lin, BIOSYST ENG. 199Yu Chi Tsai, Jih Tay Hsu, Shih Torng Ding, Dan Jeric Arcega Rustia, and Tate Lin. 2020. Assessment of dairy cow heat stress by monitoring drinking behaviour using an embedded imaging system. BIOSYST ENG 199 (2020), 97-108.

Implementation of an automatic 3D vision monitor for dairy cow locomotion in a commercial farm. Tom Van Hertem, Andrés Schlageter Tello, Stefano Viazzi, Machteld Steensels, Claudia Bahr, Carlos Eduardo Bites Romanini, Kees Lokhorst, Ephraim Maltz, Ilan Halachmi, Daniel Berckmans, BIOSYST ENG. 173Tom Van Hertem, Andrés Schlageter Tello, Stefano Viazzi, Machteld Steensels, Claudia Bahr, Carlos Eduardo Bites Romanini, Kees Lokhorst, Ephraim Maltz, Ilan Halachmi, and Daniel Berckmans. 2018. Implementation of an automatic 3D vision monitor for dairy cow locomotion in a commercial farm. BIOSYST ENG 173 (2018), 166-175.

Synergistic use of radar Sentinel-1 and optical Sentinel-2 imagery for crop mapping: A case study for Belgium. Kristof Van Tricht, Anne Gobin, Sven Gilliams, Isabelle Piccard, REMOTE SENS-BASEL. 101642Kristof Van Tricht, Anne Gobin, Sven Gilliams, and Isabelle Piccard. 2018. Synergistic use of radar Sentinel-1 and optical Sentinel-2 imagery for crop mapping: A case study for Belgium. REMOTE SENS-BASEL 10, 10 (2018), 1642.

Early-season stand count determination in corn via integration of imagery from unmanned aerial systems (UAS) and supervised learning techniques. Sebastian Varela, Pruthvidhar Reddy Dhodda, H William, Hsu, Yared Pv Vara Prasad, Assefa, R Nahuel, Terry Peralta, Ajay Griffin, Allison Sharda, Ignacio A Ferguson, Ciampitti, REMOTE SENS-BASEL. 10343Sebastian Varela, Pruthvidhar Reddy Dhodda, William H Hsu, PV Vara Prasad, Yared Assefa, Nahuel R Peralta, Terry Griffin, Ajay Sharda, Allison Ferguson, and Ignacio A Ciampitti. 2018. Early-season stand count determination in corn via integration of imagery from unmanned aerial systems (UAS) and supervised learning techniques. REMOTE SENS-BASEL 10, 2 (2018), 343.

Potential of field hyperspectral imaging as a non destructive method to assess leaf nitrogen content in Wheat. Nathalie Vigneau, Martin Ecarnot, Gilles Rabatel, Pierre Roumet, CROP RES. 122Nathalie Vigneau, Martin Ecarnot, Gilles Rabatel, and Pierre Roumet. 2011. Potential of field hyperspectral imaging as a non destructive method to assess leaf nitrogen content in Wheat. FIELD CROP RES 122, 1 (2011), 25-31.

An application of Convolutional Neural Network to lobster grading in the Southern Rock Lobster supply chain. Anh Son, Joel Vo, Paul Scanlan, Turner, FOOD CONTROL. 113107184Son Anh Vo, Joel Scanlan, and Paul Turner. 2020. An application of Convolutional Neural Network to lobster grading in the Southern Rock Lobster supply chain. FOOD CONTROL 113 (2020), 107184.

2022. A review of deep learning in multiscale agricultural sensing. Dashuai Wang, Wujing Cao, Fan Zhang, Zhuolin Li, Sheng Xu, Xinyu Wu, REMOTE SENS-BASEL. 14559Dashuai Wang, Wujing Cao, Fan Zhang, Zhuolin Li, Sheng Xu, and Xinyu Wu. 2022. A review of deep learning in multiscale agricultural sensing. REMOTE SENS-BASEL 14, 3 (2022), 559.

Fully Contextual Network for Hyperspectral Scene Parsing. Di Wang, Bo Du, Liangpei Zhang, IEEE T GEOSCI REMOTE. 60Di Wang, Bo Du, and Liangpei Zhang. 2022. Fully Contextual Network for Hyperspectral Scene Parsing. IEEE T GEOSCI REMOTE 60 (2022), 1-16.

Adaptive Spectral-Spatial Multiscale Contextual Feature Extraction for Hyperspectral Image Classification. Di Wang, Bo Du, Liangpei Zhang, Yufei Xu, IEEE T GEOSCI REMOTE. 59Di Wang, Bo Du, Liangpei Zhang, and Yufei Xu. 2021. Adaptive Spectral-Spatial Multiscale Contextual Feature Extraction for Hyperspectral Image Classification. IEEE T GEOSCI REMOTE 59, 3 (2021), 2461-2477.

Gui-Song Xia, and Dacheng Tao. 2022. An Empirical Study of Remote Sensing Pretraining. Di Wang, Jing Zhang, Bo Du, IEEE T GEOSCI REMOTE. Di Wang, Jing Zhang, Bo Du, Gui-Song Xia, and Dacheng Tao. 2022. An Empirical Study of Remote Sensing Pretraining. IEEE T GEOSCI REMOTE (2022), 1-1.

Advancing plain vision transformer towards remote sensing foundation model. Di Wang, Qiming Zhang, Yufei Xu, Jing Zhang, Bo Du, Dacheng Tao, Liangpei Zhang, IEEE T GEOSCI REMOTE. Di Wang, Qiming Zhang, Yufei Xu, Jing Zhang, Bo Du, Dacheng Tao, and Liangpei Zhang. 2022. Advancing plain vision transformer towards remote sensing foundation model. IEEE T GEOSCI REMOTE (2022).

Qinqin Hou, and Shaofei Gong. 2020. Cattle face recognition method based on parameter transfer and deep learning. Hongyu Wang, Junping Qin, In JPCS2022. 145312054IOP PublishingHongyu Wang, Junping Qin, Qinqin Hou, and Shaofei Gong. 2020. Cattle face recognition method based on parameter transfer and deep learning. In JPCS2022, Vol. 1453. IOP Publishing, 012054.

Qiong Zheng, and Zhiping Peng. 2021. Estimation of paddy rice nitrogen content and accumulation both at leaf and plant levels from UAV hyperspectral imagery. Li Wang, Shuisen Chen, Dan Li, Chongyang Wang, Hao Jiang, REMOTE SENS-BASEL. 132956Li Wang, Shuisen Chen, Dan Li, Chongyang Wang, Hao Jiang, Qiong Zheng, and Zhiping Peng. 2021. Estimation of paddy rice nitrogen content and accumulation both at leaf and plant levels from UAV hyperspectral imagery. REMOTE SENS-BASEL 13, 15 (2021), 2956.

Mapping sugarcane in complex landscapes by integrating multi-temporal Sentinel-2 images and machine learning algorithms. Ming Wang, Zhengjia Liu, Muhammad Hasan Ali Baig, Yongsheng Wang, Yurui Li, Yuanyan Chen, LAND USE POLICY. 88104190Ming Wang, Zhengjia Liu, Muhammad Hasan Ali Baig, Yongsheng Wang, Yurui Li, and Yuanyan Chen. 2019. Mapping sugarcane in complex landscapes by integrating multi-temporal Sentinel-2 images and machine learning algorithms. LAND USE POLICY 88 (2019), 104190.

Ofa: Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework. Peng Wang, An Yang, Rui Men, Junyang Lin, Shuai Bai, Zhikang Li, Jianxin Ma, Chang Zhou, Jingren Zhou, Hongxia Yang, PMLRInternational Conference on Machine Learning. Peng Wang, An Yang, Rui Men, Junyang Lin, Shuai Bai, Zhikang Li, Jianxin Ma, Chang Zhou, Jingren Zhou, and Hongxia Yang. 2022. Ofa: Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework. In International Conference on Machine Learning. PMLR, 23318-23340.

Weed Density Extraction based on Few-shot Learning through UAV Remote Sensing RGB and Multi-spectral Images in Ecological Irrigation Area. Shubo Wang, Yu Han, Jian Chen, Kai Zhang, Zichao Zhang, Xuzan Liu, FRONT PLANT SCI. 3456Shubo Wang, Yu Han, Jian Chen, Kai Zhang, Zichao Zhang, and Xuzan Liu. 2022. Weed Density Extraction based on Few-shot Learning through UAV Remote Sensing RGB and Multi-spectral Images in Ecological Irrigation Area. FRONT PLANT SCI (2022), 3456.

Winter wheat yield prediction at county level and uncertainty analysis in main wheat-producing regions of China with deep learning approaches. Xinlei Wang, Jianxi Huang, Quanlong Feng, Dongqin Yin, REMOTE SENS-BASEL. 121744Xinlei Wang, Jianxi Huang, Quanlong Feng, and Dongqin Yin. 2020. Winter wheat yield prediction at county level and uncertainty analysis in main wheat-producing regions of China with deep learning approaches. REMOTE SENS-BASEL 12, 11 (2020), 1744.

Combining multi-source data and machine learning approaches to predict winter wheat yield in the conterminous United States. Yumiao Wang, Zhou Zhang, Luwei Feng, Qingyun Du, Troy Runge, REMOTE SENS-BASEL. 121232Yumiao Wang, Zhou Zhang, Luwei Feng, Qingyun Du, and Troy Runge. 2020. Combining multi-source data and machine learning approaches to predict winter wheat yield in the conterminous United States. REMOTE SENS-BASEL 12, 8 (2020), 1232.

Remote sensing for agricultural applications: A meta-review. Marie Weiss, Frédéric Jacob, Grgory Duveiller, REMOTE SENS ENVIRON. 236111402Marie Weiss, Frédéric Jacob, and Grgory Duveiller. 2020. Remote sensing for agricultural applications: A meta-review. REMOTE SENS ENVIRON 236 (2020), 111402.

Dongjian He, and Huaibo Song. 2020. Lameness detection of dairy cows based on the YOLOv3 deep learning algorithm and a relative step size characteristic vector. Dihua Wu, Qian Wu, Xuqiang Yin, Bo Jiang, Han Wang, BIOSYST ENG. 189Dihua Wu, Qian Wu, Xuqiang Yin, Bo Jiang, Han Wang, Dongjian He, and Huaibo Song. 2020. Lameness detection of dairy cows based on the YOLOv3 deep learning algorithm and a relative step size characteristic vector. BIOSYST ENG 189 (2020), 150-163.

Unified perceptual parsing for scene understanding. Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, Jian Sun, ECCV2018. Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, and Jian Sun. 2018. Unified perceptual parsing for scene understanding. In ECCV2018. 418-434.

MODIS-based remote sensing monitoring of grass production in China. Bin Xu, Xiuchun Yang, Weiguo Tao, Zhihao Qin, Haiqi Liu, Jianming Miao, Yuyun Bi, INT J REMOTE SENS. 29Bin Xu, Xiuchun Yang, Weiguo Tao, Zhihao Qin, Haiqi Liu, Jianming Miao, and Yuyun Bi. 2008. MODIS-based remote sensing monitoring of grass production in China. INT J REMOTE SENS 29, 17-18 (2008), 5313-5327.

Gmflow: Learning optical flow via global matching. Haofei Xu, Jing Zhang, Jianfei Cai, Hamid Rezatofighi, Dacheng Tao, CVPR2022. 8121-8130Haofei Xu, Jing Zhang, Jianfei Cai, Hamid Rezatofighi, and Dacheng Tao. 2022. Gmflow: Learning optical flow via global matching. In CVPR2022. 8121-8130.

DeepCropMapping: A multi-temporal deep learning approach with improved spatial generalizability for dynamic corn and soybean mapping. Jinfan Xu, Yue Zhu, Renhai Zhong, Zhixian Lin, Jialu Xu, Hao Jiang, Jingfeng Huang, Haifeng Li, Tao Lin, REMOTE SENS ENVIRON. 247111946Jinfan Xu, Yue Zhu, Renhai Zhong, Zhixian Lin, Jialu Xu, Hao Jiang, Jingfeng Huang, Haifeng Li, and Tao Lin. 2020. DeepCropMapping: A multi-temporal deep learning approach with improved spatial generalizability for dynamic corn and soybean mapping. REMOTE SENS ENVIRON 247 (2020), 111946.

Yufei Xu, Jing Zhang, arXiv:2204.12484Qiming Zhang, and Dacheng Tao. 2022. Vitpose: Simple vision transformer baselines for human pose estimation. arXiv preprintYufei Xu, Jing Zhang, Qiming Zhang, and Dacheng Tao. 2022. Vitpose: Simple vision transformer baselines for human pose estimation. arXiv preprint arXiv:2204.12484 (2022).

Vitae: Vision transformer advanced by exploring intrinsic inductive bias. Yufei Xu, Qiming Zhang, Jing Zhang, Dacheng Tao, NIPS2021. 34Yufei Xu, Qiming Zhang, Jing Zhang, and Dacheng Tao. 2021. Vitae: Vision transformer advanced by exploring intrinsic inductive bias. NIPS2021 34 (2021), 28522-28535.

High-accuracy image segmentation for lactating sows using a fully convolutional network. Aqing Yang, Huasheng Huang, Chan Zheng, Xunmu Zhu, Xiaofan Yang, Pengfei Chen, Yueju Xue, BIOSYST ENG. 176Aqing Yang, Huasheng Huang, Chan Zheng, Xunmu Zhu, Xiaofan Yang, Pengfei Chen, and Yueju Xue. 2018. High-accuracy image segmentation for lactating sows using a fully convolutional network. BIOSYST ENG 176 (2018), 36-47.

Modeling grassland above-ground biomass based on artificial neural network and remote sensing in the Three-River Headwaters Region. Shuxia Yang, Qisheng Feng, Tiangang Liang, Baokang Liu, Wenjuan Zhang, Hongjie Xie, REMOTE SENS ENVIRON. 204Shuxia Yang, Qisheng Feng, Tiangang Liang, Baokang Liu, Wenjuan Zhang, and Hongjie Xie. 2018. Modeling grassland above-ground biomass based on artificial neural network and remote sensing in the Three-River Headwaters Region. REMOTE SENS ENVIRON 204 (2018), 448-455.

DeepSolo: Let Transformer Decoder with Explicit Points Solo for Text Spotting. Maoyuan Ye, Jing Zhang, Shanshan Zhao, Juhua Liu, Tongliang Liu, Bo Du, Dacheng Tao, CVPR2023. Maoyuan Ye, Jing Zhang, Shanshan Zhao, Juhua Liu, Tongliang Liu, Bo Du, and Dacheng Tao. 2023. DeepSolo: Let Transformer Decoder with Explicit Points Solo for Text Spotting. In CVPR2023.

. Hang Yu, Yufei Xu, Jing Zhang, Wei Zhao, Ziyu Guan, Dacheng Tao, n. d.Hang Yu, Yufei Xu, Jing Zhang, Wei Zhao, Ziyu Guan, and Dacheng Tao. [n. d.].

A Benchmark for Animal Pose Estimation in the Wild. Ap-10k, Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track. Round 2AP-10K: A Benchmark for Animal Pose Estimation in the Wild. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2).

Lu Yuan, Dongdong Chen, Yi-Ling Chen, Noel Codella, Xiyang Dai, Jianfeng Gao, Houdong Hu, Xuedong Huang, Boxin Li, Chunyuan Li, arXiv:2111.11432Florence: A new foundation model for computer vision. arXiv preprintLu Yuan, Dongdong Chen, Yi-Ling Chen, Noel Codella, Xiyang Dai, Jianfeng Gao, Houdong Hu, Xuedong Huang, Boxin Li, Chunyuan Li, et al. 2021. Florence: A new foundation model for computer vision. arXiv preprint arXiv:2111.11432 (2021).

2022. A survey on deep learning applications in wheat phenotyping. Amirhossein Zaji, Zheng Liu, Gaozhi Xiao, S Jatinder, Yuefeng Sangha, Ruan, APPL SOFT COMPUT. 109761Amirhossein Zaji, Zheng Liu, Gaozhi Xiao, Jatinder S Sangha, and Yuefeng Ruan. 2022. A survey on deep learning applications in wheat phenotyping. APPL SOFT COMPUT (2022), 109761.

Internet of things for smart cities. Andrea Zanella, Nicola Bui, Angelo Castellani, Lorenzo Vangelista, Michele Zorzi, IEEE INTERNET THINGS. 1Andrea Zanella, Nicola Bui, Angelo Castellani, Lorenzo Vangelista, and Michele Zorzi. 2014. Internet of things for smart cities. IEEE INTERNET THINGS 1, 1 (2014), 22-32.

Extracting aquaculture ponds from natural water surfaces around inland lakes on medium resolution multispectral images. Zhe Zeng, Di Wang, Wenxia Tan, Jianhua Huang, INT J APPL EARTH OBS. 80Zhe Zeng, Di Wang, Wenxia Tan, and Jianhua Huang. 2019. Extracting aquaculture ponds from natural water surfaces around inland lakes on medium resolution multispectral images. INT J APPL EARTH OBS 80 (2019), 13-25.

RCSANet: A Full Convolutional Network for Extracting Inland Aquaculture Ponds from High-Spatial-Resolution Images. Zhe Zeng, Di Wang, Wenxia Tan, Gongliang Yu, Jiacheng You, Botao Lv, Zhongheng Wu, REMOTE SENS-BASEL. 1392Zhe Zeng, Di Wang, Wenxia Tan, Gongliang Yu, Jiacheng You, Botao Lv, and Zhongheng Wu. 2020. RCSANet: A Full Convolutional Network for Extracting Inland Aquaculture Ponds from High-Spatial-Resolution Images. REMOTE SENS-BASEL 13, 1 (2020), 92.

Improving unmanned aerial vehicle remote sensing-based rice nitrogen nutrition index prediction with machine learning. Hainie Zha, Yuxin Miao, Tiantian Wang, Yue Li, Jing Zhang, Weichao Sun, Zhengqi Feng, Krzysztof Kusnierek, REMOTE SENS-BASEL. 12215Hainie Zha, Yuxin Miao, Tiantian Wang, Yue Li, Jing Zhang, Weichao Sun, Zhengqi Feng, and Krzysztof Kusnierek. 2020. Improving unmanned aerial vehicle remote sensing-based rice nitrogen nutrition index prediction with machine learning. REMOTE SENS-BASEL 12, 2 (2020), 215.

Decision support systems for agriculture 4.0: Survey and challenges. Zhaoyu Zhai, Victoria José Fernán Martínez, Néstor Lucas Beltran, Martínez, COMPUT ELECTRON AGR. 170105256Zhaoyu Zhai, José Fernán Martínez, Victoria Beltran, and Néstor Lucas Martínez. 2020. Decision support systems for agriculture 4.0: Survey and challenges. COMPUT ELECTRON AGR 170 (2020), 105256.

Capability of crop water content for revealing variability of winter wheat grain yield and soil moisture under limited irrigation. Chao Zhang, Jiangui Liu, Jiali Shang, Huanjie Cai, SCI TOTAL ENVIRON. 631Chao Zhang, Jiangui Liu, Jiali Shang, and Huanjie Cai. 2018. Capability of crop water content for revealing variability of winter wheat grain yield and soil moisture under limited irrigation. SCI TOTAL ENVIRON 631 (2018), 677-687.

Coastal fisheries resource monitoring through A deep learning-based underwater video analysis. Dian Zhang, E O&apos; Noel, Andre J Conner, Chunjie Simpson, Suzanne Cao, Bing Little, Wu, ESTUAR COAST SHELF S. 269107815Dian Zhang, Noel E O'Conner, Andre J Simpson, Chunjie Cao, Suzanne Little, and Bing Wu. 2022. Coastal fisheries resource monitoring through A deep learning-based underwater video analysis. ESTUAR COAST SHELF S 269 (2022), 107815.

Spatiotemporal patterns of paddy rice croplands in China and India from. Geli Zhang, Xiangming Xiao, M Chandrashekhar, Jinwei Biradar, Yuanwei Dong, Qin, A Michael, Yuting Menarguez, Yao Zhou, Cui Zhang, Jie Jin, Wang, SCI TOTAL ENVIRON. 579Geli Zhang, Xiangming Xiao, Chandrashekhar M Biradar, Jinwei Dong, Yuanwei Qin, Michael A Menarguez, Yuting Zhou, Yao Zhang, Cui Jin, Jie Wang, et al. 2017. Spatiotemporal patterns of paddy rice croplands in China and India from 2000 to 2015. SCI TOTAL ENVIRON 579 (2017), 82-92.

Monitoring plant diseases and pests through remote sensing technology: A review. Jingcheng Zhang, Yanbo Huang, Ruiliang Pu, Pablo Gonzalez-Moreno, Lin Yuan, Kaihua Wu, Wenjiang Huang, COMPUT ELECTRON AGR. 165104943Jingcheng Zhang, Yanbo Huang, Ruiliang Pu, Pablo Gonzalez-Moreno, Lin Yuan, Kaihua Wu, and Wenjiang Huang. 2019. Monitoring plant diseases and pests through remote sensing technology: A review. COMPUT ELECTRON AGR 165 (2019), 104943.

Detecting powdery mildew of winter wheat using leaf level hyperspectral measurements. Jingcheng Zhang, Ruiliang Pu, Jihua Wang, Wenjiang Huang, Lin Yuan, Juhua Luo, COMPUT ELECTRON AGR. 85Jingcheng Zhang, Ruiliang Pu, Jihua Wang, Wenjiang Huang, Lin Yuan, and Juhua Luo. 2012. Detecting powdery mildew of winter wheat using leaf level hyperspectral measurements. COMPUT ELECTRON AGR 85 (2012), 13-23.

Empowering things with intelligence: a survey of the progress, challenges, and opportunities in artificial intelligence of things. Jing Zhang, Dacheng Tao, IEEE INTERNET THINGS. 8Jing Zhang and Dacheng Tao. 2020. Empowering things with intelligence: a survey of the progress, challenges, and opportunities in artificial intelligence of things. IEEE INTERNET THINGS 8, 10 (2020), 7789-7817.

Combining optical, fluorescence, thermal satellite, and environmental data to predict county-level maize yield in China using machine learning approaches. Liangliang Zhang, Zhao Zhang, Yuchuan Luo, Juan Cao, Fulu Tao, REMOTE SENS-BASEL. 1221Liangliang Zhang, Zhao Zhang, Yuchuan Luo, Juan Cao, and Fulu Tao. 2019. Combining optical, fluorescence, thermal satellite, and environmental data to predict county-level maize yield in China using machine learning approaches. REMOTE SENS-BASEL 12, 1 (2019), 21.

Integrating satellite-derived climatic and vegetation indices to predict smallholder maize yield using deep learning. Liangliang Zhang, Zhao Zhang, Yuchuan Luo, Juan Cao, Ruizhi Xie, Shaokun Li, AGR FOREST METEOROL. 311108666Liangliang Zhang, Zhao Zhang, Yuchuan Luo, Juan Cao, Ruizhi Xie, and Shaokun Li. 2021. Integrating satellite-derived climatic and vegetation indices to predict smallholder maize yield using deep learning. AGR FOREST METEOROL 311 (2021), 108666.

Vitaev2: Vision transformer advanced by exploring inductive bias for image recognition and beyond. Qiming Zhang, Yufei Xu, Jing Zhang, Dacheng Tao, INT J COMPUT VISION. Qiming Zhang, Yufei Xu, Jing Zhang, and Dacheng Tao. 2023. Vitaev2: Vision transformer advanced by exploring inductive bias for image recognition and beyond. INT J COMPUT VISION (2023), 1-22.

Prediction of soil organic carbon based on Landsat 8 monthly NDVI data for the Jianghan Plain in Hubei Province. Yangchengsi Zhang, Long Guo, Yiyun Chen, Tiezhu Shi, Mei Luo, Qinglan Ju, Haitao Zhang, Shanqin Wang, China. REMOTE SENS-BASEL. 111683Yangchengsi Zhang, Long Guo, Yiyun Chen, Tiezhu Shi, Mei Luo, QingLan Ju, Haitao Zhang, and Shanqin Wang. 2019. Prediction of soil organic carbon based on Landsat 8 monthly NDVI data for the Jianghan Plain in Hubei Province, China. REMOTE SENS-BASEL 11, 14 (2019), 1683.

California almond yield prediction at the orchard level with a machine learning approach. Zhou Zhang, Yufang Jin, Bin Chen, Patrick Brown, FRONT PLANT SCI. 10809Zhou Zhang, Yufang Jin, Bin Chen, and Patrick Brown. 2019. California almond yield prediction at the orchard level with a machine learning approach. FRONT PLANT SCI 10 (2019), 809.

Evaluation of three deep learning models for early crop classification using sentinel-1A imagery time series-A case study in Zhanjiang. Hongwei Zhao, Zhongxin Chen, Hao Jiang, Wenlong Jing, Liang Sun, Min Feng, China. REMOTE SENS-BASEL. 112673Hongwei Zhao, Zhongxin Chen, Hao Jiang, Wenlong Jing, Liang Sun, and Min Feng. 2019. Evaluation of three deep learning models for early crop classification using sentinel-1A imagery time series-A case study in Zhanjiang, China. REMOTE SENS-BASEL 11, 22 (2019), 2673.

Pyramid scene parsing network. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, Jiaya Jia, CVPR2017. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid scene parsing network. In CVPR2017. 2881-2890.

Blockchain challenges and opportunities: A survey. Zibin Zheng, Shaoan Xie, Hong-Ning Dai, Xiangping Chen, Huaimin Wang, INT J WEB GRID SERV. 14Zibin Zheng, Shaoan Xie, Hong-Ning Dai, Xiangping Chen, and Huaimin Wang. 2018. Blockchain challenges and opportunities: A survey. INT J WEB GRID SERV 14, 4 (2018), 352-375.

WHU-Hi: UAV-borne hyperspectral with high spatial resolution (H2) benchmark datasets and classifier for precise crop identification based on deep convolutional neural network with CRF. Yanfei Zhong, Xin Hu, Chang Luo, Xinyu Wang, Ji Zhao, Liangpei Zhang, REMOTE SENS ENVIRON. 250112012Yanfei Zhong, Xin Hu, Chang Luo, Xinyu Wang, Ji Zhao, and Liangpei Zhang. 2020. WHU-Hi: UAV-borne hyperspectral with high spatial resolution (H2) benchmark datasets and classifier for precise crop identification based on deep convolutional neural network with CRF. REMOTE SENS ENVIRON 250 (2020), 112012.

Integrating climate and satellite remote sensing data for predicting county-level wheat yield in China using machine learning methods. Weimo Zhou, Yujie Liu, Syed Tahir Ata Ul Karim, Quansheng Ge, Xing Li, Jingfeng Xiao, INT J APPL EARTH OBS. 111102861Weimo Zhou, Yujie Liu, Syed Tahir Ata Ul Karim, Quansheng Ge, Xing Li, and Jingfeng Xiao. 2022. Integrating climate and satellite remote sensing data for predicting county-level wheat yield in China using machine learning methods. INT J APPL EARTH OBS 111 (2022), 102861.

Research on remote sensing classification of fruit trees based on Sentinel-2 multi-temporal imageries. Xinxing Zhou, Yangyang Li, Yuankai Luo, Yawei Sun, Yijun Su, Changwei Tan, Yaju Liu, SCI REP-UK. 12Xinxing Zhou, Yangyang Li, Yuankai Luo, Yawei Sun, Yijun Su, Changwei Tan, and Yaju Liu. 2022. Research on remote sensing classification of fruit trees based on Sentinel-2 multi-temporal imageries. SCI REP-UK 12, 1 (2022), 1-14.

Estimation of biomass in wheat using random forest regression algorithm and remote sensing data. Xudong Zhou, Xinkai Zhu, Zhaodi Dong, Wenshan Guo, The Crop Journal. 4Xudong Zhou, Xinkai Zhu, Zhaodi Dong, Wenshan Guo, et al. 2016. Estimation of biomass in wheat using random forest regression algorithm and remote sensing data. The Crop Journal 4, 3 (2016), 212-219.

Estimating maize above-ground biomass using 3D point clouds of multi-source unmanned aerial vehicle data at multi-spatial scales. Wanxue Zhu, Zhigang Sun, Jinbang Peng, Yaohuan Huang, Jing Li, Junqiang Zhang, Bin Yang, Xiaohan Liao, REMOTE SENS-BASEL. 112678Wanxue Zhu, Zhigang Sun, Jinbang Peng, Yaohuan Huang, Jing Li, Junqiang Zhang, Bin Yang, and Xiaohan Liao. 2019. Estimating maize above-ground biomass using 3D point clouds of multi-source unmanned aerial vehicle data at multi-spatial scales. REMOTE SENS-BASEL 11, 22 (2019), 2678.

Automatic recognition of lactating sow postures by refined two-stream RGB-D faster R-CNN. Xunmu Zhu, Changxin Chen, Bin Zheng, Xiaofan Yang, Haiming Gan, Chan Zheng, Aqing Yang, Liang Mao, Yueju Xue, BIOSYST ENG. 189Xunmu Zhu, Changxin Chen, Bin Zheng, Xiaofan Yang, Haiming Gan, Chan Zheng, Aqing Yang, Liang Mao, and Yueju Xue. 2020. Automatic recognition of lactating sow postures by refined two-stream RGB-D faster R-CNN. BIOSYST ENG 189 (2020), 116-132.

Detection of fragmented rectangular enclosures in very high resolution remote sensing images. Igor Zingman, Dietmar Saupe, A B Otávio, Karsten Penatti, Lambers, IEEE T GEOSCI REMOTE. 54Igor Zingman, Dietmar Saupe, Otávio AB Penatti, and Karsten Lambers. 2016. Detection of fragmented rectangular enclosures in very high resolution remote sensing images. IEEE T GEOSCI REMOTE 54, 8 (2016), 4580-4593.