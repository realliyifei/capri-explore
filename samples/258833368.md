# Deep Learning Approaches to Lexical Simplification: A Survey

CorpusID: 258833368
 
tags: #Linguistics, #Computer_Science

URL: [https://www.semanticscholar.org/paper/a9429423352c9b15531d32a43b5cd560519a3214](https://www.semanticscholar.org/paper/a9429423352c9b15531d32a43b5cd560519a3214)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | False |
| By Annotator      | (Not Annotated) |

---

Deep Learning Approaches to Lexical Simplification: A Survey


Kai North knorth8@gmu.edu 
George Mason University
USA

Tharindu Ranasinghe 
Aston University
UK

Matthew Shardlow 
Manchester Metropolitan University
UK

Marcos Zampieri 
George Mason University
USA

Deep Learning Approaches to Lexical Simplification: A Survey

Lexical Simplification (LS) is the task of replacing complex for simpler words in a sentence whilst preserving the sentence's original meaning. LS is the lexical component of Text Simplification (TS) with the aim of making texts more accessible to various target populations. A past survey (Paetzold and Specia, 2017b) has provided a detailed overview of LS. Since this survey, however, the AI/NLP community has been taken by storm by recent advances in deep learning, particularly with the introduction of large language models (LLM) and prompt learning. The high performance of these models sparked renewed interest in LS. To reflect these recent advances, we present a comprehensive survey of papers published between 2017 and 2023 on LS and its sub-tasks with a special focus on deep learning. We also present benchmark datasets for the future development of LS systems.

# Introduction

LS improves the readability of any given text with the aim of helping vocabulary and literacy development. LS achieves this by replacing complex words in a sentence with simpler alternatives. LS returns a simplified sentence which can be passed to a TS system for further syntactic and grammatical simplification. The replaced complex words are those words which a general or targeted population found to be hard to read, interpret, or understand. Previous LS systems have been designed to simplify complex words for children, second language learners, individuals with reading disabilities or low-literacy (Paetzold and Specia, 2017b). LS therefore provides both developers and users with a degree of personalization that is unattainable through seq2seq or generative TS systems (Yeung and Lee and Yeung, 2018a).

Deep learning, and latterly, LLM and prompt learning, have revolutionized the way we approach many NLP tasks, including LS. Previous LS systems have relied upon lexicons, rule-based, statistical, n-gram, and word embedding models to identify and then simplify complex words (Paetzold and Specia, 2017b). These approaches would identify a complex word, for example, "bombardment" as being in need of simplification and would suggest "attack" as a suitable alternative ( Figure  1), hereby referred to as a candidate substitution.

State-of-the-art deep learning models, such as BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019), GPT-3 (Brown et al., 2020), and others, automatically generate, select, and rank candidate substitutions with performances superior to traditional approaches. These include relying on pre-existing lexicons, simplification rules, or engineered features (Saggion et al., 2022). There have been no surveys published on deep learning approaches for LS. The paper by Paetzold and Specia (2017b) is the most recent survey on LS but it precedes studies that demonstrate the headway made by state-of-theart deep learning approaches. A broad comprehensive survey on TS was published in 2021 (Al-Thanyyan and Azmi, 2021). However, this survey likewise does not cover recent advances in the field nor does it focus specifically on LS. This paper therefore continues pre-existing literature by providing an updated survey of the latest deep learning approaches for LS and its sub-tasks of substitute generation (SG), selection (SS), and ranking (SR).


# Pipeline

We structure this survey around the main components of the LS pipeline: SG, SS, and SR (Section 3). We also provide an overview of recent datasets (Section 4), and discuss open challenges in LS (Section 5.1). Normally, an LS pipeline starts with complex word identification (CWI). However, since it is often considered as a standalone precursor, we refer the reader to North et al. (2022b), for a detailed survey on CWI methods. Substitute Generation SG returns a number: k, of candidates substitutions that are suitable replacements for a previously identified complex word. Usually, an LS system will generate candidate substitution in the range of k = [1, 3, 5, or 10] with top-k referring to the most appropriate candidates. These candidate substitutions need to be more simple, hence easier to read, interpret, or understand than the original complex word. The candidate substitutions also need to preserve the original complex word's meaning, especially in its provided context. Substitute Selection SS filters the generated topk candidate substitutions and removes those which are not suitable. For instance, candidate substitutions which are not synonymous to the original complex word or that are more complex are often removed.

Substitute Ranking SR orders the remaining top-k candidate substitutions from the most to the least appropriate simplification. The original complex word is then replaced with the most suitable candidate substitution.


## Evaluation Metrics

All sub-tasks of the LS pipeline are evaluated using precision, accuracy, recall, and F1-score. Several additional metrics have also been used: potential, mean average precision (MAP), and accuracy at top-k. Potential is the ratio of predicted candidate substitutions for which at least one of the top-k candidate substitutions generated was among the gold labels (Saggion et al., 2022). MAP evaluates whether the returned top-k candidate substitutions match the gold labels as well as whether they have the same positional rank. Accuracy at top-k = [1, 2, or 3] is the ratio of instances where at least one of the candidate substitutions at k is among the gold labels.


# Deep Learning Approaches

Prior to deep learning approaches, lexicon, rulebased, statistical, n-gram, and word embedding models were state-of-the-art for SG, SS, and SR. As previously mentioned, Paetzold and Specia (2017b) have provided a comprehensive survey detailing these approaches, their performances, as well as their impact on LS literature. The following sections provide an extension of the work carried out by Paetzold and Specia (2017b). We introduce new deep learning approaches for LS and begin our survey of the LS pipeline at the SG phase. The recent developments in the CWI step of the pipeline have been extensively surveyed by North et al. (2022b).


## Substitute Generation

In 2017, word embedding models were state-ofthe-art for SG. Word embedding models, such as Word2Vec (Mikolov et al., 2013), were used alongside more traditional approaches, such as querying a lexicon, or generating candidate substitutions based on certain rules (Paetzold and Specia, 2017b). Word embedding models conducted SG by converting potential candidate substitutions into vectors, hence word embeddings, and then calculating which of these vectors had the highest cosine similarity, or lowest cosine distance, with the vector of the target complex word. These vectors were then converted back into their word forms and were considered the top-k candidate substitutions.

Word Embeddings + LLMs Post 2017, word embedding models continued to be implemented for SG. However, they were now combined with the word embeddings produced by LLMs or by a LLM's prediction scores. Alarcón et al. (2021a) experimented with various word embeddings models for generating Spanish candidate substitutions. They used word embeddings models, such as Word2Vec, Sense2Vec (Trask et al., 2015), and FastText (Bojanowski et al., 2016), along with the pre-trained LLM BERT, to generate these word embeddings. It was discovered that a more traditional approach that produced candidate substitutions by querying a pre-existing lexicon outperformed these word embedding models in terms of both potential and recall yet slightly under-performed these word embedding models in regards to precision. The traditional approach achieved a potential of 0.898, a recall of 0.597, and a precision of 0.043 on the EASIER dataset (Alarcón et al., 2021b  (Sense2Vec), on the other hand, attained a potential, recall, and precision score of 0.506, 0.282, and 0.056, respectively. Surprisingly, this went against the assumption that word embedding models would have achieved a superior performance given their state-of-the-art reputation demonstrated by Paetzold and Specia (2017a). During error analysis, it was found that these word embeddings models often produced antonyms of the target complex word as potential candidate substitutions. This is due to how word embedding models calculate word similarity between vectors. Seneviratne et al. (2022) used a word embedding model and a pre-trained LLM: XLNet (Yang et al., 2019), to produce an embedding similarity score and a prediction score for SG. They followed a similar approach conducted by Arefyev et al. (2020). Arefyev et al. (2020) utilized context2vec (Melamud et al., 2016) and ELMo (Peters et al., 2018) to encode the context of the target complex word to gain a probability distribution of each word belonging to that particular context. They then used this probability distribution to estimate the likelihood, or appropriateness, of a potential candidate substitution replacing the target complex word. This score was used alongside a LLM prediction score from either BERT, RoBERTa, or XLNet, to produce a final list of top-k candidate substitutions. Both Seneviratne et al. (2022) and Arefyev et al. (2020) discovered that their combined approach of using a word embedding model alongside a pretrained LLM prediction score failed to surpass the performance of using a single pre-trained LLM. For instance, Seneviratne et al. (2022) (2020) used LLMs trained on a MLM objective for multi-word LS, whereas Qiang et al. (2020) were the first to use MLM for Spanish SG. MLM has subsequently become a popular approach to SG. 7 out of the 11 system reports submitted to TSAR-2022 (Saggion et al., 2022), described their approach as consisting of a MLM objective.

Known as LSBert, the model introduced by Qiang et al. (2020), used the pre-trained LLM BERT. Sentences were taken from the LS datasets LexMTurk (Horn et al., 2014), BenchLS (Paetzold and Specia, 2016b), and NNSeval (Paetzold and Specia, 2016c). Two versions of each sentence were then concatenated, being separated by the [SEP] special token. They were then fed into the LLM. The first sentence was identical to that extracted from the datasets, whereas the second sentence had its complex word replaced with the [MASK] special token. The LLM then attempted to predict the word replaced by the [MASK] special token by taking into consideration its left and right context as well as the prior original sentence. In this way, LLMs provide candidate substitutions with the highest probability (highest prediction score) of fitting into the surrounding context and that are also similar to the target complex word in the original sentence. For the top-k=1 candidate substitution, LSBert achieved F1-scores for SG of 0.259, 0.272, and 0.218 on the three datasets LexMTurk (Horn et al., 2014), BenchLS (Paetzold and Specia, 2016b), and NNSeval (Paetzold and Specia, 2016c) respectively. These performances surpassed that of all prior approaches (Paetzold and Specia, 2017b). The previous highest F1-score was achieved by a word-embedding model (Paetzold and Specia, 2017a), which produced F1-scores of 0.195, 0.236, and 0.218 for each dataset, respectively.

Before the release of the TSAR-2022 shared-task (Saggion et al., 2022), Ferres and Saggion (2022) introduced a new dataset: ALEXSIS (TSAR-2022 ES), that would later make up (along with an additional English and Portuguese dataset) the TSAR-2022 dataset (Saggion et al., 2022). Using their Spanish dataset, they experimented with a number of monolingual LLMs pre-trained on either Spanish data as well as several multilingual LLMs, such as mBERT and RoBERTa. Ferres and Saggion (2022) adopted the MLM approach used by LS-Bert. They experimented with the Spanish LLMs: BETO (Cañete et al., 2020), BERTIN (De la Rosa and Fernández, 2022), RoBERTa-base-BNE, and RoBERTA-large-BNE (Fandiño et al., 2022) for SG. They discovered that their largest pre-trained Spanish LLM: RoBERTA-large-BNE, achieved the greatest SG performance after having also removed candidate substitutions equal to the complex word, regardless of capitalization or accentuation and being less than 2 characters long. North et al. (2022a) was inspired by the success of the monolingual LLMs shown by Ferres and Saggion (2022). They likewise tested a range of LLMs for SG with a MLM objective, including multilingual LLLMs: mBERT, and XLM-R (Conneau et al., 2020), and several monolingual LLMs, including Electra for English (Clark et al., 2020), RoBERTAlarge-BNE for Spanish, and BERTimbau (Souza et al., 2020) Wilkens et al. (2022) also used a range of monolingual LLMs for SG. However, they used an ensemble of BERT-like models with three different masking strategies: 1). copy, 2). query expansion, and 3). paraphrase. The copy strategy replicated that of LSBert (Qiang et al., 2020), whereby two sentences were inputted into a LLM concatenated with the [SEP] special token. The first sentence being an unaltered version of the original sentence, and the second sentence having its complex word masked. The query expansion strategy used Fast-Text to generate five related words with the highest cosine similarity to the target complex word. For iteration 2a). of the query expansion strategy, the first sentence was the original unaltered sentence, the second sentence replaced the complex word with one of the suggested similar words produced by FastText, and sentence 3 was the masked sentence. Iteration 2b). of this strategy was the same as iteration 2a)., however, sentence 2 now consisted of all five suggested words. Lastly, the paraphrase strategy generated 10 new contexts for each complex word composed of paraphrases of the original sentence. These new contexts were limited to 512 tokens. The ensembles used for these three masking strategies consisted of BERT and RoBERTa LLMs for English, several BETO LLMs for Spanish, and several BERTimbau LLMs for Portuguese. The paraphrase strategy showed the worst performance with a joint MAP/Potential@1 score of 0.217, whereas the query expansion strategy obtained a MAP/Potential@1 score of 0.528, 0.477, and 0.476 for English, Spanish, and Portuguese, respectively. This surpassed the performance of the paraphrase strategy and the original copy strategy used by LSBert, regardless of the LLMs used.

Prompt Learning Prompt learning has also been used for SG and is currently state-of-the-art (Table  3). Prompt learning involves feeding into a LLM input that is presented in such a way as to provide a description of the task as well as to return a desired output. PromptLS is an example of prompt learning applied to SG. Created by Vásquez-Rodríguez et al. (2022), PromptLS consisted of a variety of pre-trained LLMs fine-tuned on several LS datasets. These fined-tuned LLMs were then presented with four combinations of prompts: a). "a easier word for bombardment is", b). "a simple word for bombardment is", c). "a easier synonym for bombardment is", and lastly, d). "a simple synonym for bombardment is". These prompt combinations were supplied to a RoBERTa LLM on all of the English data extracted from the LexMTurk (Horn et al., 2014), BenchLS (Paetzold and Specia, 2016b), NN-Seval (Paetzold and Specia, 2016c), and CERF-LS (Uchida et al., 2018) LS datasets. They were also translated and fed into BERTIN fine-tuned on the Spanish data obtained from EASIER, along with BR-BERTo fine-tuned on all of the Portuguese data taken from SIMPLEX-PB (Hartmann and Aluísio, 2020). Vásquez-Rodríguez et al. (2022) also used these prompts on a zero-shot condition. It was discovered that the fine-tuned LLMs outperformed the zero-shot models on all conditions by an average increase in performance between 0.3 to 0.4 across all metrics: acc@1, acc@3, MAP@3, and Preci-sion@3. The prompt combinations that produced the best candidate substitutions were "easier word" for English, "palabra simple" and "palabra fácil" for Spanish, and "palavra simples" and "sinônimo simples" for Portuguese.

Prompt learning has likewise been applied to causal language models for SG, such as GPT-3. Aumiller and Gertz (2022) experimented with a variety of different prompts, which they fed into a GPT-3. These prompts were of four types: 1). zero-shot with context, 2). single-shot with context, two-shot with context, 3). zero-shot without context, and 4). single-shot without context. The size of each shot: n, refers to how many times a prompt is inputted into GPT-3. For instance, those shots with context would input a given sentence and then ask the question, "Given the above context, list ten alternative words for <complex word> that are easier to understand.", n number of times. Those without context, however, would input n times the following:"Give me ten simplified synonyms for the following word: <complex word>". Aumiller and Gertz (2022) also combined all types of prompts in an ensemble, generating candidate substitutions from each prompt type and then deciding upon final candidate substations through plurality voting and additional SS and SR steps (Section 3.2). Their ensemble approach outperformed all other prompt types and SG models submitted to TSAR-2022 (Saggion et al., 2022) (Table 3).


## Substitute Selection and Ranking

Traditional approaches to SS are still implemented post SG. Methods such as POS-tag and antonym filtering, semantic or sentence thresholds have been used to remove inappropriate candidate substitutions after having been generating from the above deep learning approaches (Saggion et al., 2022). Nevertheless, the majority of modern deep learning approaches have minimal SS, with SS often being simultaneously conducted during SG or SR. For instance, the metric used to generate the top-k can-didate substitutions, by it either similarity between word embeddings, or a pre-train LLM's prediction score, tends not to suggest candidate substitutions that are deemed as being inappropriate by other SS methods. Likewise, SR techniques that rank candidate substitutions in order of their appropriateness will in turn move inappropriate simplifications further down the list of top-k candidate substitutions to the point that they are no longer considered.

Word Embeddings Word embedding models continued to be used for SS without LLMs, regardless of the arrival of pre-trained LLMs, such as BERT. For instance, Song et al. (2020) created a unique LS system that filtered candidate substitutions by applying a semantic similarity threshold, matching only those candidate substitutions with the same POS tag as the target complex word, calculating contextual relevance, being a measure of how reasonable and fluent a sentence is after the complex word had been replaced, and by using cosine similarity between word embeddings to rank candidate substitutions. They generated word embeddings by Word2Vec and evaluated their model's performance on the LS-2007 dataset (Mc-Carthy and Navigli, 2007). It was found that the use of Word2Vec improved their model's performance having achieved an acc@1 of 0.269. Their second highest performing model, without the use of Word2Vec embeddings, produced an acc@1 of 0.218. (2018) created the neural readability ranker (NNR) for SR. Consisting of a feature extraction, a Gaussianbased feature vectorization layer, and a task specific output node, NNR is a deep learning algorithm capable of ranking candidate substitutions based on their perceived complexity. It performances regression, whereby having been trained on the Word Complexity Lexicon (WCL), as well as several features and character n-grams converted into Gaussian vectors, it is able to provide a value between 0 and 1 corresponding to the complexity of any given word. It achieves this by conducting pairwise aggregation. For each pair of potential candidate substitutions, the model predicts a value that defines which candidate substitution is more or less complex than the other. A return positive value indicates that the first candidate substitution is more complex than the second, whereas a negative value dictates that the second candidate substitution is more complex than the first. This is applied to all combinations of candidate substitutions given a complex word. Each candidate substitution is then ranked in accordance to its comparative complexity with all other potential candidate substitutions. Maddela and Xu (2018) applied their NNR model to the LS-2012 dataset and outperformed prior word embedding techniques for SR. They achieved an Prec@1 of 0.673, whereas the previous state-of-the-art model provided by Paetzold and Specia (2017a) achieved an Prec@1 of 0.656.


## Neural Regression Maddela and Xu

Word Embeddings + LLMs One of the most common approaches to SS and SR involves the use of word embeddings and LLMs. Seneviratne et al. (2022) filtered and ranked top-k=20 candidate substitutions based on the same combined score that they used for SG. It consisted of their MLM model's prediction score of the generated candidate together with the inner product of the target word's embedding and the embedding of the potential candidate substitution. These top-k=20 candidate substitutions were then subject to one of three additional ranking metrics. The first ranking metric (CILex_1) ranked candidate substitutions on their cosine similarity between the original sentence and a copy of the original sentence with the candidate substitution in place of its complex word. The second and third ranking metrics made use of dictionary definitions of the target complex word and its candidate substitutions. They calculated the cosine similarity between each embedding of each definition and the embedding of the sentence of the target complex word. Those with the highest cosine similarities between a). the definition of the target complex word and the definition of the candidate substitution (CILex_2), or b). the definition of the target complex word and the word embedding of the original sentence with the candidate substitution in place of its complex word (CILex_3), were used to determine the rank of each candidate substitution. They discovered that all three metrics produced similar performances on the TSAR-2022 dataset with CILex 1, 2, and 3 achieving acc@1 scores of 0.375, 0.380, and 0.386, respectively. Li et al. (2022) used a set of features taken from LSBert combined with what they referred to as an equivalence score. Equivalence score was created to gauge semantic similarity between candidate substitution and complex word to an extent that was more expressive than the cosine similarity between word embeddings. To obtain this equivalence score, they used a pre-trained RoBERTa LLM trained for natural language inference (NLI) which predicts the likelihood of one sentence entailing another. The model was trained on a multi-genre corpus with a MLM objective. The product of the returned likelihood of the original sentence with the candidate substitution preceding the original sentence and vice-versa equated to the equivalence score. Since Li et al. (2022) used the same method of SG as LSBert, having only changed their LLM to RoBERTa, they concluded that their system's superior performance was a consequence of its unique SR. They achieved an acc@1 of 0.659, whereas LSBert attained an acc@1 of 0.598 on the English TSAR-2022 dataset (Saggion et al., 2022).

Aleksandrova and Brochu Dufour (2022) ranked candidate substitutions on three metrics: a). grammaticality, b). meaning preservation, and c). simplicity. Grammaticality was calculated by firstly determining whether the candidate substitution had the same POS tag in terms of person, number, mood, tense, and so forth. Those that matched on all POS-tag categories were assigned the value of 1 or 0 if at least one category did not match. Preservation was determined by using BERTScore to generate cosine similarities between the embeddings of the original sentence and the embeddings of the original sentence, having replaced the target complex word with the candidate substitution. Lastly, preservation was obtained by using a CEFR vocabulary classifier trained on data from the English Vocabulary Profile (EVP). The data used to train the CEFR classifier was first masked and fed into a pre-trained LLM: BERT. The outputted encodings were then used to train an SVM model resulting in their CEFR classifier. Their model failed to surpass the baseline LSBert models at TSAR-2022 in terms of acc@1, having achieved a score of 0.544.


## MLM Prediction

Scores LS systems have also relied entirely on MLM prediction scores for SS and SR. North et al. (2022a) and Vásquez-Rodríguez et al. (2022) adopt this approach. They have no additional SR steps and rank their candidate substitutions per their generated MLM prediction scores. They do, however, apply some basic filtering with both studies removing duplicates as well as candidate substitutions equal to the complex word. Surprisingly, minimal SR has been shown to surpass other more technical approaches (Table 3). North et al. (2022a) has achieved state-of-the-art performance on the TSAR-2022 Portuguese dataset, whereas Vásquez-Rodríguez et al. (2022) has consistently produced high performances across the English and Spanish TSAR-2022 datasets. Only GPT-3 based-models have surpassed these performances (Aumiller and Gertz, 2022) (Table 3).


# Resources

Post 2017 LS datasets have been created for either all sub-tasks within the LS pipeline or for a specific purpose (Appendix, Table 2). Recent international competitions (shared-tasks) have also provided their own LS datasets (*). LS resources are available for multiple languages, predominately English (EN), Spanish (ES), Portuguese (PT), French (FR), Japanese (JP), and Chinese (ZH).


## English

Personalized-LS Lee and Yeung (2018b) constructed a dataset of 12,000 English words for personalized LS. These words were ranked on a fivepoint Likert scale. 15 native Japanese speakers were tasked with rating the complexity of each word. These complexity rating were then applied to BenchLS, in turn personalizing the dataset for Japanese speakers.

WCL Maddela and Xu (2018) introduced the Word Complexity Lexicon (WCL). The WCL is a dataset made up of 15,000 English words annotated with complexity ratings. Annotators were 11 nonnative English speakers using a six-point Likert scale.

LCP-2021* The dataset provided at the LCP-2021 shared-task (CompLex) , was developed using crowd sourcing. 10,800 complex words in context were selected from three corpora covering the Bible, biomedical articles, and European Parliamentary proceedings. Their lexical complexities were annotated using a 5-point Likert scale.


## SimpleText-2021* The

SimpleText-2021 shared-task (Ermakova et al., 2021) introduced three pilot tasks: 1). to select passages to be simplified, 2). to identify complex concepts within these passages, and 3). to simplify these complex concepts to generate an easier to understand passage. They provided their participants with two sources of data, these being the Citation Network Dataset, DBLP+Citation, ACM Citation network, together with titles extracted from The Guardian newspaper with manually annotated keywords.

TSAR-2022* TSAR-2022 (Saggion et al., 2022) supplied datasets in English, Spanish, and Portuguese. These datasets contained target words in contexts taken from journalistic texts and Wikipedia articles, along with 10 candidate substitutions (approx. 20 in raw data) provided by crowdsourced annotators located in the UK, Spain, and Brazil. The candidate substitutions were ranked per their suggestion frequency. The English, Spanish, and Portuguese datasets contained 386, 381, and 386 instances, respectively.


## Datasets in Other Languages

Spanish The ALexS-2020 shared-task (Zambrano and Ráez, 2020) included a Spanish dataset consisting of 723 complex words from recorded transcripts. Merejildo (2021) provided the Spanish CWI corpus (ES-CWI). A group of 40 nativespeaking Spanish annotators identified complex words within 3,887 academic texts. The EASIER corpus (Alarcón et al., 2021b) contains 5,310 Spanish complex words in contexts taken from newspapers with 7,892 candidate substitutions. A small version of the corpus is also provided with 500 instances (EASIER-500).

Portuguese The PorSimples dataset (Aluísio and Gasperin, 2010) consists of extracts taken from Brazilian newspapers. The dataset is divided into nine sub-corpora separated by degree of simplification and source text. The PorSimplesSent dataset (Leal et al., 2018) was adapted from the previous PorSimples dataset. It contains strong and natural simplifications of PorSimples's original sentences. SIMPLEX-PB (Hartmann and Aluísio, 2020) provides a selection of features for each of its candidate substitutions.

French ReSyf contains French synonyms that have been ranked in regards to their reading difficulty using a SVM (Billami et al., 2018). It consists of 57,589 instances with a total of 148,648 candidate substitutions. FrenchLys is a LS tool designed by Rolin et al. (2021). It provides its own dataset that contains sentences sampled from a French TS dataset: ALECTOR, and french schoolbooks. Substitute candidates were provided by 20 French speaking annotators.

Japanese The Japanese Lexical Substitution (JLS) dataset (Kajiwara and Yamamoto, 2015) con-tains 243 target words, each with 10 contexts (2,430 instances in total). Crowd-sourced annotators provided and ranked candidate substitutions. The JLS Balanced Dataset (Kodaira et al., 2016) expanded the previous JLS dataset to make it more representative of different genres and contains 2,010 generalized instances. Nishihara and Kajiwara (2020) created a new dataset (JWCL & JSSL) that increased the Japanese Education Vocabulary List (JEV). It houses 18,000 Japanese words divided into three levels of difficulty: easy, medium, or difficult.

Chinese Personalized-ZH (Lee and Yeung, 2018a) consists of 600 Chinese words. Each word's complexity was ranked by eight learners of Chinese on a 5-point lickert-scale. HanLS was constructed by Qiang et al. (2021). It contains 534 Chinese complex words. 5 native-speaking annotators gave and ranked candidate substitutions. Each complex word has on average 8 candidate substitutions.


# Discussion and Conclusion

Since the 2017 survey on LS (Paetzold and Specia, 2017b), deep learning approaches have provided new headway within the field. MLM is now the go to method for SG, with the majority of recent LS studies having employed a MLM objective. The casual language model: GPT-3, surpasses the performance of all other approaches when subjected to prompt learning, especially when an ensemble of prompts are taken into consideration (Table 3). The prediction scores of MLM or casual language modeling have replaced various SS and SR techniques. LS systems that employ minimal SS and no SR apart from ranking their LLM's prediction scores, have outperformed more technical, featureoriented, and unsupervised ranking methods (Table  3). However, an exception is made with regards to equivalence score (Li et al., 2022), which has been shown to be effective at SR.

Future LS systems will make use of new advances in deep learning. We believe prompt learning and models, such as GPT-3, will become increasingly popular, given their state-of-the-art performance at SG. Using an ensemble of various prompts for SS and SR may advance LS performance. In addition, the creation of new metrics similar to equivalence score will likewise be beneficial.


## Open Challenges in LS

LS has a number of open research areas that are either unaddressed, or the current body of work is inconclusive. In this brief section, we conclude this survey by outlining a few key areas for future development of LS research.

Evaluation: The metrics we use to evaluate LS are not perfect (Section 2.1). Automated metrics that condense a wide problem into a single numerical score can harm outcomes with human participants. Development of more faithful resources, as well as direct evaluation with intended user groups of simplification systems is a fruitful avenue for future work. This can be done by taking into consideration variation in data annotation instead of labels produced by aggregating unique annotations as in most datasets currently available.

Explainability: Lexical simplifications are inherently more explainable than sentence simplification as the operations are directly applied at the lexeme level. However, the decision process on whether to simplify and which word to choose is increasingly hidden behind the black-box of a model. Work to explain and interpret these decisions will allow researchers to better understand the opportunities and threats of applying modern NLP techniques to LS research. Personalization: One model does not fit all. The simplification needs of a language learner compared to a stroke victim, compared to a child are each very different. Modeling these needs and using them to personalize LS systems will allow for personalized simplification output more adequate the needs of particular user groups.

Perspectivism: Even within a population of common characteristics, each individual will bring a unique perspective on what and how to simplify. Systems which can alter their outputs to each user's needs will provide adaptive simplifications that go beyond our current technology. This will, in turn, improve the evaluation of LS models as previously discussed in this section.

Integration: LS is only one part of the wider simplification puzzle. Integrating LS systems with explanation generation, redundancy removal, and sentence splitting will further accelerate the adoption of automated simplification practices beyond the halls of research allowing such technology to reach a wider audience.

## Figure 1 :
1LS Pipeline. SG, SS, and SR are the main components of LS.


was outperformed by North et al. (2022a) on the TSAR-2022 dataset. Masked Language Modeling The introduction of pre-trained LLMs, also saw the arrival of Masked Language Modeling (MLM) for SG. Przy-była and Shardlow

## Table 1 :
1The top 3 deep learning approaches across the TSAR-2022 datasets. Best performances in bold.


for Portuguese. Their monolingual LLMs scored an acc@1 score of 0.517, 0.353, and 0.481 on the English, Spanish, and Portuguese TSAR-2022 datasets respectively. Whistely et al. (2022) also experimented with similar monolingual LLMs for SG. They used BERT for English, BETO for Spanish, and BERTimbau for Portuguese. Interestingly, their models' performances were lower compared to that of North et al. (2022a), despite their Portuguese LS system consisting of the same language model. Whistely et al. (2022) achieved acc@1 scores of 0.378, 0.250, and 0.3074 for English, Spanish, and Portuguese, respectively. This is likely due to the additional SS and SR steps implemented by Whistely et al. (2022) and the lack thereof shown within the LS system provided by North et al. (2022a) (Section 3.2).
Table 2: Datasets that can be used for LS arranged in chronological order. Marked datasets (*) were used in benchmark competitions. L1 and L2 refers to first and second language speakers.
(Saggion et al., 2022)
Automated Text Simplification: A Survey. S Suha, Aqil M Al-Thanyyan, Azmi, ACM Comput. Surv. 542Suha S. Al-Thanyyan and Aqil M. Azmi. 2021. Auto- mated Text Simplification: A Survey. ACM Comput. Surv., 54(2).

Exploration of Spanish Word Embeddings for Lexical Simplification. Rodrigo Alarcón, Lourdes Moreno, Paloma Martínez, Proceedings of CTTS. CTTSRodrigo Alarcón, Lourdes Moreno, and Paloma Martínez. 2021a. Exploration of Spanish Word Em- beddings for Lexical Simplification. In Proceedings of CTTS.

Lexical Simplification System to Improve Web Accessibility. Rodrigo Alarcón, Lourdes Moreno, Paloma Martínez, IEEE Access. 9Rodrigo Alarcón, Lourdes Moreno, and Paloma Martínez. 2021b. Lexical Simplification System to Improve Web Accessibility. IEEE Access, 9:58755- 58767.

RCML at TSAR-2022 Shared Task: Lexical Simplification With Modular Substitution Candidate Ranking. Desislava Aleksandrova, Olivier Brochu, Dufour, Proceedings of TSAR. TSARDesislava Aleksandrova and Olivier Brochu Dufour. 2022. RCML at TSAR-2022 Shared Task: Lexical Simplification With Modular Substitution Candidate Ranking. In Proceedings of TSAR.

Fostering digital inclusion and accessibility: The porsimples project for simplification of portuguese texts. Sandra Maria , Aluísio , Caroline Gasperin, Proceedings of YIWCALA. YIWCALASandra Maria Aluísio and Caroline Gasperin. 2010. Fostering digital inclusion and accessibility: The porsimples project for simplification of portuguese texts. In Proceedings of YIWCALA.

Always Keep your Target in Mind: Studying Semantics and Improving Performance of Neural Lexical Substitution. Nikolay Arefyev, Boris Sheludko, Alexander Podolskiy, Alexander Panchenko, Proceedings of COLING. COLINGNikolay Arefyev, Boris Sheludko, Alexander Podol- skiy, and Alexander Panchenko. 2020. Always Keep your Target in Mind: Studying Semantics and Im- proving Performance of Neural Lexical Substitution. In Proceedings of COLING.

UniHD at TSAR-2022 Shared Task: Is Compute All We Need for Lexical Simplification?. Dennis Aumiller, Michael Gertz, Proceedings of TSAR. TSARDennis Aumiller and Michael Gertz. 2022. UniHD at TSAR-2022 Shared Task: Is Compute All We Need for Lexical Simplification? In Proceedings of TSAR.

ReSyf: a French lexicon with ranked synonyms. B Mokhtar, Thomas Billami, Núria François, Gala, Proceedings of ACL. ACLMokhtar B. Billami, Thomas François, and Núria Gala. 2018. ReSyf: a French lexicon with ranked syn- onyms. In Proceedings of ACL.

. Piotr Bojanowski, Edouard Grave, Armand Joulin, Tomas Mikolov, arXiv:1607.04606Enriching Word Vectors with Subword Information. arXiv preprintPiotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2016. Enriching Word Vec- tors with Subword Information. arXiv preprint arXiv:1607.04606.

Prafulla Dhariwal, and Others. 2020. Language Models Are Few-Shot Learners. Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Proceedings of NeurIPS. NeurIPSTom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, and Oth- ers. 2020. Language Models Are Few-Shot Learn- ers. In Proceedings of NeurIPS.

Spanish pre-trained bert model and evaluation data. José Cañete, Gabriel Chaperon, Rodrigo Fuentes, Jou-Hui Ho, Hojin Kang, Jorge Pérez, Proceedings of PML4DC at ICLR. PML4DC at ICLRJosé Cañete, Gabriel Chaperon, Rodrigo Fuentes, Jou- Hui Ho, Hojin Kang, and Jorge Pérez. 2020. Span- ish pre-trained bert model and evaluation data. In Proceedings of PML4DC at ICLR.

ELECTRA: Pretraining text encoders as discriminators rather than generators. Kevin Clark, Minh-Thang Luong, Quoc Le, Christopher Manning, Proceedings of ICLR. ICLRKevin Clark, Minh-Thang Luong, Quoc Le, and Christopher Manning. 2020. ELECTRA: Pre- training text encoders as discriminators rather than generators. In Proceedings of ICLR.

Unsupervised cross-lingual representation learning at scale. Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Proceedings of ACL. ACLVishrav Chaudhary, and OthersAlexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, and Others. 2020. Unsuper- vised cross-lingual representation learning at scale. In Proceedings of ACL.

Zeroshot reading comprehension and reasoning for spanish with BERTIN GPT-J-6B. Javier De, La Rosa, Andres Fernández, Proceedings of SE-PLN. SE-PLNJavier De la Rosa and Andres Fernández. 2022. Zero- shot reading comprehension and reasoning for span- ish with BERTIN GPT-J-6B. In Proceedings of SE- PLN.

Bert: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Proceedings of NAACL. NAACLJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language understand- ing. In Proceedings of NAACL.

Josiane Mothe, and Others. 2021. Overview of SimpleText CLEF 2021 Workshop and Pilot Tasks. Liana Ermakova, Patrice Bellot, Pavel Braslavski, Jaap Kamps, Proceedings of LREC. LRECLiana Ermakova, Patrice Bellot, Pavel Braslavski, Jaap Kamps, Josiane Mothe, and Others. 2021. Overview of SimpleText CLEF 2021 Workshop and Pilot Tasks. In Proceedings of LREC.

Joaquin Silveira Ocampo, and Others. 2022. Maria: Spanish language models. Jordi Armengol Asier Gutiérrez Fandiño, Marc Estapé, Joan Llop Pàmies, Palao, Procesamiento del Lenguaje Natural. esamiento del Lenguaje Natural68Asier Gutiérrez Fandiño, Jordi Armengol Estapé, Marc Pàmies, Joan Llop Palao, Joaquin Silveira Ocampo, and Others. 2022. Maria: Spanish language models. Procesamiento del Lenguaje Natural, 68.

ALEXSIS: A dataset for lexical simplification in Spanish. Daniel Ferres, Horacio Saggion, Proceedings of LREC. LRECDaniel Ferres and Horacio Saggion. 2022. ALEXSIS: A dataset for lexical simplification in Spanish. In Proceedings of LREC.

Adaptação lexical automática em textos informativos do português brasileiro para o ensino fundamental. Nathan Siegle Hartmann, Sandra Maria Aluísio, Linguamática. 122Nathan Siegle Hartmann and Sandra Maria Aluísio. 2020. Adaptação lexical automática em textos infor- mativos do português brasileiro para o ensino funda- mental. Linguamática, 12(2):3-27.

Learning a lexical simplifier using Wikipedia. Colby Horn, Cathryn Manduca, David Kauchak, Proceedings of ACL. ACLColby Horn, Cathryn Manduca, and David Kauchak. 2014. Learning a lexical simplifier using Wikipedia. In Proceedings of ACL.

Evaluation Dataset and System for Japanese Lexical Simplification. Tomoyuki Kajiwara, Kazuhide Yamamoto, Proceedings of ACL. ACLTomoyuki Kajiwara and Kazuhide Yamamoto. 2015. Evaluation Dataset and System for Japanese Lexical Simplification. In Proceedings of ACL.

Controlled and Balanced Dataset for Japanese Lexical Simplification. Tomonori Kodaira, Tomoyuki Kajiwara, Mamoru Komachi, Proceedings of ACL. ACLTomonori Kodaira, Tomoyuki Kajiwara, and Mamoru Komachi. 2016. Controlled and Balanced Dataset for Japanese Lexical Simplification. In Proceedings of ACL.

A nontrivial sentence corpus for the task of sentence readability assessment in Portuguese. Sidney Evaldo Leal, Magali Sanches Duran, Sandra Maria Aluísio, Proceedings of COLING. COLINGSidney Evaldo Leal, Magali Sanches Duran, and San- dra Maria Aluísio. 2018. A nontrivial sentence cor- pus for the task of sentence readability assessment in Portuguese. In Proceedings of COLING.

Automatic prediction of vocabulary knowledge for learners of chinese as a foreign language. John Lee, Chak Yan Yeung, Proceedings of IC-NLSP. IC-NLSPJohn Lee and Chak Yan Yeung. 2018a. Automatic pre- diction of vocabulary knowledge for learners of chi- nese as a foreign language. In Proceedings of IC- NLSP.

Personalizing lexical simplification. John Lee, Chak Yan Yeung, Proceedings of COLING. COLINGJohn Lee and Chak Yan Yeung. 2018b. Personalizing lexical simplification. In Proceedings of COLING.

MANTIS at TSAR-2022 Shared Task: Improved Unsupervised Lexical Simplification with Pretrained Encoders. Xiaofei Li, Daniel Wiechmann, Yu Qiao, Elma Kerz, Proceedings of TSAR. TSARXiaofei Li, Daniel Wiechmann, Yu Qiao, and Elma Kerz. 2022. MANTIS at TSAR-2022 Shared Task: Improved Unsupervised Lexical Simplification with Pretrained Encoders. In Proceedings of TSAR.

Yinhan Liu, Myle Ott, Naman Goyal, arXiv:1907.11692Jingfei Du, and Others. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv preprintYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, and Others. 2019. Roberta: A robustly opti- mized bert pretraining approach. arXiv preprint arXiv:1907.11692.

A wordcomplexity lexicon and a neural readability ranking model for lexical simplification. Mounica Maddela, Wei Xu, Proceedings of EMNLP. EMNLPMounica Maddela and Wei Xu. 2018. A word- complexity lexicon and a neural readability ranking model for lexical simplification. In Proceedings of EMNLP.

SemEval-2007 Task 10: English Lexical Substitution Task. Diana Mccarthy, Roberto Navigli, Proceedings of SemEval. SemEvalDiana McCarthy and Roberto Navigli. 2007. SemEval- 2007 Task 10: English Lexical Substitution Task. In Proceedings of SemEval.

context2vec: Learning Generic Context Embedding with Bidirectional LSTM. Oren Melamud, Jacob Goldberger, Ido Dagan, Proceedings of SIGNLL. SIGNLLOren Melamud, Jacob Goldberger, and Ido Dagan. 2016. context2vec: Learning Generic Context Em- bedding with Bidirectional LSTM. In Proceedings of SIGNLL.

Creación de un corpus de textos universitarios en español para la identificación de palabras complejas en el área de la simplificación léxica. Borbor Merejildo, Universidad de GuayaquilMaster's thesisBorbor Merejildo. 2021. Creación de un corpus de tex- tos universitarios en español para la identificación de palabras complejas en el área de la simplificación léxica. Master's thesis, Universidad de Guayaquil.

Efficient Estimation of word Representations in Vector Space. Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean, Proceedings of ICLR. ICLRTomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient Estimation of word Represen- tations in Vector Space. In Proceedings of ICLR.

Word Complexity Estimation for Japanese Lexical Simplification. Daiki Nishihara, Tomoyuki Kajiwara, Proceedings of LREC. LRECDaiki Nishihara and Tomoyuki Kajiwara. 2020. Word Complexity Estimation for Japanese Lexical Simpli- fication. In Proceedings of LREC.

Tharindu Ranasinghe, and Marcos Zampieri. 2022a. GMU-WLV at TSAR-2022 Shared Task: Evaluating Lexical Simplification Models. Kai North, Alphaeus Dmonte, Proceedings of TSAR. TSARKai North, Alphaeus Dmonte, Tharindu Ranasinghe, and Marcos Zampieri. 2022a. GMU-WLV at TSAR- 2022 Shared Task: Evaluating Lexical Simplifica- tion Models. In Proceedings of TSAR.

Lexical Complexity Prediction: An Overview. Kai North, Marcos Zampieri, Matthew Shardlow, ACM Computing Surveys. 955Kai North, Marcos Zampieri, and Matthew Shard- low. 2022b. Lexical Complexity Prediction: An Overview. ACM Computing Surveys, 55(9).

SemEval 2016 Task 11: Complex Word Identification. Gustavo Paetzold, Lucia Specia, Proceedings of SemEval. SemEvalGustavo Paetzold and Lucia Specia. 2016a. SemEval 2016 Task 11: Complex Word Identification. In Pro- ceedings of SemEval.

Lexical simplification with neural ranking. Gustavo Paetzold, Lucia Specia, Proceedings of EACL. EACLGustavo Paetzold and Lucia Specia. 2017a. Lexical simplification with neural ranking. In Proceedings of EACL.

A Survey on Lexical Simplification. Gustavo H Paetzold, Lucia Specia, J. Artif. Int. Res. 601Gustavo H. Paetzold and Lucia Specia. 2017b. A Sur- vey on Lexical Simplification. J. Artif. Int. Res., 60(1):549-593.

Benchmarking Lexical Simplification Systems. Gustavo Henrique Paetzold, Lucia Specia, Proceedings of LREC. LRECGustavo Henrique Paetzold and Lucia Specia. 2016b. Benchmarking Lexical Simplification Systems. In Proceedings of LREC.

Unsupervised lexical simplification for non-native speakers. Gustavo Henrique Paetzold, Lucia Specia, Proceedings of AAAI. AAAIGustavo Henrique Paetzold and Lucia Specia. 2016c. Unsupervised lexical simplification for non-native speakers. In Proceedings of AAAI.

Deep Contextualized Word Representations. Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer, Proceedings of NAACL. NAACLMatthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep Contextualized Word Rep- resentations. In Proceedings of NAACL.

Multi-Word Lexical Simplification. Piotr Przybyła, Matthew Shardlow, Proceedings of COLING. COLINGPiotr Przybyła and Matthew Shardlow. 2020. Multi- Word Lexical Simplification. In Proceedings of COLING.

Lexical simplification with pretrained encoders. Jipeng Qiang, Yun Li, Zhu Yi, Yunhao Yuan, Xindong Wu, Proceedings of AAAI. AAAIJipeng Qiang, Yun Li, Zhu Yi, Yunhao Yuan, and Xin- dong Wu. 2020. Lexical simplification with pre- trained encoders. In Proceedings of AAAI.

. Jipeng Qiang, Xinyu Lu, Yun Li, Yunhao Yuan, Xindong Wu, Chinese Lexical SimplificationJipeng Qiang, Xinyu Lu, Yun Li, Yunhao Yuan, and Xindong Wu. 2021. Chinese Lexical Simplification.

Speech, and Language Processing. 29IEEE/ACM Transactions on Audio, Speech, and Lan- guage Processing, 29:1819-1828.

FrenLyS: A Tool for the Automatic Simplification of French General Language Texts. Eva Rolin, Quentin Langlois, Patrick Watrin, Thomas François, Proceedings of RANLP. RANLPEva Rolin, Quentin Langlois, Patrick Watrin, and Thomas François. 2021. FrenLyS: A Tool for the Automatic Simplification of French General Lan- guage Texts. In Proceedings of RANLP.

2022. Findings of the TSAR-2022 Shared Task on Multilingual Lexical Simplification. Horacio Saggion, Sanja Štajner, Daniel Ferrés, Kim Cheng Sheang, Matthew Shardlow, Kai North, Marcos Zampieri, Proceedings of TSAR. TSARHoracio Saggion, Sanja Štajner, Daniel Ferrés, Kim Cheng Sheang, Matthew Shardlow, Kai North, and Marcos Zampieri. 2022. Findings of the TSAR- 2022 Shared Task on Multilingual Lexical Simplifi- cation. In Proceedings of TSAR.

Sandaru Seneviratne, Elena Daskalaki, Hanna Suominen, CILS at TSAR-2022 Shared Task: Investigating the Applicability of Lexical Substitution Methods for Lexical Simplification. In Proceedings of TSAR. Sandaru Seneviratne, Elena Daskalaki, and Hanna Suominen. 2022. CILS at TSAR-2022 Shared Task: Investigating the Applicability of Lexical Substitu- tion Methods for Lexical Simplification. In Proceed- ings of TSAR.

The CW Corpus: A New Resource for Evaluating the Identification of Complex Words. Matthew Shardlow, Proceedings of ACL. ACLMatthew Shardlow. 2013. The CW Corpus: A New Re- source for Evaluating the Identification of Complex Words. In Proceedings of ACL.

CompLex -a new corpus for lexical complexity prediction from Likert Scale data. Matthew Shardlow, Michael Cooper, Marcos Zampieri, Proceedings of READI. READIMatthew Shardlow, Michael Cooper, and Marcos Zampieri. 2020. CompLex -a new corpus for lexi- cal complexity prediction from Likert Scale data. In Proceedings of READI.

A New Context-Aware Method Based on Hybrid Ranking for Community-Oriented Lexical Simplification. Jiayin Song, Jingyue Hu, Leung-Pun, Lap-Kei Wong, Tianyong Lee, Hao, Proceedings of DASFAA. DASFAAJiayin Song, Jingyue Hu, Leung-Pun Wong, Lap- Kei Lee, and Tianyong Hao. 2020. A New Context-Aware Method Based on Hybrid Ranking for Community-Oriented Lexical Simplification. In Proceedings of DASFAA.

BERTimbau: pretrained BERT models for Brazilian Portuguese. Fábio Souza, Rodrigo Nogueira, Roberto Lotufo, Proceedings of BRACIS. BRACISFábio Souza, Rodrigo Nogueira, and Roberto Lotufo. 2020. BERTimbau: pretrained BERT models for Brazilian Portuguese. In Proceedings of BRACIS.

Semeval -2012 task 1: English lexical simplification. Lucia Specia, Kumar Jauhar, Rada Sujay, Mihalcea, Proceedings of SemEval. SemEvalLucia Specia, Kumar Jauhar, Sujay, and Rada Mihal- cea. 2012. Semeval -2012 task 1: English lexical simplification. In Proceedings of SemEval.

Andrew Trask, Phil Michalak, John Liu, abs/1511.06388sense2vec -A Fast and Accurate Method for Word Sense Disambiguation In Neural Word Embeddings. ArXiv. Andrew Trask, Phil Michalak, and John Liu. 2015. sense2vec -A Fast and Accurate Method for Word Sense Disambiguation In Neural Word Embeddings. ArXiv, abs/1511.06388.

CEFR-based Lexical Simplification Dataset. Satoru Uchida, Shohei Takada, Yuki Arase, Proceedings of LREC. LRECSatoru Uchida, Shohei Takada, and Yuki Arase. 2018. CEFR-based Lexical Simplification Dataset. In Pro- ceedings of LREC.

UoM&MMU at TSAR-2022 Shared Task: Prompt Learning for Lexical Simplification. Laura Vásquez-Rodríguez, Nhung Nguyen, Sophia Ananiadou, Matthew Shardlow, Proceedings of TSAR. TSARLaura Vásquez-Rodríguez, Nhung Nguyen, Sophia Ananiadou, and Matthew Shardlow. 2022. UoM&MMU at TSAR-2022 Shared Task: Prompt Learning for Lexical Simplification. In Proceedings of TSAR.

PresiUniv at TSAR-2022 Shared Task: Generation and Ranking of Simplification Substitutes of Complex Words in Multiple Languages. Sandeep Peniel John Whistely, Galiveeti Mathias, Poornima, Proceedings of TSAR. TSARPeniel John Whistely, Sandeep Mathias, and Galiveeti Poornima. 2022. PresiUniv at TSAR-2022 Shared Task: Generation and Ranking of Simplification Substitutes of Complex Words in Multiple Lan- guages. In Proceedings of TSAR.

Isabelle Gribomont, and Others. 2022. CENTAL at TSAR-2022 Shared Task: How Does Context Impact BERT-Generated Substitutions for Lexical Simplification?. Rodrigo Wilkens, David Alfter, Rémi Cardon, Proceedings of TSAR. TSARRodrigo Wilkens, David Alfter, Rémi Cardon, Isabelle Gribomont, and Others. 2022. CENTAL at TSAR- 2022 Shared Task: How Does Context Impact BERT- Generated Substitutions for Lexical Simplification? In Proceedings of TSAR.

XLNet: Generalized Autoregressive Pretraining for Language Understanding. Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, V Quoc, Le, Proceedings of NeurIPS. NeurIPSZhilin Yang, Zihang Dai, Yiming Yang, Jaime Car- bonell, Ruslan Salakhutdinov, and Quoc V. Le. 2019. XLNet: Generalized Autoregressive Pretrain- ing for Language Understanding. In Proceedings of NeurIPS.

Personalized text retrieval for learners of Chinese as a foreign language. Yan Chak, John Yeung, Lee, Proceedings of COLING. COLINGChak Yan Yeung and John Lee. 2018. Personalized text retrieval for learners of Chinese as a foreign lan- guage. In Proceedings of COLING.

Anaïs Tack, and Marcos Zampieri. Chris Seid Muhie Yimam, Shervin Biemann, Gustavo Malmasi, Luci Paetzold, Sanja Specia, Štajner, Proceedings of BEA. BEASeid Muhie Yimam, Chris Biemann, Shervin Malmasi, Gustavo Paetzold, Luci Specia, Sanja Štajner, Anaïs Tack, and Marcos Zampieri. 2018. A Report on the Complex Word Identification Shared Task 2018. In Proceedings of BEA.

Overview of ALexS 2020: First Workshop on Lexical Analysis at SEPLN. Jenny Alexandra , Ortiz Zambrano, Arturo Montejo Ráez, Proceedings of ALexS. ALexSJenny Alexandra Ortiz Zambrano and Arturo Montejo Ráez. 2020. Overview of ALexS 2020: First Work- shop on Lexical Analysis at SEPLN. In Proceedings of ALexS.