# Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey

CorpusID: 257767458
 
tags: #Medicine, #Computer_Science

URL: [https://www.semanticscholar.org/paper/d135ec27b06266dcc013431a7778fc37e5e79f70](https://www.semanticscholar.org/paper/d135ec27b06266dcc013431a7778fc37e5e79f70)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | True |
| By Annotator      | (Not Annotated) |

---

Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey


Fatemeh Mosaiyebzadeh fatemehm@ime.usp.br 
Seyedamin Pouriyeh spouriye@kennesaw.edu 
Department of Information and Technology
Kennesaw State University
MariettaGAUSA

Reza M Parizi rparizi1@kennesaw.edu 
Decentralized Science Lab
School of Computing
Kennesaw State University
MariettaGAUSA

Macquarie University
SydneyAustralia

Institute of High Performance Computing and Networking
Binjiang Institute of Zhejiang University
HangzhouZhejiangChina

National Research Council
NaplesItaly

Quan Z Sheng 
Meng Han mhan@zju.edu.cn 
¶ 
Liang Zhao 
Department of Information and Technology
Kennesaw State University
MariettaGAUSA

Giovanna Sannino giovanna.sannino@icar.cnr.it 
Daniel Macêdo Batista 

Department of Computer Science
University of São Paulo
Brazil

Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey
Index Terms-Privacy enhancing technologiesInternet of Healthcare ThingsFederated learningSecurityPrivacy
Advancements in wearable medical devices in IoT technology are shaping the modern healthcare system. With the emergence of the Internet of Healthcare Things (IoHT), we are witnessing how efficient healthcare services are provided to patients and how healthcare professionals are effectively used AIbased models to analyze the data collected from IoHT devices for the treatment of various diseases. To avoid privacy breaches, these data must be processed and analyzed in compliance with the legal rules and regulations such as HIPAA and GDPR. Federated learning is a machine leaning based approach that allows multiple entities to collaboratively train a ML model without sharing their data. This is particularly useful in the healthcare domain where data privacy and security are big concerns. Even though FL addresses some privacy concerns, there is still no formal proof of privacy guarantees for IoHT data.Privacy Enhancing Technologies (PETs) are a set of tools and techniques that are designed to enhance the privacy and security of online communications and data sharing. PETs provide a range of features that help protect users' personal information and sensitive data from unauthorized access and tracking. This paper reviews PETs in detail and comprehensively in relation to FL in the IoHT setting and identifies several key challenges for future research.

## I. INTRODUCTION

In recent years, we have witnessed an accelerated growth of IoT devices in various domains such as healthcare [1], smart transportations [2], smart home and building [3], and smart cities [4]. In the healthcare domain, IoT technology has shown its capabilities and applications in collecting patients' data to enable healthcare professionals to analyze the data for better and more efficient treatment of various diseases. These devices are designed to automatically collect, send, receive, and store data over the networks in order to proactively detect, diagnose, monitor, and treat patients both in and out of the healthcare systems.

Internet of Healthcare Things (IoHT) is a sub-type of the Internet of Things (IoT) oriented to e-health by combining various smart devices such as smart watches, wearable trackers, and other smart connected devices to record various health measures such as heart rate, body temperature, and blood pressure [5]. A huge amount of information collected from those variety of IoHT devices and applications is later employed in data analytics where it is empowered with Artificial Intelligence (AI) and Machine Learning (ML) models to mine such information and improve the health decision making.

Traditionally, healthcare organizations use centralized MLbased models in clouds or data centers to train the data generated by IoHT devices aiming to take reliable decisions in the healthcare domain. However, such models usually suffer from performance and accuracy issues due to the unavailability of sufficient data to reside centrally on the server side for training due to direct access restrictions/regulations (HIPAA and GDPR) on such data, where all may lead to biased models that cannot be trustworthy [6] [7]. Additionally, even with sufficient data, the training procedure in a centralized setting is time-consuming and expensive tasks make them out of interest of hospitals and research centers [8].

Recently, the Federated Learning (FL) concept has been discovered as a promising way for the eHealth systems to overcome data privacy concerns in IoHT [9]. FL is a distributed ML-based approach that maintains patients' data where they are generated and enables the training of ML models collaboratively on multiple clients' health data like hospitals or IoHT devices in a decentralized network [10] [11]. However, recent studies have shown that sometimes FL can not guarantee proper privacy-preserving [12].

Privacy Enhancing Technologies (PETs) are a set of tools and techniques that are designed to enhance the privacy and security of online communications and data sharing. PETs provide a range of features that help protect users' personal information and sensitive data from unauthorized access and tracking. The development of PETs can offer a reliable pathway toward data-driven technologies such as MLbased models while preserving privacy. PETs are a group of methods, procedures, and techniques to extract value from data, and simultaneously reduce the privacy and security risk to private data [13]. PETs are crucial, especially in industries like healthcare that collect and use sensitive data extensively. In healthcare domain, collected patient data allow researchers and healthcare professionals to distinguish disease, drug development, and improve public health. For instance, vaccine development research during the COVID-19 pandemic has shown the importance of information in public health.

There are various PETs that can be utilized to improve privacy in FL. For example, secure multi-party computation (SMPC) [14], syntactic anonymization such as k-anonymity [15], homomorphic encryption [16], zeroknowledge proofs [17], differential privacy [18], and blockchain techniques [19] are some of those techniques that are aligned with FL framework and will be discussed in this paper.

In this paper, we aim to explore the privacy concerns in FL environment from PET perspective and discuss how PETs are integrated into FL to enhance privacy issues.

To the best of our knowledge, there is no current research to provide a comprehensive survey on FL for the IoHT from a PET perspective. To fill this research gap, we comprehensively reviewed PETs and FL integration in smart healthcare environments. This paper reviews the main topics of privacy and FL in smart healthcare systems. Initially, we reviewed the privacy requirements and the cause of privacy leakage and violation in FL. Then, we review the PETs approach according to four PETs applied to FL. Finally, we summarize the PETs applied to FL and present some open issues.

The remaining part of this paper is organized as follows. Section II summarizes the surveys similar to ours while highlighting the differences. In Section III, we provide the general principles of FL and the different sorts of this technique used in smart healthcare environments. We provide the motivations for using the privacy-preserving FL in smart healthcare in Section V. Section VI is dedicated to a complete literature review of PETs. Section VII presents PET's application on FL in the smart healthcare environment. Section VIII presents open issues related to PETs in FL and concluding remarks are given in Section IX. Fig. 1 depicts a systematic outline of this survey paper.


## II. RELATED WORK

There are many review papers that cover a wide range of security and privacy challenges in FL environment that are either dedicated in other domains or covered security and privacy issues at the general level. In this section, we tried to discuss the most recent and similar to our work.

In [20], the focus is to provide an overview of FL, highlighting protocols, platforms, algorithms, market implications, and real-life use-cases, in terms of software and hardware. The advantage related to privacy, brought by FL, is presented in some parts of the work but this is not the main focus of the paper. Some use-cases related to health applications are presented but there are no comments about IoHT (In fact, authors state that IoT is not the focus of the paper).

The authors in [21] provide a formal definition of FL and review the existing works using FL. The works are evaluated in terms of five aspects and one of these aspects is privacy mechanisms. Three mechanisms are considered: model aggregation, homomorphic encryption, and differential privacy. In our survey, we focus on privacy and consider a different approach, classifying four techniques: anonymization, cryptography, perturbation method, and blockchain. Similar to [20], in [21] some use-cases related to health applications are presented but there are no comments about IoHT.

The authors in [22] review the FL method specifically in terms of both security and privacy. Different implementations of FL are considered and evaluated. Some of the FL threats in terms of security and privacy are similar to those considered in our paper. Some applications are oriented to IoT but there are no comments about IoHT.

In [23], the authors focused on the IoT domain only. Similar to [21], a formal definition of FL is presented. Healthcare applications are considered in the survey but the comparison and analysis of the works do not specify what privacy attacks the works are oriented to and neither the datasets used by them.

In another effort [24], a number of privacy-preserving mechanisms adopted for FL frameworks are evaluated by the authors, as well as their application to vehicle activity recognition. In this study, they examined the open-source FL frameworks FATE and PFL. The FATE framework uses homomorphic encryption to secure computations and input data, while PFL uses multi-party secure computations and differential privacy to protect the processing of vertically partitioned data and train neural networks for horizontally partitioned data. Similar to [21] and [20], there are no comments about IoHT in the survey.

Nguyen et al. [25] represent the summary of FL in the Internet of Medical Things (IoMT). In this study, a federated EHR management system, a federated remote monitoring system, a federated COVID-19 detection system, and a federated medical imaging system were discussed. Innovative FL designs for IoMT are investigated, including secure FL, resource-aware FL, and incentive-aware FL. Also, privacyenhanced FL to protect security is explored, but this is not the main focus of the paper. Similar to [24], in [25], among the privacy-enhancing mechanisms, differential privacy method is taken into consideration, while in our survey, we examine four different technologies that enhance privacy.

To the best of our knowledge, this work is the first survey specifically focused on reviewing Federated Learning applications in IoHT from the perspective of Privacy-Enhancing Technologies. A side-by-side comparison of recent efforts in this domain is shown in Table I.


## III. FEDERATED LEARNING FOR HEALTHCARE

The overall FL principle and the many FL types in the context of e-healthcare are discussed in this section.


## A. Principles of FL for Smart Healthcare

Privacy breaches have become a major concern for users' data. Therefore, governments establish policies to prevent privacy leakage in order to preserve users' data privacy. Breaching these policies is expensive for companies, and it has boosted the development of FL in 2016 by Google [26] [27]. FL or collaborative learning trains a global machine learning model without explicitly exchanging the local data on multiple parties. In an FL system, clients train local machine-learning models on local datasets and exchange some parameters like gradients or model weights with the central server to obtain a global model.

In general, the FL process for IoHT consists of the following steps:

1) Initialization: The aggregation server selects data generated by IoHT devices, such as Blood Sample Reader or human motion detection to do the prediction or classification task. Furthermore, the central server chooses a group of participants to participate in the FL process.

2) Updating Local Training model: The server sends an initial model to the devices to initiate the distributed training after choosing the IoHT devices for the learning process. Each device computes its updated model by training a local model with its own dataset that is kept locally. Then, each device sends its updated model to central the server in order to aggregate all of the updated models. 3) Model Aggregation: After receiving the parameters from each IoHT device in the FL process, the aggregation step combines all parameters to generate a global learning model. Federated Averaging (FedAvg) algorithm is an averaging model which we can use to calculate the global model and send it to all IoHT devices for updating the local model.


## B. FL Types for Smart Healthcare

Studying the FL methods utilized in various domains shows that based on data partitioning, FL methods can be categorized into Horizontal FL, Vertical FL, and Federated Transfer Learning.

In horizontal FL, or sample-based federated learning, the datasets of different healthcare clients have the same feature space and different sample space. Since the local data are in the same feature space, local healthcare participants can train the local model using their local data by the same AI model such as the neural network model. Afterwards, the global model simply can be updated by combining all the local models transmitted from local healthcare organizations or institutions [28]. A horizontal FL example in smart healthcare can be multiple implanted medical devices from different hospitals as clients, that collect very similar data but have little to no overlap of patients [29].

In vertical FL, the datasets of different healthcare organizations have similar sample spaces and different feature spaces. This method can be used to address the overlapping sample at distributed clients. The vertical FL usually utilizes entity alignment techniques to collect the overlapped samples of the hospitals. Then, the overlapped data can be applied to the local training model integrated with encryption techniques [30]. An example of vertical FL in IoHT applications can be the shared learning model between hospitals and cardiologists. Both hospitals and cardiologists with various data features, which have patients with a similar sample space, use a vertical FL for training an AI model by utilizing historical medical records at hospitals and cardiologist data for smart healthcare decisions [31].

Federated Transfer Learning is an integration of transfer learning into federated learning to handle datasets that have various sample spaces and various feature spaces. In fact, transfer learning is a way to transfer knowledge from one particular problem to another to decrease the distribution divergence between different domains [32]. An example of federated transfer learning in healthcare organizations can be disease diagnosis by collaborating countries with numerous hospitals that have various patients and various therapeutic programs [33].


## IV. PRIVACY REQUIREMENTS FOR IOHT SYSTEMS

For IoHT devices, privacy requirements are more stringent than for typical IoT infrastructures. IoHT healthcare systems have some privacy requirements, such as data protection privacy [34]. During the collection and storage of patient data, we must continually take into account ethical privacy regulations throughout the entire data lifecycle. For instance, Privacy policies such as GDRP and HIPAA are laws for preserving privacy at the data level [35]. According to privacy policies, only authorized individuals can have access to patient health data. In fact, data privacy protection is a way to preserve personal data from unauthorized use and manipulation.

Thus, to protect the privacy of patient data, the IoHT system should be designed to guarantee the following [36]:

• Preserve the privacy of patients and the confidentiality of patient health care data (prevention of unauthorized access to health information). • The integrity of healthcare data (prevention of unauthorized data manipulation). • The availability of health data for authorized people.


## V. MOTIVATION OF USING PRIVACY-PRESERVING FL IN


## SMART HEALTHCARE

In the next two sections, we will summarily cover the benefit FL and the potential threats of using FL in smart healthcare.


## A. Benefits of FL in IoHT

Due to various characteristics of FL such as privacypreserving, and collaborative learning in a distributed data environment bring many advantages to the IoHT domain that will be discussed briefly in the next subsections.

1) Improving the privacy of user data: With increasing the number of IoHT devices and publicly available medical datasets generated by IoHT devices, privacy concerns are also growing in the e-healthcare systems. Collected data by IoHT devices, such as heartbeat, blood pressure, and glucose level, is more sensitive compared to other types of data. According to data privacy protection legislation, private patient data is the most sensitive data and is restricted by government laws. To address data privacy challenges in the e-healthcare domain, FL offers a decentralized training mechanism where each client or institution can control private data and define a privacypreservation policy [37]. In the FL framework, the raw health data are stored at a medical devices or local site and do not leave the IoHT devices during the federated data training process. During model training, only the local updates like model gradients need to be sent to the central server, which reduces the risk of sensitive and personal data leakage and ensures a high level of patient data privacy [38].

2) Less biased model: Because a centralized model can only be trained using limited data from a single hospital, the result may be biased in the predictions. Therefore, mitigation bias recently gains a lot of attention in modern machine learning techniques [39]. Thus, for models to be more generalizable, more data must be used, which can be achieved through data sharing between organizations. However, exchanging patients' electronic health data between hospitals is against their data security and privacy because healthcare data is sensitive [40]. Under these circumstances, to address the bias issue, federated learning has emerged as an option for building a collaborative learning model for healthcare data and producing models that yield unbiased results. The trained model is less biased and smarter as different datasets from various sources are integrated into the learning process [41].

3) Improving the scalability: In the centralized model, uploading all of the healthcare data to the server leads to a waste of computing resources, breaches privacy, and puts more pressure on the wireless communication network, which declines the network's scalability. However, FL's distributed nature enables the scalability of IoHT networks [42]. In fact, FL has the ability to use the computational resources located at multiple IoHT devices across different hospitals located in different geographic regions in a parallel manner. For instance, when new hospitals or healthcare institutions participate, they add more computational resources in the federated learning process. Therefore, these more computational resources allow federated learning to enhance performance. Moreover, the FL architecture avoids sending the massive amounts of IoHT data gathered to the cloud, which can result in significant network bandwidth saving and drastically reduce communication costs [43] [44].


## B. Privacy Leakage and Potential Threats in Federated Learning

Although FL provides a privacy-aware framework to train a global model without sharing data and allows clients to use the framework using their local dataset, recent works have shown that FL can face privacy breaches and information leakage.

The FL frameworks restrict sharing data on local devices with third-party or central servers. Nonetheless, it is possible to reveal sensitive information through the back-tracing of gradients and update the communication models through the training process [45] [46]. For example, Zhu et al. [47] introduces a deep leakage from Gradient (DLG), which shows malicious attackers can steal the training data in a few iterations. In their study, they showed how private training data can be easily leaked because of sharing the gradients. Similarly, Aono et al. [48] reported that accessing a small portion of original gradients may cause leakage in local training data. Although FL models on decentralized data sources have shown promising results with respect to preserving data privacy. But, it is still vulnerable to several types of attacks such as poisoning attacks [49], inference attacks [50], and backdoor attacks [51].

In a poisoning attack, which occurs during the training time, an attacker tries to manipulate the training data sample by injecting designed samples to compromise the whole learning process [52]. In Poisoning attacks including data poisoning attack [53] and model poisoning attack [54] the ultimate goal of attackers is to change the behavior of the target model. A data poisoning attack aims to mislead the global model by manipulating the local training data. The attacker flips the labels of training data and adds noise in order to degrade the quality of models [55]. Fig. 2 shows how an attacker changes the trained model by flipping the data labels. In the model poisoning attack, the attacker attempts to manipulate local model updates before sending the models to the server. This method includes various techniques to manipulate the FL local training procedure, such as direct gradient manipulation and changing the learning rule [56].

In an inference attack, the attacker aims to exchange gradients during the FL training process, which can result in serious information leakage about the features of clients' training data. The inference attack includes inferring class representatives [57], inferring membership [58], inferring data properties [59], and inferring samples/labels [60]. In the inference of class representatives, the adversary creates samples that are not in the original training dataset. Attackers use these false samples to learn sensitive information about the training dataset [61]. The inference of memberships tries to determine whether a given data sample has been used for model training [62]. In the property inference attack, the attacker aims to infer the property information of the training dataset [63]. In the inferring samples, the attacker recreates labels from the gradients and recovers the original training samples that are used during training [64]. In a backdoor attack, the goal of the attacker is to destroy the global FL model and then replace the actual global FL model with the attacker's model [65]. This attack can be also classified as a type of model poisoning attack, but it is more harmful than poisoning attacks [51]. In fact, the attacker  are designed to enable companies to embed privacy-by-design principles into their data governance practices to minimize the amount of personal data they collect, use and share while maximizing data security and privacy. In this context, our objective is to explore how PETs can be utilized to enhance privacypreserving in FL to improve patient data privacy in IoHT devices and e-healthcare. Four wide categories of PETs are used to improve privacy protection, including (1) anonymization technique [68], (2) cryptographic technique [69], (3) perturbation technique [70], and (4) blockchain technique [71].


## A. Anonymization Techniques

Anonymization techniques are broadly used for privacy enhancing by changing the state of a data set and removing the identifier from dataset information in a way so that the dataset is usable and protects the privacy of individual's personal information [72]. Anonymity technology can better avoid the leakage of sensitive patient data and provide more secure environment for smart healthcare systems. There are several anonymization technologies that are appropriate for big medical data, which are based on three categories of widely used anonymity protection techniques: k-anonymity, ldiversity, and t-closeness models [73].

The idea of k-anonymity is to anonymize the quasi-identifier in the dataset that can be used by attackers to identify sensitive information about individuals. After selecting the quasiidentifiers, k-anonymity applies for each sample in the dataset, which can guarantee that each sample in the dataset cannot be re-identified from at least k-1 samples [74]. l-diversity is an extension of the k-anonymity mechanism to enhance privacy against against homogeneity attacks and background knowledge attacks on k-anonymity [75]. l-diversity ensures that there are at least l "well-performing" values for the sensitive attributes and protects against attribute disclosure [76]. Finally, t-closeness is proposed to reduce attacks against k-anonymity and l-diversity approaches and solve the attribute disclosure problem [77].


## B. Cryptographic Techniques

Cryptographic techniques have been used to avoid privacy disclosure of individual's private data in federated learning [78]. These methods consist of homomorphic encryption, secure multi-party computation, and zero-knowledge proofs.

Homomorphic encryption is a form of encryption for privacy-enhancing in FL to prevent information leakage during the parameter exchanging process among clients. In this method, parameters are encoded before adding or multiplying operations [79]. There are two main widely used homomorphic encryption methods: fully homomorphic encryption and partially homomorphic encryption. Fully homomorphic encryption supports both additive and multiplicative operations on ciphertext, while partially homomorphic encryption only supports either additive or multiplicative operations on the ciphertext. Compared with partially homomorphic encryption, fully homomorphic encryption provides stronger encryption, and both can be applied to horizontal and vertical federated learning [80].

Secure multi-party computation (SMC) [81] is a sub-field of cryptographic schemes to protect private information. SMC can be used to solve the problem of collaborative computing between all parties such that no party learns anything about other participants' data [82]. The application of SMC allows multiple participants to concentrate on safely calculating a function for various participant without the requirement of trusted third-parties and revealing input. However, due to the additional encryption and decryption operations, SMC suffers from computational overhead and high communication costs [83].

Zero-knowledge proofs (ZKP) [84] is a cryptographic system to achieve both input privacy and verifiability in federated learning [85]. A zero-knowledge proof involves a prover to make sure with another entity called a verifier that distinguishes the validity of a given statement. ZKP can be an appropriate method for verification of sensitive healthcare data among collaborators because it allows sharing data securely and privately between multiple participants [86].


## C. Perturbation Techniques

A perturbation method is to protect private data and model privacy by adding random noise to the original data or training data during the training process. The differential privacy technique is a widely used perturbation method implemented in the FL frameworks in medical applications. It is one of the PETs methods and guarantees privacy [87] using probability statistical models to mask sensitive private data in a dataset [88] and protect healthcare data against inference attack on FL frameworks. By adding noise to the model parameters or data, data can be deferentially private [89] [90], and the parties cannot realize whether an individual record participates in the learning process or not. Differential privacy techniques include two categories: global differential and local differential privacy techniques. In the global differential privacy (GDP) setting, there is a trusted curator that applies carefully random noise to the real values returned for a particular query [91]. Different from GDP, a local differential privacy (LDP) technique does not need a trusted third-party. In fact, LDP allows users to locally perturb the input data, and it often produces too noisy data, as noise is applied to achieve individual record privacy [92]. As an advantage, the differential privacy technique by adding random noise makes data sets more secure because an attacker cannot distinguish which information is true. Therefore, more noises that are added to the sensitive data have a direct relationship to how the data is hard for an attacker to recognize true information about individuals in the dataset [93].


## D. Blockchain Techniques

Blockchain is beneficial in many non-financial industries such as healthcare due to its cryptographic security, immutability, and accountability [98]. Researchers have recently started implementing blockchain technology to decentralize traditional data management systems. For instance, blockchainbased data management prevents security breaches and assure GDPR compliance [99]. Therefore, blockchain-based PETs solutions can be used in Medical IoT to safeguard individuals' rights over their personal data [100]. Accordingly, Blockchain is a promising technique to improve the security and scalability of the FL system. This technique has provided a high level of security in the domain of healthcare by integrating blockchain into a federated learning to maintain the trained parameters [101]. The blockchain-based system is effective for decentralized federated learning training without the need for any central server which can mitigate risks of single-point failures [102]. To provide IoHT data provenance, blockchain has shown great promise, and also provides permission control of the participants to enhance the security and privacy of parameters in federated learning. Blockchain has gained popularity for managing the trust and provenance of trustworthy federated nodes, their datasets, the accuracy of the models, and the immutability of the global model [103]. A blockchain method consists of public (permissionless), private and consortium (permissioned). A public blockchain system allows any client to participate in the decentralized process without the need for authorized permission. In a private and consortium system, only the client with authorized permission can be involved in the block validation and confirmation process.


## VII. PETS IN FEDERATED LEARNING

In this section, we discuss the security and privacy issues in FL from PETs perspective. The PETs used in FL can be classified in several categories detailed as follows.


## A. Anonymization Methods

Several research has been published in the literature that integrates anonymization techniques and FL [104] [105] [106], and some of these studies attempt to evaluate the incorporation  [96] Preserving private data MNIST × -Non-negative matrix with high accuracy HARUS factorization [97] Avoiding an attack from eICU × Inference attack Anonymous random an untrustable central hybridization analyzer in FL & obtain similar performance compared with a centralized model of FL and anonymization methods in a smart healthcare environment [107]. For instance, in [94], the authors proposed a syntactic anonymity approach to guarantee privacy in federated learning. They used the anonymization based on (k, k n )anonymization algorithm. This approach contains two steps. In the first step, the anonymization method is applied to the original private data, which includes relational and a transactional attributes, at the local site and then feeds this anonymized data to a global model. The second step is a global anonymization mapping process, which can be used for the prediction process in the FL global model. They evaluated the proposed method using Medical Information Mart for Intensive Care (MIMIC III) 1 dataset gathered from one million patients. The results demonstrated that this approach enhances the level of privacy compared to the differential privacy method in FL. Similarly, Grama et al. [95] presented an adaptive privacypreserving FL method for healthcare data. In order to enhance privacy, they used the k-anonymity method on top of the FL that can protect data by anonymization. In fact, anonymization by applying the data protection method can cause information loss. But, the proposed k-anonymity method in this paper decreases losing data. Similar to [94], the authors evaluated the performance of the proposed approach based on two health datasets to predict diabetes mellitus onset 2 and heart failure diseases 3 . Their results showed that the k-anonymity method using k=4 can improve the protection of the healthcare data, if it is applied to a dataset that contains an adequate number of samples.

In [96], the author presented a federated PF-NMF framework. This FL framework contains multiple local privacy filters (PF), which are used to remove sensitive data to minimize the risk of privacy leakage. In the training phase, PF acts as an encoder. The framework includes a decoder in the testing phase and feeds the test data into the autoencoder. The author evaluated the proposed approach on the MNIST 4 and HARUS dataset (human static and dynamic activities gathered by wearable devices) 5 . The results showed that federated PF-NMF achieves better accuracy and enhances the privacy of sensitive data.

In another work [97], the authors proposed a new method called federated machine learning with anonymous random hybridization (FeARH) to eliminate the privacy problems in an untrustworthy central analyzer. The hybridization algorithm adds the randomization into the parameter sets shared with other parties. With a hybrid algorithm, the medical data, which is replaced by a randomized parameters, do not need to be shared with other institutions. They evaluated the proposed approach on eICU dataset 6 and the results showed that FeARH achieves similar performance compared with FL and centralizes the machine learning method. Similar to [96], in [97] the authors use anonymized data in the training phase. Table II summarizes the representative existing anonymization techniques applied for FL in smart healthcare.


## B. Cryptographic Algorithms

Cryptographic methods are widely used in several FL methods to preserve data privacy when exchanging intermediate parameters during the FL training process [113] [114] [115]. For example, similar to [97] which covers smart healthcare domain, Zhang et al. [108] presented the FL mechanism in the Internet of Healthcare Things (IoHT). They applied the cryptographic masking scheme based on homomorphic encryption and the secure multi-party computation to protect private medical data against reconstruction attacks or model inversion attacks. To evaluate the efficiency of the proposed FL model and validity of the privacy-enhancing masking scheme, the authors used real skin cancer datasets 7 . The result showed  [109] Securing FL environ-UP-FALL × Inference attack xMK-CKKS multi-key ment on IoHT devices homomorphic encryption [110] Enhancing patient's 3D brain MRI × Membership fully homomorphic data privacy inference attack encryption (FHE) [111] Protect medical data eICU × Reverse Secure multi-party computation privacy on IoHT devices engineering attack [112] Privacy-enhanced Daily and Sports × Global aggregation Zero-knowledge proofs decentralized

Activities & applications poisoning attack that the proposed model improves the privacy protection of the medical data and achieves reliable accuracy in skin cancer detection. Ma et al. [109] proposed a novel privacy-enhancing FL on a smart healthcare scenario for elderly-fall detection, the authors used UP-FALL Detection dataset 8 . Similar to [108], they applied homomorphic encryption scheme to FL in order to prevent privacy leakage and achieve secure encryption and decryption in the FL system. The proposed xMK-CKKS multikey homomorphic encryption scheme utilizes an aggregated public key to encrypt the model updates before sharing them with a server for aggregation. The model decryption occurs after clients share information of their secret keys. The result showed that the proposed FL scheme using multikey homomorphic encryption is effective in communication, computational cost, and energy consumption, while ensuring the implementation of secure FL on IoHT devices.

In [110], the authors combined FL and fully homomorphic encryption (FHE) to define a novel secure FL framework for biomedical data analysis. They used the CKKS homomorphic encryption scheme based on ciphertext packing and rescaling, similarly to the authors in [109]. The authors evaluated the performance of the proposed FL model using a large-scale 3D brain MRI dataset 9 to predict brain age in a secure environment. The result showed that the integration of a FL framework and encryption scheme does not reduce the efficiency of FL, also increases the privacy of the patient's private data.

In [111], the authors provided a secure and scalable FL framework to implement AI across hospital sites, collaborators, and edge devices. Similarly to [108], to address privacy challenges, they integrated the proposed FL framework with a secure multi-party computation algorithm to avoid data leakage and reverse engineering attacks via model updates. They evaluated the performance of the SMPC method in FL using the Philips ICU dataset. The results demonstrated that the developed FL framework with a SMPC algorithm can be used in a large ecosystem of the Internet of Healthcare Things 8 http://sites.google.com/up.edu.mx/har-up/ 9 https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/ DVN/2RKAQP (IoHT) and healthcare hospital sites. Moreover, the proposed framework significantly protects medical data privacy.

Heiss et al. [112] proposed a model for blockchain-based FL that leverages verifiable off-chain computations (VOC) using zero-knowledge proofs (ZKP). The architecture enables the computational correctness of local learning processes verifiable on blockchain and provides globally verifiable management of global learning parameters. They evaluated the performance of the architecture through an in-home health monitoring system where sensitive data serve as inputs to the FL system. The author used Daily and Sports Activities dataset 10 and the results showed that verifiable off-chain computations (VOC) using zero-knowledge proofs (ZKP) enhances privacy in decentralized applications. Similar to [111] and [108], in [112], the authors integrated zero-knowledge proofs (ZKP) with FL in order to enhance privacy in IoHT ecosystem. Table III summarizes the cryptographic methods applied for FL in smart healthcare.


## C. Perturbation Methods

Similar to [109], in [116], the authors proposed a bandwidth-efficient FL framework in IoHT environment. The framework ensures privacy for FL based on Differential Privacy (DP). They discovered that exchanging the model update from a huge amount of IoHT devices needs a significant bandwidth. Therefore, they proposed the FL-SIGN-DP scheme to reduce communication costs and enhance privacy. Participants in FL-SIGN-DP only transmit the updated model's sign to the aggregation server. They used the electronic health records of roughly a million patients to assess the performance of the proposed scheme with regard to the in-hospital mortality rate. The proposed scheme is compared with centralized learning, FL-SIGN without using standard FL, differential privacy, and differential privacy with standard FL. The results showed that the FL-SIGN-DP consumes less bandwidth and can guarantee privacy protection.

Islam et al. [117] proposed a FL model to analyze patients' genomic data and identify the risk of heart failure. To enhance the privacy-preserving of the patient private data sharing among collaborating healthcare organizations in FL framework, they applied differential privacy mechanisms through feature selection based on statistical methods to increase scalability and accuracy in a federated setting where data are vertically partitioned. They evaluated the performance of the proposed FL framework using the IQVIA dataset and BC-TCGA dataset 11 for predicting the causes of certain heart failure and the BC-TCGA dataset for cancer prediction to compare their proposed FL method. The result demonstrated that their proposed model obtains better accuracy with the highest privacy for the IQVIA and BC-TCGA datasets in a federated training setting.

The authors in [118] proposed federated adversarial learning (FAL) on biomedical named entity recognition (BioNER). The differential privacy technology is also used to protect the security and privacy of the data, which adds Gaussian noise during the local training and model aggregation process to enhance privacy. More specifically, only the noised parameters with differential privacy are transferred among the server and the client. Therefore, the data leakage possibility has decreased on the local client's side. The dataset collected from 5 departments of a tumor hospital is used to examine the performance of the proposed scheme. The Result showed that the proposed FAL framework can connect data parties and prevent data leakage during data exchange inside medical institutions.

Similarly to [116], in [119], the authors proposed a costeffective and privacy-preserving FL framework which is IoHT Alzheimer's disease detection scheme. They presented an FL based privacy-preserving smart healthcare system, namely ADDetector, to detect Alzheimer's disease. Moreover, they implemented a differential privacy (DP) mechanism on the user data to avoid patient's data leakage during transferring data to the client and enhance the privacy level against the attacker. An ADReSS Challenge dataset from INTERSPEECH 2020 12 is used to evaluate the performance of the ADDetector FL-based scheme. The proposed FL-based framework and DP-based mechanism use the audio from smart devices to detect low-cost Alzheimer's disease. The experimental results showed that the ADDETECTOR FL-based framework achieves better accuracy and low average time overhead with a high level of privacy and security protection.

Dinh et al. [120] proposed an FL framework, called FedGAN, to facilitate COVID-19 detection by enhancing privacy among medical institutions in edge cloud computing. The aim of the framework is to create realistic COVID-19 X-ray data and detect it automatically without the need for sharing COVID-19 image with parties. Additionally, they integrated a differential privacy at each hospital site to increase and guarantee the data privacy in federated COVID-19 data training. To apply the differential privacy, they used both differentially private stochastic gradient descent and a gradient perturbation technique; they also added the Gaussian noises to the gradient during the training. Additionally, they use the FedGAN blockchain-based system for safe COVID-19 data analysis. To evaluate the performance of proposed FedGAN model, they used two popular COVID-19 X-ray data sets for simulations, including a DarkCOVID 13 and a ChestCOVID 14 dataset. The result demonstrated that FedGAN framework enhances the performance of COVID-19 detection and provides high level of privacy. Table IV presents a summary of the perturbation methods applied for FL in smart healthcare.


## D. Blockchain Methods

Blockchain methods have been widely used in many FL methods to provide privacy and security in IoHT (smart healthcare systems).

For smart healthcare systems, the authors of [121] proposed an infrastructure called FedMedChain, which is based on secure FL and blockchain to predict the COVID-19 for IoMT scenarios, similarly to [120] which proposes an privacypreserving FL-based scheme for analysis of COVID-19 data in a secure environment. The proposed system can improve public communication and address the challenges of big data silos and data security. Furthermore, information security and privacy analyses showed that the proposed infrastructure is robust against privacy breaches and can improve information security.

Similarly to [121], to solve privacy concerns, the authors in [122] presented a model based on the FL and blockchain, which is used to predict COVID-19 symptoms, how it spreads, and speed up using the medical data in research and treatment. In addition, the combination of FL and blockchain could be useful for real time environment and for organizations that do not want share sensitive data with third parties because of privacy concerns. After analyzing the combination of blockchain and FL solution, the authors noted that the proposed solution securely protects the data access and would help to build a robust model.

Similarly to [121], Lakhan et al. [123] proposed a privacypreserving FL for IoMT system. It is a mathematical model called FL-BETS, which is a FL-based privacy enhancing and malware detection-enable blockchain IoMT system for different healthcare workloads. The aim of this study is to preserve privacy and fraud of data in the local fog nodes and remote clouds network with minimum energy consumption and delay. The performance evaluation of the FL-BETS framework, compared to other existing machine learning and blockchain methods in malware analysis shows the best performance in fraud analysis, data validation, energy and delay constraints for healthcare applications. Also, the model decreases energy consumption by 41% and delay by 28%.

Similar to [121] and [123], in [124], the authors proposed the model by integrating Blockchain and FL-enabled approaches to provide a secure architecture for privacy preservation in smart healthcare systems. In this model, blockchain- Health Records [117] Preserving privacy and predicting BC-TCGA × -Differential privacy risk of heart failure [118] Avoiding medical data leakage Dataset of a × × Adversarial attack Differential privacy during data exchange tumor hospitals [119] privacy-preserving IoHT ADReSS × Man-in-the-middle Differential privacy Alzheimer's disease detection attack [120] Preserving privacy and improving DarkCOVID × -Differential privacy COVID19 detection ChestCOVID Inference attack [122] Preserving data privacy -× × -Blockchain & predicting COVID-19 [123] Fraud-detection for ECG heartbeat × × Fraud attack Blockchain IoHT E-Heart videos Blood pressure [124] Privacy preserving for Healthcare data × × Replay attack Blockchain IoHT in cloud [125] Preserving the patient's CC-19 -Blockchain privacy and detection COVID-19 CT scan based IoT cloud apps enhance security and privacy by combining FL and blockchain technologies. The proposed model has provided secure data sharing for the IoHT environment with privacy preservation. Organizations can use federated-based blockchain cloud architecture without collaborating sensitive and private healthcare system data in the cloud.

Kumar et al. [125] developed an FL blockchain-based approach to train the global model for detection of COVID-19 patients based on Computed tomography (CT) slices while preserving the privacy of patients' private data and the organization, similarly to [121]. The proposed model evaluated real-life COVID-19 patients' data 15 that were collected from various hospitals with different types of CT scanners and publicly available to the research community. The results showed that the blockchain-based FL smartly detects COVID-19 patients using computed tomography (CT) scans among various hospitals while preserving sensitive data privacy. Table V summarizes the blockchain methods applied for FL in smart healthcare.


## VIII. KEY CHALLENGES FOR FUTURE RESEARCH

While PETs in FL have many advantages and have been growing rapidly in recent years, some challenges cannot be ignored. Existing frameworks are still at an early stage and need improving methods to enhance data privacy. 15 https://paperswithcode.com/dataset/cc-19 1) Computation cost: One of the main challenges of FL is represented by privacy-enhancing to prevent data leakage. FL needs multiple iterations to achieve the final global model. Therefore, the number of training iterations has a direct impact on increasing the cost of the training model. As shown in [111], multi-party computation is a way to protect data privacy in FL. Performing experiments with a different number of workers does not impact the computation cost, however, increasing the number of training rounds significantly boosts the computation cost. Therefore, the trade-off between privacy risk and computation time has been a promising topic for researchers.

2) Privacy and security: In Section VII-D, some studies show that integration of the blockchain method and FL is a way to enhance privacy in IoHT. However, there is an open issue that may lead to privacy leakage. In the FL, only the central server has information about the sources of the local model updates, and the addresses of the clients are private. However, addresses in blockchain are public, and using blockchain in FL gives the ability to other clients to communicate with each other and obtain the training model based on the public information from the blockchain. Therefore, the risk of data leakage among clients cannot be ignored.

3) Linkage attacks: The k-anonymity technique is a way to preserve the anonymity of individuals. The key idea is how to modify the attributes of the dataset in a way that each instance has at least k-1 other entities with identical quasi-identifiers. Therefore, an identifiable record would link to multiple records in the anonymous dataset. However, k-anonymity cannot avoid privacy leakage against linkage attacks where a sensitive attribute is shared among a group of individuals with the same quasi-identifier.


## IX. CONCLUSIONS

This survey has reviewed nineteen representative works that apply federated learning (FL) in the Internet of Healthcare Things (IoHT) domain in terms of privacy aspects, including attacks and privacy-enhancing technologies (PETs). The datasets used by these works have also been summarized, which are helpful for researchers aiming to reproduce these works. Some open research issues on the topic still exist, such as the trade-off between privacy risk and computational time, the risk of data leakage among colluding clients, and the sharing of sensitive attributes. Along with the current research efforts, we encourage more insights into the problems of this area and more efforts in addressing the open research issues identified in this paper.

## Fig. 1 .
1Outline of the paper.


Fig 3 shows an example of inference attacks.

## Fig. 2 .
2An illustration of the poisoning attacks against FL Fig. 3. An illustration of the Inference attacks against FLcompromises the devices of one or several participants and trains a model using backdoor data, then submits the resulting model. After federated averaging, the global model is replaced by the backdoored model as shown inFig. 4. In the backdoor, an adversary can be hidden and has no impact on the accuracy or functionality of the global model like accuracy. As a result, the accuracy of the validation dataset makes it difficult to distinguish the backdoor attack[66] [67].VI. PRIVACY ENHANCING TECHNOLOGIESPrivacy Enhancing Technologies (PETs) are a set of tools and techniques that aim to protect individuals' privacy. PETs

## Fig. 4 .
4An illustration of the Backdoor attacks against FL

## TABLE I COMPARISON
ITO THE RELATED WORKSReferences IoHT environment Healthcare domain 
Privacy Mechanisms 
Anonymization Cryptography Perturbation Blockchain 

[20] 
× 
× 
× 
× 
× 

[21] 
× 
× 
× 
× 

[22] 
× 
× 
× 

[23] 
× 
× 

[24] 
× 
× 
× 
× 

[25] 
× 
× 
× 

Our work 



## TABLE II SUMMARY
IIOF ANONYMIZATION TECHNIQUES APPLIED IN FL FOR THE SMART HEALTHCARE ENVIRONMENT.Ref. 
Aim 
Dataset 
Dataset Available Open-Source 
Privacy Attack 
Privacy-Enhancing Method 
[94] 
Maximize data utility 
MIMIC III 
× 
Inference attack 
syntactic anonymization 
& 
model performance 
[95] 
Applying data privacy 
Pima Indians 
× 
Poisoning attack 
k-anonymity 
engineering without 
diabetes 
reducing the accuracy 
& 
Cleveland 
heart disease 


## TABLE III SUMMARY
IIIOF CRYPTOGRAPHIC ALGORITHMS APPLIED IN FL FOR THE SMART HEALTHCARE ENVIRONMENTRef. 
Aim 
Dataset 
Dataset Available Open-Source 
Privacy Attack 
Privacy-Enhancing Method 
[108] 
Preserving privacy in 
HAM10000 
× 
Inference attack 
Homomorphic encryption 
skin cancer detection 
& 
with reliable accuracy 
secure multi-party computation 


## TABLE IV SUMMARY
IVOF PERTURBATION METHOD APPLIED IN FL FOR THE SMART HEALTHCARE ENVIRONMENTRef. 
Aim 
Dataset 
Dataset Available Open-Source 
Privacy Attack 
Privacy-Enhancing Method 
[116] 
Enhancing privacy 
Two real-world 
× 
Inference attack 
Differential privacy 
& 
Electronic 
bandwidth efficiency 


## TABLE V SUMMARY
VOF BLOCKCHAIN METHOD APPLIED IN FL FOR THE SMART HEALTHCARE ENVIRONMENTRef. 
Aim 
Dataset 
Dataset Available Open-Source Privacy Attack Privacy-Enhancing Method 
[121] IoMT privacy-preserving 
-
× 
× 
Backdoors 
Blockchain 
& 
& 
predict the COVID-19 

https://registry.opendata.aws/mimiciii/ 2 https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database 3 https://archive.ics.uci.edu/ml/datasets/heart+disease
https://www.tensorflow.org/datasets/catalog/mnist 5 http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition +Using+Smartphones 6 https://eicu-crd.mit.edu/ 7 https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/ DVN/DBW86T
https://archive.ics.uci.edu/ml/datasets/daily+and+sports+activities
https://www.kaggle.com/datasets/saurabhshahane/gene-expressionprofiles-of-breast-cancer 12 https://luzs.gitlab.io/adress/
https://github.com/ieee8023/COVID-chestxray-dataset 14 https://github.com/ieee8023/covid-chestxray-dataset
ACKNOWLEDGMENTSThis research is part of the INCT of the Future Internet for Smart Cities funded by CNPq proc. 465446/2014-0, Coordenação de Aperfeiçoamento de Pessoal de Nível Superior -Brasil (CAPES) -Finance Code 001, FAPESP proc. 14/50937-1 and proc. 15/24485-9.
An iot guided healthcare monitoring system for managing real-time notifications by fog computing services. N Mani, A Singh, S L Nimmagadda, Procedia Computer Science. 167N. Mani, A. Singh, and S. L. Nimmagadda, "An iot guided healthcare monitoring system for managing real-time notifications by fog com- puting services," Procedia Computer Science, vol. 167, pp. 850-859, 2020.

Fuzzy group-based intersection control via vehicular networks for smart transportations. J Cheng, W Wu, J Cao, K Li, IEEE Transactions on Industrial Informatics. 132J. Cheng, W. Wu, J. Cao, and K. Li, "Fuzzy group-based intersection control via vehicular networks for smart transportations," IEEE Trans- actions on Industrial Informatics, vol. 13, no. 2, pp. 751-758, 2016.

A review of internet of things for smart home: Challenges and solutions. B L R Stojkoska, K V Trivodaliev, Journal of cleaner production. 140B. L. R. Stojkoska and K. V. Trivodaliev, "A review of internet of things for smart home: Challenges and solutions," Journal of cleaner production, vol. 140, pp. 1454-1464, 2017.

Iot based smart and intelligent smart city energy optimization. Z Chen, C Sivaparthipan, B Muthu, Sustainable Energy Technologies and Assessments. 49101724Z. Chen, C. Sivaparthipan, and B. Muthu, "Iot based smart and intelli- gent smart city energy optimization," Sustainable Energy Technologies and Assessments, vol. 49, p. 101724, 2022.

Industry 4.0 and health: Internet of things, big data, and cloud computing for healthcare 4.0. G Aceto, V Persico, A Pescapé, Journal of Industrial Information Integration. 18100129G. Aceto, V. Persico, and A. Pescapé, "Industry 4.0 and health: Internet of things, big data, and cloud computing for healthcare 4.0," Journal of Industrial Information Integration, vol. 18, p. 100129, 2020.

Reducing bias and increasing utility by federated generative modeling of medical images using a centralized adversary. J.-F Rajotte, S Mukherjee, C Robinson, A Ortiz, C West, J M L Ferres, R T Ng, Proceedings of the Conference on Information Technology for Social Good. the Conference on Information Technology for Social GoodJ.-F. Rajotte, S. Mukherjee, C. Robinson, A. Ortiz, C. West, J. M. L. Ferres, and R. T. Ng, "Reducing bias and increasing utility by federated generative modeling of medical images using a centralized adversary," in Proceedings of the Conference on Information Technology for Social Good, 2021, pp. 79-84.

Machine learning in medicine: addressing ethical challenges. E Vayena, A Blasimme, I G Cohen, PLoS medicine. 15111002689E. Vayena, A. Blasimme, and I. G. Cohen, "Machine learning in medicine: addressing ethical challenges," PLoS medicine, vol. 15, no. 11, p. e1002689, 2018.

Federated learning for healthcare domain-pipeline, applications and challenges. M Joshi, A Pal, M Sankarasubbu, ACM Transactions on Computing for Healthcare. M. Joshi, A. Pal, and M. Sankarasubbu, "Federated learning for health- care domain-pipeline, applications and challenges," ACM Transactions on Computing for Healthcare, 2022.

Handling privacysensitive medical data with federated learning: Challenges and future directions. O Aouedi, A Sacco, K Piamrat, G Marchetto, IEEE Journal of Biomedical and Health Informatics. O. Aouedi, A. Sacco, K. Piamrat, and G. Marchetto, "Handling privacy- sensitive medical data with federated learning: Challenges and future directions," IEEE Journal of Biomedical and Health Informatics, 2022.

Federated machine learning: Concept and applications. Q Yang, Y Liu, T Chen, Y Tong, ACM TIST. 102Q. Yang, Y. Liu, T. Chen, and Y. Tong, "Federated machine learning: Concept and applications," ACM TIST, vol. 10, no. 2, pp. 1-19, 2019.

Federated learning for healthcare: Systematic review and architecture proposal. R S Antunes, C André Da Costa, A Küderle, I A Yari, B Eskofier, ACM TIST. 134R. S. Antunes, C. André da Costa, A. Küderle, I. A. Yari, and B. Eskofier, "Federated learning for healthcare: Systematic review and architecture proposal," ACM TIST, vol. 13, no. 4, pp. 1-23, 2022.

A critical evaluation of privacy and security threats in federated learning. M Asad, A Moustafa, C Yu, Sensors. 20247182M. Asad, A. Moustafa, and C. Yu, "A critical evaluation of privacy and security threats in federated learning," Sensors, vol. 20, no. 24, p. 7182, 2020.

An introduction to privacy enhancing technologies. G Danezis, Internet Society Geneva's Monthly Conferences Cycle. Geneva, SwitzerlandG. Danezis, "An introduction to privacy enhancing technologies," in Internet Society Geneva's Monthly Conferences Cycle, Geneva, Switzerland, 2004.

Mitfed: A privacy preserving collaborative network attack mitigation framework based on federated learning using sdn and blockchain. Z Abou El Houda, A S Hafid, L Khoukhi, IEEE Transactions on Network Science and Engineering. Z. Abou El Houda, A. S. Hafid, and L. Khoukhi, "Mitfed: A privacy preserving collaborative network attack mitigation framework based on federated learning using sdn and blockchain," IEEE Transactions on Network Science and Engineering, 2023.

A survey on federated learning in data mining. B Yu, W Mao, Y Lv, C Zhang, Y Xie, Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery. 1211443B. Yu, W. Mao, Y. Lv, C. Zhang, and Y. Xie, "A survey on federated learning in data mining," Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, vol. 12, no. 1, p. e1443, 2022.

A resource-constrained and privacy-preserving edge-computing-enabled clinical decision system: A federated reinforcement learning approach. Z Xue, P Zhou, Z Xu, X Wang, Y Xie, X Ding, S Wen, IEEE Internet of Things Journal. 811Z. Xue, P. Zhou, Z. Xu, X. Wang, Y. Xie, X. Ding, and S. Wen, "A resource-constrained and privacy-preserving edge-computing-enabled clinical decision system: A federated reinforcement learning approach," IEEE Internet of Things Journal, vol. 8, no. 11, pp. 9122-9138, 2021.

Urllc resource slicing and scheduling for trustworthy 6g vehicular services: A federated reinforcement learning approach. M Hao, D Ye, S Wang, B Tan, R Yu, Physical Communication. 49101470M. Hao, D. Ye, S. Wang, B. Tan, and R. Yu, "Urllc resource slicing and scheduling for trustworthy 6g vehicular services: A federated reinforcement learning approach," Physical Communication, vol. 49, p. 101470, 2021.

Feddpgan: federated differentially private generative adversarial networks framework for the detection of covid-19 pneumonia. L Zhang, B Shen, A Barnawi, S Xi, N Kumar, Y Wu, Information Systems Frontiers. 236L. Zhang, B. Shen, A. Barnawi, S. Xi, N. Kumar, and Y. Wu, "Fed- dpgan: federated differentially private generative adversarial networks framework for the detection of covid-19 pneumonia," Information Systems Frontiers, vol. 23, no. 6, pp. 1403-1415, 2021.

Revealing the landscape of privacy-enhancing technologies in the context of data markets for the iot: A systematic literature review. G M Garrido, J Sedlmeir, Ö Uludag, I S Alaoui, A Luckow, F Matthes, Journal of Network and Computer Applications. 103465G. M. Garrido, J. Sedlmeir, Ö. Uludag, I. S. Alaoui, A. Luckow, and F. Matthes, "Revealing the landscape of privacy-enhancing technologies in the context of data markets for the iot: A systematic literature review," Journal of Network and Computer Applications, p. 103465, 2022.

Federated Learning: A Survey on Enabling Technologies, Protocols, and Applications. M Aledhari, R Razzak, R M Parizi, F Saeed, IEEE Access. 8M. Aledhari, R. Razzak, R. M. Parizi, and F. Saeed, "Federated Learn- ing: A Survey on Enabling Technologies, Protocols, and Applications," IEEE Access, vol. 8, pp. 140 699-140 725, 2020.

A survey on federated learning. C Zhang, Y Xie, H Bai, B Yu, W Li, Y Gao, Knowledge-Based Systems. 216106775C. Zhang, Y. Xie, H. Bai, B. Yu, W. Li, and Y. Gao, "A survey on federated learning," Knowledge-Based Systems, vol. 216, p. 106775, 2021.

A Survey on Security and Privacy of Federated Learning. V Mothukuri, R M Parizi, S Pouriyeh, Y Huang, A Dehghantanha, G Srivastava, Future Generation Computer Systems. 115V. Mothukuri, R. M. Parizi, S. Pouriyeh, Y. Huang, A. Dehghantanha, and G. Srivastava, "A Survey on Security and Privacy of Federated Learning," Future Generation Computer Systems, vol. 115, pp. 619- 640, 2021.

Federated Learning for Internet of Things: A Comprehensive Survey. D C Nguyen, M Ding, P N Pathirana, A Seneviratne, J Li, H Vincent Poor, IEEE COMST. 233D. C. Nguyen, M. Ding, P. N. Pathirana, A. Seneviratne, J. Li, and H. Vincent Poor, "Federated Learning for Internet of Things: A Comprehensive Survey," IEEE COMST, vol. 23, no. 3, pp. 1622-1658, 2021.

Analysis of privacy-enhancing technologies in open-source federated learning frameworks for driver activity recognition. E Novikova, D Fomichov, I Kholod, E Filippov, Sensors. 2282983E. Novikova, D. Fomichov, I. Kholod, and E. Filippov, "Analysis of privacy-enhancing technologies in open-source federated learning frameworks for driver activity recognition," Sensors, vol. 22, no. 8, p. 2983, 2022.

Federated Learning for Smart Healthcare: A Survey. D C Nguyen, Q.-V Pham, P N Pathirana, M Ding, A Seneviratne, Z Lin, O Dobre, W.-J Hwang, ACM Comput. Surv. 553D. C. Nguyen, Q.-V. Pham, P. N. Pathirana, M. Ding, A. Seneviratne, Z. Lin, O. Dobre, and W.-J. Hwang, "Federated Learning for Smart Healthcare: A Survey," ACM Comput. Surv., vol. 55, no. 3, feb 2022.

Communication-efficient learning of deep networks from decentralized data. B Mcmahan, E Moore, D Ramage, S Hampson, B A Arcas, Artificial intelligence and statistics. B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, "Communication-efficient learning of deep networks from decentral- ized data," in Artificial intelligence and statistics. PMLR, 2017, pp. 1273-1282.

Federated learning: Strategies for improving communication efficiency. J Konečnỳ, H B Mcmahan, F X Yu, P Richtárik, A T Suresh, D Bacon, arXiv:1610.05492arXiv preprintJ. Konečnỳ, H. B. McMahan, F. X. Yu, P. Richtárik, A. T. Suresh, and D. Bacon, "Federated learning: Strategies for improving communica- tion efficiency," arXiv preprint arXiv:1610.05492, 2016.

Federated learning: opportunities and challenges. P M Mammen, arXiv:2101.05428arXiv preprintP. M. Mammen, "Federated learning: opportunities and challenges," arXiv preprint arXiv:2101.05428, 2021.

Federated learning in a medical context: a systematic literature review. B Pfitzner, N Steckhan, B Arnrich, ACM TOIT. 212B. Pfitzner, N. Steckhan, and B. Arnrich, "Federated learning in a medical context: a systematic literature review," ACM TOIT, vol. 21, no. 2, pp. 1-31, 2021.

An introduction to the federated learning standard. T Zhang, S Mao, GetMobile: Mobile Computing and Communications. 253T. Zhang and S. Mao, "An introduction to the federated learning stan- dard," GetMobile: Mobile Computing and Communications, vol. 25, no. 3, pp. 18-22, 2022.

A systematic review of federated learning in the healthcare area: From the perspective of data properties and applications. C.-R Shyu, K T Putra, H.-C Chen, Y.-Y Tsai, K T Hossain, W Jiang, Z.-Y Shae, Applied Sciences. 112311191C.-R. Shyu, K. T. Putra, H.-C. Chen, Y.-Y. Tsai, K. T. Hossain, W. Jiang, and Z.-Y. Shae, "A systematic review of federated learning in the healthcare area: From the perspective of data properties and applications," Applied Sciences, vol. 11, no. 23, p. 11191, 2021.

Fedhealth: A federated transfer learning framework for wearable healthcare. Y Chen, X Qin, J Wang, C Yu, W Gao, IEEE Intelligent Systems. 354Y. Chen, X. Qin, J. Wang, C. Yu, and W. Gao, "Fedhealth: A federated transfer learning framework for wearable healthcare," IEEE Intelligent Systems, vol. 35, no. 4, pp. 83-93, 2020.

Federated learning for smart healthcare: A survey. D C Nguyen, Q.-V Pham, P N Pathirana, M Ding, A Seneviratne, Z Lin, O Dobre, W.-J Hwang, ACM Computing Surveys (CSUR). 553D. C. Nguyen, Q.-V. Pham, P. N. Pathirana, M. Ding, A. Seneviratne, Z. Lin, O. Dobre, and W.-J. Hwang, "Federated learning for smart healthcare: A survey," ACM Computing Surveys (CSUR), vol. 55, no. 3, pp. 1-37, 2022.

Wearable indoor localisation approach in internet of things. H Huang, J Zhou, W Li, J Zhang, X Zhang, G Hou, IET Networks. 55H. Huang, J. Zhou, W. Li, J. Zhang, X. Zhang, and G. Hou, "Wearable indoor localisation approach in internet of things," IET Networks, vol. 5, no. 5, pp. 122-126, 2016.

Is hipaa compliant with the gdpr?. G Mooney, G. Mooney, "Is hipaa compliant with the gdpr?" 2018.

Privacy, confidentiality, and electronic medical records. R C BarrowsJr, P D Clayton, Journal of the American medical informatics association. 32R. C. Barrows Jr and P. D. Clayton, "Privacy, confidentiality, and elec- tronic medical records," Journal of the American medical informatics association, vol. 3, no. 2, pp. 139-148, 1996.

Federated learning: a collaborative effort to achieve better medical imaging models for individual sites that have small labelled datasets. D Ng, X Lan, M M S Yao, W P Chan, M Feng, Quantitative Imaging in Medicine and Surgery. 112852D. Ng, X. Lan, M. M.-S. Yao, W. P. Chan, and M. Feng, "Federated learning: a collaborative effort to achieve better medical imaging mod- els for individual sites that have small labelled datasets," Quantitative Imaging in Medicine and Surgery, vol. 11, no. 2, p. 852, 2021.

Privacy-preserving blockchain-based federated learning for iot devices. Y Zhao, J Zhao, L Jiang, R Tan, D Niyato, Z Li, L Lyu, Y Liu, IEEE Internet of Things Journal. 83Y. Zhao, J. Zhao, L. Jiang, R. Tan, D. Niyato, Z. Li, L. Lyu, and Y. Liu, "Privacy-preserving blockchain-based federated learning for iot devices," IEEE Internet of Things Journal, vol. 8, no. 3, pp. 1817-1829, 2020.

Federated machine learning: Survey, multi-level classification, desirable criteria and future directions in communication and networking systems. O A Wahab, A Mourad, H Otrok, T Taleb, IEEE Communications Surveys & Tutorials. 232O. A. Wahab, A. Mourad, H. Otrok, and T. Taleb, "Federated machine learning: Survey, multi-level classification, desirable criteria and future directions in communication and networking systems," IEEE Commu- nications Surveys & Tutorials, vol. 23, no. 2, pp. 1342-1397, 2021.

Federated learning in medicine: facilitating multi-institutional collaborations without sharing patient data. M J Sheller, B Edwards, G A Reina, J Martin, S Pati, A Kotrotsou, M Milchenko, W Xu, D Marcus, R R Colen, Scientific reports. 101M. J. Sheller, B. Edwards, G. A. Reina, J. Martin, S. Pati, A. Kotrotsou, M. Milchenko, W. Xu, D. Marcus, R. R. Colen et al., "Federated learn- ing in medicine: facilitating multi-institutional collaborations without sharing patient data," Scientific reports, vol. 10, no. 1, pp. 1-12, 2020.

The future of digital health with federated learning. N Rieke, J Hancox, W Li, F Milletari, H R Roth, S Albarqouni, S Bakas, M N Galtier, B A Landman, K Maier-Hein, NPJ digital medicine. 31N. Rieke, J. Hancox, W. Li, F. Milletari, H. R. Roth, S. Albarqouni, S. Bakas, M. N. Galtier, B. A. Landman, K. Maier-Hein et al., "The future of digital health with federated learning," NPJ digital medicine, vol. 3, no. 1, pp. 1-7, 2020.

Federated learning in mobile edge networks: A comprehensive survey. W Y B Lim, N C Luong, D T Hoang, Y Jiao, Y.-C Liang, Q Yang, D Niyato, C Miao, IEEE COMST. 223W. Y. B. Lim, N. C. Luong, D. T. Hoang, Y. Jiao, Y.-C. Liang, Q. Yang, D. Niyato, and C. Miao, "Federated learning in mobile edge networks: A comprehensive survey," IEEE COMST, vol. 22, no. 3, pp. 2031- 2063, 2020.

Federated learning for internet of things: Recent advances, taxonomy, and open challenges. L U Khan, W Saad, Z Han, E Hossain, C S Hong, IEEE COMST. L. U. Khan, W. Saad, Z. Han, E. Hossain, and C. S. Hong, "Federated learning for internet of things: Recent advances, taxonomy, and open challenges," IEEE COMST, 2021.

Federated learning for edge networks: Resource optimization and incentive mechanism. L U Khan, S R Pandey, N H Tran, W Saad, Z Han, M N Nguyen, C S Hong, IEEE COMMAG. 5810L. U. Khan, S. R. Pandey, N. H. Tran, W. Saad, Z. Han, M. N. Nguyen, and C. S. Hong, "Federated learning for edge networks: Resource optimization and incentive mechanism," IEEE COMMAG, vol. 58, no. 10, pp. 88-93, 2020.

Exploiting unintended feature leakage in collaborative learning. L Melis, C Song, E De Cristofaro, V Shmatikov, IEEE Symposium on Security and Privacy. L. Melis, C. Song, E. De Cristofaro, and V. Shmatikov, "Exploiting un- intended feature leakage in collaborative learning," in IEEE Symposium on Security and Privacy, 2019, pp. 691-706.

Protection against reconstruction and its applications in private federated learning. A Bhowmick, J Duchi, J Freudiger, G Kapoor, R Rogers, arXiv:1812.00984arXiv preprintA. Bhowmick, J. Duchi, J. Freudiger, G. Kapoor, and R. Rogers, "Pro- tection against reconstruction and its applications in private federated learning," arXiv preprint arXiv:1812.00984, 2018.

Deep leakage from gradients. L Zhu, Z Liu, S Han, Advances in neural information processing systems. 32L. Zhu, Z. Liu, and S. Han, "Deep leakage from gradients," Advances in neural information processing systems, vol. 32, 2019.

Privacy-preserving deep learning via additively homomorphic encryption. Y Aono, T Hayashi, L Wang, S Moriai, IEEE Transactions on Information Forensics and Security. 135Y. Aono, T. Hayashi, L. Wang, S. Moriai et al., "Privacy-preserving deep learning via additively homomorphic encryption," IEEE Transac- tions on Information Forensics and Security, vol. 13, no. 5, pp. 1333- 1345, 2017.

Analyzing federated learning through an adversarial lens. A N Bhagoji, S Chakraborty, P Mittal, S Calo, International Conference on Machine Learning. PMLRA. N. Bhagoji, S. Chakraborty, P. Mittal, and S. Calo, "Analyzing feder- ated learning through an adversarial lens," in International Conference on Machine Learning. PMLR, 2019, pp. 634-643.

Privacy-preserving in defending against membership inference attacks. Z Ying, Y Zhang, X Liu, Proceedings of the 2020 Workshop on Privacy-Preserving Machine Learning in Practice. the 2020 Workshop on Privacy-Preserving Machine Learning in PracticeZ. Ying, Y. Zhang, and X. Liu, "Privacy-preserving in defending against membership inference attacks," in Proceedings of the 2020 Workshop on Privacy-Preserving Machine Learning in Practice, 2020, pp. 61-63.

How to backdoor federated learning. E Bagdasaryan, A Veit, Y Hua, D Estrin, V Shmatikov, International Conference on Artificial Intelligence and Statistics. PMLR, 2020. E. Bagdasaryan, A. Veit, Y. Hua, D. Estrin, and V. Shmatikov, "How to backdoor federated learning," in International Conference on Artificial Intelligence and Statistics. PMLR, 2020, pp. 2938-2948.

Deep model poisoning attack on federated learning. X Zhou, M Xu, Y Wu, N Zheng, Future Internet. 13373X. Zhou, M. Xu, Y. Wu, and N. Zheng, "Deep model poisoning attack on federated learning," Future Internet, vol. 13, no. 3, p. 73, 2021.

Data poisoning attacks against federated learning systems. V Tolpegin, S Truex, M E Gursoy, L Liu, European Symposium on Research in Computer Security. SpringerV. Tolpegin, S. Truex, M. E. Gursoy, and L. Liu, "Data poisoning attacks against federated learning systems," in European Symposium on Research in Computer Security. Springer, 2020, pp. 480-501.

Understanding distributed poisoning attack in federated learning. D Cao, S Chang, Z Lin, G Liu, D Sun, IEEE 25th ICPADS. D. Cao, S. Chang, Z. Lin, G. Liu, and D. Sun, "Understanding dis- tributed poisoning attack in federated learning," in IEEE 25th ICPADS, 2019, pp. 233-239.

Threats to federated learning: A survey. L Lyu, H Yu, Q Yang, arXiv:2003.02133arXiv preprintL. Lyu, H. Yu, and Q. Yang, "Threats to federated learning: A survey," arXiv preprint arXiv:2003.02133, 2020.

A taxonomy of attacks on federated learning. M S Jere, T Farnan, F Koushanfar, IEEE Security & Privacy. 192M. S. Jere, T. Farnan, and F. Koushanfar, "A taxonomy of attacks on federated learning," IEEE Security & Privacy, vol. 19, no. 2, pp. 20-28, 2020.

Soteria: Provable defense against privacy leakage in federated learning from representation perspective. J Sun, A Li, B Wang, H Yang, H Li, Y Chen, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. the IEEE/CVF conference on computer vision and pattern recognitionJ. Sun, A. Li, B. Wang, H. Yang, H. Li, and Y. Chen, "Soteria: Provable defense against privacy leakage in federated learning from represen- tation perspective," in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2021, pp. 9311-9319.

Gan enhanced membership inference: A passive local attack in federated learning. J Zhang, J Zhang, J Chen, S Yu, ICC 2020-2020 IEEE International Conference on Communications (ICC). IEEEJ. Zhang, J. Zhang, J. Chen, and S. Yu, "Gan enhanced membership in- ference: A passive local attack in federated learning," in ICC 2020-2020 IEEE International Conference on Communications (ICC). IEEE, 2020, pp. 1-6.

Poisoningassisted property inference attack against federated learning. Z Wang, Y Huang, M Song, L Wu, F Xue, K Ren, IEEE Transactions on Dependable and Secure Computing. Z. Wang, Y. Huang, M. Song, L. Wu, F. Xue, and K. Ren, "Poisoning- assisted property inference attack against federated learning," IEEE Transactions on Dependable and Secure Computing, 2022.

Combined federated and split learning in edge computing for ubiquitous intelligence in internet of things: State-of-the-art and future directions. Q Duan, S Hu, R Deng, Z Lu, Sensors. 22165983Q. Duan, S. Hu, R. Deng, and Z. Lu, "Combined federated and split learning in edge computing for ubiquitous intelligence in internet of things: State-of-the-art and future directions," Sensors, vol. 22, no. 16, p. 5983, 2022.

Deep models under the gan: information leakage from collaborative deep learning. B Hitaj, G Ateniese, F Perez-Cruz, Proceedings of the 2017 ACM SIGSAC conference on computer and communications security. the 2017 ACM SIGSAC conference on computer and communications securityB. Hitaj, G. Ateniese, and F. Perez-Cruz, "Deep models under the gan: information leakage from collaborative deep learning," in Proceedings of the 2017 ACM SIGSAC conference on computer and communications security, 2017, pp. 603-618.

Beyond inferring class representatives: User-level privacy leakage from federated learning. Z Wang, M Song, Z Zhang, Y Song, Q Wang, H Qi, IEEE INFOCOM 2019-IEEE conference on computer communications. IEEEZ. Wang, M. Song, Z. Zhang, Y. Song, Q. Wang, and H. Qi, "Beyond inferring class representatives: User-level privacy leakage from feder- ated learning," in IEEE INFOCOM 2019-IEEE conference on computer communications. IEEE, 2019, pp. 2512-2520.

Exploiting unintended property leakage in blockchain-assisted federated learning for intelligent edge computing. M Shen, H Wang, B Zhang, L Zhu, K Xu, Q Li, X Du, IEEE Internet of Things Journal. 84M. Shen, H. Wang, B. Zhang, L. Zhu, K. Xu, Q. Li, and X. Du, "Exploiting unintended property leakage in blockchain-assisted feder- ated learning for intelligent edge computing," IEEE Internet of Things Journal, vol. 8, no. 4, pp. 2265-2275, 2020.

A framework for evaluating client privacy leakages in federated learning. W Wei, L Liu, M Loper, K.-H Chow, M E Gursoy, S Truex, Y Wu, European Symposium on Research in Computer Security. SpringerW. Wei, L. Liu, M. Loper, K.-H. Chow, M. E. Gursoy, S. Truex, and Y. Wu, "A framework for evaluating client privacy leakages in federated learning," in European Symposium on Research in Computer Security. Springer, 2020, pp. 545-566.

Never too late: Tracing and mitigating backdoor attacks in federated learning. H Zeng, T Zhou, X Wu, Z Cai, 2022 41st International Symposium on Reliable Distributed Systems (SRDS). H. Zeng, T. Zhou, X. Wu, and Z. Cai, "Never too late: Tracing and mitigating backdoor attacks in federated learning," in 2022 41st International Symposium on Reliable Distributed Systems (SRDS).

. IEEE. IEEE, 2022, pp. 69-81.

Backdoor attacks on federated learning with lottery ticket hypothesis. Z Yin, Y Yuan, P Guo, P Zhou, arXiv:2109.10512arXiv preprintZ. Yin, Y. Yuan, P. Guo, and P. Zhou, "Backdoor attacks on federated learning with lottery ticket hypothesis," arXiv preprint arXiv:2109.10512, 2021.

Can you really backdoor federated learning. Z Sun, P Kairouz, A T Suresh, H B Mcmahan, arXiv:1911.07963arXiv preprintZ. Sun, P. Kairouz, A. T. Suresh, and H. B. McMahan, "Can you really backdoor federated learning?" arXiv preprint arXiv:1911.07963, 2019.

IT-security and privacy: design and use of privacyenhancing security mechanisms. S Fischer-Hübner, SpringerS. Fischer-Hübner, IT-security and privacy: design and use of privacy- enhancing security mechanisms. Springer, 2001.

A review on the state-of-the-art privacypreserving approaches in the e-health clouds. A Abbas, S U Khan, IEEE journal of Biomedical and health informatics. 184A. Abbas and S. U. Khan, "A review on the state-of-the-art privacy- preserving approaches in the e-health clouds," IEEE journal of Biomed- ical and health informatics, vol. 18, no. 4, pp. 1431-1441, 2014.

Privacyenhancing technologies and metrics in personalized information systems. J Parra-Arnau, D Rebollo-Monedero, J Forné, Advanced research in data privacy. SpringerJ. Parra-Arnau, D. Rebollo-Monedero, and J. Forné, "Privacy- enhancing technologies and metrics in personalized information sys- tems," in Advanced research in data privacy. Springer, 2014, pp. 423-442.

Enhancing privacy and data security across healthcare applications using blockchain and distributed ledger concepts. H Liu, R G Crespo, O S Martínez, HealthcareMDPI8243H. Liu, R. G. Crespo, and O. S. Martínez, "Enhancing privacy and data security across healthcare applications using blockchain and distributed ledger concepts," in Healthcare, vol. 8, no. 3. MDPI, 2020, p. 243.

Federated learning approach to protect healthcare data over big data scenario. G Dhiman, S Juneja, H Mohafez, I El-Bayoumy, L K Sharma, M Hadizadeh, M A Islam, W Viriyasitavat, M U Khandaker, Sustainability. 1452500G. Dhiman, S. Juneja, H. Mohafez, I. El-Bayoumy, L. K. Sharma, M. Hadizadeh, M. A. Islam, W. Viriyasitavat, and M. U. Khandaker, "Federated learning approach to protect healthcare data over big data scenario," Sustainability, vol. 14, no. 5, p. 2500, 2022.

Protecting privacy when disclosing information: k-anonymity and its enforcement through generalization and suppression. P Samarati, L Sweeney, SRI International, Tech. Rep. P. Samarati and L. Sweeney, "Protecting privacy when disclosing information: k-anonymity and its enforcement through generalization and suppression," SRI International, Tech. Rep., 1998.

Anonymizing data for privacy-preserving federated learning. O Choudhury, A Gkoulalas-Divanis, T Salonidis, I Sylla, Y Park, G Hsu, A Das, arXiv:2002.09096arXiv preprintO. Choudhury, A. Gkoulalas-Divanis, T. Salonidis, I. Sylla, Y. Park, G. Hsu, and A. Das, "Anonymizing data for privacy-preserving feder- ated learning," arXiv preprint arXiv:2002.09096, 2020.

l-diversity: Privacy beyond k-anonymity. A Machanavajjhala, D Kifer, J Gehrke, M Venkitasubramaniam, ACM TKDD. 113A. Machanavajjhala, D. Kifer, J. Gehrke, and M. Venkitasubramaniam, "l-diversity: Privacy beyond k-anonymity," ACM TKDD, vol. 1, no. 1, pp. 3-es, 2007.

Anonymization of sensitive quasi-identifiers for l-diversity and t-closeness. Y Sei, H Okumura, T Takenouchi, A Ohsuga, IEEE Transactions on Dependable and Secure Computing. 164Y. Sei, H. Okumura, T. Takenouchi, and A. Ohsuga, "Anonymization of sensitive quasi-identifiers for l-diversity and t-closeness," IEEE Transactions on Dependable and Secure Computing, vol. 16, no. 4, pp. 580-593, 2017.

From t-closeness to differential privacy and vice versa in data anonymization. J Domingo-Ferrer, J Soria-Comas, Knowledge-Based Systems. 74J. Domingo-Ferrer and J. Soria-Comas, "From t-closeness to differen- tial privacy and vice versa in data anonymization," Knowledge-Based Systems, vol. 74, pp. 151-158, 2015.

Achieving security and privacy in federated learning systems: Survey, research challenges and future directions. A Blanco-Justicia, J Domingo-Ferrer, S Martínez, D Sánchez, A Flanagan, K E Tan, Engineering Applications of Artificial Intelligence. 106104468A. Blanco-Justicia, J. Domingo-Ferrer, S. Martínez, D. Sánchez, A. Flanagan, and K. E. Tan, "Achieving security and privacy in federated learning systems: Survey, research challenges and future directions," Engineering Applications of Artificial Intelligence, vol. 106, p. 104468, 2021.

A review of applications in federated learning. L Li, Y Fan, M Tse, K.-Y. Lin, Computers & Industrial Engineering. 149106854L. Li, Y. Fan, M. Tse, and K.-Y. Lin, "A review of applications in federated learning," Computers & Industrial Engineering, vol. 149, p. 106854, 2020.

From distributed machine learning to federated learning: A survey. J Liu, J Huang, Y Zhou, X Li, S Ji, H Xiong, D Dou, Knowledge and Information Systems. J. Liu, J. Huang, Y. Zhou, X. Li, S. Ji, H. Xiong, and D. Dou, "From distributed machine learning to federated learning: A survey," Knowledge and Information Systems, pp. 1-33, 2022.

Protocols for secure computations. A C Yao, 23rd Annual Symposium on Foundations of Computer Science. IEEEA. C. Yao, "Protocols for secure computations," in 23rd Annual Symposium on Foundations of Computer Science. IEEE, 1982, pp. 160-164.

A comprehensive survey of privacypreserving federated learning: A taxonomy, review, and future directions. X Yin, Y Zhu, J Hu, ACM Computing Surveys (CSUR). 546X. Yin, Y. Zhu, and J. Hu, "A comprehensive survey of privacy- preserving federated learning: A taxonomy, review, and future direc- tions," ACM Computing Surveys (CSUR), vol. 54, no. 6, pp. 1-36, 2021.

Applying federated learning in software-defined networks: A survey. X Ma, L Liao, Z Li, R X Lai, M Zhang, Symmetry. 142195X. Ma, L. Liao, Z. Li, R. X. Lai, and M. Zhang, "Applying federated learning in software-defined networks: A survey," Symmetry, vol. 14, no. 2, p. 195, 2022.

The knowledge complexity of interactive proof systems. S Goldwasser, S Micali, C Rackoff, SIAM Journal on computing. 181S. Goldwasser, S. Micali, and C. Rackoff, "The knowledge complexity of interactive proof systems," SIAM Journal on computing, vol. 18, no. 1, pp. 186-208, 1989.

V eri fl: Communication-efficient and fast verifiable aggregation for federated learning. X Guo, Z Liu, J Li, J Gao, B Hou, C Dong, T Baker, IEEE Transactions on Information Forensics and Security. 16X. Guo, Z. Liu, J. Li, J. Gao, B. Hou, C. Dong, and T. Baker, "V eri fl: Communication-efficient and fast verifiable aggregation for federated learning," IEEE Transactions on Information Forensics and Security, vol. 16, pp. 1736-1751, 2020.

Secure remote multi-factor authentication scheme based on chaotic map zero-knowledge proof for crowdsourcing internet of things. W Liu, X Wang, W Peng, IEEE Access. 8W. Liu, X. Wang, and W. Peng, "Secure remote multi-factor au- thentication scheme based on chaotic map zero-knowledge proof for crowdsourcing internet of things," IEEE Access, vol. 8, pp. 8754-8767, 2019.

Privacy-preserving gradient boosting decision trees. Q Li, Z Wu, Z Wen, B He, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence34Q. Li, Z. Wu, Z. Wen, and B. He, "Privacy-preserving gradient boosting decision trees," in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 34, no. 01, 2020, pp. 784-791.

Selecting privacyenhancing technologies for managing health data use. S Jordan, C Fontaine, R Hendricks-Sturrup, Frontiers in Public Health. 10S. Jordan, C. Fontaine, and R. Hendricks-Sturrup, "Selecting privacy- enhancing technologies for managing health data use," Frontiers in Public Health, vol. 10, 2022.

Differential privacy via wavelet transforms. X Xiao, G Wang, J Gehrke, IEEE Transactions on knowledge and data engineering. 238X. Xiao, G. Wang, and J. Gehrke, "Differential privacy via wavelet transforms," IEEE Transactions on knowledge and data engineering, vol. 23, no. 8, pp. 1200-1214, 2010.

Stochastic gradient descent with differentially private updates. S Song, K Chaudhuri, A D Sarwate, IEEE Global Conference on Signal and Information Processing. S. Song, K. Chaudhuri, and A. D. Sarwate, "Stochastic gradient descent with differentially private updates," in IEEE Global Conference on Signal and Information Processing, 2013, pp. 245-248.

Differentially private continual monitoring of heavy hitters from distributed streams. T.-H H Chan, M Li, E Shi, W Xu, International Symposium on Privacy Enhancing Technologies Symposium. SpringerT.-H. H. Chan, M. Li, E. Shi, and W. Xu, "Differentially private continual monitoring of heavy hitters from distributed streams," in International Symposium on Privacy Enhancing Technologies Sympo- sium. Springer, 2012, pp. 140-159.

Privacy at scale: Local differential privacy in practice. G Cormode, S Jha, T Kulkarni, N Li, D Srivastava, T Wang, Proceedings of the 2018 International Conference on Management of Data. the 2018 International Conference on Management of DataG. Cormode, S. Jha, T. Kulkarni, N. Li, D. Srivastava, and T. Wang, "Privacy at scale: Local differential privacy in practice," in Proceedings of the 2018 International Conference on Management of Data, 2018, pp. 1655-1658.

Privacy enhancing technologies for solving the privacy-personalization paradox: Taxonomy and survey. N Kaaniche, M Laurent, S Belguith, Journal of Network and Computer Applications. 171102807N. Kaaniche, M. Laurent, and S. Belguith, "Privacy enhancing tech- nologies for solving the privacy-personalization paradox: Taxonomy and survey," Journal of Network and Computer Applications, vol. 171, p. 102807, 2020.

A syntactic approach for privacy-preserving federated learning. O Choudhury, A Gkoulalas-Divanis, T Salonidis, I Sylla, Y Park, G Hsu, A Das, ECAI 2020. IOS PressO. Choudhury, A. Gkoulalas-Divanis, T. Salonidis, I. Sylla, Y. Park, G. Hsu, and A. Das, "A syntactic approach for privacy-preserving federated learning," in ECAI 2020. IOS Press, 2020, pp. 1762-1769.

Robust aggregation for adaptive privacy preserving federated learning in healthcare. M Grama, M Musat, L Muñoz-González, J Passerat-Palmbach, D Rueckert, A Alansary, arXiv:2009.08294arXiv preprintM. Grama, M. Musat, L. Muñoz-González, J. Passerat-Palmbach, D. Rueckert, and A. Alansary, "Robust aggregation for adaptive privacy preserving federated learning in healthcare," arXiv preprint arXiv:2009.08294, 2020.

A non-negative matrix factorization framework for privacy-preserving and federated learning. Z Alsulaimawi, IEEE 22nd International Workshop on Multimedia Signal Processing. Z. Alsulaimawi, "A non-negative matrix factorization framework for privacy-preserving and federated learning," in IEEE 22nd International Workshop on Multimedia Signal Processing, 2020, pp. 1-6.

Fearh: Federated machine learning with anonymous random hybridization on electronic medical records. J Cui, H Zhu, H Deng, Z Chen, D Liu, Journal of Biomedical Informatics. 117103735J. Cui, H. Zhu, H. Deng, Z. Chen, and D. Liu, "Fearh: Federated machine learning with anonymous random hybridization on electronic medical records," Journal of Biomedical Informatics, vol. 117, p. 103735, 2021.

Petchain: a blockchain-based privacy enhancing technology. I T Javed, F Alharbi, T Margaria, N Crespi, K N Qureshi, IEEE Access. 9I. T. Javed, F. Alharbi, T. Margaria, N. Crespi, and K. N. Qureshi, "Petchain: a blockchain-based privacy enhancing technology," IEEE Access, vol. 9, pp. 41 129-41 143, 2021.

Gdpr-compliant personal data management: A blockchain-based solution. N B Truong, K Sun, G M Lee, Y Guo, IEEE Transactions on Information Forensics and Security. 15N. B. Truong, K. Sun, G. M. Lee, and Y. Guo, "Gdpr-compliant personal data management: A blockchain-based solution," IEEE Trans- actions on Information Forensics and Security, vol. 15, pp. 1746-1761, 2019.

Preserving patients' privacy in medical iot using blockchain. B Alamri, I T Javed, T Margaria, Edge Computing-EDGE 2020: 4th International Conference, Held as Part of the Services Conference Federation. Honolulu, HI, USASpringer2020B. Alamri, I. T. Javed, and T. Margaria, "Preserving patients' privacy in medical iot using blockchain," in Edge Computing-EDGE 2020: 4th International Conference, Held as Part of the Services Conference Federation, SCF 2020, Honolulu, HI, USA, September 18-20, 2020, Proceedings 4. Springer, 2020, pp. 103-110.

Blockchain and federated learning for 5g beyond. Y Lu, X Huang, K Zhang, S Maharjan, Y Zhang, IEEE Network. 351Y. Lu, X. Huang, K. Zhang, S. Maharjan, and Y. Zhang, "Blockchain and federated learning for 5g beyond," IEEE Network, vol. 35, no. 1, pp. 219-225, 2020.

Federated learning meets blockchain in edge computing: Opportunities and challenges. D C Nguyen, M Ding, Q.-V Pham, P N Pathirana, L B Le, A Seneviratne, J Li, D Niyato, H V Poor, IEEE Internet of Things Journal. 816D. C. Nguyen, M. Ding, Q.-V. Pham, P. N. Pathirana, L. B. Le, A. Seneviratne, J. Li, D. Niyato, and H. V. Poor, "Federated learning meets blockchain in edge computing: Opportunities and challenges," IEEE Internet of Things Journal, vol. 8, no. 16, pp. 12 806-12 825, 2021.

A survey on data provenance in iot. R Hu, Z Yan, W Ding, L T Yang, World Wide Web. 232R. Hu, Z. Yan, W. Ding, and L. T. Yang, "A survey on data provenance in iot," World Wide Web, vol. 23, no. 2, pp. 1441-1463, 2020.

Gradientleaks: Understanding and controlling deanonymization in federated learning. T Orekondy, S J Oh, Y Zhang, B Schiele, M Fritz, arXiv:1805.05838arXiv preprintT. Orekondy, S. J. Oh, Y. Zhang, B. Schiele, and M. Fritz, "Gradient- leaks: Understanding and controlling deanonymization in federated learning," arXiv preprint arXiv:1805.05838, 2018.

Waffle: Weight anonymized factorization for federated learning. W Hao, N Mehta, K J Liang, P Cheng, M El-Khamy, L Carin, IEEE Access. 10W. Hao, N. Mehta, K. J. Liang, P. Cheng, M. El-Khamy, and L. Carin, "Waffle: Weight anonymized factorization for federated learning," IEEE Access, vol. 10, pp. 49 207-49 218, 2022.

Analyzing user-level privacy attack against federated learning. M Song, Z Wang, Z Zhang, Y Song, Q Wang, J Ren, H Qi, IEEE JSAC. 3810M. Song, Z. Wang, Z. Zhang, Y. Song, Q. Wang, J. Ren, and H. Qi, "Analyzing user-level privacy attack against federated learning," IEEE JSAC, vol. 38, no. 10, pp. 2430-2444, 2020.

Evaluating efficiency and effectiveness of federated learning approaches in knowledge extraction tasks. F Marulli, L Verde, S Marrone, R Barone, M S De Biase, International Joint Conference on Neural Networks. IEEEF. Marulli, L. Verde, S. Marrone, R. Barone, and M. S. De Biase, "Eval- uating efficiency and effectiveness of federated learning approaches in knowledge extraction tasks," in International Joint Conference on Neural Networks. IEEE, 2021, pp. 1-6.

Homomorphic encryption-based privacy-preserving federated learning in iot-enabled healthcare system. L Zhang, J Xu, P Vijayakumar, P K Sharma, U Ghosh, IEEE Transactions on Network Science and Engineering. L. Zhang, J. Xu, P. Vijayakumar, P. K. Sharma, and U. Ghosh, "Homomorphic encryption-based privacy-preserving federated learning in iot-enabled healthcare system," IEEE Transactions on Network Science and Engineering, 2022.

Privacy-preserving federated learning based on multi-key homomorphic encryption. J Ma, S.-A Naas, S Sigg, X Lyu, International Journal of Intelligent Systems. J. Ma, S.-A. Naas, S. Sigg, and X. Lyu, "Privacy-preserving federated learning based on multi-key homomorphic encryption," International Journal of Intelligent Systems, 2022.

Secure neuroimaging analysis using federated learning with homomorphic encryption. D Stripelis, H Saleem, T Ghai, N Dhinagar, U Gupta, C Anastasiou, G Ver, S Steeg, M Ravi, P M Naveed, Thompson, 17th International Symposium on Medical Information Processing and Analysis. SPIE12088D. Stripelis, H. Saleem, T. Ghai, N. Dhinagar, U. Gupta, C. Anastasiou, G. Ver Steeg, S. Ravi, M. Naveed, P. M. Thompson et al., "Secure neuroimaging analysis using federated learning with homomorphic encryption," in 17th International Symposium on Medical Information Processing and Analysis, vol. 12088. SPIE, 2021, pp. 351-359.

Privacy enhancing and scalable federated learning to accelerate ai implementation in cross-silo and iomt environments. A S Rachakonda, B S Moorthy, C A Jain, D A Bukharev, E A Bucur, F F Manni, G T M Quiterio, H L Joosten, I N I Mendez, IEEE Journal of Biomedical and Health Informatics. A. S. Rachakonda, B. S. Moorthy, C. A. Jain, D. A. Bukharev, E. A. Bucur, F. F. Manni, G. T. M. Quiterio, H. L. Joosten, and I. N. I. Mendez, "Privacy enhancing and scalable federated learning to accelerate ai implementation in cross-silo and iomt environments," IEEE Journal of Biomedical and Health Informatics, 2022.

Advancing blockchain-based federated learning through verifiable off-chain computations. J Heiss, E Grünewald, N Haimerl, S Schulte, S Tai, arXiv:2206.11641arXiv preprintJ. Heiss, E. Grünewald, N. Haimerl, S. Schulte, and S. Tai, "Advancing blockchain-based federated learning through verifiable off-chain com- putations," arXiv preprint arXiv:2206.11641, 2022.

Homomorphic encryption and federated learning based privacy-preserving cnn training: Covid-19 detection use-case. F Wibawa, F O Catak, M Kuzlu, S Sarp, U Cali, Proceedings of the 2022 European Interdisciplinary Cybersecurity Conference. the 2022 European Interdisciplinary Cybersecurity ConferenceF. Wibawa, F. O. Catak, M. Kuzlu, S. Sarp, and U. Cali, "Homomorphic encryption and federated learning based privacy-preserving cnn train- ing: Covid-19 detection use-case," in Proceedings of the 2022 European Interdisciplinary Cybersecurity Conference, 2022, pp. 85-90.

A method to improve the privacy and security for federated learning. Y Bai, M Fan, IEEE 6th ICCCS. Y. Bai and M. Fan, "A method to improve the privacy and security for federated learning," in IEEE 6th ICCCS, 2021, pp. 704-708.

Bfv-based homomorphic encryption for privacy-preserving cnn models. F Wibawa, F O Catak, S Sarp, M Kuzlu, Cryptography. 6334F. Wibawa, F. O. Catak, S. Sarp, and M. Kuzlu, "Bfv-based homo- morphic encryption for privacy-preserving cnn models," Cryptography, vol. 6, no. 3, p. 34, 2022.

Privacypreserving and bandwidth-efficient federated learning: An application to in-hospital mortality prediction. R Kerkouche, G Acs, C Castelluccia, P Genevès, Proceedings of the Conference on Health, Inference, and Learning. the Conference on Health, Inference, and LearningR. Kerkouche, G. Acs, C. Castelluccia, and P. Genevès, "Privacy- preserving and bandwidth-efficient federated learning: An application to in-hospital mortality prediction," in Proceedings of the Conference on Health, Inference, and Learning, 2021, pp. 25-35.

Privacy-preserving federated learning model for healthcare data. T U Islam, R Ghasemi, N Mohammed, IEEE 12th CCWC. T. U. Islam, R. Ghasemi, and N. Mohammed, "Privacy-preserving federated learning model for healthcare data," in IEEE 12th CCWC, 2022, pp. 0281-0287.

A federated adversarial learning method for biomedical named entity recognition. H Zhao, S Yuan, N Xie, J Leng, G Wang, IEEE BIBM, 2021. H. Zhao, S. Yuan, N. Xie, J. Leng, and G. Wang, "A federated adversarial learning method for biomedical named entity recognition," in IEEE BIBM, 2021, pp. 2962-2969.

A federated learning based privacy-preserving smart healthcare system. J Li, Y Meng, L Ma, S Du, H Zhu, Q Pei, X Shen, IEEE Transactions on Industrial Informatics. 183J. Li, Y. Meng, L. Ma, S. Du, H. Zhu, Q. Pei, and X. Shen, "A federated learning based privacy-preserving smart healthcare system," IEEE Transactions on Industrial Informatics, vol. 18, no. 3, 2021.

Federated learning for covid-19 detection with generative adversarial networks in edge cloud computing. D C Nguyen, M Ding, P N Pathirana, A Seneviratne, A Y Zomaya, IEEE Internet of Things Journal. D. C. Nguyen, M. Ding, P. N. Pathirana, A. Seneviratne, and A. Y. Zomaya, "Federated learning for covid-19 detection with generative adversarial networks in edge cloud computing," IEEE Internet of Things Journal, 2021.

Iomt: A covid-19 healthcare system driven by federated learning and blockchain. O Samuel, A Omojo, A Onuja, Y Sunday, P Tiwari, D Gupta, G Hafeez, A Yahaya, O Fatoba, S Shamshirband, IEEE Journal of Biomedical and Health Informatics. O. Samuel, A. Omojo, A. Onuja, Y. Sunday, P. Tiwari, D. Gupta, G. Hafeez, A. Yahaya, O. Fatoba, and S. Shamshirband, "Iomt: A covid-19 healthcare system driven by federated learning and blockchain," IEEE Journal of Biomedical and Health Informatics, 2022.

Protecting personal healthcare record using blockchain & federated learning technologies. S Aich, N K Sinai, S Kumar, M Ali, Y R Choi, M.-I Joo, H.-C Kim, in 24th ICACT. IEEE, 2022S. Aich, N. K. Sinai, S. Kumar, M. Ali, Y. R. Choi, M.-I. Joo, and H.-C. Kim, "Protecting personal healthcare record using blockchain & federated learning technologies," in 24th ICACT. IEEE, 2022, pp. 109-112.

Federated-learning based privacy preservation and fraud-enabled blockchain iomt system for healthcare. A Lakhan, M A Mohammed, J Nedoma, R Martinek, P Tiwari, A Vidyarthi, A Alkhayyat, W Wang, IEEE Journal of Biomedical and Health Informatics. A. Lakhan, M. A. Mohammed, J. Nedoma, R. Martinek, P. Tiwari, A. Vidyarthi, A. Alkhayyat, and W. Wang, "Federated-learning based privacy preservation and fraud-enabled blockchain iomt system for healthcare," IEEE Journal of Biomedical and Health Informatics, 2022.

A framework for privacy-preservation of iot healthcare data using federated learning and blockchain technology. S Singh, S Rathore, O Alfarraj, A Tolba, B Yoon, Future Generation Computer Systems. 129S. Singh, S. Rathore, O. Alfarraj, A. Tolba, and B. Yoon, "A framework for privacy-preservation of iot healthcare data using federated learning and blockchain technology," Future Generation Computer Systems, vol. 129, pp. 380-388, 2022.

Blockchain-federated-learning and deep learning models for covid-19 detection using ct imaging. R Kumar, A A Khan, J Kumar, N A Golilarz, S Zhang, Y Ting, C Zheng, W Wang, IEEE Sensors Journal. 2114R. Kumar, A. A. Khan, J. Kumar, N. A. Golilarz, S. Zhang, Y. Ting, C. Zheng, W. Wang et al., "Blockchain-federated-learning and deep learning models for covid-19 detection using ct imaging," IEEE Sensors Journal, vol. 21, no. 14, pp. 16 301-16 314, 2021.