# IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING 1 A Survey on Multi-Behavior Sequential Recommendation

CorpusID: 261339556
 
tags: #Computer_Science

URL: [https://www.semanticscholar.org/paper/ca9f41ad1c3f0ed51781eef6cfcd035bf4d01d1a](https://www.semanticscholar.org/paper/ca9f41ad1c3f0ed51781eef6cfcd035bf4d01d1a)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | True |
| By Annotator      | (Not Annotated) |

---

IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING 1 A Survey on Multi-Behavior Sequential Recommendation


Xiaoqing Chen 
Zhitao Li 
Weike Pan 
Zhong Ming 
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING 1 A Survey on Multi-Behavior Sequential Recommendation
Index Terms-Multi-behavior sequential recommendationMa- trix factorizationDeep learning
People usually have the explicit or implicit desire to get the information they need and are most interested in from massive information, which has led to the creation of personalized recommender systems. Recommender systems are set up to address the issue of information overload in traditional information retrieval systems such as search engines, and have been a significant area of research focused on recommending information that is of most interest to users. There is a sequential nature to the behavior of a person interacting with a system, such as examining one item of clothing before examining others. The problem of taking this sequential nature into account in delivering recommendation is known as sequential recommendation (SR). The traditional sequential recommendation problem merely takes into account a single type of behavior of the users, while in real scenarios users tend to engage in multiple types of behaviors, such as examining and adding clothes to cart before purchasing them, leading to the proposal of multibehavior sequential recommendation (MBSR). MBSR considers both sequentiality and heterogeneity of user behaviors, which can achieve state-of-the-art recommendation through suitable modeling. Hence, MBSR is a relatively new and worthy direction for in-depth research, for which some related works have been proposed. This survey aims to shed light on the MBSR problem. Firstly, we introduce MBSR in detail, including its problem definition, application scenarios and challenges faced. Secondly, we detail the classification of MBSR, including neighborhood-based methods, matrix factorization-based methods and deep learningbased methods, where we further classify the deep learningbased methods into different learning architectures based on RNN, GNN, Transformer, and generic architectures as well as architectures that integrate hybrid techniques. In each method, we present related works based on the data perspective and the modeling perspective, as well as analyze the strengths, weaknesses and features of these works. Finally, we discuss some promising future research directions to address the challenges and improve the current status of MBSR.

## I. INTRODUCTION

Nowadays, people are increasingly relying on the Internet to obtain information, and are faced with information overload due to the complexity and huge amount of network information. Traditional search engines cannot filter the items for each user well, making it difficult for people to quickly access the information they want. As such, recommender systems that can effectively solve the information overload problem and provide personalized services to different users are of great importance. Recommender systems [1], [2] is a fundamental tool to recommend items of most interest to the users from a large amount Xiaoqing  of information. The recommendation process usually involves collecting and analyzing the users' historical behavior data to learn their preferences and behavior patterns, and thus find the items which better align with their preferences. The historical behavior data used can be divided into explicit feedback and implicit feedback. The explicit feedback data, also known as multi-class feedback, includes the behaviors such as a user's ratings and likes on items, while the implicit feedback data, also known as one-class feedback, includes the behaviors like browses, adds to cart and purchases.

Since the implicit feedback data is more readily available compared with the explicit feedback data in real scenarios, many works have focused on studying recommendation problems based on one single type of implicit feedback behavior, which brings up the issue of single-behavior recommendation (SBR) [3]- [5]. However, SBR usually contains fewer data, which is prone to the data sparsity or cold-start issues [6]. Besides, there is often more than one type of interaction between users and items in real-world scenarios, such as examination, adding to cart and purchase in the setting of an ecommerce platform. This indicates that there will be multiple types of user feedback, i.e., users' feedback is heterogeneous, which needs to be taken into account when modeling user preferences [6]- [8]. As such, researchers have turned to the study of multi-behavior recommendation (MBR) problems [9], [10]. Different from the SBR problem, MBR provides personalized recommendations to users based on their heterogeneous one-class implicit feedback. In the modeling of MBR, not only a user's target feedback, such as the purchase behavior during online shopping, but also the information from auxiliary feedback such as browsing and favorites will be considered.

In addition to being heterogeneous, users' implicit feedback is also naturally sequential. In order to utilize the sequential information, some recent works have proposed singlebehavior sequential recommendation (SBSR), which begins to consider the sequential information of the one-class implicit feedback from users. Currently, there are advanced methods with better recommendation performance in SBSR. They use the sequences of users' historical behaviors composed of one-class feedback to learn users' long-term and short-term preferences, and thus predict the items that users may interact with in the near future [11]- [13]. However, SBSR only models the users' one-class implicit feedback, ignoring other implicit feedback information from users. Multi-behavior sequential recommendation (MBSR), can fully consider the implicit feedback information of the users, solving the problem in SBSR. In MBSR, an algorithm usually models a user's heterogeneous behaviors and the sequential information of the behaviors arXiv:2308.15701v1 [cs.IR] 30 Aug 2023 simultaneously, so as to recommend items more aligned with the real preferences of the user [14], [15]. With the integration of MBR and SBSR, MBSR can be closer to the real behaviors of users. Nonetheless, it correspondingly brings more new challenges, including (i) sequence modeling of heterogeneous behavioral feedback, (ii) relationship modeling between user behaviors, (iii) joint long-term and short-term preferences modeling, (iv) existing noise, bias and other related issues in MBSR. We will discuss the specific challenges in detail in a subsequent section.

We also review some relatively well-known works and stateof-the-art works from leading conferences and journals in this survey, so as to illustrate how the MBSR problem is studied for personalized recommendation, hoping to provide some guidance for future research on MBSR. Specifically, we categorize the existing works on multi-behavior sequential recommendation into neighborhood-based methods, matrix factorizationbased methods, and deep learning-based methods. Firstly, in neighborhood-based methods, we introduce how to use the neighborhood information to solve the recommendation problem, and how to extend existing methods from SBSR to MBSR. Secondly, in matrix factorization-based methods, we introduce the general idea of matrix factorization used in recommendation problems and mainly introduce the typical work from the perspective of transfer learning. Thirdly, in deep learning-based methods, we mainly focus on how to apply the ideas of deep learning to the MBSR problem, and describe the MBSR methods based on recurrent neural network (RNN), graph neural network (GNN), Transformer, generic methods and hybrid methods. We further delineate the related works of each deep learning framework from different modeling perspectives. Finally, we briefly discuss some future research directions, and conclude the paper.

The multi-behavioral sequential recommendation is currently considered an emerging area with limited related works and a lack of relevant surveys. In order to provide a comprehensive overview and enable researchers to keep abreast of the latest developments in MBSR, we conduct a survey on this topic, where we classify and compare various techniques and related works. The key contributions of our survey are summarized as follows.

• We present an in-depth overview of the MBSR problem by discussing its background, problem definition, application scenarios, and the existing challenges. Additionally, we provide a comprehensive classification of the current works on MBSR from three key perspectives: technique, data, and modeling. • We provide a summary of the strengths and weaknesses of each technique employed, alongside a detailed comparison and analysis of representative MBSR works based on the provided classification. • We propose valuable future research directions to address the challenges posed by MBSR.

The rest of the paper is organized as follows. In Section 2, we give the background on MBSR, encompassing four aspects, i.e., problem definition, application scenarios, challenges and categorization. Then in Sections 3, 4 and 5, we present an outline of the prominent works of MBSR in terms of neighborhood-based methods, matrix factorization-based methods and deep learning-based methods, respectively. In Section 6, we discuss some possible future research directions for MBSR, and finally, we draw the paper to a conclusion in Section 7.


## II. PRELIMINARIES


## A. Problem Definition

The MBSR problem mainly focuses on next item recommendation in a heterogeneous feedback sequence. We assume that there is a set of users, i.e., U, a set of items, i.e., I, and a set of behaviors (or feedback), i.e., F, in the system. For the corresponding recommendation methods, the input is a set of (user, heterogeneous behavior sequence) pairs, i.e., (u, S u ), where u ∈ U represents a user ID, and S u = i 1 u , f 1 u , . . . , (i t u , f t u ) , . . . , i |Su| u , f |Su| u represents the historical interaction sequence between the user and the items. In the sequence, each (i t u , f t u ) tuple represents the (item, behavior) pair composed of the item i and the corresponding behavior f interacted by the user u at the tth time step, where i t u ∈ I, f t u ∈ F. We use time step instead of timestamp since MBSR does not generally introduce timestamp which represents precise time in modeling. Proper modeling the input data can learn the user's preferences, as well as the representations and relationships of the items and behaviors, etc. Based on a typical recommendation method, we can predict the preference valuer u t+1,j of a user u for any item j ∈ I at the (t+1)th time step according to the most recent L historical interactions of user u before the (t + 1)th time step, i.e.,
S t u = i t−L+1 u , f t−L+1 u , . . . , i ℓ u , f ℓ u , . . . , (i t u , f t u ) , t ≤ |S u |.
We can then rank the preference valuesr u |S u |+1,j of the user u for the candidate items j ∈ I to generate a top-K list of items for user u, which indicates the next items that user u is most likely to interact with. We illustrate the general MBSR in Figure 1, and show the commonly used symbols and corresponding interpretations in Table I, where we employ various font styles to denote diverse types of notations, i.e., uppercase bold for matrices, lowercase bold for vectors, lowercase non-bold for scalars, and copperplate for sets. 


## B. Application Scenarios

In recommender systems, MBSR is a relatively new research hotspot, attracting extensive attention from both academia and industry. In industry, the related works on MBSR are mainly applied to the click-through rate (CTR) prediction tasks. Similar to sequential recommendation, CTR leverages historical (user, item) interaction information to generate a list of items for recommendation to the user at the next time step. However, 


## Notation

Explanation n user number m item number R the observed set of (user, item, behavior) tuples U user set
I item set F behavior set u ∈ U user ID i ∈ I item ID f ∈ F
behavior ID Su the sequence of (item, behavior) pairs that user u has interacted with Se the sequence examined by user u Sn the sequence unexamined by user u S l the sequence that user u has liked S d the sequence that user u has disliked i t u ∈ I the item interacted by user u at the time step t (t ∈ {1, 2, . . . , |Su|}) f t u ∈ F the behavior of user u at the time step t (t ∈ {1, 2, . . . , |Su|})
Uu ∈ R d×1 the embedding of user u Vi ∈ R d×1 the embedding of item i F f ∈ R d×1
the embedding of behavior f r u t,i the predicted preference of user u to item i at the time step t rt,i the predicted preference on item i at the time step t r u t,i,f the predicted preference that user u generates behavior f on item i at the time step t Em(·) the ID-to-embedding function σ(·) the sigmoid function ⊙ the element-wise product function in contrast to sequential recommendation, CTR ranks items by predicting a user's click-through rate on the items, which makes the CTR task require an input of item information, and thus the data processing methods and models used will often be different from those in sequential recommendation. Currently, MBSR has been used in many areas, varying from e-commerce [16], [17] and video recommendation [18], [19] to news recommendation [20], [21]. In e-commerce, researchers predict the items that are most probable to be purchased by users through the behavior sequential information of users' browses, adds-to-cart, favorites, and purchases [14], [22], [23]. In video recommendation, users will generate behaviors like examinations, shares and others, where the sharing behavior can be used as the target behavior, and the examination behavior can be used as the auxiliary behavior [24]. In news recommendation, users may interact with news by explicit feedback (e.g., dislike) and implicit feedback (e.g., browse), which makes it possible to incorporate these feedbacks to infer users' positive and negative interest preferences [25].

To better learn the real preferences of users, some research works also take into account the dwelling time, category information, and other more fine-grained information in the MBSR problem [26]- [28]. Moreover, some works on MBSR focus not only on better capturing user preferences, but also on designing relevant multi-behavior sequential recommendation algorithms in the context of user privacy protection issues. Importantly, MBSR methods also consider the heterogeneous behavior information of users and the sequential information within or between the behaviors, allowing for more useful information to be learned when modeling, which makes it closer to real recommendation scenarios. Hence, it is of great significance to design a recommendation algorithm for multibehavior sequential recommendation.


## C. Challenges

The MBSR problem involves modeling both multiple behaviors and behavioral sequences, contributing to the necessity to consider the existing problems of MBR and SBSR, as well as how to integrate these two kinds of information well. In particular, MBSR has to face the following challenges.

• Sequence modeling of heterogeneous behavioral feedback. In a traditional sequential recommendation problem [12], [29], researchers mostly consider only a single type of behavior, ignoring the potential and importance of other behaviors, especially in instances where the utilized data for the target behavior is sparse. It indicates that it is necessary to model the users' multiple heterogeneous behaviors in the sequential recommendation problem. However, different from SBSR, the uncertainty of users' intention due to heterogeneous behaviors makes it more challenging to predict the user's preference in MBSR. Hence, it is a key and challenging issue to model heterogeneous behaviors well in sequential recommendations without information loss. • Relationship modeling between user behaviors. In the MBSR problem, multiple behaviors of users are often related to each other [26]. For example, in an e-commerce platform, users tend to examine an item, and check the reviews of the item before purchasing it, or purchase an item after examination and adding to cart other items of the same category. Different from MBR, which does not consider the sequential relationship of behaviors, MBSR takes the sequential nature of various behaviors into account. For example, MBR treats both cases the same for users who examine first and then purchase and for users who purchase and then examine, whereas MBSR considers the distinction between the two in modeling. According to the above issues mentioned, there are correlations and transitions among different behaviors within a user-item interaction sequence, which is a great challenge in modeling. • Joint long-term and short-term preference modeling with heterogeneous behaviors of users. Most of the traditional recommendation algorithms statically model the interaction information between users and items [30]- [32], which usually reveals users' long-term stable preferences. However, it ignores the dynamic changes of users' sequential behavior interacted with items. The dynamics of user preferences [33] indicate the user's current shortterm preferences, which can be revealed in the dynamically changing behavioral sequential information of the user. Since the user's interactive behavior information is a behavior sequence that naturally evolved over time, the sequential information can dynamically display the user's long-term stable preferences and short-term needs.

How to take the sequential information into account is the main challenge of SBSR. However, compared with SBSR, the behavioral heterogeneity of MBSR leads to an even greater challenge in modeling a user's long-term and short-term preferences simultaneously. • Related issues such as noise and bias. Some previous works regard unexamined behavior and missing behavior as implicit negative feedback of users, or simply ignore them [34]- [36]. Unexamination does not always represent a negative user preference [37], nor does an examination represent a positive user preference, where there may be mis-examinations. As for bias, since most current recommender systems tend to utilize the implicit feedback of users to make recommendation to users with the goal of more accurate item ranking, there may be a selection bias in implicit feedback data (e.g., a user may examine on an item simply because it is ranked highly). As such, the possible noise and bias in MBSR also deserve our attention.


## D. Categorization

The relevant methods applied to the MBSR problem can be classified into three categories at the technical level, including neighborhood-based methods, matrix factorization-based methods and deep learning-based methods, which are also the three major methods generally included in the field of recommender systems [2], [38]. For MBSR, with the continuous rise of artificial neural network and deep learning in various fields in recent years, and with the increasing complexity of information (i.e., the necessity to model heterogeneous behavior information and behavior sequential information simulta- neously), as well as for higher recommendation performance, the majority of the current works utilize deep learning-based methods for modeling, with fewer efforts on the other two branches. As a result, we will primarily pay attention to the deep learning-based methods for the MBSR problem in this paper.

For deep learning-based methods, we review the classic, the best and the latest works according to the neural network architectures they utilize, including RNN-based learning architecture, GNN-based learning architecture, Transformerbased learning architecture, generic-methods-based learning architecture and hybrid-methods-based learning architecture. We first introduce the basic paradigm of each type of neural network architecture, and then discuss the related works applied to the MBSR problem. In these works, the loss functions used generally contain pointwise-based loss function, such as logistic loss [39] and square loss [40] and pairwise-based loss function like BPR loss [5], as well as their combined or varied loss functions. In the second place, we classify the related works according to different data perspectives and modeling perspectives under each neural network architecture. Specifically, the data perspectives comprise four forms, namely a sequence of (item, behavior) pairs, some behavior-specific subsequences of items, a behavior-agnostic sequence of items and a sequence of behaviors; the modeling perspectives include both local and global approaches; and some of the MBSR works may integrate different data or modeling perspectives. As for related works with each neural network architecture, we discuss the strengths, weaknesses, features and some issues related to sequential heterogeneous information, such as considering more fine-grained information in modeling (e.g., item category), and taking into account how to address the noise and bias. We illustrate the above detailed categorization in Figure 2.


## III. NEIGHBORHOOD-BASED METHODS

The neighborhood-based method [41] is an early method in recommender systems, which is mainly divided into userbased collaborative filtering, item-based collaborative filtering and hybrid collaborative filtering. In the idea of user-based collaborative filtering, two users who have similar taste in the past may also have similar taste in the future, while in the idea of item-based collaborative filtering, users may purchase items similar to those purchased in the past. Hybrid collaborative filtering combines the ideas of the first two, and its prediction is a weighted combination of them. Regardless of the form of neighborhood-based methods, the main core concept of which is similarity. However, how to define the similarity is a matter of concern for MBSR.


## A. Basic Paradigm

In the case with implicit feedback data, the similarity between two items can be calculated using measures such as the Jaccard index and the cosine similarity. Taking item-based collaborative filtering with the Jaccard index as an example, the similarity of items k and j is calculated as follows:
s ii ′ = |U i ∩ U i ′ | |U i ∪ U i ′ |(1)
where U i and U i ′ denote the set of users who have interacted with item i and item i ′ , respectively. Based on the calculated similarity, we may select the top-K nearest item set N i ′ for each item i ′ , and then predict the score according to the following formula:
r ui ′ = i∈Iu∩N i ′ s ii ′(2)
As the predicted rating of an item increases, the possibility that the user will be interested in it increases accordingly. Although there is almost no work for MBSR using neighborhood-based methods, we will introduce BIS [12], a work toward the SBSR problem, to illustrate the idea of the use of similarity in sequential recommendation. It is expected to have some possibilities and inspirations to solve the MBSR problem.


## B. BIS

Bidirectional item similarity (BIS) designs a bidirectional item similarity to perform the next-item recommendation task. The bidirectional item similarity between items i and i ′ is defined as follows:
sim (ℓ,ρ) i ′ →i = u∈Ui∩U i ′ δ (−ρℓ ⩽ (t − t ′ ) ⩽ ℓ) |U i ∪ U i ′ |(3)
where ℓ and ρ are hyperparameters. In this equation, if the con-
dition −ρℓ ⩽ (t − t ′ ) ⩽ ℓ is satisfied, δ (−ρℓ ⩽ (t − t ′ ) ⩽ ℓ)
will be set to 1, so that the numerator will be added by 1 and the similarity between items i and i ′ will increase accordingly. It is worth noting that when ρ is equal to 1 and ℓ → ∞, the bidirectional item similarity degenerates to Jaccard index, i.e.,sim (∞,1)

i ′ →i = |Ui∩U i ′ | |Ui∪U i ′ | , which does not take into account any sequential information. When predicting the preference score, BIS only considers the bidirectional item similarities of the last k items that user u has interacted with.

Obviously, BIS and ABIS (adaptive BIS) [12], an improved version of BIS based on some factorization techniques, can be extended to the problem of multi-behavior sequential recommendation. For example, if we divide the input sequence into multiple behavior-specific subsequences, we can easily apply BIS and ABIS for each subsequence. These neighborhoodbased methods are easy to maintain and more interpretable, but they are less able to capture user preferences and lack transitivity, which means that two users will never be connected if they have not bought a common item. Moreover, ABIS only considers the closest neighboring items in modeling, ignoring users' long-term preferences and periodicity.


## IV. MATRIX FACTORIZATION-BASED METHODS

Although neighborhood-based methods may provide interpretability, their aforementioned disadvantages and lower efficiency make them less applicable to MBSR. To address the problem of non-transitivity, a method named matrix factorization has been proposed to connect users who have not purchased common items before [42], [43].


## A. Basic Paradigm

In recommender systems, the idea of matrix factorization is mainly reflected in transforming the (user, item) interaction matrix into the inner product of two low-rank matrices, i.e., a user-specific matrix and an item-specific matrix. Taking the rating matrix M ∈ R m×n formed by (user, item) interactions as an example, M is decomposed into a user matrix U ∈ R m×k and an item matrix V ∈ R n×k , so that each missing value (i.e., a predicted value)r ui in the rating matrix can be obtained by multiplying the user embedding U u and the item embedding V i :r
ui = U u · V ⊤ i (4)

## B. TransRec++

TransRec++ [44] introduces several behavior transition vectors to capture the sequential relationships between user behaviors and their dynamics, and takes into account some recent preceding items which can learn the weights automatically. The behavior transition vectors contain four types, i.e., from examination to examination e2e, from examination to purchase e2p, from purchase to examination p2e, and from purchase to purchase p2p, which we illustrate in Figure 3. In step ℓ, the overall translation vector of user u to the target item i t u is calculated by the following equation:
U (ℓ)i t u u = U u + U (ℓ)b(i t−ℓ u )2b(i t u ) u(5)
where b(·) denotes the behavior type. To achieve a transition of item i t−ℓ u to a future item i t u in step ℓ for a user's sequence, the formula can be calculated as follows:
V i t−ℓ u +Ũ (ℓ)i t u u ≈ V i t u , ℓ = 1, 2, . . . , L(6)
where V i t−ℓ u and V i t u are the embedding vectors of item i t−ℓ u and item i t u , respectively. The prediction formula is defined as follows:
r ui t u = p i t u − L ℓ=1 (η ℓ + η u ℓ ) || V i t−ℓ u +Ũ (ℓ)i t u u − V i t u ∥ 2 2 (7)
where p iu is an item bias, and η ℓ , η u ℓ denote a global weight and a user-specific weight, respectively.

As one of the few matrix factorization-based solutions towards the next-item recommendation in MBSR, TransRec++ combines the ideas of Fossil [45] and TransRec [46] to address behavioral heterogeneity well. The proposed behavior transition can also be utilized in other deep learning-based approaches to reach better performance, such as RIB [26] and BINN [22] that we will mention later. However, TransRec++ becomes more complex in modeling when there are more behavior types, and when it only contains two types of behaviors its time complexity is already five times that of the SBSR-oriented method TransRec. There may also be noise in the modeling of behavior transition, e.g., e2e may be caused by user mis-examination.

In summary, as a conventional approach, the matrix factorization-based recommendation algorithm owns several benefits, including high interpretability and computational efficiency. These algorithms employ a linear model, which possesses a straightforward structure, and a clear association between the modeling concept and the problem under consideration, leading to a higher degree of interpretability. The algorithms are computationally efficient as the model has few parameters, and typically, only matrix multiplication operations are necessary for computation. However, matrix factorizationbased recommendation algorithms face challenges in handling non-linear features like sequence information and higher-order neighborhood information.


## V. DEEP LEARNING-BASED METHODS

Due to the insignificant improvement in recommendation effectiveness of matrix factorization-based methods, researchers have turned to studying deep learning-based algorithms. Deep learning [47], [48] is an improvement on the traditional neural network, and a multi-layer perceptron (MLP) with multiple hidden layers is a typical deep learning architecture. Deep learning has made substantial progress in a variety of application areas, including natural language processing and generation [49], [50], speech recognition and synthesis [51], as well as computer vision [52], [53]. Recently, deep learning has gained increasing usage in recommender systems, demonstrating high recommendation performance in multi-behavior recommendation [54], [55], sequential recommendation [13], [29] and federated recommendation [56], [57]. In this section, we mainly discuss the application and the corresponding works of deep learning in MBSR in terms of different neural network architectures (i.e., RNN, GNN, Transformer, generic methods and hybrid methods). We will present how different works model sequentiality and heterogeneity in MBSR, and examine whether these works address some other specific challenges. Additionally, we will distinguish between the different applications of these works such as next-item, nextbasket and session-based recommendation, and discuss their features, strengths, and weaknesses. This will help to establish a better understanding of the use of deep learning techniques in MBSR.

A. RNN-based Learning Architecture 1) Basic Paradigm: Recurrent neural network (RNN) [58] is a classical deep learning method that can effectively process data with sequentiality. Currently, RNN has been applied to numerous fields, including information retrieval, speech recognition, machine translation and so on. Since RNN can take into account the characteristics of sequences, they have also been utilized to solve the SBSR problems and MBSR problems in the early works [14], [26], [29]. RNN contains multiple RNN cells, with its basic structure illustrated in Figure 4. In the RNN learning architecture, the current time step receives the output of the previous time step as the input, and the output obtained from the RNN cell will be used as the input of the next time step, so as to capture the sequential nature of the data. Each cell of RNN is a layer of deep feedforward neural network, and a set of learning parameters will be shared across different time steps to capture sequential features and reduce the model complexity. The basic formula of RNN is as follows:
h t = σ (W xh x t + W hh h t−1 + b h ) (8) y t = σ (W ho h t + b o )(9)
where W xh ∈ R d×d , W hh ∈ R d×d and W ho ∈ R d×d are the corresponding weight matrices, and b h and b o are the corresponding bias vectors. However, there is a certain challenge in the training process of RNN, that is, as the depth deepens, RNN has the problem of gradient disappearance or gradient explosion, and thus is prone to the difficulty in dealing with the long-term dependency of data [59]. To address this issue, many derivative methods based on RNN have been proposed, among which the most wellknown ones are long short-term memory (LSTM) [60] and gated recurrent unit (GRU) [61], a simplified version of LSTM. Both LSTM and GRU set up a hidden unit in the hidden layer to store long-term features, which enables to address the issue of modeling long-term data dependency.

2) Methods in MBSR: There are some research works on RNN-based neural network architectures for solving MBSR problems, which differ in terms of the perspective of the input sequences and the perspective of modeling the behavior types. Specifically, from the data perspective, most of the works have an input sequence of (item, behavior) pairs, such as RLBL [14], RIB [26], BINN [22], HUP [27], IARS [28] and 


## Works

Data Perspective Model Perspective Features RLBL [14] A sequence of (item, behavior) pairs Local Capture the influence of heterogeneous behaviors by utilizing a behavior transition matrix. RIB [26] A sequence of (item, behavior) pairs Local Leverage GRU and attention mechanism simultaneously.

BINN [22] A sequence of (item, behavior) pairs Local Design the CLSTM and the Bi-CLSTM, where the behavior vector is as context in LSTM. CBS [63] Some behavior-specific subsequences of items Local Design of models with and without shared parameters for behaviors simultaneously; towards the next-basket recommendation. DIPN [64] Some behavior-specific subsequences of items Local Leverage GRU and attention mechanism simultaneously; behaviors are specific, including swipe, touch and browse interactive behavior. HUP [27] A sequence of (item, behavior) pairs


## Local

Design the Behavior-LSTM where adds behavior gate and time gate to the LSTM; leverage attention mechanism; take into account the category of the items. IARS [28] A sequence of (item, behavior) pairs Local Propose Soft-MGRU (a multi-behavior gated recurrent unit) with sharing parameters between behaviors; leverage attention mechanism; take into account the category of the items. DeepRec [62] Some behavior-specific subsequences of items Local + Global Utilizing multi-behavior sequence data to make privacy-preserving recommendation. MBN [65] Some behavior-specific subsequences of items


## Local

The overall Meta-RNN and the separate Behavior-RNN share the learned potential representations by gathering and then scattering; towards the next-basket recommendation.

DeepRec [62]. In contrast, other works have some behaviorspecific subsequences of items, such as CBS [63], DIPN [64] and MBN [65]. From the modeling perspective, DeepRec models a user's behavior types in the cloud from a global perspective and in the user's own client from a local perspective, while other works mentioned above utilize a local perspective only to model the behavior types. We distinguish and summarize these works in Table II and describe some of them in detail as shown below.

RLBL. The recurrent log-bilinear model (RLBL) [14] illustrated in Figure 5 is the first work oriented towards nextitem recommendation. RLBL integrates the ideas of RNN and log-bilinear (LBL) to address the challenge of long-term and short-term preference modeling. Specifically, RLBL uses behavior-specific transition matrices to distinguish between heterogeneous behaviors in a user's historical interaction sequence, and splits the sequence into multiple windows. Then RLBL captures the short-term contextual information for each window by LBL, and finally integrates these features at the granularity of the window by RNN to construct the user's long-term contextual information.

In RLBL, each window contains a sequence of (item, behavior) pairs of length n, i.e., 
{(i t−n+1 u , f t−n+1 u ), ..., (i t u , f t u ) }. In the pair i t−i u , f t−i u of the sequence, RLBL uses an item embedding V i t−i u ∈ R d×1h t+1 = W RLBL h t−n+1 + n−1 i=0 C i M f t−i u V i t−i u(10)
where W RLBL ∈ R d×d is utilized to capture the sequential information between the hidden state h t+1 ∈ R d×1 and the hidden state h t−n+1 ∈ R d×1 . And then the predicted preference that user u generates behavior f on item i at the (t + 1)th time step is calculated as follows:
r t+1,i,f = (h t+1 + U u ) T M f V i(11)
where U u ∈ R d×1 is the user embedding, and h t+1 ∈ R d×1 is the representation incorporating the long-term and short-term preferences of user u.

RLBL and its extended version TA-RLBL [14], which considers continuous time differences, can model the longterm and short-term context information for data well with the consideration of the sequential and heterogeneous nature of user behaviors. However, the modeling of user behavior is relatively straightforward, and there are some important issues that are overlooked. For example, the transition matrix is the same for all users, and it does not take into account the feature information of the items.

RIB. An interpretable recommendation framework from the micro behavior perspective (RIB) [26], another classic work towards next-item recommendation, models heterogeneous behaviors and dwell time to capture more fine-grained user information by GRU. Specifically, RIB takes a sequence of (item, behavior) pairs as input, taking items and behaviors encoded as item embeddings and behavior embeddings via an embedding layer, respectively. Then the embedding e t ∈ R 2d×1 is obtained by concatenating the above two embeddings and fed into a GRU layer to obtain the hidden state at each time step. The calculation equations of the reset gate r t ∈ R d×1 , the update gate z t ∈ R d×1 , the internal state c t ∈ R d×1 and the external state h t ∈ R d×1 at the tth time step in GRU are shown below:
r t = σ (W er e t + W hr h t−1 ) (12) z t = σ (W ez e t + W hz h t−1 ) (13) c t = tanh (W ec e t + W hc (r t · h t−1 )) (14) h t = (1 − z t ) h t−1 + z t c t(15)
where W er , W ez , W ec ∈ R d×2d , and W hr , W hz , W hc ∈ R d×d are the learnable weight parameters inside GRU. Then the hidden state is passed into an attention layer to get the attention score for each time step. Finally, in the output layer, the hidden states of each time step are multiplied with the corresponding attention scores, where the results are added to obtain a latent representation for predicting the user's preference value for an item. Similar to RLBL, RIB introduces different behavioral information into the input side of the RNN (in this case GRU), but the difference is that RIB uses an embedding matrix to represent multiple behavioral information, where each behavior corresponds to an embedding vector. RIB also uses an attention layer to capture the importance of different behaviors, and in the original paper, modeling of dwell time was also considered. Nevertheless, RIB may not capture real user behavior information since it uses an embedding matrix to represent behavior types and then concatenates them directly with the item embedding.

BINN. Behavior-intensive neural network (BINN) [22], based on LSTM, models users' long-term and short-term preferences to improve the next-item recommendation performance. BINN takes a sequence of (item, behavior) pairs as input and models each sequence from a local perspective. BINN contains two modules, session behaviors learning (SBL) to model a user's current consumption motivation and preference behaviors learning (PBL) to learn the user's historical stable preference. In SBL, a context-aware LSTM (CLSTM) incorporating the behavioral information as input is built, whose input gate i t , forgetting gate f t , output gate o t , internal state c t and external state h t at the tth time step are as follows:
i t = σ(W vi V i t u + W hi h t−1 + W ci c t−1 + W bi F f t u + b i ) (16) f t = σ(W vf V i t u + W hf h t−1 + W cf c t−1 + W bf F f t u + b f ) (17) c t = f t c t−1 + i t tanh(W vc V i t u + W hc h t−1 + W bc F f t u + b c ) (18) o t = σ(W vo V i t u + W ho h t−1 + W mathrmco c t + W bo F f t u + b o ) (19) h t = o t tanh(c t )(20)
where W (·) ∈ R d×d are the internal model parameters of the LSTM. Then the output h t at the last time step t can be served as the user's current consumption motivation representation h SBL . In PBL, BINN adopts a bidirectional CLSTM (Bi-CLSTM) which considers both forward and backward input sequences to obtain the long-term preference representation h PBL . By concatenating h SBL with h PBL , the obtained representation is utilized to make predictions and generate recommended items. BINN proposes a novel gating structure, consisting of Bi-CLSTM and CLSTM, which enables the memorization of multi-behavior information in sequences. In contrast to RLBL and RIB in how to introduce multi-behavior information, BINN modifies the internal structure of the LSTM by feeding behavior embedding matrix into the Bi-CLSTM and CLSTM to make it suitable for multi-behavior sequences. However, the limitations of BINN are similar to those of RIB, as both represent multiple types of user behavior directly in embedding matrix, which might make it challenging to capture real user behavioral information.

IARS. Intention-aware recommender system (IARS) [28] is also a work that incorporates the item category to perform the next-item recommendation task. IARS consists of four blocks in total, which are an RNN-based encoder for perceiving user intent, and three decoders, i.e., a judgment or prediction task based on user intent, so as to learn the complex and coexisting intent of the user. Specifically, the encoder takes a sequence of (item, behavior, category) tuples as input, adopts a local modeling perspective, processes the behavior types through multiple multi-behavior GRU units (MGRUs) to capture multiple intentions of the user. Note that we only discuss Soft-MGRU, one type of MGRU, for its lower spatial complexity and better performance by sharing the same set of parameters between different behaviors. After an embedding layer, the item embedding, category embedding and behavior embedding are fed into Soft-MGRU to obtain the hidden state h t at the time step t.

Soft-MGRU encodes the dependencies of items in multibehavior sequences and obtains hidden states that characterize user intentions. It takes into account item categories and utilizes an attention network to capture the user's purchase intention for candidate items. The introduction of multi-behavior information is also achieved through the GRU's input which concatenates the embeddings of behavior, item, and category. However, the behavior embedding only participates in the computation of the reset gate and update gate, which may not be sufficient to represent the complete behavior information of the user.

MBN. Multi-behavior network (MBN) [65] models multibehavior sequences towards the next-basket recommendation problem. The MBN architecture is composed of three modules, i.e., basket encoder, meta multi-behavior sequence encoder and recurring-item-aware predictor. Specifically, the basket encoder converts the item representation e v to the basket representation of the items E f u,t by a max pooling method. In the meta multi-behavior sequence encoder, multiple behaviorspecific subsequences of items are taken as input and go through Behavior-RNN layers to learn behavior-specific information, which is local in the perspective of modeling. In addition to the Behavior-RNN layers, this work also proposes a Meta-RNN layer to learn the collective knowledge of multibehavior sequences. Then a gathering-scattering scheme is utilized to correlate the Meta-RNN layer and the Behavior-RNN layer. The representations learned by the Behavior-RNN layers are gathered to the Meta-RNN layer to learn the collective knowledge of multi-behavior sequences, and then the representations learned by the Meta-RNN layer are scattered to the individual Behavior-RNN layer to calibrate behavioral modeling. In the recurring-item-aware predictor, a mixed probabilistic function in the generate mode and the repeat mode is proposed to predict the probability of each item in the next basket, which can simulate the distribution of items with biased repetition.

MBN introduces a method of gathering and then scattering to fuse and assign the learned multi-behavior information to different Behavior-RNNs layers at the Meta RNN layer, which is a more explicit way to model intra-behavioral and inter-behavioral sequence information. In addition, any type of user's behavior can be treated as the target behavior. Nonetheless, as the number of behavior types increases, the number of behavioral RNN layers and associated parameters also increases, resulting in heightened computational complexity. Moreover, the division of the item basket in MBN is based on the time span, which may not align with the real-world scenario of purchasing a basket of items at the same time.

In addition to the above works, several efforts employ RNN-based learning architecture to model the sequentiality and heterogeneity of user behaviors. CBS [63] models longer sequences rather than short-term dependencies for the nextbasket recommendation problem with the use of a LSTM with or without shared parameters for each of the two behaviors (or the representation obtained from the embedding layer directly for the target behavior sequence). DIPN [64] employs a GRU and a hierarchical attention mechanism to effectively capture heterogeneous user behaviors and utilizes a multi-task module to capture short-term and long-term purchase preferences. HUP utilizes the attention mechanism, and designs LSTMs with the addition of behavior gate and time gate at the micro-, item-, and category-levels to capture different granularities of information from session-based recommendation. In terms of federated recommendation, DeepRec [62] applies GRU on the historical interaction data of all users on the cloud, and is then pushed to users' devices, which makes it possible to fine-tune it for the individuals to obtain a personal recommendation model for each of them.

In summary, the RNN-based learning architecture is suitable for sequence problems and can store short-term memories, but suffers from gradient disappearance and gradient explosion problems. In addition, RNN is inefficient and has difficulty in predicting information about future sequences since the output of the current moment depends on the computation and the output of the previous moment. At present, the industry has rarely leveraged RNN-based learning architecture for recommendation.


## B. GNN-based Learning Architecture

Graph neural network (GNN) [66], [67], utilized to extract features, is a widespread technique in recent years, and there have been many excellent graph neural network models, including GCN [68], GraphSAGE [69], GAT [70] and so on. It can fully exploit the higher-order neighbor information of nodes and performs well on recommender systems.

1) Basic Paradigm: In general, graph neural network models use graph convolution to allow nodes to obtain information about their neighbors. To make the procedure more specific, an example is shown in Figure 6, which depicts four nodes, labeled as node 1, node 2, node 3, and node 4. Node 1's firstorder neighbors are node 2 and node 3. During the first-order graph convolution, the embeddings of node 2 and node 3 are aggregated into the embedding of node 1. In the second-order graph convolution, node 3 is a neighbor of node 4. Since node 3 has already obtained information about node 4 in the firstorder graph convolution, node 1 is able to obtain information about its second-order neighbor, node 4, during the secondorder graph convolution. This allows the graph convolution network to effectively utilize information from higher-order neighbors of nodes. 2) Methods in MBSR: In MBSR, there are lots of works achieving great recommendation performance based on GNN, such as MGNN-SPred [24], DMBGN [71], GPG4HSR [72], BGNN [73] and BA-GNN [74]. We describe some of them in detail below, and summarize the data perspective, the modeling perspective and the characteristics of these works in Table III. MGNN-SPred. Multi-relational graph neural network model for session-based target behavior prediction (MGNN-SPred) [24] also utilizes GNN to model multi-behavior sequences in session-based recommendation scenarios from a global modeling perspective. Firstly, MGNN-SPred treats the multi-behavior sequences S p and S e as some sequences of behavior-specific items, and constructs a global graph from all the training sequences, where the nodes represent items, and the edges have two attributes, namely, purchase edges and examination edges. For example, the purchase edge of item a and item b means a user purchases item a and then purchases item b. For each node v, we can obtain four types of neighbor node subsets, i.e., N p+ (v), N e+ (v), N p− (v) and N e+ (v). For example, N e+ (v) and N e− (v) denote the incoming edges and outgoing edges of the node which is treated as an examined item, respectively. We give the concrete forms of the neighbor node subsets of the node v as follows:
N p+ (v) = {v ′ | (v ′ → v, purchase) ∈ E} (21) N e+ (v) = {v ′ | (v ′ → v, examination) ∈ E} (22) N p− (v) = {v ′ | (v → v ′ , purchase) ∈ E} (23) N e− (v) = {v ′ | (v → v ′ , examination) ∈ E}(24)
where E denotes the edge set. Secondly, for a target item v, the k-level aggregated representations of four different neighbors (taking N p+ (v) as an example) and the node representation h k v obtained from the final iteration can be calculated as follows:
h k p+,v = v ′ ∈Np+(v) h k−1 v ′ |N p+ (v)|(25)h k v = h k−1 v + h k p+,v + h k e+,v + h k p−,v + h k e−,v(26)
where h k v ∈ R d×1 and h K v ∈ R d×1 denote the k-th step and the last step of the item v representation in GNN, respectively. And h K v is used as the corresponding item potential representation. Thirdly, it treats the multi-behavior sequences as some sequences of behavior-specific items and obtains the user's examination preference and purchase preference by aggregating all item potential representations of the examination sequence and the purchase sequence, respectively. The final preference representation is obtained after feeding the above two preferences to the fully connected layer and the gated network.

MGNN-SPred is a simple but effective method for GNN to be directly applied to MBSR. By constructing a graph, the sequential occurrence relationships of different behaviors are reflected in the graph, allowing aggregation between different behaviors and enhancing their information capability. Additionally, the MGNN-SPred approach, which first models distinct behavioral sequences individually before passing through the gated neural network, effectively captures both intrabehavioral and inter-behavioral information, ensuring a wellbalanced information representation. Due to these advantages of MGNN-SPred, some of the subsequent works for MBSR are based on MGNN-SPred with some improvements [73]- [75]. For example, the improvement of BA-GNN [74] over MGNN-SPred is that BA-GNN constructs separate graphs for different behavior sequences, and utilizes a gated graph neural network (GG-NNs) [76] and a sparse self-attention mechanism to address the noise effect in the examination sequence, thus better capturing the information in multi-behavior sequences.

DMBGN. Deep multi-behavior graph networks (DM-BGN) [71] focuses on the task of voucher redemption rate prediction in the session-based recommendation scenario. It utilizes GNN to model users' long-term voucher redemption preferences from a global perspective.

Firstly, it treats the multi-behavior sequences S atc and S ord as some sequences of behavior-specific items, and divides them into four parts, i.e., S + atc , S − atc , S + ord and S − ord . For example, the sequence S + atc means that the behaviors of addto-cart happen before the behavior on the voucher, while the sequence S − atc means that the behaviors of add-to-cart happen after the behavior on the voucher. S + atc , S − atc , S + ord and S − ord are connected to the central voucher node by the closest items from the temporal perspective. We obtain four sub-graphs in the end, i.e., atc + , atc − , ord + and ord − . Secondly, the four sub-graphs constructed above are fed into GNN with the Weisfeiler-Leman algorithm [77], separately. The representations of the four sequences S + atc , S − atc , S + ord and S − ord are concatenated and sent to a multilayer perceptron (MLP) function. Then the final UVG embedding is generated by concatenating the output of the MLP function and the embedding of the central voucher node, and the score for the historical UVG is obtained by the dot-product between the two representations. Finally, the representation of the embedding calculated from the target UVG component is enhanced via an attention network.. GNN can model the relationship between multiple behaviors and vouchers effectively. In building the graph, it is also reasonable that the coupon node is only connected to nodes of other behaviors that are temporally close, which improves the relationship between temporally close nodes and the coupon. Furthermore, DMBGN incorporates all historical sequences into the GNN network, thus proficiently capturing users' long-term preferences. The output of these past sequences is subjected to attention, together with the output of the current sequence, effectively enhancing the information representation of the current sequence.  GPG4HSR. Global and personalized graphs for heterogeneous sequential recommendation (GPG4HSR) [72] simultaneously considers the transition relationships between different behaviors and local contextual information, thereby improving the next-item recommendation performance, which we illustrate in Figure 7. GPG4SHR focuses on two types of behaviors, i.e., examinations and purchases, and takes a sequence of (item, behavior) pairs as input to model all sequences and each sequence from a global and local perspective, respectively. Specifically, GPG4HSR first feeds the input into an embedding layer to obtain the item embedding v i t , the behavior embedding F f t and the position embedding p t of the item i t interacted by the behavior type f t at the time step t. Then the embeddings are introduced to a global graph layer and a personalization layer to capture the transition patterns between behaviors and users' intent considering adjacent contextual information, respectively. In the global graph layer, the input is the global node v i t of each item of a sequence (abbreviated as v) and all the edges linked to it in the global graph, where there are six edge types to distinguish specific behavioral transitions, (i.e., e2e, p2p, e2p+, e2p−, p2e+ and p2e−) that considers the transition directions (inward or outward) between different behaviors on top of TransRec++. The corresponding neighbor node subsets are N e2e
(v), N p2p (v), N e2p+ (v), N e2p− (v), N p2e+ (v) and N p2e− (v).
The final generated neighbor group and behavior transition-specific representation are as follows (take e2p+ as an example):
N e2p+ (v) = {(v ′ , freq) | (v ′ → v, freq, e2p+) ∈ E g } (27) h e2p+ v = (v ′ ,freq)∈Ne2p+(v) freq × v v ′ (v ′ ,freq)∈Ne2p+(v) freq(28)
where v v ′ is a concise representation of the node v ′ linked to the node v, freq ∈ R represents the frequency of the corresponding edge. Then the global graph representation h g v of the node v can be represented as the sum of the node representation with the weighted representation of all behavior transition representations.

In the personalization graph layer, the input contains the item embedding and the behavior embedding of the node v, i.e., (v v + F v ), as well as the inward and outward attributes of node-connected edges, which can learn the importance of different behaviors and the adjacent context information, thereby capturing users' intent. The final graph representation h v of the node v obtained by fusing the global graph representation h g v and the personalized graph representation h u v :
h u v = v v + F v + h + v + h − v (29) h v = γ u h g v + (1 − γ u ) h u v (30) where γ u = σ (W gp [h g v ; h u v ]).
The final graph representation of the sequence h u can be obtained by concatenating the graph representation of the corresponding nodes of the sequence, and then passed into a dropout layer and stacked self-attention blocks same as SASRec [78] together with the corresponding position embedding. The obtained representation is concatenated with the target behavior vector and fed into a softmax function to obtain the user's predicted preference value for the items.

GPG4HSR constructs both a global graph and a personalized graph, where the global graph is used to capture the relationships among heterogeneous behaviors, and the personalized graph is used to enhance the contextual representation of a single user's multi-behavior sequence for a better comprehension of the user's preferences. In addition, the graph construction with the time complexity O(|R|), where R denotes the set of the user-item interaction, making it more efficient. Nevertheless, as the number of behavior types increases, the number of behavior transfer relationship types also increases, which increases the complexity of graph construction. Moreover, the multi-order behavior transition relationships, which typically optimize performance, can pose challenges in modeling.

BGNN. Behavior-aware graph neural network (BGNN) [73] distinguishes between two different behavioral sequences by utilizing a dual-channel learning strategy for the session-based recommendation. BGNN takes an examination sequence and a purchase sequence as input, and models the heterogeneous behavior transitions to obtain the semantic connections between diverse behaviors by two global graphs, i.e., homogeneous behavior transition graph (HoBTG) and heterogeneous behavior transition graph (HeBTG), so as to improve the recommendation performance.

Specifically, BGNN sends the examination sequence and the purchase sequence into the auxiliary channel and the target channel, respectively. In the target channel, the item representation is learned in the purchase sequence through HoBTG, which is basically equivalent to the modeling of the behavior transition relationship of MGNN-SPred. The auxiliary channel consists of three modules to learn the item presentation of the examination sequence. The first module directly uses homogeneous behavior transition in the target channel to obtain potential representation; the second module adaptively adjusts the contributions of different neighbors of nodes through an attention mechanism to learn the purchaseoriented item representation; and the third module is for representation aggregation, which is the representation of items obtained by balancing the above two modules by gathering. After obtaining the item presentation matrices of the examination sequence and the purchase sequence, the matrices are sent to an attention network separately and then fused together. Finally, the user's preference value for the item is obtained through a prediction layer.

BGNN constructs graphs that explicitly capture two behavior transition patterns of homogeneous and heterogeneous ones, and utilizes these graphs in the auxiliary behavior to capture the contribution of the auxiliary behavior to the target behavior, thereby improving the user's next preferred item prediction under the target behavior, though its training time is about 1.4 times of that of MGNN-SPred. However, BGNN encounters difficulties in the setting of more behavior types, that is, the transition relationships between behaviors become more complex with an increase in the number of behavior types, and additional graphs may also need to be constructed, thus increasing the complexity of the algorithm.

In summary, by constructing the user-item graph, GNN can be easily applied to the recommendation system methods. For each graph node, the aggregation of neighbors' information allows each behavior to obtain information about other behaviors that occurred close in time. The recommendation performance is obviously enhanced by the information enhancement of the neighbor nodes. In comparison to RNN, GNN has the ability to model more complex relationships within multi-behavior sequences, and possesses stronger capabilities to handle data sparsity.


## C. Transformer-based Learning Architecture

The Transformer model [79], a deep learning architecture that utilizes a self-attention network to reduce the computational complexity and thus enhance the training speed, has gained wide recognition in recent years for its superior performance in sequence-to-sequence modeling. This model has been utilized in a wide range of research areas, including natural language processing [80], [81], computer vision [82], [83], and recommender systems [23], [84], [85].

1) Basic Paradigm: The basic architecture of the Transformer model is depicted in Figure 8. It consists of two modules: the encoders and the decoders. In this discussion, we will focus on the encoders. The most crucial component within the encoder is the multi-head self-attention component. This component comprises several self-attention subcomponents, which are widely used in recommendation models. We will 
Q i = Em(S e )W Q i , K i = Em(S e )W K i , V i = Em(S e )W V i (31) head i = softmax Q ⊤ i K i √ d t V i (32) F e = concatenate (head 1 , · · · , head h ) W O (33) where Em(S e ) ∈ R ne×d , W Q i ∈ R d×dt , W K i ∈ R d×dt , W V
i ∈ R d×dt and W O ∈ R hdt×d are the projection matrices. n e is the length of the sequence S e , d t is the dimension of K i , and F e is the output of the self-attention component.

2) Methods in MBSR: In MBSR, there are some works obtaining great recommendation performance based on Transformer, including DMT [23], DFN [84], FeedRec [25], Nex-tIP [86], MB-STR [87], DUMN [88] and FLAG [85]. We describe some of them in detail below, and summarize the data perspective, the modeling perspective and characteristics of these works in Table IV. DMT. Deep Multifaceted Transformers (DMT) [23] utilizes a multi-gate mixture-of-experts (MMoE) approach, a multi-task learning technique, to enhance the performance of both click-through rate (CTR) and click value rate (CVR) predictions. Furthermore, it employs the Transformer model to analyze multi-behavior sequences from a local modeling perspective. The architecture of DMT is depicted in Figure9. Firstly, it treats the multi-behavior sequences as some sequences of behavior-specific items and inputs those into the encoder of Transformer. Take the examination sequence as an example, and the formula is as follows:
F e = Encoder (PE (Em(S e )))(34)E e = Decoder(F e , PE(V target i ))(35)
where PE(·) is the positional encoding function, and it explicitly represents the sinusoidal positional embedding or the learned positional embedding [78], [79] in DMT. V target i is the embedding of the item to be predicted and one of the inputs for the decoder of Transformer. Secondly, E e , E a and E o are concatenated and flattened with the normalized dense features gathered from the recommender system and the target 


## Works

Data Perspective Model Perspective Features DMT [23] Some behavior-specific subsequences of items Local + Global Use target item as query; Consider implicit feedback bias by a bias deep neural network. DFN [84] Some behavior-specific subsequences of items Local + Global Use target item as query; Consider implicit negative feedback noise by an attention network . DUMN [88] Some behavior-specific subsequences of items Local Consider implicit feedback noise; Use memory network to obtain the long-term user preference. FeedRec [25] Some behavior-specific subsequences of items and a sequence of (item, behavior) pairs Local + Global Consider implicit feedback noise by an attention network; Consider multiple patterns of the multi-behavior sequences.

NextIP [86] Some behavior-specific subsequences of items and a sequence of (item, behavior) pairs Local + Global Treat the problem as the item prediction task and the purchase prediction task; Consider multiple patterns of the multibehavior sequences. MB-STR [87] A sequence of (item, behavior) pairs


## Local

A novel positional encoding function to model multi-behavior sequence relationships. FLAG [85] A behavior-agnostic sequence of items and a sequence of behaviors Local + Global Model user's local preference, local intention and global preference simultaneously. item embedding V target i . Thirdly, the multi-task training model MMoE is used to improve the performance of both CTR and CVR prediction. In particular, DMT considers bias in implicit feedback, such as position and neighboring bias, and utilizes a deep neural network with the ReLU function.

DMT uses a Transformer with unshared parameters to capture the relationships within each behavior and subsequently feeds the different behavioral features into the MMoE module, lacking the explicit modeling of the relationships between the different behaviors. A bias deep neural network is proposed for modeling implicit feedback bias, which is a good modeling solution.

DFN. Deep feedback network (DFN) [84], another work for CTR prediction in ads, models multi-behavior sequences utilizing Transformer from a local modeling perspective and three modules commonly used in industry, i.e., a wide component, an FM component, and a deep component.

We can draw a comparison between DFN and DMT [23]. Firstly, like DMT, DFN employs a Transformer architecture with unshared parameters to capture the relationships within each behavior. It treats multi-behavior sequences as a series of behavior-specific items and inputs them into a multi-head selfattention mechanism. Secondly, DFN also takes into account the implicit feedback noise. Unlike DMT, DFN leverages the attention mechanism to explore the relationship between different behaviors, which can be advantageous. Noting that the implicit negative feedback, i.e., the unexamination sequence S n , is abundant in real life but contains noise. As such, DFN uses implicit positive feedback f e and explicit negative feedback f d to denoise the implicit negative feedback by an attention network. The formula is as follows:
f ne = attention(Em(S n ), f e )(36)f nd = attention(Em(S n ), f d )(37)
where f e ∈ R 1×d and f d ∈ R 1×d are the keys, and f ne ∈ R 1×d and f nd ∈ R 1×d are the outputs of the two attention networks, respectively. Finally, f e , f d , f n , f nc and f nd are concatenated and fed in the three modules commonly used in industry mentioned above with other features, i.e., item features, user profiles, and recommendation contexts. In addition to DFN, two other works also denoise the implicit feedback by an attention network with the help of the explicit feedback, the first of which, DUMN [88], also utilizes a memory network for modeling users' long-term preferences to perform the CTR prediction task, while the second work FeedRec [25], a work focusing on news recommendation, uses Transformers with shared and unshared parameters to perform user modeling.

NextIP. A dual-task learning approach towards the item prediction task and purchase prediction task (NextIP) [86] utilizes the self-attention mechanism to model multi-behavior sequences from a local modeling perspective and performs the next-item recommendation task. Unlike other methods, NextIP simultaneously treats the multi-behavior sequences as some sequences of behavior-specific items and a sequence of (item, behavior) pairs. Specifically, NextIP treats the multi-behavior sequential recommendation problem as two tasks, i.e., the item prediction task and the purchase prediction task.

In the item prediction task, the embeddings of behaviorspecific and behavior-aware item sequencesare entered into the self-attention block (SAB). Subsequently, NextIP proposes the target-behavior-aware context aggregator (TBCG) to fully model the interplay of different behaviors at different times. Specifically, TBCG takes the representations of the most recent interaction for behavior-specific subsequences as keys and values, takes the user's target behavior embedding as a query, and inputs those into the attention module and mean pooling function with the target behavior representations from the behavior-specific subsequence representations. Finally, the item prediction result is calculated by the inner product between the target item embedding and the representation added by the output of TBCG and the most recent interaction representation of the behavior-aware sequences.

In the purchase prediction task, the user's behavior sequence embeddings are input into the behavior-aware self-attention block, masked depending on user behavior types and behavior distance. Each auxiliary behavior representation from the output of the behavior-aware self-attention block is treated as negative samples to model the user purchase preference.

In summary, NextIP proposes a new perspective on this multi-behavior sequential recommendation problem, by framing it as both an item prediction and a purchase prediction task. This new perspective offers a fresh outlook on the issue at hand, allowing for more accurate and efficient solutions. Moreover, NextIP considers multiple input patterns of the multi-behavior sequences and uses the self-attention network to model multi-behavior sequences with good performance. The contrastive loss function used to train the model also contributes to recommendation performance.

MB-STR. Multi-behavior sequential Transformer recommender (MB-STR) [87] utilizes Transformer to model multibehavior sequences from both global and local modeling perspectives, to address the next-item recommendation problem. MB-STR treats the multi-behavior sequence as a sequence of (item, behavior) pairs and feeds it into the multi-head self-attention network, which considers the sequential pattern and distinguishes it based on the types of behavior. Then a parameter-shared network like MMoE is used to model the behavior-specific information, denoted as a Behavior Aware Prediction (BA-Pred) module. BA-Pred includes two parts, i.e., the parameters-shared experts and the behavior-specific experts, where the latter are shared for the representations of the same behavior.

In summary, MB-STR employs a range of behavior-specific parameters to represent diverse behavioral sequences at a fine-grained level. This approach enables effective modeling of the distinctiveness and interdependence among various behaviors, rendering it a robust tool for behavior modeling. Meanwhile, the total number of parameters in MB-STR is O(|V|d+|B|d 2 +n), and its time complexity is O(n 2 d+nd 2 ), which is moderate compared to other works. Moreover, unlike the positional encoding function of the classical Transformer, MB-STR is inspired by T5 [89] in natural language processing and uses a novel positional encoding function to model multibehavior sequence relationships, which can better capture their positional relationships.

FLAG. Feedback-aware local and global (FLAG) [85] takes into account both user intent and preference complexity in modeling multi-behavior sequences for next-item recommendation. It takes a behavior-agnostic sequence of items and a sequence of behaviors as input, and employs both the global and local modeling perspectives. FLAG has four parts, including a local preference modeling, a global preference modeling, a local intention modeling and a prediction module.

In the local preference modeling, the input matrix X (0) u , composed of the element-wise additions of the item embedding and the position embedding, is fed into the multiple stacked feedback-aware self-attention blocks (FSABs), and then obtains a user's local preference z lp t at time step t from the top FSAB. Specifically, an FSAB successively goes through a feedback-aware input layer with a mask mechanism, a self-attention layer and a feed-forward layer. In the global preference modeling, the authors use a location-based attention layer to model users' global preferences z gp . Given that the preferences of users, both local and global, cannot be effectively modeled through local preference modeling and global preference modeling alone, a feedback-based attention layer (FAL) is proposed for local intention modeling. It receives an input matrix O that takes into account both the examinationspecific and purchase-specific embedding matrices:
o t u = V i t u + p ′ t + F f t u (38) O = o 1 u ; . . . ; o l u ; . . . ; o T u(39)
where V i t u ∈ R 1×d , p ′ t ∈ R 1×d and F f t u ∈ R 1×d are the itemspecific embedding vector, the position-specific embedding vector and the behavior-specific embedding vector f t u of the item i t u at time step t, respectively. And the next behavior F f t+1 u is treated as a query vector to uncover the user's local intention in the following time step, so as to obtain the final local intention feature z li t . Then an item similarity gating (ISG) module is proposed to achieve a balance between the local and global preferences with a weight factor λ, and then the obtained balanced preference representation z lgp t and the local intention feature z li t are element-wise added to get the final representation z t of the sequence at time step t.

FLAG models the user's local preference, global preference and local intention with acceptable time complexity and space complexity, where the multiple behaviors is utilized as a mask matrix in the local preference learning module, and as part of the input to the module through behavior embedding for better distinguishing the user's different behaviors and consequently improve preference modeling. However, in the local intention learning module, FLAG uses the next real feedback as the query vector during training, which may have a data bias that allows the model to overfitting the historical behavioral data. Furthermore, this approach may not perform well in cold-start settings where there is little historical interaction data.

In summary, Transformer, a sequence-to-sequence model, has demonstrated exceptional performance in recommender systems. Typically, Transformer captures the temporal relationship of behaviors by incorporating positional information in MBSR. Through the utilization of an attention mechanism, it is able to model relationships both within and between behaviors. With superior parallel computing capabilities, an enhanced ability to capture long-term dependencies, and stronger interpretability, Transformer surpasses RNN and GNN in MBSR to some extent.


## D. Generic-Methods-based Learning Architecture

Since there are a lot of relevant and advanced works in a research area, it is necessary to study a generic framework that can utilize any of the previous relevant works to obtain information. A learning architecture based on a generic method that can employ a particular designed module on a state-of-theart model, combined with some innovative modeling modules to enhance the performance of that model, which is a direction worth further study.

1) Methods in MBSR: For the MBSR problem, the most important issues to consider are how to model sequences and how to distinguish between different behaviors. As such, the use of generic-methods-based learning architectures can be chosen to improve the recommendation performance by following previous effective models of SBSR or MBR in the modeling of sequences or heterogeneous behaviors. Behavioraware recommendation (BAR) [90] is a generic framework utilized in terms of obtaining sequence representations, which we introduce below.

BAR. BAR proposes a generic learning architecture for modeling multi-behavior sequences from a global modeling perspective, including a behavior attention layer and a taskspecific layer, as we illustrate in Figure 10. In the behavior attention layer, an attention network is used to enhance the presentation of the item embedding. Firstly, the embedding of an item ℓ is added by the behavior embedding B b ℓ u and the position embedding P ℓ . Then an attention network is used to obtain the attention score α ℓ ∈ R representing the relationship between the behavior embedding B b ℓ u and the new presentation of item embedding X ℓ , and is added to the item embedding V i ℓ u to learn the hidden representation at each time step: where RM(·) denotes some important components used in sequential recommendation methods, e.g., recurrent neural network and convolutional neural network. RM(·) reflects the generality of BAR, as any SBSR method like SASRec [78] can be utilized as a module of RM(·) to learn the potential representations of sequences. The task-specific layer is proposed as a solution to address the challenge of unknown whether the behavior is the purchase or not when the model is focused on predicting the next purchased item. It uses an MLP to obtain the connection between the sequential information representation h t−1 and the behavior embedding B b ℓ u . In summary, a general framework like BAR with directly applying the modeling methods used in SBSR possesses better performance and strong generalization capability, but now there are few works aiming to enhance the performance of recommendations. Hence, it could be beneficial to investigate the generalizability of modeling behavior types and transitions or to propose a generic model that incorporates the items' knowledge graph and the social connections among users.
h t−1 = RM (1 + α t−L ) V i t−L u , . . . , (1 + α t−1 ) V i t−1 u(40)

## E. Hybrid-Methods-based Learning Architecture

Combining multiple technologies for modeling can make use of the advantages of different technologies, and different technologies can also complement each other, leading to the improvement of modeling ability. The effective integration of diverse technologies within different modules is a crucial aspect to be considered when utilizing a hybrid-methods-based learning architecture.

1) Methods in MBSR: MBSR needs to model the sequence and behavior types at the same time, and it also needs to consider long-term and short-term preferences, as well as local or global information, which provides opportunities for employing different technologies. In MBSR, there are some works utilizing different techniques, including MKM-SR [15], MBGNN [75], MBHT [91], KHGT [92] and TGT [93]. We describe some of them in detail below, and summarize the data MBHT [91] Transformer + GNN A sequence of (item, behavior) pairs Local + Global Model users' short-term and long-term preferences by self-attention network and graph neural network, respectively. TGT [93] Transformer + GNN A sequence of (item, behavior) pairs

Local + Global Model long-term and short-term multibehavior sequence features separately to model a user's dynamic preference.

perspective, the modeling perspective and the characteristics of these works in Table V. MKM-SR. Micro-behaviors and item knowledge into multitask learning for session-based recommendation (MKM-SR) [15] utilizes the gated graph neural networks (gated GNN, GG-NNs) [94] and the gated recurrent units (GRU) to model multi-behavior sequences from a global modeling perspective. Here the global modeling perspective denotes that all sequences are modeled together, rather than each sequence separately. We focus on the part of MKM-SR that models user multi-behavior sequential information, i.e., M-SR. It treats the multi-behavior sequence as a sequence of items and a sequence of behaviors modeling. Then M-SR utilizes GG-NNs and GRU to model the item sequence and the behavior sequence, respectively, and concatenates the output vectors to obtain the behavioral characteristics of the user.

M-SR aggregates the embedding of the nodes by the constructed user-item graph. Subsequently, it is fed into the GRU module to enhance the information further. In comparison with the methods utilizing RNN alone, M-SR can capture the bidirectional sequence relationships. Furthermore, M-SR's methodology of framing the item sequence and inputting it into the GGNN proficiently models the relationships among all items. Additionally, utilizing the GRU to input behavioral sequences, rather than GGNN, enables M-SR to effectively capture the user's behavioral sequential preferences.

KHGT. Knowledge-enhanced hierarchical graph Transformer network (KHGT) [92] also utilizes Transformer and graph neural network to model multi-behavior sequences from both the global and local modeling perspectives, and treats the multi-behavior sequence as some sequences of behaviorspecific items modeling. For the position information of the user multi-behavior sequences, KHGT designs a novel encoding position function, which takes into account the users, the items, and the behavior types. For the user-item graph, unlike other methods, it constructs a heterogeneous graph of all users and interacted items. Each edge represents a record of a user's interaction with an item under a certain behavior type. The item-item graph is constructed using the item relation information, such as the item category. To extract the transition information about the nodes, a behavior-specific multi-head self-attention network is employed, and then the information of the graphs is utilized to aggregate the neighborhood information of the learning node. Finally, the information of each node is obtained.

KHGT is one of the few approaches to incorporate an itemto-item relationship within MBSR. This integration effectively enhances the information pertaining to each item, resulting in improved recommendation performance. It constructs the useritem and item-item graphs, and uses Transformer to model the relationship between different behaviors. The relationships within each behavior and between multiple behaviors are thoroughly considered and are thus modeled well.

Apart from the above two works, MBGNN [75] leverages GRU and GNN to model the user's global and local preferences, respectively, to solve the session-based recommendation problem, where behavior transition is considered in the construction of the graph similar to other GNN-based works. Whereas, both MBHT [91] and TGT [93] utilize GNN and Transformer to model users' long-term and shortterm preferences, respectively, where the former designs a novel self-attention mechanism inspired by Linformer [95]. In summary, the increasing use of hybrid-methods-based learning architecture for works in MBSR suggests that combining different techniques can leverage the strengths of these techniques and play a complementary role, thus enhancing the recommendation performance. Consequently, this is a direction worthy of further research.


## VI. FUTURE DIRECTIONS

The multi-behavior sequential recommendation (MBSR) problem, which is more representative of real-world recommendation scenarios, has increasingly gained attention from academia and industry in recent years. Although some works with superior recommendation performance towards the MBSR problem have been proposed, there are still many issues worthy of further study. In this section, we discuss some potential future research directions for the MBSR problem, including data, techniques, optimization targets and trustworthiness and responsibility.

Data. In the field of artificial intelligence, a comprehensive understanding of data is crucial for developing models. In the case of MBSR, the complexity of the data also poses various challenges when modeling. First of all, data sparsity has always been the focus of recommendation algorithms [96], and MBSR is no exception. However, excessive data sparsity can undermine the performance of association-based algorithms like collaborative filtering in recommender systems. Additionally, the multiple behaviors of MBSR make the pattern of data sparsity more intricate. In practical situations, such as cold-start settings, where new users or items are seldom interacted with, resolving the data sparsity issue is necessary to generate reasonable recommendations. Secondly, it is essential to explicitly model the data imbalance in MBSR. The data suffers from a heterogeneous behavioral distribution problem similar to MBR and a sequence length problem similar to SBSR. User behavior distribution and interaction sequence lengths often differ in real-world scenarios. For instance, in shopping scenarios, users tend to make fewer purchases than examination behaviors, and users may examine varying item quantities. Thirdly, there are several issues associated with data processing, including periodicity and noise. Periodicity refers to users' inclination to examine items at specific times, and noise refers to users examining items that do not align with their current preferences. While related works have focused on denoising [84], [88], there remains a significant scope for further research, particularly in terms of how to explicitly model various types of specific noise, such as interactions that align with a user's long-term preferences but not their current preferences. As such, it is necessary to further explore how to deal with data sparsity, imbalance, periodicity and noise, etc, so as to improve the effectiveness of recommendations.

Techniques. Technical innovation has been the approach that most works have been focused on to improve the recommendation performance, and there are several challenges to the techniques currently used for MBSR. Firstly, single types of techniques have their own limitations. For example, Transformer can solve the problem of parallel computation that RNN is limited, but is less capable of capturing the local information than RNN due to the point-wise dot-product self-attention utilized [97], [98]. As such, combining multiple complementary components or techniques to solve the MBSR problem is an important research direction. Secondly, efficiency is an essential issue in MBSR due to the complexity of the data. It is worthwhile to investigate how to improve recommendation performance without sacrificing efficiency so as to enable real-time recommendations. Thirdly, how to maintain acceptable time and space complexity when the number of behavior types increases is also a challenging issue. Fourthly, some works propose models that perform well on some datasets but poorly on others during training and prediction [72], [85]. As such, it remains a challenge to improve the generalization of the models for MBSR. In addition, there are difficulties in investigating the MBSR problem utilizing data from different domains, or data with auxiliary information such as item category information, reviews, and knowledge graphs. As interactive conversational recommender systems become more prevalent between users and platforms, future MBSR techniques may need to model multi-behavior sequential data and multiple rounds of conversational text data. In summary, there is much valuable research that can be done on the technical aspects of the MBSR problem, especially in terms of combining methods, improving efficiency, and adaptability of data diversity.

Optimization targets. Optimizing targets in MBSR also presents several challenges. Currently, most works on MBSR focus on a single target, such as recommending more items that users would like to buy in a shopping scenario. However, the diversity of user behaviors allows the possibility of optimizing multiple targets simultaneously. For example, on the business side of the industry, there is often more than one single target to optimize [99], instead, there is a need to jointly optimize multiple targets, such as increasing the view rate and like rate of a video simultaneously. At present, the multi-target optimization methods mainly include setting sample weight, stacking multiple models, sharing model parameters for joint training and MMoE [100], etc. However, there are some shortcomings in these methods. For example, in the method of stacking multiple models, the models are independent of each other, which makes the training process prone to the situation of over-fitting, while the sharing of experts in MMoE among all tasks may bring bias to some tasks. As such, how to optimize multiple objectives in a rational way is also a direction worth investigating.

LLMs. The remarkable performance of large language models [101], [102] has received great attention within the academic community. A mounting body of research is presently dedicated to expansive language models in the domain of recommendation systems [103], [104]. Due to the large amount of textual information intrinsic to the recommendation task itself, as well as the commendable language comprehension ability and external knowledge reserve of the large model, modeling the representation of users and items with text information may hopefully supplant conventional ID-based paradigms. In the task of multi-behavior sequential recommendation, in addition to modeling sequence relationships, different behavior information also needs to be modeled for items. How to use a large model to effectuate a synergistic amalgamation of distinct behavioral signals with the textual profiles of users and items is a relatively new direction. Noting that items may have different relationships under different behaviors. To illustrate, if you have browsed a certain type of product, you may buy the same type of product from a different brand. But buying this type of item may not buy it from a different brand again. Therefore, it is necessary to integrate multibehavioral information into the modeling of large models and recommendation tasks, rather than simple sequence modeling.

Trustworthiness and responsibility. The need to build more trustworthy and responsible recommender systems has been raised when recommender systems consistently pursue higher accuracy, and are determined to recommend items to users transparently, fairly and unbiasedly. Explainability and security are two main aspects of the trustworthiness of recommender systems [105], which also require further attention in MBSR.

Firstly, in terms of explainability, the complexity of the behaviors in MBSR makes the deep learning model less explainable. Attention is a common approach applied to MBSR to improve the explanation of deep learning models [26], [84], [90], [91]. Secondly, in terms of security, the issue of privacy protection is becoming increasingly important to the state and to the public. Recommender systems need to avoid the problem of user information leakage when designing a model, including the risk of information leakage between users, between platforms, and between both users and platforms. For the MBSR problem, the user's behaviors are considered private. Such private-sensitive data can only be observed on the user's own client and cannot be uploaded to the cloud, thereby complicating the modeling process. To address this challenge, the federated recommendation, one of the most effective and popular approaches addressed the privacy protection problem in recommender systems, is first proposed by Google in 2016 [106]. Not much work has been done to consider privacy and security in MBSR [62], and the use of federated learning [107] to secure privacy is an interesting direction. As such, it is important to build trustworthy and responsible recommender systems with higher explainability under the requirement of privacy protection, so that users can be fairly recommended the items they are interested in.

VII. CONCLUSIONS MBSR combines SBSR and MBR, requiring to model both sequential information and heterogeneous behaviors, which provides some challenges while allowing for some optimization in recommendation performance. MBSR is closer to the range of user feedback that occurs in real-life scenarios. The increasing amount of works for MBSR in academia and industry, although much fewer than those for SBSR, indicates the importance of MBSR in recommender systems. In this paper, we first introduce the MBSR problem in detail, followed by a classification of related works, encompassing neighborhoodbased methods, matrix factorization-based methods, and deep learning-based methods.

Due to the complexity of the MBSR problem, lots of works use deep learning-based methods, including RNN, GNN, and Transformer, or their generic and hybrid architectures. For each of these learning architectures, we present their general form before transitioning to how to apply the learning architecture to the MBSR problem based on previous works. For each work, we introduce it by technology, data and modeling perspectives, and discuss its strengths and weaknesses.

Through a detailed discussion of the works that have been done so far, we find that MBSR still faces many challenges. In response to these challenges, we suggest five possible future directions, including data, techniques, security, optimization targets and explanation, which we hope will give the readers some guidance on how to solve the MBSR problem better.

## …Fig. 1 .
1Illustration of multi-behavior sequential recommendation (MBSR).

## Fig. 2 .
2Categorization of multi-behavior sequential recommendation (MBSR).

## …Fig. 3 .
3Illustration of behavior transition.

## Fig. 4 .
4Illustration of recurrent neural network (RNN).

## Fig. 5 .
5to represent the historically interacted item i t−i u of user u, a behavior correlation embedding M f t−i u ∈ R d×d to represent the user's behavior f t−i u for item i t−i u , and a position transition embedding C i ∈ R d×d to separately capture the position context information of each position in the window i t−i u , f t−i u , i ∈ {0, 1, . . . , n − 1}. Hence, the hidden state h t+1 at the (t + 1)th time step is Illustration of recurrent log-bilinear model (RLBL). calculated below:

## Fig. 6 .
6An example of graph convolution.

## Fig. 7 .
7Illustration of global and personalized graphs for heterogeneous sequential recommendation (GPG4HSR).

## Fig. 8 .
8Illustration of Transformer. specifically examine the self-attention component by considering the representation of an examination sequence S e . The calculation of the self-attention component is as follows:

## Fig. 9 .
9Illustration of deep multifaceted Transformers (DMT).

## Fig. 10 .
10Illustration of behavior-aware recommendation (BAR).


Chen, Zhitao Li, Weike Pan and Zhong Ming are with the College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China, 518060.

## TABLE I SOME
INOTATIONS AND EXPLANATIONS.

## TABLE II DATA
II& MODELING PERSPECTIVES AND FEATURES USED IN WORKS BASED ON RNN LEARNING ARCHITECTURE.

## TABLE III DATA
III& MODELING PERSPECTIVES AND FEATURES USED IN WORKS BASED ON GNN LEARNING ARCHITECTURE.Works 
Data Perspective 
Model Perspective 
Features 
MGNN-
SPred [24] 

Some behavior-specific 
subsequences of items 

Global 
Modeling behavior from behavior transition relations, containing ho-
mogeneous behavior transitions intra each kind of behavior-specific 
subsequences. 
DMBGN [71] Some behavior-specific 
subsequences of items 

Global 
Focus on the task of voucher redemption rate prediction and model 
the relationship between multiple behaviors and vouchers effectively. 
GPG4HSR [72] A sequence of (item, 
behavior) pairs 

Local + Global 
Learn various behavior transition relations from the global graph and 
the personalized graph, respectively. 
BGNN [73] 
Some behavior-specific 
subsequences of items 

Global 
Construct directed graphs for different behavior transition (homoge-
neous and heterogeneous) information. 
BA-
GNN [74] 

Some behavior-specific 
subsequence of items 

Global 
Construct directed graphs for different behavior-specific sequences 
respectively. 



## TABLE IV DATA
IV& MODELING PERSPECTIVES AND FEATURES USED IN WORKS BASED ON TRANSFORMER LEARNING ARCHITECTURE.

## TABLE V
VDATA & MODELING PERSPECTIVES AND FEATURES USED IN WORKS BASED ON HYBRID LEARNING ARCHITECTURE.RNN + GNNA behavior-agnostic sequence of items and a sequence of behaviors Global Consider the knowledge graph of the items and the attributes.Local + Global Consider both behavior type and direction to distinguish different node sets. KHGT[92] Transformer + GNN Some behavior-specific subsequences of items Local + Global Consider item-item relation information.Works 
Hybrid Techniques 
Data Perspective 
Model Perspective 
Features 
MKM-
SR [15] 

MBGNN [75] RNN + GNN 
Some behavior-specific subse-
quences of items 


ACKNOWLEDGEMENTSWe thank the support of National Natural Science Foundation of China Nos. 62172283 and 62272315, and Mr. Jinwei Luo for helpful discussions.
Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. G Adomavicius, A Tuzhilin, IEEE Transactions on Knowledge and Data Engineering. 176G. Adomavicius and A. Tuzhilin, "Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions," IEEE Transactions on Knowledge and Data Engineering, vol. 17, no. 6, pp. 734-749, 2005.

F Ricci, L Rokach, B Shapira, Recommender Systems Handbook. SpringerSecond EditionF. Ricci, L. Rokach, and B. Shapira, Recommender Systems Handbook (Second Edition). Springer, 2015.

Dual collaborative topic modeling from implicit feedbacks. L Gai, L Lei, Proceedings 2014 IEEE International Conference on Security, Pattern Analysis, and Cybernetics, ser. SPAC. 2014 IEEE International Conference on Security, Pattern Analysis, and Cybernetics, ser. SPACL. Gai and L. Lei, "Dual collaborative topic modeling from implicit feedbacks," in Proceedings 2014 IEEE International Conference on Security, Pattern Analysis, and Cybernetics, ser. SPAC, 2014, pp. 395- 404.

Pairwise probabilistic matrix factorization for implicit feedback collaborative filtering. G Li, W Ou, Neurocomputing. 204G. Li and W. Ou, "Pairwise probabilistic matrix factorization for implicit feedback collaborative filtering," Neurocomputing, vol. 204, pp. 17-25, 2016.

Bpr: Bayesian personalized ranking from implicit feedback. S Rendle, C Freudenthaler, Z Gantner, L Schmidt-Thieme, Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence, ser. UAI'09. the 25th Conference on Uncertainty in Artificial Intelligence, ser. UAI'09S. Rendle, C. Freudenthaler, Z. Gantner, and L. Schmidt-Thieme, "Bpr: Bayesian personalized ranking from implicit feedback," in Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence, ser. UAI'09, 2009, pp. 452-461.

Adaptive bayesian personalized ranking for heterogeneous implicit feedbacks. W Pan, H Zhong, C Xu, Z Ming, Knowledge-Based Systems. 73W. Pan, H. Zhong, C. Xu, and Z. Ming, "Adaptive bayesian personal- ized ranking for heterogeneous implicit feedbacks," Knowledge-Based Systems, vol. 73, pp. 173-180, 2015.

Bprh: Bayesian personalized ranking for heterogeneous implicit feedback. H Qiu, Y Liu, G Guo, Z Sun, J Zhang, H T Nguyen, Information Sciences. 453H. Qiu, Y. Liu, G. Guo, Z. Sun, J. Zhang, and H. T. Nguyen, "Bprh: Bayesian personalized ranking for heterogeneous implicit feedback," Information Sciences, vol. 453, pp. 80-98, 2018.

An empirical study on recommendation with multiple types of feedback. L Tang, B Long, B Chen, D Agarwal, Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'16. the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'16L. Tang, B. Long, B. Chen, and D. Agarwal, "An empirical study on recommendation with multiple types of feedback," in Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'16, 2016, pp. 283-292.

Transfer learning for heterogeneous oneclass collaborative filtering. W Pan, M Liu, Z Ming, IEEE Intelligent Systems. 314W. Pan, M. Liu, and Z. Ming, "Transfer learning for heterogeneous one- class collaborative filtering," IEEE Intelligent Systems, vol. 31, no. 4, pp. 43-49, 2016.

Transfer to rank for heterogeneous one-class collaborative filtering. W Pan, Q Yang, W Cai, Y Chen, Q Zhang, X Peng, Z Ming, ACM Transactions on Information Systems. 371W. Pan, Q. Yang, W. Cai, Y. Chen, Q. Zhang, X. Peng, and Z. Ming, "Transfer to rank for heterogeneous one-class collaborative filtering," ACM Transactions on Information Systems, vol. 37, no. 1, pp. 1-20, 2019.

Factorizing personalized markov chains for next-basket recommendation. S Rendle, C Freudenthaler, L Schmidt-Thieme, Proceedings of the 19th International Conference on World Wide Web, ser. WWW'10. the 19th International Conference on World Wide Web, ser. WWW'10S. Rendle, C. Freudenthaler, and L. Schmidt-Thieme, "Factorizing personalized markov chains for next-basket recommendation," in Pro- ceedings of the 19th International Conference on World Wide Web, ser. WWW'10, 2010, pp. 811-820.

Next-item recommendation via collaborative filtering with bidirectional item similarity. Z Zeng, J Lin, L Li, W Pan, Z Ming, ACM Transactions on Information Systems. 381Z. Zeng, J. Lin, L. Li, W. Pan, and Z. Ming, "Next-item recommenda- tion via collaborative filtering with bidirectional item similarity," ACM Transactions on Information Systems, vol. 38, no. 1, pp. 1-22, 2019.

Personalized top-n sequential recommendation via convolutional sequence embedding. J Tang, K Wang, Proceedings of the 11th ACM International Conference on Web Search and Data Mining, ser. WSDM'18. the 11th ACM International Conference on Web Search and Data Mining, ser. WSDM'18J. Tang and K. Wang, "Personalized top-n sequential recommendation via convolutional sequence embedding," in Proceedings of the 11th ACM International Conference on Web Search and Data Mining, ser. WSDM'18, 2018, pp. 565-573.

Multi-behavioral sequential prediction with recurrent log-bilinear model. Q Liu, S Wu, L Wang, IEEE Transactions on Knowledge and Data Engineering. 296Q. Liu, S. Wu, and L. Wang, "Multi-behavioral sequential prediction with recurrent log-bilinear model," IEEE Transactions on Knowledge and Data Engineering, vol. 29, no. 6, pp. 1254-1267, 2017.

Incorporating user micro-behaviors and item knowledge into multi-task learning for session-based recommendation. W Meng, D Yang, Y Xiao, Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, ser. SIGIR'20. the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, ser. SIGIR'20W. Meng, D. Yang, and Y. Xiao, "Incorporating user micro-behaviors and item knowledge into multi-task learning for session-based rec- ommendation," in Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, ser. SIGIR'20, 2020, pp. 1091-1100.

Two decades of recommender systems at amazon.com. B Smith, G Linden, IEEE Internet Computing. 213B. Smith and G. Linden, "Two decades of recommender systems at amazon.com," IEEE Internet Computing, vol. 21, no. 3, pp. 12-18, 2017.

Billion-scale commodity embedding for e-commerce recommendation in alibaba. J Wang, P Huang, H Zhao, Z Zhang, B Zhao, D L Lee, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data MiningJ. Wang, P. Huang, H. Zhao, Z. Zhang, B. Zhao, and D. L. Lee, "Billion-scale commodity embedding for e-commerce recommendation in alibaba," in Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2018, pp. 839- 848.

Deep neural networks for youtube recommendations. P Covington, J Adams, E Sargin, Proceedings of the 10th ACM Conference on Recommender Systems. the 10th ACM Conference on Recommender SystemsP. Covington, J. Adams, and E. Sargin, "Deep neural networks for youtube recommendations," in Proceedings of the 10th ACM Confer- ence on Recommender Systems, 2016, pp. 191-198.

The netflix recommender system: Algorithms, business value, and innovation. C A Gomez-Uribe, N Hunt, ACM Transactions on Management Information Systems (TMIS). 64C. A. Gomez-Uribe and N. Hunt, "The netflix recommender system: Algorithms, business value, and innovation," ACM Transactions on Management Information Systems (TMIS), vol. 6, no. 4, pp. 1-19, 2015.

Personalized news recommendation based on click behavior. J Liu, P Dolan, E R Pedersen, Proceedings of the 15th International Conference on Intelligent User Interfaces. the 15th International Conference on Intelligent User InterfacesJ. Liu, P. Dolan, and E. R. Pedersen, "Personalized news recommenda- tion based on click behavior," in Proceedings of the 15th International Conference on Intelligent User Interfaces, 2010, pp. 31-40.

Mind: A large-scale dataset for news recommendation. F Wu, Y Qiao, J.-H Chen, C Wu, T Qi, J Lian, D Liu, X Xie, J Gao, W Wu, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsF. Wu, Y. Qiao, J.-H. Chen, C. Wu, T. Qi, J. Lian, D. Liu, X. Xie, J. Gao, W. Wu et al., "Mind: A large-scale dataset for news recommen- dation," in Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 2020, pp. 3597-3606.

Learning from history and present: Next-item recommendation via discriminatively exploiting user behaviors. Z Li, H Zhao, Q Liu, Z Huang, T Mei, E Chen, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'18. the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'18Z. Li, H. Zhao, Q. Liu, Z. Huang, T. Mei, and E. Chen, "Learning from history and present: Next-item recommendation via discriminatively exploiting user behaviors," in Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'18, 2018, pp. 1734-1743.

Deep multifaceted transformers for multi-objective ranking in large-scale ecommerce recommender systems. Y Gu, Z Ding, S Wang, L Zou, Y Liu, D Yin, Proceedings of the 29th ACM International Conference on Information and Knowledge Management, ser. CIKM'20. the 29th ACM International Conference on Information and Knowledge Management, ser. CIKM'20Y. Gu, Z. Ding, S. Wang, L. Zou, Y. Liu, and D. Yin, "Deep multifaceted transformers for multi-objective ranking in large-scale e- commerce recommender systems," in Proceedings of the 29th ACM International Conference on Information and Knowledge Management, ser. CIKM'20, 2020, pp. 2493-2500.

Beyond clicks: Modeling multi-relational item graph for session-based target behavior prediction. W Wang, W Zhang, S Liu, Q Liu, B Zhang, L Lin, H Zha, Proceedings of the Web Conference 2020, ser. WWW'20. the Web Conference 2020, ser. WWW'20W. Wang, W. Zhang, S. Liu, Q. Liu, B. Zhang, L. Lin, and H. Zha, "Beyond clicks: Modeling multi-relational item graph for session-based target behavior prediction," in Proceedings of the Web Conference 2020, ser. WWW'20, 2020, pp. 3056-3062.

Feedrec: News feed recommendation with various user feedbacks. C Wu, F Wu, T Qi, Q Liu, X Tian, J Li, W He, Y Huang, X Xie, Proceedings of the ACM Web Conference 2022, ser. WWW'22. the ACM Web Conference 2022, ser. WWW'22C. Wu, F. Wu, T. Qi, Q. Liu, X. Tian, J. Li, W. He, Y. Huang, and X. Xie, "Feedrec: News feed recommendation with various user feedbacks," in Proceedings of the ACM Web Conference 2022, ser. WWW'22, 2022, pp. 2088-2097.

Micro behaviors: A new perspective in e-commerce recommender systems. M Zhou, Z Ding, J Tang, D Yin, Proceedings of the 11th ACM International Conference on Web Search and Data Mining, ser. WSDM'18. the 11th ACM International Conference on Web Search and Data Mining, ser. WSDM'18M. Zhou, Z. Ding, J. Tang, and D. Yin, "Micro behaviors: A new perspective in e-commerce recommender systems," in Proceedings of the 11th ACM International Conference on Web Search and Data Mining, ser. WSDM'18, 2018, pp. 727-735.

Hierarchical user profiling for e-commerce recommender systems. Y Gu, Z Ding, S Wang, D Yin, Proceedings of the 13th International Conference on Web Search and Data Mining, ser. WSDM'20. the 13th International Conference on Web Search and Data Mining, ser. WSDM'20Y. Gu, Z. Ding, S. Wang, and D. Yin, "Hierarchical user profiling for e-commerce recommender systems," in Proceedings of the 13th Inter- national Conference on Web Search and Data Mining, ser. WSDM'20, 2020, pp. 223-231.

Modeling multiple coexisting categorylevel intentions for next item recommendation. Y Xu, Y Zhu, J Yu, ACM Transactions on Information Systems. 39324Y. Xu, Y. Zhu, and J. Yu, "Modeling multiple coexisting category- level intentions for next item recommendation," ACM Transactions on Information Systems, vol. 39, no. 3, pp. 23:1-23:24, 2021.

Session-based recommendations with recurrent neural networks. B Hidasi, A Karatzoglou, L Baltrunas, D Tikk, Proceedings of the 4th International Conference on Learning Representations, ser. ICLR'16. the 4th International Conference on Learning Representations, ser. ICLR'16B. Hidasi, A. Karatzoglou, L. Baltrunas, and D. Tikk, "Session-based recommendations with recurrent neural networks," in Proceedings of the 4th International Conference on Learning Representations, ser. ICLR'16, 2016.

Collaborative filtering with temporal dynamics. Y Koren, Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'09. the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'09Y. Koren, "Collaborative filtering with temporal dynamics," in Proceed- ings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'09, 2009, pp. 447-456.

Mining indecisiveness in customer behaviors. Q Liu, X Zeng, C Liu, H Zhu, E Chen, H Xiong, X Xie, 2015 IEEE International Conference on Data Mining, ser. ICDM. Q. Liu, X. Zeng, C. Liu, H. Zhu, E. Chen, H. Xiong, and X. Xie, "Min- ing indecisiveness in customer behaviors," in 2015 IEEE International Conference on Data Mining, ser. ICDM, 2015, pp. 281-290.

Collaborative knowledge base embedding for recommender systems. F Zhang, N J Yuan, D Lian, X Xie, W Ma, Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'16. the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'16F. Zhang, N. J. Yuan, D. Lian, X. Xie, and W. Ma, "Collaborative knowledge base embedding for recommender systems," in Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'16, 2016, pp. 353-362.

Unfolding temporal dynamics: Predicting social media popularity using multi-scale temporal decomposition. B Wu, T Mei, W Cheng, Y Zhang, Proceedings of the 30th AAAI Conference on Artificial Intelligence, ser. AAAI'16. the 30th AAAI Conference on Artificial Intelligence, ser. AAAI'16B. Wu, T. Mei, W. Cheng, and Y. Zhang, "Unfolding temporal dy- namics: Predicting social media popularity using multi-scale temporal decomposition," in Proceedings of the 30th AAAI Conference on Artificial Intelligence, ser. AAAI'16, 2016, pp. 272-278.

Unifying explicit and implicit feedback for collaborative filtering. N N Liu, E W Xiang, M Zhao, Q Yang, Proceedings of the 19th ACM International Conference on Information and Knowledge Management, ser. CIKM'10. the 19th ACM International Conference on Information and Knowledge Management, ser. CIKM'10N. N. Liu, E. W. Xiang, M. Zhao, and Q. Yang, "Unifying explicit and implicit feedback for collaborative filtering," in Proceedings of the 19th ACM International Conference on Information and Knowledge Management, ser. CIKM'10, 2010, pp. 1445-1448.

Rank and rate: Multitask learning for recommender systems. G Hadash, O S Shalom, R Osadchy, Proceedings of the 12th ACM Conference on Recommender Systems, ser. RecSys'18. the 12th ACM Conference on Recommender Systems, ser. RecSys'18G. Hadash, O. S. Shalom, and R. Osadchy, "Rank and rate: Multi- task learning for recommender systems," in Proceedings of the 12th ACM Conference on Recommender Systems, ser. RecSys'18, 2018, pp. 451-454.

Recommendations with negative feedback via pairwise deep reinforcement learning. X Zhao, L Zhang, Z Ding, L Xia, J Tang, D Yin, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'18. the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'18X. Zhao, L. Zhang, Z. Ding, L. Xia, J. Tang, and D. Yin, "Recom- mendations with negative feedback via pairwise deep reinforcement learning," in Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'18, 2018, pp. 1040-1048.

Fast matrix factorization for online recommendation with implicit feedback. X He, H Zhang, M Kan, T Chua, Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval, ser. SIGIR'16. the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval, ser. SIGIR'16X. He, H. Zhang, M. Kan, and T. Chua, "Fast matrix factorization for online recommendation with implicit feedback," in Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval, ser. SIGIR'16, 2016, pp. 549- 558.

A survey on heterogeneous one-class collaborative filtering. X Chen, L Lin, W Pan, Z Ming, ACM Transactions on Information Systems. 38454X. Chen, L. Lin, W. Pan, and Z. Ming, "A survey on heterogeneous one-class collaborative filtering," ACM Transactions on Information Systems, vol. 38, no. 4, pp. 35:1-35:54, 2020.

Logistic matrix factorization for implicit feedback data. C C Johnson, Advances in Neural Information Processing Systems. 27C. C. Johnson, "Logistic matrix factorization for implicit feedback data," Advances in Neural Information Processing Systems, vol. 27, no. 78, pp. 1-9, 2014.

Probabilistic matrix factorization. A Mnih, R R Salakhutdinov, Advances in Neural Information Processing Systems. 20A. Mnih and R. R. Salakhutdinov, "Probabilistic matrix factorization," Advances in Neural Information Processing Systems, vol. 20, 2007.

A comprehensive survey of neighborhood-based recommendation methods. C Desrosiers, G Karypis, Recommender Systems HandbookC. Desrosiers and G. Karypis, "A comprehensive survey of neighborhood-based recommendation methods," Recommender Systems Handbook, pp. 107-144, 2011.

Sorec: Social recommendation using probabilistic matrix factorization. H Ma, H Yang, M R Lyu, I King, Proceedings of the 17th ACM Conference on Information and Knowledge Management. the 17th ACM Conference on Information and Knowledge ManagementH. Ma, H. Yang, M. R. Lyu, and I. King, "Sorec: Social recommen- dation using probabilistic matrix factorization," in Proceedings of the 17th ACM Conference on Information and Knowledge Management, 2008, pp. 931-940.

A review on matrix factorization techniques in recommender systems. R Mehta, K Rana, 2017 2nd International Conference on Communication Systems, Computing and IT Applications (CSCITA. R. Mehta and K. Rana, "A review on matrix factorization techniques in recommender systems," in 2017 2nd International Conference on Communication Systems, Computing and IT Applications (CSCITA), 2017, pp. 269-274.

Transrec++: Translation-based sequential recommendation with heterogeneous feedback. Z Zhan, M He, W Pan, Z Ming, Frontiers of Computer Science. 162162615Z. Zhan, M. He, W. Pan, and Z. Ming, "Transrec++: Translation-based sequential recommendation with heterogeneous feedback," Frontiers of Computer Science, vol. 16, no. 2, p. 162615, 2022.

Fusing similarity models with markov chains for sparse sequential recommendation. R He, J Mcauley, Proceedings of the 16th IEEE International Conference on Data Mining, ser. ICDM'16. the 16th IEEE International Conference on Data Mining, ser. ICDM'16R. He and J. McAuley, "Fusing similarity models with markov chains for sparse sequential recommendation," in Proceedings of the 16th IEEE International Conference on Data Mining, ser. ICDM'16, 2016, pp. 191-200.

Translation-based recommendation. R He, W Kang, J Mcauley, Proceedings of the 11th ACM Conference on Recommender Systems, ser. RecSys'17. the 11th ACM Conference on Recommender Systems, ser. RecSys'17R. He, W. Kang, and J. McAuley, "Translation-based recommendation," in Proceedings of the 11th ACM Conference on Recommender Systems, ser. RecSys'17, 2017, pp. 161-169.

Deep learning. Y Lecun, Y Bengio, G Hinton, Nature. 5217553Y. LeCun, Y. Bengio, and G. Hinton, "Deep learning," Nature, vol. 521, no. 7553, pp. 436-444, 2015.

I Goodfellow, Y Bengio, A Courville, Deep Learning. MIT pressI. Goodfellow, Y. Bengio, and A. Courville, Deep Learning. MIT press, 2016.

A unified architecture for natural language processing: Deep neural networks with multitask learning. R Collobert, J Weston, Proceedings of the 25th International Conference on Machine Learning, ser. ICML'08. the 25th International Conference on Machine Learning, ser. ICML'08R. Collobert and J. Weston, "A unified architecture for natural language processing: Deep neural networks with multitask learning," in Proceed- ings of the 25th International Conference on Machine Learning, ser. ICML'08, 2008, pp. 160-167.

Recursive deep models for semantic compositionality over a sentiment treebank. R Socher, A Perelygin, J Wu, J Chuang, C D Manning, A Y Ng, C Potts, Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. the 2013 Conference on Empirical Methods in Natural Language ProcessingR. Socher, A. Perelygin, J. Wu, J. Chuang, C. D. Manning, A. Y. Ng, and C. Potts, "Recursive deep models for semantic compositionality over a sentiment treebank," in Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, ser. EMNLP, 2013, pp. 1631-1642.

Context-dependent pretrained deep neural networks for large-vocabulary speech recognition. G E Dahl, D Yu, L Deng, A Acero, IEEE Transactions on Audio, Speech, and Language Processing. 201G. E. Dahl, D. Yu, L. Deng, and A. Acero, "Context-dependent pre- trained deep neural networks for large-vocabulary speech recogni- tion," IEEE Transactions on Audio, Speech, and Language Processing, vol. 20, no. 1, pp. 30-42, 2011.

Imagenet classification with deep convolutional neural networks. A Krizhevsky, I Sutskever, G E Hinton, Advances in Neural Information Processing Systems. 25A. Krizhevsky, I. Sutskever, and G. E. Hinton, "Imagenet classification with deep convolutional neural networks," Advances in Neural Infor- mation Processing Systems, vol. 25, 2012.

Building high-level features using large scale unsupervised learning. Q V Le, 2013 IEEE International Conference on Acoustics, Speech and Signal Processing. Q. V. Le, "Building high-level features using large scale unsupervised learning," in 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, ser. ICASSP, 2013, pp. 8595-8598.

Learning to recommend with multiple cascading behaviors. C Gao, X He, D Gan, X Chen, F Feng, Y Li, T Chua, L Yao, Y Song, D Jin, IEEE Transactions on Knowledge and Data Engineering. 336C. Gao, X. He, D. Gan, X. Chen, F. Feng, Y. Li, T. Chua, L. Yao, Y. Song, and D. Jin, "Learning to recommend with multiple cascading behaviors," IEEE Transactions on Knowledge and Data Engineering, vol. 33, no. 6, pp. 2588-2601, 2019.

Collaborative metric learning with memory network for multi-relational recommender systems. X Zhou, D Liu, J Lian, X Xie, Proceedings of the 28th International Joint Conference on Artificial Intelligence, ser. IJCAI'19. the 28th International Joint Conference on Artificial Intelligence, ser. IJCAI'19X. Zhou, D. Liu, J. Lian, and X. Xie, "Collaborative metric learning with memory network for multi-relational recommender systems," in Proceedings of the 28th International Joint Conference on Artificial Intelligence, ser. IJCAI'19, 2019, pp. 4454-4460.

Fedgnn: Federated graph neural network for privacy-preserving recommendation. C Wu, F Wu, Y Cao, Y Huang, X Xie, abs/2102.04925CoRR. C. Wu, F. Wu, Y. Cao, Y. Huang, and X. Xie, "Fedgnn: Federated graph neural network for privacy-preserving recommendation," CoRR, vol. abs/2102.04925, 2021.

Fedctr: Federated native ad ctr prediction with cross platform user behavior data. C Wu, F Wu, L Lyu, Y Huang, X Xie, ACM Transactions on Intelligent Systems and Technology. 134C. Wu, F. Wu, L. Lyu, Y. Huang, and X. Xie, "Fedctr: Federated native ad ctr prediction with cross platform user behavior data," ACM Transactions on Intelligent Systems and Technology, vol. 13, no. 4, pp. 62:1-62:19, 2022.

Recurrent neural network based language model. T Mikolov, M Karafiát, L Burget, J Cernockỳ, S Khudanpur, Interspeech. 23T. Mikolov, M. Karafiát, L. Burget, J. Cernockỳ, and S. Khudanpur, "Recurrent neural network based language model." in Interspeech, vol. 2, no. 3, 2010, pp. 1045-1048.

Learning long-term dependencies with gradient descent is difficult. Y Bengio, P Simard, P Frasconi, IEEE Transactions on Neural Networks. 52Y. Bengio, P. Simard, and P. Frasconi, "Learning long-term dependen- cies with gradient descent is difficult," IEEE Transactions on Neural Networks, vol. 5, no. 2, pp. 157-166, 1994.

Long short-term memory. S Hochreiter, J Schmidhuber, Neural Computation. 98S. Hochreiter and J. Schmidhuber, "Long short-term memory," Neural Computation, vol. 9, no. 8, pp. 1735-1780, 1997.

Empirical evaluation of gated recurrent neural networks on sequence modeling. J Chung, C Gulcehre, K Cho, Y Bengio, arXiv:1412.3555arXiv preprintJ. Chung, C. Gulcehre, K. Cho, and Y. Bengio, "Empirical evaluation of gated recurrent neural networks on sequence modeling," arXiv preprint arXiv:1412.3555, 2014.

Deeprec: On-device deep learning for privacy-preserving sequential recommendation in mobile commerce. J Han, Y Ma, Q Mei, X Liu, Proceedings of The Web Conference 2021, ser. WWW'21. The Web Conference 2021, ser. WWW'21J. Han, Y. Ma, Q. Mei, and X. Liu, "Deeprec: On-device deep learning for privacy-preserving sequential recommendation in mobile com- merce," in Proceedings of The Web Conference 2021, ser. WWW'21, 2021, pp. 900-911.

Modeling contemporaneous basket sequences with twin networks for next-item recommendation. D Le, H W Lauw, Y Fang, Proceedings of the 27th International Joint Conference on Artificial Intelligence, ser. IJCAI'18. the 27th International Joint Conference on Artificial Intelligence, ser. IJCAI'18D. Le, H. W. Lauw, and Y. Fang, "Modeling contemporaneous basket sequences with twin networks for next-item recommendation," in Proceedings of the 27th International Joint Conference on Artificial Intelligence, ser. IJCAI'18, 2018, pp. 3414-3420.

Buying or browsing?: Predicting real-time purchasing intent using attention-based deep network with multiple behavior. L Guo, L Hua, R Jia, B Zhao, X Wang, B Cui, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'19. the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'19L. Guo, L. Hua, R. Jia, B. Zhao, X. Wang, and B. Cui, "Buying or browsing?: Predicting real-time purchasing intent using attention-based deep network with multiple behavior," in Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'19, 2019, pp. 1984-1992.

Mbn: Towards multi-behavior sequence modeling for next basket recommendation. Y Shen, B Ou, R Li, ACM Transactions on Knowledge Discovery from Data. 165Y. Shen, B. Ou, and R. Li, "Mbn: Towards multi-behavior sequence modeling for next basket recommendation," ACM Transactions on Knowledge Discovery from Data, vol. 16, no. 5, pp. 81:1-81:23, 2022.

The graph neural network model. F Scarselli, M Gori, A C Tsoi, M Hagenbuchner, G Monfardini, IEEE Transactions on Neural Networks. 201F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Monfardini, "The graph neural network model," IEEE Transactions on Neural Networks, vol. 20, no. 1, pp. 61-80, 2008.

A comprehensive survey on graph neural networks. Z Wu, S Pan, F Chen, G Long, C Zhang, S Y Philip, IEEE Transactions on Neural Networks and Learning Systems. 321Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and S. Y. Philip, "A comprehensive survey on graph neural networks," IEEE Transactions on Neural Networks and Learning Systems, vol. 32, no. 1, pp. 4-24, 2020.

Semi-supervised classification with graph convolutional networks. M Welling, T N Kipf, Proceedings of the 5th International Conference on Learning Representation, ser. ICLR'17. the 5th International Conference on Learning Representation, ser. ICLR'17M. Welling and T. N. Kipf, "Semi-supervised classification with graph convolutional networks," in Proceedings of the 5th International Conference on Learning Representation, ser. ICLR'17, 2016.

Inductive representation learning on large graphs. W Hamilton, Z Ying, J Leskovec, Proceedings of the 31th International Conference on Neural Information Processing Systems, ser. NeurIPS'17. the 31th International Conference on Neural Information Processing Systems, ser. NeurIPS'17W. Hamilton, Z. Ying, and J. Leskovec, "Inductive representation learning on large graphs," in Proceedings of the 31th International Con- ference on Neural Information Processing Systems, ser. NeurIPS'17, 2017, pp. 1025-1035.

Graph attention networks. P Velickovic, G Cucurull, A Casanova, A Romero, P Lio, Y Bengio, Proceedings of the 6th International Conference on Learning Representation, ser. ICLR'18. the 6th International Conference on Learning Representation, ser. ICLR'18P. Velickovic, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio, "Graph attention networks," in Proceedings of the 6th International Conference on Learning Representation, ser. ICLR'18, 2018.

Dmbgn: Deep multi-behavior graph networks for voucher redemption rate prediction. F Xiao, L Li, W Xu, J Zhao, X Yang, J Lang, H Wang, Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, ser. KDD'21. the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, ser. KDD'21F. Xiao, L. Li, W. Xu, J. Zhao, X. Yang, J. Lang, and H. Wang, "Dmbgn: Deep multi-behavior graph networks for voucher redemption rate prediction," in Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, ser. KDD'21, 2021, pp. 3786-3794.

Global and personalized graphs for heterogeneous sequential recommendation by learning behavior transitions and user intentions. W Chen, M He, Y Ni, W Pan, L Chen, Z Ming, Proceedings of the 16th ACM Conference on Recommender Systems, ser. RecSys'22. the 16th ACM Conference on Recommender Systems, ser. RecSys'22W. Chen, M. He, Y. Ni, W. Pan, L. Chen, and Z. Ming, "Global and personalized graphs for heterogeneous sequential recommendation by learning behavior transitions and user intentions," in Proceedings of the 16th ACM Conference on Recommender Systems, ser. RecSys'22, 2022, pp. 268-277.

Bgnn: Behavior-aware graph neural network for heterogeneous session-based recommendation. J Luo, M He, W Pan, Z Ming, Frontiers of Computer Science. J. Luo, M. He, W. Pan, and Z. Ming, "Bgnn: Behavior-aware graph neural network for heterogeneous session-based recommendation," Frontiers of Computer Science, 2022.

Ba-gnn: Behavioraware graph neural network for session-based recommendation. Y Liang, Q Song, Z Zhao, H Zhou, M Gong, Frontiers of Computer Science. 00Y. Liang, Q. Song, Z. Zhao, H. Zhou, and M. Gong, "Ba-gnn: Behavior- aware graph neural network for session-based recommendation," Fron- tiers of Computer Science, vol. 0, no. 0, pp. 1-16, 2022.

Multi-behavior graph neural networks for session-based recommendation. W Pan, K Yang, 2021 3rd International Conference on Machine Learning, Big Data and Business Intelligence, ser. MLB-DBI. W. Pan and K. Yang, "Multi-behavior graph neural networks for session-based recommendation," in 2021 3rd International Conference on Machine Learning, Big Data and Business Intelligence, ser. MLB- DBI, 2021, pp. 756-761.

Gated graph sequence neural networks. Y Li, D Tarlow, M Brockschmidt, R Zemel, Proceedings of the 4th International Conference on Learning Representations, ser. ICLR'16. the 4th International Conference on Learning Representations, ser. ICLR'16Y. Li, D. Tarlow, M. Brockschmidt, and R. Zemel, "Gated graph sequence neural networks," in Proceedings of the 4th International Conference on Learning Representations, ser. ICLR'16, 2016.

Weisfeiler and leman go neural: Higher-order graph neural networks. C Morris, M Ritzert, M Fey, W L Hamilton, J E Lenssen, G Rattan, M Grohe, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence33C. Morris, M. Ritzert, M. Fey, W. L. Hamilton, J. E. Lenssen, G. Rattan, and M. Grohe, "Weisfeiler and leman go neural: Higher-order graph neural networks," in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 33, no. 01, 2019, pp. 4602-4609.

Self-attentive sequential recommendation. W.-C Kang, J Mcauley, Proceedings of the 2018 IEEE International Conference on Data Mining, ser. ICDM'18. the 2018 IEEE International Conference on Data Mining, ser. ICDM'18W.-C. Kang and J. McAuley, "Self-attentive sequential recommenda- tion," in Proceedings of the 2018 IEEE International Conference on Data Mining, ser. ICDM'18, 2018, pp. 197-206.

Attention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, Ł Kaiser, I Polosukhin, Advances in Neural Information Processing Systems. 30A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin, "Attention is all you need," Advances in Neural Information Processing Systems, vol. 30, 2017.

Bert: Pre-training of deep bidirectional transformers for language understanding. J Devlin, M.-W Chang, K Lee, K Toutanova, arXiv:1810.04805arXiv preprintJ. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, "Bert: Pre-training of deep bidirectional transformers for language understanding," arXiv preprint arXiv:1810.04805, 2018.

Y Liu, M Ott, N Goyal, J Du, M Joshi, D Chen, O Levy, M Lewis, L Zettlemoyer, V Stoyanov, arXiv:1907.11692Roberta: A robustly optimized bert pretraining approach. arXiv preprintY. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov, "Roberta: A robustly optimized bert pretraining approach," arXiv preprint arXiv:1907.11692, 2019.

An image is worth 16x16 words: Transformers for image recognition at scale. A Dosovitskiy, L Beyer, A Kolesnikov, D Weissenborn, X Zhai, T Unterthiner, M Dehghani, M Minderer, G Heigold, S Gelly, arXiv:2010.11929arXiv preprintA. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly et al., "An image is worth 16x16 words: Transformers for image recognition at scale," arXiv preprint arXiv:2010.11929, 2020.

End-to-end object detection with transformers. N Carion, F Massa, G Synnaeve, N Usunier, A Kirillov, S Zagoruyko, European conference on computer vision. N. Carion, F. Massa, G. Synnaeve, N. Usunier, A. Kirillov, and S. Zagoruyko, "End-to-end object detection with transformers," in European conference on computer vision, 2020, pp. 213-229.

Deep feedback network for recommendation. R Xie, C Ling, Y Wang, R Wang, F Xia, L Lin, Proceedings of the 29th International Joint Conference on Artificial Intelligence, ser. IJCAI'20. the 29th International Joint Conference on Artificial Intelligence, ser. IJCAI'20R. Xie, C. Ling, Y. Wang, R. Wang, F. Xia, and L. Lin, "Deep feedback network for recommendation," in Proceedings of the 29th International Joint Conference on Artificial Intelligence, ser. IJCAI'20, 2020, pp. 2519-2525.

Flag: A feedback-aware local and global model for heterogeneous sequential recommendation. M He, J Lin, J Luo, W Pan, Z Ming, ACM Transactions on Intelligent Systems and Technology. M. He, J. Lin, J. Luo, W. Pan, and Z. Ming, "Flag: A feedback-aware local and global model for heterogeneous sequential recommendation," ACM Transactions on Intelligent Systems and Technology, 2022.

Dual-task learning for multi-behavior sequential recommendation. J Luo, M He, X Lin, W Pan, Z Ming, Proceedings of the 31st ACM International Conference on Information and Knowledge Management, ser. CIKM'22. the 31st ACM International Conference on Information and Knowledge Management, ser. CIKM'22J. Luo, M. He, X. Lin, W. Pan, and Z. Ming, "Dual-task learning for multi-behavior sequential recommendation," in Proceedings of the 31st ACM International Conference on Information and Knowledge Management, ser. CIKM'22, 2022.

Multi-behavior sequential transformer recommender. E Yuan, W Guo, Z He, H Guo, C Liu, R Tang, Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, ser. SIGIR'22. the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, ser. SIGIR'22E. Yuan, W. Guo, Z. He, H. Guo, C. Liu, and R. Tang, "Multi-behavior sequential transformer recommender," in Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, ser. SIGIR'22, 2022, pp. 1642-1652.

Denoising user-aware memory network for recommendation. Z Bian, S Zhou, H Fu, Q Yang, Z Sun, J Tang, G Liu, K Liu, X Li, Proceedings of the 15th ACM Conference on Recommender Systems, ser. RecSys'21. the 15th ACM Conference on Recommender Systems, ser. RecSys'21Z. Bian, S. Zhou, H. Fu, Q. Yang, Z. Sun, J. Tang, G. Liu, K. Liu, and X. Li, "Denoising user-aware memory network for recommendation," in Proceedings of the 15th ACM Conference on Recommender Systems, ser. RecSys'21, 2021, pp. 400-410.

Exploring the limits of transfer learning with a unified text-to-text transformer. C Raffel, N Shazeer, A Roberts, K Lee, S Narang, M Matena, Y Zhou, W Li, P J Liu, Jouranl of Machine Learning Research. 21140C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, P. J. Liu et al., "Exploring the limits of transfer learning with a unified text-to-text transformer," Jouranl of Machine Learning Research, vol. 21, no. 140, pp. 1-67, 2020.

Bar: Behavior-aware recommendation for sequential heterogeneous one-class collaborative filtering. M He, W Pan, Z Ming, Information Sciences. 608M. He, W. Pan, and Z. Ming, "Bar: Behavior-aware recommendation for sequential heterogeneous one-class collaborative filtering," Infor- mation Sciences, vol. 608, pp. 881-899, 2022.

Multi-behavior hypergraph-enhanced transformer for sequential recommendation. Y Yang, C Huang, L Xia, Y Liang, Y Yu, C Li, Proceedings of the 28th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'22. the 28th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'22Y. Yang, C. Huang, L. Xia, Y. Liang, Y. Yu, and C. Li, "Multi-behavior hypergraph-enhanced transformer for sequential recommendation," in Proceedings of the 28th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'22, 2022, pp. 2263- 2274.

Knowledge-enhanced hierarchical graph transformer network for multi-behavior recommendation. L Xia, C Huang, Y Xu, P Dai, X Zhang, H Yang, J Pei, L Bo, Proceedings of the 35th AAAI Conference on Artificial Intelligence, ser. AAAI'21. the 35th AAAI Conference on Artificial Intelligence, ser. AAAI'21L. Xia, C. Huang, Y. Xu, P. Dai, X. Zhang, H. Yang, J. Pei, and L. Bo, "Knowledge-enhanced hierarchical graph transformer network for multi-behavior recommendation," in Proceedings of the 35th AAAI Conference on Artificial Intelligence, ser. AAAI'21, 2021, pp. 4486- 4493.

Multi-behavior sequential recommendation with temporal graph transformer. L Xia, C Huang, Y Xu, J Pei, IEEE Transactions on Knowledge and Data Engineering. L. Xia, C. Huang, Y. Xu, and J. Pei, "Multi-behavior sequential recommendation with temporal graph transformer," IEEE Transactions on Knowledge and Data Engineering, 2022.

Session-based recommendation with graph neural networks. S Wu, Y Tang, Y Zhu, L Wang, X Xie, T Tan, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence33S. Wu, Y. Tang, Y. Zhu, L. Wang, X. Xie, and T. Tan, "Session-based recommendation with graph neural networks," in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 33, no. 01, 2019, pp. 346-353.

Linformer: Selfattention with linear complexity. S Wang, B Z Li, M Khabsa, H Fang, H Ma, arXiv:2006.04768arXiv preprintS. Wang, B. Z. Li, M. Khabsa, H. Fang, and H. Ma, "Linformer: Self- attention with linear complexity," arXiv preprint arXiv:2006.04768, 2020.

Resolving data sparsity by multi-type auxiliary implicit feedback for recommender systems. G Guo, H Qiu, Z Tan, Y Liu, J Ma, X Wang, Knowledge-Based Systems. 138G. Guo, H. Qiu, Z. Tan, Y. Liu, J. Ma, and X. Wang, "Resolving data sparsity by multi-type auxiliary implicit feedback for recommender systems," Knowledge-Based Systems, vol. 138, pp. 202-207, 2017.

Enhancing the locality and breaking the memory bottleneck of transformer on time series forecasting. S Li, X Jin, Y Xuan, X Zhou, W Chen, Y.-X Wang, X Yan, Advances in Neural Information Processing Systems. 32S. Li, X. Jin, Y. Xuan, X. Zhou, W. Chen, Y.-X. Wang, and X. Yan, "Enhancing the locality and breaking the memory bottleneck of trans- former on time series forecasting," Advances in Neural Information Processing Systems, vol. 32, pp. 5243-5253, 2019.

Hero-gang neural model for named entity recognition. J Hu, Y Shen, Y Liu, X Wan, T.-H Chang, abs/2205.07177CoRR. J. Hu, Y. Shen, Y. Liu, X. Wan, and T.-H. Chang, "Hero-gang neural model for named entity recognition," CoRR, vol. abs/2205.07177, 2022.

Deep bayesian multi-target learning for recommender systems. Q Wang, Z Ji, H Liu, B Zhao, arXiv:1902.09154arXiv preprintQ. Wang, Z. Ji, H. Liu, and B. Zhao, "Deep bayesian multi-target learning for recommender systems," arXiv preprint arXiv:1902.09154, 2019.

Modeling task relationships in multi-task learning with multi-gate mixture-of-experts. J Ma, Z Zhao, X Yi, J Chen, L Hong, E H Chi, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'18. the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'18J. Ma, Z. Zhao, X. Yi, J. Chen, L. Hong, and E. H. Chi, "Modeling task relationships in multi-task learning with multi-gate mixture-of-experts," in Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD'18, 2018, pp. 1930- 1939.

Gpt-3: Its nature, scope, limits, and consequences. L Floridi, M Chiriatti, 30Minds and MachinesL. Floridi and M. Chiriatti, "Gpt-3: Its nature, scope, limits, and consequences," Minds and Machines, vol. 30, pp. 681-694, 2020.

A survey of large language models. W X Zhao, K Zhou, J Li, T Tang, X Wang, Y Hou, Y Min, B Zhang, J Zhang, Z Dong, arXiv:2303.18223arXiv preprintW. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang, J. Zhang, Z. Dong et al., "A survey of large language models," arXiv preprint arXiv:2303.18223, 2023.

A survey on large language models for recommendation. L Wu, Z Zheng, Z Qiu, H Wang, H Gu, T Shen, C Qin, C Zhu, H Zhu, Q Liu, arXiv:2305.19860arXiv preprintL. Wu, Z. Zheng, Z. Qiu, H. Wang, H. Gu, T. Shen, C. Qin, C. Zhu, H. Zhu, Q. Liu et al., "A survey on large language models for recommendation," arXiv preprint arXiv:2305.19860, 2023.

Recommender systems in the era of large language models (llms). W Fan, Z Zhao, J Li, Y Liu, X Mei, Y Wang, J Tang, Q Li, arXiv:2307.02046arXiv preprintW. Fan, Z. Zhao, J. Li, Y. Liu, X. Mei, Y. Wang, J. Tang, and Q. Li, "Recommender systems in the era of large language models (llms)," arXiv preprint arXiv:2307.02046, 2023.

Trustworthy recommender systems. S Wang, X Zhangb, Y Wang, H Liu, F Ricci, arXiv:2208.06265arXiv preprintS. Wang, X. Zhangb, Y. Wang, H. Liu, and F. Ricci, "Trustworthy recommender systems," arXiv preprint arXiv:2208.06265, 2022.

Communication-efficient learning of deep networks from decentralized data. B Mcmahan, E Moore, D Ramage, S Hampson, B A Arcas, Artificial Intelligence and Statistics. B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, "Communication-efficient learning of deep networks from decentral- ized data," in Artificial Intelligence and Statistics, 2017, pp. 1273- 1282.

Federated machine learning: Concept and applications. Q Yang, Y Liu, T Chen, Y Tong, ACM Transactions on Intelligent Systems and Technology (TIST). 102Q. Yang, Y. Liu, T. Chen, and Y. Tong, "Federated machine learning: Concept and applications," ACM Transactions on Intelligent Systems and Technology (TIST), vol. 10, no. 2, pp. 1-19, 2019.