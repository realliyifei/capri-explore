# A survey on GANs for computer vision: Recent research, analysis and taxonomy

CorpusID: 247597155
 
tags: #Computer_Science

URL: [https://www.semanticscholar.org/paper/4876459cc2abb2189c41a4e2ec23c6407048920e](https://www.semanticscholar.org/paper/4876459cc2abb2189c41a4e2ec23c6407048920e)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | True |
| By Annotator      | (Not Annotated) |

---

A survey on GANs for computer vision: Recent research, analysis and taxonomy
27 Mar 2023

Guillermo Iglesias *guillermo.iglesias@upm.es**e.talavera@upm.escorrespondingauthoralberto.diaz@upm.es 
Departamento de Sistemas Informáticos
Universidad Politécnica de Madrid ETSISI -Campus Sur
C/Alan Turing, s/n28031MadridSpain

Edgar Talavera 
Departamento de Sistemas Informáticos
Universidad Politécnica de Madrid ETSISI -Campus Sur
C/Alan Turing, s/n28031MadridSpain

Alberto Díaz-Álvarez 
Departamento de Sistemas Informáticos
Universidad Politécnica de Madrid ETSISI -Campus Sur
C/Alan Turing, s/n28031MadridSpain

A survey on GANs for computer vision: Recent research, analysis and taxonomy
27 Mar 2023Preprint submitted to arXiv March 28, 2023Generative Adversarial NetworkArtificial IntelligenceMachine LearningDeep Learning
In the last few years, there have been several revolutions in the field of deep learning, mainly headlined by the large impact of Generative Adversarial Networks (GANs). GANs not only provide an unique architecture when defining their models, but also generate incredible results which have had a direct impact on society. Due to the significant improvements and new areas of research that GANs have brought, the community is constantly coming up with new researches that make it almost impossible to keep up with the times. Our survey aims to provide a general overview of GANs, showing the latest architectures, optimizations of the loss functions, validation metrics and application areas of the most widely recognized variants. The efficiency of the different variants of the model architecture will be evaluated, as well as showing the best application area; as a vital part of the process, the different metrics for evaluating the performance of GANs and the frequently used loss functions will be analyzed.The final objective of this survey is to provide a summary of the evolution and performance of the GANs which are having better results to guide future researchers in the field.

## Introduction

Generative Adversarial Networks (GANs) are specific Artificial Neural Networks (ANNs) architectures that were introduced in 2014 by Ian GoodFellow [51]. GANs are a type of generative models based on game theory where ANNs are used to mimic a data distribution. Since they were firstly introduced, GANs have supposed a large change in the synthesized data generated by Artificial Intelligence (AI).

Due to their success, the number of GAN related researches has increased exponentially [29]. These researches have focused on different aspects of the models, from optimizing their training [77,55] to applying GAN to new fields such as language generation [190], image generation [79,77], image-to-image translation [211,67], image generation in text description [212], video generation [98], and other domains [80] achieving state-of-the-art results.

GAN models are capable of replicating a data distribution and generating synthesized data, applying a certain standard deviation to create new and never seen before data. Due to the particularities of GANs, one of the fields were they have supposed a change in the quality of the synthesized data is in computer vision. Although there were previous models [1,8,173], GANs have shown to generate sharper results [161].

The main peculiarity of GANs lies in their training, where it is based on game theory, where two neural networks compete in a min-max game. Both networks must optimize their corresponding objective functions, generating a situation where two players compete for opposites objectives. Fig. 1 shows how the GAN architecture is composed. Due to this architecture complexity, GANs suffer from instability during their training [185,169,116].

The instability of training in these models gives rise to problems such as mode collapse, so that researches have been made to tackle this kind of problems [16,7,2,12,42]. As [168] defines, mode collapse happens when the GANs model generates the same class outputs with different inputs.

Because of the considerable variety of fields in which GANs are applied [3], the variety of different GAN architectures is wide [211,67,5]. This research focuses on outlining the fields where GANs have achieved better results. We will review the different GAN architectures that exist, how they are structured, and how they are adapted to fulfill the particularities of each problem.

Although we will explain different GAN architectures, it should be noted that, when new GAN models are created, they usually combine the different results of previous researches. Most of the models that we will present are usually overlapped to achieve better results.

GAN surveys are usually focused on GAN models structure [185,48] or their application in certain tasks [180,4]. Because we will focus on novel GAN architectures, this survey can be identified as the first type. Nevertheless, in the final steps of this survey, we will review how different GAN architectures are applied to real world problems.

This survey focuses on contextualizing the recent progress in the GAN field, reviewing the different variants that have been lately presented and how they address the main problems of training GANs. We provide a complete view of the GAN structure and particularities, then we contextualize the main problems that the networks suffer. We also summarize how GAN performance is measured, explaining the most used metrics that researchers use. During the different sections we outline how the presented architectures treat the differ-ent problems that we have characterized. Finally we propose a classification of GANs based on their application, for each class we review the progress that the main variants have followed and we compare their results.


## Related Work

Several other surveys of GANs published during the last years [134,177,48,152,187] have been studied to investigate the recent trends. For example, [185] focus on the instability issues that GANs suffer and show different ways to minimize it. The results suggest that some novel architectures try to control GAN's training, while this control can be achieved by focusing on tuning hyperparameters. It also emphasizes that much of the theoretical work does not fulfill in reality, which causes some GANs to convergence when they should not and not converge when they should.

Few surveys have been conducted to explore several approaches to optimize the loss function of GAN. This research approach tries to enhance the similarity between original and synthesized data distributions by defining an appropriate loss function. Surveys such as [133] are focus on analyzing the state-of-the-art GANs and further analyzing the performance of a huge variety of networks. In addition, they propose a set of recommendations of which loss function works best for each case of use.

Other works focusing on the applications of GANs instead of their composition or loss function. For example, [53] focus on how different GAN's architectures have been used during the last years for different problems, while [180] shows the different architectures for computer vision and their applications.

Due to the constant evolution of GANs during the last few years, these reviews are outdated almost instantaneously. As a result of some relevant and recent researches like [80,200,106] cannot be found in any recent GAN review [3,34]. We consider that a new and more complete review must be done, covering the researches that previous reviews did not fill in and contributing to a deeper and more thorough analysis of the state-of-the-art of GANs.


## Structure of this survey

This survey is structured as follows. Section 4 is a concise introduction of GAN composition and principles, we will also summarize the common problems that GANs suffer to then review the different solutions proposed to each problem. The different evaluation metrics are also reviewed, we address each metric strengths and weaknesses.  


## Generative Adversarial Networks (GANs)

In this section, we will review the basic characteristics of GANs, their structure, composition, and common problems. We will especially focus on GAN problems because most of the GAN architectures [119,160] are created to minimize the training problems.


### Definition and structure

GANs are an architecture composed of various neural networks, their objective is to replicate a data distribution in an unsupervised way. To achieve it, they are composed of two neural networks that play a two-player zero-sum game. In this game, the network called the Generator (G) is in charge of creating new data samples replicating, but not copying, the origin data distribution; while the Discriminator (D) tries to distinguish real and generated data.

From a formal point of view, D estimates p(y|x), that is, the probability of a label y given the sample x; while G generates a sample given a latent space z, which can be denoted as G(z).

This process consists in both networks competing. While G tries to generate more realistic results, D improves its accuracy detecting which samples are real and which not. In this process, both competitors are synchronized, if G creates a better output, it will be more difficult for D to differentiate them. On the other hand, if D is more precise, it will be more difficult for G to fool D. This process is a minimax game in which D tries to maximize the accuracy and G tries to minimize it. The formulation of the minimax game loss function can be denoted as:
min G max D L(D, G) = Ex∼p r log[D(x)] + Ez∼p z log[1 − D(G(x))](1)
where x ∼ pr is the distribution of the real data and z ∼ pz denotes the probability distribution of the latent space of G. z ∼ pz is commonly a Gaussian or uniform noise that G uses to model new samples of data denoted as G(z). D function is to differentiate between the real distribution D(x) and the synthesized distribution
D(G(x)).
According to the equation, the initial publication where the GANs where presented [51] proved the existence of a unique solution. This solution is called Nash Equilibrium (NE) and it happens when neither player can improve their loss [125].

Several researches have demonstrated that reaching the NE might not be possible in practice [43,61] or the unique solution [49].


### Common problems

Due to GAN's particularities previously described, there are some aspects in GAN's training [150] to which special attention should be given.

In addition of summarizing the different main GANs problems, during the section 5

we will connect the different GAN architectures with the problems that they tackle. It should be noted that the recent proposed architectures tries to minimize the different GAN issues to optimize their models.


#### Mode collapse

The objective is to generate synthesized data from a latent space, which requires not only quality in the generated data, but generalization and diversity in the different synthesized samples. In other words, GAN models should be able to recreate new unseen data. Mode collapse occurs when the same class outputs are generated by different inputs from the latent space [207].

There are studies [2] that shows how the quality and diversity of GANs are correlated. Many efforts [120,7,96] have been taken to tackle mode collapse, but it is still an open problem.

In practice, it is not common for GAN's model to generate always the same output with different inputs [50], this issue is known as complete mode collapse. This type of error occurs rarely, however, it is a common problem that occurs in a partial form or 


#### Gradient vanishing

GAN's training must be balanced, both G and D need to be synchronized to learn together progressively [159,207]. A very accurate D is capable to differentiate between the real and synthesized data, this can be denoted as D(x) = 1 and D(G(z)) = 0.

The loss function in this case approaches to zero, generating gradients close to zero and providing little feedback to the G. On the other hand, a poorly accurate D cannot differentiate between real and synthesized data, providing to G useless information.


#### Instability

Due to the particularity of GANs, the combination of two models learning from each other is a complex task. GAN training is based on a zero-sum game where both networks compete to find its particular solution, playing a minimax game.

This architecture of models is based on cooperation to optimize the global loss function, but the problems that D and G must optimize are opposite. Due to the particularity of the objective function of the networks, there can be times during the training where a small change in one of the networks can lead to a big change in the other, in turn producing further changes. Those intervals in which both networks start to desynchronize their states are very delicate since large changes in the gradients can lead to a network losing its learning [5,213].

It should be noted that instability periods tend to generate more instability, making the problem last longer. Networks can reverse the instability process, but even if it happens, it will cost the training performance.

Many of the last proposed GAN architectures are focused on stabilize their training [77,5]. By stabilizing the training, it is usually achieved a better performance of the networks, this is why most of the last progress involve a more stable training.


#### Stopping problem

Traditional neural networks have to optimize a loss function decreasing monotonically, in theory, the cost function. Due to the minimax game that GANs have to optimize, this does not happen to them [49,107,10]. In a GAN training, the loss function does not follow any pattern, so it is not possible to know the state of the networks by their loss function. This causes that, when a training is occurring, it is not possible to know when the models have been fully optimized.


### Evaluation metrics

Due to GAN's particularity, there is not an unique metric to measure the quality of the synthesized data [190]. One of the reasons of why there is no consensus among researches is the particularity of each GAN application. As mentioned in previous sections, GANs can be used to replicate any data distribution, but it depends on the particular problem how to measure the differences between the origin and synthesized distributions [17].

As there is not an unique universal metric to measure the performance of these kinds of models, during the last years there has been developed different metrics. Each metric has its particular strength and it should be noted that, in practice, different metrics are used and compared to measure different aspects and to have a wider view of the GAN performance [50].

Since there is not an evaluation metric that fulfills all GAN possible applications, we will review the most widely used metrics:


#### Inception Score (IS) and its variants

IS [150] measures the quality and diversity of the generated samples of a GAN.

To do so, it uses a pretrained neural network classifier called Inception v3 [165]. The model is pretrained using a dataset of real world images called Imagenet [36], it can differentiate between 1.000 of classes of images.

The IS is calculated by predicting the probabilities of the generated samples. A sample is classified strongly as one specific class means that it has high quality. In other words, it is assumed that low entropy and high quality data are correlated. The IS value varies between 1 and the number of classes of the classifier.

One of the main problems of the IS is that it cannot handle mode collapse. In this case, all generated samples by the GAN will be practically the same, but the IS would be very high if the images are strongly classified as one class. If this happens, the IS could be high and the real situation is very bad.

Other particularity of this metric is that it is designed to measure the quality of images since it uses an image classifier.

Based on IS, there are some modifications to the metric. For example, Mode Score (MS) [129] is a evaluation metric that takes into account the prior distribution of the labels over the data, i.e. it is designed to reflect the quality and diversity of the synthesized data simultaneously.

Other modification of IS is the modified-Inception Score (m-IS) [58]. It measures the diversity within the same class category output, trying to mitigate the mode collapse problem.

Some of them, like Fréchet inception distance (FID) [61] calculate the mean and covariance of the synthesized images and then calculate the distance between the real and generated image distribution. The distance is measured using the Fréchet distance, also known as the Wasserstein-2 distance. The FID is calculated as follows:
F ID = |µ − µw| 2 + tr(Σ + Σw − 2(ΣΣw) 1/2 )(2)
where w denotes the synthesized data of the G.

The FID is the most common used metric to measure the quality of generated images [79,77,78,33]. The use of a common metric for different architectures allows to compare different results using a common metric. In further sections we will go through different results comparing them using FID.

One of the strengths of using this metric is that it takes into consideration contamination such as Gaussian noise, Gaussian blur, black rectangles, swirls, among others.


#### Multi-scale structural similarity for image quality (MS-SSIM)

is based on the comparison between two image structures, luminance and contrast at different scales [181]. The MS-SSIM provides a metric that compares the similarity between the real and the synthesized dataset. One of the strengths of MS-SSIM is that it correlates closer pixels with strong dependence. In comparison with other metrics such as Mean Squared Error (MSE), that calculates the absolute error of an image,

MS-SSIM provides a metric based on the geometry and structure of the image.

The MS-SSIM scale is based on Structural Similarity Index Measure (SSIM), and this metric is calculated as follows:
SSIM (x, y) = [lM (x, y)] α M · M j=1 [cj(x, y)] β j [Sj(x, y)] γ j(3)
where x and y are two windows of image of common size, l is the luminance of an image, c the contrast and S the structure. The value of SSIM is a decimal between 0 and 1, the value of 1 represents two identical sets of data. Therefore, it is assumed that the higher value of SSIM, the higher quality of the synthesized images.

MS-SSIM is calculated using the average pairwise of SSIM with N batches. This metric is commonly used with IS or its variations [87] to provide a wider view of the generated data quality.


#### Classifier Two-sample Test (C2ST)

To measure the quality of the generated distribution, a binary classifier can be used [93]. The classifiers divide the samples into synthesized and real ones, judging whether different samples belong to the same data distribution.

It should be noted that this method is not constrained to image evaluation, since a classifier can be used to classify any given data distribution, it can be adapted to any type of input data. Neural networks can be used as a C2ST, as mentioned in previous sections, D is indeed a classifier of real and generated data. As is proposed in [109], a C2ST can be applied to GANs by using the same composition of the discriminator, as is said in the paper "training a fresh discriminator on a fresh set of data". C2ST-Neural Network (C2ST-NN).

Using C2ST, we can measure the distance between the synthesized and real data distributions. This provides a useful, human-interpretable metric of GAN performance. C2ST has been applied to different GANs architectures such as DCGAN or CGAN, using C2ST-NN and C2ST-1-NN [109].


#### Perceptual path length

Using the well-known neural network classifier VGG16 [155] the perceptual path length was designed [79] to measure the entanglement of images. 


#### Maximum Mean Discrepancy (MMD)

is used to measure the distance between two distributions [18]. A lower score for MMD means that the distributions that are being compared are closer, and that means that the synthesized data is similar to the original.

Given distributions P and Q and a kernel k. As it is defined in [94], MMD can be denoted as:
M k (P, Q) = ||µ P − µ Q || 2 H = E P [k(x, x )] −2E P,Q [k(x, y)] + E Q [k(y, y )](4)
It should be noted that this method can be used with any type of data.


#### Human rank (HR)

Human classification can be useful in some cases. Either to complement other evaluation metrics, either because there is not other metric that fulfills the particular problem, human evaluation of the generated data can be done.

Due to the particularity of this method, it can only be used when the synthesized data is comprehensive for a human.

For example, in [211,67] human classifications were applied via Amazon Mechanical Turk (AMT) to evaluate the realism of the outputs of the GAN. In this case, participants had to differentiate between the generated and real images. The more images that fool humans perception, the better.

This method can provide an approximation of how GANs creation would be perceived by humans.


## GAN variants

Since the first GAN was developed [51] there has been published many different variations of it [79,67,77,5]. To have a broad vision about recent GAN researches, we will review the recent progress in this field.

This section is divided into GAN models according to their main features. That said, we will divide the different GAN's variations in architecture modification based and loss function modification based.


### Architecture optimization

Some recent researches [79,77,211] are focused on the architecture of the GAN is designed. Some of them [77] suggest a change in GANs training, others [79] add changes to the structure of the G or D models.

Despite this, we will review traditional GAN's architecture, we will focus on models that are relevant for GAN recent development. It should be noted that the collection of architectures that we will review should not be considered individually.

GAN model evolution is supported by constant optimization. Therefore, to have a complete vision of GAN evolution, we will go through the different models that have been relevant in the last years.


#### Deep Convolutional GAN (DCGAN)

One year after, the first GAN was proposed in 2014 [51], the DCGAN was introduced [142] suggesting some changes to the original architecture. The main objective of the DC-GAN is to use convolutional layers instead of the firstly proposed fully connected layers.

The main change to the fully connected GANs is the substitution of the dense layers by convolutional layers. Convolutional layers have been used during the last decade for computer vision tasks. By applying different filters to the images, the convolutional layers are able to extract the main features of the matrix of pixels keeping the correlation between adjacent pixels.

Convolutional layers are used not only used for image processing, but there are recent projects [72] that use matrices of data to take advantage of using convolutional layers.

In addition to the convolutional layers, other changes were suggested to stabilize the GAN's training. Replacing the pooling layers by strided convolution has shown better performance [157,6]. Therefore, it is proposed to use strided convolutions in both G and D.

The use of batch normalization layers in both G and D is proposed, this has been shown to reduce the noise and improve the diversity of the generated samples [99,186].

To activate the convolutional layers, it is proposed to use a Rectified Linear Unit (ReLU) activation for the hidden layer of G, hyperbolic tangent (tanh) for the output layer of G and leaky rectified linear unit Leaky Rectified Linear Unit (LeakyReLU) for D.

In addition to the mentioned changes in the architecture of the GANs, the DCGAN paper also presents a technique to visualize the filters learned by the models. This helps the comprehension of GANs learning methods, confirming previous works related to biology [66].

This architecture supposes a change in how GANs are designed and trained. The innovations that were proposed in the paper are applied in most of the following GAN models.


#### Conditional GAN (CGAN)

Proposed in 2014 [121], the CGAN architecture adds a latent class label c along with the latent space. The new label is used to split the processed data into different classes, thus the synthesized data is generated according to the class of the input label.

There are some problems that require the generated data to be classified into different classes [108,113,97].

Despite being a simple technique, it has proven to prevent mode collapse. However, the training of a CGAN requires a labeled dataset complicating its application to some problems.

CGAN architecture has influenced GANs model since its proposition, there has been developed many variations [67,25,130].


#### Auxiliary Classifier GAN (ACGAN)

ACGAN [130] modifies the CGAN structure. The D of the ACGAN does not receive the class label c as an input, instead D is used to classify the probability of the image class. To train the model, the loss function must be modified, dividing the objective function in two parts, one for the correct source of data and the other for the class label. ACGAN loss function can be denoted as:
Ls = E[logP (S = real|X real )] +E[logP (S = f ake|X f ake )] (5) Lc = E[logP (C = c|X real )] +E[logP (C = c|X f ake )] (6)
where Ls is the log-likelihood of the correct data distribution and Lc is the loglikelihood of the correct class label.


#### Interpretable Representation Learning by Information Maximizing GANs (InfoGAN)

One of the mentioned deficiencies of conditional GANs was the requirement of a labeled dataset. InfoGAN [25] provides an architecture to train conditional GANs with an unsupervised method. To do so, the latent class label c is substituted by a latent code vector.

The latent space and the latent code are maximized by using the Mutual Information [154]. The mutual information term is not easy to calculate because it requires the posterior P (c|x). To optimize the training performance, an auxiliary distribution Q(c|x) is defined. Said so, the loss function of the InfoGAN is defined as follows:
min G,Q max D V Inf oGAN (D, G, Q) = V (D, G) −λLI (G, Q)(7)
where λ is a hyperparameter that is in charge of the latent code control. As it is proposed in the original paper [25] a λ equal to 1 is used when the latent code is discrete, for continuous latent codes a smaller λ should be used. The reason for that is to control the differential entropy.


#### Image-to-Image Translation with Conditional Adversarial Nets (Pix2Pix)

The main objective of the Pix2Pix [67] architecture is to do an image-to-image translation. That is, given an image from a domain A, transform this image to other domain B. For example, given a map of a street, transform the map to an aerial photo of the street on the map.

The Pix2Pix architecture is based on an autoencoder, but skips some connections.

This architecture is known as U-Net, and it is based on the idea of retrieving information at early stages of the network. The same approaches of skipping connections have been used before [60,164,210,71] showing great results and improving the network performance.

In addition to the new architecture, a new loss function is proposed that is denoted as:

LGAN
(G, D) = Ey[]logD(y)] +Ex,z[log(1 − D(G(x, z))](8)
As a follow-up of Pix2Pix, Pix2PixHD was proposed [105] improving the quality of the generated images. Many later works have used Pix2Pix [141,124,132,41] converting it to one of the most popular architectures of the last decade.

The immediate application of these algorithms to images has had a great impact on society, radically increasing its popularity thanks to the applications developed.


#### Cycle-Consistent GAN (CycleGAN)

Cyclic consistency is the idea that, given a data x from a domain A, if the data is translated to a domain B and translated again to the A domain it should be recovered the data x. In other words, if a sample is translated to a domain and recovered from that domain, it should not change. This process, where a data sample is transformed and recovered, is known as cycle consistency, and it has been widely used during the last decades [162,75].

This idea is the main base of CycleGAN [211]. The main strength of the application of cycles is that paired data is not a requirement. GAN architecture adds a new mapping denoted as F, its function is to do the inverse mapping to retrieve the original data. In other words, the function of F is F (G(x)) = x. To train the architecture, a new cycle consistency loss is proposed to train the so-called forward and backward cycle consistency. The cycle consistency loss is denoted as follows:
L cycle (G, F ) = E x p data (x) [||F (G(x)) − x||1] +E y p data (y) [||G(F (y)) − y||1](9)
Despite CycleGAN was first proposed for image-to-image translation, it can be used for any data translation.


#### Unsupervised Dual Learning for Image-to-Image Translation (DualGAN)

The architecture of DualGAN [196] is very similar to CycleGAN. As it was with the CycleGAN, the DualGAN does not require paired data to train its models. To learn the translation from one data domain to another, DualGAN has two pairs of identical G and D, each pair is responsible for their respective translation.

To stabilize the training and prevent mode collapse, the loss format of WGAN [5] is used. This marks the architecture of the network and the construction of the objective function.

In order to train each pair of G and D a reconstruction error term is defined. The reconstruction error objective is the same that it was in CycleGAN, calculating the distance between the original sample of data and its corresponding recovered sample.

The reconstruction error is defined as:
l g (u, v) = λU ||u − GB(GA(u, z), z )|| +λV ||v − GA(GB(v, z ), z)|| −DB(GB(v, z )) − DA(GA(u, z))(10)
while U and V are both domains, λU and λV are two constant parameters and z and z are both random noises. λU and λV are normally set a value within [100.0, 1, 000.0], when the domain U contains real images (e.g. a human face photo) and V does not (e.g. a sketch of human face), it is more optimal to use a smaller value of λU than λV .

DualGAN has been widely used and modified [194,138,100]. For example, in [175] a DualGAN architecture was used to transform an input speech emotion. In this application, given the Fundamental Frequency (F0) of a certain emotion, the trained network is capable of changing the emotion of the sound. To do so, F0 is encoded using wavelet kernel learning [195] using the same methodology as [111].


#### Learning to Discover Cross-Domain Relations with GANs (DiscoGAN)

DiscoGAN [81] is an architecture that follows the same structure as DualGAN and

CycleGAN. The particularity that DiscoGAN has is the usage of an autoencoder for the G. For D, it uses a classifier based on the encoder of the G.

Autoencoders have been used to other reconstruction problems [24,110,118]  A scheme of the progressive training of ProGAN can be seen in Fig.3.

Due to the explained training methodology, ProGAN is capable to stabilize the training of GANs, which is one of the most important GAN problems. In addition, In the proposed dynamic growing algorithm, each step chooses among different growing possibilities: grow G with a certain convolution layer, grow D with a certain convolution layer, or grow both G and D to a higher resolution. A scheme of the training methodology can be seen in Fig.4. If all children were preserved in each step, it will produce an exponential growing that would lead to large inefficiency. To avoid that, before the children generation, a prune is made. Known as greedy prune, the prune is done by keeping the top K children of each generation. Then each child becomes a parent and generates a new batch of children. The process repeats until the network grows to the desired size.

In the original research, the child search was made combining different kernel sizes and number of filters, each parameter is known as an action, and the number of total actions is denoted as T . It can be easily noted that different hyperparameters can be searched by using this algorithm. To avoid a large increment of the number of children, the algorithm proposes a probability p of a child to test a new parameter. A higher K, T and p means a wider search, contributing to a better exploration of the candidates but a slower training.

It should be noted that the search algorithm lacks the efficiency of the architecture by having to do multiples training simultaneously. It also lacks the ability of growing, due to the quick growing of the number of networks.


#### A Style-Based Generator Architecture for Generative Adversarial Networks (StyleGAN)

StyleGAN [79] is based on the idea that, improving the processing of the latent space, the quality of the generated data will improve. Due to the particularities of the latent space, there are many interpolations on the variables [149,90] that produces entanglement in the learned characteristics of the G. The architecture of the StyleGAN is based on previous style transfer researches [65].

With the architecture of StyleGAN, G is capable to learn different styles of the input data disentangling high-level characteristics. This produces an improvement on the quality of the generated data and helps in the interpretation of the latent space, previously poorly understood. Controlling the latent space leads to better interpolation properties, enabling interpolation operations in different scales, e.g., interpolation of poses, hair or freckles in human face images.

In the StyleGAN architecture, the input of G is mapped to an intermediate latent 
space called W ,

#### Alias-Free GAN

During the last years, multiples architectures have been improving the quality of the synthesized images. The previously mentioned StyleGAN achieved one of the best results in image generation, producing images of human faces with a quality never seen before. Besides its good results, some problems remain opened.

One of the most visible problems that generated images of StyleGAN had was the known as texture sticking. It happens when a certain image feature depends on absolute coordinates instead depending on other feature localization. E.g. the texture of the beard of a human face seems stuck when interpolating different images. The texture sticking problem is noticeable especially when interpolating images, e.g. changing the posture of a human face image.

Alias-Free GAN [78] focus on solving the texture sticking problem of the StyleGAN.

The main idea is to suppress the alias in the generated images, this way the finer details will be attached to the underlying surface of the image. To achieve this, each layer of G is designed to be equivariant by applying rotations and translations to the continuous input.

To achieve an equivariant G, many changes have been made. A 10-pixel margin is used for the internal representations, due to the assumption of infinite spatial extension for the feature maps. The Leaky ReLU layers are wrapped between an upsampling and a downsampling, this is implemented with a CUDA kernel for optimization. The cutoff frequency of the StyleGAN is cut off to ensure the alias frequencies are in the stopband. In addition, the learned input constant of StyleGAN is substituted by Fourier features [166,192]. Finally, the rotation equivariant version of the network is obtained by reducing the kernel size of 3 × 3 convolutions to 1 × 1 and changing the sinc-based downsampling to a radially symmetric jinc-based one.


#### Self Attention GAN (SAGAN)

SAGAN [199]  SAGAN uses self attention layers [174], these layers are capable to capture structural and geometric features of multiclass datasets. The feature maps of each convolution are split into a 1 × 1 convolution in query, key and value, then they are multiplied to construct the output of the layer. This way the network can learn long-range dependencies. The structure of the self-attention layer can be seen in Fig.5. 


#### BigGAN

The BiGAN architecture [19] focuses on generating high resolution images from diverse datasets. Previous models results were able of synthesize new samples of low dimensionality, they had problems when scaling their results to bigger samples. The results achieved by the BigGAN, in terms of FID and IS outperform previous models.

The researches of the BigGAN claim that GANs have better performance when they use higher dimensional data. The architecture of the BigGAN is based on the SAGAN [199] architecture. The authors show that, by enlarging the number of channels of the images used by a factor of 50%, the IS improve by a factor of 21%.

One innovation proposed in this article is the so-called "Truncation Trick". Previous GAN models used a normal or uniform distribution to generate the latent space of the G network. The authors claim that by using a truncated normal distribution the results, in terms of FID and IS, were better. This truncation trick reduce the variety of values of the latent space by truncating them towards zero. The main drawback produced by this is that the variability of the generated samples is reduced. It exists a relationship between the variety and fidelity of the generated samples using this truncation. The more truncation applied to the latent space, the less variety of images were produced.

Other aspect that is scaled up in this work is the batch size of the GAN training, increasing it by a factor of 8. The authors show that by using larger batches the gradients of each iteration are better, reaching a better performance in less steps.

This is caused because the composition of each batch is more diverse, being able of covering more modes of the data.


#### Your Local GAN (YLGAN)

YLGAN [33] proposes a new attention layer that substitutes the SAGAN dense attention layer [199]. 


#### A GAN Through Quantum States (QuGAN)

During the last decade, quantum computing has become a hot topic in computer science. Since it was proposed in 1980 [14] it has always been restricted to a few laboratories around the world. Thanks to the progress made recently [114], it has made possible to test the first algorithms, prototypes and ideas [22].

Thanks to quantum computing particularities, problems previously defined can be solved, or are optimized, reducing their computation time. Using quantum superposition, the multiples solutions can be evaluated simultaneously, then by using quantum interference and entanglement the correct answer can be defined.

QuGAN [158] proposes a GAN architecture powered by quantum computing. By using quantum computing, GANs are hugely optimized, reducing a 98.5% of its parameter set compared to traditional GANs.

QuGAN architectures use qubits to create the quantum layers of G and D, known as QuG and QuD. The data that the networks use is transformed into quantum states.


#### Entangling Quantum GAN (EQGAN)

EQGAN [128] proposes a variation of the previously proposed quantum GANs.

Benefiting from the entangling properties of quantum circuits, EQGANs guarantees the convergence to a NE.

The main particularity of EQGAN is that it performs quantum operations on both synthesized and real data. This approach produces fewer errors than swapping the data between quantum and classical.

To apply EQGAN to real problems, a Quantum Random Access Memory (QRAM)

is used. By using the QRAMs, the EQGAN is capable to improve the performance of the D.


#### Classification Enhancement GAN (CEGAN)

Data imbalance is a common problem when using real world datasets. Dataset often contains a majority of samples of a certain data class. In the case of GANs using unbalanced datasets, the imbalance problem results in poor quality of the synthesized data of the class with less samples.

CEGAN [160] tries to solve the data imbalance problem in GAN. The objective is to enhance the quality of the synthesized data and to improve the accuracy of the predictions.

The CEGAN architecture consists of 3 different networks, G, D and a new network known as the classifier (C). The training of the CEGAN divides in two steps. In the first step, the architecture is normally trained, using D to differentiate between fake and real samples, C is used to classify the class label of the input sample. Then, in the second step, an augmented training dataset is formed via generating new samples from G, and this new dataset is used to train the C.

The methodology presented in CEGAN substitutes previous techniques to deal with data imbalance. Unlike other methods such as undersampling [126] or oversam- 
L spectral = E x∼p data (x) [logC(φ(x))] +E x∼pg (x) [log(1 − C(φ(x)))](11)
One of the strengths of the SSD-GAN is its simplicity, easing implementation and allowing its implementation on various network architectures without excessive cost.

The 


#### Mobile Image Enhancement GAN (MIEGAN)

The MIEGAN [135] presents a novel architecture that aims to improve the quality of images taken with a mobile phone. To do so, two new networks are proposed, the so-called multi-mode cascade generative network and the adaptive multi-scale discriminative network. The generative network is composed of an Autoencoder architecture. The encoder of this new generator is divided into two streams, the inclusion of the second encoder is in charge of improving the low luminance areas, where mobile phones particularly lack in their clarity.

The discriminator network has a dual goal. First, the global discriminator ensures overall image quality. Second, a local discriminator maintains the local quality of small areas of the image. To combine both objectives, an adaptative weight allocation module is also proposed that is responsible for balancing the importance of each discriminator.

A brief scheme reviewing all presented architecture variant GANs can be seen in 


### Loss function optimization

Orthogonal to the architecture modification GANs, there are many researches [5,140,116]   other.

In this section, we will review the different most important and recent progress in variations of the loss function of the GANs.


#### WGAN

The base of the WGAN [5] is the application of the Earth Mover (EM) distance, also known as Wasserstein-1 distance. The Wasserstein distance is defined as:
W (Pr, Pg) = inf γ∈Π(Pr ,Pg ) E (x,y)∼γ [||x − y||](12)
In other words, the Wasserstein distance calculates the cost of transforming the distribution Pr to the distribution Pg. In the case of GAN, the Wasserstein distance will measure the difference between the real and synthesized data distributions.

In order to apply the new objective function, some changes must be applied to the architecture of GANs. The D of the GAN changes its objective, but previously D was used to distinguish which data was real and which was synthesized in WGAN D change its name to critic. The critic function is to measure the realness of an image, e.g. the probability that the image belongs to the real distribution. The weight change of the critic is fixed between a window (e.g. between [-0.01, 0,01]) after each gradient update. The weight clipping is done to make the parameters lie in a compact space, due to the change of the critic network.

The EM distance has shown to produce better gradient behavior than other met- 


#### WGAN-GP

In the original paper of WGAN, the authors suggest that weight clipping is "a terrible way to enforce Lipschitz constraints". Weigh clipping is one problem that the original WGAN had, but it worked well enough and its implementation was easy. The WGAN-GP [55] proposes a new technique to substitute the weight clipping that leads to the WGAN with undesired behavior.

The proposed change involves constraining the critic gradient norm output regarding to the input of the network. The constraint is softened via a penalty on the gradient norm. say that the new loss function is denoted as follows:
L = E∼ x Pg [D( ∼ x)] − E x∼Pr [D(x)]+ λE∧ x∼P ∧ x [(||∇∧ x D( ∧ x)||2 − 1) 2 ](13)
The new change makes the WGAN-GP optimize its training, stabilizing it with almost no hyperparameter tuning. The new loss function also improves the quality of the generated images over WGAN and converges faster.


#### Loss-Sensitive GAN (LS-GAN)

In order to measure the quality of the synthesized samples of data created by G, a new loss function is used in the LS-GAN [140]. The new loss function aims to use regularization theory to improve the performance of GANs architecture. The main idea behind the new loss function is that a real sample produces smaller losses than a synthesized one, the margin between both is predefined. Once this assumption is set, we can infer that the training of G must aim at minimizing the loss margin between real and synthesized images. The proposed loss function is denoted as follows:
min D LD = Ex∼p r L θ (x) + λEx∼p r z∼pz (∆(x, G(z)) +L θ (x) + L θ (G(z)))+ (14) min G LG = Ez∼p z L θ (G(z))(15)
where λ is a hyperparameter for balancing and θ are the parameters of D.

The loss function is regularized via Lipschitz regularity condition over the density of the real data. Due to the regularization, the created models are better in generalization of new data.


#### Least Square GAN (LSGAN)

The new loss function presented in LSGAN [116] aims to reduce the vanishing gradient problem. The main objective of the LSGAN is to punish the synthesized samples that are far from the real data but still in the correct side of the decision boundary. The least squares loss function is denoted as follows:
min D VLSGAN (D) = 1 2 E x∼p data (x) [(D(x) − b) 2 ] + 1 2 E z∼pz (z) [(D(G(z)) − a) 2 ](16)min G VLSGAN (G) = 1 2 E z∼pz (z) [(D(G(z)) − c) 2 ](17)
where a and b are the labels for fake and real data respectively and c is the label that G wants D to believe is real data. It should be noted that the square of both equations is responsible for punishing far from the decision boundary samples.

The LSGAN tries to generate more gradients while penalizing samples that lie a long way from the decision boundary. This way the gradients are forced to be higher, preventing the gradient vanishing problem. Compared to the classical sigmoid cross entropy loss function of GANs, the new least squares loss is flat only at one point as we can see in Fig.8. 


#### Unrolled GAN (UGAN)

The UGAN [119] loss function is defined to prevent instability in GANs training.

The idea behind UGAN is to dynamically adapt G and D to prevent the situation of unbalance, where one of the networks is more trained than the other. Commonly, due to the particularity of the problem to solve, the D problem is easier to solve than the G one, producing an imbalance in favor of the D.

The training of UGAN is dynamically changed, the presented loss is surrogated for training the G. The surrogate objective function is created by unrolling K steps of D for each update of the G. Using the proposed loss function, the G behavior adapts to the training state of the D. The surrogate loss function is defined as follows:
dfK (θG, θD) dθG = ∂f (θG, θ K D (θG, θD)) ∂θG + ∂f (θG, θ K D (θG, θD)) ∂θ K D (θG, θD) dθ K D (θG, θD) dθG(18)
With the application of the proposed loss function, the UGAN demonstrates to stabilize the training by adjusting and synchronizing G and D networks. Furthermore, it prevents mode collapse, avoiding the model to drop regions of the data distribution.

Despite this, the most important weakness of the UGAN is its computational cost.

When the generator loss is optimized, the performance of the network drops. It depends on the particular problem how many unrolls need to stabilize its training. In the original paper, for example, it varies between 1 and 10. 


#### Realness GAN

where A0 and A1 are the fake and real distributions.

Using the new loss function, the RealnessGAN is capable of recovering more modes than a standard GAN, preventing mode collapse. Furthermore, RealnessGAN shows a better performance, generating higher quality images in both real-world and synthetic datasets.

One of the strengths of the RealnessGAN is its simple implementation, due to the fact that RealnessGAN is a generalization of the original GAN. That said, despite being one of the most recently proposed architectures, it is expected to be widely used due to its good results and easy implementation.


#### Spectral Normalization for GANs (SN-GAN)


## SN-GAN [122] proposes a new technique to normalize the weights of D networks.

A more stable training is searched through spectral normalization.

Respect previous normalizations [151] spectral normalization is easier to implement. The previous methods imposed a much stronger constraint on the network matrix. With the spectral normalization, it is possible to relax this constraint, allowing the network to satisfy the local 1-Lipschitz constraint. The spectral normalization is defined as follows:W
SN := W/σ(W )(20)
where W is the weight matrix of D and σ(W ) is the L2 normalization of W.

As mentioned before, the proposed D network is very simple and additionally its computational cost is small. It also requires the tuning of one hyperparameter, the Lipschitz constant.

The generated images using SN-GAN are more diverse, achieving better comparative IS respecting other weight normalizations.


#### Cyclic-Synthesized GAN (CSGAN)

CSGAN [76] proposes a new loss function for image-to-image translation problems.

Previous works developed architectures for concrete domains of translation, CSGAN proposes a common framework for different domain translation.

The Cyclic-Synthesized Loss (CS) is proposed as the objective function of CSGAN.

The new loss objective is to evaluate the differences between a synthesized image and its correspondent cycled image. The proposed loss function is denoted as follows:
L(GAB, GBA, DA, DB) = LLSGAN A + LLSGAN B +λALcyc A + λBLcyc B + µALCS A + µBLCS B(21)
were LCS A and LCS B are the Cyclic-Synthesized loss of both domains.

With respect to previous architectures, CSGAN produces images of better quality, notably reducing the artifacts of the synthesized images. The results show better performance of CSGAN in Chinese University of Hong Kong (CUHK) dataset [179] and comparable performance in FACADES dataset [171]. The comparison of the performance is made against GAN [51], Pix2Pix [67], DualGAN [196], CycleGAN [211] and Photo-Sketch Synthesis using Multi-Adversarial Networks (PS2MAN) [178].


#### Multi-IlluStrator Style GAN (MISS GAN)

The proposed architecture of MISS GAN [11] presents only one trained model to  To train the MISS GAN models five different objective functions are proposed.

The first loss function is called the adversarial objective (L adv ) and it is in charge of, taking the input image and the target domain, ensure that the generated image style corresponds with the target domain. To do so the L adv takes two discriminator predictions, one for the input image and other for the synthesized image.

The second loss function is denoted as style reconstruction objective (Lsty), and it enforces the G to use the mapping network style code while receiving a generated latent code, to calculate the Lsty the output of the G encoder over the generated image.

The third proposed objective function is called style diversification objective (L ds ) and it compares a pair of synthesized images, each image corresponds to a different style code, each one generated from a different latent code. The objective of this loss function is to force G to produce diverse images, preventing two images with different latent codes from being the same.

The fourth objective function is the cycle consistency loss (Lcyc) used in the Cy-cleGAN [211].

Finally, the fifth objective function is called content features loss (L content f eat ), and it computes the distance in the feature space by using a VGG16 [155] network.

To combine the different objective function a total objective is defined as follows:
max D min G,F,E L adv + λstyLsty − λ ds L ds
+λcycLcyc + λ f eat L content f eat (22) where E is the style encoder and F is the mapping network, all the λ parameters correspond to a hyperparameter for each objective function. 
min G max D r Ex[d r s (N, D(x))] − r Ez[d r s (N, D(G(z)))](23)
where d r s denotes the r-th moment distance between a sample and the north pole of the hypersphere. 


#### Super Resolution GAN (SRGAN)

In order to apply GANs to image upscaling the SRGAN [92] was proposed. The proposed GAN objective is to take an input natural image and upscale it resolution by a factor of 4.

To achieve the super resolution, the new variant proposes a couple of adversarial and content losses. Both functions are combined using the called perceptual loss function, this function is in charge of ass solution respecting the relevant characteristics of the data. The content loss is defined as follows:

l SR = l SR X + 10 −3 l SR Gen l SR Gen (24) where l SR Gen is the adversarial loss and l SR X is the content loss. The content loss used relies on a pre-trained VGG-19 model [155]. This model, respecting the usage of a loss function such as MSE is more invariant to changes in pixel space. This metric will provide the network information about the quality of the content of the synthesized image. The new loss function is calculated as:
l SR V GG/i,j = 1 Wi,jHi,j W i,j x=1 H i,j y=1
(φi,j(I HR )x,y −φi,j(G θG (I LR ))x,y) 2 (25) where I LR refers to the low resolution images and I HR refers to the high resolution image.

In addition to the content loss, the adversarial loss is defined as being this part of the generative component of the GAN. This function is responsible for pushing the generated images to be realistic and indistinguishable from the real ones. The loss function is defined as:
l SR Gen = N n=1 −logD θD (D θG (I LR ))(26)
The application of SRGAN improves the results of previous algorithms for image super resolution.

Since the introduction of the SRGAN it has been used in many different applications [203,35,209]. In addition, there are works such as [103] that presents some improvements in the SRGAN structure, the new architecture is known as Super Resolution Channel Attention GAN (srcaGAN). The architecture presented in this papers adds a channel attention module to the models, this module recovers the attention layer used in SAGAN [199]. The results presented in this new architecture outperforms the SRGAN.


#### Weighted SRGAN (WSRGAN)

One of the characteristics of the SRGAN [92] was the combination of the content loss and adversarial loss during the training. The WSRGAN proposes is changing the importance of each loss and studying the effect of this action.

The main objective of the WSRGAN is to improve the performance of the architecture by analyzing its performance in different combinations of its objective functions.

Then the new weighted loss function is defined as follows:
l SR X = wl SR M SE + (1 − w)10 −3 + l SR V GG(27)
where w is the parameter that controls the impact of each loss function on the final result.

After training the network with different weight configurations, the paper concludes that the MSE loss is the most important loss function, being supported by the VGG loss.

Additionally, the definition of the weight parameter is declared dynamically, obtaining even better results than when it is static.

A brief scheme reviewing the different presented loss function variant GANs can be seen in Fig.10. We divide the different GANs in different groups based on the proposed changes in the loss function. 


### GAN timeline

A timeline with the reviewed architectures is presented in figure 11. The GANs that  


## GAN applications

As mentioned before, GANs are one of the most popular applications of machine learning of the last years. GANs models can achieve results in fields where previous models could not, in other cases, GANs improve the previous results significantly.

In this section, we will review the most important fields where GAN architectures are applied, paying a special attention to the GAN models related to computer vision tasks and we will compare the different architecture results.

Most of the last researches focus on how to apply GANs to generate new synthesized data, replicating a data distribution. But, as we will review in this section GANs can be applied to other fields, e.g. video game creation [80].


### Image synthesis

One of the most important fields in which GANs are applied is in computer vision. In particular, realistic image generation is the most widely used application of GANs [79,77,5].

Most of the proposed GAN variants are tested by generating real world images.

Arguably, image synthesis is the first application one might think of when thinking about GAN. Its popularity is due to the good results that GAN can achieve. Compared with previous methods, GANs provide sharper results [47]. Both in academic world and for the general public GAN has raised a lot of interest.

One of the main reasons of the GAN success is its results easy understanding.

As the mainly generated output of GANs are images, they can be easily understood by anyone. Even if a person does not have any technical understanding of artificial intelligence, it is possible to judge the results.

Within computer vision, image generation is the most used method to test GANs.

There are plenty of real world images datasets that can be used to train GANs. The availability of datasets that can be used for training neural networks is usually the main drawback of artificial intelligence projects. Either by its availability or by its content [37] having a good dataset is essential for machine learning. When real world images are used to train GAN models, the availability of good datasets is not a problem, there are a large variety of datasets [36,86] that have been widely tested and are well known in the academic community.

Since the first GAN publication [51] GAN architectures have been used for synthesizing real world images. In the original proposed GAN the models were used to generate images replicating MNIST [91], CIFAR-10 [86] and Toronto Face Database (TFD) [163] datasets. The generated images using the original structure were very blurry and did not have good quality. Besides that, the presented results supposed the presentation of the GAN architecture.

One of the first improvements to the original architecture was the DCGAN [142], it proposed structural changes and hyperparameter tunning respect the first proposed model. The results of the DCGAN showed improvements in the performance and generation of the networks, the generated images were clearer and more recognizable.

Despite that, the architecture still suffered from instability and mode collapse.

The WGAN architecture [5] could reduce drastically the mode collapse and instability of the previous models. Thus, later models adapted the loss function of the WGAN along with their respective structural changes in the network. The Table 2 summarizes the performance of the presented GAN models during this section. The compared datasets are MNIST [91], TFD [163], CIFAR-10 [86], CelebA-HQ [77] and Flickr-Faces-HQ (FFHQ) [79]. The used metric for comparing the different variants are accuracy of the models (the higher score the better ↑), IS (the higher score the better↑) and FID (the lower score the better ↓)


### Image-to-image translation

Taking an image from one domain and converting it to the other domain is known as image-to-image translation. It was first proposed with the Pix2Pix architecture [121], Pix2Pix is based on CGAN following the idea of generating images conditioned on their composition via a label input. With Pix2Pix the networks are capable of learning how the same image is translated between one domain and another.

The main drawback that Pix2Pix had was the requirement of having a paired dataset of images in both domains.

Following the steps of Pix2Pix CycleGAN [211], DualGAN [196] and DiscoGAN [81] were developed. These new architectures were based on the cyclic consistency idea.

Cyclic consistency was previously used in machine learning [162,75], it is based on the idea that translating an image from one domain to another and then doing the reverse operation will recover the original image. Following this concept the new networks were capable of translating images without a paired dataset. By not needing a paired dataset the number of possible applications of GAN to image-to-image translation increased considerably.

Later on the CSGAN was proposed [76] improving the results of previous architectures. The new proposed loss function achieved better results in image generation, comparing with CycleGAN [211], DualGAN [196], DiscoGAN [81] and PS2MAN [178]. behind GAN applications they act as a catalyst to make more people interested in artificial intelligence and, ultimately, it will bring more people to academic research in the field.

The Table 3 summarizes the performance of the presented GAN models in imageto-image translation tasks. The data is obtained from [76], where the SSIM (the higher score the better ↑), MSE (the lower score the better ↓), Peak Signal to Noise Ratio (PSNR) (the higher score the better ↑) and Learned Perceptual Image Patch Similarity (LPIPS) [205,101] (the lower score the better ↓) are computed for different GAN variants. The comparison is made for CUHK [179] and FACADES [171] datasets.

The LPIPS is a metric that measure the distance between the real and the generated distribution via perceptual similarity. 


### Video generation

GANs have proven to generate state-of-the-art results in image processing. Along with image generation comes the possibility to generate a set of images generating a video. Video generation is a more complex task than image generation. The issues associated with image generation are included in video generation, but the computational cost of training models that can process video is high. In addition, the synthesized videos must be coherent.

One of the particular problems of video is the motion blur generated by the networks [57]. When a video is generated, the tracking of some objects can be difficult, generating fuzziness in some portions of the image. Some works have tried to tackle this problem [204,197,146], but it is still an open problem.

One of the most popular applications of video generation with GANs is the known as deep fake. Deep fake consists in taking a video of a person and changing the face of the human to be someone else. Many works have been developed in the last years in this field [183].

Deep fake is one of the most controversial applications of GAN, the possibility of changing a face in a video allows to generate fake videos that can be used to supplant a person. This problem is magnified in the case of women [117] due to their position in society. Even so, there are some applications of deep fake where it can be beneficial [89], its application still raises doubts in the society. This is why many recent researches have focused on how to detect deep fake videos [84,40,23,208].

Other application of GANs to video generation are video-to-video translation, which is indeed the general case of deep fake. Many architectures of this type have been proposed during the last years [27,9].

It should be noted that, in the case of video processing, the standard is to use previous information, such as another video, to generate the synthesized data. Unlike image generation, video generation is more interesting if the new information is conditioned by an external agent. In image processing, the only input was the latent space, but the final images were conditioned by the dataset of the training. When videos are generated, the degree of freedom is extended, enabling the generated data to be less controlled. Controlling the video output is necessary to maintain the coherence of the final output, but it also eases the GAN job, which is significantly more difficult with respect to image processing.


### Image generation from text

Since the introduction of CGAN the capabilities of GANs were expanded. The possibility of constraint the synthesized information that GANs produced made the networks have a wider range of application. By controlling the output of the generations of the networks the applications of them can be much more specific and interesting. One field were GANs have shown to outperform previous techniques in image generation from text [88].

Stacked GANs (StackGAN) [201]  The Table 4 summarizes the performance of the presented GAN models during this section. In addition to the mentioned networks the Generative Adversarial Text to Image Synthesis (GAN-INT-CLS) [144] and the Generative Adversarial What-Where Network (GAWWN) [145] are included, both of this networks act as a reference of previous architectures. The compared metrics are HR (the lower score the better ↓), IS (the higher score the better ↑) and FID (the lower score the better ↓). The compared datasets are Common Objects in Context (COCO) [102], Caltech-UCSD Birds (CUB) [176] and Oxford-102 [127].


### Language generation

GANs models have been used during the last years in Natural Language Processing (NLP) tasks. The previously mentioned text-to-image field is one of the applications of GAN where natural language is involved. But there are some applications of GAN completely focused on how to produce new text using the models.

Previous methods to process natural language used the known as Long Short-Term

Memory (LSTM) [64]. LSTM is capable of maintaining local relationships in space The textGAN approach to language generation, suffering from the known as exposure bias. This bias is caused by the objective function of the network, that focus on maximizing the log likelihood of the prediction. The exposure bias is visible in the inference stage, when the G generates a sequence of words iteratively predicting each word based on the previous ones. The problem comes when the prediction is based on words never seen before in the training stage. Some works were made to tackle this problem [13] but the Sequence GAN (SeqGAN) [198] is the architecture that betters the results produced.  [20]. The results of the SeqGAN shows a huge improvement in tasks such as language generation, poem composition and music generation. In addition, the performance of the models shows certain creativity in the synthesized data.

Despite the good results of GAN in NLP tasks during the last years, there have been developed architectures that outperform GANs in language generation. The most successful architecture of this field is the Generative Pre-trained Transformer 3 (GPT-3) [44], which belongs to the GPT-n series. The GPT-3 is a generator model based on the transformer [174] architecture. The extraordinary results presented by the GPT-3 are often very difficult to distinguish from human writing. The emergence of the GPT-3 caused a lower interest in GAN models applied to NLP. Due to the good results of transformers in NLP, the GAN approximation to this field has been losing interest.


### Data augmentation

Other field where GANs have shown to be really useful is in data augmentation.

Due to the particularities of the GAN they can be used to obtain more samples of an origin data distribution, replicating its distribution. This way, by using GANs, the number of samples of a dataset can be multiplied.

Traditionally, data augmentation was achieved via transforming the initial data; e.g. cropping, rotating, shearing, or flipping images. One of the main drawbacks of these methods is that they transform the original data by slightly changing their structure, with the usage of GANs for data augmentation the new samples tries to synthesize new data from the original distribution. Instead of changing the samples of the dataset the generated samples of GAN are synthesized from scratch. This way, the new data is replicated by imitating the original data distribution. It should be noted that data augmentation does not necessarily replace other methods of data augmentation, it proposes an alternative that, in many cases, can be used together with other data augmentation algorithms.

For example, the Data Augmentation Optimized for GAN (DAG) [170] proposes an enhanced data augmentation method for GAN, combining it with data transformation such as rotation, flipping or cropping. The DAG shows to improve the performance of data augmentation in GAN models, improving the FID of CGAN, Self-supervised GAN (SSGAN) and CycleGAN. The proposed architecture uses one D for each transformation of the data, but a unique G.

Data augmentation with GANs have been used in cases where obtaining a dataset is difficult. For example, in medical applications there is usually not many information available, in this cases GANs can make the difference. This is why during the last years

GANs have been used in medical data augmentation [45,82,139,59].


### Other domains

As mentioned before, due to the particularities of the GANs they can be applied to many different fields. One of the main strengths of the machine learning is that it adapts to different situations without substantial changes in its structure. In particular, GAN can be adapted to any type of data distribution as long as there is an available dataset.


#### GameGAN

One of the most interesting applications of GAN is the presented with the GameGAN [80].

The main purpose of GameGAN is to generate entirely a video game using machine learning. To do so, the complete Model-View-Controller (MVC) software design patterns is replicated using artificial intelligence. The proposed architecture is composed by three different modules.

The dynamics engine is in charge of the logic of the whole system, maintaining the global coherence and updating the internal state of the game. The dynamics engine, for example, controls which actions of the game are possible (e.g. eating a fruit in pac-man) and which ones are not (e.g. run through a wall in pac-man). The dynamics engine is composed by an LSTM that updates the state of the game in each frame, the LSTM provides the network way to control the previous states of the game to calculate the new information of the subsequent frames. This way, the network can access to the complete history of the game, maintaining the consistency of the system.

To save the state of the game a memory module is used. This module focus on maintain long-term consistency of the game scene. When the game is being played there are different elements of the scene that not always are visible, with the memory module these elements are consistent over the time. This memory remembers the generated static elements of the game. The memory module is implemented by using Neural Turing Machine (NTM) [52].

The third module that composes the system is the rendering engine, it is in charge of generating a visualization of the current state of the game. This module focuses on representing the different elements of the game realistically, producing disentangled scenes. The rendering engine is composed by transposed convolution layers that are initially trained using an autoencoder architecture to warm up the system and then they train along with the rest of the modules.

The adversarial training of GameGAN has three types of discriminators. The single image discriminator evaluates the quality of each generated frame, judging how realistic it is. The action-conditioned discriminator determines if two consecutive frames are consistent with respect the input of the player. Finally the temporal discriminator maintains the long-term consistency of the scene, preventing elements from appearing or disappearing randomly.

One of the basis of GameGAN is the disentangling of dynamic and static elements of the game. The static elements of a game could be, for example, walls while the dynamics elements of a game are elements such as nonplayable characters. By disentangling both types of elements, the game behavior is more interpretable for the model. 


#### Medical imaging GANs

One of the most popular application of the GAN architecture is to enlarge datasets.

The objective of synthesizing new data is to produce larger datasets that improve the performance of machine learning models, which are very sensible with the number of samples used in their training.

There are many fields where data augmentation can be applied, but in medical imaging to augment data have certain benefits due to the particularities of the problem.

First, the medical datasets are usually small, because of the cost of obtaining the images, most of the time it is necessary to use measurement and recording machines such as radiography, magnetic resonance or ultrasound. But, in addition to the cost of obtaining these images there also exists ethical and legal problems related to the nature of the data. Most of the time, obtaining images that expose the health status of different people is impossible, which leads to even more lack of available data.

It should be noted that one of the benefits of generating data with GAN is that the new samples do not belong to any real person.

Because of all these factors, there has been lots of GAN works related to the medical imaging field [56,123,172,153,85,188]. In addition, the work of Chen et al. [28] analyses the evolution of the field of medical data augmentation and suggests that the research in this field remains strong in the year 2021, despite that the fact that from 2019 onwards the number of published works have been the same.


#### GANs in agriculture

Similar to the medical imaging field, obtaining images to train the computer vision models of agricultural image analysis is not an easy task. These models benefit from having large-scale balanced datasets but the cost of obtaining high quality labelled data makes the data augmentation a crucial task in these datasets.

Many different GAN models have been applied to agricultural data, such as [95,191,69]. These works aim to generate new images of plant with different diseases, augmenting the number of samples by using GAN.

In these cases the use of GAN improves the results of the machine learning models by enlarging the number of available data. The agricultural images have different particularities that make the analysis of them a difficult task. For example the biological variability between two samples of the same specie makes crucial to have many different samples to learn all the modes of the data. In particular, the same leaf of a fruit can drastically differ from one individual to another.

Other important factor is that the labelling of the data can be very costly, specially for specific applications such as the disease detection of certain plant, e.g. tomato leaf [95].

In addition, the environment where the images are taken, most of the time in crops, can lead to many variance in the images, such as lighting changes or object occlusion.


#### Drug discovery using GANs

The process of discovering and designing new drugs has recently been impulsed by the field of Deep Learning [70,32]. In particular, GANs are an useful technique to synthesize new useful samples of data. In the drug environment, the GAN architecture can process the drug compound using graphs or Simplified Molecular Input Line Entry Specification (SMILES), to then generate synthetic samples of drugs.

Due to the flexibility that ANNs have in terms of operating with different data types, it is possible to use the same architectures in different fields. In this case the overall GAN design can be adapted to molecular data, being able to transfer the same principles of the image generation to new data types.

The research followed by Kadurin et al. [73,74] generates new drug compounds for anticancer therapy, using biological and chemical datasets. In particular, in [74] it is used an Adversarial Autoencoder that uses molecular fingerprints as inputs of the network. By using this architecture the researches are able of define the desired properties of the synthesized drugs. Some of the new synthetic drugs discovered by the Deep Learning architecture corresponded with previous known anticancer drugs.

This led the researches to suggest that the remaining unknown drugs generated by the GAN could be used to further study their properties.

The work presented in [131] proposes the generation of new drugs combining GANs with reinforcement learning techniques. In particular, the proposed G takes as input a random latent space and process it with RNN to produce a sequence of drug by using SMILES representation. The D on its side uses a 1 dimensional CNN to distinguish the real data from the synthesized one. The results of the paper suggest that the new drugs discovered were unique and diverse. This may alleviate the first phases of drug development, which are very expensive in terms of time.

The Federated Generative Adversarial Network for Graph-based Molecule Drug Discovery (FL-DISCO) architecture [115] aims to combine the generation potential of GAN with the processing of molecules using graphs of the Graph Neural Networks while maintaining the privacy of the data using Federated Learning [83]. By using graph representation of the molecules instead of SMILES as previous works, the represented samples have more realistic structures, maintaining structural relationships of the connected atoms of the molecules. The Federated Learning framework is based on using different clients to train a specific neural network model, each client has its respective portion of the data, which uses to train the network. This way each client knows a portion of the data and uses it to update the central model, but it maintains the privacy due to the fact that the clients are not able to communicate with each other. The results of this research show progress in terms of novelty and diversity of the synthesized drugs respect previous works.


## Discussion

Since their introduction in 2014 GANs have been the most important generative architecture in computer vision. The results provided by the developed GANs were notoriously better than previous architectures, such as Variational Autoencoders. This leaded to a constant improvement of the model, solving problems like stabilization or mode collapse.

With the introduction of the Diffusion models [38,63,156], the results of GANs have been surpassed by this new models solving some of its most important problems.

Some aspects in which diffusion models outperform GANs are better stability, they do not suffer from mode collapse and they provide more diverse results. This is mainly caused because of the fact that they are likelihood-based [30]. Despite the better results of diffusion models they still have shortcomings in some aspects such as the cost of synthesizing new samples, which makes them difficult to being applied in real-time problems.

In [148] it was developed a diffusion model to perform an image-to-image translation. The results showed in this research show that their solution outperforms GANs without special attention to the hyper-parameter tunning or any kind of sophisticated technique or loss function. Moreover this research shows the great stability of the diffusion model architecture.

Despite the fact that Diffusion models are a novel architecture with not many works published, it is a very potential architecture to surpass GAN results in a near future. At present, there are not enough results or applications of diffusion models to data generation, but the potential of this new architecture could lead to a significant improvement in the results of data synthesis. We consider that this models could replace GANs because of their stability and not needing fine-tunning in their hyperparameters.

Other new architectures have been used to enhance the results of GANs, such as transformers, to improve their results. Transformer architecture is a time-series-based architecture that adopts the self-attention layers [174] making possible to design larger models. Transformers have been used as the base neural model of the G and D of the GAN architecture, improving the performance of the model.

The TransGAN [68] presents a GAN architecture free of convolutions that makes possible to generate high resolution images by using transformer in both G and D of the GAN. The results of the article shows an improved results respect to the IS and FID on CIFAR-10 dataset [86].

Another work that showcases the interaction between GANs and transformers is the one presented in [112]. This work uses the generative model to predict pedestrian paths, using the memory that the transformer architecture has. In this sense, the GAN makes possible to train the network to predict future paths of pedestrians, while the transformer provides the memory to process an historical sequence of the latest movements.


## Conclusion

This report summarizes the recent progress of GANs, going from the basic principles in which GAN are sustained to the most innovative architectures of the last years.

In addition, the different problems that GANs can suffer are categorized and the most common evaluation metrics are explained and discussed.

Respect the recent progress in the field, a taxonomy for the GAN variants is proposed. The researches are divided in two groups, one with the GANs that focus in architecture optimization and the other with the GANs that focus in objective function optimization. Despite being two separate groups of variants, it should be noted that the different researches benefit from the progress of the rest. These ecosystem where there are various approaches for GAN development is connected with the main problems that are reviewed in this survey, since normally each research focus in trying to solve a certain problematic of previous researches.

Finally the different application of the GANs during the last years are summarized.

The different applications of GAN are influenced by the development of the field, its impact in the society and in the industry. We conclude with a comparison between the different architectures performance to provide a quantitative view of the evolution of GANs.

## Figure 1 :
1Architecture of a GAN model.


Section 5 reviews the most important GANs proposed since their introduction in 2014, paying special attention to the GANs proposed in the recent years. This section is divided in two types of GANs, the ones focused on improving the architecture of the GAN and the ones that tries to improve the GAN performance by changing its loss function behavior. This section also includes a new taxonomy of the reviewed articles and a timeline to have a clear vision of how the research in this field has been developed. Section 6 summarizes the most important application of GAN architecture related to computer vision tasks. This section also includes GANs applied to other domains different than image generation, paying special attention to the treatment of different types of data, such as molecular composition or medical imaging. Finally, section 7 discuss the actual situation of GAN with the development of new architectures such as diffusion models or transformers. Here, we describe the potential of these new models in comparison with GAN.


, so applying of this architecture to domain-to-domain translation problems can benefit from their particularities. Autoencoders are based on the idea of reducing the dimensionality of the input data, then they reconstruct the same information. By doing the dimensional reduction, the network is capable of maintaining the essential features of the input data. In the case of domain-to-domain translation, by using autoencoders, the architecture is capable of maintaining the main features of a sample and translating this core information to other specific domains. The results presented in the original work show how GANs can learn high-level relationships between two complete different domains. In the experiments carried out in the research, it was demonstrated how the networks discovered relationships such as orientation. E.g., pairing images of chairs and car with the same orientation. 5.1.9. GANILLA The GANILLA [62] architecture modifies the structure of the G of the GAN for image style transfer. The main objective of the variant is to maintain both the content and the style of an image, previous methods usually lack one of this aspects in favor of the other. The main idea of the GANILLA is to do the style transfer of an image balancing style and content. The architecture of GANILLA uses low-level features to maintain the content of the image at the same time as the style transfer is done. The G model is based on two stages, one for downsampling the input image and the other for upsampling the information of the first stage. This architecture ensures that the style transfer maintains the input features of the image but, in addition, some layers concatenate features of previous layers such as edges, shapes or morphological features. With these two methods, the architecture controls both content and style.The downsampling stage is based on ResNet-18[60] but with skipped connections.This skipped connections then feed the upsampling module. The architecture of the GANILLA can be observed in theFig.2

## Figure 2 :
2Structure of the proposed architecture of the GANILLA. Figure based on Reference [62]. For training the models, the cyclic consistency method of the CycleGAN [211] is used. This way, two pairs of G and D are used to map both domains. The results of the GANILLA show the good performance, in specific for children's book illustration dataset. Due to the particularities of the images of children's books, being highly contrasted images with abstract objects, previous architectures had difficulty to do the style transfer. However, with the usage of low level features of the GANILLA, it is achieved an improvement of the overall performance. 5.1.10. Progressive Growing of GANs (ProGAN) Training a complex model can lead to strong instability. To tackle the instability of GANs models, ProGAN [77] proposes a training methodology based on a growing architecture. The idea of a progressive neural network was previously proposed [147]. The main idea behind progressive networks is the concatenation of different training phases. In each phase, a model is trained and, as the trainings are developed, the model number of layers increases. This way the created model scales up gradually stabilizing the training. The strength of this architecture is that, due to the simplicity of the first model, the networks are capable to learn properly the simplest form of the problem and then use the learned characteristics to scale up little by little the complexity of the problem. With each new phase, it is important to emphasize that the weights of the networks remain trainable, letting them to adapt to the new phases.

## Figure 3 :
3Training schedule of ProGAN. Figure based on Reference [77]. ProGAN's training methodology speeds up the training phase and produces images of state-of-the-art quality, e.g. achieving an inception score of 8.8 in the unsupervised CIFAR-10 [86] dataset. The ProGAN described in the original paper used the Gradient Penalty WGAN (WGAN-GP) [55] loss format, despite that ProGAN architecture can be applied to any loss function. ProGAN training methodology has been implemented in many recent researches [193, 15]. 5.1.11. Dynamically Grown GAN (DGGAN) DGGAN [104] proposes a new training methodology based on ProGAN. The architecture of the networks of DGGAN not only grow periodically, they rather grow dynamically adapting their architecture and parameters during the training. The DGGAN questions some aspects of GANs such as the symmetry between G and D or layer choice. The new methodology can automatically search the optimal parameters, respecting ProGAN growing strategy was previously defined. The DGGAN starts with a base D and G, the training alternates between training steps and the growing of the network. To grow the network, a set of child architectures are created. Each child has the same architecture as the parent, but each child proposes a different growing change to the network. During the training children architectures are trained, initializing the weights of the inherited parent layers with their respective parent weights.

## Figure 4 :
4Training methodology of DGGAN. Figure based on Reference [104].


then is used in each convolution layer via an Adaptive Instance Normalization (ADAIN). In addition to the latent space, gaussian noise is added to the output of each convolution layer. The StyleGAN architecture uses the training methodology used in ProGAN, supporting the previously mentioned idea that each research should not be considered as an isolated result. The paradigm of investigation is supported by the continuous mixing of new techniques. Said so, the StyleGAN improves the quality of the generated images of the Pro-GAN, achieving a FID score of 5.06 in CelebA-HQ dataset and 4.40 in FFHQ dataset.


architecture covers the problem of local spatial information of images. I.e. images that have different components correlated in different positions of the image can be difficult to cover because the receptive field of the network is not big enough. In SAGAN, the generation of different features is made considering cues from all images. In addition, SAGAN D is capable of evaluating the consistency of features along the image.

## Figure 5 :
5Self attention layer of SAGAN. Figure based on Reference[199].


This new layer preserves two-dimensional image locality and contributes the flow of information through the different layers. To preserve the twodimensional locality and quantify how information flows through the model, the framework of Information Flow Diagram (IFD) [39] is used. The modification of the self attention layer of SAGAN introduces sparse attention layers. This new method reduces the quadratic complexity of the attention layer by splitting the attention into multiple subsets of data. The main problem of the sparse attention layer is that, besides its computational optimization, it lacks the information flow of the network. To tackle this information flow graphs are introduced, these graphs will be used to support Full Information through the layers of the network. The results show how applying the new layer improves the quality of the images compared to the SAGAN generated images. The architecture of the SAGAN, modifying the dense attention layer and preserving the rest parameters is called YLG-SAGAN. YLG-SAGAN not only improves the FID of SAGAN, reducing it score from 14.53 to 8.95, furthermore it optimizes the training time to around a 40%.

## pling [ 143 ]
143CEGAN does not modify the original dataset. This way, some problems of the traditional methods are avoided, e.g. shortening the original dataset by undersampling or redundant information by oversampling with geometric transformations. 5.1.20. Measuring the Realness in the Spatial and Spectral Domains (SSD-GAN)The SSD-GAN[26] tackles the problem of high frequency samples in GANs. The described problem causes high spectrum discrepancies between the real and the synthesized samples. The SSD-GAN proposes to alleviate this discrepancy to enhance the quality of the synthesized data.The idea behind the architecture is to reduce the gap of spectrum discrepancy, combining the spectral realness and the spatial realness of each sample, to do so a new D is defined. The new proposed D is known as D ss and it combines D and a classifier C. D is in charge of measuring the spatial realness of an image, this is the same approach of the D of the traditional GAN[51]. The new proposed C is in charge of the known as spectral classification, this is, measure the difference of the specters of synthesized and real data. The C objective function is called spectral classification loss and it is defined as:

## Fig. 6
6shows how both spatial and spectral information are processed by the new D proposed for the SSD-GAN. SSD-GAN results show the potential of the proposed architecture. The quality of the images enhances the results of previous architectures, e.g. reducing the FID score of the StyleGAN [79] from 4.40 to 4.06 by including the spectral classification.

## Figure 6 :
6Structure of the proposed enhanced D of the SSD-GAN. Figure based on Reference [26].

## Fig. 7 .
7We divide the different architecture-based GANs in different groups based on the proposed changes. The illustration gives a global view of how are interconnected different researches of the last years.


that focuses on the objective function of GANs. For example, the instability problem of GANs is actually caused by the Jensen-Shannon divergence, where D often wins over G. Along with architecture optimization GANs, there have been developed loss optimization researches, where both approaches coexist and interact with each

## Figure 7 :
7Survey proposed division of architecture variants for GANs.

## Figure 8 :
8Comparison between sigmoid cross entropy loss function (a) and least squares loss function (b). Figure from Reference[116].

## V
new variation presented by RealnessGAN [189] is a generalization of the original version of the GAN. The proposed loss function changes the output of D, making it a distribution of the realness of the input data. In other words, the discriminator function is to measure the potential realness of the input data. (G, D) = Ex∼p data [DKL(A1||D(x))]+ Ex∼p g [DKL(A0||D(x))]


generate illustrations for different image styles. Previous methods used different G for each style, limiting the practical application of the architectures, while MISS GAN uses a unique model. The proposed new G is based on the GANILLA [62] architecture, but it proposes some changes to the architecture of the decoder of the GANILLA G. The new decoder contains three residual blocks, these residual blocks are in charge of processing the low-level features from previous layers. The composition of each residual block can be seen in Fig.9.

## Figure 9 :
9Structure of the proposed residual blocks of the MISS GAN. Figure based onReference[11].


In the original paper, the mathematical properties of SphereGAN are proved, showing that minimizing the objective function of SphereGAN is equivalent to reducing IPM. In addition, it is proved that SphereGAN compared to WGAN can use r-Wasserstein distances, unlike WGAN that could only use 1-Wasserstein distance.This provides to SphereGAN a wider function space.The SphereGAN results show its good performance, achieving a IS of 8.39 and FID score of 17.1 in CIFAR-10[86] dataset. Compared to WGAN-GP that achieved IS of 7.86 in the same dataset.

## Figure 10 :
10Survey proposed division of loss function variants for GANs.


have been studied during sections 5.1 and 5.2 are showed temporally. This timeline provides an overview of the historical development of GANs.As it can be seen, the timeline compiles the most important works of the last decade. It is important to analyze that some researches have influenced posterior ones. In some cases some researches adopt innovation of previous works as a base to then propose new changes, e.g. the DCGAN that have influenced several posterior works. In other cases there are relationships between works can be seen as an unique research, linking each article with each other by taking previous results and improving them, e.g. in the case of ProGAN, StyleGAN and Alias-Free GAN.

## Figure 11 :
11Timeline of the reviewed GAN architectures.


Recently the ProGAN[77] introduced a new training methodology that achieved an improved performance of the networks. With the new methodology came a huge improvement in the quality of the generated images. The results showed not only a more stable trainings but sharper, with finer details and more diverse images. Due to the particularities of the applied methodology, it can be applied to other architectures, so in later works the ProGAN training methodology will be used as its base.Following the line of research of ProGAN the StyleGAN [79] was presented. The results produced by the StyleGAN could improve the results of the ProGAN. At this point some generated datasets, e.g. human faces images, were indistinguishable from real images from a human perception. Along with the high quality of the images the StyleGAN proposed style mixing, capable of generating new images combining previous images. This allows to modify image features at a high, medium and low level, allowing the network to disentangle different features of an image, providing more control of the generated images.One of the main problems of the StyleGAN was the known as texture sticking. This caused the generated images to have a certain texture in an absolute position. When interpolating different images it was noticeable that some parts of the images, e.g. the hair of a human face, maintain the same texture in spite of changing its position.The Alias-Free GAN proposed an architecture that suppressed the texture sticking problem. By eliminating the sticking problem, the interpolation of synthesized images is smoothed, generating a continuum of images, not only realistic individually but also as a set. The improvements of the Alias-Free GAN together with the style mixing of StyleGAN allows to create animations of, for example, a human face changing its position, gender or features such as the smile.


This new architecture results follows the natural progression of the GAN in image-toimage translation and promise an exciting future in what GAN can do. The image-to-image translation is especially popular in society, because of the applications that have been developed in the last years. With the architecture of the presented GANs the general public is capable, for example, of taking a personal image of themselves and transforming it into one of an old person with his face. This type of applications have become popular in social networks, increasing their visibility even more. This interaction between society and GAN development is mutually beneficial, the society uses the technological advances of the last years while the academic community gain impact and repercussion. From an academic perspective this interaction should be considered positive and it should be noted that most of the impact of machine learning during the last years have been caused by the publicity given by the mass media and the social networks. Although most of the people are not interested in the technique


was one of the firsts proposed architectures for image generation from text. The architecture splits in two stages, the generation problem, the objective is to divide the main problem in sub-problems that are easier to handle in the network. The known as Stage-I GAN is in charge of producing a coarse sketch of the desired image, this way this part of the network focuses on translating the text to a image that fulfills the description. Then, the Stage-II GAN takes the generated image from Stage-I GAN, increases its resolution and define the finer details. The StackGAN is able of producing images that match the input description while achieving sharp, high quality samples. Later on the StackGAN++ (StackGAN-v2)[202] was proposed, this new architecture resolved some problems of the original StackGAN, stabilizing its training and improving the overall quality of the synthesized images.One problem of the StackGAN is that it is highly dependent on the sketch generated by the Stage-I GAN. To solve this Dynamic Memory GAN (DM-GAN) proposed a new technique based on memory networks[54,184] that divides the generation problem in two steps. In the first one a initial image is generated and in the second step a memory network is used to refine the details and produce a high quality image. To con-nect the memory and the GAN a response gate is proposed, by controlling dynamically the flow of information the gate is capable of fusing the information appropriately. The results of the StackGAN shows a higher quality respecting all previous architectures. Dual Attentional GAN (DualAttn-GAN) proposed a new architecture based on two modules. The Visual Attention Module (VAM) is in charge of taking care of the internal representations of the image information, capturing the global structures and their relationships. The Textual Attention Module (TAM) defines the relations between the text and the image, defining the links between both. Finally a Attention Embedding Module (AEM) fuse the visual with the textual information, concatenating them along with the input features of the image. The results of the DualAttn-GAN shows an improved performance respecting previously used architectures. Following the general architecture of StackGAN Deep Fusion GAN (DF-GAN) was proposed [167]. The DF-GAN architecture only have one stage of image generation, this backbone synthesized new images conditioned by an input text using only one pair of G and D. Thus being a simpler structure, DF-GAN achieves better performance and efficiency compared with previous variants. The new techniques that DF-GAN proposes are a new fusion module, known as deep text-image fusion block, and a new discriminator capable of promoting the generator to synthesize higher quality images without extra networks. The results of the DF-GAN shows an improvement on the quality of the images, without committing to more complex models and improving the efficiency of the previous architectures. The one-stream information approach followed in DF-GAN was reused in Lightweight Dynamic Conditional GAN (LD-CGAN) [46]. The proposed architecture of the LD-CGAN consists on one G and two independent discriminators. The generator is composed by a Conditional Embedding (CE) that disentangles the features of the input text by using unsupervised learning. Then a Conditional Manipulating Block (CM-B) provides continuously the images features with the compensation information. Finally using the known as Pyramid Attention Refine Block (PAR-B) the generated image is enriched maintaining multiscale context and spatial multiscale features. The results of the architecture not only shows a higher quality image respecting previous methods, but also improves the performance decreasing the number of parameters by 86.8% and the computation time by 94.9%.

## Finally,
GameGAN introduces a warm-up phase where certain real frames are introduced in the network during the first epoch of the training. Then the frequency of real frames is reduced little by little until it disappears. This way the first epochs of the training, that are usually the most complex in the network, are controlled and progressively the GAN gains more control over the output. This helps the network to understand the problem.


multiple features that are changing, that means that those features are entangled under the same representation. This metric measures how well the GAN is learning the different features of the input images, measuring the entanglement of the generated images.The embeddings 

of consecutive images are calculated using VGG16, interpolating random latent space 

inputs, then it is calculated how the synthesized images changes. 

Drastic change means that, for a minimum change in the latent space there are 




rics. The results of the original paper show that, compared with the classical GAN loss function, the WGAN has better behavior in terms of convergence, mode collapse avoiding and stability. Particularly in low-dimensional manifold distributions, WGAN has shown to outperform traditional JS and KL divergences[182]. Other important benefit of WGAN is that the loss correlates with the quality of the synthesized samples and converges to a minimum.WGAN is one of the most adopted variants, due to its capacity to deal with instability and mode collapse. Many later GAN variants[147,79] use the WGAN loss function along with their own changes. For example, the Multi-marginal Wasserstein GAN (MWGAN) [21] proposes a new objective function based on WGAN for multi marginal domain translation.

## Table 2 :
2Performance summary of image generation GANsModel 

CIFAR-10 
CelebA-HQ 
FFHQ 

Accuracy ↑ 
IS ↑ 
FID ↓ 
FID ↓ 

DCGAN 
82.8% 
6.58 
-
-

ProGAN 
-
8.80 
7.79 
8.04 

StyleGAN 
-
-
5.06 
4.40 

StyleGAN2 
-
-
-
2.70 

Alias-Free GAN 
-
-
-
3.07 



## Table 3 :
3Performance summary of image-to-image translation GANsModel 

CUHK 
FACADES 

SSIM ↑ 
MSE ↓ 
PSNR ↑ 
LPIPS ↓ 
SSIM ↑ 
MSE ↓ 
PSNR ↑ 
LPIPS ↓ 

GAN 
0.5398 
94.8815 
28.3628 
0.157 
0.1378 
103.8049 
27.9706 
0.525 

Pix2Pix 
0.6056 
89.9954 
28.5989 
0.154 
0.2106 
101.9864 28.0568 
0.216 

DualGAN 
0.6359 
85.5418 
28.8351 
0.132 
0.0324 
105.0175 
27.9187 
0.259 

CycleGAN 
0.6537 
89.6019 
28.6351 
0.099 
0.0678 
104.3104 
27.9489 
0.248 

PS2MAN 
0.6409 
86.7004 
28.7779 
0.098 
0.1764 
102.4183 
28.032 
0.221 

CSGAN 
0.6616 
84.7971 28.8693 
0.094 
0.2183 
103.7751 
27.9715 
0.22 



## Table 4 :
4Performance summary of image generation from text GANs paragraphs and text while maintaining global coherence. In addition to LSTM the previous methods used Recurrent Neural Network (RNN) to generate new texts [31]. The Text GAN (textGAN) [206] uses LSTM along with Convolutional Neural Network (CNN) to synthesize new text. The proposed method applies the GAN training methodology via the known as adversarial training. The textGAN uses a LSTM as the G of the network and a CNN as the D. One of the main problems of the textGAN was the highly entangled features of the network, making the interpolation of different writing styles very difficult.Model 

COCO 
CUB 
Oxford-102 

HR ↓ 
IS ↑ 
FID ↓ 
HR ↓ 
IS ↑ 
FID ↓ 
HR ↓ 
IS ↑ 
FID ↓ 

GAN-INT-CLS 
1.89 
7.88 
-
2.81 
2.88 
-
1.87 
2.66 
-

GAWWN 
-
-
-
1.99 
3.62 
-
-
-
-

StackGAN 
1.11 
8.45 
-
1.37 
3.70 
-
1.13 
3.20 
-

StackGAN-v2 
1.55 
8.30 
81.59 
1.19 
4.04 
15.30 
1.30 
3.26 
48.68 

DM-GAN 
-
30.49 
32.64 
-
4.75 
16.09 
-
-
-

DualAttn-GAN 
-
-
-
-
4.59 
14.06 
-
4.06 
40.31 

DF-GAN 
-
-
21.42 
-
5.10 
14.81 
-
-
-

LD-CGAN 
-
-
-
-
4.18 
-
-
3.45 
-

and time, this feature provides the networks the ability of process whole sentences, 




The G of SeqGAN is trained using a stochastic policy of Reinforcement Learning(RL). The RL reward is calculated by judging a complete sentence made with the G of the model. Then, to compute the intermediate steps a Monte Carlo Search is made

A learning algorithm for boltzmann machines. D H Ackley, G E Hinton, T J Sejnowski, Cognitive Science. 9Ackley, D. H., Hinton, G. E., and Sejnowski, T. J. A learning algorithm for boltzmann machines. Cognitive Science 9, 1 (1985), 147-169.

On the tradeoff between mode collapse and sample quality in generative adversarial networks. S Adiga, M A Attia, W.-T Chang, R Tandon, IEEE Global Conference on Signal and Information Processing. GlobalSIP)Adiga, S., Attia, M. A., Chang, W.-T., and Tandon, R. On the tradeoff between mode collapse and sample quality in generative adversarial networks. In 2018 IEEE Global Conference on Signal and Information Processing (GlobalSIP) (2018), pp. 1184-1188.

Generative adversarial network: An overview of theory and applications. A Aggarwal, M Mittal, G Battineni, International Journal of Information Management Data Insights. 1100004Aggarwal, A., Mittal, M., and Battineni, G. Generative adversarial net- work: An overview of theory and applications. International Journal of Infor- mation Management Data Insights 1, 1 (2021), 100004.

Applications of generative adversarial networks (gans): An updated review. H Alqahtani, M Kavakli-Thorne, D G Kumar Ahuja, Archives of Computational Methods in Engineering. 28Alqahtani, H., Kavakli-Thorne, M., and Kumar Ahuja, D. G. Applica- tions of generative adversarial networks (gans): An updated review. Archives of Computational Methods in Engineering 28 (12 2019).

. M Arjovsky, S Chintala, L Bottou, Wasserstein Gan, Arjovsky, M., Chintala, S., and Bottou, L. Wasserstein gan, 2017.

Strided convolution instead of max pooling for memory efficiency of convolutional neural networks. R Ayachi, M Afif, Y Said, Atri , M , Proceedings of the 8th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT'18). M. S. Bouhlel and S. Rovettathe 8th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT'18)Cham, 2020Springer International Publishing1Ayachi, R., Afif, M., Said, Y., and Atri, M. Strided convolution instead of max pooling for memory efficiency of convolutional neural networks. In Proceed- ings of the 8th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT'18), Vol.1 (Cham, 2020), M. S. Bouhlel and S. Rovetta, Eds., Springer International Publishing, pp. 234-243.

Solving mode collapse using manifold guided training. D Bang, H Shim, Mggan, Bang, D., and Shim, H. Mggan: Solving mode collapse using manifold guided training, 2018.

. D Bank, N Koenigstein, R Giryes, Autoencoders, Bank, D., Koenigstein, N., and Giryes, R. Autoencoders, 2021.

Recycle-gan: Unsupervised video retargeting. A Bansal, S Ma, D Ramanan, Y Sheikh, Proceedings of the European conference on computer vision (ECCV). the European conference on computer vision (ECCV)Bansal, A., Ma, S., Ramanan, D., and Sheikh, Y. Recycle-gan: Unsuper- vised video retargeting. In Proceedings of the European conference on computer vision (ECCV) (2018), pp. 119-135.

Convergence problems with generative adversarial networks (gans). S A Barnett, Barnett, S. A. Convergence problems with generative adversarial networks (gans), 2018.

Miss gan: A multi-illustrator style generative adversarial network for image to illustration translation. N Barzilay, T B Shalev, R Giryes, Pattern Recognition Letters. Barzilay, N., Shalev, T. B., and Giryes, R. Miss gan: A multi-illustrator style generative adversarial network for image to illustration translation. Pattern Recognition Letters (2021).

Seeing what a gan cannot generate. D Bau, J.-Y Zhu, J Wulff, W Peebles, H Strobelt, B Zhou, A Torralba, Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV. the IEEE/CVF International Conference on Computer Vision (ICCVBau, D., Zhu, J.-Y., Wulff, J., Peebles, W., Strobelt, H., Zhou, B., and Torralba, A. Seeing what a gan cannot generate. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) (October 2019).

Scheduled sampling for sequence prediction with recurrent neural networks. S Bengio, O Vinyals, N Jaitly, N Shazeer, arXiv:1506.03099arXiv preprintBengio, S., Vinyals, O., Jaitly, N., and Shazeer, N. Scheduled sam- pling for sequence prediction with recurrent neural networks. arXiv preprint arXiv:1506.03099 (2015).

The computer as a physical system: A microscopic quantum mechanical hamiltonian model of computers as represented by turing machines. P Benioff, Journal of statistical physics. 22Benioff, P. The computer as a physical system: A microscopic quantum me- chanical hamiltonian model of computers as represented by turing machines. Journal of statistical physics 22, 5 (1980), 563-591.

Data augmentation using generative adversarial networks for pneumonia classification in chest xrays. V Bhagat, S Bhaumik, 2019 Fifth International Conference on Image Information Processing (ICIIP). IEEEBhagat, V., and Bhaumik, S. Data augmentation using generative adversarial networks for pneumonia classification in chest xrays. In 2019 Fifth International Conference on Image Information Processing (ICIIP) (2019), IEEE, pp. 574- 579.

Study of prevention of mode collapse in generative adversarial network (gan). Bhagyashree, V Kushwaha, G C Nandi, 2020 IEEE 4th Conference on Information Communication Technology (CICT) (2020). Bhagyashree, Kushwaha, V., and Nandi, G. C. Study of prevention of mode collapse in generative adversarial network (gan). In 2020 IEEE 4th Conference on Information Communication Technology (CICT) (2020), pp. 1-6.

Pros and cons of gan evaluation measures. A Borji, Computer Vision and Image Understanding. 179Borji, A. Pros and cons of gan evaluation measures. Computer Vision and Image Understanding 179 (2019), 41-65.

A test of relative similarity for model selection in generative models. W Bounliphone, E Belilovsky, M B Blaschko, I Antonoglou, A Gretton, Bounliphone, W., Belilovsky, E., Blaschko, M. B., Antonoglou, I., and Gretton, A. A test of relative similarity for model selection in generative models, 2016.

Large scale gan training for high fidelity natural image synthesis. A Brock, J Donahue, K Simonyan, arXiv:1809.11096arXiv preprintBrock, A., Donahue, J., and Simonyan, K. Large scale gan training for high fidelity natural image synthesis. arXiv preprint arXiv:1809.11096 (2018).

. C B Browne, E Powley, D Whitehouse, S M Lucas, P I Cowling, P Rohlfshagen, S Tavener, D Perez, S Samothrakis, andBrowne, C. B., Powley, E., Whitehouse, D., Lucas, S. M., Cowling, P. I., Rohlfshagen, P., Tavener, S., Perez, D., Samothrakis, S., and

A survey of monte carlo tree search methods. S Colton, IEEE Transactions on Computational Intelligence and AI in games. 4Colton, S. A survey of monte carlo tree search methods. IEEE Transactions on Computational Intelligence and AI in games 4, 1 (2012), 1-43.

Multi-marginal wasserstein gan. J Cao, L Mo, Y Zhang, K Jia, C Shen, M Tan, Advances in Neural Information Processing Systems. 32Cao, J., Mo, L., Zhang, Y., Jia, K., Shen, C., and Tan, M. Multi-marginal wasserstein gan. Advances in Neural Information Processing Systems 32 (2019), 1776-1786.

Quantum chemistry in the age of quantum computing. Y Cao, J Romero, J P Olson, M Degroote, P D Johnson, M Kieferová, I D Kivlichan, T Menke, B Peropadre, N P Sawaya, Chemical reviews. 119Cao, Y., Romero, J., Olson, J. P., Degroote, M., Johnson, P. D., Kieferová, M., Kivlichan, I. D., Menke, T., Peropadre, B., Sawaya, N. P., et al. Quantum chemistry in the age of quantum computing. Chemical reviews 119, 19 (2019), 10856-10915.

Evading deepfake-image detectors with white-and black-box attacks. N Carlini, H Farid, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (2020). the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (2020)Carlini, N., and Farid, H. Evading deepfake-image detectors with white-and black-box attacks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (2020), pp. 658-659.

Interactive reconstruction of monte carlo image sequences using a recurrent denoising autoencoder. C R A Chaitanya, A S Kaplanyan, C Schied, M Salvi, A Lefohn, D Nowrouzezahrai, Aila , T , ACM Transactions on Graphics (TOG). 36Chaitanya, C. R. A., Kaplanyan, A. S., Schied, C., Salvi, M., Lefohn, A., Nowrouzezahrai, D., and Aila, T. Interactive reconstruction of monte carlo image sequences using a recurrent denoising autoencoder. ACM Transac- tions on Graphics (TOG) 36, 4 (2017), 1-12.

Infogan: Interpretable representation learning by information maximizing generative adversarial nets. X Chen, Y Duan, R Houthooft, J Schulman, I Sutskever, Abbeel , P , Proceedings of the 30th International Conference on Neural Information Processing Systems. the 30th International Conference on Neural Information Processing SystemsChen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., and Abbeel, P. Infogan: Interpretable representation learning by information max- imizing generative adversarial nets. In Proceedings of the 30th International Conference on Neural Information Processing Systems (2016), pp. 2180-2188.

Y Chen, G Li, C Jin, S Liu, T Li, Ssd-Gan, arXiv:2012.05535Measuring the realness in the spatial and spectral domains. arXiv preprintChen, Y., Li, G., Jin, C., Liu, S., and Li, T. Ssd-gan: Measuring the realness in the spatial and spectral domains. arXiv preprint arXiv:2012.05535 (2020).

Mocycle-gan: Unpaired video-to-video translation. Y Chen, Y Pan, T Yao, X Tian, Mei , T , Proceedings of the 27th ACM International Conference on Multimedia. the 27th ACM International Conference on MultimediaChen, Y., Pan, Y., Yao, T., Tian, X., and Mei, T. Mocycle-gan: Un- paired video-to-video translation. In Proceedings of the 27th ACM International Conference on Multimedia (2019), pp. 647-655.

Generative adversarial networks in medical image augmentation: a review. Y Chen, X.-H Yang, Z Wei, A A Heidari, N Zheng, Z Li, H Chen, H Hu, Q Zhou, Q Guan, Computers in Biology and Medicine. 105382Chen, Y., Yang, X.-H., Wei, Z., Heidari, A. A., Zheng, N., Li, Z., Chen, H., Hu, H., Zhou, Q., and Guan, Q. Generative adversarial networks in medical image augmentation: a review. Computers in Biology and Medicine (2022), 105382.

Generative adversarial networks: A literature review. J Cheng, Y Yang, X Tang, N Xiong, Y Zhang, F Lei, KSII Transactions on Internet & Information Systems. 1412Cheng, J., Yang, Y., Tang, X., Xiong, N., Zhang, Y., and Lei, F. Gener- ative adversarial networks: A literature review. KSII Transactions on Internet & Information Systems 14, 12 (2020).

Diffusion models in vision: A survey. F.-A Croitoru, V Hondru, R T Ionescu, M Shah, arXiv:2209.04747arXiv preprintCroitoru, F.-A., Hondru, V., Ionescu, R. T., and Shah, M. Diffusion models in vision: A survey. arXiv preprint arXiv:2209.04747 (2022).

Semi-supervised sequence learning. A M Dai, Q V Le, Advances in neural information processing systems. 28Dai, A. M., and Le, Q. V. Semi-supervised sequence learning. Advances in neural information processing systems 28 (2015), 3079-3087.

Deep learning in drug discovery and medicine; scratching the surface. D Dana, S V Gadhiya, St, L G Surin, D Li, F Naaz, Q Ali, L Paka, M A Yamin, M Narayan, I D Goldberg, Molecules. 232384Dana, D., Gadhiya, S. V., St. Surin, L. G., Li, D., Naaz, F., Ali, Q., Paka, L., Yamin, M. A., Narayan, M., Goldberg, I. D., et al. Deep learning in drug discovery and medicine; scratching the surface. Molecules 23, 9 (2018), 2384.

Your local gan: Designing two dimensional local attention mechanisms for generative models. G Daras, A Odena, H Zhang, A G Dimakis, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionDaras, G., Odena, A., Zhang, H., and Dimakis, A. G. Your local gan: Designing two dimensional local attention mechanisms for generative models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2020), pp. 14531-14539.

A review on generative adversarial networks. De Silva, D M Poravi, G , 2021 6th International Conference for Convergence in Technology (I2CT) (2021). De Silva, D. M., and Poravi, G. A review on generative adversarial networks. In 2021 6th International Conference for Convergence in Technology (I2CT) (2021), pp. 1-4.

Oct image segmentation using neural architecture search and srgan. O Dehzangi, S H Gheshlaghi, A Amireskandari, N M Nasrabadi, A Rezai, 2020 25th International Conference on Pattern Recognition (ICPR) (2021). IEEEDehzangi, O., Gheshlaghi, S. H., Amireskandari, A., Nasrabadi, N. M., and Rezai, A. Oct image segmentation using neural architecture search and srgan. In 2020 25th International Conference on Pattern Recognition (ICPR) (2021), IEEE, pp. 6425-6430.

Imagenet: A large-scale hierarchical image database. J Deng, W Dong, R Socher, L.-J Li, K Li, L Fei-Fei, 2009 IEEE conference on computer vision and pattern recognition. IeeeDeng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L. Ima- genet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition (2009), Ieee, pp. 248-255.

Bringing the people back in: Contesting benchmark machine learning datasets. E Denton, A Hanna, R Amironesei, A Smart, H Nicole, M K Scheuerman, arXiv:2007.07399arXiv preprintDenton, E., Hanna, A., Amironesei, R., Smart, A., Nicole, H., and Scheuerman, M. K. Bringing the people back in: Contesting benchmark ma- chine learning datasets. arXiv preprint arXiv:2007.07399 (2020).

Diffusion models beat gans on image synthesis. P Dhariwal, Nichol , A , Advances in Neural Information Processing Systems. 34Dhariwal, P., and Nichol, A. Diffusion models beat gans on image synthesis. Advances in Neural Information Processing Systems 34 (2021), 8780-8794.

Network coding for distributed storage systems. A G Dimakis, P B Godfrey, Y Wu, M J Wainwright, K Ramchandran, IEEE transactions on information theory. 56Dimakis, A. G., Godfrey, P. B., Wu, Y., Wainwright, M. J., and Ram- chandran, K. Network coding for distributed storage systems. IEEE transac- tions on information theory 56, 9 (2010), 4539-4551.

B Dolhansky, J Bitton, B Pflaum, J Lu, R Howes, M Wang, Canton Ferrer, C , The deepfake detection challenge dataset. arXiv e-prints (2020). 2006Dolhansky, B., Bitton, J., Pflaum, B., Lu, J., Howes, R., Wang, M., and Canton Ferrer, C. The deepfake detection challenge dataset. arXiv e-prints (2020), arXiv-2006.

Rf pix2pix unsupervised wi-fi to video translation. M Drob, arXiv:2102.09345arXiv preprintDrob, M. Rf pix2pix unsupervised wi-fi to video translation. arXiv preprint arXiv:2102.09345 (2021).

Combating mode collapse in gan training: An empirical analysis using hessian eigenvalues. R Durall, A Chatzimichailidis, P Labus, J Keuper, Durall, R., Chatzimichailidis, A., Labus, P., and Keuper, J. Combating mode collapse in gan training: An empirical analysis using hessian eigenvalues, 2020.

Gans may have no nash equilibria. F Farnia, A Ozdaglar, Farnia, F., and Ozdaglar, A. Gans may have no nash equilibria, 2020.

Gpt-3: Its nature, scope, limits, and consequences. Minds and Machines. L Floridi, M Chiriatti, 30Floridi, L., and Chiriatti, M. Gpt-3: Its nature, scope, limits, and conse- quences. Minds and Machines 30, 4 (2020), 681-694.

Synthetic data augmentation using gan for improved liver lesion classification. M Frid-Adar, E Klang, M Amitai, J Goldberger, H Greenspan, IEEE 15th international symposium on biomedical imaging (ISBI 2018). IEEEFrid-Adar, M., Klang, E., Amitai, M., Goldberger, J., and Greenspan, H. Synthetic data augmentation using gan for improved liver lesion classification. In 2018 IEEE 15th international symposium on biomedical imaging (ISBI 2018) (2018), IEEE, pp. 289-293.

Lightweight dynamic conditional gan with pyramid attention for text-to-image synthesis. L Gao, D Chen, Z Zhao, J Shao, H T Shen, Pattern Recognition. 110107384Gao, L., Chen, D., Zhao, Z., Shao, J., and Shen, H. T. Lightweight dynamic conditional gan with pyramid attention for text-to-image synthesis. Pattern Recognition 110 (2021), 107384.

Gan and vae from an optimal transport point of view. A Genevay, G Peyré, M Cuturi, arXiv:1706.01807arXiv preprintGenevay, A., Peyré, G., and Cuturi, M. Gan and vae from an optimal transport point of view. arXiv preprint arXiv:1706.01807 (2017).

A survey on the progression and performance of generative adversarial networks. B Ghosh, I K Dutta, M Totaro, M Bayoumi, 2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT) (2020). Ghosh, B., Dutta, I. K., Totaro, M., and Bayoumi, M. A survey on the progression and performance of generative adversarial networks. In 2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT) (2020), pp. 1-8.

A González-Prieto, A Mozo, E Talavera, S Gómez-Canaval, Dynamics of fourier modes in torus generative adversarial networks. Mathematics. 94González-Prieto, A., Mozo, A., Talavera, E., and Gómez-Canaval, S. Dynamics of fourier modes in torus generative adversarial networks. Mathematics 9, 4 (2021).

I Goodfellow, tutorial: Generative adversarial networks. Goodfellow, I. Nips 2016 tutorial: Generative adversarial networks, 2017.

Generative adversarial networks. I J Goodfellow, J Pouget-Abadie, M Mirza, B Xu, D Warde-Farley, S Ozair, A Courville, Y Bengio, Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde- Farley, D., Ozair, S., Courville, A., and Bengio, Y. Generative ad- versarial networks, 2014.

. A Graves, G Wayne, I Danihelka, arXiv:1410.5401Neural turing machines. arXiv preprintGraves, A., Wayne, G., and Danihelka, I. Neural turing machines. arXiv preprint arXiv:1410.5401 (2014).

J Gui, Z Sun, Y Wen, D Tao, Ye , J , A review on generative adversarial networks: Algorithms, theory, and applications. Gui, J., Sun, Z., Wen, Y., Tao, D., and Ye, J. A review on generative adversarial networks: Algorithms, theory, and applications, 2020.

Dynamic neural turing machine with soft and hard addressing schemes. C Gulcehre, S Chandar, K Cho, Y Bengio, arXiv:1607.00036arXiv preprintGulcehre, C., Chandar, S., Cho, K., and Bengio, Y. Dynamic neu- ral turing machine with soft and hard addressing schemes. arXiv preprint arXiv:1607.00036 (2016).

Improved training of wasserstein gans. I Gulrajani, F Ahmed, M Arjovsky, V Dumoulin, A Courville, Proceedings of the 31st International Conference on Neural Information Processing Systems. the 31st International Conference on Neural Information Processing SystemsRed Hook, NY, USACurran Associates IncNIPS'17Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., and Courville, A. Improved training of wasserstein gans. In Proceedings of the 31st Interna- tional Conference on Neural Information Processing Systems (Red Hook, NY, USA, 2017), NIPS'17, Curran Associates Inc., p. 5769-5779.

Lesion maskbased simultaneous synthesis of anatomic and molecular mr images using a gan. P Guo, P Wang, J Zhou, V M Patel, S Jiang, International Conference on Medical Image Computing and Computer-Assisted Intervention. SpringerGuo, P., Wang, P., Zhou, J., Patel, V. M., and Jiang, S. Lesion mask- based simultaneous synthesis of anatomic and molecular mr images using a gan. In International Conference on Medical Image Computing and Computer- Assisted Intervention (2020), Springer, pp. 104-113.

Exploring the effects of blur and deblurring to visual object tracking. Q Guo, W Feng, R Gao, Y Liu, Wang , S , IEEE Transactions on Image Processing. 30Guo, Q., Feng, W., Gao, R., Liu, Y., and Wang, S. Exploring the effects of blur and deblurring to visual object tracking. IEEE Transactions on Image Processing 30 (2021), 1812-1824.

S Gurumurthy, R K Sarvadevabhatla, V B Radhakrishnan, Deligan, Generative adversarial networks for diverse and limited data. Gurumurthy, S., Sarvadevabhatla, R. K., and Radhakrishnan, V. B. Deligan : Generative adversarial networks for diverse and limited data, 2017.

Cycle gan-based data augmentation for multi-organ detection in ct images via yolo. M Hammami, D Friboulet, R Kechichian, 2020 IEEE International Conference on Image Processing (ICIP) (2020). IEEEHammami, M., Friboulet, D., and Kechichian, R. Cycle gan-based data augmentation for multi-organ detection in ct images via yolo. In 2020 IEEE International Conference on Image Processing (ICIP) (2020), IEEE, pp. 390- 393.

Deep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionHe, K., Zhang, X., Ren, S., and Sun, J. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (2016), pp. 770-778.

Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems. M Heusel, H Ramsauer, T Unterthiner, B Nessler, S Hochreiter, 30Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., and Hochre- iter, S. Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems 30 (2017).

Generative adversarial networks for image to illustration translation. S Hicsonmez, N Samet, E Akbas, P Duygulu, Ganilla, Image and Vision Computing. 95103886Hicsonmez, S., Samet, N., Akbas, E., and Duygulu, P. Ganilla: Generative adversarial networks for image to illustration translation. Image and Vision Computing 95 (2020), 103886.

Denoising diffusion probabilistic models. J Ho, A Jain, Abbeel , P , Advances in Neural Information Processing Systems. 33Ho, J., Jain, A., and Abbeel, P. Denoising diffusion probabilistic models. Advances in Neural Information Processing Systems 33 (2020), 6840-6851.

Long short-term memory. S Hochreiter, J Schmidhuber, Neural computation. 9Hochreiter, S., and Schmidhuber, J. Long short-term memory. Neural computation 9, 8 (1997), 1735-1780.

Arbitrary style transfer in real-time with adaptive instance normalization. X Huang, S Belongie, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer VisionHuang, X., and Belongie, S. Arbitrary style transfer in real-time with adap- tive instance normalization. In Proceedings of the IEEE International Conference on Computer Vision (2017), pp. 1501-1510.

Receptive fields of single neurones in the cat's striate cortex. D H Hubel, T N Wiesel, The Journal of physiology. 148Hubel, D. H., and Wiesel, T. N. Receptive fields of single neurones in the cat's striate cortex. The Journal of physiology 148, 3 (1959), 574-591.

Image-to-image translation with conditional adversarial networks. P Isola, J.-Y Zhu, T Zhou, A A Efros, Isola, P., Zhu, J.-Y., Zhou, T., and Efros, A. A. Image-to-image transla- tion with conditional adversarial networks, 2018.

Y Jiang, S Chang, Z Wang, Transgan, arXiv:2102.07074Two transformers can make one strong gan. 13arXiv preprintJiang, Y., Chang, S., and Wang, Z. Transgan: Two transformers can make one strong gan. arXiv preprint arXiv:2102.07074 1, 3 (2021).

Unsupervised image enhancement for improved grape leaf disease recognition. H Jin, Y Li, J Qi, J Feng, D Tian, W Mu, Grapegan, Computers and Electronics in Agriculture. 198107055Jin, H., Li, Y., Qi, J., Feng, J., Tian, D., and Mu, W. Grapegan: Unsuper- vised image enhancement for improved grape leaf disease recognition. Computers and Electronics in Agriculture 198 (2022), 107055.

Deep learning for drug design: an artificial intelligence paradigm for drug discovery in the big data era. Y Jing, Y Bian, Z Hu, L Wang, X.-Q S Xie, The AAPS journal. 20Jing, Y., Bian, Y., Hu, Z., Wang, L., and Xie, X.-Q. S. Deep learning for drug design: an artificial intelligence paradigm for drug discovery in the big data era. The AAPS journal 20, 3 (2018), 1-10.

Perceptual losses for real-time style transfer and super-resolution. J Johnson, A Alahi, L Fei-Fei, European conference on computer vision. SpringerJohnson, J., Alahi, A., and Fei-Fei, L. Perceptual losses for real-time style transfer and super-resolution. In European conference on computer vision (2016), Springer, pp. 694-711.

High accuracy protein structure prediction using deep learning. Fourteenth Critical Assessment of Techniques for Protein Structure Prediction. J Jumper, R Evans, A Pritzel, T Green, M Figurnov, K Tunyasuvunakool, O Ronneberger, R Bates, A Žídek, A Bridgland, 24Abstract Book) 22 (2020Jumper, J., Evans, R., Pritzel, A., Green, T., Figurnov, M., Tunya- suvunakool, K., Ronneberger, O., Bates, R.,Žídek, A., Bridgland, A., et al. High accuracy protein structure prediction using deep learning. Fourteenth Critical Assessment of Techniques for Protein Structure Prediction (Abstract Book) 22 (2020), 24.

The cornucopia of meaningful leads: Applying deep adversarial autoencoders for new molecule development in oncology. A Kadurin, A Aliper, A Kazennov, P Mamoshina, Q Vanhaelen, K Khrabrov, A Zhavoronkov, Oncotarget. 810883Kadurin, A., Aliper, A., Kazennov, A., Mamoshina, P., Vanhaelen, Q., Khrabrov, K., and Zhavoronkov, A. The cornucopia of meaningful leads: Applying deep adversarial autoencoders for new molecule development in oncol- ogy. Oncotarget 8, 7 (2017), 10883.

drugan: an advanced generative adversarial autoencoder model for de novo generation of new molecules with desired molecular properties in silico. A Kadurin, S Nikolenko, K Khrabrov, A Aliper, A Zhavoronkov, Molecular pharmaceutics. 14Kadurin, A., Nikolenko, S., Khrabrov, K., Aliper, A., and Zha- voronkov, A. drugan: an advanced generative adversarial autoencoder model for de novo generation of new molecules with desired molecular properties in silico. Molecular pharmaceutics 14, 9 (2017), 3098-3104.

Forward-backward error: Automatic detection of tracking failures. Z Kalal, K Mikolajczyk, J Matas, 2010 20th international conference on pattern recognition. IEEEKalal, Z., Mikolajczyk, K., and Matas, J. Forward-backward error: Au- tomatic detection of tracking failures. In 2010 20th international conference on pattern recognition (2010), IEEE, pp. 2756-2759.

Cyclic-synthesized generative adversarial networks for image-to-image transformation. K B Kancharagunta, S R Dubey, Csgan, arXiv:1901.03554arXiv preprintKancharagunta, K. B., and Dubey, S. R. Csgan: Cyclic-synthesized gen- erative adversarial networks for image-to-image transformation. arXiv preprint arXiv:1901.03554 (2019).

Progressive growing of gans for improved quality, stability, and variation. T Karras, T Aila, S Laine, J Lehtinen, Karras, T., Aila, T., Laine, S., and Lehtinen, J. Progressive growing of gans for improved quality, stability, and variation, 2018.

T Karras, M Aittala, S Laine, E Härkönen, J Hellsten, J Lehtinen, Aila , T , arXiv:2106.12423Alias-free generative adversarial networks. arXiv preprintKarras, T., Aittala, M., Laine, S., Härkönen, E., Hellsten, J., Lehti- nen, J., and Aila, T. Alias-free generative adversarial networks. arXiv preprint arXiv:2106.12423 (2021).

A style-based generator architecture for generative adversarial networks. T Karras, S Laine, Aila , T , Karras, T., Laine, S., and Aila, T. A style-based generator architecture for generative adversarial networks, 2019.

Learning to simulate dynamic environments with gamegan. S W Kim, Y Zhou, J Philion, A Torralba, S Fidler, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionKim, S. W., Zhou, Y., Philion, J., Torralba, A., and Fidler, S. Learn- ing to simulate dynamic environments with gamegan. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2020), pp. 1231-1240.

Learning to discover cross-domain relations with generative adversarial networks. T Kim, M Cha, H Kim, J K Lee, Kim , J , PMLRInternational Conference on Machine Learning. Kim, T., Cha, M., Kim, H., Lee, J. K., and Kim, J. Learning to discover cross-domain relations with generative adversarial networks. In International Conference on Machine Learning (2017), PMLR, pp. 1857-1865.

Gan-based ppg augmentation for medical diagnosis in low-resource settings. D Kiyasseh, G A Tadesse, L Thwaites, T Zhu, D Clifton, IEEE journal of biomedical and health informatics. 24Kiyasseh, D., Tadesse, G. A., Thwaites, L., Zhu, T., Clifton, D., et al. Plethaugment: Gan-based ppg augmentation for medical diagnosis in low-resource settings. IEEE journal of biomedical and health informatics 24, 11 (2020), 3226-3235.

Federated learning: Strategies for improving communication efficiency. J Konečnỳ, H B Mcmahan, F X Yu, P Richtárik, A T Suresh, D Bacon, arXiv:1610.05492arXiv preprintKonečnỳ, J., McMahan, H. B., Yu, F. X., Richtárik, P., Suresh, A. T., and Bacon, D. Federated learning: Strategies for improving communication efficiency. arXiv preprint arXiv:1610.05492 (2016).

Vulnerability assessment and detection of deepfake videos. P Korshunov, Marcel , S , 2019 International Conference on Biometrics (ICB). IEEEKorshunov, P., and Marcel, S. Vulnerability assessment and detection of deepfake videos. In 2019 International Conference on Biometrics (ICB) (2019), IEEE, pp. 1-6.

Synthesizing anonymized and labeled tof-mra patches for brain vessel segmentation using generative adversarial networks. T Kossen, P Subramaniam, V I Madai, A Hennemuth, K Hildebrand, A Hilbert, J Sobesky, M Livne, I Galinovic, A A Khalil, Computers in biology and medicine. 131104254Kossen, T., Subramaniam, P., Madai, V. I., Hennemuth, A., Hildebrand, K., Hilbert, A., Sobesky, J., Livne, M., Galinovic, I., Khalil, A. A., et al. Synthesizing anonymized and labeled tof-mra patches for brain vessel segmentation using generative adversarial networks. Computers in biology and medicine 131 (2021), 104254.

Learning multiple layers of features from tiny images. A Krizhevsky, G Hinton, Krizhevsky, A., Hinton, G., et al. Learning multiple layers of features from tiny images.

The GAN landscape: Losses, architectures, regularization, and normalization. K Kurach, M Lucic, X Zhai, M Michalski, S Gelly, Kurach, K., Lucic, M., Zhai, X., Michalski, M., and Gelly, S. The GAN landscape: Losses, architectures, regularization, and normalization, 2019.

Evolution of neural text generation: Comparative analysis. L Kurup, M Narvekar, R Sarvaiya, A Shah, Advances in Computer, Communication and Computational Sciences. SpringerKurup, L., Narvekar, M., Sarvaiya, R., and Shah, A. Evolution of neural text generation: Comparative analysis. In Advances in Computer, Communica- tion and Computational Sciences. Springer, 2021, pp. 795-804.

Deepfake: A social construction of technology perspective. A O Kwok, S G Koh, Current Issues in Tourism. 24Kwok, A. O., and Koh, S. G. Deepfake: A social construction of technology perspective. Current Issues in Tourism 24, 13 (2021), 1798-1802.

Feature-based metrics for exploring the latent space of generative models. S Laine, ICLR workshop poster. Laine, S. Feature-based metrics for exploring the latent space of generative models. ICLR workshop poster (2018).

Gradient-based learning applied to document recognition. Y Lecun, L Bottou, Y Bengio, P Haffner, Proceedings of the IEEE. 86LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P. Gradient-based learning applied to document recognition. Proceedings of the IEEE 86, 11 (1998), 2278-2324.

Photorealistic single image super-resolution using a generative adversarial network. C Ledig, L Theis, F Huszár, J Caballero, A Cunningham, A Acosta, A Aitken, A Tejani, J Totz, Z Wang, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionLedig, C., Theis, L., Huszár, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Tejani, A., Totz, J., Wang, Z., et al. Photo- realistic single image super-resolution using a generative adversarial network. In Proceedings of the IEEE conference on computer vision and pattern recognition (2017), pp. 4681-4690.

Testing statistical hypotheses. E L Lehmann, J P Romano, Springer Science & Business MediaLehmann, E. L., and Romano, J. P. Testing statistical hypotheses. Springer Science & Business Media, 2006.

Mmd gan: Towards deeper understanding of moment matching network. C.-L Li, W.-C Chang, Y Cheng, Y Yang, Póczos , B , Li, C.-L., Chang, W.-C., Cheng, Y., Yang, Y., and Póczos, B. Mmd gan: Towards deeper understanding of moment matching network, 2017.

Fwdganbased data augmentation for tomato leaf disease identification. M Li, G Zhou, A Chen, J Yi, C Lu, M He, Y Hu, Computers and Electronics in Agriculture. 194106779Li, M., Zhou, G., Chen, A., Yi, J., Lu, C., He, M., and Hu, Y. Fwdgan- based data augmentation for tomato leaf disease identification. Computers and Electronics in Agriculture 194 (2022), 106779.

Tackling mode collapse in multi-generator gans with orthogonal vectors. W Li, L Fan, Z Wang, C Ma, X Cui, Pattern Recognition. 110107646Li, W., Fan, L., Wang, Z., Ma, C., and Cui, X. Tackling mode collapse in multi-generator gans with orthogonal vectors. Pattern Recognition 110 (2021), 107646.

A sar-to-optical image translation method based on conditional generation adversarial network (cgan). Y Li, R Fu, X Meng, W Jin, F Shao, Li, Y., Fu, R., Meng, X., Jin, W., and Shao, F. A sar-to-optical image translation method based on conditional generation adversarial network (cgan).

. IEEE Access. 8IEEE Access 8 (2020), 60338-60343.

Video generation from text. Y Li, M Min, D Shen, D Carlson, Carin , L , Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence32Li, Y., Min, M., Shen, D., Carlson, D., and Carin, L. Video generation from text. Proceedings of the AAAI Conference on Artificial Intelligence 32, 1 (Apr. 2018).

Improved boundary equilibrium generative adversarial networks. Y Li, N Xiao, W Ouyang, IEEE Access. 6Li, Y., Xiao, N., and Ouyang, W. Improved boundary equilibrium generative adversarial networks. IEEE Access 6 (2018), 11342-11348.

An improved dualgan for near-infrared image colorization. W Liang, D Ding, Wei , G , Infrared Physics & Technology. 116103764Liang, W., Ding, D., and Wei, G. An improved dualgan for near-infrared image colorization. Infrared Physics & Technology 116 (2021), 103764.

Conditional image-toimage translation. J Lin, Y Xia, T Qin, Z Chen, T.-Y Liu, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionLin, J., Xia, Y., Qin, T., Chen, Z., and Liu, T.-Y. Conditional image-to- image translation. In Proceedings of the IEEE conference on computer vision and pattern recognition (2018), pp. 5524-5532.

. T.-Y Lin, M Maire, S Belongie, J Hays, P Perona, D Ramanan, P Dollár, C L Zitnick, Microsoft coco: Common objects in contextLin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., and Zitnick, C. L. Microsoft coco: Common objects in context.

European conference on computer vision. SpringerIn European conference on computer vision (2014), Springer, pp. 740-755.

A super resolution algorithm based on attention mechanism and srgan network. B Liu, Chen , J , IEEE Access. Liu, B., and Chen, J. A super resolution algorithm based on attention mech- anism and srgan network. IEEE Access (2021).

Dynamically grown generative adversarial networks. L Liu, Y Zhang, J Deng, S Soatto, Proceedings of the AAAI Conference on Artificial Intelligence (2021). the AAAI Conference on Artificial Intelligence (2021)35Liu, L., Zhang, Y., Deng, J., and Soatto, S. Dynamically grown genera- tive adversarial networks. In Proceedings of the AAAI Conference on Artificial Intelligence (2021), vol. 35, pp. 8680-8687.

High-resolution image synthesis and semantic manipulation with conditional gans. M Liu, J Zhu, A Tao, J Kautz, B Catanzaro, Liu, M., Zhu, J., Tao, A., Kautz, J., and Catanzaro, B. High-resolution image synthesis and semantic manipulation with conditional gans. In ICCV (2017).

Diverse conditional image synthesis via contrastive generative adversarial network. R Liu, Y Ge, C L Choi, X Wang, H Li, Divco, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)Liu, R., Ge, Y., Choi, C. L., Wang, X., and Li, H. Divco: Diverse condi- tional image synthesis via contrastive generative adversarial network. In Proceed- ings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (June 2021), pp. 16377-16386.

Approximation and convergence properties of generative adversarial learning. S Liu, O Bousquet, K Chaudhuri, Liu, S., Bousquet, O., and Chaudhuri, K. Approximation and convergence properties of generative adversarial learning, 2017.

A deep transfer learning model with classical data augmentation and cgan to detect covid-19 from chest ct radiography digital images. M Loey, G Manogaran, N E Khalifa, Neural Computing and Applications. Loey, M., Manogaran, G., and Khalifa, N. E. M. A deep transfer learning model with classical data augmentation and cgan to detect covid-19 from chest ct radiography digital images. Neural Computing and Applications (2020), 1-13.

Revisiting classifier two-sample tests. D Lopez-Paz, M Oquab, Lopez-Paz, D., and Oquab, M. Revisiting classifier two-sample tests, 2018.

Variational autoencoder reconstruction of complex many-body physics. I A Luchnikov, A Ryzhov, P.-J Stas, S N Filippov, H Ouerdane, Entropy. 211091Luchnikov, I. A., Ryzhov, A., Stas, P.-J., Filippov, S. N., and Ouerdane, H. Variational autoencoder reconstruction of complex many-body physics. En- tropy 21, 11 (2019), 1091.

Emotional voice conversion using dual supervised adversarial networks with continuous wavelet transform f0 features. Z Luo, J Chen, T Takiguchi, Ariki , Y , IEEE/ACM Transactions on Audio, Speech, and Language Processing. 27Luo, Z., Chen, J., Takiguchi, T., and Ariki, Y. Emotional voice conversion using dual supervised adversarial networks with continuous wavelet transform f0 features. IEEE/ACM Transactions on Audio, Speech, and Language Processing 27, 10 (2019), 1535-1548.

An improved gan with transformers for pedestrian trajectory prediction models. Z Lv, X Huang, W Cao, International Journal of Intelligent Systems. 37Lv, Z., Huang, X., and Cao, W. An improved gan with transformers for pedestrian trajectory prediction models. International Journal of Intelligent Systems 37, 8 (2022), 4417-4436.

Speckle noise reduction in optical coherence tomography images based on edge-sensitive cgan. Y Ma, X Chen, W Zhu, X Cheng, D Xiang, F Shi, Biomedical optics express. 9Ma, Y., Chen, X., Zhu, W., Cheng, X., Xiang, D., and Shi, F. Speckle noise reduction in optical coherence tomography images based on edge-sensitive cgan. Biomedical optics express 9, 11 (2018), 5129-5146.

The emerging commercial landscape of quantum computing. E R Macquarrie, C Simon, S Simmons, E Maine, Nature Reviews Physics. 2MacQuarrie, E. R., Simon, C., Simmons, S., and Maine, E. The emerging commercial landscape of quantum computing. Nature Reviews Physics 2, 11 (2020), 596-598.

Fl-disco: Federated generative adversarial network for graph-based molecule drug discovery: Special session paper. D Manu, Y Sheng, J Yang, J Deng, T Geng, A Li, C Ding, W Jiang, Yang , L , 2021Manu, D., Sheng, Y., Yang, J., Deng, J., Geng, T., Li, A., Ding, C., Jiang, W., and Yang, L. Fl-disco: Federated generative adversarial net- work for graph-based molecule drug discovery: Special session paper. In 2021

IEEE/ACM International Conference On Computer Aided Design (ICCAD) (2021). IEEEIEEE/ACM International Conference On Computer Aided Design (ICCAD) (2021), IEEE, pp. 1-7.

Least squares generative adversarial networks. X Mao, Q Li, H Xie, R Y Lau, Z Wang, Paul Smolley, S , Proceedings of the IEEE International Conference on Computer Vision (ICCV. the IEEE International Conference on Computer Vision (ICCVMao, X., Li, Q., Xie, H., Lau, R. Y., Wang, Z., and Paul Smolley, S. Least squares generative adversarial networks. In Proceedings of the IEEE International Conference on Computer Vision (ICCV) (Oct 2017).

Historia del" fake" audiovisual:" deepfake" y la mujer en un imaginario falsificado y perverso. V C Martínez, G P Castillo, Historia y comunicación social. 2455Martínez, V. C., and Castillo, G. P. Historia del" fake" audiovisual:" deep- fake" y la mujer en un imaginario falsificado y perverso. Historia y comunicación social 24, 2 (2019), 55.

Rodeo: robust de-aliasing autoencoder for real-time medical image reconstruction. J Mehta, A Majumdar, Pattern Recognition. 63Mehta, J., and Majumdar, A. Rodeo: robust de-aliasing autoencoder for real-time medical image reconstruction. Pattern Recognition 63 (2017), 499- 510.

Unrolled generative adversarial networks. L Metz, B Poole, D Pfau, J Sohl-Dickstein, Metz, L., Poole, B., Pfau, D., and Sohl-Dickstein, J. Unrolled generative adversarial networks, 2017.

The bures metric for generative adversarial networks. H D Meulemeester, J Schreurs, M Fanuel, B D Moor, J A Suykens, Meulemeester, H. D., Schreurs, J., Fanuel, M., Moor, B. D., and Suykens, J. A. K. The bures metric for generative adversarial networks, 2021.

Conditional generative adversarial nets. M Mirza, S Osindero, Mirza, M., and Osindero, S. Conditional generative adversarial nets, 2014.

Spectral normalization for generative adversarial networks. T Miyato, T Kataoka, M Koyama, Yoshida , Y , arXiv:1802.05957arXiv preprintMiyato, T., Kataoka, T., Koyama, M., and Yoshida, Y. Spectral normal- ization for generative adversarial networks. arXiv preprint arXiv:1802.05957 (2018).

Learning data augmentation for brain tumor segmentation with coarse-to-fine generative adversarial networks. T C Mok, Chung , A , International MICCAI Brainlesion Workshop. SpringerMok, T. C., and Chung, A. Learning data augmentation for brain tumor seg- mentation with coarse-to-fine generative adversarial networks. In International MICCAI Brainlesion Workshop (2018), Springer, pp. 70-80.

Feasibility of new fat suppression for breast mri using pix2pix. M Mori, T Fujioka, L Katsuta, Y Kikuchi, G Oda, T Nakagawa, Y Kitazume, K Kubota, U Tateishi, Japanese Journal of Radiology. 38Mori, M., Fujioka, T., Katsuta, L., Kikuchi, Y., Oda, G., Nakagawa, T., Kitazume, Y., Kubota, K., and Tateishi, U. Feasibility of new fat suppression for breast mri using pix2pix. Japanese Journal of Radiology 38, 11 (2020), 1075-1081.

Non-cooperative games. J Nash, Annals of mathematics. Nash, J. Non-cooperative games. Annals of mathematics (1951), 286-295.

Diversified sensitivity-based undersampling for imbalance classification problems. W W Ng, J Hu, D S Yeung, S Yin, F Roli, IEEE transactions on cybernetics. 45Ng, W. W., Hu, J., Yeung, D. S., Yin, S., and Roli, F. Diversified sensitivity-based undersampling for imbalance classification problems. IEEE transactions on cybernetics 45, 11 (2014), 2402-2412.

Automated flower classification over a large number of classes. M.-E Nilsback, A Zisserman, Sixth Indian Conference on Computer Vision, Graphics & Image Processing. IEEENilsback, M.-E., and Zisserman, A. Automated flower classification over a large number of classes. In 2008 Sixth Indian Conference on Computer Vision, Graphics & Image Processing (2008), IEEE, pp. 722-729.

M Y Niu, A Zlokapa, M Broughton, S Boixo, M Mohseni, V Smelyanskyi, H Neven, arXiv:2105.00080Entangling quantum generative adversarial networks. arXiv preprintNiu, M. Y., Zlokapa, A., Broughton, M., Boixo, S., Mohseni, M., Smelyanskyi, V., and Neven, H. Entangling quantum generative adversarial networks. arXiv preprint arXiv:2105.00080 (2021).

S Nowozin, B Cseke, R Tomioka, Training generative neural samplers using variational divergence minimization. Nowozin, S., Cseke, B., and Tomioka, R. f-gan: Training generative neural samplers using variational divergence minimization, 2016.

Conditional image synthesis with auxiliary classifier gans. A Odena, C Olah, J Shlens, PMLRInternational conference on machine learning. Odena, A., Olah, C., and Shlens, J. Conditional image synthesis with auxiliary classifier gans. In International conference on machine learning (2017), PMLR, pp. 2642-2651.

Drug discovery using generative adversarial network with reinforcement learning. G R Padalkar, S D Patil, M M Hegadi, N K Jaybhaye, 2021 International Conference on Computer Communication and Informatics (ICCCI) (2021). IEEEPadalkar, G. R., Patil, S. D., Hegadi, M. M., and Jaybhaye, N. K. Drug discovery using generative adversarial network with reinforcement learning. In 2021 International Conference on Computer Communication and Informatics (ICCCI) (2021), IEEE, pp. 1-3.

Stochastic pix2pix: a new machine learning method for geophysical and well conditioning of rule-based channel reservoir models. W Pan, C Torres-Verdín, M J Pyrcz, Natural Resources Research. 30Pan, W., Torres-Verdín, C., and Pyrcz, M. J. Stochastic pix2pix: a new machine learning method for geophysical and well conditioning of rule-based channel reservoir models. Natural Resources Research 30, 2 (2021), 1319-1345.

Loss functions of generative adversarial networks (gans): opportunities and challenges. Z Pan, W Yu, B Wang, H Xie, V S Sheng, J Lei, S Kwong, IEEE Transactions on Emerging Topics in Computational Intelligence. 4Pan, Z., Yu, W., Wang, B., Xie, H., Sheng, V. S., Lei, J., and Kwong, S. Loss functions of generative adversarial networks (gans): opportunities and chal- lenges. IEEE Transactions on Emerging Topics in Computational Intelligence 4, 4 (2020), 500-522.

Recent progress on generative adversarial networks (gans): A survey. Z Pan, W Yu, X Yi, A Khan, F Yuan, Y Zheng, IEEE Access. 7Pan, Z., Yu, W., Yi, X., Khan, A., Yuan, F., and Zheng, Y. Recent progress on generative adversarial networks (gans): A survey. IEEE Access 7 (2019), 36322-36333.

Mobile image enhancement via a multi-module cascade neural network. Z Pan, F Yuan, J Lei, W Li, N Ling, S Kwong, Miegan, IEEE Transactions on Multimedia. 24Pan, Z., Yuan, F., Lei, J., Li, W., Ling, N., and Kwong, S. Miegan: Mobile image enhancement via a multi-module cascade neural network. IEEE Transactions on Multimedia 24 (2021), 519-533.

Sphere generative adversarial network based on geometric moment matching. S W Park, J Kwon, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionPark, S. W., and Kwon, J. Sphere generative adversarial network based on geometric moment matching. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2019), pp. 4292-4301.

S Pei, R Y Da Xu, G Meng, Dp-Gan, arXiv:2108.02353Alleviating mode collapse in gan via diversity penalty module. arXiv preprintPei, S., Da Xu, R. Y., and Meng, G. dp-gan: Alleviating mode collapse in gan via diversity penalty module. arXiv preprint arXiv:2108.02353 (2021).

Synthetic ct generation from mri using improved dualgan. D Prokopenko, J V Stadelmann, H Schulz, S Renisch, D V Dylov, arXiv:1909.08942arXiv preprintProkopenko, D., Stadelmann, J. V., Schulz, H., Renisch, S., and Dylov, D. V. Synthetic ct generation from mri using improved dualgan. arXiv preprint arXiv:1909.08942 (2019).

Saggan: Semi-supervised attention-guided gans for data augmentation on medical images. C Qi, J Chen, G Xu, Z Xu, T Lukasiewicz, Y Liu, arXiv:2011.07534arXiv preprintQi, C., Chen, J., Xu, G., Xu, Z., Lukasiewicz, T., and Liu, Y. Sag- gan: Semi-supervised attention-guided gans for data augmentation on medical images. arXiv preprint arXiv:2011.07534 (2020).

Loss-sensitive generative adversarial networks on lipschitz densities. G Qi, arXiv:1701.06264corr abs/1701.06264. arXiv preprintQi, G. Loss-sensitive generative adversarial networks on lipschitz densities, corr abs/1701.06264. arXiv preprint arXiv:1701.06264 (2017).

Enhanced pix2pix dehazing network. Y Qu, Y Chen, J Huang, Y Xie, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionQu, Y., Chen, Y., Huang, J., and Xie, Y. Enhanced pix2pix dehazing network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2019), pp. 8160-8168.

Unsupervised representation learning with deep convolutional generative adversarial networks. A Radford, L Metz, S Chintala, Radford, A., Metz, L., and Chintala, S. Unsupervised representation learn- ing with deep convolutional generative adversarial networks, 2016.

Smote-rs b*: a hybrid preprocessing approach based on oversampling and undersampling for high imbalanced data-sets using smote and rough sets theory. E Ramentol, Y Caballero, R Bello, F Herrera, Knowledge and information systems. 33Ramentol, E., Caballero, Y., Bello, R., and Herrera, F. Smote-rs b*: a hybrid preprocessing approach based on oversampling and undersampling for high imbalanced data-sets using smote and rough sets theory. Knowledge and information systems 33, 2 (2012), 245-265.

Generative adversarial text to image synthesis. S Reed, Z Akata, X Yan, L Logeswaran, B Schiele, H Lee, PMLRInternational Conference on Machine Learning. Reed, S., Akata, Z., Yan, X., Logeswaran, L., Schiele, B., and Lee, H. Generative adversarial text to image synthesis. In International Conference on Machine Learning (2016), PMLR, pp. 1060-1069.

Learning what and where to draw. S E Reed, Z Akata, S Mohan, S Tenka, B Schiele, H Lee, Advances in neural information processing systems. 29Reed, S. E., Akata, Z., Mohan, S., Tenka, S., Schiele, B., and Lee, H. Learning what and where to draw. Advances in neural information processing systems 29 (2016), 217-225.

Video deblurring by fitting to test data. X Ren, Z Qian, Chen , Q , arXiv:2012.05228arXiv preprintRen, X., Qian, Z., and Chen, Q. Video deblurring by fitting to test data. arXiv preprint arXiv:2012.05228 (2020).

. A A Rusu, N C Rabinowitz, G Desjardins, H Soyer, J Kirkpatrick, K Kavukcuoglu, R Pascanu, R Hadsell, arXiv:1606.04671Progressive neural networks. arXiv preprintRusu, A. A., Rabinowitz, N. C., Desjardins, G., Soyer, H., Kirkpatrick, J., Kavukcuoglu, K., Pascanu, R., and Hadsell, R. Progressive neural networks. arXiv preprint arXiv:1606.04671 (2016).

Palette: Image-to-image diffusion models. C Saharia, W Chan, H Chang, C Lee, J Ho, T Salimans, D Fleet, M Norouzi, ACM SIGGRAPH 2022 Conference Proceedings. Saharia, C., Chan, W., Chang, H., Lee, C., Ho, J., Salimans, T., Fleet, D., and Norouzi, M. Palette: Image-to-image diffusion models. In ACM SIGGRAPH 2022 Conference Proceedings (2022), pp. 1-10.

T Sainburg, M Thielk, B Theilman, B Migliori, T Gentner, arXiv:1807.06650Generative adversarial interpolative autoencoding: adversarial training on latent space interpolations encourage convex latent distributions. arXiv preprintSainburg, T., Thielk, M., Theilman, B., Migliori, B., and Gentner, T. Generative adversarial interpolative autoencoding: adversarial training on latent space interpolations encourage convex latent distributions. arXiv preprint arXiv:1807.06650 (2018).

. T Salimans, I Goodfellow, W Zaremba, V Cheung, A Radford, Chen , X , Improved techniques for training gansSalimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., and Chen, X. Improved techniques for training gans, 2016.

Weight normalization: A simple reparameterization to accelerate training of deep neural networks. T Salimans, D P Kingma, Advances in neural information processing systems. 29Salimans, T., and Kingma, D. P. Weight normalization: A simple reparam- eterization to accelerate training of deep neural networks. Advances in neural information processing systems 29 (2016), 901-909.

A survey on generative adversarial networks for imbalance problems in computer vision tasks. V Sampath, I Maurtua, J J A Martín, A Gutierrez, Journal of big Data. 8Sampath, V., Maurtua, I., Martín, J. J. A., and Gutierrez, A. A survey on generative adversarial networks for imbalance problems in computer vision tasks. Journal of big Data 8, 1 (2021), 1-59.

Data augmentation of 3d brain environment using deep convolutional refined auto-encoding alpha gan. A Segato, V Corbetta, M Di Marzo, L Pozzi, De Momi, E , IEEE Transactions on Medical Robotics and Bionics. 3Segato, A., Corbetta, V., Di Marzo, M., Pozzi, L., and De Momi, E. Data augmentation of 3d brain environment using deep convolutional refined auto-encoding alpha gan. IEEE Transactions on Medical Robotics and Bionics 3, 1 (2020), 269-272.

A mathematical theory of communication. The Bell system technical journal. C E Shannon, 27Shannon, C. E. A mathematical theory of communication. The Bell system technical journal 27, 3 (1948), 379-423.

Very deep convolutional networks for largescale image recognition. K Simonyan, A Zisserman, International Conference on Learning Representations. Simonyan, K., and Zisserman, A. Very deep convolutional networks for large- scale image recognition. In International Conference on Learning Representa- tions (2015).

Generative modeling by estimating gradients of the data distribution. Y Song, S Ermon, Advances in Neural Information Processing Systems. 32Song, Y., and Ermon, S. Generative modeling by estimating gradients of the data distribution. Advances in Neural Information Processing Systems 32 (2019).

Striving for simplicity: The all convolutional net. J T Springenberg, A Dosovitskiy, T Brox, M Riedmiller, Springenberg, J. T., Dosovitskiy, A., Brox, T., and Riedmiller, M. Striving for simplicity: The all convolutional net, 2015.

S A Stein, B Baheri, R M Tischio, Y Mao, Q Guan, A Li, B Fang, S Xu, Qugan, arXiv:2010.09036A generative adversarial network through quantum states. arXiv preprintStein, S. A., Baheri, B., Tischio, R. M., Mao, Y., Guan, Q., Li, A., Fang, B., and Xu, S. Qugan: A generative adversarial network through quantum states. arXiv preprint arXiv:2010.09036 (2020).

Gan-qp: A novel gan framework without gradient vanishing and lipschitz constraint. J Su, Su, J. Gan-qp: A novel gan framework without gradient vanishing and lipschitz constraint, 2018.

Classification enhancement generative adversarial networks for unraveling data imbalance problems. S Suh, H Lee, P Lukowicz, Y O Lee, Cegan, Neural Networks. 133Suh, S., Lee, H., Lukowicz, P., and Lee, Y. O. Cegan: Classification en- hancement generative adversarial networks for unraveling data imbalance prob- lems. Neural Networks 133 (2021), 69-86.

A comparison study of vae and gan for software fault prediction. Y Sun, L Xu, L Guo, Y Li, Wang , Y , Algorithms and Architectures for Parallel Processing. S. Wen, A. Zomaya, and L. T. YangChamSpringer International PublishingSun, Y., Xu, L., Guo, L., Li, Y., and Wang, Y. A comparison study of vae and gan for software fault prediction. In Algorithms and Architectures for Parallel Processing (Cham, 2020), S. Wen, A. Zomaya, and L. T. Yang, Eds., Springer International Publishing, pp. 82-96.

Dense point trajectories by gpuaccelerated large displacement optical flow. N Sundaram, T Brox, K Keutzer, European conference on computer vision. SpringerSundaram, N., Brox, T., and Keutzer, K. Dense point trajectories by gpu- accelerated large displacement optical flow. In European conference on computer vision (2010), Springer, pp. 438-451.

The toronto face dataset. J Susskind, A Anderson, G E Hinton, UTML TR 2010-001U. TorontoTechnical ReportSusskind, J., Anderson, A., and Hinton, G. E. The toronto face dataset. Tech. rep., Technical Report UTML TR 2010-001, U. Toronto, 2010.

Going deeper with convolutions. C Szegedy, W Liu, Y Jia, P Sermanet, S Reed, D Anguelov, D Erhan, V Vanhoucke, A Rabinovich, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionSzegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., and Rabinovich, A. Going deeper with convo- lutions. In Proceedings of the IEEE conference on computer vision and pattern recognition (2015), pp. 1-9.

Rethinking the inception architecture for computer vision. C Szegedy, V Vanhoucke, S Ioffe, J Shlens, Z Wojna, Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z. Re- thinking the inception architecture for computer vision, 2015.

M Tancik, P P Srinivasan, B Mildenhall, S Fridovich-Keil, N Raghavan, U Singhal, R Ramamoorthi, J T Barron, R Ng, arXiv:2006.10739Fourier features let networks learn high frequency functions in low dimensional domains. arXiv preprintTancik, M., Srinivasan, P. P., Mildenhall, B., Fridovich-Keil, S., Raghavan, N., Singhal, U., Ramamoorthi, R., Barron, J. T., and Ng, R. Fourier features let networks learn high frequency functions in low dimensional domains. arXiv preprint arXiv:2006.10739 (2020).

M Tao, H Tang, S Wu, N Sebe, X.-Y Jing, F Wu, B Bao, Df-Gan, arXiv:2008.05865Deep fusion generative adversarial networks for text-to-image synthesis. arXiv preprintTao, M., Tang, H., Wu, S., Sebe, N., Jing, X.-Y., Wu, F., and Bao, B. Df-gan: Deep fusion generative adversarial networks for text-to-image synthesis. arXiv preprint arXiv:2008.05865 (2020).

Catastrophic forgetting and mode collapse in gans. H Thanh-Tung, Tran , T , 2020 International Joint Conference on Neural Networks (IJCNN) (2020). Thanh-Tung, H., and Tran, T. Catastrophic forgetting and mode collapse in gans. In 2020 International Joint Conference on Neural Networks (IJCNN) (2020), pp. 1-10.

Improving generalization and stability of generative adversarial networks. H Thanh-Tung, T Tran, S Venkatesh, Thanh-Tung, H., Tran, T., and Venkatesh, S. Improving generalization and stability of generative adversarial networks, 2019.

On data augmentation for gan training. N.-T Tran, V.-H Tran, N.-B Nguyen, T.-K Nguyen, N.-M Cheung, IEEE Transactions on Image Processing. 30Tran, N.-T., Tran, V.-H., Nguyen, N.-B., Nguyen, T.-K., and Cheung, N.-M. On data augmentation for gan training. IEEE Transactions on Image Processing 30 (2021), 1882-1897.

Spatial pattern templates for recognition of objects with regular structure. R Tyleček, R Andšára, SpringerIn German conference on pattern recognitionTyleček, R., andŠára, R. Spatial pattern templates for recognition of objects with regular structure. In German conference on pattern recognition (2013), Springer, pp. 364-374.

Generation of annotated brain tumor mris with tumor-induced tissue deformations for training and assessment of neural networks. H Uzunova, J Ehrhardt, H Handels, International Conference on Medical Image Computing and Computer-Assisted Intervention. SpringerUzunova, H., Ehrhardt, J., and Handels, H. Generation of annotated brain tumor mris with tumor-induced tissue deformations for training and assessment of neural networks. In International Conference on Medical Image Computing and Computer-Assisted Intervention (2020), Springer, pp. 501-511.

A Van Den Oord, N Kalchbrenner, Rnn, ICML. van den Oord, A., and Kalchbrenner, N. Pixel rnn. In ICML (2016).

Attention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, L Kaiser, I Polosukhin, Advances in neural information processing systems. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., and Polosukhin, I. Attention is all you need. In Advances in neural information processing systems (2017), pp. 5998-6008.

Towards end-to-end f0 voice conversion based on dual-gan with convolutional wavelet kernels. C L M Veillon, N Obin, A Roebel, arXiv:2104.07283arXiv preprintVeillon, C. L. M., Obin, N., and Roebel, A. Towards end-to-end f0 voice conversion based on dual-gan with convolutional wavelet kernels. arXiv preprint arXiv:2104.07283 (2021).

C Wah, S Branson, P Welinder, P Perona, S Belongie, The caltech-ucsd birds-200-2011 dataset. Wah, C., Branson, S., Welinder, P., Perona, P., and Belongie, S. The caltech-ucsd birds-200-2011 dataset.

. K Wang, C Gou, Y Duan, Y Lin, X Zheng, F.-Y Wang, Wang, K., Gou, C., Duan, Y., Lin, Y., Zheng, X., and Wang, F.-Y.

Generative adversarial networks: introduction and outlook. IEEE/CAA Journal of Automatica Sinica. 4Generative adversarial networks: introduction and outlook. IEEE/CAA Journal of Automatica Sinica 4, 4 (2017), 588-598.

High-quality facial photo-sketch synthesis using multi-adversarial networks. L Wang, V Sindagi, Patel , V , 13th IEEE international conference on automatic face & gesture recognition (FG 2018). IEEEWang, L., Sindagi, V., and Patel, V. High-quality facial photo-sketch synthe- sis using multi-adversarial networks. In 2018 13th IEEE international conference on automatic face & gesture recognition (FG 2018) (2018), IEEE, pp. 83-90.

Face photo-sketch synthesis and recognition. X Wang, X Tang, 31Wang, X., and Tang, X. Face photo-sketch synthesis and recognition. IEEE transactions on pattern analysis and machine intelligence 31, 11 (2008), 1955- 1967.

Generative adversarial networks in computer vision: A survey and taxonomy. Z Wang, Q She, T E Ward, Wang, Z., She, Q., and Ward, T. E. Generative adversarial networks in computer vision: A survey and taxonomy, 2020.

Multiscale structural similarity for image quality assessment. Z Wang, E Simoncelli, A Bovik, The Thrity-Seventh Asilomar Conference on Signals. 2Wang, Z., Simoncelli, E., and Bovik, A. Multiscale structural similarity for image quality assessment. In The Thrity-Seventh Asilomar Conference on Signals, Systems Computers, 2003 (2003), vol. 2, pp. 1398-1402 Vol.2.

. L Weng, From Gan To Wgan, arXiv:1904.08994arXiv preprintWeng, L. From gan to wgan. arXiv preprint arXiv:1904.08994 (2019).

The emergence of deepfake technology: A review. M Westerlund, Technology Innovation Management Review. 911Westerlund, M. The emergence of deepfake technology: A review. Technology Innovation Management Review 9, 11 (2019).

. J Weston, S Chopra, A Bordes, arXiv:1410.3916Memory networks. arXiv preprintWeston, J., Chopra, S., and Bordes, A. Memory networks. arXiv preprint arXiv:1410.3916 (2014).

Stabilizing generative adversarial network training: A survey. M Wiatrak, Albrecht , S V , arXivWiatrak, M., and Albrecht, S. V. Stabilizing generative adversarial network training: A survey. arXiv (2019).

L1 norm batch normalization for efficient training of deep neural networks. S Wu, G Li, L Deng, L Liu, D Wu, Y Xie, L Shi, IEEE Transactions on Neural Networks and Learning Systems. 30Wu, S., Li, G., Deng, L., Liu, L., Wu, D., Xie, Y., and Shi, L. L1 norm batch normalization for efficient training of deep neural networks. IEEE Transactions on Neural Networks and Learning Systems 30, 7 (2019), 2043-2051.

A survey of image synthesis and editing with generative adversarial networks. X Wu, K Xu, P Hall, Tsinghua Science and Technology. 22Wu, X., Xu, K., and Hall, P. A survey of image synthesis and editing with generative adversarial networks. Tsinghua Science and Technology 22, 6 (2017), 660-674.

Learning to synthesise the ageing brain without longitudinal data. T Xia, A Chartsias, C Wang, S A Tsaftaris, A D N Initiative, Medical Image Analysis. 73102169Xia, T., Chartsias, A., Wang, C., Tsaftaris, S. A., Initiative, A. D. N., et al. Learning to synthesise the ageing brain without longitudinal data. Med- ical Image Analysis 73 (2021), 102169.

Real or not real, that is the question. Y Xiangli, Y Deng, B Dai, C C Loy, Lin , D , arXiv:2002.05512arXiv preprintXiangli, Y., Deng, Y., Dai, B., Loy, C. C., and Lin, D. Real or not real, that is the question. arXiv preprint arXiv:2002.05512 (2020).

Diversity-promoting GAN: A crossentropy based generative adversarial network for diversified text generation. J Xu, X Ren, J Lin, X Sun, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language ProcessingBrussels, BelgiumAssociation for Computational LinguisticsXu, J., Ren, X., Lin, J., and Sun, X. Diversity-promoting GAN: A cross- entropy based generative adversarial network for diversified text generation. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (Brussels, Belgium, Oct.-Nov. 2018), Association for Computational Linguistics, pp. 3940-3949.

Style-consistent image translation: A novel data augmentation paradigm to improve plant disease recognition. M Xu, S Yoon, A Fuentes, J Yang, D S Park, Frontiers in Plant Science. 12Xu, M., Yoon, S., Fuentes, A., Yang, J., and Park, D. S. Style-consistent image translation: A novel data augmentation paradigm to improve plant disease recognition. Frontiers in Plant Science 12 (2021), 773142-773142.

Positional encoding as spatial inductive bias in gans. R Xu, X Wang, K Chen, B Zhou, C C Loy, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionXu, R., Wang, X., Chen, K., Zhou, B., and Loy, C. C. Positional encoding as spatial inductive bias in gans. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2021), pp. 13569-13578.

Proegan-ms: A progressive growing generative adversarial networks for electrocardiogram generation. H Yang, J Liu, L Zhang, Y Li, H Zhang, IEEE Access. 9Yang, H., Liu, J., Zhang, L., Li, Y., and Zhang, H. Proegan-ms: A progres- sive growing generative adversarial networks for electrocardiogram generation. IEEE Access 9 (2021), 52089-52100.

Data-free knowledge amalgamation via group-stack dual-gan. J Ye, Y Ji, X Wang, X Gao, M Song, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionYe, J., Ji, Y., Wang, X., Gao, X., and Song, M. Data-free knowledge amal- gamation via group-stack dual-gan. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2020), pp. 12516-12525.

. F Yger, A Rakotomamonjy, Wavelet kernel learning. Pattern Recognition. 44Yger, F., and Rakotomamonjy, A. Wavelet kernel learning. Pattern Recog- nition 44, 10-11 (2011), 2614-2629.

Unsupervised dual learning for image-to-image translation. Z Yi, H Zhang, P Tan, M Gong, Dualgan, Proceedings of the IEEE international conference on computer vision. the IEEE international conference on computer visionYi, Z., Zhang, H., Tan, P., and Gong, M. Dualgan: Unsupervised dual learning for image-to-image translation. In Proceedings of the IEEE international conference on computer vision (2017), pp. 2849-2857.

Effective and fast deepfake detection method based on haar wavelet transform. M A Younus, T M Hasan, 2020 International Conference on Computer Science and Software Engineering (CSASE) (2020). IEEEYounus, M. A., and Hasan, T. M. Effective and fast deepfake detection method based on haar wavelet transform. In 2020 International Conference on Computer Science and Software Engineering (CSASE) (2020), IEEE, pp. 186- 190.

Sequence generative adversarial nets with policy gradient. L Yu, W Zhang, J Wang, Yu , Y Seqgan, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence31Yu, L., Zhang, W., Wang, J., and Yu, Y. Seqgan: Sequence generative adversarial nets with policy gradient. In Proceedings of the AAAI conference on artificial intelligence (2017), vol. 31.

Self-attention generative adversarial networks. H Zhang, I Goodfellow, D Metaxas, A Odena, PMLRInternational conference on machine learning. Zhang, H., Goodfellow, I., Metaxas, D., and Odena, A. Self-attention generative adversarial networks. In International conference on machine learning (2019), PMLR, pp. 7354-7363.

Mff-gan: An unsupervised generative adversarial network with adaptive and gradient joint constraints for multi-focus image fusion. H Zhang, Z Le, Z Shao, H Xu, J Ma, Information Fusion. 66Zhang, H., Le, Z., Shao, Z., Xu, H., and Ma, J. Mff-gan: An unsupervised generative adversarial network with adaptive and gradient joint constraints for multi-focus image fusion. Information Fusion 66 (2021), 40-53.

Text to photo-realistic image synthesis with stacked generative adversarial networks. H Zhang, T Xu, H Li, S Zhang, X Wang, X Huang, D N Metaxas, Stackgan, Proceedings of the IEEE international conference on computer vision. the IEEE international conference on computer visionZhang, H., Xu, T., Li, H., Zhang, S., Wang, X., Huang, X., and Metaxas, D. N. Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks. In Proceedings of the IEEE international conference on computer vision (2017), pp. 5907-5915.

Realistic image synthesis with stacked generative adversarial networks. H Zhang, T Xu, H Li, S Zhang, X Wang, X Huang, D N Metaxas, Stackgan++, IEEE transactions. 41Zhang, H., Xu, T., Li, H., Zhang, S., Wang, X., Huang, X., and Metaxas, D. N. Stackgan++: Realistic image synthesis with stacked generative adversar- ial networks. IEEE transactions on pattern analysis and machine intelligence 41, 8 (2018), 1947-1962.

Super-resolution generative adversarial network (srgan) enabled on-chip contact microscopy. H Zhang, T Zhu, X Chen, L Zhu, D Jin, P Fei, Journal of Physics D: Applied Physics. 54394005Zhang, H., Zhu, T., Chen, X., Zhu, L., Jin, D., and Fei, P. Super-resolution generative adversarial network (srgan) enabled on-chip contact microscopy. Jour- nal of Physics D: Applied Physics 54, 39 (2021), 394005.

Deblurring by realistic blurring. K Zhang, W Luo, Y Zhong, L Ma, B Stenger, W Liu, Li , H , Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionZhang, K., Luo, W., Zhong, Y., Ma, L., Stenger, B., Liu, W., and Li, H. Deblurring by realistic blurring. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2020), pp. 2737-2746.

The unreasonable effectiveness of deep features as a perceptual metric. R Zhang, P Isola, A A Efros, E Shechtman, Wang , O , Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionZhang, R., Isola, P., Efros, A. A., Shechtman, E., and Wang, O. The unreasonable effectiveness of deep features as a perceptual metric. In Proceed- ings of the IEEE conference on computer vision and pattern recognition (2018), pp. 586-595.

Generating text via adversarial training. Y Zhang, Z Gan, Carin , L , NIPS workshop on Adversarial Training. 21academia. eduZhang, Y., Gan, Z., and Carin, L. Generating text via adversarial training. In NIPS workshop on Adversarial Training (2016), vol. 21, academia. edu, pp. 21- 32.

Towards the gradient vanishing, divergence mismatching and mode collapse of generative adversarial nets. Z Zhang, C Luo, Yu , J , Proceedings of the 28th ACM International Conference on Information and Knowledge Management. the 28th ACM International Conference on Information and Knowledge ManagementNew York, NY, USAAssociation for Computing MachineryCIKM '19Zhang, Z., Luo, C., and Yu, J. Towards the gradient vanishing, divergence mismatching and mode collapse of generative adversarial nets. In Proceedings of the 28th ACM International Conference on Information and Knowledge Man- agement (New York, NY, USA, 2019), CIKM '19, Association for Computing Machinery, p. 2377-2380.

Multiattentional deepfake detection. H Zhao, W Zhou, D Chen, T Wei, W Zhang, Yu , N , Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionZhao, H., Zhou, W., Chen, D., Wei, T., Zhang, W., and Yu, N. Multi- attentional deepfake detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2021), pp. 2185-2194.

Deep learning-based channel estimation with srgan in ofdm systems. S Zhao, Y Fang, L Qiu, 2021 IEEE Wireless Communications and Networking Conference (WCNC) (2021). IEEEZhao, S., Fang, Y., and Qiu, L. Deep learning-based channel estimation with srgan in ofdm systems. In 2021 IEEE Wireless Communications and Networking Conference (WCNC) (2021), IEEE, pp. 1-6.

Learning temporal transformations from time-lapse videos. Y Zhou, T L Berg, European conference on computer vision. SpringerZhou, Y., and Berg, T. L. Learning temporal transformations from time-lapse videos. In European conference on computer vision (2016), Springer, pp. 262- 277.

Unpaired image-toimage translation using cycle-consistent adversarial networks. J.-Y Zhu, T Park, P Isola, A A Efros, 2017 IEEE International Conference on Computer Vision (ICCV. Zhu, J.-Y., Park, T., Isola, P., and Efros, A. A. Unpaired image-to- image translation using cycle-consistent adversarial networks. In 2017 IEEE International Conference on Computer Vision (ICCV) (2017), pp. 2242-2251.

Dm-gan: Dynamic memory generative adversarial networks for text-to-image synthesis. M Zhu, P Pan, W Chen, Yang , Y , Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR. the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPRZhu, M., Pan, P., Chen, W., and Yang, Y. Dm-gan: Dynamic memory generative adversarial networks for text-to-image synthesis. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (June 2019).

Improved training of generative adversarial networks using decision forests. Y Zuo, G Avraham, T Drummond, Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV). the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)Zuo, Y., Avraham, G., and Drummond, T. Improved training of generative adversarial networks using decision forests. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) (January 2021), pp. 3492-3501.