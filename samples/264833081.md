# Emotion Detection for Misinformation: A Review

CorpusID: 264833081
 
tags: #Computer_Science

URL: [https://www.semanticscholar.org/paper/acbb28ffe548d3f87c701c5f9a965bdca474a9a4](https://www.semanticscholar.org/paper/acbb28ffe548d3f87c701c5f9a965bdca474a9a4)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | True |
| By Annotator      | (Not Annotated) |

---

Emotion Detection for Misinformation: A Review
1 Nov 2023

Zhiwei Liu 
Department of Computer Science
National Centre for Text Mining
The University of Manchester
M1 7DNManchesterUK

Tianlin Zhang 
Department of Computer Science
National Centre for Text Mining
The University of Manchester
M1 7DNManchesterUK

Kailai Yang 
Department of Computer Science
National Centre for Text Mining
The University of Manchester
M1 7DNManchesterUK

Paul Thompson 
Department of Computer Science
National Centre for Text Mining
The University of Manchester
M1 7DNManchesterUK

Zeping Yu 
Department of Computer Science
National Centre for Text Mining
The University of Manchester
M1 7DNManchesterUK

Sophia Ananiadou sophia.ananiadou@manchester.ac.uk 
Department of Computer Science
National Centre for Text Mining
The University of Manchester
M1 7DNManchesterUK

Emotion Detection for Misinformation: A Review
1 Nov 20235D6E73AE5D271E9A46FD5B631AA449CAarXiv:2311.00671v1[cs.CL]Sentiment analysis Emotion detection Misinformation Rumor Fake news Stance detection
With the advent of social media, an increasing number of netizens are sharing and reading posts and news online.However, the huge volumes of misinformation (e.g., fake news and rumors) that flood the internet can adversely affect people's lives, and have resulted in the emergence of rumor and fake news detection as a hot research topic.The emotions and sentiments of netizens, as expressed in social media posts and news, constitute important factors that can help to distinguish fake news from genuine news and to understand the spread of rumors.This article comprehensively reviews emotion-based methods for misinformation detection.We begin by explaining the strong links between emotions and misinformation.We subsequently provide a detailed analysis of a range of misinformation detection methods that employ a variety of emotion, sentiment and stance-based features, and describe their strengths and weaknesses.Finally, we discuss a number of ongoing challenges in emotion-based misinformation detection based on large language models and suggest future research directions, including data collection (multi-platform, multilingual), annotation, benchmark, multimodality, and interpretability.

## Introduction

Misinformation is false information that is created specifically to mislead readers [1], including fake news and rumors.Fake news refers to intentionally fabricated information whose publishing or dissemination may mislead readers or result in panic [2].Rumors are defined as unverified or unsupported hearsay or information that become spread among people [3].Rumors and fake news are now ubiquitous.They affect people's daily lives, alter their emotions and lead them to trust incorrect information.Social media platforms, such as Twitter, Facebook, Reddit and Sina Weibo, constitute important means not only for socialising, but also for spreading news and rumors, and generate a huge amount of information every day [4].According to the Datareportal April 2023 global overview 1 , approximately 4.80 billion people (about 60% of the world's population) use social media.Moreover, its use is continuing to grow rapidly, with 150 million new user identities added in the last year, representing an annual growth rate of 3.2%.Now that smartphones are commonplace, users can create, share and browse publicly available content on social media anytime and anywhere, thus increasing the ease and speed at which information can spread.However, due to a lack of effective regulatory measures, the Internet has become flooded with fake news and rumors, which can be challenging to distinguish from genuine facts [5].Such misinformation can manipulate the emotions and intentions of netizens [6], which in turn can impact upon social factors, politics and the economy.For example, during the COVID-19 pandemic, rumors about the virus spread across the Internet, which caused panic and tension among society [7].Furthermore, recent advances in artificial intelligence (AI) and the emergence of large language models (LLMs) such as Instruct-GPT [8], ChatGPT and GPT-4 [9] are making it increasingly straightforward to generate false information that appears highly convincing [10].Accordingly, there is an urgent global-level need for methods that can detect misinformation effectively.

Rumors and fake news trigger specific emotions and sentiments.For example, Zaeem et al. [11] observed a statistically significant relationship between negative sentiment and fake news.These emotions and sentiments can in turn give rise to specific behaviors or actions, such as the motivation to spread rumors [12].Furthermore, readers are more likely to believe news that aligns with their existing beliefs [13].For instance, in politics, conservative supporters are more likely to believe negative news about liberals.Rumor-mongering often takes advantage of these trends by disseminating fake news on social media channels that targets users with particular beliefs, and which triggers strong emotions [6].For example, fake news that attacks politics often intentionally embeds anger [14].The aim of the rumor-mongers is to promote the further spread of the rumor by encouraging user actions such as forwarding, liking, and commenting.Such behaviour is exemplified in Figure 1, which shows two samples of fake news on social media, with associated user comments.It has been found that false rumors tend to generate more reshares, spread over longer time periods, and become more viral when they include words that convey emotions of trust, anticipation or anger [15,16].Additionally, it was found that during the COVID-19 epidemic, there was a correlation between the level of anger felt by the public and the likelihood that rumors would be circulated [17].All of the above observations serve to demonstrate the strong relationships between emotions and misinformation.

Recently, it has been shown that natural language processing (NLP) methods that recognise affective information (e.g., emotions and sentiment [18]) in text can make important contributions towards the automated detection of misinformation and conspiracies [19].Significant advances in many NLP tasks (e.g., classification, summarisation, question answering, and information extraction) have been facilitated by the advent of deep learning (DL) methods, which are able to extract higher-level and more complex feature representations through multiple processing layers, compared to conventional machine learning methods.Various DL approaches that exploit emotion features have been used to approach the problem of misinformation detection, including Convolutional Neural Networks (CNN) [20], Recurrent Neural Networks (RNN) [21] and Graph Convolutional Networks (GCN) [22].Furthermore, pre-trained language models such as BERT [23], RoBERTa [24], and LLMs [25,26,27] have been used as backbone models for detecting misinformation.The various proposed methods have exploited emotion features in diverse ways.For example, Al-Saif et al [28] developed a context-aware approach for rumor detection in Arabic social media that combines emotion features with other types of features (i.e., topics and reactions), while Zhang et al. [29] accounts for the dual emotions expressed in both the fake news post and its followup comments.Emotion detection can also be successfully employed as an auxiliary task within a multi-task framework to improve the accuracy of fake news detection [30].Such examples illustrate the potential for emotion information to be integrated within misinformation detection methods in a broad range of ways to improve performance.

Determining the stance of social media users towards news also plays a crucial role in identifying misinformation [31,32,33].Stance is defined as the expression of an attitude towards a given piece of information [34], which may include supporting, denying, querying, or commenting upon it [35].Users often take a stance towards rumors propagated in online spheres [36].For example, the public has expressed various attitudes towards climate change on social media platforms [37].Moreover, users are more likely to accept and support information that aligns with their viewpoints [38].For instance, individuals with strong opinions about "Americanness" tended to demonstrate support in their tweets relating to former US President Trump's October 2018 post concerning the cancellation of birthright citizenship [39].Emotions and sentiment have an underlying connection with attitudes and are thus advantageous for stance detection [40,41].For example, if a person expresses positive feelings towards a political candidate, then this is likely to indicate that they support or agree with the candidate's policies.The importance of sentiment and emotion has been confirmed by a number of studies that have used them in combination with other features for stance detection in rumors and fake news [42,43,44].Examples include Wang et al. [45], who combined emotion and sentiment with Twitter metadata features, Xuan et al. [46], who integrated emotion with content and user features, and Parimi et al. [47], who made use various features of rumors, including content and emotions.

Several surveys relating to rumor and fake news detection have been published recently.The majority of these reviews a variety of detection techniques [48,49,50,51,52], while [53] focuses specifically on methods that employ GCNs.D'Ulizia et al. [54] provides an overview of available datasets for evaluating fake news detection methods.Alsaif et al. [55] reviews recent approaches that use stance detection as a means to identify rumors, while Hardalov et al. [56] examines the relationship between stance detection and misinformation identification.Shahid et al, [57] conducts a comprehensive survey of state-of-the-art methods for detecting malicious users and bots.Shelke et al. [58] analyzes methods for detecting sources of misinformation in social networks.Among these studies, little attention is paid to the role of emotion in fake news and rumor detection.Although Alonso et al. [19] provide an overview of the application of sentiment analysis in the detection of fake news, it touches only very briefly on approaches that employ fine-grained emotion information, and does not discuss emotion-based stance detection.Furthermore, given the highly active nature of research in this area, there are many recently developed methods that are not included in the above review.To the best of our knowledge, the current article constitutes the first comprehensive survey of methods that use both sentiment and emotion as a means to detect fake news, rumors, and stances.The aim of the survey is to facilitate an enhanced understanding about the latest developments in this area and to act as a driver and a guide for promising future research.

We collected articles from five different literature search platforms, i.e., IEEE Xplore, ACM Digital Library, Web of Science, Scopus, and DBLP.The process for article selection process consisted of three main steps, i.e.: collection, preliminary screening, and manual review.

Collection: Similarly to the search strategy described in [59,60], we conducted an initial keyword search aimed at retrieving articles published between January 2016 and September 2023 that mention both misinformation and affective information.The specific query used was as follows: (emotion OR sentiment OR affective) AND (rumor OR "fake news" OR misinformation OR disinformation).The search resulted in the retrieval of 6,483 articles.

Preliminary screening: After deduplication, we employed RobotAnalyst [61], a tool that prioritizes articles based on relevance feedback and active learning [62,63] in order to minimize the amount of human work required in the screening phase of reviews.Articles were screened based on title and abstract, and were retained only if: (1) They were relevant to rumor/fake news analysis or detection.(2) They involved the use of affective information.The screening process resulted in the identification of 473 articles for further review.


## Manual review:

We conducted a manual full-text examination of the articles resulting from the preliminary screening phase, and retained those that: (1) Focus on methods both for analyzing or detecting misinformation, and detecting emotions and/or sentiment.(2) Apply learning methods to the task of misinformation detection or analysis.

(3) Use affective information as a feature for misinformation detection or analysis.By applying these criteria, 90 articles were retained, and form the basis for the detailed analysis presented in this review.

Figure 2 illustrates the temporal distribution of studies describing emotion-based applications in misinformation that have been published in recent years.Particularly noticeable is the significant surge in the number of articles published over the last two years.This provides evidence of an increasing appreciation of the importance of emotion in detecting rumors and fake news.

In this review, we focus on advanced emotion-based fusion methods for misinformation detection.Our main contributions are as follows:

1. We summarize the findings of articles exploring relationships between emotions and misinformation, in order to motivate emotion-based approaches to misinformation detection.

2. We categorize and summarize available datasets that can support misinformation detection.

3. We categorise and discuss emotion-based methods for misinformation detection based on both conventional machine learning and DL methods, with a focus on advanced emotion-based fusion approaches.We also provide an overview of articles concerning emotion-based stance detection in misinformation.

4. We present and analyze the performance of the advanced methods discussed, and discuss their relative strengths and weaknesses.

5. We outline a number of challenges faced in the development of misinformation detection methods, and suggest promising future research directions, with an emphasis on the increasingly important role of LLMs.

Figure 3 illustrates the structure of the remainder of the article, which may be summarised as follows: Section 2 introduces related work on rumors, fake news detection, and emotion detection.Section 3 presents studies that analyze relationships between emotions and misinformation.Section 4 explores approaches to emotion-based misinformation detection, including a summary of available datasets, a detailed analysis of advanced fusion methods and a summary of emotion-based stance detection in misinformation.Section 5 discusses the strengths and weaknesses of advanced emotion-based misinformation detection methods.Section 6 presents ongoing challenges and future research directions; Finally, Section 7 concludes this paper by summarizing our findings.


## Related work


### Fake News and Rumors Detection

The convenience of accessing social media platforms on various electronic devices means that people can easily post or access large amounts of information on the Internet.This can lead to the rampant spread of misinformation.Certain individuals intentionally spread rumors to gain attention, mislead readers, or make a profit, even though such rumors can pose significant harm to society [64].Therefore, there is an urgent need to detect misinformation in an efficient and effective manner.A large body of research has aimed to respond to this need, which has been summarized in various reviews, which cover both methods for detecting rumors and fake news [48,49,50,51,53] and potential applications of these methods, including source detection [57,58], bot detection [57,65,66] and stance detection [55,56].

Misinformation detection approaches consist of three main components, i.e., the datasets used to support their development, the methods used to perform detection, and the features used within these methods.The majority of the datasets are obtained from social media platforms such as Twitter, Facebook and Sina Weibo, or from fact-checking websites, such as Snopes2 , Factcheck3 , PolitiFact 4 .Detection methods may be divided into those based on conventional machine learning [51] or DL [50,53].Figure 4 presents a range of features that have been employed for misinformation detection.Among these features, contentbased features constitute the most diverse class;  types of features that fall under each of the content-based sub-classes shown in Figure 4. Within the Affective group of features, dual emotion features aim to account for the importance of considering different emotional perspectives when identifying misinformation, i.e., both publisher emotion, which refers to the emotions conveyed in an original post that starts a thread on social media, and social emotion, which refers to the emotions expressed in follow-up posts that respond to and/or comment on the original post.


### Sentiments and Emotions

Sentiments and emotions are important and fundamental aspects of our lives.What we do and say reflects our emotions in some way.Emotion detection (ED) and sentiment analysis (SA) are two types of NLP techniques for analyzing human expressions that can help us to understand people's feelings towards specific topics [67].SA [68] aims to capture the overall emotional tone conveyed by a data source (usually positive, negative, or neutral), along with the strength of this tone [69].ED is the process of classifying data at a finer-grained level, according to the emotions that it conveys.

Compared to sentiment, the term emotion refers to more specific and stronger feelings [70].For example, positive sentiment encompasses a range of different emotions, such as happiness and joy, while negative sentiment includes the emotions of sadness and anger, among others.

A number of theoretical emotion classification models has been proposed, which can be divided into two categories, i.e., categorical and dimensional [71].Categorical models define a single discrete set of emotional states; examples include Shaver [72] (sadness, love, joy, anger, surprise and fear), Ekman [73] (joy, anger, fear, disgust, sadness and surprise), and Plutchik [74] (anticipation, surprise, anger, fear, trust, disgust, joy and sadness).In contrast, dimensional models posit that emotions can be decomposed into a number of distinct dimensions.One of the best-known examples is Plutchick's wheel of emotions [74,75], in which emotions are defined in a two-dimensional space of valence and arousal.The wheel is divided into 24 primary, secondary, and tertiary dyads based on eight basic emotions.Other popular dimensional emotion models include the PAD model [76], which is based on three dimensions, i.e., Pleasure (the pleasantness of the emotion), Arousal (the level of physiological activation or intensity of the emotion), and Domination (the degree of control or dominance experienced in the emotion); and the VAD model [77], in which Arousal and Dominance are supplemented by Valence (the positivity or negativity of the emotion).

A range of automated methods has been developed to detect both sentiment and emotions in text, which may be broadly categorized into dictionary-based, conventional machine learning [78], and DL [79] methods.The dictionarybased approach involves constructing an inventory of words that denote specific sentiments and/or emotions, and matching them against words appearing in the text to be processed to obtain information about the sentiments and emotions conveyed.Meanwhile, methods based on conventional machine learning and DL apply learning algorithms to datasets annotated with sentiment or emotion labels to teach them how to detect the different ways in which these types of emotions may be conveyed in text.Recently, there has also been a growing interest in exploring how LLMs can be exploited to enhance the accuracy of sentiment analysis and emotion detection [80,81,82].


## Relationships between emotions and misinformation

Although emotions are regarded as a dominant driver of human behavior, the exploration of their role in the online diffusion of misinformation has only recently begun.Misinformation can evoke emotional responses in readers, which in turn can lead to specific behaviors, such as belief in the information, resharing or liking it, etc [13].

Table 1 lists a range of recent studies that has investigated the relationships between emotions and misinformation, e.g., how the expression of particular emotions can indicate that a data source is likely to contain misinformation and/or predict the likely response of readers.For each study, we list the dataset used, the ED and relationship analysis methods (RAM) methods employed, and details of the most important relationships identified.The most commonly explored topic is COVID-19, according to the explosion of rumors and fake news generated by the pandemic.To perform ED, the majority of researchers applied dictionary-based methods (Table 7 for details) or traditional machine learning methods, while Wu et al. [83] manually annotated discrete emotions based on the Pleasure-Arousal-Dominance (PAD) emotional state model.In [13,12,84,85,86,87], questionnaires were designed to ask participants to directly report their emotions.Among these approaches, Zhang et al. [12] and Martel et al. [84] use the Positive-Negative Emotional Scale (PANAS) to further quantify the emotional state of participants.The analysis of Li et al. [88] was based on the results obtained from their novel Multi-EmoBERT multilabel emotion recognition tool.Wan et al. [89] used a mixture of existing NLP tools and lexicons for ED, enhanced using rules and automated weighting.They extracted Emotion Triple Elements to study potentially different responses to emotional triggers.For relationship analysis, a range of commonly used statistical analysis methods has been applied, including Logistic Regression (LR) [83,90], Linear Regression [91], and T-Test [92,93].

Various indicators have been used to judge the impact of emotions on the spread of rumors, the degree of outbreak, etc.For example, the questionnaires of [12,85,87] directly asked participants what actions they would take when faced with certain types of news, such as sharing intention or "likes".Other studies used cascade size, cascade lifetime, and structural virality [15,16,94] to analyze the patterns of misinformation spread.Cascade size corresponds to the number of forwardings generated by a cascade; cascade lifetime is the length of time that a rumor cascade remains active, i.e., the time elapsed between the root broadcast and the final forwarding; structural virality [95] provides an aggregated metric combining the depth and breadth of a cascade.In addition, many studies have analyzed relationships by investigating the number of rumors that occur over time, or by comparing the number of rumors that convey different emotions.

The analyses detailed in Table 1 reveal a number of important relationships between emotions and misinformation, which can sometimes depend on the types of topics being discussed.Misinformation is generally associated with a significant level of high-arousal emotions such as anger, sadness, anxiety, surprise, and fear.Rumors conveying anger, sadness, anxiety, and fear are likely to generate a large number of shares, and to be long-lived and viral [15,17,83,90], while emotional appeals (like anger and disgust) can increase users' engagement with fake posts [96].Fake news expresses higher overall emotion, negative sentiment, and lower positive sentiment than genuine news [92,93].In general, it may be concluded that sentiment, emotions, and misinformation are inextricably intertwined, thus confirming that sentiment and emotion both have important parts to play in the automated detection of fake news and rumors.


## Emotion-based misinformation detection

Motivated by the results of analyses such as those outlined in Section 3, many studies have used sentiment and/or emotions as the main features to guide the automated detection of fake information.In this section, we provide a detailed survey of emotion-based methods for misinformation.We firstly introduce the datasets used to support the development of such methods, and subsequently describe a range of detection methods employing a mixture of conventional machine learning, DL methods, and advanced fusion techniques.We additionally provide a summary of the closely related task of emotion-based stance detection in misinformation.Table 3 lists the complete set of emotionbased misinformation detection methods that we have reviewed.Appendices B and C, respectively, list commonly used ED tools and provide an overview of evaluation metrics used in misinformation detection.The ease with which fake news is spread online is positively associated with the strength of anger that it conveys.[100] Anger and disgust increase users' engagement with fake posts.


### Datasets

Table lists a range of publicly available datasets aimed at facilitating the development and/or evaluation of misinformation detection methods.The majority of these datasets consist of data obtained from popular social media platforms and fact-checking websites, such as Twitter, Weibo, Reddit, politifact.com,gossipcop.com,etc.For each dataset, we provide its commonly used name and reference, its source, a description of its size and main characteristics, its level of availability, and notes.The latter is used to indicate datasets that cover languages other than English, those that are multimodal, those specifically concerning COVID-19, and those annotated with stance information.Datasets without notes consist of textual English data that is labeled according to whether or not it represents misinformation.

As may be observed in Table 2, the majority of datasets is publicly available, which is highly advantageous to promote research in the field of misinformation.Due to the prevalence of rumors relating to the COVID-19 pandemic on social media, there has been a trend towards collecting misinformation datasets relating to this topic, as a means to explore rumor detection in the field of health disease transmission [102,103,104,105].Another important feature of several of the datasets listed (including PHEME [106], the Twitter series [107], and the Weibo series [29,108,109]) is that they include comments/replies relating to original news stories or tweets.Such datasets allow the exploration of methods that take into account the dual publisher and social emotions, and the possible interactions between them, to improve the accuracy of misinformation detection.We can furthermore observe that several datasets are multimodal, i.e., they consist of both text and images.These include FakeNewsNet [110], Fakeddit [111] and MediaEval2016 [112].The inclusion of images in these datasets provides scope to explore methods that take advantage of visual clues to complement textbased information in identifying misinformation.Although the majority of datasets only contain English text, there is a growing number of corpora that cover other single and sometimes multiple languages, including Chinese, Portuguese, Spanish and Danish, thus providing opportunities to develop methods that are multilingual and/or which target lesser resourced languages.While most datasets are annotated according to whether or not their constituent text constitutes fake news or rumor, there is also a number of corpora annotated with stance-related labels, which can facilitate investigations into how stance information can contribute towards the detection of misinformation.


### Conventional Machine Learning Methods

Machine learning is a branch of AI that uses algorithms and statistical models to teach computers how to make predictions and decisions automatically.As shown in Table 3, a variety of machine learning algorithms has been used to develop misinformation classifiers.These include both supervised methods, such as passive-aggressive [171], Naive Bayes (NB) [151], k-Nearest Neighbour (KNN) [135,161], Support Vector Machine (SVM) [159], Random Forests (RF) [24], Decision Tree (DT) [157], AdaBoost (AB) [127], LOGIT, Grad Boosting, XG-Boost, Gradient Boost (GB) [152], and unsupervised methods like K-Means and DB-SCAN [128].


### Deep Learning Methods

DL is a sub-field of machine learning that has made breakthrough progress in many fields, especially in computer vision, NLP, speech recognition, and other AI fields [183].Compared to conventional machine learning methods, DL techniques can handle larger and more complex datasets and can result in improved performance on certain tasks [184].DL algorithms build complex models by stacking multiple neural network layers, which are called deep neural networks.Pre-training is a DL model training strategy, in which models are initially trained on a large-scale data set to learn a common feature representation that is suitable for application in a range of different scenarios.Pre-trained models are subsequently fine-tuned to achieve optimal results when applied to specific tasks.As shown in Table 3, DL approaches have been widely used in both sentiment/emotion analysis and misinformation detection.For example, Iwendi et al. [21] explored the use of RNN, GRU, and LSTM as classifiers to detect fake news relating to COVID-19 based on 39 features (including sentiment, linguistic, and named entities) extracted from news articles and social media posts.Ajao et al. [152] employed various machine learning methods and an LSTM with hierarchical attention networks (HAN) [185] for rumor detection.A Bi-LSTM was used by Hamed et al. [172] to detect misinformation using dual emotions and content features.In [20], the authors adopted CNN and Bi-GRU to extract dual emotion features.To evaluate the effectiveness of their proposed multi-tasking framework for rumor detection, Choudhry et al. [30] employed various DL methods, including LSTM, BERT, CNN, RoBERTa, CapsuleNet [186] and HAN.Various studies have applied GCN and GNN to model the graph-like structure of social media posts [162,178].

Pre-trained models, including BERT, DistilBERT, and RoBERTa, have frequently been used used as the basis for extracting sentiment and emotion features in the context of misinformation detection [22,24,160,162,168,175,177,179].A popular technique has been to use transfer learning to fine-tune these pre-trained models on large emotion detection datasets (e.g., GoEmotions [187] and DailyDialogue [188]) prior to labeling misinformation datasets.Moreover, there exists a small number of pre-trained models for languages other than English, such as AraBERT-Twitter and MARBERT, which were used for rumor detection in Arabic social media [28].

For multimodal data, Resnet18, VGG16 and Xception have been used to extract image features [131,132,166,167].Similarly to text-only datasets, these studies use transfer learning to fine-tune pre-trained image models on visual sentiment datasets, then extract image features from the misinformation dataset, and finally merge them with text features for misinformation detection.


### Advanced Fusion Methods

A wide variety of methodologies for emotion-based misinformation has been developed (See Table 3 for a complete list).In the majority of cases, information about emotions and/or sentiment is fused with other types of features, aiming to take full advantage of the specific characteristics of the dataset used to maximize detection performance.Additional features may be based, for example, on various aspects of textual content; information regarding the structure or temporality of collections of social media posts; and/or images associated with textual data.Moreover, approaches vary in terms of whether they carry out learning within the context of single or multi-task framework.In this section, we introduce a selection of these advanced fusion methods,

A Twiter_harvard [122] Twitter 111 events with tweet ids and user information (60 rumors and 51 non-rumors) A health-related news [123] Twitter 709 posts (54% rumour, 30% non-rumour and 16% unknown), collected using the keywords #zikavirus and zika microcephaly R MultiSourceFake [124] which are categorized according to the types of additional features and/or the learning strategy that they employ.


#### Methods Combining Emotion with Other Text-Based Features

Various methods have attempted to exploit the wealth of valuable information conveyed in text by combining emotion/sentiment features with other features derived from the textual content of news articles or social media posts.

Ghanem et al. [124] proposed the FakeFlow model (Figure 5 (a)), which aims to model the flow of affective information in fake news articles, based on the hypothesis that the pattern of affective information in fake news differs from that found in genuine news, e.g., emotions of fear are often evoked towards the start of fake new articles.The model consists of two modules, the first encoding topic information, extracted using a CNN, and the second capturing 23 affective features relating to emotion, sentiment, morality, imageability and hyperbola.In the first module, potential relationships between topics and affective information are captured by concatenating their respective vectors (e.g., emotions in a fake article about Islam are likely to vary from those in an article in favor of a politician).A contextaware self-attention mechanism is subsequently applied to weight segments according to their similarity to neighboring segments.In the second module, the flow of the affective information within the articles is modeled by feeding the affective vectors to Bi-GRUs.Finally, a dot product and  Mixture-of-Experts [177], (c) EmoAttentionBERT [163] (d) LSTM (with Fuzzy Sentiment) [164] average operation are applied to distill the output of the two modules into a compact representation, which is fed into a fully connected layer and a softmax layer to determine the factuality of the article.

The multi-domain fake-news detection system described in [177] (Figure 5 (b)) is based on mixture-of-experts model, which involves training multiple neural networks based on TextCNNs (experts), each targeted at a different part (domain) of a dataset.Pre-trained BERT and CLIP [189] text encoders are applied to obtain two different embeddings of news content, which are combined as a fusion embedding.The use of the CLIP text encoder, which is pre-trained on image-text paired datasets, aims to take advantage of the rich semantic representations obtained through state-of-theart multimodal learning.A Collaboration module adaptively determines the weights of each expert model, to enhance or suppress their contribution in the final mixture-of-experts model.The module consists of a fusion vector C  , which combines sentence-level embeddings e  from attention, sentiment embeddings e  obtained by fine-tuning BERT using the Weibo_senti_100k dataset, and domain embeddings e  .The expert networks are accumulated and multiplied via the collaborative influence function C  , which is determined by the Collaboration module, and then used for classification.

The EmoAttention BERT model architecture [163] (Figure 5 (c)) uses both emotion and snippet attention to verify the truth of political claims, supported by evidence from Google news snippets.The content of snippets is encoded using word embeddings, while the NRC Intensity Emotion Lexicon [190] is used to calculate word-level intensities for eight basic emotions.An emotional attention layer assigns a weight to each emotion vector to identify the most relevant emotional signals in a given evidence snippet, while a snippet attention layer weights each evidence snippet with respect to the associated claim.Finally, the vectors from both layers are distilled and fed into a softmax layer to predict the truth of the claim.

Mohamed et al. [164] detects fake news using an LSTM that combines textual embeddings from Word2Vec with fuzzy sentiment features (Figure 5 (d)).Sentiment features are extracted by firstly identifying opinion-denoting words and associated polarity information using the SentiWordNet [191] and WordNet5 , resulting in an initial score.These values are subsequently modified using fuzzy logic functions, according to the presence of different types of linguistic hedges (i.e., words that modify the intensity and meaning of an expressed opinion, such as not, very, and quite), using fuzzy logic functions to obtain the final sentiment score.


#### Mining of Dual Emotions

A number of studies has investigated how misinformation detection in social media can be improved by taking into account information about the different emotions expressed   [29], (c) EFN [134] in posts that announce news (i.e., publisher posts) and posts that comment on or react to these source posts (i.e., social posts) Luvembe et al. [20] developed a deep normalized attentionbased mechanism for enriched extraction of dual emotion features (Figure 6 (a)), which combines CNN and Bi-GRU.The CNN layer is used to obtain embeddings for both publisher and social posts, after which a stacked Bi-GRU with attention is utilized to extract and concatenate emotion features from each type of post.Classification of publisher tweets according to whether or not they report misinformation is performed using a random forest model, whose features are guided by a genetic algorithm, which determines the subset of features that can achieve optimal classification performance.

The MDE model [29] (Figure 6 (b)) detects misinformation in social media posts by integrating features from existing Bi-GRU fake news detectors with publisher and social emotion features and the relationship between them.A vector representing emotions in the publisher post emo  , is obtained by concatenating the emotion category, lexiconbased emotion score, emotional intensity, sentiment score, and other auxiliary features (e.g., emoticons and punctuation).A vector is created for each social post, by applying the same method used to obtain the publisher emotion vector.The individual social emotion vectors are subsequently combined, after which they are aggregated in two ways, i.e. using mean pooling emo   (to represent average emotion signals) and max pooling emo   (to capture extreme emotional signals).These two types of aggregation are then concatenated to obtain the overall Social Emotion emo  .The Emotion Gap emo  represents the difference between the publisher and social emotions, and is obtained by concatenating (emo  -emo   ) and (emo  -emo   ).Finally, dual emotion features are obtained by concatenating the publisher emotion (emo  ), the social emotion (emo  ) and the Emotion Gap (emo  ).These features are combined with those from the existing Bi-GRU fake news detector, and fed into a multi-layer perceptron (MLP) layer and a softmax layer to determine whether or not the publisher post represents fake news.

The end-to-end emotion-based fake news detection framework for social media (EFN) proposed by Guo et al. [134] (Figure 6 (c)) consists of a content module, comment module and fake news detection module.The content module (left of the figure) is used to encode publisher posts using Bi-GRUs for word embeddings and emotion embeddings, the latter of which is trained using large-scale Weibo datasets, with emoticons as the emotion labels.A gate recurrent unit (Gate_N) is then applied to combine word embeddings, emotion embeddings, and 19 sentence-based emotion features.Subsequently, all vectors are fed into another Bi-GRU, whose final hidden state is used as the representation of the publisher post.The comment module (right of the figure) represents information about follow-up social posts.The comment module architecture is similar to the content module, except that all comments are concatenated before being fed into the Bi-GRU, and sentence-based emotion features are not used.A different Gate (Gate_C) is used to fuse features.Finally, the output of the third Gate (Gate_M), which combines the content and comment representations, is fed to a fully connected layer with softmax activation to determine whether or not the publisher post constitutes fake news.


#### Methods Based on Tree or Graph Structures

Due to the inherent relationships among posts relating to fake news, such as retweets or likes of source posts from followers on Twitter, social media data may be viewed as tree structures and graph structures through which information propagates.Accordingly, several methods employ tree or graph structures to model the spread of information and capture the relationship between nodes of the tree.The words  and phrases that make up sentences can also be arranged into hierarchical tree-like structures, according to the grammatical and semantic relationships that hold between them.Several misinformation detection methods make use of features based on these relationships, including dependency tree and sentiment tree information.

In [23], an earliest rumor detection approach for social media is described (Figure 7 (a)).It considers only publisher posts without their follow-up social comments, with the aim of catching potentially harmful rumors before they become widespread.The use of a syntax and sentiment enhanced version BERT (SSE-BERT) is inspired by the observations that both the sentiment and syntactic features of rumors are often distinct from non-rumors.Syntactic dependency trees firstly are obtained for each source post using DDParser [192], and are encoded into a dependency sequence by preorder traversal.Sentiment-denoting words in seven different categories are then recognised using an external sentiment lexicon (i.e., ALO [193]).Specific embeddings are then assigned to each token according to the sentiment lexicon.All features are learned by BERT and distilled using elementwise addition.Finally, the vector of [CLS] in BERT is fed into a fully connected network with softmax to detect rumorous publisher posts.

Driven by the scarcity of high-quality annotated training data, [174] developed an unsupervised approach, ptVAE (Figure 7 (b)).Based on the observations that rumorous tweets exhibit different sentiment patterns compared to rumorous tweets, and that they diffuse more rapidly, deeply and broadly, the method aims to detect rumors by identifying collections of tweets whose propagation patterns and sentiment characteristics differ from those of normal (i.e, non-rumorous) collections.The proposed model consists of a Sentiment Pattern Module (SPM), Propagation Feature Module (PFM), and Cross-alignment module.In the SPM (left of Figure 7 (b)), a tree encoder infers the pattern of sentiment labels along the input propagation tree and uses a GRU to encode this pattern into a latent vector z 1 .The original sentiment labels for each node are then reconstructed by decoding z 1 using a node label decoder and a child label distribution decoder which, respectively, predict the label of each node and the label distribution of the node's children.The PFM (right of Figure 7 (b)) creates vectors capturing the speed, and depth & breadth of propagation, and combines them as the input to a VAE, whose encoder and decoder are based on a multilayer perception.The Cross-alignment module then jointly learns the propagation tree of the SPM and the propagation characteristics of the PFM.

Li et al. [88] propose the Multi-EmoBERT model (Figure 7 (c)) to detect multiple co-existing emotions in fake news content on social media platforms.The first part consists of a Word Encoder to obtain representations of words, and a Hashtag Encoder to obtain representations of emotionword hashtags and emojis, which are common features of social media text.The second part is the Sentiment Semantic Composition Encoder, which uses the Stanford CoreNLP toolkit to construct sentiment trees, and employs a selfattention mechanism and phrase node selection to obtain phrase level vectors.The final part is a label correlation layer that uses a parameter to capture correlations between co-existing emotions.A subsequent analysis, revealing that multiple emotions are often conveyed within a single fake news posting, demonstrates the potential value of Multi-EmoBERT in detecting fake news posts.

The method described in [178] combines the use of semantic and sentiment information, along with the structure of information propagation in social network posts to obtain enriched features for rumor detection.BERT is used to separately capture information about publisher tweets and follow-up social comments, while Bi-GRU with Attention is used to encode sentiment information conveyed in followup tweets.Propagation features of tweets are obtained with the aid of a Bi-GCN network.The various features are then spliced and fused to detect rumors.

Figure 8 (a) illustrates the graph attention network-based model (MHN) developed by Zhang et al. [175], aimed at detecting longer news articles that contain misinformation.The approach is based on the finding that patterns of sentiments expressed across sentences in fake news articles are usually very different from patterns in real news articles.The model employs two types of graph structures.Firstly, a sentiment interaction network encodes sentence-level sentiment features using a pre-trained RoBERTa model, and captures changes in sentiment in that occur in the context of the surrounding sentences.A sentiment comparison model calculates comparison vectors between each contextual sentiment representation obtained from the input news document and its corresponding original sentiment embedding; discrepancies between these embeddings could be indicative of fake news.Secondly, a heterogeneous document graph encodes the semantic content of the article, by capturing interactions between sentences, topics, and entities.A comparison between the contextual entity vectors and those obtained from a knowledge graph is aimed at detecting potential information inconsistencies that could denote fake news.The sentiment comparison vector, entity comparison vector and article representations are combined and passed through a Softmax layer to make predictions.Dong et al. [162] designed a Sentiment-Aware Hypergraph Attention Network (SA-HyperGAT) for fake news detection in social media (Figure 8 (b)).The use of hypergraphs is intended to capture higher-order dependency information between words and sentences, compared to general graphs.Separate hypergraphs are constructed for publisher posts and follow-up social comments.In the former hypergraph, each node corresponds to a word in the news text, while in the latter, nodes correspond to user comments.Sentiment labels for each comment, obtained using a fine-tuned RoBERTa model, are used as hyperedges in the graph.Representations of comments are learnt using an LSTM, after which nodeto-edge attention and edge-to-node attention are applied to learn the representation of the hypergraphs.Final feature vectors are obtained by applying mean pooling to both hypergraphs; these vectors are combined and then fed into a softmax classifier to obtain the final prediction.

The graph-based contextual and semantic learning (GCS) method for detecting rumors in tweets [165] (Figure 8 (c)) is based on a novel approach to graph-based representation learning, and the identification of two prevalent categories of words that constitute the building blocks for constructing contextual patterns for rumor detection, i.e., substantial words, which are used to express emotions, sentiments, or suspicions about the event, and bridge words, which connect substantial words.After data pre-processing, publisher and social tweets are combined to allow important relationships to be identified, e.g., social tweets may convey skepticism, correction, verification, etc, towards the publisher tweet.The combined tweets are represented as word co-occurrence graphs, to which clustering coefficient and eigenvector centrality are applied to identify substantial and topical words and bridge words, respectively.These are further enriched with negative emotional patterns and skeptical patterns.Next, a modified TF-IDF formula is used to rank and select the top-k patterns most likely to be indicative of rumor.Semantic vectors are then generated for both tweets and patterns using word embeddings, which are combined and then converted into features using cosine similarity for subsequent use by different conventional machine classification algorithms (i.e., support vector machine, gradient boosting, conditional random field, and logistic regression).


#### Methods Based on Temporal Information

Various temporal features have been explored to enhance the performance of misinformation detection, based on the time-sensitive patterns that are frequently observed in social media, e.g., rumors initially spread quickly but gradually disappear, while reader emotions tend to change over time.The TDEI model [22] (Figure 9 (a)) integrates emotion features with information concerning time-sensitive dynamic changes in the topological propagation structure of tweets, which is considered to be a better predictor of rumors than the final, static propagation structure.The graph representing the propagation structure of a publisher post and its associated social comments is firstly divided into a sequence of temporal snapshot graphs.Stacked GCNs and a readout function are used to learn structural features of the snapshots.A GRU with self-attention is then applied to learn the diffusion process of structures.Meanwhile, emotion vectors are extracted from each post using a pre-trained, finetuned BERT model.A self-attention mechanism is then used to merge the emotion vectors for each post corresponding to a rumor event into a single vector, whose dimensionality is adjusted using a fully connected layer.The temporal dynamic structure and emotion vector are then concatenated and fed into multi-layer perception with softmax function to make predictions.

The SD-TsDTS-CGRU fusion rumor detection method [153,154] (Figure 9 (b)) focuses on detecting rumors at the event level, i.e., by considering all information expressed in the complete set of sequential posts related to the same topic or event.Posts are firstly automatically partitioned into sets covering distinct events by dividing them into intervals using a two-step dynamic time series division algorithm, based on fuzzy clustering and information granules [194].The latter step helps to ensure that each batch of posts covers information at an appropriate level of granularity and has a consistent semantic interpretation.The calculation of information granularity takes into account the number of sentiment words belonging to each fine-grained sentiment category in each interval, obtained using a novel sentiment dictionary containing sentiment words and emoticons.Following the division, word embeddings and sentiment information extracted from the posts in each event-specific set are fed to two different GRUs, whose outputs are combined and fed into a dense layer with Softmax function to predict whether or not each set of event-related posts constitutes a rumor.

Temporal sentiment features of rumors are employed in [169] (Figure 9 (c)) to account for changes in sentiment over the lifetime of an original publisher post and its associated social posts in both Chinese and English social media datasets.The Baidu sentiment API 6 and NLTK sentiment module 7 are used to obtain sentiment scores for Chinese and English posts, respectively.Temporal features are characterized using a one-hot vector, whose length is modified by normalizing the number of posts in the reply series.Temporal sentiment features are obtained by multiplying the modified one-hot vector with the sentiment score.Textual features of posts are obtained using pre-trained word embeddings and a mean pooling layer, which are combined with the sentiment vector to derive a microblog representation.An RvNN and max pooling layer are then used to obtain a comprehensive representation of an event as it propagates through the path of social replies, which is passed to a MLP with ReLU to determine whether or not the publisher post is a rumor.


#### Multitask Learning

Multi-task learning optimizes several learning tasks simultaneously, exploiting shared information to improve the prediction performance of the model for each task.Auxiliary tasks can be added to the main task to boost the performance.Several studies have explored how emotion and sentiment detection can act as auxiliary tasks in a multi-task learning framework to enhance misinformation detection accuracy.

The method developed by Choudhry et al. [30,181,182] (Figure 10 (a)) aims to address the issue of cross-domain robustness in determining the veracity of news articles.Generalizability of the method across different domains is achieved using a domain-adaptive framework, whose aim is to facilitate the extraction of domain-invariant features by aligning the source and target domains in the feature space.The multi-task learning setup trains an emotion classifier as an auxiliary task in parallel to a fake news detector, to try to improve the alignment between the source and target domains, while adversarial training helps to make the model robust to outliers.The emotion classifier assigns emotion labels according to Ekman's or Plutchik's emotions, with the aid of the Unison model [195].An LSTM is used as the feature extractor, which is trained using the accumulated loss from the fake news classifier, emotion classifier and a domain classifier, the latter of which acts as a discriminator in learning domain-invariant features.

Based on the relatedness between the tasks of detecting fake news, novelty, emotion, and sentiment, Kumari et al. [160] (Figure 10 (b)) developed a multi-task learning framework in which the latter three of these are treated as auxiliary tasks.Using premise-hypothesis pairs as input, the model detects whether or not the hypothesis is fake with respect to the premise.Pre-trained and/or fine-tuned models are firstly used to determine whether the hypothesis is novel with respect to the premise, and whether or not the hypothesis and premise differ in terms of binary emotion values (i,e., sadness/joy/trust vs. anger/fear/disgust/surprise) and sentiment (positive or negative).Different Bi-LSTMs that use pretrained GloVe and BERT-based embeddings are employed to obtain two different input textual representations, which are concatenated and used as the input to the three auxiliary tasks and the main task of fake news detection.


#### Multimodal Methods

On platforms like Twitter or Weibo, people often attach images to their textual posts to better express their opinions or emotions.Several studies have thus attempted to exploit information from these images to improve the detection of rumors, mainly based on two different frameworks, both of which involve combining features from text and images, but which differ in terms of whether emotion features are extracted from text (Figure 11 (a)) [150,173] or images (Figure 11 (b)) [131,132,167].The Title-Text Similarity and Emotion-Aware Fake News Detection method [173] applies BERT with a fully connected layer and ResNet-50 to obtain textual and visual features, respectively.The publisher emotion extractor from [29] (described above in Section 4.4.2) is used to obtain a range of emotion-based feature values from textual news content.The scaled dot-product attention mechanism is also used to capture the similarity between the title and textual features, based on the observation that authors of fake news may attempt to catch the reader's attention by using titles that are not relevant to the news content.All features are subsequently combined and fed into a FC layer with softmax to make predictions.

The SAME multi-modal embedding model [150] incorporates user sentiment for fake news detection.Firstly, VGGNet and CNN are used to represent images, while text is represented using Glove and MLP, and profiles (i.e., source, publisher and keywords) are represented using one-hot encoding.An adversarial learning mechanism is then applied to find semantic correlations between different modalities.A novel hybrid similarity loss method based on Graph Affinity Metric and Local Similarity Metric is used to incorporate the user's sentiments (i.e., positive, negative or neutral), which are obtained using VADER.Finally, a fully connected layer with softmax is applied as a classifier.

The multimodal framework in [131,132] makes use of text and images from source-target pairs, in which the target corresponds to information from fake news datasets, while the source corresponds to background information associated with a target data item, extracted from credible websites.BERT and ResNET18 [196] are firstly used to encode the text and images of source-target pairs, respectively.The textual and visual features are concatenated to obtain multimodal feature representations.These are encoded using VisualBERT [197], which is designed to capture the rich semantics found in images and their associated text.A novelty detection module then uses these multimodal representations to determine the credibility of the new news (target) with respect to prior verified news (source), using supervised contrastive learning (SCL) such that target representations attract source representations that provide support, and repel them otherwise.The second module pretrains a neural network to predict image emotion labels using two classes, i.e. joy/love/sadness vs. fear/surprise/anger.All features are then fused and passed to MLP with softmax to make predictions.

Uppada et al. [167] developed a framework for fake news detection that combines visual and textual features.The architecture, which consists of two fine-tuned Xception models, makes use of the Error Level Analysis (ELA) technique to help to identify digitally altered images.One fine-tuned Xception model is trained on an ELA image dataset to detect editing traces in digital images, while the other is trained on a visual sentiment analysis dataset to determine whether images convey positive or negative sentiments.BERT is applied to learn contextual knowledge from image captions.The output of the three branches is combined and passed to the fake image classifier.


### Emotion-based stance detection in misinformation

In addition to emotions and sentiment, the stance of readers is also an important factor in affecting rumor diffusion.If somebody supports a piece of fake news, he/she is more likely to reshare it.Emotions can impact upon a person's thinking, judgment, and decision-making, which in turn can influence their stance toward a particular topic.This section introduces methods that use emotion as a feature for stance detection in misinformation.

Most work in this area has been driven by shared tasks, in which a number of teams compete with each other to produce the best results for a given task and dataset.Examples of relevant tasks include SemEval-2017-Task8 [35], SemEval-2019-Task7 [35], and the FNC dataset [142,143].Lillie et al. [139] constructed a Danish stance-annotated dataset (DAST), consisting of Reddit posts.A number of other publicly available stance-annotated datasets has also been used in various studies [47,149,207].Further details about these datasets are provided in Table 2. Most stance detection methods detect emotion features using simple dictionaries or tools, and use conventional machine learning approaches, based on sentiment features and a variety of other features.Further details are provided in Table 4.


## Discussion

The analysis in Section 4 revealed the wide range of designs of advanced fusion methods for emotion-based misinformation detection.In this section, we conduct a comparative analysis to identify the most effective strategies.Table 5 provides performance statistics in terms of F1score for a range of the advanced methods discussed in Section 4, along with those of the baseline methods used for comparison.Where possible, we also provide the results of ablation experiments, i.e., where sentiment/emotion features are excluded to assess their impact on overall performance.As part of our analysis, we compare the performance of different methods that have been evaluated using the same dataset.Although we suggest possible reasons for different performance levels, it is important to note that performance may influenced by numerous factors, including differences in data processing methods, selection of base models, and the predictive behavior of the sentiment model, etc.

Feature Fusion: Textual data contains an abundance of information, which has been encoded using a wide variety of features in different misinformation detection methods, as illustrated in Figure 4.In Table 3, we list the specific features that have been combined with emotion and/or sentiment information in different studies.While a comparison of the performance of complete models with those of ablation experiments in Table 5 confirms the importance of sentiment and emotion features in misinformation detection, high levels of performance can only be achieved by combining multiple features.For example, it is shown in [124] that the proposed combination of topic and affective features outperforms the use of either topic or affective features in isolation.Furthermore, [131,132] show that extracting features from the images that accompany posts on social media platforms can provide additional clues about the emotional states and behaviors of individuals and thus help to boost the results of misinformation detection.

Model Fusion: Different models and learning techniques have their own advantages and disadvantages, and optimal misinformation detection performance methods can generally only be achieved by combining a number of different techniques.For example, pre-trained models like GloVe and BERT are effective in encoding textual content with word embeddings, while RoBERTa can be successfully employed for sentiment and emotion detection [213].Meanwhile, methods like CNN, LSTM, or GRU may be usefully adopted for feature extraction.Encoding information about the graph structure inherent in many datasets requires different approaches.For instance, dependency and sentiment trees may be used to represent grammatical or semantic aspects of sentence structure, while GCN and hypergraphs can encode the tree-like structure of social media data.To capture temporal features of rumor propagation, different studies have utilized RNN, LSTM and GRU models, which excel in handling time series data.The application of fusion or ensemble techniques can fully leverage the relative strengths of these different types of methods and models, as may be confirmed by comparing the results of the advanced methods with baseline methods in Table 5.

Comparison between different fusion methods: Although the experimental results for EmoAttention BERT [163] highlight the importance of emotionally charged style, and in particular emotional intensity, as a predictive feature of fake news, Table 5 illustrates that the performance of this method is low.A probable reason is that their method is evaluated on a complex dataset that includes multiple domains and labels, but their fairly simple framework fails to account for potential differences in the characteristics S Topic-based Bi-LSTM [208] Fuzzy Logic Semantic, User-based features of data across different domains.A possible solution is to adopt a multi-task architecture, similar to [30,181,182], in which a domain classifier is incorporated as a discriminator to ensure that the model performs well across multiple domains through reinforcement learning.Similarly, The challenging characteristics of the RumourEval-2019 dataset (i.e., low inter-annotator agreement and sparse data [141,214]) resulted in relatively low performance from RvNN with Temporal [169] (0.53 F1) and MDE [29] (0.35 F1) methods, even though they achieved much higher results on other datasets.In comparison, AGWu-RF [20] attained vastly superior results on RumourEval-2019 (0.95 F1).In common with MDE, AGWu-RF uses dual emotion features.However, its combination of these features with a random forest with genetically adapted weights appears to make it robust in handling this problematic dataset.Furthermore, AGWu-RF is demonstrated to be sufficiently generalizable for successful application to social media datasets with varying characteristics, e.g., it outperforms both [30] and [165] on the PHEME dataset.It is also notable that while AGWu-RF uses only textual information, it achieves better results than [167] on the multimodal Fakeddit dataset, even though the latter method uses both text and image features.Source tweets in Twitter15 and Twitter16 are annotated with four class labels, i.e., non-rumor (NR), false rumor (FR), true rumor (TR), and unverified rumor (UR).While these datasets are used to evaluate both the ptVAE [174] and SA-HyperGAT [162] methods, the evaluation of ptVAE uses only two classes, i.e., true (non-rumors and true rumors) and false (false rumors).Nevertheless, ptVAE exhibits lower performance than SA-HyperGAT on these datasets, and is also inferior to several other methods that have been evaluated on the Weibo16 dataset.This could be due to the less rigorous data processing methods used in ptVAE, but it is more likely that their proposed VAE architecture for sentiment analysis is not as effective as other methods, such as the fine-tuned RoBERTa model used in SA-HyperGAT [162].Table 5 shows that many methods use Weibo16 for evaluation.The performance comparison provides strong evidence that combining sentiment/emotion features with those accounting for the propagational and/or temporal features is highly important.Specifically, [178], TDEI [22] and SD-TsDTS-CGRU [153,154] and RvNN with Temporal [169] all achieve high levels of performance on Weibo16 (0.94 F1 or higher).The impressive F1 of 0.95 achieved by SSE-BERT [23] on the same dataset, by combining sentiment and dependency tree information from source posts indicates the potential value of considering syntactic information.While MDE [29] and ptVAE [174] perform the worst, with scores below 0.9.Additionally, both FakeFlow [124] and MHN [175] were evaluated on the LUN dataset, and analyze changes in affective information across the different parts of articles.However, the superior performance of FakeFlow suggests that accounting for affective interactions with different topics represents a more successful approach.The analysis above underlines the complexities of developing effective misinformation detection models.High levels of performance can only be achieved through leveraging multiple relevant features, which include thematic, temporal, propagation structure, dual emotion and/or image information, in addition to sentiment and emotion.Furthermore, the specific methods chosen to learn or represent these features can also impact upon performance, and it is usually necessary to combine a range of learning methods to achieve optimal results.Moreover, to achieve cross-domain robustness, the employment of multi-task learning frameworks incorporating reinforcement learning can be advantageous.


## Challenges and future research directions

While this article has reviewed a large and diverse body of research relating to emotion-based misinformation detection, there still remains a variety of unsolved challenges in this field.In this section, we outline the most important of these challenges, and discuss potential future directions of research.


### Dataset Collection (Multi-platform, Multilingual)

There are many popular social media platforms such as Twitter, Facebook, Reddit and Sina Weibo, among others, which constitute major means of spreading misinformation.While the language used on each platform is diverse, and the data formats are varied, making the processing of such data cumbersome.Given that the dissemination of fake news is a global problem, it is important to develop approaches that are more universally applicable than most currently available methods.However, achieving this goal is hindered by the limitations of the majority of currently publicly available datasets, which are usually collected from a single platform (as shown in Table 2) and which predominantly concern textual data in a single language (typically English or Chinese).Only by developing larger and more diverse datasets will it be possible to develop more general models that are urgently needed.These should cover multiple data formats obtained from different platforms and covering multiple languages.


### Annotation (Emotion)

The development of emotion-based misinformation detection methods with optimal performance requires that supporting misinformation datasets are annotated with reliable emotion and/or sentiment labels, since inaccurate labels are likely to impact negatively on the overall performance of the methods.While this is most often carried out using dictionary lookup, some studies have employed transfer learning methods, by applying models trained on other sentiment analysis or emotion-labeled datasets to automatically annotate the emotions expressed in misinformation datasets.Examples include [30,181,182], which use a previously developed Unison model, and [162], which utilizes a finetuned RoBERTa model.However, the emotion labels obtained in these ways are not sufficiently accurate.Compared to time-consuming manual annotation, a more promising approach is to use LLMs to annotate emotion and/or sentiment [80,81,82], given their advanced capabilities and transferability.Both [81] and [82] have demonstrated that LLMs can compete with or exceed the state-of-the-art (SOTA) in recognising emotions in dialogue.In particular [81] showed that the LLaMA-7B [215] model can achieve performance levels close to those of SOTA supervised methods, but using only half as much training data for fine-tuning.Zhang et al. [80] developed an instruction-tuned LLM for financial sentiment analysis which, augmented with additional context from external sources, is able to outperform LLM baselines such as ChatGPT and LLaMA by margins of between 15% and 48%.The above studies all highlight the tremendous potential of LLMs in the field of sentiment analysis.


### Multimodality

Although rumors and fake news were traditionally spread through face-to-face communication, the emergence of social media resulted in their primary means of dissemination switching to text.However, continual advances in technology have led to an increasing shift towards multimodality.For example, people now frequently augment textual post content with images or videos, while on platforms like YouTube or TikTok, videos are the predominant means of sharing information.Accordingly, it is becoming increasingly important to explore methods that can address the challenges of multimodality [216], and that are able to adapt to the ever-changing characteristics of social media communication.While we have reviewed a number of approaches that combine text and image-based information, recent advanced multi-modal models that integrate language and visual understanding provide considerable scope for further research in this area.For example, GPT-4 has a certain level of visual understanding capability, although its implementation details have not been publicly disclosed.Inspired by the success of LLMs, some studies have started to focus on large multi-modal models, such as LLaVA [217,218], an end-to-end large multimodal model that connects a visual encoder and a large language model to achieve general visual and language understanding.Additionally, MiniGPT-5 [219] introduces a novel interleaved vision-and-language generation technique, with a focus on non-descriptive multimodal generation.Exploring the integration of these large multimodal models within misinformation detection methods is an interesting and promising research direction.


### Benchmark

Several benchmark datasets have been developed in the context of shared tasks, which are aimed at evaluating various different characteristics of misinformation detection methods.For example, the datasets created for SemEval-2017-Task8 [35] and SemEval-2019-Task7 [35] focus on stance detection and misinformation detection, while the CLEF2020 -CheckThat!Lab [98] addresses multilingualism through the inclusion of benchmark data in both English and Arabic.These are complemented by a recently developed multi-modal benchmark for fake news detection [220].Despite the value of these datasets in facilitating the evaluation of various different individual aspects of methods, there is still a lack of a suitably comprehensive benchmark that can simultaneously evaluate the ability of misinformation detection methods to handle diverse types of multi-modal data from multiple platforms and covering different languages, as well as assessing their ability to perform important subsidiary tasks such as emotion, sentiment and stance detection, identification of rumor source, etc.We believe that the development of such a dataset would be of enormous value in helping to guide research in this area towards the development of more robust and universally applicable misinformation methods, as well as focusing attention on the development of important supporting technologies.


### Interpretability

Understanding how and why misinformation detection models have arrived at their decision about whether or not a post or news article represents true or fake information can be important to make their reasoning processes more transparent and make it easier to understand why errors occur.However, despite the high levels of performance achieved by many DL approaches, their black-box nature means that no such reasoning information is available, and that their decisions are hard to justify.Although it remains a challenge to develop models that are both sufficiently accurate and whose results are interpretable, several studies have proposed possible solutions for explainable misinformation detection.These include the use of topic-based features for classification [221], Explainable Artificial Intelligence (XAI) techniques [222] and Commonsense Knowledge Graphs [223].Recent research has also begun to focus on the development of interpretable LLMs [224], such as MentalLLaMA [225], which is an interpretable mental health analysis model based on LLaMA-2.Accordingly, it is hoped that researchers working in misinformation detection will begin to place greater emphasis on exploring the increasing range of options that could be used to improve the interpretability of their models.


### Large Language Models

The popularity of ChatGPT and GPT-4 [9] has resulted in the powerful capabilities of LLMs becoming widely known [226].As mentioned above, there is potential for LLMs to be employed in misinformation detection in multiple ways, including sentiment and emotion detection, multimodal analysis, and to enhance the interpretability of detection models.Some studies have additionally begun to explore the use of LLMs for rumor and fake news prediction.For example, Hu et al. [25] designed a framework for fake news detection in which a small language model (i.e., BERT) is complemented by an LLM, which provides multi-perspective guiding principles to improve prediction accuracy.Meanwhile, Pavlyshenko et al. [26] designed prompts to fine-tune LLaMA for rumor and fake news detection.Cheung et al [27] used external knowledge to bridge the gap between knowledge encoded in the LLM and the most up-to-date information available on the Internet, in order to enhance fake news detection performance.The promising results achieved by these approaches, combined with the indisputable power and advanced capabilities of LLMs, motivate further exploration of how they can be best exploited to further improve the accuracy of rumor and fake news detection.


## Conclusion

The unstoppable growth of social media is making it easier than ever for misinformation to spread rapidly and widely.As such, there is an increasingly urgent need for robust automated methods that can detect and stop this spread as efficiently and effectively as possible.In this article, we have comprehensively analyzed emotion-based applications for rumor and fake news detection.After introducing related work, we firstly motivated such approaches by summarizing research that confirms the strong links between emotion and misinformation.We subsequently provided an overview of available datasets that can support the development of misinformation detection methods, followed by a summary of both conventional and deep learning methods that have been employed in emotion-based misinformation detection approaches.We then proceeded to describe and categorise a diverse range of recently proposed advanced methods that combine the use of emotion and/or sentiment with various other features, and which integrate a number of different learning methods to achieve their goals.We additionally provided an overview of emotion-based stance detection methods in misinformation.Subsequently, we discussed the relative strengths and weaknesses of different advanced methods from various perspectives.Finally, we outlined several unsolved challenges in the field of rumor and fake news detection, and provided suggestions for future research directions, with a focus on the greater exploitation of the increasingly ubiquitous LLMs.In summary, our review has aimed to demonstrate the significant role of sentiment and emotion in misinformation, and to highlight the most important aspects in its automated detection.It is intended that the survey will enable researchers who are interested in this field to better appreciate the potential value of affective information in misinformation detection, and will help to drive further advances to the SOTA in this field.


## A. Specific types of content-based features B. Emotion Detection Tools

Various tools and resources are used for the detection of emotion and sentiment features, the most commonly used of which are summarized in Table 7.In addition to the methods in Table 7, there are also some title-text similarity, word similarity, sentence similarity, cosine similarity between source post and related comments Cluster Features word-cluster feature, brown cluster feature [199], SDQC depth-based clusters [199] Semantic Feature word vector features (Glove [227], BERT [228], GoogleW2V [229], Word2vec [230]) Grammatical Features part-of-speech tags, noun, verbs, adjectives, and pronouns Lexical Features bad sexual words, cue words, multilingual hate lexicon, linguistic words, specific categories, denial term, support words, negation words, swear words, surprise and doubt words Linguisticinformed Features tf-idf, n-gram, named entity recognition, text language, bag-of-characters, bag of words (BoW) Stylistic Features [43] question marks, exclamation marks, punctuation marks, length of a sentence, uppercase ratio, consecutive characters and letters, presence of URLs, number of stop words, number of upper case letters, number of lower case letters, number of numeric values, word count, character count, sentence count, average sentence length, ease of comprehension, lexical diversity Syntactic Features ratio of negation, bag of relations (all tokens, list of words, verbs) Conversation based Features text similarity to source tweet, text similarity to replied tweet, tweet depth Twitter Metadata [28,204] the number of characters in a tweet, the number of retweets, favorites, presence of hashtags, URLs, mentions, existence of photos, creating time gaps for posts, Twitter verification.etc. Reddit Metadata [139] karma, gold status, Reddit employment status (if any), verified e-mail, reply count, upvotes, and whether the user is the submission submitter.Reddit commenting syntax: sarcasm ('/s'), edited ('edit:'), and quote count ('>') Others Topics, term features, textual novelty other efficient sentiment analysis tools such as Emojis Dictionary8 , Emoticons list9 , Affect-Br [242], SemEval10 , MPQA 11 , ENGAR [243], Hespress Facebook12 , Offense lexicon 13 , Sarcasm lexicon [244], Named entities lexicon (Religion lexicon, Nationality lexicon, Named entities) [158], Baidu sentiment API 14 , NLTK sentiment module 15 , SEO Scout's analysis tool 16 , IBM Watson's Natural Language Understanding (NLU) 17 , MeaningCloud18 , ParallelDots 19 , Empath [245], EffectWordNet [246], Hu&Liu opinion lexicon 20 , SSWE [247], NRC-Canada [248], Stanford sentiment Tree [249], Dictionary of Affect in Language (DAL) [250], Affective Norms for English Words (ANEW) [241], Meta-Mind sentimentclassifier API 21 .


## C. Evaluation Measurements


## C.1. Misinformation Detection Evaluation

A variety of techniques has been used to evaluate the output of misinformation detection methods, including accuracy, recall, precision, and F1-score, Macro F1, class-wise F1-score, AUC [172,176,177], and RMSE [29].These are calculated on the basis of a number of basic concepts, which are defined as follows: TP (True Positive) refers to the number of samples that the model correctly predicts as positive; TN (True Negative) refers to the number of samples that the model correctly predicts as negative; FP (False Positive) refers to the number of samples that the model incorrectly predicts as positive; FN (False Negative) refers to the number of samples that the model incorrectly predicts as negative.

The accuracy indicates the overall classification correctness of a model:   [234] Arabic An open-source package consisting of a set of Python APIs for NLP with accompanying command-line tools that thin-wrap these APIs sentiment Affective Lexicon Ontology (ALO) [193] Chinese Lexicon in which each entry is with an emotion and sentiment polarity sentiment, emotion TextBlob a English A Python sentiment analysis library that uses the Natural Language ToolKit (NLTK) sentiment scores with subject and polarity LIWC [235] Multilingual Text analysis software to conduct various calculations related to emotions, social dynamics, and cognitive processes by counting relevant words.Root Mean Squared Error (RMSE) represents the expected value of the squared error.


## Various text analyses
𝑅𝑀𝑆𝐸 = √ √ √ √ 1 𝑛 𝑛 ∑ 𝑖=1 | | 𝑦 𝑖 − ŷ𝑖 | | 2(5)

## C.2. Stance Detection Evaluation Measurements

Accuracy, recall, precision, and F1-score, Macro F1, class-wise F1-score, FNC1-Score [202,203], weighted accuracy [207] are used in stance detection.

The FNC-1 weighted accuracy score is used as the final evaluation metric for the FNC-1 dataset.  − 1  = 0.25 *    + 0.75 *  ,, (6) Weighted Accuracy is a performance metric that takes into account the weight of each class in an imbalanced dataset.It calculates the overall performance of the model by taking a weighted average of the accuracy for each category.


## CRediT authorship contribution statement

## Figure 1 :
1
Figure 1: Fake news samples


## Figure 2 :
2
Figure 2: Distribution of publications on emotion-based applications in misinformation since 2016.


## Figure 3 :Figure 4 :
34
Figure 3: Structure of this article


## Figure 5 :
5
Figure 5: Emotion-based misinformation detection by combining emotion with other text-based features.(a) FakeFlow [124], (b)Mixture-of-Experts[177], (c) EmoAttentionBERT[163] (d) LSTM (with Fuzzy Sentiment)[164]


## Figure 6 :
6
Figure 6: Emotion-based misinformation detection by mining of dual emotions.(a) AGWu-RF[20], (b) MDE[29], (c) EFN[134]


## Figure 7 :
7
Figure 7: Emotion-based misinformation detection based on tree structures.(a) SSE-BERT[23], (b) ptVAE[174], (c) Multi-EmoBERT[88]


## Figure 8 :
8
Figure 8: Emotion-based misinformation detection based on graph structure.(a) MHN[175], (b) SA-HyperGAT[162], (c) GCS[165]


## Figure 9 :
9
Figure 9: Emotion-based misinformation detection based on temporal information.(a) TDEI[22], (b) SD-TsDTS-CGRU[153,154], (c) RvNN with Temporal[169]


## Figure 10 :
10
Figure 10: Emotion-based misinformation detection based on multi-task learning.(a)[30,181,182], (b)[160]


## FluFigure 11 :
11
Figure 11: Emotion-based misinformation detection based on temporal information.(a) Multimodel with text emotion.(b) Multimodel with image emotion


## 1 ) 2 )
12
 =  +     +   +   +   (Recall measures the model's ability to identify positive-class samples: =     +   (Precision measures the proportion of true positive samples among the samples predicted as positive by the model:  =     +  (3)F1 score takes into account both precision and recall and represents the harmonic mean of precision and recall: 1  = 2 *  *    +   (4)Macro F1 is used to evaluate the performance of multiclass classifier, by combining the F1  of each class; Class-wise F1  refers to the F1  of each individual class, and can be used to evaluate the performance of the classifier for each class.The AUC (Area Under the Curve) is a commonly used metric for evaluating the performance of classification models.It measures the predictive ability of a model by calculating the area under the ROC (Receiver Operating Characteristic) curve.


## Zhiwei Liu :
Liu
Writing -original draft, Conceptualization, Methodology, Data curation, Visualization, review & editing.Tianlin Zhang: Writing -original draft, review & editing.Kailai Yang: Writing -original draft, review & editing.Paul Thompson: Writing -original draft, review & editing.Zeping Yu: Writing -review & editing.Sophia Ananiadou: Writing -review & editing.


## Table 6 in
6
Appendix A provides more detail regarding the specific
IntroductionFake News and Rumor DetectionRelated workSentiments and Emotions DatasetsMethods Combining EmotionRelationships between emotions and misinformationConventional Machine Learning Methods Deep Learning Methodswith Other Text-Based Features Mining of Dual Emotions Methods Based on Tree or Graph StructuresEmotion detection for misinformationEmotion-based misinformation detectionAdvanced Fusion Methods Emotion-based stance detection in misinformationMethods Based on Temporal Information Multitask Learning Multimodal MethodsDiscussionStrengths and Weaknesses of Advanced Fusion MethodsDataset Collection (Multi-platform, Multilingual)Data Annotation (Emotion)Challenges and futureMultimodalityresearch directionsBenchmarkInterpretabilityConclusionLarge Language ModelsAppendicesEmotions Extracted Tools Content-based FeaturesEvaluation Measurements Misinformation DetectionEvaluation MeasurementsStance DetectionEvaluation Measurements

## Table 1
1
Relationships between emotions and misinformation.ED: Emotion Detection, RAM: Relation analysis methods.MANOVA: Multivariate Analysis of Variance, MANCOVA: Multivariate Analysis of Covariance, ANOVA: Analysis of Variance.
Pub Year DataEDRAMRelationship (Partly)[90] DemonetizationLIWCLogistic RegressionPosts with a higher level of anger, sadness, and anxiety arerelatedindicative of rumor.[17] COVID-19ManualTime-lagged Cross-The angrier, sadder, or more fear the public felt, the more rumorsRelatedcorrelation Analysesthere were likely to be.[84] News Head-Questionnaire,PANAS Linear Mixed-effectsEmotion plays a causal role in people's susceptibility to incorrectlylinesAnalysesperceiving fake news as accurate.[97] [98]NRCSVMEmotion-based features contribute more to the rumor recognitioncapabilities than personality-based ones.[11] Open-Meaningt.Ioud,Chi-squareTest,Relationships exist between negative sentiment and fake news,Source DataTextBlob5, AFINN6P(T|S),Goodmanand between positive sentiment and genuine news.and Kruskal's Gamma[15] TwitterQuestionnaireGeneralizedLinearRumors conveying anticipation, anger, or trust, or which areModelhighly offensive, generate more shares, are longer-lived, and moreviral.[16] TwitterNRCGeneralizedLinearFalse rumors with a high proportion of terms conveying positiveModelsentiment, trust, anticipation, or anger are more likely to go viral.[99] COVID-19Decision TreeSPSS 22.0, GrangerThe more negative people feel about COVID-19, the more likelyRelatedCausality Testit is that rumors will be generated.[13] News Head-QuestionnaireMANOVA,Emotional reactivity of participants is associated with responselinesMANCOVA, ANOVAbehavior intentions.[12] Questionnaire Questionnaire,Multilevel Linear Re-Expression of emotion in online rumors positively affects readers'PANASgressionemotions. Readers' emotions affect their intentions to spreadrumors.[83] COVID-19Pleasure-Arousal-Logistic RegressionWeibo messages filled with high-arousal emotions such as fear,RelatedDominanceanger and surprise are more likely to be rumors.[91] Twitter,EmotionLexicon,Logit Regression, Lin-WeiboML, DLear Regression

## Table 2
2
Summary of misinformation datasets.A: Available, N: No link, R: Request.An empty cell in the Notes column means that the dataset is English and consists only of textual data Politifact An extended version of the above LIAR dataset, in which the claims are accompanied by sentences that provide justifications for the assigned labels
DatasetSourceDescription
[118]DBANK[118]Twitter 60 million tweets from 2014-2015, concerning various topics grouped into 1049 real-world events, each labeled by 30 human annotators A Kaggle Fake News dataset [119] various 12,999 posts, consisting of both text and metadata, collected over a period of 30 days from 244 websites A George McIntire dataset various 6.3k news items, with an equal distribution of fake and real items.(https://github.com/GeorgeMcIntire/fake_real_news_dataset)A SLN [120] various 360 news articles covering 12 contemporary news topics in 4 domains (civics, science, business, and soft news) A LUN [121] various News items classified as trusted(13995), satire(14985), hoax(12047) or propaganda




news pairs in both Chinese and English; test data contains 80,126 news pairs.Given the title of a fake news article A and the title of an incoming news article B, participants are asked to classify B according to whether it agrees with A, disagrees with A or is unrelated to A
DatasetSourceDescriptionANotesWeibo21 [109]Weibo4,488 fake and 4,640 real news items from 9 different domains collected betweenAmultimodal,December 2014 and March 2021 with news text, image content, timestamps, andChinesecommentsWeibo16 [108]Weibo2313 rumors and 2351 non-rumors with commentsAChineseWeibo-16 (dedu-Weibo3706 news items (1,355 fake, 2351 real) with commentsAChineseplication) [29]Weibo-20 [29]Weibo6362 news items (3161 fake, 3201 real) with commentsAChineseWeibo20-miaoWeibo3034 rumors and 3034 non-rumors created between 2016 and 2020AChinese[23][134]Weibo7880 fake and 7907 real news items with approximately 160k commentsNChinesePortuguese-various76,782 news items, labeled according to whether they were sourced from true orNPortuguesedata[135]fake news sites prelabeledFakeNewsSet[136]Twitter 300 fake and 300 genuine news itemsAPortugueseFake.Br [137]various3,600 fake and 3,600 genuine news items classified into six categories (politics, TVAPortuguese& celebrities, society & daily news, science & technology, economy, and religion)CLEF2020[138]competi-Five tasks related to verification of claims: task1: check-worthiness of tweets (962AEnglish, Arabictiontweets in English and 7,500 tweets in Arabic); task 2 -verified claim retrieval(1,197 tweets and 10,375 verified claims in English); task 3 -evidence retrieval(200 claims and 14,742 corresponding Web pages containing evidence).; task 4-claim verification (165 claims in Arabic); Task 5 -check-worthiness on debates(70 debate transcripts in English). All Tasks will run in English. Additionally, tasks1, 3, and 4 will also run in Arabic and Spanish.[28]Twitter 202 false rumors and 201 true rumors relating to 403 real-world events withRArabiccommentsDAST [139]Reddit3007 source posts (273 Support, 300 Deny, 81 Query, 2353 comments); 3007Astance, Danishtop-level comments (261 Support, 632 Deny, 304 Query, 1810 comments)ByteDancefakeByte-320,767 Astance, Chinesenews dataset [140]Danceand EnglishRumourEval17-Twitter Task A (stance classification): 5568 posts (1004 Support, 415 Deny, 464 Query,AstanceTask8 [35]3685 comments); Task B (veracity prediction): 325 source posts (145 True, 74False, 106 Unverified) with associated commentsRumourEval-19-PoliticalNews Task7 [141] [125] Buzzfeed Political News [126] FNC-1 [142, 143]various Twitter, various Reddit ter Twit-Snopes,5,994 real and 5,403 fake news articles Task A (stance classification): 8574 posts (1184 Support, 606 Deny, 608 Query, 14,240 news pages from 2013-2018 (7,136 fake and 7,104 genuine) 6176 comments); Task B (veracity prediction): 446 source posts (185 True, 138 False, 123 Unverified) with associated comments 49972 tuples, each consisting of a headline-body pairA A A A Astance stance[127] Covid-Stance HWB [128] [144] [129] Emergent [142] PHEME_stance [145] MultiFC [130] London Riots [146] [147] 2020 US Presiden-Infodemic [102] tial Election [148] COAID [103] Sydney Siege [149] Twitter 4375 tweets (2906 affirm, 1469 deny) various 23,935 news items from September 1995 to January 2021 Twitter 14,374 tweets (2848 Neutral, 4685 Against, 6841 Favor) related to COVID-19 various 500 real and 500 fake documents related to health and well being various News articles from eight web sources concerning the Hanoi summit between the various 300 claims, and 2,595 associated article headlines Twitter 297 threads containing 4,561 tweets (including retweets), spanning 138 rumors presidents of the United States and North Korea, Donald Trump and Kim Jong-un organised into 9 stories respectively various 36,534 multi-domain claims with their metadata (different domains have different Twitter 7297 tweets concerning 7 different rumors (5761 support, 957 deny, 579 question) N A A A A N A A labels, which encompass both direct truth ratings ("correct," "incorrect") and Twitter 327,484 tweets concerning 72 rumors (60.9% support, 27.4% against) N labels that are difficult to map to a level of truthfulness (e.g. 'grass roots Twitter 2500 tweets manually labeled with stance, 1250 for each presidential candidate A movement!', 'misattributed', 'not the whole story')) various 10,700 social media posts and articles (5600 real, 5100 fake) on COVID-19. A (Joe Biden and Donald Trump) various 4,251 news items (204 fake and 3,565 true news articles, 28 fake and 454 A Nstance stance stance stance stance stance COVID-19 COVID-19 stancetrue claims), 296,000 related user engagements (e.g. clicks, shares), 926 socialplatform posts about COVID-19.[104]various586 genuine and 578 fake news items, and more than 1,100 news items and socialACOVID-19media posts regarding COVID-19.[105]Twitter Globally-collected Tweets related to the epidemic, obtained by filtering tweetsRCOVID-19containing word or hashtag Covid-19, Corona Virus, Corona, COVID, covid19,and sarscov2FakeNewsNet[110] Politifact 432 fake and 624 real news items with content, images, and social networkAmultimodalinformationFakeNewsNet[110] Gossipcop 5,323 fake and 16,817 real news items with content, images, and social networkAmultimodalinformationFakeddit [111]Reddit1,063,106 samples with submission title, image, comments and metadataAmultimodalMediaEval2016Twitter 193 cases of real and 220 cases of misused images/videos, associated with 6,225Amultimodal[112]real and 9,596 fake posts posted by 5,895 and 9,216 unique users, respectivelyNovEmoFake[131]Amultimodal,Hindi,Bengali, TamilMultimodal-Weibo9528 posts (4749 rumor and 4779 non-rumor) with images, created between MayNmultimodal,Weibo[133]2012 and January 2016Chinese
various Dataset 1 (Buzzfeed 2016 election data): 36 real and 35 fake items; Dataset 2 (political news): 75 real, 75 fake and 75 satire items; Dataset 3 (Burfoot and Baldwins satire): 233 satire and 4000 real items various 6816 real and 4950 fake news items (text and images) with background information (where and in which context the news item was first published) R multimodal MMM [132] various 5630 real and 4840 fake news items (text and images) with background information (where and in which context the news item was first published)


## Table 3
3
Summary of emotion-based misinformation detection.EF: Emotion Features, E: Emotion, S: Sentiment, IE: Image Emotion, ED: Emotion Detection, ERD: Emotion-based Rumor Detection, MLs: Various Machine Learning methods.Other abbreviations are explained in section 4.2.
Pub Year DataEFEDERDOther Features[134] CustomizedEGRUEFN (Fig. 6 (c))[150] PolitiFact, GossipCopSVADERSAMEImage, User-based[151] Various Public DatasetSNaive BayesNB, RFtf-idf scores, Cosine similarityscores[152] PHEMESLIWCMLs, LSTM-HANTopics[153] Weibo16EALOSD-DTS-GRU (Fig. 9 (b))Time[154] Weibo16, Twitter16S, E DictionariesSD-TsDTS-CGRU (Fig. 9 (b))Time[155] PHEME, Twitter15, Twit-Sa Hierarchical Attention Net-User-basedter16work with User and Sentimentinformation[128] HWBENRC IntensityMLs[156] Fake.BrS, E DictionariesMLsGrammatical, Stylistic[157] FakeNewsNet, CredBankSDictionariesDT, Bi-LSTMTopics[158] CLEF2020SDictionariesWeb CheckTopics, Offense Named Enti-ties[159] FakeNewsNetSVADERMLs, DNNRetweet Rate[22] Weibo16SBERTTDIE (Fig. 9 (a))Time, Propagation Structure[160] ByteDance, FNC, Covid-S, E BERT, LSTMMultitask (Fig. 10 (b))Textual NoveltyStance[29] RumourEval19,Weibo16,S, E DictionariesMDE (Fig. 6 (b))Dual EmotionWeibo20[161] FakeNewsSetS, E DictionariesMLsImage Captioning, Grammat-ical, Stylistic[23] Weibo16, Weibo20SALO, BERTSSE-BERT (Fig. 7 (a))Dependency Tree[124] MultiSourceFake, LUN, Po-S, E Bi-GRUs basd onFakeFlow (Fig. 5 (a))TopicsliticalNews, FakeNewsNetdictionary[30] PHEME, FakeNews AMT,EUnison modelMultitask (Fig. 10 (a))DomainsCeleb, Gossipcop[24] ISOTERoBERTaRoBERTa, RF[21] [104]SGRU, LSTM, RNNStylistic, Linguistic-informed[162] Twitter15, Twitter16SRoBERTaSA-HyperGAT (Fig. 8 (b))Structure[105] CustomizedSVADERModified VADERDiffused Information[163] MultiFCS, E EmoAttentionEmoAttention BERT (Fig. 5BERT(c))[164] Infodemic, CoAIDSFuzzySentimentLSTM (with Fuzzy Sentiment)Scoring(Fig. 5 (d))[129] CustomizedSSenticNetConceptual Graphs with senti-Entityment[132] MMM [131]IEResnet18SCL, BERT and ResNET18Novelty, Image,[165] PHEMES, E NRCGCS (Fig. 8 (c))N-gram, Similarity Matching[166] MediaEval2016,IEVGG16CredNNMultimodal-weibo[167] FakedditIEXceptionBERT, XceptionImage, image caption[168] ByteDance, Covid-Stance,EBERTLRNoveltyFNC, LIAR-PLUS[169] Weibo16, RumourEvalSDictionariesRvNN with Temporal (Fig. 9Time(c))[170] Buzzfeed Political NewsSSEO Scout's analy-MLsStylistic, Linguistic-informedsis[127] CustomizedSAfinn, VADERMLsTopics, Title-text similarity[28] CustomizedS, E DictionariesArabic PLMsTopics, Stylistic, User-based[20] RumourEval19,PHEME,S, E CNN, Bi-GRUAGWu-RF (Fig. 6 (a))StylisticFakeddit[171] ISOT, LIARSLexicon-basedMLsGrammatical, Likes[172] FakedditS, E DictionariesBi-LSTMTitle[173] PolitiFact, GossipCopS, E method in [29]BERT, ResNeSt-50Title-Text similarity,Images[174] Weibo16, Twitter15, Twit-SSentiment PatternptVAE (Fig. 7 (b))User-based, Structure, Prop-ter16Module (SPM)agation[175] SLN, LUNS, E RoBERTa,MHN (Fig. 8 (a))Graph, Topics, EntitiesSentimentInteraction Graph[176] Twiter-harvard,health-ENRCMLsLinguistic-informed,User-relatedbased[135] Portuguese datsaset (custu-SSentiment GradientMLs, LSTMmized), Fake.br

## Table 4
4
Emotion-based stance detection in rumor and fake news.EF: Emotion Features, S: Sentiment, E: Emotion, ED: Emotion Detection, ESD: Emotion-based Stance Detection, RDES: Rumor Detection based on Emotion and Stance.
Pub Year DataEFEDESDRDESOther Features[149]2016 Sydney SiegeSMetaMind APILR, NB, RFStylistic, Twitter metadata, Linguistic-datainformed[45] 2017 SemEval2017S, E SSWE, ZSWEEnsemble ClassifierEnsemble Clas-Linguistic-informed, Stylistic, Tweetsifiermetadata,User-based,Semantic,Cluster features,[198]2017 SemEval2017SVADERXGBoostStylistic, Similarity, Twitter metadata,Grammatical features[199]2017 RumourEval,SStanford senti-DT, RF, KNNLinguistic-informed, Twitter metadata,PHEMEment toolUser-based, Similarity, Lexical features[200]2018 SemEval2017SNLTKLinear SVC, LR, RF,Linear SVC, LR,Stylistic, Lexical, Conversation-based,DT, SVMRF, DT, SVMUser-based features[201]2018 SemEval2017S, EEnsemble ClassifierEnsemble Clas-Stylistic, Twitter metadatasifier[42] 2018 FNC datasetSNRC-Lex, NRC-stacked LSTMsLinguistic-informed, Topics, SimilarityCanadafeatures[202]2018 EmergentSStanford Senti-LR, RFGrammatical, Stylistic, Structural fea-datasetmenttures[203]2018 FNC datasetSlexicon basedCNN, LSTM, GRUStylistic, Linguistic-informed features[43] 2019 SemEval2019S, E Various Dictio-LRLRLexical, Syntactic, Stylistic, Twitter,nariesConversation-based, Cluster features[204]2019 SemEval2019SNLTK, VADEREnsemble ClassifierStylistic, Linguistic-informed, Grammati-cal, Semantic, Similarity, User-based fea-tures[205]2019 SemEval2019SBi-LSTM and rulesBi-LSTM andStylistic, Conversation-based, User-rulesbased features[139]2019 DASTSAfinnLSTM, LR, SVMHMMsStylistic, Lexical, Reddit metadata,Linguistic-informed, Semantic, Similarityfeatures[46] 2019 SemEval2017SSenticNet5LR, DT, RF, Lin-Stylistic, Topic, User-based featuresearSVC, NB[206]2019 SemEval2017EVarious Dictio-NB, DT, SVM, RFStylistic, Conversation-basednaries[207]2020 [147]; LondonSVADERGraph-based Algo-Cluster, Linguistic-informed, Lexical fea-Riots Dataset;rithmturesPHEME[44] 2021 SemEval2019S, E Various Dictio-Multi-Task LearningSentenceConversion-based, Stylistic, Grammati-nariesbased on longformerEncodercal features[47] 2023 2020 US Pres-idential Elec-tion [148]

## Table 5
5
Performance of advanced fusion methods.Ablation: No emotion, use the same methods as the Evaluation column, but without sentiment/emotion features.The evaluation scores provided for each dataset listed in the Data column, separated by commas (Example: score 1 , score 2 ).When separate results are provided for different categories in the dataset, these categories are shown in brackets in the Data column.The same structure is used to report the specific results for the different categories in the scores for different categories are indicated like (score   , score   ), with the categories already labeled in the Data.
MethodsPub and baselineDataEvaluationAblation: No emotionMethods Combining Emotion with Other Text-Based FeaturesFakeFlow [124] Baseline (BERT) MixtureofExperts[177] Baseline (BERT) EmoAttentionBERT[163] MultiFC (snopes, politifact) MultiSourceFake, LUN MultiSourceFake Weibo21 Baseline (BERT) LSTM with Fuzzy Combination of Infodemic andF1-macro 0.96, 0.96 F1-macro 0.93 F1 0.9223 F1 0.8795 F1-macro 0.344, 0.318 F1-macro 0.295, 0.282 F1 0.9143MultiSourceFake 0.91 0.9185 0.9024Sentiment[164]CoAIDAGWu-RF [20]RumourEval19, PHEME, FakedditF1 0.95, 0.97, 0.97Mining ofBaseline(RumorEval,PHEME:DTCA[209];F1 0.82, 0.83, 0.83DualFakeddit:DeepNet[210])EmotionsMDE [29]RumourEval19, Weibo16, Weibo20 F1-macro 0.346, 0.867, 0.915EFN [134]CustomizedF1 0.8740.859Baseline (GRU)F1 0.84SSE-BERT [23]Weibo16, Weibo20F1 0.947, 0.9430.941, 0.94Baseline (Bi-GCN)F1 0.892, 0.882ptVAE [174]Weibo16,Twitter15,F1 (0.853,0.848), (0.67,0.697),(0.776,0.754),Methods Based on Tree or Graph StructuresBaseline (GFVAE [211]) [178] Baseline (BERT) MHN [175]Twitter16(True,False) Weibo16 LUN, SLN(0.682,0.682) F1(0.752,0.745),(0.623,0.653),(0.639,0.648) (0.6,0.638),(0.641,0.676) F1 0.97 F1 0.88 F1-macro 0.7169, 0.8972 (LUN) no sentiment net 0.6983Baseline (GCN+Attn)F1-macro 0.6642, 0.8524SA-HyperGAT [162]Twitter15, Twitter16 (UR, NR,F1(0.857,0.838,0.923,0.88),(0.837,0.763,0.905,0.861),TR, FR)(0.925,0.886,0.957,0.86)(0.866,0.765,0.939,0.87)Baseline (Bi-GCN)F1 (0.752,0.772,0.885,0.847),(0.818,0.772,0.885,0.847)GCS [165]PHEMEF1 0.9342Baseline ([152])F1 0.8496TDEI [22]Weibo16 (True, False)F1 (0.969,0.968)(0.959,0.958)MethodsBaseline(RVNN)F1 (0.911,0.905)Based onSD-TsDTS-CGRU [153,Weibo16,Twitter16-2(non-F1 (0.963,0.963), (0.880,0.889)Weibo16(rumor) 0.92Temporal154]rumor,rumor)InformationBaseline(GRU)F1 (0.830,0.835), (0.796,0.804)RvNNwithTemporal[169] Weibo16, RumourEval19F1-macro 0.939, 0.5340.925,0.492Baseline(RVNN)F1-macro 0.919, 0.506[30]PHEME, FakeNewsAMT, Celeb,F1 0.864, 0.866, 0.879, 0.7780.848,0.806,MultitaskGossipcop0.815,0.745Learning[181, 182]Source: FakeNewsAMT; Target:Accuracy 0.7950.451Gossipcop (cross domain)[160]ByteDance, FNC, Covid-StanceF1 0.9974, 0.9688, 0.98590.8821, 6826, 0.8428Baseline(SiameseLSTM[212])F1 0.8783, 0.675, 0.8392[173]PolitiFact, GossipCopF1 0.92, 0.8940.914, 0.892Baseline (BERT)F1 0.818, 0.850[150]PolitiFact, GossipCopF1-macro 0.7724, 0.80420.7085, 0.7091Baseline (SVM)F1-macro 0.6557, 0.6124Multimodal[132]MMM (real, fake)F1 (0.960,0.949)0.926, 0.907MethodsBaseline(MLBERT+ResNet)F1 (0.765,0.703)[131]NovEmoFakeF1-micro 0.97750.9054Baseline(BERT,ResNet)F1-micro (0.8002, 0.7401)[167]FakedditF1 0.9329 Accrucy 0.9194Baseline(BERT+ResNet)Accrucy 0.8909

## Table 6
6
Specific types of content-based features
TermFeaturesSimilarityFeatures

## Table 7
7
Emotion Detection Tools
ToolTargetDescriptionLanguage
https://datareportal.com/reports/digital-2023-april-global-statshot
https://www.snopes.com/
https://www.factcheck.org/
https://www.politifact.com/
https://wordnet.princeton.edu/
https://ai.baidu.com/tech/nlp_apply/sentiment_classify
https://www.nltk.org/api/nltk.sentiment.html?highlight=sentiment# module-nltk.sentiment
https://drive.google.com/file/d/1G1vIkkbqPBYPKHcQ8qy0G2zkoab 2Qv4v/view
https://en.wikipedia.org/wiki/List_of_emoticons
http://www.saifmohammad.com/WebPages/SCL.html
http://www.purl.org/net/ArabicSA
https://fr-fr.facebook.com/Hespress
https://sites.google.com/site/offensevalsharedtask/
https://ai.baidu.com/tech/nlp_apply/sentiment_classify
https://www.nltk.org/api/nltk.sentiment.html?highlight=sentiment #module-nltk.sentiment
https://seoscout.com
https://https://www.sciencedirect.com/topics/computerscience/natural-language-understanding
18 https://www.meaningcloud.
com/19 https://apis.paralleldots.com/text_docs/index.html
http://www.cs.uic.edu/liub/FBS
https://www.metamind.io

Online misinformation: Challenges and future directions. M Fernandez, H Alani, Companion Proceedings of the The Web Conference. 2018. 2018

Social media and fake news in the 2016 election. H Allcott, M Gentzkow, Journal of economic perspectives. 3122017

P Bordia, N Difonzo, Rumor, gossip and urban legends. 200754

Semantic analysis of cultural heritage news propagation in social media: Assessing the role of media and journalists in the era of big data. T A Maniou, Sustainability. 1313412021

Science audiences, misinformation, and fake news. D A Scheufele, N M Krause, Proceedings of the National Academy of Sciences. 116162019

Research on the spread and governance of internet rumors under the covid-19. R Li, Y Wang, Academic Journal of Humanities & Social Sciences. 472021

A covid-19 rumor dataset. M Cheng, S Wang, X Yan, T Yang, W Wang, Z Huang, X Xiao, S Nazarian, P Bogdan, Frontiers in Psychology. 126448012021

Training language models to follow instructions with human feedback. L Ouyang, J Wu, X Jiang, D Almeida, C Wainwright, P Mishkin, C Zhang, S Agarwal, K Slama, A Ray, Advances in Neural Information Processing Systems. 352022

R Openai, arXivGpt-4 technical report. 2023

Research on the impact of trends related to chatgpt. Y Yan, B Li, J Feng, Y Du, Z Lu, M Huang, Y Li, Procedia Computer Science. 2212023

On sentiment of online fake news. R N Zaeem, C Li, K S Barber, IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM). IEEE2020. 2020

Emotional contagion in the propagation of online rumors. N Zhang, J Song, K Chen, S Jia, Issues in Information Systems. 2322022

Emotions: The unexplored fuel of fake news on social media. C G Horner, D Galletta, J Crawford, A Shirsat, Journal of Management Information Systems. 3842021

The spread of true and false news online. S Vosoughi, D Roy, S , science. 35963802018

Emotions in online rumor diffusion. N Pröllochs, D Bär, S Feuerriegel, EPJ Data Science. 101512021

Emotions explain differences in the diffusion of true vs. false social media rumors. N Pröllochs, D Bär, S Feuerriegel, Scientific Reports. 111227212021

Public emotions and rumors spread during the covid-19 epidemic in china: web-based correlation study. W Dong, J Tao, X Xia, L Ye, H Xu, P Jiang, Y Liu, Journal of Medical Internet Research. 2211e219332020

J Cui, Z Wang, S.-B Ho, E Cambria, Survey on sentiment analysis: evolution of research methods and topics. 2023

Sentiment analysis for fake news detection. M A Alonso, D Vilares, C Gómez-Rodríguez, J Vilares, Electronics. 101113482021

Dual emotion based fake news detection: A deep attention-weight update approach. A M Luvembe, W Li, S Li, F Liu, G Xu, Information Processing & Management. 6041033542023

Covid-19 fake news sentiment analysis. C Iwendi, S Mohan, E Ibeke, A Ahmadian, T Ciano, Computers and electrical engineering. 1011079672022

Rumor detection on social media using temporal dynamic structure and emotional information. C Wang, B Zhou, H Tu, Y Liu, 2021 IEEE Sixth International Conference on Data Science in Cyberspace (DSC). IEEE2021

Syntax and sentiment enhanced bert for earliest rumor detection. X Miao, D Rao, Z Jiang, Natural Language Processing and Chinese Computing: 10th CCF International Conference, NLPCC 2021. Qingdao, ChinaSpringerOctober 13-17, 2021. 2021Proceedings, Part I 10

Foreal: Roberta model for fake news detection based on emotions. V Kolev, G Weiss, G Spanakis, ICAART. 22022

B Hu, Q Sheng, J Cao, Y Shi, Y Li, D Wang, P Qi, arXiv:2309.12247Bad actor, good advisor: Exploring the role of large language models in fake news detection. 2023arXiv preprint

Analysis of disinformation and fake news detection using fine-tuned large language model. B M Pavlyshenko, arXiv:2309.047042023arXiv preprint

Factllama: Optimizing instructionfollowing language models with external knowledge for automated fact-checking. T.-H Cheung, K.-M Lam, arXiv:2309.002402023arXiv preprint

Exploring the role of emotions in arabic rumor detection in social media. H F Al-Saif, H Z Al-Dossari, Applied Sciences. 131588152023

Mining dual emotion for fake news detection. X Zhang, J Cao, X Li, Q Sheng, L Zhong, K Shu, Proceedings of the web conference 2021. the web conference 20212021

An emotionaware multitask approach to fake news and rumor detection using transfer learning. A Choudhry, I Khatri, M Jain, D K Vishwakarma, IEEE Transactions on Computational Social Systems. 2022

A review on sentiment analysis techniques and applications. M R Yaakub, M I A Latiffi, L S Zaabar, IOP conference series: materials science and engineering. IOP Publishing201955112070

Earlier detection of rumors in online social networks using certainty-factor-based convolutional neural networks. S Santhoshkumar, L Dhinesh Babu, Social network analysis and mining. 202010

Early detection of rumours on twitter via stance transfer learning. L Tian, X Zhang, Y Wang, H Liu, Advances in Information Retrieval: 42nd European Conference on IR Research. Lisbon, PortugalSpringerApril 14-17, 2020. 20202020Proceedings, Part I 42

Towards automatic fake news detection: cross-level stance detection in news articles. C Conforti, M T Pilehvar, N Collier, Proceedings of the first workshop on fact extraction and VERification (FEVER). the first workshop on fact extraction and VERification (FEVER)2018

L Derczynski, K Bontcheva, M Liakata, R Procter, G W S Hoi, A Zubiaga, arXiv:1704.05972Semeval-2017 task 8: Rumoureval: Determining rumour veracity and support for rumours. 2017arXiv preprint

Adaptive cost-sensitive stance classification model for rumor detection in social networks. Z Zojaji, B Tork Ladani, Social Network Analysis and Mining. 1211342022

Towards sentiment and temporal aided stance detection of climate change tweets. A Upadhyaya, M Fisichella, W Nejdl, Information Processing & Management. 6041033252023

Combating fake news on social media with source ratings: The effects of user and expert reputation ratings. A Kim, P L Moravec, A R Dennis, Journal of Management Information Systems. 3632019

Sentiment and network analysis of twitter reactions to the us birthright citizenship ban debate. A Worrall, A Ndumu, L H Gerido, International Conference on Information. Springer2022

Stance and sentiment in tweets. S M Mohammad, P Sobhani, S Kiritchenko, ACM Transactions on Internet Technology (TOIT). 1732017

Detecting stance in tweets and analyzing its interaction with sentiment. P Sobhani, S Mohammad, S Kiritchenko, Proceedings of the fifth joint conference on lexical and computational semantics. the fifth joint conference on lexical and computational semantics2016

A retrospective analysis of the fake news challenge stance detection task. A Hanselowski, P Avinesh, B Schiller, F Caspelherr, D Chaudhuri, C M Meyer, I Gurevych, Proceedings of the 27th International Conference on Computational Linguistics. the 27th International Conference on Computational Linguistics2018

Upv-28-unito at semeval-2019 task 7: Exploiting post's nesting and syntax information for rumor stance classification. B Ghanem, A T Cignarella, C Bosco, P Rosso, F M R Pardo, Proceedings of the 13th international workshop on semantic evaluation. the 13th international workshop on semantic evaluation2019

Fine-tune longformer for jointly predicting rumor stance and veracity. A , Proceedings of the 3rd ACM India Joint International Conference on Data Science & Management of Data (8th ACM IKDD CODS & 26th COMAD). the 3rd ACM India Joint International Conference on Data Science & Management of Data (8th ACM IKDD CODS & 26th COMAD)2021

Ecnu at semeval-2017 task 8: Rumour evaluation using effective features and supervised ensemble models. F Wang, M Lan, Y Wu, Proceedings of the 11th International Workshop on Semantic Evaluation. the 11th International Workshop on Semantic EvaluationSemEval-2017. 2017

Rumor stance classification via machine learning with text, user and propagation features. K Xuan, R Xia, 2019 International Conference on Data Mining Workshops (ICDMW). IEEE2019

Flacorm: fuzzy logic and ant colony optimization for rumor mitigation through stance prediction in online social networks. P Parimi, R R Rout, Social Network Analysis and Mining. 131222023

A review of rumor detection techniques in social networks. Y Liu, H Shen, L Shi, Journal of Intelligent & Fuzzy Systems. 2023Preprint

A review on fake news detection techniques. K Mandal, A Malik, 10.1109/ICSCCC58608.2023.101765302023 Third International Conference on Secure Cyber Computing and Communication (ICSCCC). 2023

A review of methodologies for fake news analysis. M Tajrian, A Rahman, M A Kabir, M R Islam, 10.1109/ACCESS.2023.3294989IEEE Access. 112023

A review of fake news detection methods using machine learning. M Choudhary, S Jha, D Saxena, A K Singh, 2nd International Conference for Emerging Technology (INCET). IEEE2021

A survey on fake news and rumour detection techniques. A Bondielli, F Marcelloni, Information Sciences. 4972019

A survey on the use of graph convolutional networks for combating fake news. I Varlamis, D Michail, F Glykou, P Tsantilas, Future Internet. 143702022

Fake news detection: a survey of evaluation datasets. A D'ulizia, M C Caschera, F Ferri, P Grifoni, PeerJ Computer Science. 7e5182021

Review of stance detection for rumor verification in social media. H F Alsaif, H D Aldossari, Engineering Applications of Artificial Intelligence. 1191058012023

A survey on stance detection for mis-and disinformation identification. M Hardalov, A Arora, P Nakov, I Augenstein, arXiv:2103.002422021arXiv preprint

Are you a cyborg, bot or human?-a survey on detecting fake news spreaders. W Shahid, Y Li, D Staples, G Amin, S Hakak, A Ghorbani, IEEE Access. 102022

Source detection of rumor in social network-a review. S Shelke, V Attar, Online Social Networks and Media. 92019

Natural language processing applied to mental illness detection: a narrative review. T Zhang, A M Schoene, S Ji, S Ananiadou, NPJ digital medicine. 51462022

Emotion fusion for mental illness detection from social media: A survey. T Zhang, K Yang, S Ji, S Ananiadou, Information Fusion. 922023

Prioritising references for systematic reviews with robotanalyst: a user study. P Przybyła, A J Brockmeier, G Kontonatsios, M.-A Le Pogam, J Mcnaught, E Elm, K Nolan, S Ananiadou, Research synthesis methods. 932018

Using text mining for study identification in systematic reviews: a systematic review of current approaches. A O'mara-Eves, J Thomas, J Mcnaught, M Miwa, S Ananiadou, Systematic reviews. 412015

Reducing systematic review workload through certainty-based screening. M Miwa, J Thomas, A O'mara-Eves, S Ananiadou, Journal of biomedical informatics. 512014

Mining misinformation in social media. L Wu, F Morstatter, X Hu, H Liu, Big data in complex and social networks. 2016

A method of machine learning for social bot detection combined with sentiment analysis. G Long, D Lin, J Lei, Z Guo, Y Hu, L Xia, Proceedings of the 2022 5th International Conference on Machine Learning and Natural Language Processing. the 2022 5th International Conference on Machine Learning and Natural Language Processing2022

V Chawla, Y Kapoor, A hybrid framework for bot detection on twitter: Fusing digital dna with bert, Multimedia Tools and Applications. 2023

Emotion analysis: A survey. N M Hakak, M Mohd, M Kirmani, M Mohd, 10.1109/COMPTELIX.2017.80040022017 International Conference on Computer, Communications and Electronics. 2017

Sentiment analysis: a comparative study on different approaches. M D Devika, C Sunitha, A Ganesh, Procedia Computer Science. 872016

Sentiment strength detection in short informal text. M Thelwall, K Buckley, G Paltoglou, D Cai, A Kappas, Journal of the American society for information science and technology. 61122010

Vector based sentiment and emotion analysis from text: A survey. H A Uymaz, S K Metin, Engineering Applications of Artificial Intelligence. 1131049222022

Emotion detection from text and speech: a survey. K Sailunaz, M Dhaliwal, J Rokne, R Alhajj, Social Network Analysis and Mining. 82018

Emotion knowledge: further exploration of a prototype approach. P Shaver, J Schwartz, D Kirson, C O'connor, Journal of personality and social psychology. 52610611987

An argument for basic emotions. P Ekman, Cognition & emotion. 63-41992

A general psychoevolutionary theory of emotion. R Plutchik, Theories of emotion. Elsevier1980

Text-based emotion detection: Advances, challenges, and opportunities. F A Acheampong, C Wenyu, H Nunoo-Mensah, Engineering Reports. 27e121892020

Evidence for a three-factor theory of emotions. J A Russell, A Mehrabian, Journal of research in Personality. 1131977

Norms of valence, arousal, and dominance for 13,915 english lemmas, Behavior research methods. A B Warriner, V Kuperman, M Brysbaert, 201345

Machine learning techniques for emotion detection and sentiment analysis: current state, challenges, and future directions. A Alslaity, R Orji, Behaviour & Information Technology. 2022

A survey on deep learning for textual emotion analysis in social networks. S Peng, L Cao, Y Zhou, Z Ouyang, A Yang, X Li, W Jia, S Yu, Digital Communications and Networks. 852022

Enhancing financial sentiment analysis via retrieval augmented large language models. B Zhang, H Yang, T Zhou, A Babar, X.-Y Liu, arXiv:2310.040272023arXiv preprint

S Feng, G Sun, N Lubis, C Zhang, M Gašić, arXiv:2309.12881Affect recognition in conversations using large language models. 2023arXiv preprint

Instructerc: Reforming emotion recognition in conversation with a retrieval multi-task llms framework. S Lei, G Dong, X Wang, K Wang, S Wang, arXiv:2309.119112023arXiv preprint

Emotion makes rumor viral? the effects of discrete emotions on rumor-mongering on social media during a social crisis. Y Wu, C Zou, L Wang, Z Pan, 2022WHICEB 2022 Proceedings

Reliance on emotion promotes belief in fake news. C Martel, G Pennycook, D G Rand, Cognitive research: principles and implications. 52020

That's interesting! the role of epistemic emotions and perceived credibility in the relation between prior beliefs and susceptibility to fake-news. A Rijo, S Waldzus, Computers in Human Behavior. 1411076192023

The application of emotions, sharing motivations, and psychological distance in examining the intention to share covid-19-related fake news. W.-K Tan, C Y Hsu, Online Information Review. 4712023

The effects of emotions, individual attitudes towards vaccination, and social endorsements on perceived fake news credibility and sharing motivations. K Ali, C Li, S A Muqtadir, Computers in human behavior. 1341073072022

Multi-emotion recognition using multi-emobert and emotion analysis in fake news. J Li, L Xiao, Proceedings of the 15th ACM Web Science Conference 2023. the 15th ACM Web Science Conference 20232023

Fake news, real emotions: Emotion analysis of covid-19 infodemic in weibo. M Wan, Y Zhong, X Gao, S Y M Lee, C.-R Huang, IEEE Transactions on Affective Computing. 2023

Do emotions determine rumors and impact the financial market? the case of demonetization in india. M Prabhala, I Bose, IEEE international conference on industrial engineering and engineering management (IEEM). IEEE2019. 2019

Anger can make fake news viral online. Y Chuai, J Zhao, Frontiers in Physics. 109701742022

Does fake news in different languages tell the same story? an analysis of multi-level thematic and emotional characteristics of news about covid-19. L Zhou, J Tao, D Zhang, Information Systems Frontiers. 2522023

Does fake news in different languages tell the same story? an analysis of multi-level thematic and emotional characteristics of news about covid-19. L Zhou, J Tao, D Zhang, Information Systems Frontiers. 2522023

Moral emotions shape the virality of covid-19 misinformation on social media. K Solovev, N Pröllochs, Proceedings of the ACM web conference 2022. the ACM web conference 20222022

The structural virality of online diffusion. S Goel, A Anderson, J Hofman, D J Watts, Management Science. 6212016

When falsehood wins? varied effects of sensational elements on users' engagement with real and fake posts. M Sui, I Hawkins, R Wang, Computers in Human Behavior. 1421076542023

Profiling fake news spreaders: Stylometry, personality, emotions and embeddings. E Fersini, J Armanini, M D'intorni, CLEF (Working Notes). 2020

CLEF2020, Clef2020 -checkthat! lab, in: CLEF. 2020

P Wang, H Shi, X Wu, L Jiao, Sentiment analysis of rumor spread amid covid-19: Based on weibo text. MDPI202191275

Exploration of online fake news through machine learning and sentiment analyses. N S Khan, F Molla, R S Khan, E H Shamim, S Hossain, M M Hasan, International Conference on Intelligent Computing & Optimization. Springer2022

Emotionally driven fake news in south africa. M Gagiano, V Marivate, EPiC Series in Computing. 932023

Fighting an infodemic: Covid-19 fake news dataset. P Patwa, S Sharma, S Pykl, V Guptha, G Kumari, M S Akhtar, A Ekbal, A Das, T Chakraborty, Combating Online Hostile Posts in Regional Languages during Emergency Situation: First International Workshop, CONSTRAINT 2021, Collocated with AAAI 2021, Virtual Event. SpringerFebruary 8, 2021. 20211

L Cui, D Lee, Coaid , arXiv:2006.00885Covid-19 healthcare misinformation dataset. 2020arXiv preprint

Explore covid-19 infodemic. S Li, Towards Data Science. 2020

Modified valence aware dictionary for sentiment reasoning classifier for detection and classification of covid-19 related rumors from social media data streams. S Arora, R Rani, N Saxena, Concurrency and Computation: Practice and Experience. 3421e71242022

PHEME dataset for Rumour Detection and Veracity Classification. E Kochkina, M Liakata, A Zubiaga, 10.6084/m9.figshare.6392078.v12018

Detect rumors in microblog posts using propagation structure via kernel learning. J Ma, W Gao, K.-F Wong, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 55th Annual Meeting of the Association for Computational Linguistics20171

Detecting rumors from microblogs with recurrent neural networks. J Ma, W Gao, P Mitra, S Kwon, B J Jansen, K.-F Wong, C Meeyoung, The 25th International Joint Conference on Artificial Intelligence, AAAI. 2016

Mdfend: Multi-domain fake news detection. Q Nan, J Cao, Y Zhu, Y Wang, J Li, Proceedings of the 30th ACM International Conference on Information & Knowledge Management. the 30th ACM International Conference on Information & Knowledge Management2021

Fakenewsnet: A data repository with news content, social context, and spatiotemporal information for studying fake news on social media. K Shu, D Mahudeswaran, S Wang, D Lee, H Liu, Big data. 832020

Fakeddit: A new multimodal benchmark dataset for fine-grained fake news detection. K Nakamura, S Levy, W Y Wang, Proceedings of the Twelfth Language Resources and Evaluation Conference. the Twelfth Language Resources and Evaluation Conference2020

Verifying multimedia use at mediaeval. C Boididou, S Papadopoulos, D T Dang Nguyen, G Boato, M Riegler, A Petlund, I Kompatsiaris, 2016. 2016

Automatic detection of fake news. V Pérez-Rosas, B Kleinberg, A Lefevre, R Mihalcea, Proceedings of the 27th International Conference on Computational Linguistics. the 27th International Conference on Computational Linguistics2018

Detecting opinion spams and fake news using text classification. H Ahmed, I Traore, S Saad, Security and Privacy. 11e92018

Detection of online fake news using n-gram analysis and machine learning techniques. H Ahmed, I Traore, S Saad, Intelligent, Secure, and Dependable Systems in Distributed and Cloud Environments: First International Conference, ISDDC 2017. Vancouver, BC, CanadaSpringerOctober 26-28, 2017. 20171

liar, liar pants on fire": A new benchmark dataset for fake news detection. W Y Wang, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaAssociation for Computational Linguistics20172Short Papers)

Where is your evidence: Improving fact-checking by justification modeling. T Alhindi, S Petridis, S Muresan, Proceedings of the first workshop on fact extraction and verification (FEVER). the first workshop on fact extraction and verification (FEVER)2018

T Mitra, E Gilbert, Credbank: A large-scale social media corpus with associated credibility annotations. 20159Proceedings of the international AAAI conference on web and social media

Kaggle, Getting real about fake news, in: kaggle. 2016

Fake news or truth? using satirical cues to detect potentially misleading news. V L Rubin, N Conroy, Y Chen, S Cornwell, Proceedings of the second workshop on computational approaches to deception detection. the second workshop on computational approaches to deception detection2016

Truth of varying shades: Analyzing language in fake news and political fact-checking. H Rashkin, E Choi, J Y Jang, S Volkova, Y Choi, Proceedings of the 2017 conference on empirical methods in natural language processing. the 2017 conference on empirical methods in natural language processing2017

Rumor detection over varying time windows. S Kwon, M Cha, K Jung, PloS one. 121e01683442017

Twitter rumour detection in the health domain. R Sicilia, S L Giudice, Y Pei, M Pechenizkiy, P Soda, Expert Systems with Applications. 1102018

Fakeflow: Fake news detection by modeling the flow of affective information. B Ghanem, S P Ponzetto, P Rosso, F Rangel, Proceedings of the 16th Conference of the European Chapter. the 16th Conference of the European ChapterMain Volume2021

A topic-agnostic approach for identifying fake news pages. S Castelo, T Almeida, A Elghafari, A Santos, K Pham, E Nakamura, J Freire, Companion proceedings of the 2019 World Wide Web conference. 2019

This just in: Fake news packs a lot in title, uses simpler, repetitive content in text body, more similar to satire than real news. B Horne, S Adali, Proceedings of the international AAAI conference on web and social media. the international AAAI conference on web and social media201711

Early multi-class ensemble-based fake news detection using content features. S Rezaei, M Kahani, B Behkamal, A Jalayer, Social Network Analysis and Mining. 131162022

Emotion cognizance improves health fake news identification. K Anoop, P Deepak, V Lajish, IDEAS. 2020242020

Combining conceptual graphs and sentiment analysis for fake news detection. W Cuenca, C González-Fernández, A Fernández-Isabel, I Martín De Diego, A G Martín, Computational Intelligence and Mathematics for Tackling Complex Problems. 22022Springer

Multifc: A real-world multi-domain dataset for evidence-based fact checking of claims. I Augenstein, C Lioma, D Wang, L C Lima, C Hansen, C Hansen, J G Simonsen, arXiv:1909.032422019arXiv preprint

Identifying multimodal misinformation leveraging novelty detection and emotion recognition. R Kumari, N Ashok, P K Agrawal, T Ghosal, A Ekbal, Journal of Intelligent Information Systems. 2023

Mmm: An emotion and novelty-aware approach for multilingual multimodal misinformation detection. V Gupta, R Kumari, N Ashok, T Ghosal, A Ekbal, Findings of the Association for Computational Linguistics: AACL-IJCNLP 2022. 2022

Multimodal fusion with recurrent neural networks for rumor detection on microblogs. Z Jin, J Cao, H Guo, Y Zhang, J Luo, Proceedings of the 25th ACM international conference on Multimedia. the 25th ACM international conference on Multimedia2017

C Guo, J Cao, X Zhang, K Shu, M Yu, arXiv:1903.01728Exploiting emotions for fake news detection on social media. 2019arXiv preprint

Sentiment gradient, an enhancement to the truth, lies and sarcasm detection. F C D Da Silva, Advances in Artificial Intelligence-IBERAMIA 2022: 17th Ibero-American Conference on AI, Cartagena de Indias. ColombiaSpringer NatureNovember 23-25, 2022. 202313788107

Fakenewssetgen: A process to build datasets that support comparison among fake news detection methods. F R M Da Silva, P M S Freire, M P De Souza, G De Ab Plenamente, R R Goldschmidt, Proceedings of the Brazilian Symposium on Multimedia and the Web. the Brazilian Symposium on Multimedia and the Web2020

R A Monteiro, R L Santos, T A Pardo, T A De Almeida, E E Ruiz, O A Vale, Contributions to the study of fake news in portuguese: New corpus and automatic detection results, in: Computational Processing of the Portuguese Language: 13th International Conference. Canela, BrazilSpringer2018. September 24-26. 2018. 201813

Overview of checkthat! 2020: Automatic identification and verification of claims in social media. A Barrón-Cedeno, T Elsayed, P Nakov, G Da San Martino, M Hasanain, R Suwaileh, F Haouari, N Babulkov, B Hamdan, A Nikolov, Experimental IR Meets Multilinguality, Multimodality, and Interaction: 11th International Conference of the CLEF Association. Thessaloniki, GreeceSpringerSeptember 22-25, 2020. 20202020

Joint rumour stance and veracity prediction. A E Lillie, E R Middelboe, L Derczynski, Nordic Conference of Computational Linguistics. Linköping University Electronic Press2019. 2019

Wsdm -fake news classification. J Bytedance Wsdm Cup, Qi, 2018Kaggle

G Gorrell, E Kochkina, M Liakata, A Aker, A Zubiaga, K Bontcheva, L Derczynski, Semeval-2019 task 7: Rumoureval 2019: Determining rumour veracity and support for rumours. Association for Computational Linguistics2019Proceedings of the 13th International Workshop on Semantic Evaluation: NAACL HLT 2019

Emergent: a novel data-set for stance classification. W Ferreira, A Vlachos, Proceedings of the 2016 conference of the North American chapter of the association for computational linguistics: Human language technologies, ACL. the 2016 conference of the North American chapter of the association for computational linguistics: Human language technologies, ACL2016

Fake news challenge. Delip Rao, Dean Pomerleau, J Qi, 2017

A stance data set on polarized conversations on twitter about the efficacy of hydroxychloroquine as a treatment for covid-19. E C Mutlu, T Oghaz, J Jasser, E Tutunculer, A Rajabi, A Tayebi, O Ozmen, I Garibay, Data in brief. 331064012020

Z Arkaitz, L Maria, P Rob, W S H Geraldine, T Peter, Pheme rumour scheme dataset: journalism use case. 2016130779128

M Lukasik, T Cohn, K Bontcheva, arXiv:1506.00468Classifying tweet level judgements of rumours in social media. 2015arXiv preprint

Determining the veracity of rumours on twitter. G Giasemidis, C Singleton, I Agrafiotis, J R Nurse, A Pilgrim, C Willis, D V Greetham, Social Informatics: 8th International Conference. SocInfo; Bellevue, WA, USASpringer2016. November 11-14, 2016. 2016Proceedings, Part I 8

Knowledge enhanced masked language model for stance detection. K Kawintiranon, L Singh, Proceedings of the 2021 conference of the north american chapter of the association for computational linguistics: human language technologies. the 2021 conference of the north american chapter of the association for computational linguistics: human language technologies2021

Classifying rumor stance in crisis-related social media messages. L Zeng, K Starbird, E Spiro, Unconfirmed, Proceedings of the international aaai conference on web and social media. the international aaai conference on web and social media201610

Same: sentiment-aware multi-modal embedding for detecting fake news. L Cui, S Wang, D Lee, Proceedings of the 2019 IEEE/ACM international conference on advances in social networks analysis and mining. the 2019 IEEE/ACM international conference on advances in social networks analysis and mining2019

Fake news detection using sentiment analysis. B Bhutani, N Rastogi, P Sehgal, A Purwar, 2019 twelfth international conference on contemporary computing (IC3). IEEE2019

Sentiment aware fake news detection on online social networks. O Ajao, D Bhowmik, S Zargari, ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE2019

Rumor events detection from chinese microblogs via sentiments enhancement. Z Wang, Y Guo, J Wang, Z Li, M Tang, IEEE Access. 72019

Rumor events detection enhanced by encoding sentimental information into time series division and word representations. Z Wang, Y Guo, Neurocomputing. 3972020

Rumor detection on hierarchical attention network with user and sentiment information. S Dong, Z Qian, P Li, X Zhu, Q Zhu, Natural Language Processing and Chinese Computing: 9th CCF International Conference. Zhengzhou, ChinaSpringerOctober 14-18, 2020. 20202020Proceedings, Part II 9

A linguistic-based method that combines polarity, emotion and grammatical characteristics to detect fake news in portuguese. M P De Souza, F R M Da Silva, P M S Freire, R R Goldschmidt, Proceedings of the Brazilian Symposium on Multimedia and the Web. the Brazilian Symposium on Multimedia and the Web2020

Fake news classification of social media through sentiment analysis. L Ding, L Ding, R O Sinnott, Big Data-BigData 2020: 9th International Conference, Held as Part of the Services Conference Federation. Honolulu, HI, USASpringerSeptember 18-20, 2020. 20202020

Evolutionteam at clef2020-checkthat! lab: Integration of linguistic and sentimental features in a fake news detection approach. I Touahri, A Mazroui, CLEF (Working Notes). 2020

Sentiment and retweet analysis of user response for early fake news detection. U Ezeakunne, S M Ho, X Liu, The International Conference on Social Computing, Behavioral-Cultural Modeling, & Prediction and Behavior Representation in Modeling and Simulation (SBP-BRiMS'20). 2020

A multitask learning approach for fake news detection: Novelty, emotion, and sentiment lend a helping hand. R Kumari, N Ashok, T Ghosal, A Ekbal, 2021 International Joint Conference on Neural Networks (IJCNN). IEEE2021

A sentiment-based multimodal method to detect fake news. I M L Maia, M P De Souza, F R M Da Silva, P M S Freire, R R Goldschmidt, Proceedings of the Brazilian Symposium on Multimedia and the Web. the Brazilian Symposium on Multimedia and the Web2021

Sentiment-aware fake news detection on social media with hypergraph attention networks. D Dong, F Lin, G Li, B Liu, 2022 IEEE International Conference on Systems, Man, and Cybernetics (SMC). IEEE2022

Automatic fake news detection: Are current models "fact-checking" or "gut-checking"?. I Kelk, B Basseri, W Lee, R Qiu, C Tanner, Proceedings of the Fifth Fact Extraction and VERification Workshop (FEVER). the Fifth Fact Extraction and VERification Workshop (FEVER)2022

Applying fuzzy logic and neural network in sentiment analysis for fake news detection: case of covid-19. B Mohamed, H Haytam, F Abdelhadi, Combating fake news with computational intelligence techniques. 2022

A graph-based approach leveraging posts and reactions for detecting rumors on online social media. A Haque, M Abulaish, Proceedings of the 36th Pacific Asia Conference on Language, Information and Computation. the 36th Pacific Asia Conference on Language, Information and Computation2022

Novel approaches to fake news and fake account detection in osns: user social engagement and visual content centric model. S K Uppada, K Manasa, B Vidhathri, R Harini, B Sivaselvan, Social Network Analysis and Mining. 121522022

An image and text-based multimodal model for detecting fake news in osn's. S K Uppada, P Patel, Journal of Intelligent Information Systems. 2022

What the fake? probing misinformation detection standing on the shoulder of novelty and emotion. R Kumari, N Ashok, T Ghosal, A Ekbal, Information Processing & Management. 5911027402022

Rumor detection based on the temporal sentiment. C Fu, K Chen, X Pan, S Yu, J Ni, Y Min, China National Conference on Big Data and Social Computing. Springer2022

A hybrid linguistic and knowledge-based analysis approach for fake news detection on social media. N Seddari, A Derhab, M Belaoued, W Halboob, J Al-Muhtadi, A Bouras, IEEE Access. 102022

Fake news detection in social media based on sentiment analysis using classifier techniques. S V Balshetwar, A Rs, 2023Multimedia Tools and Applications

Fake news detection model on social media by leveraging sentiment analysis of news content and emotion analysis of users' comments. S K Hamed, M J Aziz, M R Yaakub, Sensors. 23417482023

Q Guo, Z Kang, L Tian, Z Chen, arXiv:2304.09421Tiefake: Title-text similarity and emotion-aware fake news detection. 2023arXiv preprint

Unsupervised rumor detection based on propagation tree vae. L Fang, K Feng, K Zhao, A Hu, T Li, IEEE Transactions on Knowledge and Data Engineering. 2023

Do sentence-level sentiment interactions matter? sentiment mixed heterogeneous network for fake news detection. H Zhang, Z Li, S Liu, T Huang, Z Ni, J Zhang, Z Lv, IEEE Transactions on Computational Social Systems. 2023

Rumour identification on twitter as a function of novel textual and language-context features. G Ali, M S I Malik, Multimedia Tools and Applications. 8252023

Collaborative mixtureof-experts model for multi-domain fake news detection. J Zhao, Z Zhao, L Shi, Z Kuang, Y Liu, Electronics. 121634402023

Sentiment analysis-based social network rumor detection model with bi-directional graph convolutional networks. X Zhang, Y Pan, X Gu, G Liang, International Conference on Computer Application and Information Security (ICCAIS 2022). 202312609

Misinformation detection using an ensemble method with emphasis on sentiment and emotional analyses. S E V S Pillai, W.-C Hu, 2023 IEEE/ACIS 21st International Conference on Software Engineering Research, Management and Applications (SERA). IEEE2023

F Barbieri, J Camacho-Collados, L Neves, L Espinosa-Anke, arXiv:2010.12421Tweeteval: Unified benchmark and comparative evaluation for tweet classification. 2020arXiv preprint

Emotion-guided cross-domain fake news detection using adversarial domain adaptation. A Choudhry, I Khatri, A Chakraborty, D Vishwakarma, M Prasad, Proceedings of the 19th International Conference on Natural Language Processing. the 19th International Conference on Natural Language Processing2022

An emotion-guided approach to domain adaptive fake news detection using adversarial learning (student abstract). A Chakraborty, I Khatri, A Choudhry, P Gupta, D K Vishwakarma, M Prasad, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202337

Machine learning and deep learning: A review of methods and applications. K Sharifani, M Amini, World Information Technology and Engineering Journal. 10072023

Deep learning for fake news detection: Literature review. M H Al-Tai, B M Nema, A Al-Sherbaz, Al-Mustansiriyah Journal of Science. 3422023

Hierarchical attention networks for document classification. Z Yang, D Yang, C Dyer, X He, A Smola, E Hovy, Proceedings of the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies. the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies2016

Dynamic routing between capsules, Advances in neural information processing systems. S Sabour, N Frosst, G E Hinton, 201730

Goemotions: A dataset of fine-grained emotions. D Demszky, D Movshovitz-Attias, J Ko, A Cowen, G Nemade, S Ravi, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational Linguistics2020

Y Li, H Su, X Shen, W Li, Z Cao, S Niu, arXiv:1710.03957Dailydialog: A manually labelled multi-turn dialogue dataset. 2017arXiv preprint

Learning transferable visual models from natural language supervision. A Radford, J W Kim, C Hallacy, A Ramesh, G Goh, S Agarwal, G Sastry, A Askell, P Mishkin, J Clark, International conference on machine learning. PMLR2021

Word affect intensities. S M Mohammad, Proceedings of the 11th Edition of the Language Resources and Evaluation Conference (LREC-2018). the 11th Edition of the Language Resources and Evaluation Conference (LREC-2018)Miyazaki, Japan2018

Sentiwordnet: a high-coverage lexical resource for opinion mining. A Esuli, F Sebastiani, Evaluation. 171262007

S Zhang, L Wang, K Sun, X Xiao, arXiv:2009.00901A practical chinese dependency parser based on a large-scale dataset. 2020arXiv preprint

Constructing the affective lexicon ontology. L Xu, H Lin, Y Pan, H Ren, J Chen, Journal of the China society for scientific and technical information. 2722008

L Zadeh, M Gupta, R Ragade, R Yager, Advances in fuzzy set theory and applications, Gupta, M. 1979318

Emotion recognition on twitter: Comparative study and training a unison model. N Colnerič, J Demšar, IEEE transactions on affective computing. 1132018

Deep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2016

L H Li, M Yatskar, D Yin, C.-J Hsieh, K.-W Chang, arXiv:1908.03557Visualbert: A simple and performant baseline for vision and language. 2019arXiv preprint

Uwaterloo at semeval-2017 task 8: Detecting stance towards rumours with topic independent features. H Bahuleyan, O Vechtomova, Proceedings of the 11th international workshop on semantic evaluation. the 11th international workshop on semantic evaluation2017

Simple open stance classification for rumour analysis. A Aker, L Derczynski, K Bontcheva, 10.26615/978-954-452-049-6_005https://doi.org/10.26615/978-954-452-049-6_005Proceedings of the International Conference Recent Advances in Natural Language Processing. the International Conference Recent Advances in Natural Language ProcessingVarna, Bulgaria2017. 2017

O Enayet, S R El-Beltagy, Niletmrg at semeval-2017 task 8: Determining rumour and veracity support for rumours on twitter. SemEval-2017. 2017Proceedings of the 11th international workshop on semantic evaluation

Dfki-dkt at semeval-2017 task 8: Rumour detection and classification using cascading heuristics. A Srivastava, G Rehm, J M Schneider, Proceedings of the 11th International Workshop on Semantic Evaluation. the 11th International Workshop on Semantic EvaluationSemEval-2017. 2017

The fake news challenge: Stance detection using traditional machine learning approaches. R Masood, A Aker, 2018KMIS

Combining neural, statistical and external features for fake news stance identification. G Bhatt, A Sharma, S Sharma, A Nagpal, B Raman, A Mittal, Companion Proceedings of the The Web Conference. 2018. 2018

Andrejjan at semeval-2019 task 7: A fusion approach for exploring the key factors pertaining to rumour analysis. A Janchevski, S Gievska, Proceedings of the 13th International Workshop on Semantic Evaluation. the 13th International Workshop on Semantic Evaluation2019

Gwu nlp at semeval-2019 task 7: Hybrid pipeline for rumour veracity and stance classification on social media. S Hamidian, M Diab, Proceedings of the 13th international workshop on semantic evaluation. the 13th international workshop on semantic evaluation2019

E W Pamungkas, V Basile, V Patti, arXiv:1901.01911Stance classification for rumour analysis in twitter: Exploiting affective information and conversation structure. 2019arXiv preprint

A semisupervised approach to message stance classification. G Giasemidis, N Kaplis, I Agrafiotis, J R Nurce, IEEE Transactions on Knowledge and Data Engineering. 3212020

Datastories at semeval-2017 task 4: Deep lstm with attention for message-level and topicbased sentiment analysis. C Baziotis, N Pelekis, C Doulkeridis, Proceedings of the 11th international workshop on semantic evaluation. the 11th international workshop on semantic evaluationSemEval-2017. 2017

Dtca: Decision treebased co-attention networks for explainable claim verification. L Wu, Y Rao, Y Zhao, H Liang, A Nazir, arXiv:2004.134552020arXiv preprint

Deepnet: an efficient neural network for fake news detection using news-user engagements. R K Kaliyar, P Kumar, M Kumar, M Narkhede, S Namboodiri, S Mishra, 2020 5th International Conference on Computing, Communication and Security (ICCCS). IEEE2020

Gf-vae: a flow-based variational autoencoder for molecule generation. C Ma, X Zhang, Proceedings of the 30th ACM international conference on information & knowledge management. the 30th ACM international conference on information & knowledge management2021

Investigating siamese lstm networks for text categorization. C.-H Shih, B.-C Yan, S.-H Liu, B Chen, 2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC). IEEE2017

The biases of pre-trained language models: An empirical study on prompt-based sentiment analysis and emotion detection. R Mao, Q Liu, K He, W Li, E Cambria, IEEE Transactions on Affective Computing. 2022

eventai at semeval-2019 task 7: Rumor detection on social media by exploiting content, user credibility and propagation information. Q Li, Q Zhang, L Si, Proceedings of the 13th international workshop on semantic evaluation. the 13th international workshop on semantic evaluation2019

H Touvron, T Lavril, G Izacard, X Martinet, M.-A Lachaux, T Lacroix, B Rozière, N Goyal, E Hambro, F Azhar, arXiv:2302.13971Llama: Open and efficient foundation language models. 2023arXiv preprint

Multimodal fake news detection on social media: a survey of deep learning techniques. C Comito, L Caroprese, E Zumpano, Social Network Analysis and Mining. 1312023

H Liu, C Li, Q Wu, Y J Lee, arXiv:2304.08485Visual instruction tuning. 2023arXiv preprint

H Liu, C Li, Y Li, Y J Lee, arXiv:2310.03744Improved baselines with visual instruction tuning. 2023arXiv preprint

K Zheng, X He, X E Wang, arXiv:2310.02239Minigpt-5: Interleaved visionand-language generation via generative vokens. 2023arXiv preprint

Fakesv: A multimodal benchmark with rich social context for fake news detection on short video platforms. P Qi, Y Bu, J Cao, W Ji, R Shui, J Xiao, D Wang, T.-S Chua, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202337

Interpretable fake news detection with topic and deep variational models. M Hosseini, A J Sabet, S He, D Aguiar, Online Social Networks and Media. 361002492023

I-flash: Interpretable fake news detector using lime and shap. V Dua, A Rajpal, S Rajpal, M Agarwal, N Kumar, 2023Wireless Personal Communications

An interpretable fake news detection method based on commonsense knowledge graph. X Gao, W Chen, L Lu, Y Cui, X Dai, L Dai, K Wang, J Shen, Y Wang, S Wang, Applied Sciences. 131166802023

H Zhao, H Chen, F Yang, N Liu, H Deng, H Cai, S Wang, D Yin, M Du, arXiv:2309.01029Explainability for large language models: A survey. 2023arXiv preprint

K Yang, T Zhang, Z Kuang, Q Xie, S Ananiadou, arXiv:2309.13567Mentalllama: Interpretable mental health analysis on social media with large language models. 2023arXiv preprint

W X Zhao, K Zhou, J Li, T Tang, X Wang, Y Hou, Y Min, B Zhang, J Zhang, Z Dong, arXiv:2303.18223A survey of large language models. 2023arXiv preprint

Glove: Global vectors for word representation. J Pennington, R Socher, C D Manning, Proceedings of the 2014 conference on empirical methods in natural language processing. the 2014 conference on empirical methods in natural language processing2014

J Devlin, M.-W Chang, K Lee, K Toutanova, Bert , arXiv:1810.04805Pre-training of deep bidirectional transformers for language understanding. 2018arXiv preprint

Distributed representations of words and phrases and their compositionality. T Mikolov, I Sutskever, K Chen, G S Corrado, J Dean, Advances in neural information processing systems. 262013

T Mikolov, K Chen, G Corrado, J Dean, arXiv:1301.3781Efficient estimation of word representations in vector space. 2013arXiv preprint

Senticnet 7: A commonsense-based neurosymbolic ai framework for explainable sentiment analysis. E Cambria, Q Liu, S Decherchi, F Xing, K Kwok, Proceedings of the Thirteenth Language Resources and Evaluation Conference. the Thirteenth Language Resources and Evaluation Conference2022

Crowdsourcing a word-emotion association lexicon. S M Mohammad, P D Turney, Computational intelligence. 2932013

M Abdul-Mageed, C Zhang, A Hashemi, E M B Nagoudi, arXiv:1912.13072Aranet: A deep learning toolkit for arabic social media. 2019arXiv preprint

Camel tools: An open source python toolkit for arabic natural language processing. O Obeid, N Zalmout, S Khalifa, D Taji, M Oudah, B Alhafni, G Inoue, F Eryani, A Erdmann, N Habash, Proceedings of the Twelfth Language Resources and Evaluation Conference. the Twelfth Language Resources and Evaluation Conference2020

The development and psychometric properties of liwc2015. J W Pennebaker, R L Boyd, K Jordan, K Blackburn, Tech. rep. 2015

Vader: A parsimonious rule-based model for sentiment analysis of social media text. C Hutto, E Gilbert, Proceedings of the international AAAI conference on web and social media. the international AAAI conference on web and social media20148

F Å Nielsen, arXiv:1103.2903A new anew: Evaluation of a word list for sentiment analysis in microblogs. 2011arXiv preprint

Bandyopadhyay, Enhanced senticnet with affective labels for concept-based opinion mining. S Poria, A Gelbukh, A Hussain, N Howard, D Das, S , IEEE Intelligent Systems. 2822013

Hownet-a hybrid language and knowledge resource. Z Dong, Q Dong, International conference on natural language processing and knowledge engineering. IEEE2003. 2003. 2003

Sentisense: An easily scalable concept-based affective lexicon for sentiment analysis. J C De Albornoz, L Plaza, P Gervás, 2012LREC12

Affective norms for english words (anew): Instruction manual and affective ratings, Tech. rep., Technical report C-1, the center for research in psychophysiology. M M Bradley, P J Lang, 1999

Affectpt-br: an affective lexicon based on liwc. F Carvalho, G Santos, G P Guedes, 37th International Conference of the Chilean Computer Science Society (SCCC). IEEE2015. 2018. 2018

Opinion observer: analyzing and comparing opinions on the web. B Liu, M Hu, J Cheng, Proceedings of the 14th international conference on World Wide Web. the 14th international conference on World Wide Web2005

Neural check-worthiness ranking with weak supervision: Finding sentences for fact-checking. C Hansen, C Hansen, S Alstrup, J Simonsen, C Lioma, Companion proceedings of the 2019 world wide web conference. 2019

Empath: Understanding topic signals in large-scale text. E Fast, B Chen, M S Bernstein, Proceedings of the 2016 CHI conference on human factors in computing systems. the 2016 CHI conference on human factors in computing systems2016

+/-effectwordnet: Sense-level lexicon acquisition for opinion inference. Y Choi, J Wiebe, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing. the 2014 Conference on Empirical Methods in Natural Language Processing2014

Learning sentiment-specific word embedding for twitter sentiment classification. D Tang, F Wei, N Yang, M Zhou, T Liu, B Qin, Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics. Long Papers. the 52nd Annual Meeting of the Association for Computational Linguistics20141

S M Mohammad, S Kiritchenko, X Zhu, arXiv:1308.6242Nrc-canada: Building the state-of-the-art in sentiment analysis of tweets. 2013arXiv preprint

Recursive deep models for semantic compositionality over a sentiment treebank. R Socher, A Perelygin, J Wu, J Chuang, C D Manning, A Y Ng, C Potts, Proceedings of the 2013 conference on empirical methods in natural language processing. the 2013 conference on empirical methods in natural language processing2013

Using the revised dictionary of affect in language to quantify the emotional undertones of samples of natural language. C Whissell, Psychological reports. 10522009