# Automated classification of eclipsing binary systems in the VVV Survey

CorpusID: 255902114
 
tags: #Physics, #Computer_Science

URL: [https://www.semanticscholar.org/paper/83e03cfcd81401fcaef886da3ae39635cfcf9370](https://www.semanticscholar.org/paper/83e03cfcd81401fcaef886da3ae39635cfcf9370)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | False |
| By Annotator      | (Not Annotated) |

---

Automated classification of eclipsing binary systems in the VVV Survey
2023

I V Daza-Perilla 
Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET)
Godoy Cruz2290Ciudad Autónoma de Buenos AiresArgentina

Instituto de Astronomía Teórica y Experimental
CONICET-UNC
Argentina

Facultad de Matemática
AstronomíaFísica

L V Gramajo 
Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET)
Godoy Cruz2290Ciudad Autónoma de Buenos AiresArgentina

Observatorio Astronómico de Córdoba
UNC
Argentina

M Lares 
Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET)
Godoy Cruz2290Ciudad Autónoma de Buenos AiresArgentina

Instituto de Astronomía Teórica y Experimental
CONICET-UNC
Argentina

Observatorio Astronómico de Córdoba
UNC
Argentina

T Palma 
Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET)
Godoy Cruz2290Ciudad Autónoma de Buenos AiresArgentina

Observatorio Astronómico de Córdoba
UNC
Argentina

C E Ferreira Lopes 
Instituto de Astronomá y Ciencias Planetarias
Universidad de Atacama
Copayapu 485CopiapóChile

Universidade de São Paulo
IAG
Rua do Matão 1226

Cidade Universitária
05508-900São PauloBrazil

Millennium Institute of Astrophysics
Nuncio Monseñor Sotero Sanz 100, Of. 104Providencia, SantiagoChile

D Minniti 
Departamento de Ciencias Físicas
Facultad de Ciencias Exactas
Universidad Andrés Bello
Av. Fernandez Concha 700

Las Condes
Santiago

Vatican Observatory
V00120Vatican City StateItaly

J J Clariá 
Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET)
Godoy Cruz2290Ciudad Autónoma de Buenos AiresArgentina

Observatorio Astronómico de Córdoba
UNC
Argentina


Universidad Nacional de Córdoba (UNC)
Computación, CórdobaArgentina

Automated classification of eclipsing binary systems in the VVV Survey

MNRAS
0002023Accepted XXX. Received YYY; in original form ZZZPreprint 3 February 2023 Compiled using MNRAS L A T E X style file v3.0Infrared: stars -binaries: eclipsing -methods: data analysis -methods: statistical
With the advent of large-scale photometric surveys of the sky, modern science witnesses the dawn of big data astronomy, where automatic handling and discovery are paramount. In this context, classification tasks are among the key capabilities a data reduction pipeline must possess in order to compile reliable datasets, to accomplish data processing with an efficiency level impossible to achieve by means of detailed processing and human intervention. The VISTA Variables of the Vía Láctea Survey, in the southern part of the Galactic disc, comprises multi-epoch photometric data necessary for the potential discovery of variable objects, including eclipsing binary systems ( EBs). In this study we use a recently published catalogue of one hundred EBs, classified by fine-tuning theoretical models according to contact, detached or semi-detached classes belonging to the tile d040 of the VVV. We describe the method implemented to obtain a supervised machine learning model, capable of classifying EBs using information extracted from the light curves of variable object candidates in the phase space from tile d078. We also discuss the efficiency of the models, the relative importance of the features and the future prospects to construct an extensive database of EBs in the VVV survey.

# INTRODUCTION

The generation of time-domain data from surveys like VISTA (Visible and Infrared Survey Telescope for Astronomy) in the Vía Láctea (VVV, Minniti et al. 2010;Saito et al. 2012;Hempel et al. 2014), the VISTA Variables in the Vía Láctea eXtended Survey (VVVX, Minniti et al. 2018) and from future surveys like the Vera C. Rubin Observatory Legacy Survey of Space and Time (Rubin, Juric & Tyson 2015) and

The AURA the NASA Nancy Grace Roman Space Telescope-Rubin Synergy Working Group (AURA, Gezari et al. 2022) with nightly outputs ranging from 200 -300 GB to ∼ 15 TB, along with other surveys such as the Catalina Real-Time Transient Survey (CRTS, Drake et al. 2009), MA-CHO (Alcock et al. 1992(Alcock et al. , 1996, OGLE (Udalski et al. 1993) and ASAS (Pojmanski 2002), the Panoramic Survey Tele-E-mail: vanessa.daza@unc.edu.ar scope and Rapid Response System (Chambers et al. 2016, Pan-STARRS), a high-cadence All-sky Survey System (Tonry et al. 2018), Zwicky Transient Facility (Bellm et al. 2019) as well as the next generation of surveys like PLAnetary Transits and Oscillation of stars (Rauer et al. 2014) and Large Synoptic Survey Telescope (Ivezic et al. 2008) are examples of the exponential growth in astronomical data volumes (Szalay et al. 2002). This flood of information leads to the automation of data processing and analysis. The techniques involved in the search for patterns in large astronomical datasets are notably dominated by supervised and unsupervised machine learning tools (see, e.g., Baron 2019). In particular, it is usual to use information extracted from the time series data in machine learning models for the detection, analysis, and classification of short and long period variable sources (Mahabal et al. 2019;Webb et al. 2020). These tools often aim at reproducing the results obtained with human intervention and then extend those results to large datasets through models which make the whole process fast, reliable and statistically reproducible. Classical methods such as the "phase folding method" (PFM) and harmonic analysis (HA), among others, are implemented for the acquisition of the relevant information e.g., (Debosscher et al. 2007;Ferreira Lopes & Cross 2016. These methods allow the determination of the period and shape characteristics of the light curves (Lomb 1976;Scargle 1982;Lafler & Kinman 1965). Some works have combined the two mentioned methods to improve the computational efficiency and identification of variable stars (Saha & Vivas 2017). Indeed, ∼ 75 per cent of parameters used to characterize light curves shape are derived from the folded light curve using the period (Richards et al. 2011). Therefore, a combination of multiple period finding methods could potentially increase the recovery rate (Dubath et al. 2011;Ferreira Lopes et al. 2020). Generally, however, the works that use automatic learning models make a selection of the most informative features or else, in terms of information theory, the features chosen are the ones that have the highest entropy. The aim is to improve the performance of the model as shown by Hosenie et al. (2019) using the Survey CRTS for the classification of 11 variable star types, Richards et al. (2012) for the generation of a probabilistic classification catalogue of 28 ASAS classes and VIVACE, a catalogue of VVV variables in the bulge and disc containing hundreds of thousands of eclipsing binary systems (Molnar et al. 2021). These last three works are also examples of the wide spectrum of the different types of variable stars that can be classified and the challenges faced by automated methods, through which a high performance in the classification of subclasses of variable stars is hard to achieve.

The main aim of this work is to classify the subclasses of eclipsing binary systems (EBs). The identification of these systems is relevant since it allows to derive fundamental stellar dynamical information, as well as stellar parameters, including the masses and radii of the system components (Pietrzyński et al. 2010;Torres et al. 2010). EBs have also proven to be very useful in determining precise distances to nearby galaxies (e.g., Bonanos et al. 2006;North et al. 2010), improve astrophysical models (Carmo et al. 2020), as well as in tracing the Milky Way structure (Hełminiak et al. 2013). In addition, the precise measurements obtained from these systems allow us to perform tests of stellar theory in the Hertzsprung-Russell diagram (Alzate et al. 2021). In general, EBs are classified based on their Roche lobes into three subclasses, namely, detached (D), semi-detached (SD), and contact (C) systems. There is evidence that the performance of the EBs classification models improves when the best features of the light curves representing each class are used and when the number of examples in the training set is increased (Hosenie et al. 2019). However, this information is not conclusive enough for the classification of the SD type of EBs, since in general the number of SD EBs is small compared to the number of C and D systems found in the observations (Paczyński et al. 2006). Therefore, our motivation is not only to design an automatic algorithm that mimics human classification but also to perform this task with a high performance, reliable, reproducible and open procedure. For this purpose, we propose a classification model, which we refer to as a compound decision tree (CDT), built as an ensemble model of several supervised machine learning models with a voting system for the classification of the three types.

The CDT model is retrained with self-made classifications that were visually inspected. For the definition of the CDT model, one of the most important steps was the construction of the dataset to be used in the training of the models. To do so, we used an initial dataset with reliable information of the EBs, from which we generated representative features of the subclasses and from those we selected the most correlated features with each subclass. Our sample comprises one hundred EBs recently published by Gramajo et al. (2020b), including information on the time series, physical parameters and position of the systems. In addition to this initial dataset, we include information about the periods of each system provided by Ferreira Lopes et al. (2020). Then, using the feets package (Cabral et al. 2018), we extract features of the time series of each EB, such as slope and mean. And to this set of features, we add the magnitude difference between the primary and the secondary minima. Finally, we obtain different training sets for the CDT model. On the one hand, we vary the set of selected features and, on the other hand, the feature selection methods. This paper is organised as follows: In Section 2, we detail the data used for the construction of the initial dataset. In Section 3 we describe the individually implemented machine learning models used in the CDT model structure and we describe the methodology for the construction of the samples used in the training of the models including feature generation and feature selection methods, while we analyse and discuss the results in Section 4. The compound decision tree model is described in Section 5 and the model assessment reported in Section 6. Finally, in Section 7 we present the summary and main conclusions.


# DATA

As in any attempt at classification, the success in discerning between classes depends mostly on the quality and quantity of the available information, so in this section we describe in detail how we constructed the dataset of EBs . Obtaining an ensemble supervised model classifier requires, in particular, a labelled dataset including features that once combined in the model correlate with the labels. That is, a dataset with examples of each class but with information that is important for each supervised machine learning algorithm, since each model achieves a high performance depending on the number of examples of each class and on what features are entered into it.


## Samples

The ESO Public Survey VISTA Variables in the Via Lactea Survey 1 have been mapping the NIR variability (Ks passband) of the Milky Way bulge and the inner southern part of the Galactic disc. The VVV survey performed observations using five NIR passbands (Z, Y , J, H, and Ks) plus the variability campaign on the Ks passband over the period 2010-2017 (on average about 100 Ks epochs per field). CASU (Cambridge Astronomy Survey Unit) with the VIR-CAM pipeline v1.3 (Irwin et al. 2004;Emerson et al. 2004) 2 is used to produce the reduction and aperture photometry. The readers can find a detailed description of the VVV survey in many papers published in the last few years (e.g., Saito et al. 2012;Hempel et al. 2014;Catelan et al. 2014). In particular, this paper is the second of a series of studies about the EBs included in the VVV survey.

In the first paper of this series (Gramajo et al. 2020a), the VVV tile d040 (centred at RA2000 = 11 h 58 m 14.16 s , DEC2000 = −62 • 48 15.12 , corresponding to the Galactic coordinates: l = 296.8962 • , b = −0.5576 • ) was explored and approximately 1.6 × 10 6 sources were found, from which Gramajo et al. (2020a) pre−selected 3100 variable sources by means of the Stetson variability statistics (Stetson 1996). Then, they visually inspected these 3100 variable sources after the acquisition of the phase-folded light curves with their preliminary periods through the Generalised Lomb−Scargle and the Phase Dispersion Minimisation algorithms, respectively (Zechmeister & Kürster 2009;Stellingwerf 1978), and obtained a sample of 400 sources that were not spurious signals. Finally, they interactively redefined the periods to optimise the light curve fits by using a non-linear Fourier fit and obtaining average apparent magnitudes and total amplitudes in the Ks band. From a visual inspection of the phased light curves, a final sample of one hundred EBs was gathered, where 50 of them are detached, 13 are semi-detached and 37 are contact binaries. Gramajo et al. (2020b) determined the physical and geometrical parameters of the EB sample by means of the PHOEBE 1.0 code (Prša & Zwitter 2005), as a result of which the studied sample provides information on the effective temperatures of the two components (T1 and T2), the mass ratio (M2/M1), the orbital inclination (i) of the system, the orbital eccentricity value (e), the relative size of the two components (R1/R2) and the accuracy of the fit by the χ 2 value, which measures the discrepancy between the observational data and the adopted model used to determine the physical parameters.

In the cited catalogue, we included the periods provided by Ferreira Lopes et al. (2020) and selected those with values in the interval 0.4 − 15.2 days. This condition reduced the total number of systems to 96, which we now refer to as "initial D", whose classes are intrinsically unbalanced, with 49 Detached, 35 Contact and 12 Semi-Detached systems.

In Figure 1, we show the light curves measurements for each system, distinguished by class (systems D, SD and C in the left, middle and right panels, respectively).

The magnitudes of each light curve were scaled to [0, 1], the primary minima of each light curve being located at the phase equal to zero.

Finally, we use a second sample that is also found in the outermost region of the Galactic disc and in tile d078 centred on RA2000 = 12 h 00 m 07.584 s , DEC2000 = −61 • 44 3.84 , corresponding to the Galactic coordinates: l = 296.89636 • , b = 0.53458 • , where the initial sample contains 41,508 candidates. For this sample, we used the same condition for the periods as for tile d040.


# METHODS

Among the popular modern machine learning (ML) algorithms, different types are usually considered: supervised, unsupervised, semi-supervised and reinforcement learning models. For supervised models, the training data is used expecting an output, i.e., it is known in advance how it can be labelled or classified, while in unsupervised learning models the train-ing data is used without an expected output, i.e. no label is available. Semi-supervised learning models use both labelled and unlabelled train data, usually a small amount of labelled data together with a large amount of unlabelled data. Reinforcement learning models are used to determine what actions a software agent should choose in a given environment in order to maximise some notion of "reward" or accrued reward. We used supervised models in this work, since we wanted to solve a classification problem and we have labelled training sets. Specifically, we used five of the best known supervised learning models, both individually and in a combination of some of them to create a single model which we call the "compound decision tree model". There is a large amount of material explaining ML methods in detail. However, find below a description of each of the individual models:

Decision tree (DT): they are algorithms for classification using successive partitions. They are appropriate for large datasets; one their advantages is their descriptive character. This characteristic which allows us to easily understand and interpret the results obtained by the model. They select a variable from the dataset and then a specific value for this variable. This gives us a better classification of the data: the algorithms reveal complex shapes in the data structure that cannot be detected with conventional regression methods (Breiman et al. 2017).

Random forest (RF): random forests are a combination of tree predictors so that each tree depends on the values of a random vector independently sampled and with the same distribution. The parameters of a random forest are the variables and thresholds used to split each node learned during training .

As regards the generalisation error of the forests, it converges to a limit as the number of trees in the forest becomes large; this will be good when the model has learned the pattern between the input data and the results. Therefore, the model can be trusted to perform well with new data; at least as long as the new data come from a similar distribution. The generalisation error of a forest of tree classifiers depends on the strength of the individual trees in the forest and on the correlation between them (Breiman 2001).

K-nearest neighbour (KNN): the neighbours-based classification is a type of instance-based learning or non-generalizing learning: it does not attempt to construct a general internal model but simply stores instances of the training data. Classification is computed from a simple majority vote of the nearest neighbours of each point: a query point is assigned the data class which has the most representatives within the nearest neighbours of the point (Vaidya 1989).

Linear support vector classification (LSVC): given a set of training examples with each class marked as belonging to one of two categories, the support vector model performs a non-probabilistic linear binary classification. The classification by support vector assigns the examples in the training set to points in the space to maximise the width of the gap between the two categories, by defining a hyperplane that separates them. The new examples are then assigned a category according to which side of the separating hyperplane they are on (Cortes & Vapnik 1995).

Neural networks (NN): a standard neural network consists of many simple, connected processors, called neurons, each of which produces a sequence of real-valued activations. A NN contains an input layer, one or more hidden layers and an output layer. Each artificial neuron is connected to other neurons and has an associated weight and threshold.

Learning or weight assignment consists of finding the weights that cause the NN to exhibit the desired behaviour, such as driving a car. Depending on the problem and how the neurons are connected, such behaviour may require long causal chains of computational stages, with each stage often non-linearly transforming the output of the neurons (Schmidhuber 2015).


## Generation of features

The light curves of binary systems include information such as period, amplitude and shape that depend on the physical parameters and characteristics of the system. Then it should be possible, in principle, to distinguish the different EB types on the basis of the geometrical characteristics of the curves. Since this is not a physically motivated model, the properties of the system and their influence on the classification are introduced through the features of the training dataset. Therefore, extracting the information from these time series and selecting the most relevant ones generates a much more accurate model for classification.

To extract both statistical and shape features from the light curves (mean, scatter, slope, etc.), we used the feets code (Cabral et al. 2018). feets takes as input the magnitude, in our case the Ks magnitude, its error and the time (Julian Date). In addition, we calculated the difference in height ∆m between the primary minimum and the secondary one, and included the different periods provided by Ferreira Lopes et al. (2020). As a result, we obtained 64 features of the time series of each EB which, in addition to the periods, make a total of 69 features for the 96 sources. In Table 1, we show the 69 features differentiated in 5 types: the first one is related to the form or shape of the curve (F) and includes all the values obtained from the distribution of magnitudes. The "Frecuency type" (Fr) set of features contains values resulting from the modelling of the time series in frequency space. The time-related features (T) comprise all the periods that were provided and obtained through feets. The "statistics type" set (St) contains the statistical values of the flux distribution determined through the equation 1:
F = 10 −0.4 * mag
(1) and the last set of the table includes three values calculated from the structure function with variable equal to the magnitudes Ks as a function of time. It should be noted that it is in the training process that a selection of the most relevant features is made.


## Split and pre-processing

As a first step, we divided the labelled EB sample into two sets, comprising 80 per cent and 20 per cent of the total sample for train and test, respectively. In the training of the Random Forest and Neuronal Networks models, the set with 80 per cent of the total sample was taken and divided into two, one for the training of the parameters (training set) and the other for the choice of the hyperparameters (validation set). The sizes of the train and test sets for the initial D sample are shown in the first row of Table 2. We used the min-max scaling method for each of the features. The reason for this pre-processing is that many of the ML models use the distance between the points in the feature space and, if they are not scaled to the model, could perform poorly given the large variability of the feature distribution.

Out of the 69 features obtained, those with non-zero variance were taken, since constant values are not important in the training of ML models. Therefore, the feature set was reduced to 64, discarding three components of the Fourier decomposition: Fr1 harmonics φ0, Fr2 harmonics φ0, Fr3 harmonics φ0 and two parameters which provide a natural and consistent way of estimating a time scale through a continuous time auto regressive model applied to time series, CAR tau and CAR sigma (Brockwell & Davis 2002).


## Selection of Features

Taking into account that we aimed at reaching a predictive classification modelling problem with numerical input and categorical output variables and that the performance of supervised ML models depends on the number and selection of the features, we conducted an univariate analysis study, which consists of estimating the importance of each attribute individually along with the class of the attribute. In particular, we used the correlation techniques between the input variables and the target recommended by Brownlee (2020) for this type of classification problems: ANOVA, mutual information (MI ) and χ 2 . With each technique, we will generate a list of scores for each feature, which depends on the correlation that each technique finds between the feature and the class. Therefore, the features with low entropy for the classification of EBs will occupy the lowest places in the ranked list of features of each method. Consequently, to determine in the initial D the number of features and to select the subset of features, we observed the performance obtained by the ML models, when using all features and when selecting feature sets consisting of the first 10, 35 and 50 features resulting from the ANOVA, MI and χ 2 techniques, respectively. Thus, we could study the impact on model performance when using a small sample, half, or almost all the features of the initial set.


## Balance of classes

In general, training ML models with imbalanced samples in classes affects classification, since having many examples of a particular class means that the models learn to classify that class very well and not the minority ones (Mao & Wang 2012). Therefore, we included balanced sets in our study. The choice of how to balance the data depends on the classification problem, on the number of examples of each class and on the model. Thus, in order to build a balanced sample, we implemented two methodologies on the training set. The first method is SMOTETomek, which consists of combining oversampling in the minority class (in our case, the C and SD classes) and undersampling the majority class (D class). This method uses two separate techniques: SMOTE (Synthetic Minority Over-sampling Technique, Chawla et al. (2002)) and Tomek links Tomek I (1976). SMOTE performs the oversampling by creating "synthetic" examples in the "feature space". Minority classes are oversampled by taking each sample of the minority class and introducing synthetic examples along the line segments joining any/all k nearest neighbours of the minority class. The other technique is Tomek, originally proposed by Tomek I (1976). It consists of a one-on-one scheme, which generates samples from a given dataset that preserves or improves the performance that would be obtained with the initial D. Therefore, if we implement this method in case of having two imbalanced classes, the number of examples of the majority class decreases a little and the number of examples of the minority class increases until it reaches the same number as the class that previously had the highest number of examples. The second method is RandomOverSampler, a.k.a. Random Over-Sampling Examples : (ROSE, Menardi & Torelli 2014). This procedure only oversamples the minority class by randomly choosing samples through smoothed bootstrap. The reason for generating samples using different methods to remove the imbalance lies in the fact that the distribution of features in each sample will be different, which affects the performance of the models.


## Hyperparameters

The hyperparameters of a model are the values of the configurations used during the training process and depend on each particular model. Those values are not generally obtained from the data and therefore usually provided by the data scientist. Hyperparameter tuning relies more on experimental results than on theory, so the best method to determine the optimal settings is to try many different combinations and evaluate the performance of each model. However, evaluating each model only on the training set can lead to overfitting, which is one of the most fundamental problems in ML. Therefore, to avoid overfitting, we used cross-validation, in particular the K-fold cross-validation method that divides our training set into a number of K subsets, called folds. We then iteratively fit the model K times, each time training the data on K-1 of the folds and evaluating on the K-th fold (called validation data). At the very end of training , we averaged the performance on each of the folds to come up with final validation metrics for the model. For hyperparameter tuning, we performed many iterations of the entire K-fold cross validation process, each time using different model settings. We then compared all the models, selected the best one, trained it on the full training set and then evaluated it on the test set.


## Metrics

Since in our study we used balanced and imbalanced datasets that present an inherent imbalance in classes, we preserved in the procedure that imbalance in the development and evaluation. For that reason, in our selection of metrics, we included as a decisive metric the micro average of the F1-value (F 1mic), which does take into account the mentioned class imbalance, in addition to the precision (P), recall (R), F1score (F1) and support (S) metrics and also the confusion matrices.


## Workflow

Taking into account the methodology described in this section, we generated a workflow to determine the best model. Firstly, we took the training set and generated the features for each EB. Then, we used a feature selection method and took some or all of the most important features. Next, we used the imbalanced or balanced set. After that, we trained the models with the constructed set and compared the performance on the validation set. This process was carried out with all combinations of features and balanced or imbalanced sets. Finally, we compared the performances and chose the best model. A schematic of the process is presented in Figure 2.


# RESULTS

Based on the methodology described in Section 3, we generated the features of the light curves and took the cured train dataset, i.e., the dataset with 64 features scaled between [0, 1] without the 5 features with variance equal to zero. The resulting dimensions of the training and test sets are shown in the second row of Table 2. With the training set and the DT, RF, KNN and LSVC models, we searched for the features that give the best performance. To this aim, we ran several experiments combining the different models with different inputs and used the curated dataset of 64 features, the dataset with some periods, and datasets of 10, 35 and 50 features with the highest scores according to ANOVA, MI and χ 2 techniques. Although the performance of the ML models depends on the features that enter the model (in this case the features that are extracted from the light curves), here the performance of the models with different features varied in most cases by hundredths and in very few cases by tenths, mainly because the feature sets generated by the three feature selection techniques have similar results in the score of the most important features for the classification of EBs . For the three feature selection techniques, 24 out of 35 and 8 out of 10 features with the highest performance match one another in the three methods. Figure 3 compares the scores of the 24 features that the three methods have in common. In particular, the first features are "form" and "statistical" measures extracted from the light curve. One of the features we found most relevant in the 3 methods is MedianBRP, as shown in Figure 4 for two light curves of C and D EBs . This one is related to the shape of the curve and indicates the fraction (<= 1) of photometric points within the amplitude/10 of the median magnitude. The light curve of contact binary at maxima have usually more points if compared to the detached EBs curves because there is a higher probability of finding more measurements of this type of binary system when their system components are overlapping, since the times of this event are shorter compared those of D EBs . On average for our training set, we conclude that the median value of this measurement for types C, D and SD EBs is 0.61, 0.28 and 0.52, respectively. Another form feature we found important was Beyond1Std, which constitutes the percentage of points beyond one standard deviation from the weighted mean. It gives a measure of the number of observations at the extremes of the photometric point distribution. This fact is good for distinguishing the D EBs from the other classes, since at the extremes of the magnitude distribution the D EBs show a larger fraction of points. This is due to the fact that they have the contribution of two minima, while the SD and C EBs receive, in general terms, the contribution of a single minimum. Regarding the statistical features, we noticed that some percentile of fluxes are significant for the distribution between the classes, such as Flux Percentile 20 and Flux Percentile 35, values calculated from the percentiles F5,95, which is the difference between 95th and 5th percentiles, so Flux Percentile 20 is F40,60/F5,95 and Flux Percentile 35 is F32.5,67.5/F5,95. These values in the training set distinguish well between EBs classes C and D, since the values for the SD class of EBs are more similar to class C, as shown in Table 3, where the mean of each of these features for the three EBs classes is displayed. However, we found that not all features of C and SD are similar to each other, in particular the LS  period (Lomb Scargle period) of SD EBs whose values are more similar to the D EBs class (see Table 3). Although it is not the most correlated feature with the classes for any of the three methods, it is important to keep it in the input of the models as combining it with the more informative features will help to distinguish between the C and DS of EBs classes. Our analysis shows that the set with the highest importance is practically the same for the three feature selection methods, so we can fix one of these methods and take a smaller set of features that is reliable at learning any supervised learning model. Therefore, we chose the MI method to select the 35 most informative features for classification to build the classifier model, marked in bold in Table 1. In addition, the analysis also showed that the set of 35 features chosen is good for classifying between classes C and D but not good enough for classifying SD EBs . This problem generally arises in the classification of EBs given the small number of examples we have of this type of EBs and the similar features that SD has with C and D EBs . We understand then that the model must be prepared to receive an imbalanced input with SD as the minority class. It is therefore important to take into account in the training that the model needs to input a good number of examples of each class so that it does not learn to predict only the class with more examples. We also analysed how the performance of the models behaves when inputting the imbalanced and balanced training sets with the SMOTETomek and RandomOverSample methods. As a result, the performance using these three training sets does not vary significantly so we decided to use all three sets in the classifier training .

As regards the choice of the best classifier model, we found that the performance variations among the base models is small, regardless of introducing different sets of features, with different class balance strategies and with a variation in some hyperparameters. For example, we considered as variables the number of layers of the NN or the depth of the trees in the RF model. Then the choice of the model is not straightforward, even more so when none of the models achieves a high performance in the classification of the SDs. Figure 5 shows the performance of two of the models that tend to have high performance given that they have more parameters than the other models, RF and NN, in the test set with 2 SDs.


# COMPOUND DECISION TREE (CDT)

The performance in classifying the SD EBs of each model with different inputs has not been high compared to the classification of D and C EBs. However, we observed that in some experiments the models classified the SDs asynchronously, i.e., in some cases an SD EB is classified by one or several models but not by all the others. Since there are cases where the features of the SD EBs can be very similar to the C EBs and there are other cases where they can be very similar to the D EBs , we decided to make a model composed of different models with a voting system, which we called Compound Decision Tree (CDT). This model is mainly composed of three models ones, M1, M2 and M3, following an ordering of execu- tion and meeting some requirements. The CDT is structured as follows: when a data x is entered, the first model to be used model is M1, which classifies between class D and C of EBs .
0.0 0.1 0.2 0.3 IM Score Fr9 Fr4 F25 F24 S6 Fr20 Fr17 Fr18 F7 S5 F9 Fr2 Fr7 Fr3 S3 F8 F5 F2 S2 F3 F4 F1 S4 S1
The next step depends on the classification resulting from M1: if the classification is x = D, then x enters model M2, which classifies between class D and SD. Otherwise, if x = C, then x enters model M3 and x is classified into C or SD. Each Mi model uses 4 algorithms, KNN, DT, RF and SVML, which were trained on 3 EBs samples with D, SD and C classes. The first sample, s1, has the natural imbalance of EBs , i.e., a higher number of D class EBs , followed by C class EBs and a very small number of SD class EBs . Sample s2 is sample s1 with increased data from the minority class, i.e. class SD and sample s3 is sample s1 with a decrease of examples from classes D and an increase of class C and SD. Therefore, each Mi model is formed by 4 algorithms trained with the different samples s1, s2 and s3, which leaves a total of 12 sub-models since the parameters of each algorithm change when different samples are used in the training . These Mi models consisting of 12 sub-models perform classifications between two classes, e.g., M1 classifies between C and D, it will be C if the majority of the sub-models had this result, otherwise the classification will be D and the majority of the sub-models will have classified the input as C. If the classification or vote of the sub-models gives a tie in the M1 model, the EB will be discarded. In the case of a tie vote in the M2 or M3 models, the EB class will be D or C, respectively. The model was tested on the same test set as the individual models and is not outperforming (see Figure 6).


# ASSESSMENT AND IMPROVEMENT OF MODELS FOR AUTOMATIC CLASSIFICATION

The results strongly depend on the quality of the dataset, the number of examples of each class of EBs and the size of the set. To study the impact on performance according to these variables, we took the 96 EBs and generated 4 subsamples of 24 elements , 20 EBs are used as training set and 4 as test set.

With each sample, we observed how the results vary when the training samples have one element removed to reach a set of 6 elements. Figure 7 shows the results with one of the four samples: this particular sample has in the test set all three classes of EBs .

Here it can be observed that despite having a small number of elements in the training sample, not all models perform poorly. Likewise, we find that although some models have almost the entire training set, they can perform at zero. This is the case when the training set has very few examples of a class and many in the test set. Therefore and in order to have higher reliability in classifying EBs automatically on any VVV tile, we start from a time series set of 41508 variable objects on tile d078 to classify them into D, SD and C EBs through the RF, NN and CDT models. The information of the new candidates EBs to be classified must follow the same process as the dataset used to train the model. So from the time series of each EB we obtained by means of feets the 35 features with high entropy according to the MI method. This step reduced the number of objects to 38538, as feets only accepts time series with more than 20 data.

We then classified 58 EBs from the set of 38538 variable  objects and compared these classifications with the automatic classifications, the number of hits for RF was 14, NN 1 hit and the CTD model got 32 hits. Subsequently, we included the 58 EBs to the set of 96, leaving a total of 154 EBs whose class balance is shown in Table 4. The 58 EBs were included in the training set and the models were run again, the evaluation of which on the test set results in an improvement of the classification of the SD EBs (see Figure 8). Then, 64 EBs from the set of variable objects were again classified by visual inspection and compared with the classification of the new models . In this case, the number of hits for the RF and NN models was quite low, while CDT had 54 hits, i.e. approximately 80 per cent of the 64 EBs classified by visual inspection. The class balance of the 64 EBs plus the 134 EBs is shown in Table 4, while the three light curves of D, SD and C type EBs are displayed in Figure 9.

According to these results, we concluded that the most reliable model is the CDT trained with the 96 EBs from the Gramajo et al. (2020a) catalogue plus the 198 EBs obtained in this work, which have 35 features of the light curves selected by the MI method and generated with feets.   Figure 9. The light curves of the three EBs wherein the primary minimum is located at zero. In the top panel, we show the light curve of a D-type EB . In the middle and bottom panels, we show the light curves of SD and C-type EBs , respectively.


# CONCLUSIONS

We developed a supervised ML model for the classification of EBs into detached, semi-detached and contact classes in the VVV data. The construction of the model was made based on a catalogue of 100 EBs determined in the VVV and classified object-by-object through the light curves using the phoebe software, plus periods determined by applying different methods, the generation of light curve features of each class through feets and the calculation of the magnitude difference between the primary and secondary maxima of the light curves.

By implementing statistical methods, we found that some components of the Fourier decomposition and parameters for estimating time scales are much less important in determining the classes of EBs. Moreover, the combination of different sets of features selected according to their high entropy in relation to the classification reveals that only 35 features of shape, statistics and the LS period with which the systems were determined are sufficient to obtain a good performance in the classification of the EBs of the VVV study. This is due to the fact that they have well differentiated distributions for the D and C classes. We also found that the distributions of the SDs are similar to those of the C systems for the most part but some features of the SD light curves are similar to those characterising the light curves of the D-type EBs.

This set of features performs well for the usual supervised ML models with an imbalanced dataset, i.e., a higher number of examples of D-type EBs compared to the number of examples of C-type EBs and the minority class SD. An equal performance can be obtained with balanced datasets with increased minority classes, C and SD, as well as datasets with increased minority classes and a small decrease in class D.

Usually the classification performance of variable stars, particularly EBs, in a VVV tile has good performance with supervised learning models. In our study, that performance can be achieved with approximately one hundred EBs, a small number of examples and the selection of the number of examples and features that enter the ML models. However, on examining the results, we found that this good performance is due to the good classification in the D and C classes but not so in the SD class.

In order to achieve a good performance in the classification of the three EBs classes, we developed a Compound Decision Tree (CDT) model, based on an algorithm that combines four supervised learning models with a voting system for EBs classification. CDT starts by classifying classes C and D. If the classification is D, then the input will be classified into D and SD and if the classification is C, the input will be classified into C and SD. This model improved the classification performance of the D and C EBs in the test set and therefore lowers the probability of misclassification for SD-type EBs in this set.

When we used CDT for the classification of a new sample of EBs in the d078 tile without examples of the systems in this tile in the model training and compared the results with visually made classifications of 58 EBs, CDT scores 32 hits outperforming models such as RF or NN. Subsequently, including the 58 EBs in the training set leads to an improvement in the classification of the SD-type EBs, compared to a new one of 64 visually inspected systems. The CDT model obtains approximately 80 per cent of the visually performed classification, outperforming by far each of the ML models that comprise it. Therefore, to classify EBs, our CDT model needs few features of the light curves. Thus, the classification of EBs in a new tile with CDT outperforms ML models such as NNs or RFs. The classification performance of EBs is not only good for C-and D-type EBs but also for SD-type EBs, which are generally not well classified by supervised ML models dedicated to variable source classification. Moreover, the CDT model is able to generate EB catalogues in another VVV mosaic with a reliability of about 80 per cent. Its performance improves rapidly as soon as a few EB examples are added to the mosaic to be classified.

## Figure 1 .
1Composite EB light curves, separated by class, which are scaled from 0 to 1 and with the primary minimum located at zero. These composite light curves are made using the individual measurements of 49 Detached systems (left panel), 12 Semi-Detached systems (middle panel), and 35 Contact systems (right panel).

## Figure 2 .
2Schematic of the process to determine the best model for EBs classification. classification. The generation of different training sets is shown inside the box. A training set is constructed through the choice of one of the feature selection methods: ANOVA, MI and χ 2 , the number of features and one of the balancing methods: SMOTETomek and Tomek. The red line indicates one of these combinations. The evaluation and improvement of the model using a new dataset is schematised outside the table.

## Figure 3 .Figure 4 .
34Bar chart of the scores of the 24 most correlated features with the classes calculated from the features selection, Mutual Information (MI), ANOVA and χ 2 methods. Results obtained by applying the methods on the train sample with D, C and SD classes. Light curves together with the Ks magnitude distribution of two EBs. Contact in the upper panel and detached type in the lower one. The violet band shows the values used to determine MedianBRP. The solid and dashed lines indicate the median and mean, respectively.

## Figure 5 .
5Confusion matrix visualisation of the performance. The cells indicate the fraction of elements in rows that are classified with the labels in the columns, so that the elements in the diagonal are correctly classified. Left panel: performance of the RF model. Right panel: performance of the NN model.

## Figure 6 .
6Confusion matrix visualisation of the performance in the model CDT. The cells indicate the fraction of elements in rows that are classified with the labels in the columns, so that the elements in the diagonal are correctly classified.

## Figure 8 .
8Confusion matrix visualisation of the performance of the test set with a training set of 134 EBs. The cells indicate the fraction of elements in rows that are classified with the labels in the columns, so that the elements in the diagonal are correctly classified. Left upper panel: performance of the RF model. Right upper panel: performance of the NN model. Lower panel: performance of the CDT model.

## Table 1 .
1Initial set of form, statistical, frequency, temporal and physical features of the light curves of the 96 EBs . Most of these features were obtained with feets. The rest corresponds to the different periods and to the difference in amplitude between the minima of the light curve (∆m). In bold the most important features according to the MI method.Table 2. In the development of the classifiers, initial D is divided into two sets (train and test) for model training , hyperparameter selection and model testing, respectively. The tuples in each field of the table indicate the number of EBs in each set in the first component of the tuple. In the second component of the tuple, the number of features describing each EB is indicated. The first row shows the dimensions of the initial data, while the second row displays the dimensions of the curated and pre-processed data.Features 



## Table 3 .
3Mean values of the five important features for the three feature selection methods in the training set.Features 
D 
C 
SD 

Median BRP 
0.29 ± 0.10 0.58 ± 0.15 0.50 ± 0.13 
Beyond 1Std 
0.31 ± 0.07 0.20 ± 0.05 0.20 ± 0.05 
Flux Percentile 20 0.22 ± 0.07 0.09 ± 0.07 0.11 ± 0.05 
Flux Percentile 35 0.39 ± 0.09 0.20 ± 0.13 0.21 ± 0.06 
Period LS 
1.08 ± 1.76 2.06 ± 2.62 0.89 ± 0.04 



## Table 4 .
4Figure 7. The first row shows the balance of the EB classes in the training and test sets. The second and third rows correspond to the performance achieved by the models when the number of members in the training sample is varied. Balance of the EBs classes. The second column presents the balance of the 96 EBs, the third the balance of 58 EBs classes and the fourth shows the balance of the last visually classified dataset with 64 EBs.Test set 




Period = 0.93 [d] 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2.00 Period = 16.99 [d]Phase 

15.1 

15.2 

15.3 

15.4 

15.5 

15.6 

Magnitude K 

s 

VVV-515881838312 (SD) 

Period = 2.47 [d] 

0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2.00 

Phase 

12.70 

12.75 

12.80 

12.85 

12.90 

12.95 

Magnitude K 

s 

VVV-515881850183 (C) 


MNRAS 000, 1-12(2023)
ACKNOWLEDGEMENTSThis work was partially supported by the Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET, Argentina) and the Secretaría de Ciencia y Técnica, Universidad Nacional de Córdoba, Argentina. + VVV DATA. This research has made use of NASA's Astrophysics Data System.We gratefully acknowledge the use of data from the ESO Public Survey program IDs 179. B-2002 and 198.B-2004  taken with the VISTA telescope and data products from the Cambridge Astronomical Survey Unit. D.M. gratefully acknowledges support by the ANID BASAL projects ACE210002 and  FB210003, and Fondecyt Project No. 1220724.DATA AVAILABILITYThe data underlying in this article are available on request to the corresponding author.This paper has been typeset from a T E X/L A T E X file prepared by the author.
C Alcock, Astronomical Society of the Pacific Conference Series. Filippenko A. V.103Robotic Telescopes in the 1990sAlcock C., et al., 1992, in Filippenko A. V., ed., Astronomical So- ciety of the Pacific Conference Series, Vol. 103, Robotic Tele- scopes in the 1990s. pp 193-202

. C Alcock, 10.1086/177039ApJ. 46184Alcock C., et al., 1996, ApJ, 461, 84

. J A Alzate, G Bruzual, D J Díaz-González, 10.1093/mnras/staa3576MNRAS. 501302Alzate J. A., Bruzual G., Díaz-González D. J., 2021, MNRAS, 501, 302

. D Baron, arXiv:1904.07248Baron D., 2019, arXiv e-prints, p. arXiv:1904.07248

. E C Bellm, 10.1088/1538-3873/aaecbePASP. 13118002Bellm E. C., et al., 2019, PASP, 131, 018002

. A Z Bonanos, 10.1086/508140ApJ. 652313Bonanos A. Z., et al., 2006, ApJ, 652, 313

L Breiman, 10.1023/A:1010933404324Machine Learning. 455Breiman L., 2001, Machine Learning, 45, 5

. L Breiman, J H Friedman, R A Olshen, C J Stone, 10.1201/9781315139470Classification And Regression Trees. Routledge. Breiman L., Friedman J. H., Olshen R. A., Stone C. J., 2017, Classification And Regression Trees. Routledge, doi:10.1201/9781315139470

Introduction to Time Series and Forecasting. P J Brockwell, R A Davis, 10.1007/b97391SpringerNew York, New York, NYBrockwell P. J. ., Davis R. A., 2002, Introduction to Time Se- ries and Forecasting. Springer New York, New York, NY, doi:10.1007/b97391

Data Preparation for Machine Learning: Data Cleaning, Feature Selection, and Data Transforms in Python. J Brownlee, Brownlee J., 2020, Data Preparation for Machine Learn- ing: Data Cleaning, Feature Selection, and Data Trans- forms in Python. -, https://machinelearningmastery.com/ data-preparation-for-machine-learning/

. J B Cabral, B Sánchez, F Ramos, S Gurovich, P Granitto, 10.1016/j.ascom.2018.09.005Astronomy and Computing. 25213Vanderplas J.Cabral J. B., Sánchez B., Ramos F., Gurovich S., Granitto P., Vanderplas J., 2018, Astronomy and Computing, 25, 213

A Carmo, C E Ferreira Lopes, A Papageorgiou, F J Jablonski, C V Rodrigues, A J Drake, N J Cross, M Catelan, 10.1093/mnras/staa25182020, Recovering variable stars in large surveys: EAupAlgol-type class in the Catalina Survey. Carmo A., Ferreira Lopes C. E., Papageorgiou A., Jablonski F. J., Rodrigues C. V., Drake A. J., Cross N. J., Catelan M., 2020, Recovering variable stars in large surveys: EAupAlgol-type class in the Catalina Survey, doi:10.1093/mnras/staa2518

M Catelan, 10.1017/S1743921313014725Precision Asteroseismology. Guzik J. A., Chaplin W. J., Handler G., Pigulski A.301Precision AsteroseismologyCatelan M., et al., 2014, in Guzik J. A., Chaplin W. J., Handler G., Pigulski A., eds, Precision Asteroseismol- ogy Vol. 301, Precision Asteroseismology. pp 395-396, doi:10.1017/S1743921313014725

. K C Chambers, arXiv:1612.05560arXiv e-printsChambers K. C., et al., 2016, arXiv e-prints, p. arXiv:1612.05560

. N V Chawla, K W Bowyer, L O Hall, W P Kegelmeyer, 10.1613/jair.953Journal of Artificial Intelligence Research. 16Chawla N. V., Bowyer K. W., Hall L. O., Kegelmeyer W. P., 2002, Journal of Artificial Intelligence Research, 16

C Cortes, V Vapnik, 10.1023/A:1022627411411Machine Learning. 20Cortes C., Vapnik V., 1995, Machine Learning, 20

. J Debosscher, L M Sarro, C Aerts, J Cuypers, B Vandenbussche, R Garrido, E Solano, 10.1051/0004-6361:20077638A&A. 4751159Debosscher J., Sarro L. M., Aerts C., Cuypers J., Vandenbussche B., Garrido R., Solano E., 2007, A&A, 475, 1159

. A J Drake, 10.1088/0004-637x/696/1/870ApJ. 696870Drake A. J., et al., 2009, ApJ, 696, 870

. P Dubath, 10.1111/j.1365-2966.2011.18575.xMNRAS. 4142602Dubath P., et al., 2011, MNRAS, 414, 2602

Optimizing Scientific Return for Astronomy through Information Technologies. J P Emerson, 10.1117/12.551582Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series. Quinn P. J., Bridger A.5493410Emerson J. P., et al., 2004, in Quinn P. J., Bridger A., eds, Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series Vol. 5493, Optimizing Scientific Return for Astronomy through Information Technologies. pp 401-410, doi:10.1117/12.551582

. Ferreira Lopes, C E Cross, N J G , 10.1051/0004-6361/201526733A&A. 58636Ferreira Lopes C. E., Cross N. J. G., 2016, A&A, 586, A36

. Ferreira Lopes, C E Cross, N J , 10.1051/0004-6361/201630109A&A. 604121Ferreira Lopes C. E., Cross N. J. G., 2017, A&A, 604, A121

. Ferreira Lopes, C E , 10.1093/mnras/staa1352MNRAS. 4961730Ferreira Lopes C. E., et al., 2020, MNRAS, 496, 1730

. S Gezari, arXiv:2202.12311arXiv e-printsGezari S., et al., 2022, arXiv e-prints, p. arXiv:2202.12311

L V Gramajo, T Palma, D Minniti, R K Saito, J J Clariá, R Kammers, F Surot, 10.1017/pasa.2020.44A hundred new eclipsing binary system candidates studied in a near-infrared window in the VVV survey. Gramajo L. V., Palma T., Minniti D., Saito R. K., Clariá J. J., Kammers R., Surot F., 2020a, A hundred new eclipsing binary system candidates studied in a near-infrared window in the VVV survey, doi:10.1017/pasa.2020.44

. L V Gramajo, T Palma, D Minniti, R K Saito, J J Clariá, R Kammers, F Surot, 10.1017/pasa.2020.44Publ. Astron. Soc. Australia3754Gramajo L. V., Palma T., Minniti D., Saito R. K., Clariá J. J., Kammers R., Surot F., 2020b, Publ. Astron. Soc. Australia, 37, e054

. K G Hełminiak, J Devor, D Minniti, P Sybilski, 10.1093/mnras/stt675MNRAS. 4322895Hełminiak K. G., Devor J., Minniti D., Sybilski P., 2013, MNRAS, 432, 2895

. M Hempel, The Messenger. 15524Hempel M., et al., 2014, The Messenger, 155, 24

. Z Hosenie, R J Lyon, B W Stappers, A Mootoovaloo, 10.1093/mnras/stz1999MNRAS. 4884858Hosenie Z., Lyon R. J., Stappers B. W., Mootoovaloo A., 2019, MNRAS, 488, 4858

Optimizing Scientific Return for Astronomy through Information Technologies. M J Irwin, 10.1117/12.551449Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series. Quinn P. J., Bridger A.5493Irwin M. J., et al., 2004, in Quinn P. J., Bridger A., eds, Soci- ety of Photo-Optical Instrumentation Engineers (SPIE) Con- ference Series Vol. 5493, Optimizing Scientific Return for Astronomy through Information Technologies. pp 411-422, doi:10.1117/12.551449

. Z Ivezic, 10.2298/SAJ0876001ISerbian Astronomical Journal. Ivezic Z., et al., 2008, Serbian Astronomical Journal, pp 1-13

M Juric, T Tyson, 10.1017/S174392131401285XHighlights of Astronomy. 16675Juric M., Tyson T., 2015, Highlights of Astronomy, 16, 675

. J Lafler, T D Kinman, 10.1086/190116ApJS. 11216Lafler J., Kinman T. D., 1965, ApJS, 11, 216

. N R Lomb, 10.1007/BF00648343Astrophysics and Space Science. 39447Lomb N. R., 1976, Astrophysics and Space Science, 39, 447

. A Mahabal, 10.1088/1538-3873/aaf3faPASP. 131Mahabal A., et al., 2019, PASP, 131

W Mao, F.-Y Wang, 10.1016/B978-0-12-397200-2.00008-7Advances in Intelligence and Security Informatics. ElsevierMao W., Wang F.-Y., 2012, in , Advances in Intelligence and Se- curity Informatics. Elsevier, pp 91-102, doi:10.1016/B978-0- 12-397200-2.00008-7

Data Mining and Knowledge Discovery. G Menardi, N Torelli, 10.1007/s10618-012-0295-528Menardi G., Torelli N., 2014, Data Mining and Knowledge Discov- ery, 28

. D Minniti, 10.1016/j.newast.2009.12.002New Astron. 15433Minniti D., et al., 2010, New Astron., 15, 433

. D Minniti, 10.1051/0004-6361/201732099A&A. 616Minniti D., et al., 2018, A&A, 616

. T A Molnar, J L Sanders, L C Smith, V Belokurov, P Lucas, D Minniti, 10.1093/mnras/stab3116MNRASMolnar T. A., Sanders J. L., Smith L. C., Belokurov V., Lucas P., Minniti D., 2021, MNRAS

. P North, R Gauderon, F Barblan, F Royer, 10.1051/0004-6361/200810284A&A. 52074North P., Gauderon R., Barblan F., Royer F., 2010, A&A, 520, A74

. B Paczyński, D M Szczygieł, B Pilecki, G Pojmański, 10.1111/j.1365-2966.2006.10223.xMNRAS. 368Paczyński B., Szczygieł D. M., Pilecki B., Pojmański G., 2006, MNRAS, 368

. G Pietrzyński, 10.1038/nature09598Nature. 468542Pietrzyński G., et al., 2010, Nature, 468, 542

. G Pojmanski, Acta Astron. 52397Pojmanski G., 2002, Acta Astron., 52, 397

. A Prša, T Zwitter, 10.1086/430591ApJ. 628426Prša A., Zwitter T., 2005, ApJ, 628, 426

. H Rauer, 10.1007/s10686-014-9383-4Experimental Astronomy. 38249Rauer H., et al., 2014, Experimental Astronomy, 38, 249

. J W Richards, 10.1088/0004-637X/733/1/10ApJ. 73310Richards J. W., et al., 2011, ApJ, 733, 10

Construction of a Calibrated Probabilistic Classification Catalog: Application to 50k Variable Sources in the All-Sky Automated Survey. J W Richards, D L Starr, A A Miller, J S Bloom, N R Butler, H Brink, A Crellin-Quick, Technical reportRichards J. W., Starr D. L., Miller A. A., Bloom J. S., Butler N. R., Brink H., Crellin-Quick A., 2012, Technical report, Con- struction of a Calibrated Probabilistic Classification Catalog: Application to 50k Variable Sources in the All-Sky Automated Survey. -

. A Saha, A K Vivas, 10.3847/1538-3881/aa8fd3AJ. 154231Saha A., Vivas A. K., 2017, AJ, 154, 231

. R K Saito, 10.1051/0004-6361/201118407A&A. 537107Saito R. K., et al., 2012, A&A, 537, A107

. J D Scargle, 10.1086/160554ApJ. 263835Scargle J. D., 1982, ApJ, 263, 835

J Schmidhuber, 10.1016/j.neunet.2014.09.003Deep Learning in neural networks: An overview. Schmidhuber J., 2015, Deep Learning in neural networks: An overview, doi:10.1016/j.neunet.2014.09.003

. R F Stellingwerf, 10.1086/156444ApJ. 224953Stellingwerf R. F., 1978, ApJ, 224, 953

. P B Stetson, 10.1086/133808PASP. 108851Stetson P. B., 1996, PASP, 108, 851

A S Szalay, J Gray, J Vandenberg, American Astronomical Society Meeting Abstracts. 6Szalay A. S., Gray J., Vandenberg J., 2002, in American Astro- nomical Society Meeting Abstracts. p. 134.06

I Tomek, 10.1109/TSMC.1976.4309452IEEE Transactions on Systems, Man, and Cybernetics. SMC-6, 769Tomek I 1976, IEEE Transactions on Systems, Man, and Cyber- netics, SMC-6, 769

. J L Tonry, 10.1088/1538-3873/aabadfPASP. 13064505Tonry J. L., et al., 2018, PASP, 130, 064505

. G Torres, J Andersen, A Giménez, 10.1007/s00159-009-0025-1A&ARv. 1867Torres G., Andersen J., Giménez A., 2010, A&ARv, 18, 67

. A Udalski, M Szymanski, J Kaluzny, M Kubiak, M Mateo, Acta Astron. 4369Udalski A., Szymanski M., Kaluzny J., Kubiak M., Mateo M., 1993, Acta Astron, 43, 69

. P M Vaidya, 10.1007/BF02187718Discrete & Computational Geometry. 4101Vaidya P. M., 1989, Discrete & Computational Geometry, 4, 101

. S Webb, 10.1093/mnras/staa2395MNRAS. 4983077Webb S., et al., 2020, MNRAS, 498, 3077

. M Zechmeister, M Kürster, 10.1051/0004-6361:200811296A&A. 496577Zechmeister M., Kürster M., 2009, A&A, 496, 577