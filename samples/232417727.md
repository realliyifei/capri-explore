# An Overview of Human Activity Recognition Using Wearable Sensors: Healthcare and Artificial Intelligence

CorpusID: 232417727
 
tags: #Medicine, #Engineering, #Computer_Science

URL: [https://www.semanticscholar.org/paper/ddbf23d95ef88abf02d7baf0bb2e91496e6ccff9](https://www.semanticscholar.org/paper/ddbf23d95ef88abf02d7baf0bb2e91496e6ccff9)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | True |
| By Annotator      | (Not Annotated) |

---

An Overview of Human Activity Recognition Using Wearable Sensors: Healthcare and Artificial Intelligence


Rex Liu rexliu@ucdavis.edu 
Department of Computer Science
School of Engineering


Albara Ah Ramli arramli@ucdavis.edu 
Department of Computer Science
School of Engineering


Huanle Zhang dtczhang@ucdavis.edu 
Department of Computer Science
School of Engineering


Erik Henricson ehenricson@ucdavis.edu 
Department of Physical Medicine and Rehabilitation
School of Medicine
University of California
Davis

Xin Liu xinliu@ucdavis.edu 
Department of Computer Science
School of Engineering


An Overview of Human Activity Recognition Using Wearable Sensors: Healthcare and Artificial Intelligence
Human activity recognition (HAR) · Healthcare · Internet of things (IoT) · Artificial intelligence (AI) · Wearable sensors
With the rapid development of the internet of things (IoT) and artificial intelligence (AI) technologies, human activity recognition (HAR) has been applied in a variety of domains such as security and surveillance, human-robot interaction, and entertainment. Even though a number of surveys and review papers have been published, there is a lack of HAR overview papers focusing on healthcare applications that use wearable sensors. Therefore, we fill in the gap by presenting this overview paper. In particular, we present our projects to illustrate the system design of HAR applications for healthcare. Our projects include early mobility identification of human activities for intensive care unit (ICU) patients and gait analysis of Duchenne muscular dystrophy (DMD) patients. We cover essential components of designing HAR systems including sensor factors (e.g., type, number, and placement location), AI model selection (e.g., classical machine learning models versus deep learning models), and feature engineering. In addition, we highlight the challenges of such healthcare-oriented HAR systems and propose several research opportunities for both the medical and the computer science community.

# Introduction

Human activity recognition has been actively researched in the past decade, thanks to the increasing number of deployed smart devices such as smartphones and IoT devices. Based on the type of data being processed, a HAR system can be classified into vision-based and sensor-based. This paper targets wearable-sensor HAR systems in healthcare, which are the most prevalent type of sensor-based HAR systems [1]. More importantly, wearable-sensor HAR systems do not suffer from severe privacy issues like vision-based HAR systems, making wearablesensor HAR systems suitable for healthcare applications. In a wearable-sensor HAR system, a user wears portable mobile devices that have built-in sensors. The user's activities can then be classified by measuring and characterizing sensor signals when the user is conducting daily activities.

HAR for healthcare has many potential use cases, including (1) Moving gait diagnosis from expensive motion labs to the community. Gait analysis can be used in many healthcare applications, such as stroke detection, gait modification (to prevent failing), and certain disease early detection. (2) Cognitive behavior monitoring and intervention for children and adults with attentiondeficit/hyperactivity disorder (ADHD). We can leverage sensors to investigate whether fidgeting positively or negatively affects attention. (3) Stroke-patient hospital direction. When a patient is in an ambulance, a life-and-death question is whether the patient has extensive brain hemorrhage. If so, the patient should be directed to a hospital that can treat such cases. UCSF has developed a device based on an accelerometer sensor to help make this critical decision. (4) Epilepsy and Parkinson's disease study. Doctors have collected a significant amount of data on electrophysiology and episodic memory in rodents and human patients. The analysis of such sensing data can be used for various disease identification and treatment purpose. (5) An expensive device, called Vision RT, is used to ensure radiation therapy is delivered safely to cancer patients (due to patient motion). It is worth exploiting sensors to detect the patient's movement while taking radiation therapy for the less affluent communities.

However, building practical wearable-sensor HAR systems for healthcare applications not only has challenges (e.g., sensor setup, data collection, and AI model selection) that are faced by traditional wearable-HAR systems, but also challenges that are unique to the healthcare domain. For example, in addition to the overall AI model accuracy (averaging results of all users), clinicians are concerned about the model stability (i.e., the model has approximately the same accuracy for each user) and model interpretability (e.g., to discover patient movement patterns that are specific to some symptoms).

Therefore, we present this overview paper in the hope to shed light on designing wearable-sensor HAR systems for healthcare applications. To illustrate the system considerations, we share two of our healthcare systems: one for identifying the early mobility activities of ICU patients [2] and the other one for the gait analysis of DMD patients [3]. Our projects demonstrate that HAR systems for healthcare not only have commonalities such as data processing pipelines but also differences in terms of sensor setup and system requirements.

We organize this paper as follows. First, we provide the preliminaries of HAR systems. Next, we introduce our HAR systems for ICU patients and DMD patients. Then, we explain the considerations when designing a HAR system. Last, we highlight the challenges of applying wearable-sensor-based HAR systems to healthcare, and propose several research opportunities. Last, we conclude this paper. 


# Human Activity Recognition: A Primer

Given the short time-length data of wearable sensors, a HAR system needs to recognize the activity from which the data is generated. Thanks to the rapid advancement of AI technology, AI algorithms/models are increasingly adopted for recognizing the activity from the sensor data. Figure 1 illustrates the general data flow for an AI-based HAR system, which can be divided into two stages: model training and model deployment.

In the model training stage, an AI model is trained and tailored for the specific application. To achieve an accurate AI model, the following steps are often applied. First, raw sensor data from different activities should be collected. The quality of collected data significantly affects the AI model performance. The collected data is required to be diverse, representative, and large in the number of samples. Afterward, the raw data is divided into fixed-length or dynamic-length segments (i.e., time windows) [4]. Then, feature extraction is used to extract potentially useful features from the data segmentation, and feature selection is adopted to remove irrelevant features [5]. To alleviate the overfitting problem of the trained model, the set of processed features are divided into a training set, a validation set, and a test set. During the AI model training, we use the training set to tune the AI model and the validation set to measure the model's accuracy. After we finish the model training, we use the test set to evaluate the trained model. The trained model is deployed to real-world applications if its accuracy is satisfactory. Otherwise, the whole model training stage is performed repetitively by exploring different configurations, such as applying other feature extraction methods and changing AI models.

In the model deployment stage, the same data processing (e.g., segmentation, feature extraction, and selection) is applied to the new and unseen sensor data, and the trained model is executed on the processed data. It is possible that the  trained model may not work as expected in a real deployment, probably due to the model over-fitting or the lack of generality in the collected dataset [6]. In this situation, the system designer needs to revert to the model training stage.


# HAR Applications in Healthcare

Clinicians have already applied wearable sensor-based HAR systems in healthcare, thanks to the development of more lightweight wearable devices, greater computation capability, and higher accurate AI algorithms. This section presents our two HAR healthcare projects to illustrate the considerations when designing HAR systems for healthcare applications with different goals.


## Case 1: Identification of Early Mobility Activity for ICU Patients

Due to long periods of inactivity and immobilization, patients become weak when recovering from major illnesses in ICU [7]. If ICU patients' activities can be accurately recognized, clinicians can provide an optimal personalized dose of mobilities for ICU patients' different illness conditions. Therefore, doctors and researchers are extremely interested in ICU patients' early mobilization, which is an effective and safe intervention to improve functional outcomes [8]. However, early mobility activity (EMA) research is limited by the lack of accurate, effective, and comprehensive methods to recognize patients' activities in ICU.

We propose a wearable sensor-based HAR system for recognizing the EMA of ICU patients [2]. In our system, Each ICU patient wears two accelerometer devices: one on the chest and the other on the thigh, as shown in Figure 2(a). Each device continuously collects 3-axis accelerometer data at a sampling rate of 32 Hz. Figure 3(a) plots the accelerometer data when an ICU patient sits on the cardiac chair to achieve an optimal resting position. This project aims to classify 20 types of ICU-related activities (e.g., reposition, percussion).

This project has two main challenges in designing the HAR system for ICU patients. (1) Label Noise. Because the time lengths for accomplishing an early mobility activity are different for ICU patients with varying health conditions, it is laborious and time-consuming work for clinicians to annotate sensor data for each second in the real world. Therefore, our EMA sensor data are annotated for each minute by a medical expert after data collection. However, one-minute length is exceedingly long for some early mobility activities such as Reposition, which the patient needs less than 20 seconds to accomplish. This annotation process introduces the label noise in our EMA dataset, which decreases the accuracy of the model. (2) Sensor Orientation. In the actual data collection process and possible future applications, we cannot guarantee that the orientations of all accelerometers are the same, and different orientations of the accelerometers lead to different meanings of XYZ coordinate values. Therefore, without careful feature extraction and selection, the AI model generalizes poorly to different patients, affecting the system performance in practice.

To tackle these challenges and improve the accuracy of recognizing ICU patient's activities, we explore the following techniques. (1) We propose a segment voting process to handle the label noise. Specifically, each one-minute sensor data is divided into multiple fixed half-overlapped sliding segments (time windows). We train our AI model using the segments. To predict each one-minute sensor data activity, we apply our trained model to each segment. The final prediction result for the one-minute data is the activity that has the majority vote among the prediction of all segments. Our segmenting method improves the model accuracy by ∼4.08% and reduces the model instability by ∼9.77% [2]. Our experiments also demonstrate that the number of sensors contributes to eliminating label noise in our dataset. As shown in Figure 3(a), the increase in the number of sensors conveys more information, and thus improves the system's accuracy. (2) We identify and extract features that are not sensitive to sensor orientations to tackle the sensor orientation problem. Our features improve both the accuracy and the stability of AI models compared to the model trained on commonly used features.


## Case 2: Identification of Gait Characteristics for DMD Patients

Duchenne muscular dystrophy (DMD) is a genetic disorder disease that affects the dystrophin protein, essential for keeping muscle cells intact. It has an estimated incidence of 1:5000 male births, and untreated boys become wheelchairbound by the age of 12 years and die in their late teens to early 20s [9]. There is presently no cure for DMD disease. Nonetheless, gene repair interventions and other preventive therapies can be initiated as early as possible to slow the disease's progress and prevent secondary conditions. Therefore, it is important to identify children with DMD early in the course of their disease and have tools for quantitative evaluation of their gait in both the clinic and community environments.  We designed a wearable sensor-based HAR system to identify gait characteristics associated with the progression of gait abnormalities in children with DMD and to differentiate those patterns from those of typically developing peers [3] [10] To leverage this idea, we design a HAR system in which we use a smartphone to capture accelerometer data from the participants. As Figure 2(b) illustrates, participants wear a smartphone at the back of the hips over the spine (lumbosacral junction) at a location that is the closest surface point to the body's center of mass. Each smartphone collects 3-axis accelerometer data at a sampling rate of 30 Hz with the same phone orientation.

We recruited ambulatory participants with DMD between 3 and 13 years of age and typically developing controls of similar ages. We ask participants to perform exercises at various times, speeds, and distances such as free walk and 6-minute walk, as specified by the north star ambulatory assessment (NSAA) standard [11]. Figure 3(b) shows the gait pattern difference between a DMD patient and a healthy person when they are walking.

We found that classical machine learning and deep learning, after hyperparameter fine-tuning and cross-validation on seven different gait activities, led to the best performance with an accuracy exceeding 91% on the 6-min-walk-test activity [3]. We demonstrate that by using AI techniques and an accelerometer, we can distinguish between the DMD gait and typically developing peers.

There are two main challenges in designing our HAR system for the DMD application: clinical interpretability and data sparsity. (1) Clinical Interpretability. Medical practitioners desire not only a high prediction accuracy but also an interpretation of the prediction result. (2) Data Sparsity. In the healthcare domain, collecting diverse and sufficient data is challenging, especially for fatal diseases such as DMD.

We explore the following techniques to tackle these challenges. (1) To interpret AI model outcomes, we plan to link the clinical measurements with the model's extracted features by leveraging advanced AI models such as interpretable CNN [12]. However, it is an active, challenging task to find which clinical measurements correlated with the AI model features, especially for deep learning models. (2) To overcome the lack of data, we plan to use Generative Adversarial Network (GAN) [13] or synthetic minority over-sampling technique (SMOTE) [14] to generate more data samples.


## Summary of Our Projects

Our two projects target different healthcare applications with different goals: recognizing ICU patients' activities and distinguishing DMD gait patterns from those typically developing controls. The ICU project focuses on the system performance to assist the doctor in better understanding patients' recovery. While achieving high system performance, the DMD project interprets the model results further and discovers disease-specific patterns to determine the patient's condition and progression. Our example projects demonstrate the effectiveness and potential of wearable sensor-based HAR systems in healthcare. However, due to the different goals, different healthcare applications may have additional HAR system considerations. For example, our two projects adopt a different number of devices (2 versus 1) and device position (chest and thigh versus central mass body). In addition, our projects also apply different feature extractions (time and frequency domain versus clinical). In the next section, we present design considerations for building HAR systems.


# System Design

This section covers three design considerations essential for HAR systems, i.e., sensor, feature extraction and selection, and AI model selection.


## Sensor

Sensors play an essential role in wearable HAR systems. Different HAR systems adopt various sensor configurations regarding the type of sensors, the sensor position and orientation, and the number of sensors.

Sensor Types There are several types of sensors. Each sensor captures a different raw movement signal. The most commonly-used wearable sensors in HAR systems are accelerometer, gyroscope, and electrocardiography (ECG). The accelerometer sensor captures the acceleration signal that is useful for recognizing movements such as walking, running, and jumping. Gyroscopes capture the rotation movements used commonly in recognizing swinging, turning, and repositioning. ECG captures the heart rate and rhythm, which helps distinguish between intensive and light exercises.

However, many activities include both directional and rotational movements. Therefore, using one sensor type is not adequate. As a result, multiple types of sensors (e.g., accelerometer and gyroscope) are used in various application scenarios to maximize accuracy. However, using multiple types of sensors is challenging due to the increased complexity of the system in terms of synchronization issues [15].

Sensor Position and Orientation Different positions and orientations of devices affect the data features and thus the model accuracy in predicting different activities [16]. However, there have not yet been systematic comparisons of the number, type, and location of sensors to determine whether an optimal array design can capture data across a wide range of human activities and disease states. In many cases, the device position and orientation are decided by the empirical experience of clinicians.


## Number of Sensors

Generally, a large number of sensors require demanding storage and computation capability. On the other hand, more sensors can collect more diverse data, which is beneficial for improving model performance [17]. Therefore, to decide the optimal number of sensors, researchers need to carefully consider many factors such as cost, power consumption, and accuracy target as well as the feasibility of long-term use in the community to collect real-world information [18].


## Feature Extraction and Selection

In addition to the hardware setup, feature extraction and selection significantly affect the overall system performance. Before applying feature engineering to the data, the input data needs to be segmented.

Data Segmentation HAR systems collect data constantly via wearable sensors to identify possible activities. Data segmentation is applied to divide comparatively long time data into short fragments (time windows) that are suitable for AI models to learn. There are two types of data segmentation: fixed-length and dynamic-length [4]. For fixed-length segmentation, if the time window is too short, the extracted features from the fragments are insufficient to capture the activity; on the other hand, if the time window is too long, a fragment is likely to contain multiple activities. The system accuracy deteriorates in both cases. In comparison, a dynamic-length data segmentation adopts an adaptive length of fragments corresponding to the characteristics of input data. Ideally, dynamic data segmentation generates fragments, in which each fragment only contains a single and complete activity. However, dynamic data segmentation is much more complex than fixed data segmentation, and thus are not as widely adopted by existing works as fixed-length segmentation.

Feature Extraction Feature extraction is then applied to extract important features from the data fragments [5]. It can be broadly classified into time-domain and frequency-domain methods. In time-domain feature extraction, metrics such as median, variance, mean, and skewness are calculated over the amplitude variations of data over time. Time-domain features are lightweight to compute and thus are friendly to low-profile embedded devices and real-time applications. In comparison, frequency-domain features calculate the frequency variations of data over time. They include metrics such as spectral entropy, spectral power, and peak frequency. The computation overhead of frequency-domain features is generally much greater than time-domain features. In reality, most existing HAR systems adopt both time-domain features and frequency-domain features, in the consideration of the tradeoff among factors such as system accuracy, computation overhead, and power consumption.

Feature Selection Feature selection is often adopted in order to reduce system complexity. It measures the importance of features and then removes irrelevant features. Feature selection is roughly divided into three methods: filter methods, wrapper methods, and embedded/hybrid methods [5]. Filter methods select a subset of features by exploiting inherent characteristics of features, whereas wrapper methods use classifiers to estimate the useful features. On the other hand, the embedded/hybrid methods combine the results from filter methods and wrapper methods [1]. By carefully selecting features, the AI model accuracy can be significantly improved. However, in healthcare HAR systems, pursuing high accuracy is not the sole goal, as the features are often manually decided by medical experts for identifying patients. Therefore, healthcare HAR systems require feature extraction and selection that is meaningful for clinicians and meanwhile achieves high prediction accuracy.


## AI Model Selection

In the HAR field, classical machine learning algorithms and deep learning algorithms have been explored and applied, which is summarized in Figure 4. Both classical machine learning algorithms and deep learning algorithms have different advantages and disadvantages. Dataset requirement and system running overhead. The data collection process in the healthcare scenario is challenging because of the severe privacy issue and rare incidence rate of some medical activities. Therefore, in most healthcare applications, the database size is small. Correspondingly, classical machine learning models are more preferred because they work well with medium-size datasets. In contrast, even though deep learning models achieve better accuracy, they usually require a large amount of data for training. Realtime performance is another critical factor for some healthcare applications [19]. For example, [20] uses cranial accelerometers to detect stroke in an ambulance to decide whether to send the patient to a specialist stroke hospital for special treatment. Therefore, lightweight models are preferred in this use case. In addition to the running overhead of the AI models, the processing time of feature extraction also affects the model selection, because different model structures adapt differently to the extracted features.

System interpretability. The features extracted from the sensor data are helpful to understand the pattern of some specific diseases to find out the pathological characteristics of the disease. For example, we extract the temporal/spatial gait characteristics from sensor data to evaluate the gait changes associated with DMD. Classical machine learning models are easier to interpret the model's decision, especially in decision tree models. Even though there is a great deal of work in interpreting deep learning models, deep learning models have the reputation of poor interpretability.


# Challenges and Opportunities

Wearable sensor-based HAR systems are promising for a variety of healthcare problems. However, there are several challenges in fully exploiting them to build satisfactory HAR systems for healthcare. In this section, we identify challenges as well as research opportunities of HAR systems for healthcare.


## Data Sparsity

The most commonly used algorithms for the HAR system in healthcare are the supervised learning algorithms that need extensive labeled data. For some daily living activities such as walking and running, researchers could get a significant amount of the labeled data from the public dataset or the raw sensor data collected and annotated by themselves. However, for some specific human activities related to healthcare, such as the therapeutic activities of patients, researchers could not get enough sensor data since these activities are low-probability events compared with daily life activities. Furthermore, it also takes time and effort to locate the sensor data of these specific activities from the daily data and label them. For example, when patients recover from surgery, they need some range of motion(ROM) exercises several times a day to make their joints and muscles flexible and strong again. Because of the fixed and limited collection times per day and the limited number of patients are involved, raw sensor data for ROM becomes insufficient, affecting the HAR system's performance. Therefore, building HAR systems with high accuracy on small datasets in healthcare is one of the most significant challenges.

Meta-learning is one of the approaches to solve this challenge. Meta-learning aims to optimize models which can learn efficiently in a small dataset when deal-ing with new categories. In [21], researchers present a meta-learning methodology based on the Model-Agnostic Meta-Learning algorithm [22] to build personal HAR models. In [23], researchers use few-shot learning to transfer information from existing activity recognition models. However, it is unclear whether these techniques work well for medical applications. So more research is needed to explore the feasibility of transferring knowledge from daily living activities to specific activities related to healthcare.


## Model Interpretability

In HAR applications in healthcare, an increasing number of applications focus on the interpretability of the model to extract relevant features, in order to describe the severity of the disease and track the progression of the disease [3]. In addition, notwithstanding the benefit of deep learning in HAR, the underlying mechanics of machine learning are still unclear. So, various studies are trying to explain the deep learning model for the recognition of human activities. The common approach to interpreting the deep learning model is to compute the importance of each part of the input. In [24], researchers propose an interpretable convolutional neural network to select the most important sensor position for some specific activities. Instead of computing the importance of each part of the input, another approach is to make a sequence of selections about which part of the input is essential for the model training [25]. More research is required to adopt these methods to HAR systems for healthcare.


## Concurrent Activities

Most of the existing HAR research focuses on single-labeled activity, recognizing only one activity of the given data segment. However, in real-world healthcare scenarios, humans can perform multiple activities concurrently. For example, patients can do ROM exercises and percussion therapy at the same time. The AI model performance deteriorates for concurrent activities. On the other hand, designing models to recognize multiple activities per data segment is a challenging task.


## Composite Activities

In healthcare applications, optimizing HAR algorithms to identify composite activities in the community is ultimately more desirable than recognizing a single type of task. For example, when a patient moves from bed to the chair, the patient performs various activities, including sitting from supine in the bed, pivoting to place feet on the floor, standing from sitting, walking a few steps, and then sitting down on a chair. Therefore, it is preferred that an AI model can directly recognize the composite activity.


## Privacy

Wearable sensor-based HAR systems do not suffer from severe privacy issues as camera-based vision systems. However, since HAR applications continuously capture user data and recognize user activities, they may leak users' personal information if data are not secured. Therefore, secure data sharing and safe data storage are imperative for healthcare applications. To alleviate sensitive information during model training, adversarial loss functions are leveraged to guard against privacy leakage [26]. In addition, federated learning is a promising solution, which trains a global model without exposing local devices' private data [27].


## Opportunities of HAR for Healthcare

Through our experience with HAR systems for healthcare, we identify the following research opportunities.

-Community-based healthcare. Community-based healthcare requires that user devices are lightweight and affordable for the public. In addition, instructing the non-expert users/patients should be straightforward to follow. We can use digital sensing capability and the popularity of mobile devices to enable large community-based prescreening for various diseases and early signs of diseases. This can be done in a privacy-preserving manner in the sense that data does not need to leave a local device if necessary. For example, our DMD project enables community-based diagnosis during the pandemic and in rural areas where specialty labs are hundreds of miles away. -Chronic disease prevention and intervention. For chronic diseases, it is essential to capture the behaviors of patients in the long run. To this end, gait analysis, motion monitoring, ECG, and other vital signals (such as continuous glucose monitoring) can play a key role. -Health aging. With the decreased fertility rates and the increased life expectancy, population aging is becoming common for most countries. Therefore, building HAR systems for healthy aging is beneficial for senior citizens and society as a whole. We anticipate that gait and motion monitoring and diagnosis will play a critical role in healthy aging.


# Conclusion

It is gaining popularity by applying wearable sensors to recognize and analyze human activities for the healthcare domain. For example, we leverage HAR systems to recognizing patients' early mobility activities in ICU and to analyzing the symptoms of DMD patients. This overview paper covers the system design of HAR systems based on wearable sensors, focusing on healthcare applications. We emphasize the essential components of HAR systems, including sensor factors, data segmentation, feature extraction and selection, and AI model comparison.

We also highlight the challenges and opportunities of HAR systems for healthcare.

## Fig. 2 .
2Device setups in our HAR projects. (a) We use two accelerometer devices to recognize the early mobility activities of ICU patients. One device is on the chest and the other device is on the thigh. (b) We use one smartphone that captures accelerometer data to identify DMD patients. The phone is located at the backside body.

## Fig. 3 .
3Illustration of accelerometer data in our projects. (a) The z-axis of the accelerometer data from the two on-body devices when an ICU patient is performing the cardiac activity. (b) The z-axis of the accelerometer data, which shows the difference in gait characteristics between a DMD patient and a healthy person.

## Fig. 4 .
4Classical machine learning and deep learning algorithms used in HAR systems.
AcknowledgementThe authors thank Esha Datta for their contribution to the manuscript.
Cheol Hee Lee, and Hyeongjoon Moon. Sensor-based and vision-based human activity recognition: a comprehensive survey. L , Minh Dang, Kyungbok Min, Hanxiang Wang, Md Piran, Pattern Recognition. 108L. Minh Dang, Kyungbok Min, Hanxiang Wang, Md. Jalil Piran, Cheol Hee Lee, and Hyeongjoon Moon. Sensor-based and vision-based human activity recognition: a comprehensive survey. Pattern Recognition, 108:1-41, 2020.

Albara Ah Ramli, Xin Liu, and Jason Yeates Adams. Early mobility recognition for intensive care unit patients using accelerometers. Rex Liu, A Sarina, Huanle Fazio, Zhang, KDD Workshop on Artificial Intelligence of Things (AIoT). Rex Liu, Sarina A Fazio, Huanle Zhang, Albara Ah Ramli, Xin Liu, and Ja- son Yeates Adams. Early mobility recognition for intensive care unit patients using accelerometers. In KDD Workshop on Artificial Intelligence of Things (AIoT), pages 1-6, 2021.

and Erik Henricson. Gait characterization in duchenne muscular dystrophy (dmd) using a singlesensor accelerometer: Classical machine learning and deep learning approaches. Huanle Albara Ah Ramli, Jiahui Zhang, Rex Hou, Xin Liu, Alina Liu, Daniel Nicorici, Corey Aranki, Poonam Owens, Craig Prasad, Mcdonald, Albara Ah Ramli, Huanle Zhang, Jiahui Hou, Rex Liu, Xin Liu, Alina Nicorici, Daniel Aranki, Corey Owens, Poonam Prasad, Craig McDonald, and Erik Henric- son. Gait characterization in duchenne muscular dystrophy (dmd) using a single- sensor accelerometer: Classical machine learning and deep learning approaches, 2021.

Adaptive sliding window segmentation for physical activity recognition using a single tri-axial accelerometer. Mohd Halim Mohd Noor, Zoran Salcic, Kevin I-Kai Wang, Pervasive and Mobile Computing. 381Mohd Halim Mohd Noor, Zoran Salcic, and Kevin I-Kai Wang. Adaptive slid- ing window segmentation for physical activity recognition using a single tri-axial accelerometer. Pervasive and Mobile Computing, 38(1):41-59, 2016.

A survey of feature selection and feature extraction techniques in machine learning. Samina Khalid, Tehmina Khalil, Shamila Nasreen, Science and Information Conference. Samina Khalid, Tehmina Khalil, and Shamila Nasreen. A survey of feature selection and feature extraction techniques in machine learning. In Science and Information Conference, pages 372-378, 2014.

Deep learning for sensor-based activity recognition: a survey. Jindong Wang, Yiqiang Chen, Shuji Hao, Xiaohui Peng, Lisha Hu, Pattern Recognition Letters. 119Jindong Wang, Yiqiang Chen, Shuji Hao, Xiaohui Peng, and Lisha Hu. Deep learning for sensor-based activity recognition: a survey. Pattern Recognition Let- ters, 119:3-11, 2019.

Effect of early rehabilitation during intensive care unit stay on functional status: systematic review and meta-analysis. Ana Cristina Castro-Avila, Pamela Seron, Eddy Fang, Monica Gaete, Sharon Mickan, PloS One. 107Ana Cristina Castro-Avila, Pamela Seron, Eddy Fang, Monica Gaete, and Sharon Mickan. Effect of early rehabilitation during intensive care unit stay on functional status: systematic review and meta-analysis. PloS One, 10(7):1-21, 2015.

Early mobilization in the intensive care unit: a systematic review. Joseph Adler, Daniel Malone, Cardiopulmonary Physical Therapy Journal. 23Joseph Adler and Daniel Malone. Early mobilization in the intensive care unit: a systematic review. Cardiopulmonary Physical Therapy Journal, 23:5-13, 2012.

Duchenne muscular dystrophy. M Eppie, Andrew J Yiu, Kornberg, Journal of Paediatrics and Child Health. Eppie M Yiu and Andrew J Kornberg. Duchenne muscular dystrophy. Journal of Paediatrics and Child Health, pages 759-764, 2015.

An automated system for early diagnosis, severity, and progression identification in duchenne muscular dystrophy: a machine learning and deep learning approach. Alina Albara Ah Ramli, Poonam Nicorici, Jaihui Prasad, Craig Hou, Xin Mcdonald, Erik Liu, Henricson, Annual Human Genomics Symposium. University of California Davis Medical CenterAlbara Ah Ramli, Alina Nicorici, Poonam Prasad, JaiHui Hou, Craig McDonald, Xin Liu, and Erik Henricson. An automated system for early diagnosis, severity, and progression identification in duchenne muscular dystrophy: a machine learning and deep learning approach. In Annual Human Genomics Symposium -University of California Davis Medical Center, pages 12-12, 2020.

North start ambulatory assessment. Physiopedia, 29Physiopedia. North start ambulatory assessment. https://www.physio-pedia. com/North_Star_Ambulatory_Assessment. [accessed on 29-June-2021].

Interpretable convolutional neural networks. Quanshi Zhang, Ying Nian Wu, Song-Chun Zhu, IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Quanshi Zhang, Ying Nian Wu, and Song-Chun Zhu. Interpretable convolutional neural networks. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 8827-8836, 2018.

Generative adversarial networks. Ian J Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio, arXiv:1406.2661Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde- Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks, 2014. arXiv:1406.2661.

Smote: synthetic minority over-sampling technique. V Nitesh, Kevin W Chawla, Lawrence O Bowyer, W Philip Hall, Kegelmeyer, Journal of Artificial Intelligence Research. 161Nitesh V. Chawla, Kevin W. Bowyer, Lawrence O. Hall, and W. Philip Kegelmeyer. Smote: synthetic minority over-sampling technique. Journal of Artificial Intelli- gence Research, 16(1):321-357, 2002.

A survey on human activity recognition using wearable sensors. Oscar D Lara, Miguel A Labrador, IEEE Communication Surveys & Tutorials. 153Oscar D. Lara and Miguel A. Labrador. A survey on human activity recognition using wearable sensors. IEEE Communication Surveys & Tutorials, 15(3):1192- 1209, 2013.

Activity recognition and monitoring using multiple sensors on different body positions. Uwe Maurer, Asim Smailagic, Daniel P Siewiorek, Michael Deisher, International Workshop on Wearable and Implantable Body Sensor Networks (BSN). Uwe Maurer, Asim Smailagic, Daniel P. Siewiorek, and Michael Deisher. Activ- ity recognition and monitoring using multiple sensors on different body positions. In International Workshop on Wearable and Implantable Body Sensor Networks (BSN), pages 1-4, 2006.

Multisensor context aware clothing. Kristof Van Laerhoven, Albrecht Schmidt, Hans-Werner Gellersen, International Symposium on Wearable Computers. Kristof Van Laerhoven, Albrecht Schmidt, and Hans-Werner Gellersen. Multi- sensor context aware clothing. In International Symposium on Wearable Comput- ers, pages 1-8, 2002.

A review on accelerometry-based gait analysis and emerging clinical applications. Delaram Jarchi, James Pope, K M Tracey, Larisa Lee, Amirhosein Tamjidi, Saeid Mirzaei, Sanei, IEEE Reviews in Biomedical Engineering. 11Delaram Jarchi, James Pope, Tracey KM Lee, Larisa Tamjidi, Amirhosein Mirzaei, and Saeid Sanei. A review on accelerometry-based gait analysis and emerging clinical applications. IEEE Reviews in Biomedical Engineering, 11:177-194, 2018.

Bwcnn: Blink to word, a real-time convolutional neural network approach. Rex Albara Ah Ramli, Liu, I B Krishnamoorthy, Xiaoxiao Vishal, Ilias Wang, Xin Tagkopoulos, Liu, Internet of Things -ICIOT 2020. ChamSpringer International PublishingAlbara Ah Ramli, Rex Liu, Rahul Krishnamoorthy, I. B. Vishal, Xiaoxiao Wang, Ilias Tagkopoulos, and Xin Liu. Bwcnn: Blink to word, a real-time convolutional neural network approach. In Internet of Things -ICIOT 2020, pages 133-140, Cham, 2020. Springer International Publishing.

The neurological examination improves cranial accelerometry large vessel occlusion prediction accuracy. Neurocritical Care. Kevin Keenan, Paul Lovoi, Wade Smith, Kevin Keenan, Paul Lovoi, and Wade Smith. The neurological examination im- proves cranial accelerometry large vessel occlusion prediction accuracy. Neurocrit- ical Care, pages 1-10, 2020.

Learning-to-learn personalised human activity recognition models. Anjana Wijekoon, Nirmalie Wiratunga, arXiv:2006.07472Anjana Wijekoon and Nirmalie Wiratunga. Learning-to-learn personalised human activity recognition models, 2020. arXiv:2006.07472.

Model-agnostic meta-learning for fast adaptation of deep networks. Chelsea Finn, Pieter Abbeel, Sergey Levine, Proceedings of the 34th International Conference on Machine Learning. the 34th International Conference on Machine LearningChelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep networks. In Proceedings of the 34th International Conference on Machine Learning, pages 1126-1135, 2017.

Few-shot learning-based human activity recognition. Siwei Feng, Marco Duarte, Expert Systems with Applications. 138Siwei Feng and Marco Duarte. Few-shot learning-based human activity recognition. Expert Systems with Applications, 138:1-12, 2019.

Interpretable and accurate convolutional neural networks for human activity recognition. Eunji Kim, IEEE Transactions on Industrial Informatics. 1611Eunji Kim. Interpretable and accurate convolutional neural networks for human activity recognition. IEEE Transactions on Industrial Informatics, 16(11):7190- 7198, 2020.

Interpretable parallel recurrent neural networks with convolutional attentions for multi-modality activity modeling. Kaixuan Chen, Lina Yao, Xianzhi Wang, Dalin Zhang, Tao Gu, Zhiwen Yu, Zheng Yang, arXiv:1805.07233Kaixuan Chen, Lina Yao, Xianzhi Wang, Dalin Zhang, Tao Gu, Zhiwen Yu, and Zheng Yang. Interpretable parallel recurrent neural networks with convolutional attentions for multi-modality activity modeling, 2018. arXiv:1805.07233.

Privacy issues regarding the application of dnns to activity-recognition using wearables and its countermeasures by use of adversarial training. Yusuke Iwasawa, Kotaro Nakayama, Ikuko Yairi, Yutaka Matsuo, International Joint Conference on Artificial Intelligence (IJCAI). Yusuke Iwasawa, Kotaro Nakayama, Ikuko Yairi, and Yutaka Matsuo. Privacy issues regarding the application of dnns to activity-recognition using wearables and its countermeasures by use of adversarial training. In International Joint Conference on Artificial Intelligence (IJCAI), pages 1930-1936, 2017.

Communication-efficient learning of deep networks from decentralized data. H , Brendan Mcmahan, Eider Moore, Daniel Ramage, Seth Hampson, Blaise Agueray Arcas, International Conference on Artificial Intelligence and Statistics (AISTATS). H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Agueray Arcas. Communication-efficient learning of deep networks from de- centralized data. In International Conference on Artificial Intelligence and Statis- tics (AISTATS), pages 1-10, 2017.