# Better to ask online when it concerns intimate relationships? Survey mode differences in the assessment of relationship quality

CorpusID: 258512475
 
tags: #Sociology

URL: [https://www.semanticscholar.org/paper/9cfa50a80c02d78dc7fedf48b05c5e24d537f587](https://www.semanticscholar.org/paper/9cfa50a80c02d78dc7fedf48b05c5e24d537f587)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | False |
| By Annotator      | (Not Annotated) |

---

Better to ask online when it concerns intimate relationships? Survey mode differences in the assessment of relationship quality


Almut Schumann almut.schumann@bib.bund.de. 
Federal Institute for Population Research (BiB)
WiesbadenGermany

Detlev Lück 
Federal Institute for Population Research (BiB)
WiesbadenGermany

Better to ask online when it concerns intimate relationships? Survey mode differences in the assessment of relationship quality
2BB5D706BEAE3357E96563C1C741EF0610.4054/DemRes.2023.48.22
BACKGROUNDThe assessment of relationship quality is a key construct in family research and relies on several indicators.As answer behavior for sensitive and subjective questions can be biased by the interview situation, the emerging switch from face-to-face mode to web or mixed mode in surveys challenges the comparability of measurements.OBJECTIVEThis study investigates the impact of two modes of data collection -face-to-face mode and web mode -on central measurements of relationship quality in quantitative family research.METHODSIn a German experimental pilot study (2018) within the Generations and Gender Programme, target persons were randomly assigned to face-to-face or online interviews.Mode differences are assessed by comparing distributions for various indicators of relationship quality.To adjust for confounders, post-stratification weighting and multivariate regression analysis are applied.RESULTSFindings reveal consistent mode effects for almost all indicators of relationship quality even after adjusting for confounders.Respondents in web mode assess their relationship quality substantially lower than respondents in face-to-face mode, thinking more often about breaking up and reporting lower satisfaction and more conflicts.CONCLUSIONWeb mode seems to support less socially desirable reflections on respondents' relationships compared to face-to-face mode.Family researchers should consider survey

## Introduction

The assessment of relationship quality is one of the most frequently addressed topics in research on intimate relationships (see Bradbury, Fincham, and Beach 2000;Fincham and Beach 2006;Karney and Bradbury 2020).Relationship quality is connected with the stability of relationships and therefore often serves as a predictor for processes such as separation, family formation, and marriage (Karney and Bradbury 1995;Lewis and Spanier 1979).Not only family sociologists and demographers but also family psychologists frequently use indicators for relationship quality as determinants for various outcomes.Central and frequently analyzed indicators for relationship quality in quantitative family research are subjectively perceived stability (e.g., van Damme and Dykstra 2018; Wiik, Keizer, and Lappegard 2012), satisfaction with the relationship (e.g., Arránz-Becker 2013; Schmid et al. 2021), and certain interactions between partners, such as conflict behavior (e.g., Huß and Pollmann-Schult 2020;Kluwer and Johnson 2007).

Most of the studies mentioned compare aspects of relationship quality between different countries and cultural backgrounds or between different points in time or life course phases (e.g., Wiik, Keizer, and Lappegard 2012;Huß and Pollmann-Schult 2020;Schmid et al. 2021).Whenever different data sources are used for longitudinal or crossnational studies, analyses strongly depend on consistently high data quality and the comparability of data.Limitations on reliability and comparability can have many causes.A particularly important determinant is the mode of data collection (Groves et al. 2004).Face-to-face interviews have for decades been the most common mode of data collection for large-scale survey programs in the landscape of social science and family research, mainly because of their comparably high response rate and good coverage for the achievement of population-representative samples (De Leeuw, Hox, and Dillman 2008;Groves et al. 2004).Notwithstanding, one of the known and well-researched downsides of face-to-face interviews is that the personal interview situation supports the underreporting of sensitive topics, such as illicit or sexual behavior (Aquilino 1991;Tourangeau and Smith 1996).

However, this conventional wisdom is currently undergoing a reassessment.For data collectors, the switch from traditional personal interviews to online interviews is becoming increasingly attractive because web interviews are much more cost-efficient than face-to-face interviews, especially in countries where labor costs for interviewers are high (Bethlehem and Biffignandi 2012).Additionally, they facilitate rapid data collection and delivery (Couper 2011).Moreover, the ubiquity of mobile phones and smartphones is leading to an increasing use of mobile devices to complete web surveys (Gummer et al. 2023), giving respondents easier access to surveys -via QR codes, for example -and allowing them to answer at any time or from any place (Couper, Antoun, and Mavletova 2017).Last but not least, the COVID-19 pandemic strongly accelerated this transition by forcing established face-to-face studies, such as the Generations and Gender Survey (GGS) and the German family panel pairfam, to switch to web interviews (Gummer et al. 2020).So we may currently be witnessing the establishment of the selfadministered online interview as a new standard mode of data collection, at least in Western Europe and in other countries with high labor costs and appropriate sampling frames.

In view of this development, the potential impact of the mode of data collection on data quality and on substantive analyses has become an even more relevant question for empirical analysis.We examine two survey modes that mark the starting and ending points of the transition described above: face-to-face interviews and web interviews.These two modes show the greatest difference in interviewer involvement: web surveys are self-administered whereas face-to-face surveys are interviewer-administered.This comes with advantages as well as disadvantages for both modes and with positive as well as negative effects on data quality.On the one hand, an interviewer is able to motivate people to participate and thereby increase response rates (Groves et al. 2004), and the interviewer can support the respondent with questions requiring a high cognitive effort (Holbrook, Green, and Krosnick 2003).On the other hand, the presence of an interviewer increases the normative pressure on respondents to provide socially acceptable answers, whereas the anonymous environment of self-administered interviews allows them to be more honest (Tourangeau and Smith 1996;Tourangeau and Yan 2007).Especially with regard to more sensitive questions, the mode of data collection has a strong influence on biases due to social desirability (Chang and Krosnick 2010;Tourangeau and Yan 2007).Research has shown that factual measurements of sociodemographic characteristics are less affected by the interview situation, whereas subjective and private questions, which score higher on sensitivity, elicit a stronger mode effect, depending on whether they are self-administered or interviewer-administered (Burkill et al. 2016;Christensen et al. 2013).In terms of content that is important for family research, previous findings on social desirability bias between modes have often concentrated on traditional or obvious sensitive items that are strongly normative, such as attitudes toward gender and family roles (Liu 2017;Liu and Wang 2016), questions regarding sexual behavior and sexual experiences (Burkill et al. 2016;Kelly et al. 2013), and questions regarding mental and physical health (Braekman et al. 2020;Christensen et al. 2013).

The question remains open as to the extent other kinds of subjective questions are perceived as sensitive by respondents, might therefore be prone to biases based on social desirability, and thus might also be subject to effects based on the mode of data collection.The research field of relationship quality provides a very good example for analyzing this question.First of all, it is a frequently addressed topic in research about intimate relationships, with a high relevance for other family-related events, such as childbearing (Rijken and Liefbroer 2009) and union dissolution (Karney and Bradbury 1995).It might also affect personal matters, such as well-being (Gustavson et al. 2013).Second, the experimental study we use has many suitable indicators for measuring relationship quality comprehensively.These indicators cover a broad range of domains in a relationship as we study perceived relationship stability, satisfaction with different aspects of couples' daily life, different areas of conflict, and different levels of aggressive and violating conflict styles.Furthermore, these indicators provide good examples of subjective perceptions for which we lack clarification as to what extent they must be considered sensitive questions.One can assume that the normative expectation regarding the maintenance of a happy relationship in studies about intimate relationships is strong, which in turn increases respondents' perception of social pressure in a personal interview situation.The measurement of relationship quality requires subjective assessments by the respondent and may also be perceived as sensitive, depending on the individual situation.This may be true for at least some of the aspects of relationship quality for which we find indicators in our dataset.The broad spectrum of domains of relationship quality covered by the data may even provide a nuanced picture.Therefore we investigate whether measurements of this construct differ between a self-administered and an intervieweradministered interview situation.

For assessing differences between modes of conduction, an experimental pilot study was carried out in Germany within the Generations and Gender Programme (GGP), which compares the traditional face-to-face mode with the upcoming web mode.The GGP is a well-established, large-scale survey program in family research.We profit from a unique experimental setting that allows us to use an existing survey instrument, the GGS, as well as an experimental design to test for differences in the mode of conduction.The aims of this study are to examine whether differences in measurements of frequently used indicators of relationship quality occur between face-to-face and web modes and to assess which survey design provides the most reliable measurement of relationship quality.Our research question is therefore: Do measurements of indicators frequently used for explaining relationship quality conducted in face-to-face mode differ from measurements conducted in web mode?In a first descriptive step, we compare mode-specific differences between the distributions of the particular indicators for relationship quality in the two experimental groups.In a second step, we estimate multivariate regression models to adjust for family demographic confounders to assess the impact of mode on the particular items of relationship quality.Given that in each mode, persons with specific characteristics might be more or less likely to participate, the regression models allow us to control for such selective confounders.

In the context of continuing methodological innovations and developments in data collection, this study should sensitize data users to the possibility of distortions for frequently used key variables in substantive analysis due to survey mode decisions.The findings are especially relevant for data analysis as well as for data conduction of crossnational and panel surveys based on different modes of data collection.


## Background and expectations


## Face-to-face versus web interviewing

Face-to-face and web surveys differ mostly regarding the degree of interviewer involvement.According to Couper (2011), this has an impact on overall participation in a survey, thus on the response rate and data quality.A meta-analysis revealed that response rates of web surveys are lower compared to more traditional modes of data collection, such as face-to-face surveys (Daikeler, Bošnjak, and Manfreda 2020).But the last years have also shown that, at least in Western European countries, response rates of data collections in face-to-face mode have declined rapidly (Beullens et al. 2018).Nevertheless, interviewers can be helpful in the recruitment stage in motivating the target person to participate.Furthermore, web surveys obviously bear the risk of underrepresenting the off-line population (Schonlau et al. 2009).This is particularly relevant for surveys that have to rely on nonprobability samples -due to lack of a suitable sampling frame for the particular target population, for example, which lowers the representativeness needed for large-scale social science surveys (Tourangeau 2017).Moreover, the interviewer can play a helpful role during the interview by assisting the respondent in the response process.Interviewers are able to support the respondent in answering questions requiring a high cognitive effort.They can motivate and support the respondent verbally as well as through nonverbal communication throughout a long interview (Holbrook, Green, and Krosnick 2003).Some studies showed that selfadministered web surveys had higher proportions of item non-response, higher proportions of choosing "Don't know" answers, and less differentiation on rating scales than face-to-face surveys (Heerwegh 2009;Heerwegh and Loosfeldt 2008).

However, data collectors have to consider that the use of interviewers is considerably more expensive than conducting a web interview.Additionally, there are also positive effects on data quality resulting from the absence of an interviewer.While in face-to-face interviews, interviewers have the locus of control over the whole interview process, in web interviews, respondents have the autonomy to answer the questionnaire at the time and place they prefer, at the speed that suits them best, and with the option to stop during the interview and continue later on (Couper 2011).Furthermore, web interviews are characterized by a higher degree of privacy and anonymity than face-toface interviews.This may be expected to modulate the strength of social desirability effects, as discussed in detail below.


## Social desirability bias and relationship quality

Social desirability explains most prominently why the mode of data collection plays such an important role in the answering of questions prone to sensitivity.According to the concept of social desirability, respondents tend to overreport socially desirable answers and underreport socially undesirable answers (Callegaro 2008).An open question is how strongly particular questions are affected by social desirability bias.Often, the strength of social desirability bias corresponds with the degree of sensitivity of the question (Krumpal 2013).But the perceived sensitivity of a question depends strongly on the person who is interviewed and thus also on his or her individual situation and how much emotional stress the respondent would endure by giving an honest answer.This can further vary by cultural, social, and situational context (Lee and Renzetti 1990).Given that these factors vary across and even within studies due to different questionnaire contents and target populations, it is difficult to draw general conclusions about social desirability bias.

Taking the mode of conducting surveys into account, research has shown that respondents tend to answer more truthfully and honestly in an anonymous interview situation, especially for obviously sensitive questions (Chang and Krosnick 2010;Tourangeau and Smith 1996;Tourangeau and Yan 2007; for an overview: Krumpal 2013).In other words, interviewer-administered modes, such as face-to-face mode, lead more often to socially desirable responding because respondents tend to present themselves in a socially favorable manner instead of reflecting the true situation in front of the interviewer.In contrast, in self-administered interviews, such as web surveys, respondents have a higher level of privacy and a lower level of perceived social pressure and show more honest answer behavior (Heerwegh 2009).Interviewer characteristics, such as gender or ethnicity, can also affect interview dynamics and impact responses in personal interviews, particularly for questions prone to social desirability biases and for questions related to these characteristics (Davis et al. 2010).For example, research shows that the gender of the interviewer can influence response behavior regarding marriagerelated questions (Liu and Stainback 2013).Moreover, the degree of familiarity between the respondent and the interviewer might also impact the respondent's effort in answering sensitive questions, as respondents show lower levels of trust and disclosure when the interviewer is a stranger and is not familiar with the local environment (Weinreb, Sana, and Stecklov 2018).

To reduce bias related to social desirability in face-to-face interviews, highly sensitive questions are often surveyed in a computer-assisted self-interview (CASI) module, where the respondent can complete individual question blocks independently.Even though this is a good way to make respondents' answers more anonymous, the control still remains with the interviewer.By contrast, in an entirely self-administered mode, such as web, the respondent can show a higher degree of self-disclosure because there is no other person present and therefore no time pressure and a free choice of where to respond to the interview.Additionally, face-to-face interviews are mostly conducted in the respondent's own household, which means respondents might be influenced not only by the interviewer but also by any additional persons present, such as partners, spouses, or children (Schröder and Schmiedeberg 2020).So-called bystander effects have an impact on answering questions in computer-assisted personal interviews (CAPI) as well as in CASI during face-to-face interviews; research shows that the reporting of less desirable answers in web mode has the highest response accuracy compared to other selfadministered modes (Kreuter, Presser, and Tourangeau 2008).

Previous research on mode-related social desirability bias in studies about families and intimate relationships concentrates on a few subjective and objective indicators, but as far as we know, no study has investigated the impact of social desirability bias on items about relationship quality.An early experiment from the National Survey of Family Growth discloses a higher reported number of abortions in self-reports than in interviewer-administered interviews (Fu et al. 1998).This is one example of highly sensitive information in family research.A more recent experiment of the third British National Survey of Sexual Attitudes and Lifestyles examined changes in responses from the same respondents in interviews first conducted in CAPI and CASI and afterward conducted in web mode.The findings show that not all sensitive questions regarding sexual life revealed a mode effect between CAPI, CASI, and web.But for some questions regarding individual behavior, such as same-sex experiences, and for opinion questions, such as those about sexual satisfaction, the study found a higher level of self-disclosure and more socially undesirable answers in web interviews compared to CAPI and CASI (Burkill et al. 2016), which implies that even a switch to CASI mode cannot fully compensate for the downsides of conducting personal interviews.The anonymous interview situation can play a major role here, as Robertson and colleagues (2018) find that respondents in online surveys report the highest comfort level in answering questions about non-heterosexual prevalence compared to 16 other interviewer-administered as well as self-administered survey modes.An explanation is that online interviews are perceived as less intrusive and as having a higher level of anonymity and privacy without creating the feeling of being observed or recorded (Robertson et al. 2018).In the field of public health research, experiments come to similar findings regarding opinion questions and subjective assessments of personal well-being and health status.Answers to factual questions are comparable between face-to-face and self-administered survey modes, but they detect different levels of mode effects in the answering of more sensitive questions involving subjective assessments (Braekman et al. 2020;Christensen et al. 2013).

As prior research shows, mode effects can vary strongly between studies, because every survey focuses on different topics, uses different questionnaires, and aims at different target populations.This means effects between face-to-face and web surveys regarding biases due to social desirability are hard to generalize (Couper 2011).Therefore it is always necessary to evaluate such effects in the context of the particular study.What also can come into play in surveys about intimate relationships is a social expectation about how a relationship should ideally be.In such surveys, respondents might feel embarrassed to admit that their own situation does not conform to a norm or expectation about happy relationships.This means that perceived social pressure might lead to misreported feelings or subjective assessments (DeMaio 1984).What underlines this assumption is also a selective trend in the general participation in studies about families and intimate relationships: People with happier and closer relationships within a family are more likely to participate in such surveys (Kalmijn 2021).

Items that assess relationship quality are subjective questions that require respondents to reflect on their behavior and feelings.Our indicators under study serve to assess the quality of an intimate relationship.However, they cover a broad range of domains in an intimate relationship, such as household task division, child care, feelings and doubts about the relationship, and ways of dealing with conflict.These different topics can seem more or less sensitive for the respondent, depending on the individual situation, especially when they touch on a sore point in a relationship.Due to the higher anonymity, we expect that web interviews support more open and probably more honest answer behavior.Further, the locus of control is up to the respondent, which may lead to a higher comfort level in answering unpleasant private questions.This means that the respondent can fill out the questionnaire at the time and place of their own choice -for example, when they are alone at home, so that interference by a third person, such as a partner, can be avoided.Therefore we expect a mode effect for indicators of relationship quality as follows: Respondents who participate in web mode provide more socially undesirable answers and higher levels of self-disclosure than face-to-face respondents.This means that web respondents should report a lower level of relationship quality and assess the relationship on average more negatively compared to respondents in a face-toface interview.Nevertheless, it is an open question as to what extent indicators on relationship quality display such a mode effect and to what extent they must be considered to be sensitive questions in the context of family research.


## Data and methods


## Experimental design and case selection

For answering our research question, we used data from an experimental pilot study within the framework of the GGP (Emery et al. 2018).The GGP is an international family demographic infrastructure that conducts the GGS.The GGS is fielded in many European and a few non-European countries and is designed as a three-wave panel study.The study focuses on families, intimate relationships, and life course trajectories of individuals (Gauthier, Cabaço, and Emery 2018).The GGP pilot study was conducted in Germany, in addition to two other countries, in 2018.The aim of the pilot study was to test whether a revised version of the GGS questionnaire and a new survey design work well in the field and whether the GGS can be conducted as a mixed-mode or online survey.A pushto-web design was applied and compared with the traditional GGS mode, which is faceto-face mode (Lugtig et al. 2022).Push-to-web design means that we conducted web interviews as we would have done in an entirely online survey but contacted nonrespondents again after the web fielding period and asked them to participate in a personal interview.For our research question, we concentrate on the web respondents of that group.The German pilot study carried out further experiments regarding the timing and amount of incentives.As variation in incentives may affect data quality and response behavior regarding sensitive questions (Medway 2012), we compared only groups that used identical incentives.Only in this way could we obtain an experimental setting that provided the same initial conditions for both groups, except the mode of conducting the interview, which serves as the treatment.

Respondents in the reference group participated in a CAPI, and respondents in the experimental group participated in a computer-assisted web interview (CAWI).Both the face-to-face group and the web group received the same Blaise-programmed GGS questionnaire in terms of question wording, routing, and design.Further, both groups received a prepaid incentive worth five euros.The target persons, aged 18-49, were selected with simple random sampling from local registry offices (Einwohnermeldeämter) in the German federal state of Bavaria, with a quota of 50% of addresses coming from rural areas and 50% of addresses coming from urban areas.The target persons were randomly assigned to the experimental groups.The size of the gross sample was calculated by the fieldwork institute on the basis of the expected response rate per mode.The aim was to achieve at least 200 cases per experimental group.Based on experience with other German surveys, the gross sample size of the face-to-face group was set lower because the response rate for the face-to-face mode was expected to be higher than for the web mode.

Both groups received an invitation letter with the unconditional incentive in it.For the face-to-face group, the letter announced that an interviewer would come to the household to conduct the interview.For the web group, a URL with a password was provided in the letter, and target persons were asked to go online and fill out the questionnaire on their own.The web group received also two reminder letters, each two weeks after the previous letter.Table 1 gives an overview of the design specifications and the case selection.The overall response rate was calculated according to Response Rate 1 following the AAPOR classification of standard definitions (AAPOR 2016).The response rate showed that we had a higher participation -by nearly 10 percentage points -in the face-to-face group.Both response rates are rather low, but other German social science surveys conducted face-to-face yield similar response rates (Wolf et al. 2021).Our research question focuses on the assessment of relationship quality in couples, so we only considered respondents in our analyses who reported that they had had a partner for at least three months.That is how the GGS measures partnership status.Only these respondents could actually answer questions regarding their current relationship.Table 1 gives an overview of the number of cases in the sample under study.It can be seen that the proportion of people in a relationship does not differ greatly between the two groups, with 76.0% of respondents having a partner in face-to-face mode and 77.6% of respondents having a partner in web mode.This corresponds closely to the proportion of persons with partners in other German studies about families and intimate relationships (Kantar Public 2018).By comparing the distribution of family demographic characteristics in the overall sample and our analytical sample, including only respondents with a partner, for each mode shown in Table 2, we see that slightly more women and fewer younger people have a partner.However, these tendencies are evident for both modes and can therefore be ignored.Generally, respondents in the web sample -irrespective of having a partner -are higher educated and more likely to live in urban areas compared to face-to-face respondents (see Table 2), which is consistent with existing research (e.g., Atkeson, Adams, and Alvarez 2014).


## Methodological approach and measurements


### Methodological approach

The design of the experimental study allows us to compare answering patterns in faceto-face mode and web mode to assess the overall impact of one mode compared to the other.We analyze 15 single items in the univariate analyses and six items in the multivariate regression analyses.All indicators under study relate to the construct of relationship quality.

In a first step, we apply a univariate approach and calculate means and proportions on item level to see how the mode affects point estimators.We test for mode-specific differences in the distributions with a two-sample t-test for mean differences and a Pearson- 2 -test for independence between categorical variables.Univariate comparisons should reveal initial ad hoc findings regarding the extent of distortion due to social desirability and self-disclosure in one mode as compared to the other.Further, surveys often use ex-post weighting to adjust for certain biases due to mode-specific selectivity, non-response bias, or coverage bias (Groves et al. 2004).Hence we additionally apply post-stratification weighting to evaluate whether the measurement equivalence between the univariate distributions of the two modes improves or not (Bethlehem and Stoop 2007;Schonlau and Couper 2017).For example, if more young people participate in web than in face-to-face mode, this may reduce the average duration of relationships in one mode, which might have a confounding effect on relationship quality.Therefore we adjust the entire sample according to population totals for specific demographic characteristics that are available from official German statistics (census and micro census) for our target population.As auxiliary variables for weighting, we use sex, age groups, highest level of education, nationality, and regional setting.Selective nonresponse can have many sources and might not be based exclusively on demographic characteristics (Schonlau, van Soest, and Kapteyn 2007), but we had to rely on the best information available from official statistics, which include only demographic information for our target population.A detailed list and the sources of information used for post-stratification weighting can be found in Table A-1 in the appendix.

In a second step, we pool the experimental and the reference group and apply multivariate regression analysis with mode as the explaining variable and a block-wise adjustment of further confounding variables to test whether the effect of mode is robust or not.Given that participation in surveys might be selective, regression analysis allows us to control for characteristics that correlate with selective participation in one mode.Indicators of relationship quality are treated as outcome variables and the mode of conducting the survey as a predictor variable.In the first baseline model, we estimate the crude mode effect on the respective indicator of relationship quality.In the second model, we include the same standard demographic variables we used for post-stratification weighting to adjust for selective participation.In the third model, we include additional family-related variables, which are often used as adjustment variables for relationship quality.We then examine whether a possible effect of the mode of data collection on the respective indicators of relationship quality changes between the models or whether the effect is robust after adjusting for further explanatory determinants.For the one binary dependent variable, which is the question whether or not the respondent had thought about breaking up, we calculate the linear probability model (LPM) because it facilitates the interpretation of estimates, especially when comparing coefficients across differently specified models.As a robustness check, we further apply logistic regression models and estimate average marginal effects (AME) that yield results similar to those from the linear probability approach (see Table A-4 in the appendix).For the other indicators, we perform linear ordinary least squares (OLS) regression models and show the estimated coefficients.


### Measurements

The items evaluated in our study are often used as predictors, mediators, and outcomes in substantive analyses in research about the quality of intimate relationships.They are included in many large-scale surveys about families and relationships, such as the GGS.

In the univariate approach, we examine 15 indicators of relationship quality separately to get an impression of mode effects on a broad variety of items that potentially display different effects.One item relates to subjective stability, three items relate to satisfaction, and the remaining 11 items relate to conflict frequencies and styles.Starting with subjective instability, we evaluate the question of whether the respondent has thought about breaking up with their partner.The binary indicator is coded with 0 for no and 1 for yes.Items on satisfaction are an often-used survey instrument to assess feelings and are mostly measured on point scales.The GGS questionnaire contains three satisfaction scales, which cover three different domains in intimate relationships.The question wording is: "How satisfied are you with the relationship in general, the division of household tasks, and the division of child care tasks."The answers have to be assessed separately on an 11-point scale, where 0 means very dissatisfied and 10 means very satisfied.A rating of 5 means medium satisfaction.The question on satisfaction with the division of household tasks was asked only to respondents who have a coresidential partner, and the question regarding satisfaction with the division of child care tasks was filtered for parents.All other questions on the various aspects of relationship quality, including those on conflicts, were asked to all respondents who have a partner, regardless of other criteria.

Whereas the first four indicators relate more to the level of feelings, the last indicators concern behavior in a relationship, specifically conflict behavior within the couple, differentiated into frequency of conflicts and conflict styles.For the univariate approach, we use seven single items regarding the frequency of conflicts on the following issues: household chores, money, leisure time, relations with friends, relations with parents, having children, and child-raising.The answer categories range from 1 (never) to 5 (very frequently).For the multivariate analysis, we generate one indicator for the frequency of conflicts within the couple in general, summarizing the information of these seven items to reduce complexity.Given that each single item measures the frequency of certain conflicts on the same scale, we are able to directly compare answer codes.Assuming that one relationship conflict will rarely touch several of the issues represented by the seven items at the same time and that the conflicts measured by the seven items have little overlap, we consider the addition of answer codes as an appropriate way of constructing such an indicator for frequency of conflict.Accordingly, we generate an additive index (Cronbach's α: .70),which ranges from 1 (no reported conflicts) to 29 (very frequently reported conflicts).It is recoded such that the more conflicts reported, the higher the value of the index.

Finally, we look at four single items that cover reactions in conflict situations.These items assess how often respondents avoid discussions by giving in, discuss conflicts calmly, argue heatedly or get loud, or refuse to talk.Here again, answers are coded from 1 (never) to 5 (very frequently).These conflict styles are also summarized into one indicator to reduce complexity for multivariate analyses.The indicator measures the tendency of choosing inadequate conflict behavior according to the social norms of a latemodern society in which it is expected that disagreements are resolved by rational exchange of arguments.Accordingly, we recode the item "discuss conflicts calmly" reversely and construct an additive index summing up all four items, which are all recoded so that the more inadequate the conflict behavior reported, the higher the score (Cronbach's α: .54).We are aware that, in this case, we are summarizing information from more heterogeneous items, so that the validity of the generated indicator is lower.Although Cronbach's α of the second index has a lower internal consistency, the scale is sufficient for our purposes to get an additive measure of inadequate conflict behavior.The index ranges from 1 (only inadequate conflict behavior reported) to 17 (only adequate conflict behavior reported).The original wording of all questions and answer categories can be found in Table A-2 in the appendix.

As control variables for the multivariate approach, we use the same demographic indicators as for the post-stratification weighting.Sex of a respondent is coded as 0 for male and 1 for female.For nationality we distinguish between 0 for German citizenship and 1 for non-German citizenship.Age is measured in years and ranges from 18 to 49. Education is measured dichotomously: 1 for highest education (college entry qualification) and 0 for lower/middle school education or less.Information on regional setting or community size was provided by the fieldwork institute and divides areas where respondents live into (1) urban areas and (2) rural areas.These background variables are not only used frequently as standard demographic controls; they can also affect participation in web mode (Vehovar et al. 2002).To control for family-related determinants, which often correlate with relationship quality, we include the variables relationship status and the existence of coresident children under age 6.We decided to choose an indicator for having children of younger ages because we assume that infants affect couples' daily lives more than older children, as they need more care and attention, often at the expense of the young parents' relationship quality and time.Additionally, parents of younger children have a lower level of mobility and available time, which can impact participation in the respective survey mode.As a sensitivity check, we also calculate models using an indicator for having children of any age as a control variable, and we find no differences in the identified mode effects.The measurement of relationship status distinguishes between respondents who are married to their current partner, irrespectively of cohabitation (1); respondents who live together with their partner without being married (2); and respondents who have a partner but are not living in cohabitation or marriage with that partner (living apart together; 3), often in longdistance relationships.The other indicator distinguishes between "at least one child under six years living most of the time in the same household with the respondent" (1) versus "no children under six years living in the same household with the respondent" (0).Unfortunately, information about the duration of the current relationship is unavailable in the GGS.


## Results


## Univariate analyses

We start with a look at the univariate distributions of the indicators of relationship quality in the two experimental groups to examine whether the mode of conduction affects point estimators under the two experimental conditions.The distributions for all 15 single indicators of interest are shown in Table 3. Respondents using the web report higher shares of socially undesirable answers than do face-to-face respondents for almost all items under study.a Reference category is "not thought about breakup."b From 0 (very dissatisfied) to 10 (very satisfied).c From 1 (never) to 5 (very frequently).d From 1 (never) to 5 (very frequently).

Notes: F2F = face-to-face; ∆ = mode difference (in bold); 95% confidence intervals in parentheses.

Source: GGP pilot study 2018; authors' own calculations.

When we take the different content dimensions of the indicators into account, we can see that especially those items that concern feelings, such as satisfaction and the perceived stability of a relationship, display stronger mode differences.Based on these univariate findings, more than 17% of web respondents -nearly twice as many respondents as in face-to-face mode, with 9% -confirm that they have thought about breaking up with their current partner.Correspondingly, web respondents rate their general relationship satisfaction nearly 0.5 points lower on an 11-point-scale than do faceto-face respondents.The same is true for satisfaction with daily routines in a relationship, like the division of child care and household tasks.For the content-specific frequencies of conflicts as well as for the different conflict styles, most items show mode differences, with a higher reported frequency of conflicts and inappropriate conflict behavior in online interviews compared to face-to-face, but with varying magnitudes of mode differences between the single conflict items.The item on the frequency of conflicts regarding having children shows a very small and therefore negligible mode difference in the opposite direction.One explanation might be that a majority of the respondents already have children, so this topic was not leading to conflicts between parents anymore.The rather aggressive conflict behavior "argue heatedly or get loud" shows larger mode differences, whereas the comparably modest conflict style "avoid discussion by giving in" reveals almost no difference between the modes.Because avoiding a discussion might not be a socially undesirable way of dealing with your partner, this conflict behavior is not as clearly indicative of a bad conflict style as the others.

With the help of post-stratification weighting by adjusting sample distributions to the reference distributions of our target sample, we try to control for biases due to selective participation.The weighted distributions of the indicators of relationship quality are very similar, however (see Table A-3 in the Appendix).This emphasizes that ex-post weighting by the demographic indicators for which reference data are available cannot adjust for the mode-specific differences for our items under study.


## Multivariate analyses

We continue to use unweighted data for our analysis, as mode differences were the same for unweighted data and for ex-post weighted data.We estimate three models for each of our six outcome variables: a baseline model without control variables, a second model with our demographic confounder variables, and a third model with all demographic and family-related control variables.Figure 1 displays the effect of web mode on each indicator of relationship quality separately compared to the reference face-to-face mode.Because the focus of this study lies in the evaluation of the mode effect, we refrain from showing the regression results of the control variables.The regression tables of the mode effects can be found in Table A-4 (see Appendix).As described in the methodology section, the single items for frequency of conflict and conflict styles are summed up to two indexes.For each indicator, the effect of web mode is shown -first as a single effect in a baseline model; second adjusted by standard demographic variables, which should control for selective participation; and third under additional adjustment of family-related confounders.The size of mode effects can be compared only across models of the same outcome variable, not between different outcome variables.The multivariate findings in Figure 1 confirm that the effect of web mode is robust for all indicators on relationship quality even when we adjust for demographic and family-related variables.By comparing the effect of web mode across the three different models for one indicator, we see that the effect is either stable across the models or slightly increases.Therefore we focus on reporting the findings based on the third model, including demographic and family-related control variables.

Starting with the indicator on subjective instability, the estimated coefficients based on LPM show that respondents in web mode have a probability of reporting that they thought about a separation that is 9.4 percentage points higher than the probability for respondents who were asked this question in a face-to-face interview.This means that respondents in the more anonymous web mode are more likely to report that they have thought about breaking up with their current partner than respondents interviewed in a personal interview.The second indicator frequently used for measuring general relationship quality is overall satisfaction with the relationship.The results confirm the univariate findings: Even under control of demographic and family-related variables, respondents in web mode rate their satisfaction with the relationship about 0.5 points lower on an 11-point scale than respondents in face-to-face interviews.The same pattern can be seen for the reporting of satisfaction with specific domains, such as household tasks and child care.Respondents in web mode assess their satisfaction with household tasks more than 0.6 scale points lower than respondents in face-to-face mode.Results are similar for the assessment of satisfaction with child care tasks: Online respondents rate their satisfaction about 0.5 scale points lower on a scale from 0 to 10 than face-to-face respondents.As can be seen in Figure 1, the confidence interval of the mode effect on satisfaction with child care touches the zero line slightly, which might be explained by the low number of persons who answered this question, as this item was posed only to respondents who have children.

Apparently, feelings and thoughts about the relationship are assessed more negatively in web mode than in face-to-face mode, which speaks for a higher level of self-disclosure and less socially desirable answers in web surveys.In other words, the findings support the assumption that respondents in web interviews are more likely to report that they are less satisfied with their current relationship and are more likely to doubt the stability of the relationship.

The last two indicators focus on the assessment of behavior.For the indicators frequency of conflicts and conflict styles, we find a higher reporting of conflicts and inappropriate conflict behavior in web mode compared to face-to-face mode.The reporting of the number of conflicts on various topics increases by 1.3 points on a scale from 1 to 29 when respondents answer in web mode compared to face-to-face mode.The effect is similar for the reporting of inappropriate conflict behavior: Compared to respondents in a personal interview, respondents who participate in a web survey report a 0.7 scale points higher level on a scale from 1 to 17.

In summary, regarding the reporting of feelings as well as behavior, web respondents show a consistently higher socially undesirable response behavior than respondents in face-to-face interviews.Considering all indicators of relationship quality examined in this study, respondents in web mode assess their relationships more negatively than those in face-to-face mode.


## Discussion

Our analyses use experimental survey data to assess the existence and the extent of a mode effect when comparing two particularly different modes of data collection, web mode and face-to-face mode, on measurements of relationship quality in surveys about families and relationships.Our findings show clear differences for almost all indicators that assess various aspects of the quality of intimate relationships between respondents interviewed in a traditional face-to-face design and respondents who participate in selfadministered web interviews.Web respondents are more likely to state that they thought about breaking up.They assess a lower relationship satisfaction in general as well as with respect to the distribution of household chores and child care responsibilities.And they report more conflicts in their partnership as well as higher shares of aggressive or nonconstructive conflict behavior.These indicators not only cover different content-related aspects in the context of intimate relationships, but they also rely on a broad range of subjective assessments, such as feelings, behavioral patterns, and experiences.All in all, respondents who participated in web mode report a lower quality in intimate relationships.These effects are robust, as they remain stable after controlling for demographic and family-related confounders that correlate with relationship quality and survey participation.

Our results support the assumption that the anonymous and private interview situation of web surveys, compared to traditional face-to-face surveys, leads to a smaller subjectively perceived exposure to social desirability, thereby impacts the responses of interviewees, reduces bias due to social desirability responding, and thus improves the validity of measurements.According to our expectations, web respondents give more socially and normatively undesirable answers and report a less rosy picture of their partnership life than do face-to-face respondents.Further, the findings could indicate that respondents who participate online have a higher willingness to self-disclose than respondents who are confronted with an interviewer, which is in line with existing research (Robertson et al. 2018;Burkill et al. 2016).One could assume that measurements on relationship quality conducted in web surveys show a more realistic picture of today's couple relationships than those conducted face-to-face.

The findings further indicate that the assessment of relationship quality must be considered as highly sensitive and generally biased by effects of social desirability -in web mode to a lesser degree than in an interviewer-administered mode.However, we cannot prove for a general underreporting of sensitive behavior as we have no reference value of the real situation and can assess only differences in answer behavior between two modes of data collection.This result of relationship quality being a sensitive topic in surveys is relevant in particular for studies about intimate relationships, because surveys in this context are, for the same reason, confronted with the risk of selection biases toward happier and closer relationships (Kalmijn 2021).One can assume that respondents who are actually less satisfied with their relationship and unhappy with their partner tend to be generally underrepresented in a family survey and are therefore of particular interest.

Depending on the individual situation, some aspects in an intimate relationship might score higher on sensitivity than others and cause gradually stronger biases based on social desirability.As shown in our descriptive findings, single items on conflictual behavior differ in their magnitude of mode differences, which might indicate that the according behaviors are perceived as differently strongly undesirable.For example, refusal to talk may be less undesirable than aggressive and potentially threatening conflict behavior.At the same time, we can assume that similar mode effects would be found for most subjective perceptions and evaluations in other research topics within family demography and beyond; many such indicators might be perceived as sensitive by respondents, as they may expect the interviewer or others to have certain opinions and according expectations regarding an acceptable answer.The more plausible that regarding a certain subjective question, a social norm exists, the more likely it is that such an indicator will be biased by effects of social desirability and affected by mode effects.

In our study, we use two extremes of interviewer involvement as an experimental design to sensitize primary researchers as well as data users about the impact of a design decision on data.Nevertheless, there are also mixed-mode designs or hybrid modes of conducting interviews that can be placed on a gradient between face-to-face mode and web mode, such as CASI modules applied within a personal questionnaire, and these could improve measurement equivalence.A limitation of this study is therefore that it remains an open question as to whether the anonymous setting of the web is decisive for the higher degree of disclosure and lower degree of social desirability or whether the presence of an interviewer or other bystanders might be compensated for by a CASI switch.Even if one could assume less socially desirable answer behavior in CASI than in a face-to-face interview, experimental studies show that web interviews reveal the highest degree of self-disclosure for sensitive questions compared to other selfadministered modes (Burkill et al. 2016;Kreuter, Presser, and Tourangeau 2008).Nevertheless, CASI switches should be used more frequently in personal interviews with intimate and subjective questions, such as those on relationship quality, when a web interview is not possible.

Another limitation is that our experimental study relied on a small number of cases due to budget constraints, as is the case for most experimental studies.Due to the low number of observations, detailed analyses with subgroups differentiated by gender or age could not be carried out.Thus the methodological approach remained limited.It would be imaginable that, for example, women would be less affected by biases due to social desirability and mode effects than men, since women generally report lower relationship qualities and tend to break up relationships more often than men do.It would be imaginable that parents may be more affected by mode effects than people in childless relationships since maintaining a stable relationship may be more strongly socially desired if a child is involved.However, such assumptions require further investigation.

While the results in detail must thus be interpreted with caution, the mode effects nevertheless proved robust and revealed a stable pattern across several indicators, which allows us to consider our main findings reliable.It would be highly valuable for family research to analyze whether the measurement of the impact of relationship quality on substantive outcomes, such as breakups or divorces, is also affected by the mode.Unfortunately, this could not be tested in our study due to small case numbers and lack of a longitudinal design.

We conclude that data users should be aware of the need to control for the mode of data collection when analyzing data on relationship quality collected in different modes, especially when self-administered as well as interviewer-administered modes are involved.It is important not only to assess data for the representativeness of sociodemographic indicators and, if necessary, weight the data and adjust for these indicators in multivariate analyses but also to control and check for interactions with the survey mode when analyzing the data.Particularly when surveys are changing from faceto-face mode to web or mixed mode, due to adaption to the COVID-19 pandemic or simply due to cost-efficiency, data users should take the mode of conducting interviews into account.This is especially relevant when central variables measure subjective and sensitive assessments and are prone to social desirability bias.Otherwise, researchers can run the risk of confounding mode effects with substantive effects -for example, in terms of cross-national differences or change over time.


## Acknowledgments

This project was funded by the Horizon 2020 Research and Innovation Programme under grant agreement 739511 for the project Generations and Gender Programme: Evaluate, Plan, Initiate and by the Federal Institute for Population Research (BiB) in Wiesbaden, Germany, to co-finance the German data collection.

We would like to thank the GGP pilot team (Tom Emery, Susana Cabaço, Peter Lugtig, Vera Toepoel, Martin Bujard, and Robert Naderi) for designing and conducting the pilot study, as well as Tobias Gummer, Karsten Hank, Sandra Krapf, and two anonymous reviewers for their helpful comments and suggestions, which assisted us greatly.a Reference category is "not thought about breakup."b From 0 (very dissatisfied) to 10 (very satisfied).c From 1 (never) to 5 (very frequently).

d From 1 (never) to 5 (very frequently).

Notes: F2F = face-to-face; ∆ = mode difference (in bold); 95% confidence intervals in parentheses.

Source: GGP pilot study 2018; authors' own calculations.

## Figure 1 :
1
Figure 1: Effect of web mode on indicators of relationship quality with 95% confidence intervals under block-wise adjustment of demographic and family-related control variables


## Table 1 : Overview of the experimental design and case selection
1Reference groupExperimental groupMode of data collectionFace-to-face (CAPI)Web (CAWI)Country where conductedGermanyGermanyTarget population18-49 years old18-49 years oldIncentivesFive prepaid eurosFive prepaid eurosMaximum number of contactsInvitation letter + five personal contact attemptsInvitation letter + two reminder lettersGross sample6851,365Net sample193261Response rate in %29.519.4Respondents with a partner146197Respondents with a partner in %76.077.6
Source: GGP pilot study 2018; authors' own calculations.


## Table 2 : Family demographic distributions (in percent) for all respondents in the entire sample and for only respondents with a partner in the sample under study
2Face-to-faceWebAll respondentsOnly respondents with aAll respondentsOnly respondents with apartnerpartnerN (observations)192146254197SexMale47.9242.4747.2445.69Female52.0857.5352.7654.31EducationLow25.5221.9212.9014.66Middle26.0428.0833.0635.60High48.4450.0054.0349.74Age18-2937.7025.5230.6823.7130-3929.3235.8632.2732.9940-4932.9838.6237.0543.30CitizenshipGerman88.0287.6788.5487.76Non-German11.9812.3311.5612.24Regional settingUrban39.5841.1054.3351.78Rural60.4258.9045.6748.22Child under 6 inhouseholdNo60.9451.3766.9357.87Yes39.0648.6333.0742.13Relationship statusMarried62.3362.3369.7969.79Cohabiting24.6624.6617.1917.19Living apart together13.0113.0113.0213.02Source: GGP pilot study 2018, authors' own calculations.

## Table 3 : Means of indicators or percentage of confirmative answers by mode of data collection with 95% confidence intervals
3F2FWebMode differenceF2FWebMean or percentage∆nSubjective instability aThought about breaking up (in %)8.9717.138.16145181(5.27-14.86)(12.30-23.35)Satisfaction bGeneral relationship9.118.63-0.48145190(8.91-9.31)(8.43-8.82)Household tasks8.467.90-0.56127166(8.19-8.73)(7.59-8.20)Child care tasks8.668.11-0.557081(8.28-9.03)(7.73-8.50)Conflict frequency cHousehold chores2.312.450.14146196(2.13-2.48)(2.31-2.59)Money1.661.970.31146195(1.53-1.79)(1.83-2.12)Leisure time2.232.390.16146196(2.07-2.38)(2.26-2.51)Relations with friends1.501.690.19145196(1.39-1.61)(1.57-1.81)Relations with parents1.671.850.18146195(1.53-1.81)(1.72-1.99)Having children1.301.28-0.02145192(1.17-1.42)(1.18-1.38)Child-raising issues1.801.940.14142182(1.64-1.96)(1.80-2.08)Conflict style dAvoid discussion by giving in2.612.660.05132184(2.45-2.77)(2.53-2.79)Discuss conflicts calmly4.063.86-0.19136180(3.91-4.21)(3.72-4.00)Argue heatedly or get loud1.882.130.25136186(1.75-2.02)(2.00-2.25)Refuse to talk1.741.880.14136183(1.57-1.90)(1.75-2.01)

## Table A -3: Post-stratification weighted means of indicators or percentage of confirmative answers by mode of data collection
AF2FWebModeF2FWebdifferenceMean or percentage∆nSubjective instability aThought about breaking up (in %)6.2814.498.21144(3.53-10.93)(9.55-21.40)Satisfaction bGeneral relationship9.158.71-0.44144(8.96-9.35)(8.48-8.94)Household tasks8.477.88-0.59126(8.16-8.78)(7.50-8.25)Child care tasks8.638.24-0.3970(8.24-9.02)(7.78-8.69)Conflict frequency cHousehold chores2.302.420.12145(2.12-2.49)(2.26-2.57)Money1.682.050.37145(1.52-1.83)(1.85-2.26)Leisure time2.252.380.13145(2.06-2.44)(2.22-2.54)Relations with friends1.521.710.19144(1.39-1.65)(1.55-1.86)Relations with parents1.681.840.16145(1.52-1.83)(1.69-2.00)Having children1.301.230.07144(1.16-1.44)(1.14-1.33)Child-raising issues1.811.890.08141(1.63-2.00)(1.70-2.08)Conflict style dAvoid discussion by giving in2.712.67-0.04131(2.53-2.91)(2.50-2.84)Discuss conflicts calmly4.033.95-0.08135(3.85-4.20)(3.78-4.12)Argue heatedly or get loud1.912.060.15135(1.77-2.05)(1.88-2.23)Refuse to talk1.711.830.12135(1.55-1.87)(1.67-1.99)

## Table A -4: (Continued)
AModel 1:Model 2:Model 3:BaselineDemographicDemographiccontrolsand family-related controlsSatisfaction child careLinear regression modelsCoef.SECoef.SECoef.SEMode (Ref: Face-to-face)Web-0.5460.272-0.5260.270-0.5080.270(-1.083 --0.009)(-1.060 --0.007)(-1.042 -0.027)n151149149df167R 2.03.11.11Adjusted R 2.02.07.07
https://www.demographic-research.org
AcknowledgmentsReferences AppendicesAppendices
The American Association for Public Opinion Research Survey Outcome Rate Calculator 4.1 [electronic resource. Aapor, Resources/For-Researchers/Poll-Survey-FAQ/Response-Rates-An-Overview.aspx. 2016

Telephone versus face-to-face interviewing for household drug use surveys. W S Aquilino, 10.3109/10826089109063463International Journal of the Addictions. 2711991

Effects of similarity of life goals, values, and personality on relationship satisfaction and stability: Findings from a two-wave panel study. O Arránz-Becker, 10.1111/j.1475-6811.2012.01417.xPersonal Relationships. 202013

Nonresponse and mode effects in selfand interviewer-administered surveys. L Atkeson, A Adams, R Alvarez, 10.1093/pan/mpt049Political Analysis. 2232014

Handbook of web surveys. J Bethlehem, S Biffignandi, 10.1002/97811181217572012WileyHoboken

The challenges of a changing world. J Bethlehem, I Stoop, Proceedings of the Fifth ASC International Conference. M Trotman, the Fifth ASC International ConferenceBerkeleyAssociation for Survey Computing2007. September 2007University of SouthamptonOnline panels -A paradigm theft?

K Beullens, G Loosveldt, C Vandenplas, I Stoop, 10.13094/SMIF-2018-00003Response rates in the European Social Survey: Increasing, decreasing, or a matter of fieldwork efforts? Survey Methods: Insights from the Field. 2018

Research on the nature and determinants of marital satisfaction: A decade in review. T N Bradbury, F D Fincham, S R H Beach, 10.1111/j.1741-3737.2000.00964.xJournal of Marriage and the Family. 6242000

Comparing web-based versus face-toface and paper-and-pencil questionnaire data collected through two Belgian health surveys. E Braekman, R Charafeddine, S Demarest, S Drieskens, F Berete, L Gisle, J Van Der Heyden, G Van Hal, 10.1007/s00038-019-01327-9International Journal of Public Health. 652020

Using the web to collect data on sensitive behaviours: A study looking at mode effects on the British National Survey of Sexual Attitudes and Lifestyles. S Burkill, A Copas, M P Couper, S Clifton, P Prah, J Datta, F Conrad, K Wellings, A M Johnson, B Erens, 10.1371/journal.pone.0147983PLoS ONE. 1122016

Social desirability. M Callegaro, Encyclopedia of survey research methods. P J Lavrakas, Thousand Oaks; Sage2008

Comparing oral interviewing with self-administered computerized questionnaires: An experiment. L Chang, J A Krosnick, 10.1093/poq/nfp090Public Opinion Quarterly. 7412010

Effect of survey mode on response patterns: Comparison of face-to-face and self-administered modes in health surveys. A I Christensen, O Ekholm, C Glümer, K Juel, 10.1093/eurpub/ckt067European Journal of Public Health. 2422013

The future of modes of data collection. M P Couper, 10.1093/poq/nfr046Public Opinion Quarterly. 7552011

Mobile web surveys. M P Couper, C Antoun, A Mavletova, P P Biemer, E D De Leeuw, S Eckman, B Edwards, F Kreuter, L E Lyberg, N C Tucker, West , 10.1002/9781119041702.ch7Total survey error in practice. B T , New JerseyWiley2017

Web versus other survey modes: An updated and extended meta-analysis comparing response rates. J Daikeler, M Bošnjak, K L Manfreda, 10.1093/jssam/smz008Journal of Survey Statistics and Methodology. 832020

Interviewer effects in public health surveys. R E Davis, M P Couper, N K Janz, C H Caldwell, K Resnicow, 10.1093/her/cyp046Health Education Research. 2512010

International handbook of survey methodology. E D De Leeuw, J Hox, D Dillman, 2008Psychology PressNew York

Social desirability and survey measurement: A review. T J Demaio, Surveying subjective phenomena. C F Turner, E Martin, New YorkRussel Sage Foundation19842

The Generations and Gender Programme: Evaluate, plan, initiate (Deliverable 2.1: GGP Technical Case and E-Needs). T Emery, S Cabaço, P Lugtig, V Toepoel, D Lück, R Naderi, M Bujard, A Schumann, 10.31235/osf.io/439wc2018

The Cambridge handbook of personal relationships. F D Fincham, S R H Beach, 10.1017/CBO9780511606632.032Vangelisti, A.L. and Perlman, D.2006Cambridge University PressCambridgeRelationship satisfaction

Measuring the extent of abortion underreporting in the 1995 National Survey of Family Growth. H Fu, J E Darroch, S K Henshaw, E Kolb, 10.2307/2991627Family Planning Perspectives. 3031998

Generations and Gender Survey study profile. A H Gauthier, S L F Cabaço, T Emery, 10.14301/llcs.v9i4.500Longitudinal and Life Course Studies. 942018

R M Groves, F J Fowler, M P Couper, J M Lepkowski, E Singer, R Tourangeau, Survey methodology. New JerseyWiley2004

Is there a growing use of mobile devices in web surveys? Evidence from 128 web surveys in Germany. T Gummer, J K Höhne, T Rettig, J Roßmann, M Kummerow, 10.1007/s11135-022-01601-8Quality and Quantity. 2023

The impact of COVID-19 on fieldwork efforts and planning in pairfam and FReDA-GGS. T Gummer, C Schmiedeberg, M Bujard, P Christmann, K Hank, T Kunz, D Lück, F J Neyer, 10.18148/srm/2020.v14i2.7740Research. 1422020Methods

Mode differences between face-to-face and web-surveys: An experimental investigation of data quality and social desirability effects. K Gustavson, W Nilsen, R Ørstavik, E Røysamb, 10.1093/ijpor/edn054doi:10.1093/ ijpor/edn054International Journal of Public Opinion Research. Heerwegh, D.922013. 2009The Journal of Positive Psychology

Face-to-face versus web surveying in a highinternet-coverage population. Differences in response quality. D Heerwegh, G Loosfeldt, 10.1093/poq/nfn045Public Opinion Quarterly. 7252008

Telephone versus face-to-face interviewing of national probability samples with long questionnaires. A L Holbrook, M C Green, J A Krosnick, 10.1086/346010Public Opinion Quarterly. 6712003

Relationship satisfaction across the transition to parenthood: The impact of conflict behavior. B Huß, M Pollmann-Schult, 10.1177/0192513X19876084Journal of Family Issues. 4132020

Are national family surveys biased toward the happy family? A multi-actor analysis of selective survey nonresponse. M Kalmijn, 10.1177/0049124120986208Sociological Methods and Research online. first2021

Beziehungen und Familienleben in Deutschland (pairfam). 2018. 2017/2018Kantar PublicMethodenbericht Welle 10

The longitudinal course of marital quality and stability. B R Karney, T N Bradbury, 10.1037/0033-2909.118.1.3Psychological Bulletin. 11811995

Research on marital satisfaction and stability in the 2010s: Challenging conventional wisdom. B R Karney, T N Bradbury, 10.1111/jomf.12635Journal of Marriage and Family. 8212020

Social desirability bias in sexual behavior reporting: Evidence from an interview mode experiment in rural Malawi. C A Kelly, E Soler-Hampejsek, B S Mensch, P C Hewett, 10.1363/3901413International Perspectives on Sexual and Reproductive Health. 3912013

Conflict frequency and relationship quality across the transition to parenthood. E S Kluwer, M D Johnson, 10.1111/j.1741-3737.2007.00434.xJournal of Marriage and Family. 6952007

Social desirability bias in CATI, IVR, and web surveys. The effects of mode and question sensitivity. F Kreuter, S Presser, R Tourangeau, 10.1093/poq/nfn063Public Opinion Quarterly. 7252008

Determinants of social desirability bias in sensitive surveys: A literature review. I Krumpal, 10.1007/s11135-011-9640-9Quality Quantity. 472013

The problems of researching sensitive topics: An overview and introduction. R M Lee, C M Renzetti, 10.1177/0002764290033005002American Behavioral Scientist. 3351990

Theorizing about the quality and stability of marriage. R A Lewis, G B Spanier, Contemporary theories about the family. W R Burr, R F Hill, I Nye, I L Reiss, New YorkFree Press1979

Data collection mode differences between national face-to-face and web surveys on gender inequality and discrimination questions. M Liu, 10.1016/j.wsif.2016.11.007Women's Studies International Forum. 602017

Interviewer gender effects on survey responses to marriage-related questions. M Liu, K Stainback, 10.1093/poq/nft019Public Opinion Quarterly. 7722013

Comparison of face-to-face and web surveys on the topic of homosexual rights. M Liu, Y Wang, 10.1080/00918369.2015.1112587Journal of Homosexuality. 6362016

Can we successfully move a cross-national survey online? Results from a large three-country experiment in the Gender and Generations Programme Survey. P Lugtig, V Toepoel, T Emery, S L F Cabaço, M Bujard, R Naderi, A Schumann, D Lück, 10.31235/osf.io/mu8jySocArXiv. 2022

Beyond response rates: The effect of prepaid incentives on measurement error. R Medway, 2012MarylandUniversity of MarylandPhD thesis

The influence of partner relationship quality on fertility. A J Rijken, A C Liefbroer, 10.1007/s10680-008-9156-8European Journal of Population. 252009

Estimates of nonheterosexual prevalence: The roles of anonymity and privacy in survey methodology. R E Robertson, F W Tran, L N Lewark, R Epstein, 10.1007/s10508-017-1044-zArchive of Sexual Behavior. 472018

Changes in employment and relationship satisfaction in times of the COVID-19 pandemic: Evidence from the German family Panel. L Schmid, J Wörn, K Hank, B Sawatzki, S Walper, 10.1080/14616696.2020.1836385European Societies. 232021sup1: European Societies in the Time of the Coronavirus Crisis

Options for conducting web surveys. M Schonlau, M P Couper, 10.1214/16-STS597Statistical Science. 3222017

Are 'Webographic' or attitudinal questions useful for adjusting estimates from web surveys using propensity scoring?. M Schonlau, A Van Soest, A Kapteyn, 10.2139/ssrn.1006108Survey Research Methods. 132007

Selection bias in web surveys and the use of propensity scores. M Schonlau, A Van Soest, A Kapteyn, M P Couper, 10.1177/0049124108327128Sociological Methods and Research. 2732009

Effects of partner presence during the interview on survey responses: The example of questions concerning the division of household labor. J Schröder, C Schmiedeberg, 10.1177/0049124120914938Sociological Methods and Research online. first2020

Presidential address. Paradoxes of nonresponse. R Tourangeau, 10.1093/poq/nfx031Public Opinion Quarterly. 8132017

Asking sensitive questions. The impact of data collection mode, question format, and question context. R Tourangeau, T W Smith, 10.1086/297751Public Opinion Quarterly. 6011996

Sensitive questions in surveys. R Tourangeau, T Yan, 10.1037/0033-2909.133.5.859Psychological Bulletin. 13352007

Spousal resources and relationship quality in eight European countries. M Van Damme, P Dykstra, 10.1080/13668803.2018.1526776Community, Work and Family. 2152018

Nonresponse in web surveys. V Vehovar, Z Batagelj, K L Manfreda, M Zaletel, Survey Nonresponse. R M Groves, D A Dillman, J L Eltinge, R J A Little, New YorkWiley2002

Strangers in the field: A methodological experiment on interviewer-respondent familiarity. A Weinreb, M Sana, G Stecklov, 10.1177/0759106318761562Bulletin of Sociological Methodology/Bulletin de Méthodologie Sociologique. 13712018

Relationship quality in marital and cohabiting unions across Europe. K A Wiik, R Keizer, T Lappegard, 10.1111/j.1741-3737.2012.00967.xJournal of Marriage and Family. 7432012

Conducting general social surveys as self-administered mixed-mode surveys. C Wolf, P Christmann, T Gummer, C Schnaudt, S Verhoeven, 10.1093/poq/nfab039Public Opinion Quarterly. 8522021