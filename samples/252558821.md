# A Review on Machine Learning Styles in Computer Vision-Techniques and Future Directions

CorpusID: 252558821
 
tags: #Computer_Science

URL: [https://www.semanticscholar.org/paper/59694d8b594ac2bb0f91dd4a0d681133f976939a](https://www.semanticscholar.org/paper/59694d8b594ac2bb0f91dd4a0d681133f976939a)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | True |
| By Annotator      | (Not Annotated) |

---

A Review on Machine Learning Styles in Computer Vision-Techniques and Future Directions


Supriya V Mahadevkar 
Symbiosis International (Deemed University)
Symbiosis Institute of Technology
412115PuneIndia

Bharti Khemani 
Symbiosis International (Deemed University)
Symbiosis Institute of Technology
412115PuneIndia

Shruti Patil 
Symbiosis Centre for Applied Artificial Intelligence
Symbiosis International (Deemed University)
Symbiosis Institute of Technology
412115PuneIndia

Ketan Kotecha 
Symbiosis Centre for Applied Artificial Intelligence
Symbiosis International (Deemed University)
Symbiosis Institute of Technology
412115PuneIndia

Deepali R Vora 
Symbiosis International (Deemed University)
Symbiosis Institute of Technology
412115PuneIndia

Ajith Abraham 
Machine Intelligence Research Laboratories (MIR Laboratories)
98071AuburnWAUSA

AND LUBNAAbdelkareim Gabralla 
Department of Computer Science and Information Technology
College of Applied
Princess Nourah Bint Abdulrahman University
11671RiyadhSaudi Arabia

A Review on Machine Learning Styles in Computer Vision-Techniques and Future Directions
10.1109/ACCESS.2022.3209825Received 26 August 2022, accepted 16 September 2022, date of publication 26 September 2022, date of current version 13 October 2022.Corresponding author: Shruti Patil (shruti.patil@sitpune.edu.in)


## I. INTRODUCTION

Machine learning is a type of artificial intelligence (AI) that trains computers to think like humans by learning from and expanding upon previous experiences. It employs minimal VOLUME 10, 2022 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ human intervention to analyze data and spot trends. Machine learning has a wide range of effects on society, including production lines, healthcare, education, transportation, and food [1]. Machine learning is transforming our lives and industries in housing and apps, cars, retail, the food industry, etc. The goal of machine learning and computer vision is to impart to computers the ability to gather data, understand it, and make decisions based on previous and present results. Computer vision is important for the Internet of Things, Industrial Internet of Things, and human cognitive interfaces. Computer vision and machine learning techniques are used to identify and track complex human actions in multimedia streams. For the prediction and analysis task of data, there are three types of learning: supervised, unsupervised, and semisupervised [2].

The ability of computers to gather data, interpret it and make decisions based on past and present results is the aim of machine learning and computer vision. Computer vision is essential for the Internet of Things, Industrial Internet of Things, and human cognitive interfaces. Computer vision and machine learning techniques are used to identify and track complex human actions in multimedia streams. The image segmentation, localization & classification, and object detection are shown in the figure1. The authors have outlined the application areas of computer vision in the figure 4. They have listed which machine learning techniques and Python Libraries have been employed in each field.

An essential method of image processing that examines the contents of the image is segmentation. Image segmentation can be used for pattern recognition, feature extraction, content-based image retrieval, etc. Image segmentation is an important process in most medical image analysis. K-means is a widely used clustering algorithm to partition data into k clusters. The K-means and fuzzy K-means clustering algorithms can be used to identify tumor cells in MR images that may show the characteristics of the tumor's severity, facilitating the necessary diagnosis and therapy. There are numbers of well-established algorithms for prediction and analysis such as supervised learning, un-supervised learning, and semi supervised learning. These methods use the machine learning algorithms such as support vector machine, KNN etc. Scipy, Scikit, OpenCV, Matplotlib and Keras are the popular are libraries used for image segmentation.

For object detection previously sliding window, selective search and Kadane's algorithms were used but now most of the application areas uses deep learning algorithms like RCNN,YOLO,SSD for object detection in CV. The software libraries utilized in object detection for computer vision are Tensor Flow, ImageAI, GluonCV and YOLOv7. Convolution neural networks, recurrent neural networks, long short-term memories, gated recurrent units, and Bayesian networks are all used in traffic detection models. Sensors in intelligent settings collect data that is later analyzed and forecasted. One of the tasks the convolution neural network (CNN) successfully completes for successful object detection is feature extraction [3]. With a big collection of face photos, a deep convolution neural network can recognize faces through supervised learning. Data annotation and labeling is the only problem in computer vision and machine learning applications. The support vector machines, neural networks, KNN and probabilistic graphical models machine learning paradigms for computer vision. A common classification technique is support vector machines (SVMs), a subfield of supervised machine learning techniques. With a maximum margin separating two significant classifed classes, SVMs seek to locate a hyperplane [4]. Layered networks of connected processing nodes make up a neural network. A class of neural networks called convolution neural networks (CNNs) is utilized for image recognition and categorization. It has neurons that are wide, large, and deep. Due to widely available datasets, GPUs, and regularization approaches, CNN has become more and more popular in recent years.

The paper looks at a variety of machine learning applications in computer vision. For instance, biological sciences include segmentation, feature extraction, pattern matching, visual model optimization, form representation, surface reconstruction, and modeling. Computer vision uses machine learning to evaluate data from images that detect cars and pedestrians, using images to analyze remote sensing data for geographic information systems, diagnose faults in railroad ties automatically, identify different varieties of mango fruit based on size attributes, and extract graphical and textual information from document images [5]. Detecting curb ramps in Google Street View, automatically detecting and identifying faces, machine vision, handwriting recognition, enhanced driving assistance systems, and behavioral measures are some of the other techniques. Computer vision and machine learning are also used in the medical field, especially in nuclear medicine, endoscopy, angiography, magnetic resonance, ultrasound, and microscopy, according to studies in this field. Engineering, health, agriculture, astronomy, sports, cyber security, and education are among the many fields where machine learning and computer vision are used [6].


## A. MOTIVATION

There is no systematic literature review (SLR) for machine learning styles used in computer vision focuses on methodology, datasets, application areas, comparative analysis, and future directions. The existing literature lacks a comprehensive survey focused on evolution of each ML style with its architecture, CV applications, research gaps and future directions.

The table 1 and figure 4 shows how few papers have dealt with datasets. The same datasets are available; however, each one only has a specific amount of data. Different machine learning styles are used in almost every application, such as Cyber security, Object detection, Spam detection, Health Care sector, Agriculture, etc. So, based on the above literature, we suggested when and where to use a particular machine learning style. The main goal of this review is to highlight current strategies, datasets that are accessible, applications, difficulties, and potential future directions of various machine learning approaches used in computer vision. In the last section this survey describes the current research gaps with the possible ML styles as solution and the future directions in the field of computer vision.


## B. CONTRIBUTION OF WORK

The contributions of this comprehensive literature review are as follows:

• The authors comprehensively review the literature on ML styles in computer vision, emphasizing methodology, datasets, applications, associated problems, and potential future directions.

• The authors discuss and investigate the ML approaches and methodologies used and how they revive the computer vision field.

• The authors also give a summary of various publicly accessible datasets that are used to support this field of study.

• In addition, the authors examine distinct application domains while assessing machine learning techniques' function.

• Authors outline difficulties with various machine learning approaches, such as datasets, the accuracy of existing systems, and processing high-quality data.


## C. PAPER ORGANIZATION

To summarize, this study provides the following important contributions: 1) This research aims at how different machine learning styles are used in computer vision, analyses its uses, and predicts future trends. 2) Evolution and literature review of different machine learning styles used in various domains of computer vision.

3) The study discovered brief overview of architecture, working, CV applications, datasets used, advantages and limitations of primary,hybrid and advanced ML styles. 4) Recent research gaps identified and highlight the future directions.

The rest of this article is organized as follows: Section 2 gives background knowledge in terms of Evolution of all ML styles. Section 3describes literature review in terms of past eight year's publication count of papers in Scopus of each learning style and existing survey status of each ML style. Section 4 describes the introduction, framework, computer vision applications, datasets and techniques used with accuracy achieved of all machine learning styles. The comparative analysis of different ML styles, VOLUME 10, 2022 research gaps identified with future directions discussed in Section 5.Section 6 gives the conclusion of this study. Figure 3 shows the overall outline of the paper. Figure 5 shows the evolution of each learning style from past to current time.In Oct 1946, Denny M.R published the first paper on reinforcement learning in which learning with 50% reinforcement & 100% reinforcement was compared in control groups [7]. Then in 1958, the study of the transfer of training & considered their implications for the study of perceptual learning recognition was explained by Vanderplas [8]. After this, in Oct 1964, the advantage of the developed system under unsupervised learning in pattern recognition problems was discussed by Pu and Chen [9]. In the same year, the first paper on Active Learning was published. By stacking multiple images onto a board of various colors, the subject of this single experiment was required to understand the link between color pictures. Everyone of any age can benefit from this type of active learning. Chen published the first work on supervised learning [10].


## II. BACKGROUND STUDY A. EVOLUTION OF MACHINE LEARNING STYLES

In July 1970, an initial investigation was done to test whether a perceptual learning process learns the visual symbols & transfer procedure was used with deaf first-grade children. This experimental study's authors found evidence for distinctive feature learning [11]. Based on Vygotsky's theories, Sir James Britton and others in England developed Collaborative Learning(Co-Learning) in the 1970s as an active learning method. According to Britton, a student's learning comes from a community of learners composed of other students [12]. Then, A theoretical rationale elaborates upon the concepts of meta goals. Meta-learning was provided in April 1975. In 1979, Seltzer Donald S. explained how robots could learn from different methods. This author explained how sensory information is used for improved Robot learning. Then, in 1980, scientists presented an adaptive model for self-supervised learning that uses a single pattern training technique to recognize vowel sounds on a computer [13].

In 1987 Littlestone Nick published his first paper on online learning. In this, online learning of various classes of boolean functions from examples is studied. Board later rediscovered semi-supervised learning in 1989. With the learning algorithm only having access to incomplete information, several unrelated concepts were learned at once. In 1990, Suddarth & Kergosien developed multi-task learning, the main concept of which is sharing what is known by various tasks while activities are trained concurrently. Then in the same year Transduction term was coined by Vladimir Vapnik. After this, in July 1994, the first paper on Co-learning on recursive functions was published. In the same year, Macoun & Richard developed a constructivist learning model helpful for ethics education.

The first study on ensemble learning, which discussed a decorrelation network training technique for enhancing the efficacy of regression learning with ensemble neural networks, was published in 1996. Then, on June 24, 1999, the authors published a study on association rule learning. They claimed that induced rules were not primarily designed for categorization and that the new measures employed for association rule learning were support and confidence. After that, the first papers on multi-view and multi-instance learning were published in 2003. Then in 2006 CELEBRATE project developed and demonstrated a federated learning object brokerage system architecture by Massart & David. Later in Dec 2013, Marcus& Ebert published the first paper on few-shot learning when datasets with few labels are available.

In 2021, the research will be directed towards all these newly introduced machine learning styles integrating computer vision applications in various domains using large pretrained models.


## III. LITERATURE REVIEW

The Scopus publication count per year is examined in exploratory data analysis. A total of eight years are considered for publishing years between 2015 and 2022. We can see the year-by-year publishing of each machine learning style by analyzing the data. In 2018, these advanced machine learning styles area has drawn the attention of numerous researchers.

As compared to traditional machine learning styles, Transfer learning and Multi-task learning styles of advanced machine learning have gradually increased yearly shown in figure 2. With 338 publications collected from Scopus in 2021, the publication count shows a strong increase.

There is tremendous scope of work in this area to work on advanced machine learning styles using AI techniques in upcoming years..


## IV. MACHINE LEARNING STYLES

Many learning techniques depend on the way algorithms use many layers to extract progressively higher-level information from the raw input. Figure 1 illustrates several learning methods. In computer vision applications, including image segmentation, object detection, text recognition from an image, and association rule, these learning techniques are evolving into cutting-edge trends. Figure 7 depicts the various machine learning styles. Primary learning styles include Supervised, Unsupervised, and Reinforcement learning. Multi-instance, Transductive, Active, Meta, and Multi-task learning are the styles of supervised learning where the input data is labeled.

Classification, Regression, and prediction are the everyday tasks performed with these styles. Unsupervised learning includes self-supervised Learning, Constructive Learning, and Association Rule types. Association rule mining, clustering analysis, data summary visualization, and time series analysis are the essential tasks performed using Unsupervised Learning. Reinforcement learning is used mainly for sentiment analysis, robotics, and gaming. It is based on the decision taken to achieve the reward.

Other machine learning styles are becoming popular in various applications using AI. Those popular styles are Transfer learning, Federated learning, Self-taught Learning, Multi-view Learning, Online Learning, Co-learning, Fewshot learning, etc.


## A. PRIMARY STYLES

Supervised, Unsupervised, Reinforcement learning, hybrid, and other learning styles are the basic categories into which machine learning styles in computer vision are divided.


## 1) SUPERVISED LEARNING

A machine learning task called supervised learning converts every input item to the required class label value. An object is mapped by the computer with the intended output after training. It includes a broad selection of algorithms for various supervised learning issues. Over time, applications in computer vision and machine learning have increased dramatically, with society as the only gainer. Supervised learning VOLUME 10, 2022 is broadly divided into two categories, i.e., Classification and Regression. Objects will be categorized based on recognized class categories in classification to solve various real-world challenges. In Regression, however, the correlation between dependent and independent variables is calculated and displayed using scatter plots [6]. Figure 6 depicts the Supervised Learning process flow, where the input is labeled data from which features are extracted, and the model is trained. The trained model will be applied to the test dataset to forecast the result.

The performance accuracy will be calculated by comparing the predicted and actual output.

Advantages of Supervised Learning-• It gives more accurate results of classification than Unsupervised learning.

• It is simple to train and test the model with labeled dataset. Disadvantages of Supervised Learning-• Lack of training dat; • Poor data qualit; MIL is a form of poorly supervised learning in which training examples are collected into bags and given labels for the whole bag rather than for the specific cases. It enables the use of poorly labeled data, which is common in many business challenges due to the high cost of labeling data [29]. Figure 8 shows the framework for MIL training Phase. In this, we give training images as input. In training bags, image segmentation and feature extraction are performed, based on the size of dictionary bag features computed and finally applied, a classifier; the model predicts the result [30].

The majority of tasks using computer vision in medicine are either: 1) Image classification for diagnosis or 2) Segmentation to detect and separate lesions. Most contemporary MIL approaches presume that positive and negative cases from a positive and negative distribution are sampled separately. Due to the co-occurrence of several relationships, this is frequently not the case:

Similarities Within the Bag: Similarities exist between examples from the same bag that does not exist between instances from other bags. In computer vision applications, all segments are likely to have certain commonalities in capture conditions (e.g., illumination). Overlapping patches in an extraction process is another possibility.

Co-Occurrence of Instances: When instances share a semantic link, they co-occur in bags. Or when particular objects are frequently discovered together, or it is more likely to be kept in one place, this form of correlation occurs. In order to quickly train an algorithm, Active Learning (AL) tries to simplify data collection by automatically identifying which instances an annotator should categorize. The premise of active learning is that unlabeled data is readily available but costly to label. Given this, active learning aims to extensively use unlabeled data without incurring the expense of labeling it. Active learning has been a popular study area in many machine learning applications. Active learning has recently been the subject of ongoing research and hypotheses that it can outperform typical supervised learning algorithms in some situations, such as when there is a lot of unlabeled data, and manual labeling is expensive [34], have defined the Active Learning in Object Detection application. Weak supervision techniques with active learning, such as: using other forms of inadequate supervision with active learning, expressing the problem of integrating weak and strong supervision as an optimization problem under budget VOLUME 10, 2022 restrictions, and merging active learning techniques with data programming-based weak supervision approaches, are just a few examples. Figure 9 shows the architecture diagram of how active learning works. Given a set of items called ''I'' and a machine learning algorithm called ''M,'' AL seeks to provide a method for gradually selecting items from ''I'' to obtain actual labels so that ''M'' can be taught with a reduced dataset for random item sampling. The essential premise is that obtaining training data is expensive, hence it is very advantageous to reduce the amount of such a dataset for certain target accuracy. [35].

Applications of Active Learning-• Both in-person and online classes can incorporate active learning.

• When there is too much data to classify, or intelligent labeling of the data needs to take precedence over other tasks, active learning might be used.

• By adaptively choosing which samples to classify for prediction, active learning produces highly accurate predictive models at a low cost. To apply active learning to an unlabeled data collection, follow these steps-1. A small subset of this data must be manually labeled as the first step. 2. The model needs to be trained after a small amount of labeled data has been gathered. The model won't be perfect, of course, but it will help us choose which areas of the parameter space to label first to improve it.  3. Each remaining unlabeled data item's class is predicted using the model after it has been trained. 4. Depending on the prediction made by the model, a score is given to each unlabeled data point.

Once the appropriate strategy for prioritizing the labeling has been identified, a new model can be trained on a new labeled data set that has been labeled based on the priority score. After the new model has been trained on the subset of data, it can analyze the unlabeled data points to update the prioritizing scores and continue labeling [33]. In this manner, as the models advance, the labeling method may be continually improved.


## Advantages of Active Learning-

• To minimize the need for labeling issues such as image annotation, recognition, object detection, segmentation, and posture estimation.   algorithms that learn from other machine learning algorithms. Usually refers to the use of machine learning algorithms capable of combining predictions from different machine learning algorithms in the most effective way possible. Multitask learning algorithms capable of learning across several related prediction tasks are also referred to as meta-learning. There is meta-learning within the framework of supervised learning [41]. Figure 10 shows the work flow of meta learning style.

There are two perspectives on meta-learning.


## 1) Mechanistic View:

• Deep neural network model that can scan a complete dataset and generate predictions for fresh data points • This network is trained using a meta-data set, which comprises numerous datasets for a particular task.

• This viewpoint simplifies the implementation of metalearning algorithms.


## 2) Probabilistic View:

• To effectively learn new tasks from a probabilistic perspective, extract prior knowledge from a set of (meta-training) tasks.

• This last and (limited) training set is used to predict the most likely posterior parameters when learning a new task.

• This viewpoint simplifies the comprehension of metalearning algorithms. Meta-learning techniques take notes on other data-driven machine learning algorithms' outputs. Meta-learning, then, necessitates the presence of different learning algorithms that have been trained on data [42]. For classification and regression problems, supervised meta-learning algorithms, for example, learn how to translate output instances from other learning algorithms (such as projected numbers or class labels) onto examples of target values. On the other hand, meta-learning algorithms forecast a number or a class label by using the output of current machine learning algorithms as input. Meta-learning, also known as meta-machine learning, learns how to use predictions provided by machine learning algorithms in the same way machine learning learns how to use data to produce forecasts.


## Meta-Learning Algorithms

• Non-parametric techniques, • optimization-based inference, • and black-box adaptation • Bayesian meta-learning The table no. V shows a brief about meta-learning. This author used two small Datasets, i.e., AwA (Animals with Attributes) has about 30,000 photos of about 50 distinct animal classes. There are 218 occurrences, 1000 visible categories, and 360 unseen categories in CUB-200-2011 Birds (CUB). Based on the ILSVRC2012 and ILSVRC2010 datasets, ImNet-2 offers 1000 classes for visible courses and 360 classes for unseen classes. The authors use of semantic auto-encoder allows them to choose the best function for mapping semantic space and feature space so that it also functions for classes and semantic space that aren't visible.

Advantages of Meta Learning-• It improves the speed and adaptability of AI systems to environmental changes.

• The key artifact for comprehending and learning the entire system.  As shown in Figure 11, MTL takes input data from text, images, or numbers. For shared layers, an encoder or autoencoder is used to train the model, which will solve the task-specific problems simultaneously to solve multiple similar issues.

Multiple machine learning applications, including natural language processing, speech recognition, computer vision, and drug discovery, have exploited multi-task learning. Many predictions from training models, such as semantic segmentation and picture classification, can be made on a single sample.

Two MTL methods for Deep Learning-1) Hard Parameter Sharing-It is typically implemented by preserving several distinct output layers to each task while sharing the hidden levels across all tasks.

2) Soft Parameter sharing-The second approach to MTL is soft parameter sharing, where the shared layers learn their parameters independently. Advantages of Multi-task Learning-

• By utilizing MTL, the data model can better develop a valuable representation of the data, minimizing data overfitting and boosting generalization.

• It saves model training time as single training model learns multiple tasks concurrently.


## Disadvantages of Multi-task Learning-

• Multi-task learning does not necessarily work better with fewer input data. It can be the limitation of MTL.

• The MTL technique has the potential to reduce overall performance in some circumstances. Tasks can compete with one another during the training of an MTL network to produce a more robust learning representation, meaning that one or more tasks may take control of the training process. Along with additional exercises, learning how to recognize things at the pixel level in an MTL scenario is taught. The latter task frequently dominates the learning process unless a task-balancing technique is implemented, such as segmenting a different mask for each object in an image [48].

Additionally, several increased losses may result in a more complex loss function for MTL, making optimization more challenging. In many situations, collaborating on several tasks has a negative effect, and individual networks trained on a single task may perform better.


## 2) UNSUPERVISED LEARNING

Unsupervised learning majorly works on unlabelled data objects. This type of learning is frequently employed for feature extraction, spotting important patterns and structures, matching together related objects, and practical purposes [51]. Anomaly detection, clustering, density estimation, feature learning, dimensionality reduction, and association rule discovery are some of the most popular unsupervised learning tasks. Figure 12 shows the workflow of an unsupervised learning process for computer vision applications.


## a: SELF-SUPERVISED LEARNING

In some ways, self-supervised learning is a sort of unsupervised learning because it adheres to the condition that no labels are assigned. Self-supervised learning, on the other hand, instead of looking for high-level patterns for clustering, tries to tackle tasks typically addressed by supervised learning (e.g., image classification) without any labeling provided. Figure 13 displays the working of self-supervised learning from input data till the final output generation. Instead of recommending new self-supervised learning techniques, this learning aims to examine how current selfsupervised learning strategies might be applied to address domain adaption problems [53]. The primary task can learn a domain invariant feature representation thanks to the pretext  job connecting the source and destination domains. In the source domain, the primary job has labels; however, in the destination domain, there is no labeling requirement. In other words, we develop unsupervised domain adaptation through self-supervised learning. The forwarded data flow is represented by solid lines in the diagram, while the optional data flow is indicated by dotted lines [53]. Through multitask learning, the pretext and main task (such as object identification, classification, or semantic segmentation) are simultaneously learned. Advantages of Self-Supervised learning-• The frequency of labeling needed may be reduced with the use of self-supervised learning.

• Self-supervised learning can enhance the effectiveness of robotic surgeries by determining the dense depth of the human body.


## Disadvantages of Self-Supervised learning-

• It is very difficult to duplicate samples.

• Semantic distributions of collected data VOLUME 10, 2022  


## b: CONSTRUCTIVIST LEARNING

Constructivist learning changes the network structure as it learns, resulting in a network that is automatically the appropriate fit. This method begins with a ''small'' initial network.

Other hidden units and/or hidden layers are gradually added until a preset error criterion is fulfilled or no performance improvement is visible [55]. Figure 14 provides practical insight into constructive learning. The relationship between cognitive dynamics and emotion axes in the learning process Negative emotions are on the left side of the horizontal axis, while positive emotions are on the right. The vertical axis represents constructive learning, whereas the vertical axis represents destructive learning. A learner's affective and emotional state should be kept within the first two quadrants to maintain a reasonable learning rate. Suppose the tutor notices that the student's emotional state is shifting into the third or fourth quadrants. In that case, they must take immediate action to prevent the dynamic transfer, which could restart the entire learning process [55]. Advantages of Constructive learning-• Constructive learning techniques make it easy to design the initial network architecture.

• Constructive techniques are more effective in terms of network complexity and structure as well as training time.

• Because of their incremental learning nature, constructive algorithms tend to develop tiny networks.

• Effective algorithms require the specification or selection of several problem-dependent parameters; they are not restricted to ''acceptable'' and ''great'' networks producing good performance outcomes. Disadvantages of Constructive learning-• Even though learners won't always actively generate meaning and construct a suitable knowledge structure, learners will appreciate this new method to learning.

• The learner may be restricted by conceptualizing learning in that, at least initially, they may not be able to create abstractions and transfer information and skills in new settings. 


## c: ASSOCIATION RULE LEARNING

An unsupervised learning method called association rule learning looks at how one data item depends on another and then maps to make it more profitable. It seeks to uncover exciting connections or interactions between the dataset's variables [58]. A technique of machine learning based on rules called association rule learning can be used to find ''IF-THEN'' sentences or other meaningful correlations between variables in large datasets. One example is that if a consumer purchases a computer or laptop (one thing), they will also purchase anti-virus software (another item) simultaneously. IOT services, medical diagnosis, usage behavior analytics, web usage VOLUME 10, 2022 mining, cutting-edge phone applications, cybersecurity applications, and bioinformatics are a few examples of contemporary uses for association rules. The order of events within or across transactions is rarely considered by association rule learning, in contrast to sequence mining. Commonly, the ''support'' and ''confidence'' metrics are employed to evaluate the value of association rules [2].

Association rule algorithms measure the frequency of complementary occurrences, or associations, across an extensive collection of things or activities. The idea is to uncover relationships that occur more frequently than a random selection of alternatives would reveal. This rule-based strategy is a quick and effective way to mine non-numeric, classified datasets. It is shown with the help of market basket analysis in the figure15.

Example: One well-known application of this methodology is the analysis of retail sales to ascertain the best way to arrange items in a store. Newborn baby diapers may be sold 10,000 times at a business with a million transactions annually, but razor blades may be sold 100,000 times. At first inspection, there is no statistically significant correlation between newborn diapers and razors. On the other hand, rule mining would go further into transaction frequency and find that 5,000 sales involve both products.

The association system introduces a new rule indicating that 50% of all buyers buying newborn diapers also purchase razor blades, which might be helpful to information for marketing efforts rather than just knowing that 1% of customers purchase diapers and 10% buy razor blades.

Moreover, when additional data is analyzed, the rule-based Method improves performance and develops new rules. With a sizable enough dataset, it enables the computer to simulate the human brain's feature extraction and abstract association abilities from unstructured input.

Application Areas of Association Rule learning-1) Basket data analysis -Association mining can help you determine what your customers desire, whether you're planning product placement in a storefront, running a marketing campaign, or producing a business catalog [58].


## 2) Web usage mining and intrusion detection -

A powerful prediction tool for identifying new security dangers and network performance issues that haven't been assessed by humans yet is finding these hidden correlations [59]. 3) Bioinformatics (bioinformatics) -One of the essential methods for uncovering underutilized but potentially valuable processes across a wide range of disciplines, from biology to engineering and everything in between, is association mining [58].


## 3) REINFORCEMENT LEARNING

Using input from its actions and experiences, an agent is trained in an interactive environment to achieve this machine learning technique's reward and punishment mechanisms. The agent receives rewards for successful attempts and punishment for unsuccessful ones. The agent attempts to minimize inappropriate actions and maximize appropriate ones by learning from their experiences and activities [64]. When a series of decisions are required, reinforcement learning is used. The mathematical foundation of Markov decision processes is used in most reinforcement learning contexts. Reinforcement learning is utilized in computer vision applications for object detection, video analysis, gaming, and animation. Figure 16 shows the work flow of reinforcement learning process to achieve the reward.

Advantages of Reinforcement learning-    


## 4) HYBRID LEARNING STYLES a: SEMI-SUPERVISED LEARNING

These algorithms are trained on data that are both labeled and unlabeled. There is a lot of labeled data and a lot of unlabeled data. Figure 17 shows how semi-supervised learning works with labeled and unlabeled data.

The basic approach entails clustering similar data first. Using an unsupervised learning method and then applying it VOLUME 10, 2022  to existing data. The rest of the unlabeled data is labeled using the labeled information [58].

Advantages of Reinforcement learning-• In this, labeled data can contribute significantly to accurate pattern extraction.

• Semi-supervised learning can result in better convergence by having greater effects on models.

Disadvantages of Reinforcement learning-    representations largely determines their performance. We may never be able to construct the best and most diverse set of features that accurately characterize all variations in our data if we do it by hand. Figure 18 shows the framework of FL.

Images learn features by inducing scarcity using a pool of potential features, a belief network, convolution, or a combination of these methods. These methods have the critical elements listed below (Nithin & Siva Kumar, 2015), VOLUME 10, 2022  which is one of the reasons they can learn features while ensuring that they are generic to any task.

Key elements of Feature Learning are: 1. Hierarchical layer learning 2. Dimensionality 3. Generalization of manifold 4. Disentanglement.

A key issue in many computer vision applications, such as image registration, tracking, and motion analysis, is the feature matching problem. An essential component of effective feature matching techniques is rich local representation. However, it becomes difficult to extract rich local representations when the local characteristics are constrained to the coordinates of important places. Traditional methods solve NP-hard assignment issues in order to match robustly using pairs or higher order handcrafted geometric features. To solve this issue, a graph neural network model that converts feature point coordinates into local features is suggested. The conventional NP-hard assignment problems are replaced with a straightforward assignment problem that may be handled quickly [75]. Table 13 gives a summary of how feature learning is used in computer vision with datasets used and accuracy achieved.


## c: ROBOT LEARNING

Robot learning is a field of study that combines machine learning and robotics. It investigates learning algorithms that allow a robot to learn new skills or adapt to its surroundings. Numerous analytical systems, such as robots, are integrated with visual sensors from which they know the status of their surroundings by solving matching computer vision challenges in multiple applications. These tasks' solutions are utilized to make decisions regarding possible future actions [78].


## B. ADVANCED LEARNING STYLES 1) TRANSFER LEARNING

The system's capacity to recognize and apply information and abilities acquired during previous tasks to new ones. There is a need for Transfer learning to minimize the model training time and usage of the resources to solve similar kinds of functions.

In this, if you train a simple classifier to predict whether an image contains a particular set of objects, you could use the same knowledge the model gained during its training to recognize different but related groups of new things [79].

As shown in Figure 19, transfer learning takes a pre-trained model and dataset as input. It works on data and trains the model on that data to perform the machine learning tasks. Then that trained model knowledge will be used to solve similar problems. There are two types of transfer learning: one is positive transfer learning, and another is negative transfer learning. In positive transfer learning, pre-trained models can improve the performance of new tasks and the accuracy of results generated. At the same time, the negative transfer is when the implementation of new tasks degrades due to the previously trained knowledge transfer of the model.

Transfer learning is used in various domains like Medical applications, Biometrics, transportation, recommendation systems, and urban computing applications like traffic monitoring, health care, social security, etc. Pre-training a neural network on the source domain is a way to transfer learning that is frequently employed. for instance, ImageNet, a library of over 14 million annotated pictures divided into more than 20000 categories, then fine-tune it using examples from the target domain.

Machine learning models that deal with natural language processing incorporate transfer learning. Examples include teaching a model to recognize various linguistic components or embedding pre-trained layers that comprehend certain terminology or dialects. To translate models into different languages, transfer learning is used. Models' features are developed and trained using the English language. Table 15. Summarizes the different strategies used in transfer learning. Despite having the same source and target domains, the source and target tasks are different. The algorithms take advantage of the inductive biases of the source domain to enhance the target job. In the case of transductive transfer learning, the related domains are different even though the source and target tasks are comparable. For unsupervised transfer learning, the main focus is on unsupervised tasks in the target domain where the source and target domains are similar, but the tasks are different. The reusable aspects of a computer vision algorithm will be applied to a new model through transfer learning in computer vision for image and video data processing. Deep learning, a kind of machine learning that aims to emulate and duplicate the processes of the human brain, is reliant on artificial neural networks. Due to the intricacy of the models, neural network training consumes a large number of resources. To increase process efficiency and decrease resource demand, transfer learning is applied.

Advantages of Transfer learning-• Removing the requirement for each new model to have a significant collection of labeled training data.

• They are increasing the effectiveness of developing and deploying machine learning for several models.

• Using several algorithms to overcome new problems is a more generalized method of machine problem-solving.

• Instead of real-world situations, simulations can be used to train models. Disadvantages of Transfer Learning-• One of the most significant limitations to transfer learning is the problem of negative transfer.

• Transferring knowledge from a less related source (where labeled data is less) may inversely hurt the target performance, a phenomenon known as a negative transfer


## 2) ENSEMBLE LEARNING

To achieve better results, ensemble learning employs strategies that expand models and combine them. Different models used as inputs for ensemble methods in this learning are referred to as base models, which provide better prediction accuracy than a single trained model. Figure 20 shows the framework of Ensemble learning. Ensemble Learning has three methods as follows-   a learning scheme where each model gives an equally weighted prediction. 3. Stacking -The input data is divided into training and testing. The training dataset is trained using different classifiers and will be taken as input to create a meta classifier. The result of the meta classifier is the final trained model. It will then be applied to the testing dataset to check the classifier's (meta) prediction accuracy [85]. Advantages of Ensemble learning-• Compared to most other ML styles, ensemble approaches are more accurate predictors than individual models.

• When a dataset contains both linear and non-linear types of data, ensemble approaches are incredibly useful; several models can be coupled to manage this type of data.

• With ensemble approaches, bias and variance can be decreased, and the model is typically neither underfitted nor overfitted.

• A model ensemble is always more stable and less noisy.


## Disadvantages of Ensemble learning-

• Ensemble learning is a difficult task to learn, and any poor decision might result in a model with lower prediction accuracy than an individual model.

• Time and storage costs of ensemble model is high.


## 3) FEW SHOT LEARNING

Few-Shot Learning is a type of meta-learning in which a learner works on multiple similar tasks during the metatraining phase so that it may generalize successfully to unknown (but related) tasks with only a few examples [89] shown in figure 21. This Learning is commonly used to represent many tasks and train task-specific classifiers; on top of this, representation is a practical approach to the Few-Shot Learning problem.  The difficulty of wanting to recognize objects from classes that our model has not seen during training is known as zero-shot learning shown in figure 22. The data for zero-shot learning comprises the following: 1. Observed/Seen classes: These are classes for which we labeled images during training.

2. Unobserved/Unseen classes: These classes do not have any tagged images throughout the training phase. Types of Zero-Shot Learning-1) Inductive Zero-Shot: We can get tagged image data from classes that have been observed in this. The key objective is to translate semantic knowledge into visible image space so that the model can identify objects from unobserved classes during testing.

2) Transductive Zero-Shot: We also have access to unlabelled images from unobserved classes in this labeled image data from seen classes.

Methodologies Used for Zero-Shot Learning: 1) Embedding Based Method-The primary purpose of embedding-based approaches is to use a projection function trained using deep networks to map picture features and VOLUME 10, 2022 semantic attributes into a shared embedding space. The visual and semantic spaces can be used as the common embedding spaces.

2) Generative Model-Based Method-Based on generative models, this approach: The primary drawback of embedding-based techniques is that they exhibit bias and domain shifting. It suggests that because the projection function is developed using only seen classes during training, it will be biased towards predicting seen class labels as the output [84]. The learned projection function may not, at test time, accurately translate unseen class picture features to the pertinent semantic space. The deep network has only been trained to map picture data from observed classes to semantic space. It might not be able to do so successfully during testing for particular, unseen classes.

We must train our zero-shot classifier on unseen and unseen class images to overcome this limitation. It is when methods based on generative models come into play. Productive approaches use semantic properties to produce picture features for unseen classes. Typically, a conditional generative adversarial network is used, creating image features based on the semantic characteristic of a specific type.


## 5) ONLINE LEARNING

Online learning involves instruction using data that is made available in a stepwise order. The whole training data samples are always available in batch sampling-based learning, which is different from this method. It is useful when algorithms need to change their behavior in response to changing data patterns from all incoming input. For online learning to succeed, three essential needs must be met [90]. Figure 23 shows On the Left: The user is pointing to an object, and on the Right: Process Flow.

1. The neural system's flexibility allows for the rapid assimilation of new information without requiring an entire training cycle; 2. Near-real-time processing throughout the entire system; 3. The natural presentation of fresh object information is made possible by a subsystem for human-machine interaction. Advantages of Online learning-• Low cost required • Flexible to implement • Covers time and mass audiences Disadvantage of Online learning-• Less Accuracy achieved or success rate is low. Advantages of Zero-shot learning-• A strong and promising learning paradigm is called zeroshot learning, in which the classes that training instances cover and the classes that we want to classify are not related.

• To improve the generalization ability of the model • To improve scalability and robustness Disadvantages of Zero-shot learning-• Extensive smoothing • Sparsely labeled Using skin color segmentation, one instance of the VPLclassifier, and a search for pointing movements (upper branch), the scene is examined for objects that can be identified (lower branch). The ''online loop'' (right ellipse) starts when a story about an object is recounted. After establishing the position of the pertinent entity, pictures are taken. The database is expanded with views that have been artificially warped (scale/shear transformation, translatory offset). The candidate regions are categorized by the VPL classifier. The result is either a class number for a previously taught material or a reserved class label for ''unknown.'' The VPL is a neural classification architecture that performs exceptionally well when being trained and retrained online with minimal data. Three processing stages called ''VPL'' combine pixel-level feature extraction with LLM-networks, PCA, and vector quantization are used for classification [88]. The following is how the VPL is defined: Using vector quantization, the input space is divided at the first level (''V'') (VQ). For VQ, the suggested algorithm is applied. In the second level (''P'') of each of the generated reference vectors, the neural Method computes the principal components (PCs) for the training data gathered in the Voronoi tessellation cells.


## 6) FEDERATED LEARNING

Federated Learning means fed a large number of cases. FL is a machine learning approach in which numerous participating clients who maintain their training data locally train a single shared global model.

It is a distributed learning approach that builds a universal or customized model using decentralized datasets on edge devices. Model performance in FL, however, falls well short of centralized training in the field of computer vision because there isn't any investigation in a variety of tasks with a common FL framework. FL works well in complex computer vision applications such as object recognition, picture segmentation, and image classification [90].

The FL figure 24 shows the Federated learning workflow stepwise-1) On the Common Server, train a global model. 2) Using local datasets, deploy global models to edge devices (local models).

3) Use the local datasets from each edge device to improve the model (local models). 4) Post updates to locally trained models on a shared server. 5) Calculate the average of the update values and apply it to the overall model. 6) Repetition of steps 2 through 5 FL has been used, for instance, to train prediction models for mobile keyboards without sending confidential typing information to servers [91].

Federated Learning enables mobile devices to collectively create a shared prediction model while maintaining all of the training data on the device, separating the ability to do machine learning from the obligation to store training data on the cloud. Beyond the use of local models that make predictions on mobile devices, model training is extended to the device. According to how it works, your smart phone downloads the most recent model updates it by using data from your phone to learn from it, and then compiles the changes into a brief, targeted update. Using encrypted communication, only this particular change to the model is transferred to the cloud, where it is instantaneously averaged with updates from other users to enhance the shared model. There is no cloud storage for individual updates, and the training data is kept locally on your device. VOLUME 10, 2022 Example: Google Keyboard: Your phone keeps the information about the current context and whether you clicked a suggested query when Gboard displays one. The history is processed on-device by Federated Learning, which offers suggestions for enhancements for the upcoming version of Gboard's query recommendation model. Federated learning functions without the necessity for cloud-based user data storage.

FedCV is a benchmarking system and federated learning library that assesses FL on the three most common computer vision tasks, including object identification, image segmentation, and classification.

A distributed machine learning (ML) framework is federated learning (FL). FL allows numerous clients to work together to solve common distributed ML issues while maintaining their local privacy. This is done under the control of a central server. FL differs from distributed ML in that the data that each participant uploads to the server is a trained sub-model rather than the original data. The FL also permits asynchronous transmission at the same time, allowing for a suitable reduction in the communication needs [94]. Each unit builds a model and transmits its input data to the server for aggregation. Data is stored on devices, and knowledge sharing with peers uses an aggregated paradigm [10]. For edge network optimization, the federated learning technique (FL) facilitates the cooperative training of deep learning and machine learning models. There is a challenge in this area even though a complex edge network with diverse devices with different restrictions can affect its performance.

Advantages of Federated learning-• Federated learning enables several components to develop an identical, reliable machine learning model without sharing data, enabling for the resolution of crucial concerns such data privacy, security, access rights, and heterogeneous data availability.


## Challenges of implementing Federated Learning-

• Resource Allocation: To manage large amounts of dispersed data without compromising privacy or health informatics, we intend to provide helpful tools for computational research on machine learning approaches.

• Data Imbalance: 1. Size imbalance: When the size of the data sample at each edge node varies widely. 2. Global imbalance: Data that is class uneven across all nodes is referred to as global imbalance. 3. Local Imbalance: Because not all nodes have the same data distribution, this is also referred to as a local imbalance, non-identical distribution, or independent distribution.

• Statistical Heterogeneity: The edges frequently gather and distribute data among the network in a non-i.i.d. fashion. Cellular phone users have access to a large range of languages for word prediction. Additionally, there may be an underlying structure that reflects the interaction between devices and the distributions connected with them, and the amount of data on various edges may vary. • Privacy Concerns: FL takes a step toward protecting user data by releasing only model changes (such as gradient information) rather than the complete data. Transmitting local model updates throughout the training process, however, can reveal private information to the main server or a third party. Despite current efforts to strengthen federated learning's privacy through the use of technologies like differential privacy and safe multiparty computation, these methods sometimes sacrifice system efficiency or model accuracy to ensure privacy.


## V. FUTURE DIRECTIONS

This section highlights about the research gaps identified from the survey and the machine learning styles suitable to solve such challenges that could aid in this field's advancement. Table 21 gives the summary of research gaps with future directions.

The development of computer vision technology is continuing as AI becomes more pervasive in our daily lives. Due to developments in cloud computing, Auto ML pipelines, transformers, mobile-focused DL libraries, and mobile computer vision applications, as this technology scales, there will be an increased need for experts in computer vision systems.


## A. IMBALANCED DATA

If a different number of images for each of the classes is existing in the input dataset. This problem is called as class imbalance. Similarly, if a set of images is not evenly distributed in the input dataset is called imbalanced data. Transfer learning, Multi-task learning and Federated learning help to overcome this unbalanced distribution of data problem. As in case of transfer learning once the model has been trained on sample dataset can be applied to solve the similar problems with the same model. In case of the Multi-task learning model can be trained with a small number of dataset. The same knowledge generated can be applied to solve all related tasks. From supervised learning Logistic regression algorithm is very useful to tackle this issue as it resample's the original training dataset to decrease the overall level of class imbalance. The authors proposed a monitoring scheme that can infer the composition of training data for each Federated Learning(FL) round, and design a new loss function -Ratio Loss to mitigate the impact of the imbalance [110].


## B. SCARCITY OF DATA

Data scarcity occurs when: There is little or no labeled training data available, or there is insufficient data for certain labels in comparison to other labels are present in the dataset. Zero-shot learning, Few-shot learning and Transfer learning can be the solution for this type of dataset-related challenge. As Zero-shot or few-shot learning works properly with less or no labeled data. Transfer learning, where information from one dataset is used to inform a model on another, can be an effective solution on this challenge.  


## C. OVERFITTING/UNDERFITTING OF DATA

When our machine learning model is unable to recognize the data's underlying trend, underfitting occurs. Whereas overfitting is a problem when the evaluation of machine learning algorithms on training data differs from the evaluation on unknown data. Ensemble learning, Meta-Learning and Active learning are helpful to solve this problem.


## D. DETECTION AND CLASSIFICATION OF BLUR IMAGES

In order to restore images, blur identification is frequently required. Authors proposed a classification technique utilizing ensemble Support Vector Machine (SVM) structure, a novel blur type classification method for digital images. Each image is considered to be prone to no more than one of the three types of blur: haze, motion, and defocus. In the VOLUME 10, 2022  suggested method, the Radial Basis Function (RBF) kernel parameters of the SVMs are additionally optimized using the SVM-Recursive Feature Elimination (SVM-RFE) method, which is used to rank the 35 blur features that were first derived from the spatial and transform domains of the picture. Additionally, the Support Vector Rate (SVR) is used to calculate the ideal number of features for classifiers to use. To categorize the various types of blurred images, the bagging random sampling method is used to build an ensemble SVM classifier based on a weighted voting mechanism [111]. In this way supervised learning SVM ensemble and SVM multiclass algorithms useful to solve blur images problem.   


## E. HUMAN INTERVENTION REQUIRED

Meta learning and Constructive learning is the solution where human intervention is not required in the model training and testing process.


## F. ROBUSTNESS OF ML TECHNIQUES

By integrating various models, ensemble learning enhances machine learning outcomes. In comparison to using a single model, this strategy enables the generation of greater prediction performance. Ensemble models are more robust than a single train model as it combines multiple models.


## G. HIGH OPERATIONAL/MODEL TRAINING COST

Reinforcement learning, Transfer learning, Meta learning saves the model training operational cost as existing trained model is used to solve similar problems without the training model again.


## H. MORE POWER AND STORAGE CONSUMPTION

Federated learning is a distributed learning paradigm that uses decentralized datasets on edge devices to construct a global or personalized model. So the storage consumption issue can be resolved using FL.


## I. LARGE SCALE OF UNLABELED IMAGES

When input dataset consists of large scale of unlabeled images then accuracy degrades. To overcome this issue Selfsupervised learning, Few-shot, and Zero-shot learning can improve CV operations performance. As these learning styles allow to train the model with few labeled samples easily.

The development of algorithms with lower training data requirements than present models is key to the future of computer vision technology. The industry has started investigating a few potentially ground-breaking research themes to address this difficulty by applying reinforcement learning, transfer learning and multi-task learning

In 2022, as augmented and virtual reality (VR) applications advance, computer vision developers will be able to expand their expertise into new fields, such as creating simple, effective ways to replicate and interact with physical things in a 3D environment. In the future, computer vision applications will likely continue to develop and have an impact.


## VI. CONCLUSION

Machine learning and deep learning popularity have grown recently across several industries. The combination of machine learning and artificial intelligence methods has been used in many applications to carry out various computer vision tasks.

The literature on machine learning techniques applied in computer vision applications is reviewed in-depth in this article. The findings of a systematic literature review on machine learning styles are presented in this review. The authors intended to draw attention to the utilized learning types, adopted feature extraction techniques, methodologies, approaches, approved data sets, adopted application domains, and difficulties related to ML approaches in diverse sectors. This study planned, executed, and carried out different SLR phases on ML styles. In the literature review for computer vision applications, other artificial intelligence methodssuch as those based on deep learning and machine learninghave been used. Deep learning and machine learning-based techniques are popular thanks to easily accessible datasets and automated feature extraction methods. The authors investigated publicly accessible computer vision datasets. Future possibilities for ML techniques in CV based on artificial intelligence are described, along with research obstacles in the realm of ML styles in computer vision, such as domain dependency and imbalanced dataset. Future directions are mentioned in the article which will be helpful for the researchers who are working in this domain. She is also working as a Junior Research Fellow at the Symbiosis Institute of Technology. She has more than eight years of teaching and research experience in engineering colleges. She has expertise in applying innovative technology solutions to real-world problems. Her research interests include machine learning, deep learning, artificial intelligence, natural language processing, and data mining and analysis. She is also working in the application domains of computer vision in healthcare, data analysis, and machine simulation, via which she has also guided several UG and PG students as a domain expert. She has published more than 12 research articles in reputed international conferences and Scopus/web of science indexed journals and books.

BHARTI KHEMANI received the M.Tech. degree in computer engineering from the Thadomal Shahani Engineering College, Bandra, Mumbai. She is currently pursuing the Ph.D. degree with the Symbiosis Institute of Technology.

She is also working as an Assistant Professor with the A. P. Shah Institute of Technology, Mumbai. She has 12 years of academic experience in engineering colleges. She has expertise in applying innovative technology solutions to real-world problems. Her research interests include machine learning, deep learning, artificial intelligence, natural language processing, and graph neural networks (GNN). She is also working in the application domains of healthcare, misinformation detection, and machine simulation, via which she is also guiding several UG students as a domain expert. She has published more than ten research articles in national and international conferences and journals.

SHRUTI PATIL received the M.Tech. degree in computer science and the Ph.D. degree in the domain of data privacy from Pune University. She has been an industry professional in the past, currently associated with the Symbiosis Institute of Technology as a Professor and with SCAAI as a Research Associate, Pune, Maharashtra. She has three years of industry experience and ten years of academic experience. She has expertise in applying innovative technology solutions to real world problems. Her research interests include applied artificial intelligence, natural language processing, acoustic AI, adversarial machine learning, data privacy, digital twin applications, GANS, and multi-modal data analysis. She is also working in the application domains of healthcare, sentiment analysis, emotion detection, and machine simulation via which she is also guiding several UG, PG, and Ph.D. students as a domain expert. She has published more than 30 research articles in reputed international conferences and Scopus/web of science indexed journals and books.

KETAN KOTECHA has expertise and experience of cutting-edge research and projects in AI and deep learning for last more than 25 years. He has published widely in several excellent peer-reviewed journals on various topics ranging from education policies, teaching-learning practices, and AI for all. He is also a Team Member for the nationwide initiative on AI and deep learning Skilling and Research named Leadingindia.ai initiative sponsored by the Royal Academy of Engineering, the U.K. under Newton Bhabha Fund. He is currently the Head of the Symbiosis Centre for Applied Artificial Intelligence (SCAAI). He is considered a foremost expert in AI and aligned technologies. Additionally, with his vast and varied experience in administrative roles, he has pioneered Education Technology. He has worked as an Administrator at Parul University and Nirma University and has several achievements in these roles to his credit.

## FIGURE 1 .
1Segmentation, classification & Object detection.

## FIGURE 2 .
22015-2022 year-wise publication count of learning styles.

## FIGURE 3 .
3Outline of paper.

## FIGURE 4 .
4AI in computer vision.

## FIGURE 5 .
5Evolution of machine learning styles-a brief history of machine learning styles.

## FIGURE 6 .
6Framework of supervised learning. • Underfitting or overfitting of training data; • The process of machine learning is complicated; a: MULTIPLE INSTANCE LEARNING (MIL)

## FIGURE 7 .
7Taxonomy of machine learning styles classification.

## FIGURE 8 .
8Framework of multiple instance learning.

## •
Active learning (AL) aims to maximize the performance increase of a model. Disadvantages of Active Learning-• It is time consuming • Sometimes memorization is necessary • Not all outcomes are predictable c: META-LEARNING Meta-learning is the process of studying itself. The most frequent examples of meta-learning are machine learning

## FIGURE 9 .
9Framework of active learning.

## FIGURE 11 .
11Framework of multitask learning.

## FIGURE 12 .
12Framework of unsupervised learning.

## FIGURE 13 .
13Framework of self-supervised learning.

## FIGURE 14 .
14Constructive learning.

## •
It is used when online computation time is important. • It is less tractable both computationally and analytically compared to tracking or regulations problems. Disadvantages of Reinforcement learning-• Reproducibility is required. • Sample inefficiency is a problem. • Wisely choose reward structure

## FIGURE 15 .
15Association rule learning.

## FIGURE 16 .
16Framework of reinforcement learning.

## •
The issue of extending labeled data • The difficulty of constructing the final classifier b: FEATURE LEARNING Current machine learning algorithms rely heavily on manually creating features, and the quality of human

## FIGURE 17 .
17Framework of semi-supervised learning.

## FIGURE 18 .
18Framework of feature learning.

## FIGURE 19 .
19Framework of transfer learning.

## FIGURE 20 .
20Ensemble learning framework. Applications of Few-shot Learning in computer vision • Few-Shot Image Recognition Human Motion And Pose Prediction • Domain Adaptation • Few-Shot Segmentation • Learning To Learn from Weak Supervision • Generating Talking Heads from Images 4) ZERO-SHOT LEARNING

## FIGURE 21 .
21Embedding-based zero-shot method.

## FIGURE 22 .
22Zero-shot learning using generative model-based methods.

## FIGURE 23 .
23On the Left: The user is pointing to an object, and on the Right: Process Flow.

## FIGURE 24 .
24Federated learning system.


SUPRIYA V. MAHADEVKAR received the M.Tech. degree (Hons.) in computer engineering from the Pimpri Chinchwad College of Engineering (PCCOE), SPPU University, Pune. She is currently pursuing the Ph.D. degree with the Symbiosis Institute of Technology, Pune.

## TABLE 1 .
1Summary of existing surveys related to machine learning in computer vision.

## Table 3
3gives experimental results of the classification problem using KNN, SVM & Bagging-APR algorithms on MUSK1 & MUSK2 datasets [31]. In table 3: MUSK1 and MUSK2 are benchmark datasets [3] consisting of 92, 102 bags, 5.17, 64.69 instances, and 47, 39 positive bags, respectively. Advantages of Multiple Instance learning-• Multiple instances learning deep neural networks are 
able to learn the features that optimally represent the 
given training data. 

• It works with worse classification performance. 
Disadvantages of Multiple Instance learning-

• Pooling functions are predefined and non trainable. 
• Hyper parameter r is global, thus, it is not adaptive to 
new instances. 

b: ACTIVE LEARNING 



## TABLE 2 .
2Supervised learning applications.

## TABLE 3 .
3Multiple instance learning.

## TABLE 4 .
4Application area of active learning.FIGURE 10. Meta-Learning framework.• To improve their predictions, meta learning algorithms can learn to incorporate the best results from machine learning algorithms. Disadvantage of Meta Learning-• The natural restrictions of measuring the true performance of the dataset may make performance estimation incorrect.Multi-task learning describes a training paradigm in which a single training model learns multiple tasks concurrently. This Learning style enables the usage of beneficial connections found in related jobs. Compared to separately trained models, they increase generalization across all functions, increasing prediction accuracy for specific tasks.d: MULTITASK LEARNING-



## TABLE 5 .
5Applications of meta-learning.

## TABLE 6 .
6Multitask learning applications.

## TABLE 7 .
7Self-supervised learning.

## TABLE 8 .
8Applications of constructive learning.

## TABLE 9 .
9Applications of association rule learning.

## TABLE 10 .
10Algorithms of association rule learning.

## TABLE 11 .
11Reinforcement Learning (RL) application Areas.

## TABLE 12 .
12Semi-supervised learning.

## TABLE 13 .
13Feature learning.

## TABLE 14 .
14Robot learning.

## TABLE 15 .
15Transfer learning strategies.

## TABLE 16 .
16Applications of transfer learning.

## TABLE 17 .
17Application areas of ensemble learning.

## TABLE 18 .
18Classification of zero-shot learning.

## TABLE 19 .
19Applications of federated learning.

## TABLE 20 .
20Comparative analysis of different learning styles.VOLUME 10, 2022 


## TABLE 20 .
20(Continued.) Comparative analysis of different learning styles.

## TABLE 21 .
21Summary of research gaps with future directions.
VOLUME 10, 2022   
   VOLUME 10, 2022   
Currently, she is working as the Head of the Department and an Associate Professor in computer science and engineering with the Symbiosis Institute of Technology, Pune. She has more than 20 years of experience in total in teaching, research, and industry. She has published more than 50 research papers in reputed national, international conferences, and journals. She has coauthored three books and two book chapters and delivered various talks in data science and machine learning. She has conducted hands-on session in data science using python for students and faculties. She was appointed as a Syllabus Revision Committee Member of Mumbai University and developed the course content for B.E. degree in information technology course. She has received grants from government bodies, such as AICTE, ISTE, and industry for conducting research, organizing conference and training courses for faculties. She is acting as a Reviewer for many international conferences and journals, such as IEEE ACCESS, Journal of Big Data analytics (IGI Global), Journal of Intelligent Systems, and Inderscience. She has organized many values added courses for the benefit of the students. More than 18 students have completed and currently, three students are pursuing their postgraduate studies under her guidance from Mumbai University. In addition to that, three students are pursuing research (Ph.D.) under her guidance at Symbiosis International University, Pune. Her course developed on ''Deep Learning'' is currently available on Unschool platform for all and two technical blogs are available to read on KnowledgeHut.com site.AJITH ABRAHAM (Senior Member, IEEE) received the Master of Science degree from Nanyang Technological University, Singapore, in 1998, and the Ph.D. degree in computer science from Monash University, Melbourne, Australia, in 2001. He is currently the Director of the Machine Intelligence Research Laboratories (MIR Laboratories), a Not-for-Profit Scientific Network for Innovation and Research Excellence Connecting Industry and Academia. The Network with HQ in Seattle, USA, is currently more than 1,500 scientific members from over 105 countries. As an investigator/a co-investigator, he has won research grants worth over more than 100 million U.S.$. Currently, he holds two university professorial appointments. He works as a Professor in artificial intelligence at Innopolis University, Russia, and the Yayasan Tun Ismail Mohamed Ali Professorial Chair of Artificial Intelligence at UCSI, Malaysia.He works in a multi-disciplinary environment. He has authored/coauthored more than 1,400 research publications out of which there are more than 100 books covering various aspects of computer science. One of his books was translated into Japanese and a few other articles were translated into Russian and Chinese. He has more than 46,000 academic citations (H-index of more than 102 as Per Google Scholar). He has given more than 150 plenary lectures and conference tutorials (in more than 20 countries).He
Machine learning: A review of learning types. S Sah, 10.20944/preprints202007.0230.v1S. Sah, ''Machine learning: A review of learning types,'' Jul. 2020, doi: 10.20944/preprints202007.0230.v1.

A new generation of AI: A review and perspective on machine learning technologies applied to smart energy and electric power systems. L Cheng, T Yu, 10.1002/er.4333Int. J. Energy Res. 436L. Cheng and T. Yu, ''A new generation of AI: A review and perspective on machine learning technologies applied to smart energy and electric power systems,'' Int. J. Energy Res., vol. 43, no. 6, pp. 1928-1973, 2019, doi: 10.1002/er.4333.

A low-cost multi-sensor data acquisition system for fault detection in fused deposition modelling. S Kumar, T Kolekar, S Patil, A Bongale, K Kotecha, A Zaguia, C Prakash, 10.3390/s22020517Sensors. 222S. Kumar, T. Kolekar, S. Patil, A. Bongale, K. Kotecha, A. Zaguia, and C. Prakash, ''A low-cost multi-sensor data acquisition system for fault detection in fused deposition modelling,'' Sensors, vol. 22, no. 2, pp. 1-33, 2022, doi: 10.3390/s22020517.

Appositeness of optimized and reliable machine learning for healthcare: A survey. S Swain, B Bhushan, G Dhiman, W Viriyasitavat, 10.1007/s11831-022-09733-8Arch. Comput. Methods Eng. 296S. Swain, B. Bhushan, G. Dhiman, and W. Viriyasitavat, ''Appositeness of optimized and reliable machine learning for healthcare: A survey,'' Arch. Comput. Methods Eng., vol. 29, no. 6, pp. 3981-4003, Oct. 2022, doi: 10.1007/s11831-022-09733-8.

Two notes on machine 'learning. H H Martens, 10.1016/S0019-9958(59)80014-0Inf. Control. 24H. H. Martens, ''Two notes on machine 'learning,''' Inf. Control, vol. 2, no. 4, pp. 364-379, 1959, doi: 10.1016/S0019-9958(59)80014-0.

Machine learning in computer vision: A review. A A Khan, A A Laghari, S A Awan, 10.4108/eai.21-4-2021.169418EAI Endorsed Trans. Scalable Inf. Syst. 832A. A. Khan, A. A. Laghari, and S. A. Awan, ''Machine learning in computer vision: A review,'' EAI Endorsed Trans. Scalable Inf. Syst., vol. 8, no. 32, pp. 1-11, 2021, doi: 10.4108/eai.21-4-2021.169418.

Partial reinforcement and conditioned taste aversion: No evidence for resistance to extinction. D M Dwyer, P Gasalla, M López, 10.1080/17470218.2017.1347191J. Exp. Psychol. 722D. M. Dwyer, P. Gasalla, and M. López, ''Partial reinforcement and conditioned taste aversion: No evidence for resistance to extinction,'' Quart. J. Exp. Psychol., vol. 72, no. 2, pp. 274-284, 2019, doi: 10.1080/17470218.2017.1347191.

Transfer of training and its relation to perceptual learning and recognition. J M Vanderplas, 10.1037/h0040233Psychol. Rev. 656J. M. Vanderplas, ''Transfer of training and its relation to perceptual learning and recognition,'' Psychol. Rev., vol. 65, no. 6, pp. 375-385, 1958, doi: 10.1037/h0040233.

A sequential decision approach to problems in pattern recognition and learning. K S Pu, C H Chen, 10.1109/SAP.1964.271134Proc. 3rd Symp. Adapt. Process. (SAP). 3rd Symp. Adapt. ess. (SAP)K. S. Pu and C. H. Chen, ''A sequential decision approach to problems in pattern recognition and learning,'' in Proc. 3rd Symp. Adapt. Process. (SAP), 1964, pp. 48-71, doi: 10.1109/SAP.1964.271134.

A note on sequential decision approach to pattern recognition and machine learning. C H Chen, 10.1016/S0019-9958(66)80015-3Inf. Control. 96C. H. Chen, ''A note on sequential decision approach to pattern recogni- tion and machine learning,'' Inf. Control, vol. 9, no. 6, pp. 549-562, 1966, doi: 10.1016/S0019-9958(66)80015-3.

The influence of congenital deafness on processes concerned with reading: An initial investigation. C W Mcintyre, R D Odom, M Byassee, 10.1080/10862967009546922J. Reading Behav. 31C. W. McIntyre, R. D. Odom, and M. Byassee, ''The influence of congenital deafness on processes concerned with reading: An initial investigation,'' J. Reading Behav., vol. 3, no. 1, pp. 36-41, Jul. 1970, doi: 10.1080/10862967009546922.

Cooperative learning: Improving university instruction by basing practice on validated theory. D W Johnson, R T Johnson, K A Smith, J. Excellence. Coll. Teaching. 254D. W. Johnson, R. T. Johnson, and K. A. Smith, ''Cooperative learning: Improving university instruction by basing practice on validated theory,'' J. Excellence. Coll. Teaching, vol. 25, no. 4, pp. 85-118, 2014. [Online].

A self-supervised vowel recognition system. S K Pal, A K Datta, D D Majumder, Pattern Recognit. 121S. K. Pal, A. K. Datta, and D. D. Majumder, ''A self-supervised vowel recognition system,'' Pattern Recognit., vol. 12, no. 1, pp. 27-34, Jan. 1980.

Beyond supervised learning: A computer vision perspective. L Chum, A Subramanian, V N Balasubramanian, C V Jawahar, 10.1007/s41745-019-0099-3J. Indian Inst. Sci. 992L. Chum, A. Subramanian, V. N. Balasubramanian, and C. V. Jawahar, ''Beyond supervised learning: A computer vision perspective,'' J. Indian Inst. Sci., vol. 99, no. 2, pp. 177-199, Jun. 2019, doi: 10.1007/s41745-019-0099-3.

A survey of image labelling for computer vision applications. C Sager, C Janiesch, P Zschech, 10.1080/2573234X.2021.1908861J. Bus. Anal. 42C. Sager, C. Janiesch, and P. Zschech, ''A survey of image labelling for computer vision applications,'' J. Bus. Anal., vol. 4, no. 2, pp. 91-110, Jul. 2021, doi: 10.1080/2573234X.2021.1908861.

A review of computer vision methods in network security. J Zhao, R Masood, S Seneviratne, 10.1109/COMST.2021.3086475IEEE Commun. Surveys Tuts. 233J. Zhao, R. Masood, and S. Seneviratne, ''A review of computer vision methods in network security,'' IEEE Commun. Surveys Tuts., vol. 23, no. 3, pp. 1838-1878, Jun. 2021, doi: 10.1109/COMST.2021.3086475.

A survey on deep multimodal learning for computer vision: Advances, trends, applications, and datasets. K Bayoudh, R Knani, F Hamdaoui, A Mtibaa, 10.1007/s00371-021-02166-7Vis. Comput. 388K. Bayoudh, R. Knani, F. Hamdaoui, and A. Mtibaa, ''A survey on deep multimodal learning for computer vision: Advances, trends, applications, and datasets,'' Vis. Comput., vol. 38, no. 8, pp. 2939-2970, Aug. 2022, doi: 10.1007/s00371-021-02166-7.

Machine learning algorithms in healthcare: A literature survey. M Ferdous, J Debnath, N R Chakraborty, 10.1109/ICCCNT49239.2020.9225642Proc. 11th Int. Conf. Comput. 11th Int. Conf. ComputM. Ferdous, J. Debnath, and N. R. Chakraborty, ''Machine learn- ing algorithms in healthcare: A literature survey,'' in Proc. 11th Int. Conf. Comput., Commun. Netw. Technol. (ICCCNT), Jul. 2020, pp. 1-6, doi: 10.1109/ICCCNT49239.2020.9225642.

Survey of review spam detection using machine learning techniques. M Crawford, T M Khoshgoftaar, J D Prusa, A N Richter, H Al Najada, 10.1186/s40537-015-0029-9J. Big Data. 21M. Crawford, T. M. Khoshgoftaar, J. D. Prusa, A. N. Richter, and H. Al Najada, ''Survey of review spam detection using machine learn- ing techniques,'' J. Big Data, vol. 2, no. 1, pp. 1-24, Dec. 2015, doi: 10.1186/s40537-015-0029-9.

Machine learning and deep learning approaches for cybersecurity: A review. A Halbouni, T S Gunawan, M H Habaebi, M Halbouni, M Kartiwi, R Ahmad, IEEE Access. 10A. Halbouni, T. S. Gunawan, M. H. Habaebi, M. Halbouni, M. Kartiwi, and R. Ahmad, ''Machine learning and deep learning approaches for cybersecurity: A review,'' IEEE Access, vol. 10, Mar. 2021.

Deep learning for computer vision: A brief review. A Voulodimos, N Doulamis, A Doulamis, E Protopapadakis, 10.1155/2018/7068349Comput. Intell. Neurosci. 2018A. Voulodimos, N. Doulamis, A. Doulamis, and E. Protopapadakis, ''Deep learning for computer vision: A brief review,'' Comput. Intell. Neurosci., vol. 2018, pp. 1-13, Feb. 2018, doi: 10.1155/2018/7068349.

Deep learning for generic object detection: A survey. L Liu, W Ouyang, X Wang, P Fieguth, J Chen, X Liu, M Pietikäinen, 10.1007/s11263-019-01247-4Int. J. Comput. Vis. 128L. Liu, W. Ouyang, X. Wang, P. Fieguth, J. Chen, X. Liu, and M. Pietikäinen, ''Deep learning for generic object detection: A sur- vey,'' Int. J. Comput. Vis., vol. 128, pp. 261-318, Feb. 2020, doi: 10.1007/s11263-019-01247-4.

A support vector machinebased ensemble algorithm for breast cancer diagnosis. H Wang, B Zheng, S W Yoon, H S Ko, 10.1016/j.ejor.2017.12.001Eur. J. Oper. Res. 2672H. Wang, B. Zheng, S. W. Yoon, and H. S. Ko, ''A support vector machine- based ensemble algorithm for breast cancer diagnosis,'' Eur. J. Oper. Res., vol. 267, no. 2, pp. 687-699, Jun. 2018, doi: 10.1016/j.ejor.2017.12.001.

Spam email detection using machine learning algorithm. R Nayak, S A Jiwani, B Rajitha, 10.1016/j.matpr.2021.03.147Mater. Today, Proc. R. Nayak, S. A. Jiwani, and B. Rajitha, ''Spam email detection using machine learning algorithm,'' Mater. Today, Proc., pp. 1-5, Apr. 2021, doi: 10.1016/j.matpr.2021.03.147.

Differential deep convolutional neural network model for brain tumor classification. I A Kader, G Xu, Z Shuai, S Saminu, I Javaid, I. Salim Ahmad, 10.3390/brainsci11030352Brain Sci. 113352I. A. El Kader, G. Xu, Z. Shuai, S. Saminu, I. Javaid, and I. Salim Ahmad, ''Differential deep convolutional neural network model for brain tumor classification,'' Brain Sci., vol. 11, no. 3, p. 352, Mar. 2021, doi: 10.3390/brainsci11030352.

. J Tavares, N Jorge, Lecture Notes in Computational Vision and Biomechanics. SpringerJ. Tavares and N. Jorge, Lecture Notes in Computational Vision and Biomechanics. Springer, 2012.

Supervised learning computer vision benchmark for snake species identification from photographs: Implications for herpetology and global health. A M Durso, G K Moorthy, S P Mohanty, I Bolon, M Salathé, R R De Castañeda, 10.3389/frai.2021.582110Frontiers Artif. Intell. 4A. M. Durso, G. K. Moorthy, S. P. Mohanty, I. Bolon, M. Salathé, and R. R. de Castañeda, ''Supervised learning computer vision benchmark for snake species identification from photographs: Implications for herpetol- ogy and global health,'' Frontiers Artif. Intell., vol. 4, pp. 1-15, Apr. 2021, doi: 10.3389/frai.2021.582110.

Inspecting buildings using drones and computer vision: A machine learning approach to detect cracks and damages. H S Munawar, F Ullah, A Heravi, M J Thaheem, A Maqsoom, 10.3390/drones60100056H. S. Munawar, F. Ullah, A. Heravi, M. J. Thaheem, and A. Maqsoom, ''Inspecting buildings using drones and computer vision: A machine learning approach to detect cracks and damages,'' Drones, vol. 6, no. 1, p. 5, Dec. 2021, doi: 10.3390/drones6010005.

On deep set learning and the choice of aggregations. M Soelch, A Akhundov, P Van Der Smagt, J Bayer, 10.1007/978-3-030-30487-4_35Artificial Neural Networks and Machine Learning-ICANN 2019: Theoretical Neural Computation. 11727M. Soelch, A. Akhundov, P. van der Smagt, and J. Bayer, ''On deep set learning and the choice of aggregations,'' in Artificial Neural Networks and Machine Learning-ICANN 2019: Theoretical Neural Computation (Lecture Notes in Computer Science), vol. 11727. 2019, pp. 444-457, doi: 10.1007/978-3-030-30487-4_35.

Multiple instance learning: A survey of problem characteristics and applications. M.-A Carbonneau, V Cheplygina, E Granger, G Gagnon, 10.1016/j.patcog.2017.10.009Pattern Recognit. 77M.-A. Carbonneau, V. Cheplygina, E. Granger, and G. Gagnon, ''Mul- tiple instance learning: A survey of problem characteristics and appli- cations,'' Pattern Recognit., vol. 77, pp. 329-353, May 2018, doi: 10.1016/j.patcog.2017.10.009.

MILES: Multiple-instance learning via embedded instance selection. Y Chen, J Bi, J Z Wang, 10.1109/TPAMI.2006.248IEEE Trans. Pattern Anal. Mach. Intell. 2812Y. Chen, J. Bi, and J. Z. Wang, ''MILES: Multiple-instance learn- ing via embedded instance selection,'' IEEE Trans. Pattern Anal. Mach. Intell., vol. 28, no. 12, pp. 1931-1947, Dec. 2006, doi: 10.1109/TPAMI.2006.248.

Image database retrieval with multipleinstance learning techniques. C Yang, T Lozano-Perez, 10.1109/ICDE.2000.839416Proc. 16th Int. Conf. Data Eng. 16th Int. Conf. Data EngC. Yang and T. Lozano-Perez, ''Image database retrieval with multiple- instance learning techniques,'' in Proc. 16th Int. Conf. Data Eng., Feb. 2000, pp. 233-243, doi: 10.1109/ICDE.2000.839416.

Not-so-supervised: A survey of semi-supervised, multi-instance, and transfer learning in medical image analysis. V Cheplygina, M De Bruijne, J P Pluim, 10.1016/j.media.2019.03.009Image Anal. 54V. Cheplygina, M. de Bruijne, and J. P. Pluim, ''Not-so-supervised: A sur- vey of semi-supervised, multi-instance, and transfer learning in medical image analysis,'' Med. Image Anal., vol. 54, pp. 280-296, May 2019, doi: 10.1016/j.media.2019.03.009.

An adaptive supervision framework for active learning in object detection. S V Desai, A C Lagandula, W Guo, S Ninomiya, V N Balasubramanian, Proc. 30th Brit. Mach. Vis. Conf. 30th Brit. Mach. Vis. ConfS. V. Desai, A. C. Lagandula, W. Guo, S. Ninomiya, and V. N. Balasubra- manian, ''An adaptive supervision framework for active learning in object detection,'' in Proc. 30th Brit. Mach. Vis. Conf., 2019, pp. 1-13.

A review and experimental analysis of active learning over crowdsourced data. B Sayin, E Krivosheev, J Yang, A Passerini, F Casati, 10.1007/s10462-021-10021-3Artif. Intell. Rev. 547B. Sayin, E. Krivosheev, J. Yang, A. Passerini, and F. Casati, ''A review and experimental analysis of active learning over crowdsourced data,'' Artif. Intell. Rev., vol. 54, no. 7, pp. 5283-5305, Oct. 2021, doi: 10.1007/s10462-021-10021-3.

The power of ensembles for active learning in image classification. W H Beluch, T Genewein, A Nurnberger, J M Kohler, 10.1109/CVPR.2018.00976Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. IEEE/CVF Conf. Comput. Vis. Pattern RecognitW. H. Beluch, T. Genewein, A. Nurnberger, and J. M. Kohler, ''The power of ensembles for active learning in image classification,'' in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., Jun. 2018, pp. 9368-9377, doi: 10.1109/CVPR.2018.00976.

C Kao, P Sen, M Liu, Localization-Aware Active Learning. Springer2C. Kao, T. L. B, P. Sen, and M. Liu, Localization-Aware Active Learning, vol. 2. Springer, 2019.

Active learning with Gaussian processes for object categorization. A Kapoor, K Grauman, R Urtasun, T Darrell, 10.1109/ICCV.2007.4408844Proc. IEEE 11th Int. Conf. Comput. Vis. IEEE 11th Int. Conf. Comput. VisA. Kapoor, K. Grauman, R. Urtasun, and T. Darrell, ''Active learning with Gaussian processes for object categorization,'' in Proc. IEEE 11th Int. Conf. Comput. Vis., Oct. 2007, pp. 1-8, doi: 10.1109/ICCV.2007.4408844.

Facial action unit detection using active learning and an efficient non-linear kernel approximation. T Senechal, D Mcduff, R E Kaliouby, 10.1109/ICCVW.2015.11Proc. IEEE Int. Conf. Comput. Vis. Workshop (ICCVW). IEEE Int. Conf. Comput. Vis. Workshop (ICCVW)T. Senechal, D. McDuff, and R. E. Kaliouby, ''Facial action unit detection using active learning and an efficient non-linear kernel approximation,'' in Proc. IEEE Int. Conf. Comput. Vis. Workshop (ICCVW), Dec. 2015, pp. 10-18, doi: 10.1109/ICCVW.2015.11.

Task-aware variational adversarial active learning. K Kim, D Park, K I Kim, S Y Chun, 10.1109/CVPR46437.2021.00807Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR). IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR)K. Kim, D. Park, K. I. Kim, and S. Y. Chun, ''Task-aware varia- tional adversarial active learning,'' in Proc. IEEE/CVF Conf. Com- put. Vis. Pattern Recognit. (CVPR), Jun. 2021, pp. 8162-8171, doi: 10.1109/CVPR46437.2021.00807.

Few-shot image recognition by predicting parameters from activations. S Qiao, C Liu, W Shen, A Yuille, 10.1109/CVPR.2018.00755Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. IEEE/CVF Conf. Comput. Vis. Pattern RecognitS. Qiao, C. Liu, W. Shen, and A. Yuille, ''Few-shot image recogni- tion by predicting parameters from activations,'' in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., Jun. 2018, pp. 7229-7238, doi: 10.1109/CVPR.2018.00755.

Deep hashing network for unsupervised domain adaptation supplementary material. H Venkateswara, J Eusebio, S Chakraborty, S Panchanathan, Proc. 30th IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR). 30th IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)USA1H. Venkateswara, J. Eusebio, S. Chakraborty, and S. Panchanathan, ''Deep hashing network for unsupervised domain adaptation supplemen- tary material,'' in Proc. 30th IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), USA, 2017, vol. 1, no. 10.

On parameter tuning in meta-learning for computer vision. F G Mohammadi, M H Amini, H R Arabnia, arXiv:2003.008372020F. G. Mohammadi, M. H. Amini, and H. R. Arabnia, ''On parameter tuning in meta-learning for computer vision,'' 2020, arXiv:2003.00837.

Semantic autoencoder for zero-shot learning. E Kodirov, T Xiang, S Gong, Q Mary, Proc. CVPR. CVPRE. Kodirov, T. Xiang, S. Gong, and Q. Mary, ''Semantic autoencoder for zero-shot learning,'' in Proc. CVPR, Jul. 2017, pp. 3174-3183. [Online].

Optimization as a model for few-shot learning. S Ravi, H Larochelle, Proc. 5th Int. Conf. Learn. Represent. (ICLR. 5th Int. Conf. Learn. Represent. (ICLRS. Ravi and H. Larochelle, ''Optimization as a model for few-shot learning,'' in Proc. 5th Int. Conf. Learn. Represent. (ICLR), 2017, pp. 1-11.

Matching networks for one shot learning,'' in Proc. O Vinyals, C Blundell, T Lillicrap, K Kavukcuoglu, D Wierstra, Adv. Neural Inf. Process. Syst. O. Vinyals, C. Blundell, T. Lillicrap, K. Kavukcuoglu, and D. Wierstra, ''Matching networks for one shot learning,'' in Proc. Adv. Neural Inf. Process. Syst., 2016, pp. 3637-3645.

A closer look at few-shot classification. W Y Chen, Y C F Wang, Y C Liu, Z Kira, J B Huang, Proc. 7th Int. Conf. Learn. Represent. (ICLR). 7th Int. Conf. Learn. Represent. (ICLR)W. Y. Chen, Y. C. F. Wang, Y. C. Liu, Z. Kira, and J. B. Huang, ''A closer look at few-shot classification,'' in Proc. 7th Int. Conf. Learn. Represent. (ICLR), 2019, pp. 1-17.

Multi-task learning using uncertainty to weigh losses for scene geometry and semantics. A Kendall, Y Gal, R Cipolla, Proc. CVPR. CVPRA. Kendall, Y. Gal, and R. Cipolla, ''Multi-task learning using uncertainty to weigh losses for scene geometry and semantics,'' in Proc. CVPR, Jun. 2018, pp. 7482-7491.

A modulation module for multi-task learning with applications in image retrieval. X Zhao, H Li, X Shen, X Liang, Y Wu, 10.1007/978-3-030-01246-5_25Computer Vision. 11205X. Zhao, H. Li, X. Shen, X. Liang, and Y. Wu, ''A modulation module for multi-task learning with applications in image retrieval,'' in Com- puter Vision (Lecture Notes in Computer Science), vol. 11205. 2018, pp. 415-432, doi: 10.1007/978-3-030-01246-5_25.

Cross-stitch networks for multi-task learning. I Misra, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR). IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)I. Misra, ''Cross-stitch networks for multi-task learning,'' in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), 2016.

Information extraction from electronic medical records using multitask recurrent neural network with contextual word embedding. J Yang, Y Liu, M Qian, C Guan, X Yuan, 10.3390/app9183658Appl. Sci. 9183658J. Yang, Y. Liu, M. Qian, C. Guan, and X. Yuan, ''Information extraction from electronic medical records using multitask recurrent neural network with contextual word embedding,'' Appl. Sci., vol. 9, no. 18, p. 3658, Sep. 2019, doi: 10.3390/app9183658.

A multi-task contextual atrous residual network for brain tumor detection & segmentation. N Le, K Yamazaki, K G Quach, D Truong, M Savvides, 10.1109/ICPR48806.2021.9412414Proc. Int. Conf. Pattern Recognit. Int. Conf. Pattern RecognitN. Le, K. Yamazaki, K. G. Quach, D. Truong, and M. Savvides, ''A multi-task contextual atrous residual network for brain tumor detec- tion & segmentation,'' in Proc. Int. Conf. Pattern Recognit., Jan. 2020, pp. 5943-5950, doi: 10.1109/ICPR48806.2021.9412414.

Self-supervised domain adaptation for computer vision tasks. J Xu, L Xiao, A M López, 10.1109/ACCESS.2019.2949697IEEE Access. 7J. Xu, L. Xiao, and A. M. López, ''Self-supervised domain adaptation for computer vision tasks,'' IEEE Access, vol. 7, pp. 156694-156706, 2019, doi: 10.1109/ACCESS.2019.2949697.

Semisupervised histology classification using deep multiple instance learning and contrastive predictive coding. M Y Lu, R J Chen, J Wang, D Dillon, F Mahmood, arXiv:1910.10825M. Y. Lu, R. J. Chen, J. Wang, D. Dillon, and F. Mahmood, ''Semi- supervised histology classification using deep multiple instance learning and contrastive predictive coding,'' 2019, arXiv:1910.10825.

Constructive learning for humanrobot interaction. A Singh, S Karanam, D Kumar, 10.1109/MPOT.2012.2189443IEEE Potentials. 324A. Singh, S. Karanam, and D. Kumar, ''Constructive learning for human- robot interaction,'' IEEE Potentials, vol. 32, no. 4, pp. 13-19, Jul. 2013, doi: 10.1109/MPOT.2012.2189443.

Facial expression recognition using constructive feedforward neural networks. L Ma, K Khorasani, Trans, Syst, Cybern Man, B , Cybern , 10.1109/TSMCB.2004.82593034L. Ma and K. Khorasani, ''Facial expression recognition using con- structive feedforward neural networks,'' IEEE Trans. Syst., Man, Cybern., B, Cybern., vol. 34, no. 3, pp. 1588-1595, Jun. 2004, doi: 10.1109/TSMCB.2004.825930.

3D model retrieval using constructivelearning for cross-model correlation. J Yang, J Zhao, Q Sun, 10.1016/j.neucom.2017.01.030Neurocomputing. 275J. Yang, J. Zhao, and Q. Sun, ''3D model retrieval using constructive- learning for cross-model correlation,'' Neurocomputing, vol. 275, pp. 1-9, Jan. 2018, doi: 10.1016/j.neucom.2017.01.030.

Machine learning: Algorithms, real-world applications and research directions. I H Sarker, 10.1007/s42979-021-00592-xComput. Sci. 23Social NetwI. H. Sarker, ''Machine learning: Algorithms, real-world applications and research directions,'' Social Netw. Comput. Sci., vol. 2, no. 3, pp. 1-21, May 2021, doi: 10.1007/s42979-021-00592-x.

Mining association in large databases. R Agrawal, T Imielinski, A Swami, Proc. ACM SIGMOD Int. Conf. Manag. Data (SIGMOD). ACM SIGMOD Int. Conf. Manag. Data (SIGMOD)R. Agrawal, T. Imielinski, and A. Swami, ''Mining association in large databases,'' in Proc. ACM SIGMOD Int. Conf. Manag. Data (SIGMOD), 1993, pp. 207-216.

Computational intelligence based machine learning methods for rule-based reasoning in computer vision applications,'' in Proc. T T Dhivyaprabha, P Subashini, M Krishnaveni, 10.1109/SSCI.2016.7850050IEEE Symp. Ser. Comput. Intell. (SSCI). T. T. Dhivyaprabha, P. Subashini, and M. Krishnaveni, ''Computational intelligence based machine learning methods for rule-based reasoning in computer vision applications,'' in Proc. IEEE Symp. Ser. Comput. Intell. (SSCI), 2016, pp. 1-8, doi: 10.1109/SSCI.2016.7850050.

The PASCAL visual object classes (VOC) challenge. M Everingham, L Van Gool, C K I Williams, J Winn, A Zisserman, 10.1007/s11263-009-0275-4Int. J. Comput. Vis. 882M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman, ''The PASCAL visual object classes (VOC) chal- lenge,'' Int. J. Comput. Vis., vol. 88, no. 2, pp. 303-338, Jun. 2010, doi: 10.1007/s11263-009-0275-4.

Set-oriented mining for association rules in relational databases. M Houtsma, A Swami, 10.1109/icde.1995.380413Proc. 11th Int. Conf. Data Eng. 11th Int. Conf. Data EngM. Houtsma and A. Swami, ''Set-oriented mining for association rules in relational databases,'' in Proc. 11th Int. Conf. Data Eng., 1995, pp. 25-33, doi: 10.1109/icde.1995.380413.

Fast algorithms for mining association rules in large databases. R Agrawal, R Srikant, Proc. 20th Int. Conf. Very Large Data Bases. 20th Int. Conf. Very Large Data BasesR. Agrawal and R. Srikant, ''Fast algorithms for mining association rules in large databases,'' in Proc. 20th Int. Conf. Very Large Data Bases, 1994, pp. 487-499.

On the relationship between entropy and Information. A Shafiee, M Karimi, 10.4006/1.3153419Phys. Essays. 203A. Shafiee and M. Karimi, ''On the relationship between entropy and Information,'' Phys. Essays, vol. 20, no. 3, pp. 487-493, Sep. 2007, doi: 10.4006/1.3153419.

Active object localization with deep reinforcement learning. J C Caicedo, S Lazebnik, 10.1109/ICCV.2015.286Proc. IEEE Int. Conf. Comput. Vis. (ICCV). IEEE Int. Conf. Comput. Vis. (ICCV)J. C. Caicedo and S. Lazebnik, ''Active object localization with deep reinforcement learning,'' in Proc. IEEE Int. Conf. Comput. Vis. (ICCV), Dec. 2015, pp. 2488-2496, doi: 10.1109/ICCV.2015.286.

Deep reinforcement learning for active breast lesion detection from DCE-MRI,'' in Proc. G Maicas, G Carneiro, A P Bradley, J C Nascimento, I Reid, 10.1007/978-3-319-66179-7_76Lecture Notes in Computer Science. Quebec City, QC, Canada; Heidelberg, GermanySpringer-Verlag10435G. Maicas, G. Carneiro, A. P. Bradley, J. C. Nascimento, and I. Reid, ''Deep reinforcement learning for active breast lesion detection from DCE-MRI,'' in Proc. Int. Conf. Med. Image Comput. Comput.- Assist. Intervent., in Lecture Notes in Computer Science, Quebec City, QC, Canada, vol. 10435. Heidelberg, Germany: Springer-Verlag, Sep. 2017, pp. 665-673, doi: 10.1007/978-3-319-66179-7_76.

Multi-scale deep reinforcement learning for real-time 3D-landmark detection in CT scans. F.-C Ghesu, B Georgescu, Y Zheng, S Grbic, A Maier, J Hornegger, D Comaniciu, 10.1109/TPAMI.2017.2782687IEEE Trans. Pattern Anal. Mach. Intell. 411F.-C. Ghesu, B. Georgescu, Y. Zheng, S. Grbic, A. Maier, J. Hornegger, and D. Comaniciu, ''Multi-scale deep reinforcement learning for real-time 3D-landmark detection in CT scans,'' IEEE Trans. Pattern Anal. Mach. Intell., vol. 41, no. 1, pp. 176-189, Jan. 2019, doi: 10.1109/TPAMI.2017.2782687.

Multiple landmark detection using multi-agent reinforcement learning. A Vlontzos, A Alansary, K Kamnitsas, D Rueckert, B Kainz, 10.1007/978-3-030-32251-9_29Proc. 22nd Int. Conf. Med. Image Comput. Comput. Assist. Intervent. (MICCAI). 22nd Int. Conf. Med. Image Comput. Comput. Assist. Intervent. (MICCAI)Shenzhen, China11767A. Vlontzos, A. Alansary, K. Kamnitsas, D. Rueckert, and B. Kainz, ''Multiple landmark detection using multi-agent reinforcement learning,'' in Proc. 22nd Int. Conf. Med. Image Comput. Comput. Assist. Intervent. (MICCAI), in Lecture Notes in Computer Science, Shenzhen, China, vol. 11767, Oct. 2019, pp. 262-270, doi: 10.1007/978-3-030-32251- 9_29.

Efficient object detection in large images using deep reinforcement learning. B Uzkent, C Yeh, S Ermon, 10.1109/WACV45572.2020.9093447Proc. IEEE Winter Conf. Appl. Comput. Vis. (WACV). IEEE Winter Conf. Appl. Comput. Vis. (WACV)B. Uzkent, C. Yeh, and S. Ermon, ''Efficient object detection in large images using deep reinforcement learning,'' in Proc. IEEE Winter Conf. Appl. Comput. Vis. (WACV), Mar. 2020, pp. 1813-1822, doi: 10.1109/WACV45572.2020.9093447.

Efficient one-shot video object segmentation. N Hoang-Xuan, E.-R Nguyen, T.-D Pham-Le, K Hoang-Nguyen, 10.1109/NICS51282.2020.9335847Proc. 7th NAFOS-TED Conf. Inf. Comput. Sci. (NICS). 7th NAFOS-TED Conf. Inf. Comput. Sci. (NICS)N. Hoang-Xuan, E.-R. Nguyen, T.-D. Pham-Le, and K. Hoang-Nguyen, ''Efficient one-shot video object segmentation,'' in Proc. 7th NAFOS- TED Conf. Inf. Comput. Sci. (NICS), Nov. 2020, pp. 320-325, doi: 10.1109/NICS51282.2020.9335847.

Learning video object segmentation from static images. F Perazzi, A Khoreva, R Benenson, B Schiele, A Sorkine-Hornung, 10.1109/CVPR.2017.372Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR). IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)F. Perazzi, A. Khoreva, R. Benenson, B. Schiele, and A. Sorkine-Hornung, ''Learning video object segmentation from static images,'' in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jul. 2017, pp. 3491-3500, doi: 10.1109/CVPR.2017.372.

VideoSSL: Semisupervised learning for video classification. L Jing, T Parag, Z Wu, Y Tian, H Wang, 10.1109/WACV48630.2021.00115Proc. IEEE Winter Conf. Appl. Comput. Vis. (WACV). IEEE Winter Conf. Appl. Comput. Vis. (WACV)L. Jing, T. Parag, Z. Wu, Y. Tian, and H. Wang, ''VideoSSL: Semi- supervised learning for video classification,'' in Proc. IEEE Winter Conf. Appl. Comput. Vis. (WACV), Jan. 2021, pp. 1109-1118, doi: 10.1109/WACV48630.2021.00115.

Semi-supervised learning with graph learning-convolutional networks. B Jiang, Z Zhang, D Lin, J Tang, B Luo, Proc. nullB. Jiang, Z. Zhang, D. Lin, J. Tang, and B. Luo, ''Semi-supervised learning with graph learning-convolutional networks,'' in Proc.

Ieee/Cvf, Conf, Comput. Vis. Pattern Recognit. (CVPR). IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2019, pp. 11313-11320.

Naive-student: Leveraging semisupervised learning in video sequences for urban scene segmentation. L C Chen, R G Lopes, B Cheng, M D Collins, E D Cubuk, B Zoph, H Adam, J Shlens, 10.1007/978-3-030-58545-7_40Lecture Notes in Computer Science). Computer VisionL. C. Chen, R. G. Lopes, B. Cheng, M. D. Collins, E. D. Cubuk, B. Zoph, H. Adam, and J. Shlens, ''Naive-student: Leveraging semi- supervised learning in video sequences for urban scene segmentation,'' Computer Vision (Lecture Notes in Computer Science), vol. 12354. 2020, pp. 695-714, doi: 10.1007/978-3-030-58545-7_40.

Deep graphical feature learning for the feature matching problem. Z Zhang, W S Lee, 10.1109/ICCV.2019.00519Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV). IEEE/CVF Int. Conf. Comput. Vis. (ICCV)Z. Zhang and W. S. Lee, ''Deep graphical feature learning for the feature matching problem,'' in Proc. IEEE/CVF Int. Conf. Com- put. Vis. (ICCV), Oct. 2019, pp. 5086-5095, doi: 10.1109/ICCV.2019. 00519.

Discovering visual patterns in art collections with spatially-consistent feature learning. X Shen, A A Efros, M Aubry, 10.1109/CVPR.2019.00950Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR). IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR)X. Shen, A. A. Efros, and M. Aubry, ''Discovering visual patterns in art collections with spatially-consistent feature learning,'' in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2019, pp. 9270-9279, doi: 10.1109/CVPR.2019.00950.

A survey of robot learning strategies for human-robot collaboration in industrial settings. D Mukherjee, K Gupta, L H Chang, H Najjaran, 10.1016/j.rcim.2021.102231Computer-Integrated Manuf. 73102231RobotD. Mukherjee, K. Gupta, L. H. Chang, and H. Najjaran, ''A survey of robot learning strategies for human-robot collaboration in indus- trial settings,'' Robot. Computer-Integrated Manuf., vol. 73, Feb. 2022, Art. no. 102231, doi: 10.1016/j.rcim.2021.102231.

Computer vision meets educational robotics. A Sophokleous, P Christodoulou, L Doitsidis, S A Chatzichristofis, 10.3390/electronics10060730Electron. 106A. Sophokleous, P. Christodoulou, L. Doitsidis, and S. A. Chatzichristofis, ''Computer vision meets educational robotics,'' Electron., vol. 10, no. 6, pp. 1-24, 2021, doi: 10.3390/electronics 10060730.

A comprehensive survey on transfer learning. F Zhuang, Z Qi, K Duan, D Xi, Y Zhu, H Zhu, H Xiong, Q He, 10.1109/JPROC.2020.3004555Proc. IEEE. IEEE109F. Zhuang, Z. Qi, K. Duan, D. Xi, Y. Zhu, H. Zhu, H. Xiong, and Q. He, ''A comprehensive survey on transfer learning,'' Proc. IEEE, vol. 109, no. 1, pp. 43-76, Jul. 2021, doi: 10.1109/JPROC.2020.3004555.

Deep convolutional neural networks with transfer learning for computer vision-based data-driven pavement distress detection. K Gopalakrishnan, S K Khaitan, A Choudhary, A , 10.1016/j.conbuildmat.2017.09.110Construction Building Mater. 157K. Gopalakrishnan, S. K. Khaitan, A. Choudhary, and A. Agrawal, ''Deep convolutional neural networks with transfer learning for com- puter vision-based data-driven pavement distress detection,'' Con- struction Building Mater., vol. 157, pp. 322-330, Dec. 2017, doi: 10.1016/j.conbuildmat.2017.09.110.

FixyNN: Efficient hardware for mobile computer vision via transfer learning. P N Whatmough, C Zhou, P Hansen, S K Venkataramanaiah, J.-S Seo, M Mattina, arXiv:1902.11128P. N. Whatmough, C. Zhou, P. Hansen, S. K. Venkataramanaiah, J.-S. Seo, and M. Mattina, ''FixyNN: Efficient hardware for mobile computer vision via transfer learning,'' 2019, arXiv:1902.11128.

Transfer learning with deep neural networks for computer vision. J Xie, Tech. Rep.J. Xie, ''Transfer learning with deep neural networks for computer vision,'' Tech. Rep., 2019.

Transfer learning methods as a new approach in computer vision tasks with small datasets. A Brodzicki, M Piekarski, D Kucharski, J Jaworek-Korjakowska, M Gorgon, 10.2478/fcds-2020-0010Comput. Decis. Sci. 453A. Brodzicki, M. Piekarski, D. Kucharski, J. Jaworek-Korjakowska, and M. Gorgon, ''Transfer learning methods as a new approach in computer vision tasks with small datasets,'' Found. Comput. Decis. Sci., vol. 45, no. 3, pp. 179-193, Sep. 2020, doi: 10.2478/fcds-2020-0010.

British sign language recognition via late fusion of computer vision and leap motion with transfer learning to American sign language. J J Bird, A Ekárt, D R Faria, 10.3390/s20185151Sensors. 2018J. J. Bird, A. Ekárt, and D. R. Faria, ''British sign language recognition via late fusion of computer vision and leap motion with transfer learning to American sign language,'' Sensors, vol. 20, no. 18, pp. 1-19, 2020, doi: 10.3390/s20185151.

Ensemble learning. I H Witten, E Frank, M A Hall, C J , 10.1016/b978-0-12-804291-5.00012-xData Mining. 4I. H. Witten, E. Frank, M. A. Hall, and C. J. Pal, ''Ensemble learning,'' Data Mining, vol. 4, pp. 479-501, Oct. 2017, doi: 10.1016/b978-0-12-804291-5.00012-x.

Road damage detection using deep ensemble learning. K Doshi, Y Yilmaz, 10.1109/BigData50022.2020.9377774Proc. IEEE Int. Conf. Big Data (Big Data). IEEE Int. Conf. Big Data (Big Data)K. Doshi and Y. Yilmaz, ''Road damage detection using deep ensemble learning,'' in Proc. IEEE Int. Conf. Big Data (Big Data), Dec. 2020, pp. 5540-5544, doi: 10.1109/BigData50022.2020. 9377774.

A twobranch neural network for non-homogeneous dehazing via ensemble learning. Y Yu, H Liu, M Fu, J Chen, X Wang, K Wang, 10.1109/CVPRW53098.2021.00028Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW). IEEE/CVF Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW)Y. Yu, H. Liu, M. Fu, J. Chen, X. Wang, and K. Wang, ''A two- branch neural network for non-homogeneous dehazing via ensemble learning,'' in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW), Jun. 2021, pp. 193-202, doi: 10.1109/CVPRW53098.2021.00028.

Strong classification system for wear identification on milling processes using computer vision and ensemble learning. V Riego, M Castejón-Limas, L Sánchez-González, L Fernández-Robles, H Perez, J Diez-Gonzalez, Á.-M Guerrero-Higueras, 10.1016/j.neucom.2020.07.131Neurocomputing. 456V. Riego, M. Castejón-Limas, L. Sánchez-González, L. Fernández-Robles, H. Perez, J. Diez-Gonzalez, and Á.-M. Guerrero-Higueras, ''Strong classification system for wear identification on milling processes using computer vision and ensemble learning,'' Neurocomputing, vol. 456, pp. 678-684, Oct. 2021, doi: 10.1016/j.neucom.2020.07.131.

NTIRE 2017 challenge on single image super-resolution: Dataset and study. E Agustsson, R Timofte, 10.1109/CVPRW.2017.150Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW). IEEE Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW)E. Agustsson and R. Timofte, ''NTIRE 2017 challenge on single image super-resolution: Dataset and study,'' in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW), Jul. 2017, pp. 1122-1131, doi: 10.1109/CVPRW.2017.150.

Adaptive computer vision: Online learning for object recognition. H Bekel, I Bax, G Heidemann, H Ritter, Proc. Joint Pattern Recognit. Symp. Joint Pattern Recognit. SympH. Bekel, I. Bax, G. Heidemann, and H. Ritter, ''Adaptive computer vision: Online learning for object recognition,'' in Proc. Joint Pattern Recognit. Symp., 2004, pp. 447-448.

Zero-shot learning-A comprehensive evaluation of the good, the bad and the ugly. Y Xian, C H Lampert, B Schiele, Z Akata, 10.1109/TPAMI.2018.2857768IEEE Trans. Pattern Anal. Mach. Intell. 419Y. Xian, C. H. Lampert, B. Schiele, and Z. Akata, ''Zero-shot learning-A comprehensive evaluation of the good, the bad and the ugly,'' IEEE Trans. Pattern Anal. Mach. Intell., vol. 41, no. 9, pp. 2251-2265, Sep. 2019, doi: 10.1109/TPAMI.2018.2857768.

Zero-shot text classification with generative language models. R Puri, B Catanzaro, arXiv:1912.10165R. Puri and B. Catanzaro, ''Zero-shot text classification with generative language models,'' 2019, arXiv:1912.10165.

Semantic-guided zero-shot learning for lowlight image/video enhancement. S Zheng, G Gupta, Proc. IEEE/CVF Winter Conf. Appl. Comput. Vis. IEEE/CVF Winter Conf. Appl. Comput. VisS. Zheng and G. Gupta, ''Semantic-guided zero-shot learning for low- light image/video enhancement,'' in Proc. IEEE/CVF Winter Conf. Appl. Comput. Vis., Jan. 2022, pp. 581-590.

Federated learning: A distributed shared machine learning method. K Hu, Y Li, M Xia, J Wu, M Lu, S Zhang, L Weng, 10.1155/2021/8261663Complexity. 2021K. Hu, Y. Li, M. Xia, J. Wu, M. Lu, S. Zhang, and L. Weng, ''Federated learning: A distributed shared machine learning method,'' Complexity, vol. 2021, pp. 1-20, Aug. 2021, doi: 10.1155/2021/ 8261663.

FedCV: A federated learning framework for diverse computer vision tasks. C He, A D Shah, Z Tang, D F A N Sivashunmugam, K Bhogaraju, M Shimpi, L Shen, X Chu, M Soltanolkotabi, S Avestimehr, arXiv:2111.110662021C. He, A. D. Shah, Z. Tang, D. F. A. N. Sivashunmugam, K. Bhogaraju, M. Shimpi, L. Shen, X. Chu, M. Soltanolkotabi, and S. Avestimehr, ''FedCV: A federated learning framework for diverse computer vision tasks,'' 2021, arXiv:2111.11066.

Realworld image datasets for federated learning. J Luo, X Wu, Y Luo, A Huang, Y Huang, Y Liu, Q Yang, arXiv:1910.11089J. Luo, X. Wu, Y. Luo, A. Huang, Y. Huang, Y. Liu, and Q. Yang, ''Real- world image datasets for federated learning,'' 2019, arXiv:1910.11089.

Experiments of federated learning for COVID-19 chest X-ray images. B Yan, J Wang, J Cheng, Y Zhou, Y Zhang, Y Yang, L Liu, H Zhao, C Wang, B Liu, 10.1007/978-3-030-78618-2_4Commun. Comput. Inf. Sci. 1423B. Yan, J. Wang, J. Cheng, Y. Zhou, Y. Zhang, Y. Yang, L. Liu, H. Zhao, C. Wang, and B. Liu, ''Experiments of federated learning for COVID-19 chest X-ray images,'' Commun. Comput. Inf. Sci., vol. 1423, pp. 41-53, Jul. 2021, doi: 10.1007/978-3-030-78618-2_4.

Research paper classification using supervised machine learning techniques. S Chowdhury, M P Schoen, 10.1109/IETC47856.2020.9249211Proc. Intermountain. Eng. Technol. Comput. (IETC). Intermountain. Eng. Technol. Comput. (IETC)S. Chowdhury and M. P. Schoen, ''Research paper classification using supervised machine learning techniques,'' in Proc. Intermountain. Eng. Technol. Comput. (IETC), Jul. 2020, pp. 1-6, doi: 10.1109/IETC47856.2020.9249211.

Extra-3. M Soelch, A Akhundov, P Van Der Smagt, J Bayer, IEEE Access. 7M. Soelch, A. Akhundov, P. van der Smagt, and J. Bayer, ''Extra-3,'' IEEE Access, vol. 7, pp. 117227-117245, 2019.

Investigating problems of semi-supervised learning for word sense disambiguation,'' in Computer Processing of Oriental Languages. Beyond the Orient: The Research Challenges Ahead. A C Le, A Shimazu, L M Nguyen, 10.1007/11940098_51Lecture Notes in Computer Science). 4285A. C. Le, A. Shimazu, and L. M. Nguyen, ''Investigating problems of semi-supervised learning for word sense disambiguation,'' in Computer Processing of Oriental Languages. Beyond the Orient: The Research Challenges Ahead (Lecture Notes in Computer Science), vol. 4285. Oct. 2014, pp. 482-489, doi: 10.1007/11940098_51.

The challenges of continuous self-supervised learning. S Purushwalkam, P Morgado, A Gupta, arXiv:2203.127102022S. Purushwalkam, P. Morgado, and A. Gupta, ''The challenges of contin- uous self-supervised learning,'' 2022, arXiv:2203.12710.

Interactive inductive learning system,'' Front. I Birzniece, 10.3233/978-1-60750-688-1-380Artif. Intell. Appl. 224I. Birzniece, ''Interactive inductive learning system,'' Front. Artif. Intell. Appl., vol. 224, pp. 380-393, Jan. 2011, doi: 10.3233/978-1-60750-688-1-380.

A transductive approach for video object segmentation. Y Zhang, Z Wu, H Peng, S Lin, 10.1109/CVPR42600.2020.00698Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR). IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR)Y. Zhang, Z. Wu, H. Peng, and S. Lin, ''A transductive approach for video object segmentation,'' in Proc. IEEE/CVF Conf. Com- put. Vis. Pattern Recognit. (CVPR), Jun. 2020, pp. 6947-6956, doi: 10.1109/CVPR42600.2020.00698.

Results of the active learning challenge. I Guyon, Proc. Active Learn. Exp. Design Workshop Conjunct. AISTATS. 16I. Guyon, ''Results of the active learning challenge,'' in Proc. Active Learn. Exp. Design Workshop Conjunct. AISTATS, vol. 16, 2011, pp. 19-45, [Online]. Available: http://eprints.pascal- network.org/archive/00007803/

Deep learning in computer vision: A critical review of emerging techniques and application scenarios. J Chai, H Zeng, A Li, E W T Ngai, 10.1016/j.mlwa.2021.100134Mach. Learn. Appl. 6Art. no. 100134J. Chai, H. Zeng, A. Li, and E. W. T. Ngai, ''Deep learning in com- puter vision: A critical review of emerging techniques and application scenarios,'' Mach. Learn. Appl., vol. 6, Dec. 2021, Art. no. 100134, doi: 10.1016/j.mlwa.2021.100134.

Efficient vector quantization using the WTA-rule with activity equalization. G Heidemann, H Ritter, Neural Process. Lett. 131G. Heidemann and H. Ritter, ''Efficient vector quantization using the WTA-rule with activity equalization,'' Neural Process. Lett., vol. 13, no. 1, pp. 17-30, 2005.

Transfer learning in computer vision tasks: Remember where you come from. X Li, Y Grandvalet, F Davoine, J Cheng, Y Cui, H Zhang, S Belongie, Y.-H Tsai, M.-H Yang, 10.1016/j.imavis.2019.103853Image Vis. Comput. 93103853X. Li, Y. Grandvalet, F. Davoine, J. Cheng, Y. Cui, H. Zhang, S. Belongie, Y.-H. Tsai, and M.-H. Yang, ''Transfer learning in computer vision tasks: Remember where you come from,'' Image Vis. Comput., vol. 93, Jan. 2020, Art. no. 103853, doi: 10.1016/j.imavis.2019.103853.

Some fundamental issues in ensemble methods. W Wang, 10.1109/IJCNN.2008.4634108Proc. IEEE Int. Joint Conf. Neural Netw. (IEEE World Congr. Comput. Intelligence). IEEE Int. Joint Conf. Neural Netw. (IEEE World Congr. Comput. Intelligence)W. Wang, ''Some fundamental issues in ensemble methods,'' in Proc. IEEE Int. Joint Conf. Neural Netw. (IEEE World Congr. Comput. Intel- ligence), Jun. 2008, pp. 2243-2250, doi: 10.1109/IJCNN.2008.4634108.

Ensemble learning. R Polikar, 10.1007/978-1-4419-9326-7_1Ensemble Machine Learning. C. Zhang and Y. MaBoston, MA, USASpringerR. Polikar, ''Ensemble learning,'' in Ensemble Machine Learning, C. Zhang and Y. Ma, Eds. Boston, MA, USA: Springer, Jan. 2012, doi: 10.1007/978-1-4419-9326-7_1.

Addressing class imbalance in federated learning. L Wang, S Xu, X Wang, Q Zhu, Proc. 35th AAAI Conf. 35th AAAI Conf11L. Wang, S. Xu, X. Wang, and Q. Zhu, ''Addressing class imbalance in federated learning,'' in Proc. 35th AAAI Conf. Artif. Intell., vol. 11, 2021, pp. 10165-10173.

Automatic blur type classification via ensemble SVM. R Wang, W Li, R Li, L Zhang, 10.1016/j.image.2018.08.003Image Commun. 71Signal ProcessR. Wang, W. Li, R. Li, and L. Zhang, ''Automatic blur type classifi- cation via ensemble SVM,'' Signal Process., Image Commun., vol. 71, pp. 24-35, Feb. 2019, doi: 10.1016/j.image.2018.08.003.

PSNet: Reconfigurable network topology design for accelerating parameter server architecture based distributed machine learning. L Liu, Q Jin, D Wang, H Yu, G Sun, S Luo, Future Gener. Comput. Syst. 106L. Liu, Q. Jin, D. Wang, H. Yu, G. Sun, and S. Luo, ''PSNet: Reconfig- urable network topology design for accelerating parameter server archi- tecture based distributed machine learning,'' Future Gener. Comput. Syst., vol. 106, pp. 320-332, May 2020.

S4L: Self-supervised semi-supervised learning. X Zhai, A Oliver, A Kolesnikov, L Beyer, Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV). IEEE/CVF Int. Conf. Comput. Vis. (ICCV)X. Zhai, A. Oliver, A. Kolesnikov, and L. Beyer, ''S4L: Self-supervised semi-supervised learning,'' in Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV), Oct. 2019, pp. 1476-1485.

The curious robot: Learningvisual representations via physical interactions. L Pinto, D Gandhi, Y Han, Y L Park, A Gupta, 10.1007/978-3-319-46475-6_1Computer Vision-ECCV 2016. Cham, SwitzerlandSpringer9906L. Pinto, D. Gandhi, Y. Han, Y. L. Park, and A. Gupta, ''The curious robot: Learningvisual representations via physical interactions,'' in Computer Vision-ECCV 2016 (Lecture Notes in Computer Science), vol. 9906. Cham, Switzerland: Springer, 2016, pp. 3-18, doi: 10.1007/978-3-319- 46475-6_1.

Vision processing for robot learning. U Nehmzow, Int. J. 262Ind. RobotU. Nehmzow, ''Vision processing for robot learning,'' Ind. Robot, Int. J., vol. 26, no. 2, pp. 121-130, Mar. 1999.