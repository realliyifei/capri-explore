# Deep Learning in Computer-Aided Diagnosis and Treatment of Tumors: A Survey

CorpusID: 226227182
 
tags: #Medicine, #Engineering, #Computer_Science

URL: [https://www.semanticscholar.org/paper/ed0c052a5e9d24042ed5d420d296d50c84394ff1](https://www.semanticscholar.org/paper/ed0c052a5e9d24042ed5d420d296d50c84394ff1)
 
| Is Survey?        | Result          |
| ----------------- | --------------- |
| By Classifier     | True |
| By Annotator      | (Not Annotated) |

---

Deep Learning in Computer-Aided Diagnosis and Treatment of Tumors: A Survey


Dan Zhao 
State Key Laboratory of Reliability and Intelligence of Electrical Equipment
Hebei University of Technology
China

Key Laboratory of Electromagnetic Field and Electrical Apparatus Reliability of Hebei Province
Hebei University of Technology
China

Guizhi Xu 
State Key Laboratory of Reliability and Intelligence of Electrical Equipment
Hebei University of Technology
China

Key Laboratory of Electromagnetic Field and Electrical Apparatus Reliability of Hebei Province
Hebei University of Technology
China

Zhenghua Xu 
State Key Laboratory of Reliability and Intelligence of Electrical Equipment
Hebei University of Technology
China

Key Laboratory of Electromagnetic Field and Electrical Apparatus Reliability of Hebei Province
Hebei University of Technology
China

Thomas Lukasiewicz 
Department of Computer Science
University of Oxford
UK

Minmin Xue 
Department of Health Management Center
983 Hospital of Joint Logistics Support Force
300142TianjinChina

Zhigang Fu 
Department of Health Management Center
983 Hospital of Joint Logistics Support Force
300142TianjinChina

Deep Learning in Computer-Aided Diagnosis and Treatment of Tumors: A Survey
Deep learningtumor diagnosistumor treatmenttumor predictionmedical application
Computer-Aided Diagnosis and Treatment of Tumors is a hot topic of deep learning in recent years, which constitutes a series of medical tasks, such as detection of tumor markers, the outline of tumor leisures, subtypes and stages of tumors, prediction of therapeutic effect, and drug development. Meanwhile, there are some deep learning models with precise positioning and excellent performance produced in mainstream task scenarios. Thus follow to introduce deep learning methods from task-orient, mainly focus on the improvements for medical tasks. Then to summarize the recent progress in four stages of tumor diagnosis and treatment, which named In-Vitro Diagnosis (IVD), Imaging Diagnosis (ID), Pathological Diagnosis (PD), and Treatment Planning (TP). According to the specific data types and medical tasks of each stage, we present the applications of deep learning in the Computer-Aided Diagnosis and Treatment of Tumors and analyzing the excellent works therein. This survey concludes by discussing research issues and suggesting challenges for future improvement.

## Introduction

Cancer is a leading cause of death and a notable public health problem worldwide. According to Global Cancer Statistics [1], by 2018, there will be an estimation of 18.1 million new cancer cases and 9.6 million deaths caused by cancer. Thus to diagnose early and treat compatibly becomes one of the most important research topics in medicine. Previously, people devote to the simple medical method to approach the above goal, which depends on the information obtained by the doctor's perception and the experiences gained by years. While the perception can be influenced by objective factors (e.g., sensory threshold, fatigue, and prior knowledge.) and the acquisition of experience often costs more time, and such experience is often subjective. With the tremendous development of artificial intelligence, considerable attention has been paid to plentiful applications based on artificial intelligence that was used for Computer-Aided Diagnosis and Treatment of Tumors because this technique could assist solve the above two issues. Since Hinton et al. [2] prove that traditional statistical methods are not necessary to extract features as long as computing resources are sufficient, deep neural networks have been asked to learn useful latent features from big data. After that, deep learning has become a new force in Computer-Aided Diagnosis and Treatment of Tumors.

Recently, deep learning differentiates many delicate branches to perform different tasks for different data types. The two most commonly branches are Computer Vision (CV), Natural Language Processing (NLP). In Computer Vision, deep learning works well in many tasks, such as classification, object detection, semantic segmentation. Also, in Natural Language Processing, these tasks (such as text classification, question answering, text abstraction) could accomplish using deep learning. For different requirements of diverse tasks, there are generating several state-of-the-art models. Commonly, these models have their specialties and focus on the specific work. For instance, Convolutional Neural Network (CNN [3]) works very well on classification; Region-CNN series (R-CNNs [4,5,6]) are excellent on object detection; Fully Convolutional Network (FCN [7]) and U-Net [8] do well in semantic segmentation; Recurrent Neural Network (RNN [9]) and Long Short-Term Memory (LSTM [10]) are good at text classification.

Due to the ability of data fusion in deep learning and the needs to model the data features of tumor in diagnosis and treatment process, there are numerous researches to construct Computer-Aided Diagnosis and Treatment of Tumors based on deep learning. Therefore, many recent efforts have been conducted to summarize the relevant researches in this area [11,12,13,14,15,16,17,18,19,20,21,22,23,24,25].

Mainly, Shen et al. summarized the contributions in computer-aided analysis of medical images, such as image registration, structural detection, tissue segmentation, computeraided disease diagnosis, and prognosis [22]. Ching et al. introduced the opportunities and obstacles to deep learning regarding biology, which focuses on the perspective of medicine [24]. Sahiner et al. focus on Convolutional Neural Networks, investigated image segmentation, detection, characterization, processing and reconstruction, tasks involving imaging and treatment in medical imaging and radiotherapy, and discussed methods • Given the existing gaps in Computer-Aided Diagnosis and Treatment of Tumors, this paper looks forward to the challenges in data types, organs, medical tasks, deep learning methods. Also, this paper points out the blank in adversarial study like the work of Finlayson et al. [26], which needs to be paid attention by researchers.


## Classic Deep Learning Models and Improvements

This section reviews classic deep learning models which widely used in Computer-Aided Diagnosis and Treatment of Tumors. Thus to mainly introduce Convolutional Neural Network (CNN [3]), Fully Convolutional Network (FCN [7]), Region-CNN (R-CNN [4]) and their improved models.

It is worth mentioning that there are still exist state-of-the-art in-depth learning model series work well on computer science, such as Mask Region-CNN (Mask R-CNN [27]) in instance segmentation and Transformer [28] series in Natural Language Processing (NLP). However, in Computer-Aided Diagnosis and Treatment of Tumors, the target organ, lesion, or tissue of tumors are generally stable in structure. It means that the instance segmentation hard to play to its strengths at the current research stage, which is especially good at multi-class and multi-object detection and segmentation. Also, clinical data (such as clinical case, prescription, and treatment plan) has never received the attention it deserves, which could be intellectualized by NLP. Therefore, this paper chooses to introduce CNN, FCN, and RCNN series in detail.


### Convolutional Neural Network and DeepMedic


#### CNN

Convolutional Neural Network (CNN [3]) was widely used in medical tasks as the foundational deep learning method. The structure of CNN with details shows in Figure 1. There are three integral parts named the convolutional layer, the pooling layer, and the Fully Connected layer (FC). Followed by the pooling layer, there will be an activate function that could enhance the ability to fit nonlinear problems.

Stem from CNN's unique structure -the convolutional layer realizes the local region connection and weight sharing, the pooling layer achieves dimension reduction, and the fully connected layer implements the task of the classifier. There are four ways to improve the CNN except for exchange activation function.

1. Specific to the fully connected layer, researchers exchange this layer into other networks such as Conditional Random Fields (CRF [29]). This improvement makes CNN no longer limited to classification tasks but keeps the ability of the feature extraction. 2. Increasing the depth of CNN by stacking multiple convolution and pooling layers. However, this method hard to achieve a super deep network due to the problems of gradient vanishing and gradient exploding. Therefore, Visual Geometry Group Network (VGGnet [30]) adopted 16layer and 19-layer structures. 3. To solve the degradation problem with skip connection, such as Deep Residual Network (ResNet [31]), solves the problem of the higher error rate generated in a deeper network. 4. Increasing the diversity of features by adding convolution kernel of different sizes and introducing the dimension reduction of 1*1 convolution kernel, such as GoogLeNet [32].

Finally, Table 1 shown the recent works in Computer-Aided Diagnosis and Treatment of Tumors using CNN.  [35], [36], [37], [38], [39], [40] Segmentation [41], [42], [34], [43], [44], [45], [46], [47], [33] Prediction [42], [48], [49], [50], [51], [52], [42], [53], [54], [55] The location and detection focus on pointing out the position of the object, except the latter one could distinguish different objects. Table 1 shows that CNN has been used to detect or locate the tumor in medical tasks, which usually is the first step of a two-stage work, such as locating or detecting first and then segmenting for the MRI of brain [34]. Similarly, Bellver et al. exchange the last layer into a single neuron to detect healthy/unhealthy liver tissues [33]. However, these researches using CNN are often ancillary products of tasks because the detection or location was not the ultimate purpose of the research. Thus detection and location using CNN cannot be regarded as independent medical tasks. There is another computer science method named Region-CNN series (R-CNNs), which will introduce after, are the start-of-the-art of object detection.

The classification is CNN's turf, thanks to its excellent ability of feature extraction, lots of researchers prefer to address the medical data by CNN. As the Table 1 shows, these researchers focus the tumor diagnosis and treatment on breast [35,36,38,40], kidney [39], bladder [40], and even 13 cancer types [37] based on histology images.

Segmentation is another application of CNN which was demanded a lot in medical tasks, weather the initial screening, subtype identification or treatment of tumors all revolve around the precise segmentation. Researchers in this area usual adopt the first variant (exchange the last layer in CNN) we introduce above to achieve the goal of lesion's segmentation. In details, the researches in Table 1 reflects the extensive applications of segmentation using CNN to deal with multi-modal data and multi-tissue organs, such as brain's MRI [41,42,34,43], rectum's MRI [45], nasopharynx's MRI [46], lung's PET [44], liver's CT [33], prostate's [56] and breast's [47] histology image.

The prediction can be regarded as an extension of classification, since its essence is to classify whether or not a certain situation will occur in the future. In general, we usually need to make the following predictions, such as tumor growth prediction [52], tumor invasiveness prediction [55], motion estimation of radiotherapy targets [49], radiation dose estimation [48], radiation toxicity prediction [50], outcome prediction [53], recurrence prediction [54], and life prediction [51]. Above all, CNN is a method with excellent feature extraction capability and is specialized in classification tasks. These two advantages of CNN depend on its structure. Based on this, researchers began to improve the model from four aspects that we reviewed before to promote the performance of CNN, make it easy to train and adapt to specific tasks. In tumor diagnosis and treatment, CNN has used to initially screen tumors, determine subtypes, outline tumors, and even predict treatment plans and outcomes. All in all, CNN can be said to be one of the most widely used models of Computer-Aided Diagnosis and Treatment of Tumors.


#### DeepMedic

DeepMedic is an efficient 11-layers deep, multi-scale, 3D CNN architecture, which is an improved model specific to brain MRI images from BRATS 2015 and ISLES 2015 [29]. Figure 2 is the structure of DeepMedic. The baseline of DeepMedic is a CNN, followed by Conditional Random Fields (CRF).

It proposes a solution with parallel convolutional pathways for multi-scale processing, which efficiently incorporate both local and contextual information and improves the segmentation results. At last, the author uses CRF to achieve space regularization.

The most valuable contribution of DeepMedic is densetraining, which can balance the distribution of training samples from different segmentation classes, which is a massive problem in medical datasets because, in clinical practice, there are many tiny objects. Meanwhile, DeepMedic could make a dense prediction over multiple adjacent pixels at one time, thus saving computing costs. In recent years, there are several works based on DeepMedic, which shows in Table 2. Segmentation [57], [58], [59], [60], [43] Prediction [58] DeepMedic is a trial variant of CNN that it focuses on the segmentation of medical tasks. Also, because of the original use for brain MRI, the most common application scenario is still the segmentation of brain MRI, which shows in Table 2.

The majority of the researches in the table is segmentation due to the improvement in the last layer. This structure makes the DeepMedic better in the brain's segmentation. Except for the work of Kamnitsas et al. [58], they predict the population survival using SVM after the specific lesion was segmented.

In general, DeepMedic's improvements to medical data are groundbreaking and widely used in brain tumor segmentation tasks, but its bright spot is also its shortcoming. That is, its applications are limited to brain segmentation. In this respect, u-net, which will be introduced later, breaks the stereotype that the improvement of the deep learning model based on medical data is just an appendage of deep learning and will not affect the development in the field of computer science.


### Fully Convolutional Network and U-Net


#### FCN

As an improved method, Fully Convolutional Network (FCN [7]) exchanged the fully connected layer into a deconvolution layer. The structure of the FCN is shown in Figure 3, which is an encoder-decoder model. The form of FCN provides a foundation for the future development of semantic segmentation. In this way, FCN allows end-to-end pixel-level classification, the original size of the feature map in up-sampling, and several roughnesses of the up-sampling. Above all, FCN can accept input images of any size and do well in medical image segmentation at medical tasks.

Because of the structure, FCN opened the gate of segmentation by its inherent advantages. Indeed, FCN has a vital status in Computer-Aided Diagnosis and Treatment of Tumors. Table 3 shows the works using FCN in the clinical practice of tumors. Segmentation [61], [62], [63], [64], [65], [66], [56] FCN was born for semantic segmentation. Hence, it is no surprise that FCN has been a milestone in medical images' segmentation. As Table 3 shows, FCN could segment the CT of liver [33] and heart [61] (which focus on the dangerous organ segmentation when planning radiotherapy), the MRI of brain [62,63], liver [64], colorectum [65] and prostate [66]. As a pioneer of the segmentation era, FCN occupies a place in the task of tumor image segmentation and opens a new chapter of the precise definition of tumor contour.


#### U-Net

As the extension of FCN, U-Net is arguably the advanced deep learning model that improved based on medical data. U-Net inherits all advantages form FCN but improves the number of deconvolution layer and skip connection layer [8]. Also, it has a symmetrical U-shape shown in Figure 4. The left side of U-Net is a contractive path, which extracts features by convolution and max pooling. Also, the right side is an expansive path, which combines the feature map from the left side using concat and sampling the feature map.

U-Net focuses on the characteristics of medical images, which could be summarized as a simple image structure, large image size, a small amount of data, multi-mode, and interpretability. Thus, having the contractive path to capture semantics and the expansive path to locate accurately, U-Net is suitable for the segmentation of the large image, such as histology images (which usually 2GB an image). Moreover, the two paths amount to a trade-off between higher resolution and more abstract features. There are recent works in Table 4 using U-Net in Computer-Aided Diagnosis and Treatment of Tumors. Segmentation [67], [68], [69], [70], [71], [56] Prediction [72], [73], [74], [75], [67] Detection [67] The most important uses of U-Net are semantic segmentation, either. However, its excellent performance also could support subsequent tasks. In segmentation, Beers et al. [68] and Isensee et al. [69] focuses on brain's MRI, Bulten et al. [56] works on prostate's histology image, Falk et al. [67] researches the microscopic video, Guo et al. [70] focus on pancreas's CT , and Zhong et al. [71] uses CT and PET of lung. Furthermore, Falk et al. [67] also finished the detection of biomarkers, and Isensee et al. [69] realized survival prediction in radiobiology.  Moreover, there are other researchers such as Nguyen et al. uses U-Net for prediction. In brief, these works respectively studied prostate [72,74] and head and neck (H&N) [73,75] on radiotherapy dose prediction based on the data of treatment plan.

Have to say, U-Net is a significant breakthrough in improving the deep learning model based on medical data, which improvement is according to the characteristics of simple medical data structure, small size, and few kinds of targets. This optimization for task objectives also further promotes the exploration of fine segmentation in the field of computer science. So, four years later, u-net is still firmly in the top spot in both medicine and computer science. This phenomenon is very thought-provoking.


### R-CNN Series

Region-CNN (R-CNN) series is a two-stage method that selects proposals on the image first and fixes bounding boxes based on the proposal. As a primitive model, R-CNN [4] is divided into three parts, finding the candidate box, using CNN to extract feature vectors, and using Support Vector Machine (SVM [76]) to classify feature vectors. Figure 5 shows the specific method, which locates 2000 candidate boxes of objects in the input picture and extracts feature vectors of images in each candidate box, next, classifies and identifies objects in each candidate box.

The improvement of R-CNN is focussing on the training speed. The Fast R-CNN [5] improves the multi-stage pipeline training of R-CNN and solves the urgent problem for time and space of training. There are two improvements in this work, adding an ROI pooling layer after the last convolution layer, and using a multi-task loss function to add frame regression directly to the training of the CNN network. Moreover, Faster RCNN [6] can view as Fast R-CNN work with the Region Proposal Network (RPN [6]). The corresponding work summarizes in Table 5. Detection [77], [78], [79], [80], [81] Classification [80], [81] Detection is the most basic function of the R-CNN series, and it is easy to see that the work based on R-CNN has completed the detection work very well. For instance, Li et al. [77] uses Faster R-CNN to detect thyroid ultrasound images. Rao et al. [78] works on R-CNN and Cai et al. [79] research Faster R-CNN to detect breast histology images. Also, Faster R-CNN in the researches of Akselrod et al. [80] and Ribli et al. [81] are both using for breast mammography to detect and classify malignant or benign lesions.

As the pioneer of target detection, R-CNNs, the two-stage method, has completed the detection of biomarkers well in the process of tumor diagnosis and treatment. It is worth mention that in the field of computer science, there are actually other object detection methods that are being updated, such as You Only Look Once series (YOLO [82], YOLOv2 [83], YOLOv3 [84]), and Segmentation is all you need [85] which written by Wu et al. in 2019. The reason why the above works are not described in detail here is that the YOLO series, as one-stage methods, has lost parts of precision (which is a crucial indicator in tumor diagnosis and treatment). Meanwhile, the work named Segmentation is all you need, which is the latest and most breakthrough deep learning method for object detection that has not been the star in the medical field. However, one of the advantages of the work finished by Cheng et al. is the detection of difficult small targets, and its performance in subsequent medical tasks is expected.


## Recent Work in Intelligent Diagnosis and Treatment of Tumors


### In-Vitro Diagnosis (IVD)

In-Vitro Diagnosis (IVD) is the first stage of tumor diagnosis, which is mainly responsible for the detection and screening of tumor markers or tumor characteristics. Early detection of cancer often determines the prognosis of patients' quality of life or even life. It is the crucial reason why deep learning is needed at this stage. IVD uses three kinds of data, which will introduce as follow.

1. Images or videos of cells in blood and tissue fluid generated from microscope to discover if there exists Circulating Tumor Cell (CTC). 2. Indicators in biophysics and biochemistry from Flow Cytometer (FCM) to discover the specified subset of cells. The main clinical problems at this stage are the early screening of tumors, identifying tumor stages and subtypes, monitoring the efficacy of therapy, and predicting prognosis of tumors. All of these medical tasks can be seen as a classification task in computer science. Of course, segmentation and object detection can also accomplish the above tasks if it is necessary. Now, with the development of CNN, there is a practical approach to solve the above problems in deep learning. Table 6 summarizes recent work for CNN in IVD. 3.1.1. Image data diagnosis in IVD In detection, the work of Falk et al. [67] is excellent by using U-Net, which enables non-machine-learning experts to analyze their data and could save manual annotation effort in a wide variety of quantification tasks. Also, this work supports single-cell segmentation with conditional adaptability. Furthermore, the datasets in this work (such as F1-MSC, F2-GOWT1, F3-SIM, F4-HeLa, DIC1-HeLa, PC1-U373, and PC2-PSC) are from the International Symposium on Biomedical Imaging (ISBI) Cell Tracking Challenge 2015. Figure 6 shows the pipeline of this work. Firstly, training the U-net on the local machine, a dedicated remote server, or a cloud service. After that, the adaptation of U-Net to newly annotated data by using transfer learning. This work performance well in follows tests.

• Detection (2D) of colocalization in two-channel epifluorescence images.

• Detection (3D) of fluorescent-protein-tagged microglial cells in a five-channel confocal-image.

• Segmentation (2D) of morphometric cell description from fluorescence, differential interference contrast, phasecontrast, and bright-field microscopy.

• Segmentation (3D) of 3D bright-field images and neurite is tracing in electron microscopy images.

In segmentation, Tran et al. [86] uses SegNet (which is a variant of FCN [90]) to efficiently segment both Red Blood Cells (WBCs) and White Blood Cells (RBCs). The dataset is the peripheral blood smear images from the ALL-IDB1 database. The details of this work are shown in Figure 7. The first step utilizes SegNet to label all of WBCs and RBCs in input images with different colors. Then, it separated all leucocytes and erythrocytes into two individual images. Finally, using the result images for various purposes, such as early detection of leukemia (a type of white blood cell cancer) and count of the complete blood cell. 


#### Gene data diagnosis in IVD

Now, genomic data is generally used for prediction, such as cancer prediction and anticancer drug responsiveness prediction.

There is a standard work written by Chang et al. [88] in the Table 6 researches for drug efficacy prediction, which employs CNN to process the genomic mutational fingerprints of cell lines and the molecular fingerprints of drugs (these data comes from CCLP1, GDSC6, CGC, GDSC). It may allow the selection of the most effective anticancer drugs for the genomic profile of the individual patient in the future. The details will show in Figure 8. In this research, the model consists of two parts, a dual convergence CNN and a generalizable prediction model. Furthermore, the inputs of the model can be molecular information of a particular small molecule, and the model could predict which of Genomics in Drug Sensitivity in Cancer (GDSC) anticancer drugs would be valid.


#### Indicators data diagnosis in IVD

With the increasing maturity of deep learning methods, more and more types of data are expected to be processed by deep learning methods, and Doan et al. [87] shown in Table 6  glycolipids) in multiple subcellular compartments (nucleus, mitochondria). Figure 9 is the illustration of the assumption by using general CNN in the research. This work may use to analyze the rare cell types such as circulating tumor cells (which are cancer cells that escaped from a primary tumor and circulate in the bloodstream) and transition states, such as cell cycle phases (mitosis). As a summary, even the In-Vitro Diagnosis is the earliest stage for the diagnosis of tumors, the data types and the large data sources are pool. There are several reasons which based on the clinical practice for In-Vitro Diagnosis mainly causes it.

• Many cytology reports do not require the same photographic evidence as imaging diagnosis, so doctors have no needs to gather image data during the diagnosis; instead, they record the values detected.

• Currently, general health examination conducted by hospitals do not include the genomic testing of tumors, and so do the medical institutions. Also, most patients lack awareness of genetic risk prediction. Therefore, to obtain a large number of high-quality tumor genome screening data is difficult.

• Clinical indicator data are presented in the form of text, and Natural Language Processing (NLP) is required to complete the task of text abstract before further analysis.

However, text abstract is rarely used in medical reports, which results in a lack of available data.


### Imaging Diagnosis (ID)

If abnormal discoveries are finding in IVD or simply because of the physical discomfort reaching the diagnostic range, patients may have to follow a doctor's orders to finish imaging diagnosis. The Imaging Diagnosis uses medical images to discover if there exist leisures and dangerous organs. These images come from UB, X-ray, CT, MRI, Digital Subtraction Angiography (DSA), RadioNuclide Imaging (RNI), Positron Emission Computed Tomography (PET), and Single-Photon Emission Computed Tomography (SPECT). There are plenty of public datasets about medical images. As usual, these datasets could be found in Grand Challenge, such as Kidney Tumor Segmentation Challenge (KiTS), Combined Healthy Abdominal Organ Segmentation (CHAOS), Decathlon-10. Furthermore, The Cancer Imaging Archive (TCIA, see: https: //www.cancerimagingarchive.net/) contains packaged datasets, such as multi-modal or multi-type data of tumors. Of course, some datasets have histology images, multiple types of medical images, genomic data, and clinical information, which are suitable for the integration of multi-modal data and tumor diagnosis and treatment.

In this stage, the essential clinical demands include diagnosing, detecting, and delineating the tumors or dangerous organs. Thanks to the applications supported by CNN, FCN, U-net, and R-CNNs, most of the problems in Imaging Diagnosis could be solved in deep learning. Among these models, CNN could be used to diagnose tumors and extract features before delineating the tumors; FCN and U-Net mostly be used to delineate the tumors; R-CNNs are good at object detection for tumors. Recent works are shown in Table 7. 


## Data

Tasks Reference MRI Segmentation [41], [57], [59], [34], [43], [45], [46], [58], [62], [63], [64], [65], [66], [69], [68], [42] Prediction [42], [58], [69] CT Segmentation [33], [61], [64], [66], [70], [91] Prediction [48], [49], [51], [54], [ Figure 11: The illustration of the work written by Isensee et al. [69] depends on U-Net to segment brain MRI and RF to predict radiomics survival.


#### MRI diagnosis in ID

MRI has good discrimination of soft tissue and no ionizing radiation damage to the human body, so it is good at imaging tumors in the brain, bladder, rectum, reproductive system, and other parts.

In segmentation, we have to introduce the work written by Drozdzal et al. [66], which combines Fully Convolutional Networks (FCNs) with Fully Convolutional Residual Networks (FC-ResNets [93]) to segment medical images, such as electron microscopy (EM) image, CT of the liver, and MRI of the prostate. The results reveal that this model is working well in both 2D and 3D medical images, which means that it could achieve accurate segmentations on a variety of image modalities and different anatomical regions. Details are shown in Figure 10, which uses the FCN to obtain pre-normalized images, and then iteratively refined employing the FC-ResNet to generate a segmentation prediction.

In prediction, Isensee et al. [69] finished the survival prediction by training an ensemble of Random Forest (RF [94]) regressor and multi-layer perceptrons on shape features describing the tumor subregions. Figure 11 is the pipeline of the work, which is derived from the U-Net. In short, the context pathway (left) aggregates high-level information that is subsequently localized precisely in the localization pathway (right). Also, this work injects gradient signals deep into the network through depth supervision.

Different from the work mentioned above [69], these works [42,58] also have a prediction part using Support Vector Machine (SVM [76] Figure 12: The pipeline of the work written by Guo et al. [70] which adopts the U-Net to integrate intra-slice and adjacent-slice contexts, and regulates the 3D shape by LOGISMOS in pancreas tumor segmentation.

and Support Vector Machine (SVM) are the machine learning method, maybe there will be a more deep learning method using for prediction soon in this field.


#### CT diagnosis in ID

CT is of high diagnostic value for tumors of the central nervous system, head and neck, chest and abdomen, and pelvic cavity. It is widely used in the diagnosis and treatment of computer-assisted tumors.

In segmentation, Guo et al. [70] employs U-Net which refined by Gaussian Mixture Model (GMM) and morphological operations to segment 3D pancreas tumor. To finish the morphological operations, the authors adopt a model named LO-GISMOS, which is a graph-based framework that translates geometric constraints of interacting surfaces and objects into graph arcs and the likelihood of segmentation surface positioning into graph node/arc costs. The details are shown in Figure 12, which combines U-Net (to integrate intra-slice and adjacent-slice contexts) and LOGISMOS (to regulate the 3D shape) for 3D tumor segmentation.

In prediction, Ardila et al. [91] built an end-to-end approach based on CNN for CT images, which outputs overall malignancy prediction for the case, a risk bucket score (LUMAS) and localization for predicted cancerous nodules. The pipeline shows in Figure 13, which contains three parts based on CNN. There is a full-volume model (to perform end-to-end analysis of LDCT), cancer Region of Interest (ROI) detection model (to detect 3D cancer candidate regions), and cancer risk prediction model (to operate on outputs from above two models). This work achieved an outstanding result, about 94.4% area under the curve on National Lung Cancer Screening Trial cases (NLST).


#### PET diagnosis in ID

Positron Emission Tomography and Computed Tomography (PET-CT) dual-modality imaging provide critical diagnostic information in current cancer diagnosis and therapy.

In segmentation, Zhong et al. [71] employ a model that combines 3D U-Net, and the graph cut based co-segmentation model to automated, accurate tumor delineation based on PET-CT, which is essential in computer-assisted tumor reading and interpretation. The details are shown in Figure 14. In this  Figure 13: The pipeline of the work of Ardila et al. [91] which is basically based on CNN.


## Graph Optimization for PET-CT Co-Segmentation
= + ′ + ( , ′ )

## 3D U-Net


## Input CT Preprocessing Region costs in CT


## Input PET Preprocessing Region costs in PET


## Contour on CT


## Contour on PET

Ground Truth Figure 14: The pipeline of the work from Zhong et al. [71] which designed two independent 3D U-Net for PET and CT to produce high-quality regions costs for subsequent graph-based co-segmentation in lung's dataset. work, the researchers focus on lung cancer PET-CT and generate high-quality voxel-level tumor confidences that were further used to locate the tumor boundary with the powerful cosegmentation model.

In prediction, Zhang et al. [52] propose a CNN to predict the pancreas tumor growth pattern that incorporates both the population trend and personalized data. Figure 15 shows the structure. The deep features extracted by CNN are combined with the time intervals and the clinical factors to feed a process of feature selection and after that, selected a robust feature subset by the Support Vector Machine Recursive Feature Elimination (SVM RFE). Finally, a SVM predictive model was used to predict the tumor's spatiotemporal growth and progression. 


#### Mammography diagnosis in ID

Now, mammography only uses for breast screening. Thus most of the researchers focus on the detection and classification of early cancer. As Figure 16 shown, Ribli et al. [81] adopt Faster R-CNN by optimized both the object detection and classifier part to detect and classify malignant or benign lesions on mammogram without any human intervention. Also, the mammogram images come from the public INbreast database. This research could realize computer-aided detection in mammographic screening.


#### Ultrasound (US) diagnosis in ID

Ultrasound (US) is the most widely used tumor screening method, thanks to its non-radioactive, multi-directional crosssectional imaging, real-time dynamic, easy to operate, fast, and other characteristics. However, ultrasound needs the assistance of deep learning because of its disadvantages of lack of specificity, focus on local areas, and is easily influenced by doctors' experience.

For instance, Li et al. [77] employs Faster R-CNN to add a spatial constrained layer before the output layer of CNN, as the pipeline is shown in Figure 17, which concatenated and normalized the conv3 and conv5 layer and then add a spatial constrained layer before the output layer. This work is more suitable for thyroid papillary carcinoma detection in ultrasound images, and the property of classification is better than SVM. This work could improve the ability of screening cancer in thyroid papillary carcinoma images fast.

As a summary, Image Diagnosis runs through the whole process of tumor diagnosis and treatment. Its data is easy to obtain and the data is huge. It is an essential part of the current research on computer-assisted tumor diagnosis and treatment thanks to the rapid development of computer vision. As can be seen from this section, the research on individual organs (especially large organs or organs that are easy to inspect) has reached a saturation point, and the future trend is nothing more than improvement in accuracy and speed. However, targeted studies are still needed for small organ tumors, such as pancreas and ovary. These small organ tumors are high malignancy and a short course of the disease (which means the data is scarcity). Besides, there is still little research on multi-modal data (although such multi-modal databases like TCIA has existed).


### Pathological Diagnosis

Pathological Diagnosis is the gold standard in the tumor's diagnosis and treatment, which determines the stage and subtype of tumors. Moreover, treatment planning depends on the results of the Pathological Diagnosis. However, because of its invasive nature, Pathological Diagnosis can not be used for early screening.

Pathological Diagnosis based on deep learning uses the images of leisures, which prepared by histopathological methods (such as H&E-stained) to discover the exceptions on the tissue structure, cell morphology, and growth pattern of the lesion. Now, the amount of public datasets is available. As usual, Grand Challenge and TCIA are available.

This stage has to screen the cell nucleus of tumors, delineate the pathological leisure, and detect the object of tumors. Same as Imaging Diagnosis, which input data is the image, and deep learning methods (such as CNN, FCN, U-Net, and R-CNNs) work well on Pathological Diagnosis. Follow Table 8 is the collection of recent works. 


## Data

Tasks Reference


## Histology images

Classification [35], [36], [37], [38], [39], [95], [40], [55] Segmentation [56], [47], [96], [55] Prediction [97], [53], [55] In Classification, Saltz et al. [37] is standard research that using CNN to classify 13 cancer types in lymphocytes on pathology images compared with The Cancer Genome Atlas (TCGA). In this research, as Figure 18 shows, each patch was annotated with a necrosis region mask segmented by a pathologist, and the expert reviewed and corrected predicted Tumor-Infiltrating lymphocytes (TIL) during the CNN training stage. This effort assess lymphocytic infiltrates across multiple TCGA tumor types for correlation. Genomic and epigenomic assessments of lymphocytic infiltrate, as well as clinical outcome, which utilizes well of TCGA and shows that molecular assessments of TILs (generated by the molecular platforms of the TCGA) can correlate with clinical outcome for specific tumor types.

In segmentation, Coudray et al. [96] show an excellent work on whole-slide images (obtained from The Cancer Genome Atlas, TCGA) to classify the Adenocarcinoma (LUAD), Squamous Cell Carcinoma (LUSC), and healthy lung tissue using Inception v3 (improved model of CNN [98]). Figure 19 is  Figure 18: The pipeline of the work from Saltz et al. [37] which could realize a global structure classification in lymphocytes by CNN.


## Download

Train 75%


## Validation 15%

Test 15%


## Inception v3

Improved model for CNN Figure 19: The pipeline of work from Coudray et al. [96] which mainly including data preprocessing and model training by CNN. the structure of this work. Also, the author validated their work on independent datasets of frozen tissues, formalin-fixed paraffin-embedded tissues, and biopsies obtained at the New York University (NYU) Langone Medical Center. Furthermore, the trained network in this work could predict gene mutations using images as the only input in LUAD, which is meant to assist pathologists in the detection of cancer subtype or gene mutations. The Average area Under the Curve (AUC) of classification is 0.97, and AUCs of prediction is from 0.733 to 0.856. In prediction, Bychkov et al. [53] combines CNN and Long Short-Term Memory (LSTM [10]) to predict colorectal cancer outcome based on images of Haematoxylin and Eosin (H & E) stained Tumour Tissue Microarray (TMA), which was shown in Figure 20. Also, this work can directly predict five-year disease-specific survival without any intermediate tissue classification. This work shows that extract more prognostic information from the tissue morphology of colorectal cancer than an experienced human observer.


## Model

As a summery, histology images in clinical practice are mainly used for tumor staging, grading, and cancer diagnosis. Therefore, classification is the priority in computer-assisted pathological diagnosis. In contrast, segmentation is about better identification of target cells, whereas prediction is about broader classification (predicting the likely consequences of future tumors). Therefore, it seems that there is no room for further development in the application of histology images. However, caused by the large capacity of pathological images, the current mainstream processing methods are training by blocks. It means that newer and better deep learning methods may be developed in the field to improve training speed or realize endto-end.


### Treatment Planning

After the diagnosis in the first three stages, doctors set out Treatment Plans according to the obtained diagnosis results, including operation therapy, radiotherapy, chemical therapy, and targeted molecular therapy. Operation therapy and radiotherapy belong to local treatment, which requires a clear division of Gross Tumor Volume (GTV), Clinical Tumor Volume (CTV), and Plan Tumor Volume (PTV) at the leisure. Therefore, images of tumors will be a suitable medium for operation therapy and radiotherapy. Chemotherapy is systemic therapy, which evaluated according to the improvement of clinical symptoms and objective indicators such as medical imaging. Molecular targeted therapy based on the level of cell molecules and therapeutic drug designs for oncogenic sites (such as protein molecules or gene fragments inside tumor cells), which can lead to specific death of tumor cells. Therefore, the data type in Treatment Planning is still image and gene expression by arrays. Now, in the stage of treatment planning, doctors have demands on accurate lesion segmentation and reliable prediction of toxicity, survival, and efficacy, the details shown in Table 9.  [42], [58], [69] CT [48], [49], [51], [54], [55], [91] PET-CT [52] Histology images [53], [97], [55] Gene [88], [89], [99] Treatment plans [72], [73], [74], [75] [50]

The prediction of the tumor through MRI, CT, PET-CT, and histology images has been introduced a lot before; next, the researches about genomic data, treatment plans, Rectum Surface Dose Maps (RSDM) will be analyzed mainly.

In genomic data, Chaudhary et al. [99] uses a synthesis method combined by AutoEncoder (AE [2]), K-means clustering [100], and Support Vector Machine (SVM [76]), see Figure Figure 21: The pipeline of the work from Chaudhary et al. [99], an AutoEncoder architecture used to integrate 3 omics of HCC data.


## U-Net Train Data

Ground Truth Prediction Dose Figure 22: The piplilne of treatment planning advanced by U-Net to predict the dose of radiotheropy [74].

The data in this work contains RNA sequencing (RNA-Seq), miRNA sequencing (miRNA-Seq), and methylation data from The Cancer Genome Atlas (TCGA). This effort predicts prognosis as good as an alternative model where genomics and clinical data are both considered.

In treatment plans, Nguyen et al. focus on predicting the dose distribution of radiotherapy, all the papers published by them [72,73,74,75] used U-Net to predict dose of radiotherapy. Such as the work [74], which shows in Figure 22, it is the first fully 3D dose distribution prediction for prostate IMRT plans. In this study, they use a similar set of 7 beam angles and criteria for treatment, which means that the model has currently learned only to predict the dose coming from approximately the same orientations, and may not be able to account for more intricate beam geometries. Also, the current model is unable to account for any physician preferences for predicting the dose, limiting the level of treatment personalization for the patient. However, the works of Nguyen et al. develop the dose prediction of cancer, which is meaningful.

As a summary, the works in this part are heavy and complex, which contains many kinds of prediction, but only a few of them are relevant. Although these efforts cover many areas (such as prediction of cancer [89], life [51] and survival [58,69]), few actually assist doctors in planning their treatment (such as prediction of radiation dose [48,72,73,74,75], radiotoxicity [50], anticancer drug response [88], and recurrence forecast [54]). There is still a dearth of real value studies on treatment plans, perhaps because it is difficult for non-medical researchers to collect data on treatment plans. Most studies only use some pre-diction as an ancillary result of research work, and there is still a huge gap in research that focuses on deep learning to assist tumor therapy. At this stage, the Computer-Aided Treatment of Tumors still needs more attention.


## Conclusion and Outlook


### Conclusion

In conclusion, how to achieve early detection of tumors, accurate diagnosis, proper treatment, and better prognosis becomes the key to tumor treatment. With the rapid development of deep learning, doctors increasingly need Computer-Aided Diagnosis and Treatment of Tumors, because the material defects of human beings limit the further development of this field. These defects usually caused by sensory thresholds, cognitive biases, and personal experience differences. In particular, deep learning has achieved great success in natural datasets to different task types. Specific to the data types (such as images, indicators and gene expression by arrays) and different medical tasks (such as classification, segmentation, detection, and prediction) in Computer-Aided Diagnosis and Treatment of Tumors, deep learning can provide effective methods (such as CNN, FCN, R-CNNs). These successes provide good reference cases and experience for a series of medical tasks of tumor diagnosis and treatment.

In order to entirely solve clinical problems by using deep learning requires a detailed understanding of the specific characteristics of the medical data and medical tasks in tumor diagnosis and treatment, which have been summarised as follows.

• Medical tasks focus on a single organ and kinds of leisure on the organ, such as the calcification, nodule, cyst, and tumor on the lung.

• Medical tasks rely on stable human structures, such as the primary or metastatic lesions of the intracranial tumor within the skull.

• The object in medical tasks is small and has individual differences, such as the pancreas and the thyroid.

• Medical tasks are multidisciplinary collaborative diagnosis and treatment.

Compared with these research which published in top magazine [37,29,63,66,95,99,96,67,91], it is easy to see, these works are either a meaningful breakthrough in the improvement of the new model (such as DeepMedic and U-Net) based on medical datasets or very close to the professional needs of medical tasks. Both types of studies have fully understood the clinical need and put it into practice. It means, when we are taskoriented and familiar with the characteristics of medical data, the deep learning method in computer science enables the rapid development of Computer-Aided Diagnosis and Treatment of Tumors. On the other hand, with the rapid development of deep learning in computer science, only by clarifying the nature and factions of various deep learning methods can researchers avoid detours. This paper reviews the recent work in Computer-Aided Diagnosis and Treatment of Tumors from the following four points, data type, organs, medical tasks, and deep learning method. These works are of great significance in the Computer-Aided Diagnosis and Treatment of Tumors. The specific content is summarized as follows.

Firstly, the survey summarizes the data type of tumor diagnosis and treatment from four stages. Each stage may have a different data type depending on its characteristics or may have a different tendency to process the data according to the requirements of the medical task.

• Stage of In-Vitro Diagnosis (IVD). There are three kinds of medical data in this stage. 1) Images from the microscope, blood smear, and Flow Cytometer (FCM • Stage of Treatment Plan. In this stage, except for the images and genomic data summarised above, radiotherapy data such as rectum surface dose maps (RSDM) is meaningful.

Secondly, the article reviews majority of organs and tissues which easy to have tumors.

• The target organ of the tumor. Such as the brain, lung, colorectum, nasopharynx, liver, kidney, bladder, stomach, cervix, head & neck.

• The target gland of the tumor. Such as breast, prostate, thyroid, ovary, and pancreas.

• The organ at risk (OAR). Such as the heart, esophagus, trachea, and aorta.

• Connective tissue, such as blood.

Thirdly, this work contains several medical tasks in four stages of tumor diagnosis and treatment, details was shown as follows.

• Detection, common medical tasks include in this part are screening the tumor, the carcinoma cells, and the biomarkers.

• Segmentation, such as delineating the lesion and organ at risk (OAR).

• Classification, such as identifying the tumor subtypes and stages.

• Prediction, which contains a lot of clinical practice types. Including 1) prediction of radiation dose, radiotoxicity, anticancer drug response, and recurrence forecast; 2) motion prediction under the action of breathing; 3) prediction of cancer, tumor invasiveness, tumor growth; and 4) prediction of life and survival.

Finally, the state-of-the-art in the Computer-Aided Diagnosis and Treatment of Tumors have been introduced detailedly before. It is a task-oriented review of different task types and their appropriate deep learning methods, such as the CNN series in the field of classification, the FCN series in the field of segmentation, and the R-CNN series of object detection. In general, these models are better at image data processing. However, recently researches are feeble in the area of non-image data which is also an essential source of clinical data.

Impressively, there are still plenty of reasons limit to the development of the Computer-Aided Diagnosis and Treatment of Tumors, which need the medical industry and the computer industry through cooperation can be targeted to solve. Such as medical imaging lacking high-quality datasets with unified standards and accurate labeling, existing models easy to overfit with less robustness, data security, and diagnostic reliability. Therefore, there are still plenty of works is waiting for researchers.


### Outlook and Challenge

According to the above summary and analysis, the Computer-Aided Diagnosis and Treatment of Tumors have thrived in all aspects of clinical practice. However, there are still many gaps and challenges worth noted based on this work. The following sections elaborate on these issues in four ways.


#### From Data Types

The data types in recent researches seem to be quite comprehensive, but more often than not, people tend to focus on the Image Diagnosis data. Even this tendency extends to a few kinds of medical images, such as MRI and CT. Histology images and cancer-associated genomic regions have been partially concerned. However, some problems limit the progress of the research. For individual histology images, it can be up to 2G in size, which requires advanced servers for researchers. Also, lots of primary hospitals have no conditions for genetic testing. Besides, the data from stages of In-Vitro Diagnosis (IVD) and Treatment Plan have the same predicaments -there is not exist a sophisticated system to store the data of tumor diagnosis and treatment in bulks.

Meanwhile, the multi-disciplinary collaboration of medical tasks makes the multi-type datasets of the same task have a strong correlation, and taking data groups as research objects will gradually become a trend. Such as the integration of genomics and histopathology mentioned in this review [96].

Above all, deep learning is an art of big data, the gaps in early screening, treatment of tumors, and the study of multiomics still need to be filled.


#### From Organs and Tissues

There are almost 20 different organs have been mentioned in this survey. However, the researchers prefer to focus on a few large organs (such as brain, liver, and lung), and the organ who has special examination (such as breast image from mammography, and thyroid image from ultrasound). Therefore, some structurally specific organ which is tiny and deep in humans body lacks the correlational research, such as the pancreas. The diagnosis and treatment of tumors in these organs is more challenging and meaningful,especially the pancreatic cancer is short disease duration and fatal. In this part, there is plenty of work which focus on tiny organs and tissues has to follow up.


#### From Medical Tasks

In this paper, more than 17 kinds of medical tasks in the Computer-Aided Diagnosis and Treatment of Tumors have been summarized. It is shown that the majority of the research priorities are detection, segmentation, and classification. There are screening the tumors, carcinoma cells, and biomarkers; delineating the lesion and Organ At Risk (OAR); and identifying the tumor subtypes and stages. However, in the prediction tasks of tumors, a unique phenomenon has emerged. Interestingly, the vast majority of studies on prediction of survival, prediction of life span do not contribute to clinical practice; they are usually just additional contributions from other studies. Although it seems significant, this kind of research tells us that patients are more likely to die if they get malignant tumors. These works do not provide constructive Suggestions to help doctors plan their next treatment. On the contrary, studies on actual adjuvant therapy, such as exercise management, radiation dose distribution prediction, radiation toxicity prediction, drug effect prediction, and tumor erosion prediction, are of clinical significance. However, due to the scarcity of data sources, this kind of research progress is languid, and more researchers need to put in relevant work.


#### From Deep Learning Methods

Although the application in the Computer-Aided Diagnosis and Treatment of Tumors of various deep learning models is generally in line with the development trend of computer science, the application is still sluggish. At present, the research in the field is still limited to simple deep learning model handling, and U-Net is the only influential model improved by medical data. There are gaps that state-of-the-art models published recently are not yet widely used in the Computer-Aided Diagnosis and Treatment of Tumors, such as Segmentation is all you need [85], a new revolution in object detection which good at difficulty tiny object; Transformer [28], BERT [101], Transformer-XL [102], XLNet [103], Sparse Transformers [104] in Natural Language Processing (NLP), which could be used for clinical data, such as medical history. It may revolutionize the performance of current oncology adjuvant therapy if the researchers introduce these advanced methods. Of course, it is particularly welcome if researchers are working on improving deep or creating learning models based on medical data and aim at medical tasks.


#### Adversarial Study

Given the existing problems in tumor diagnosis and treatment in the whole industry, this paper has made a prospect and put forward the vacancy of existing research. However, in essence, some critical studies have never been done before, and it is worth noting. Adversarial study is one of such field.

Any research in deep learning is bound to encounter the question of whether the results are credible. In such an information age, information security and ethics are worth discussing. It remains to be seen whether researchers will be able to achieve consistent results in simple information confrontation experiments in the field of tumor diagnosis and treatment, not to mention that the diagnosis and treatment of tumors are vital and should be treated with caution. As far as we know, this field is almost blank except the recent work [26], which is a very terrible blank, but also a blank with infinite opportunities.

As a summary, Computer-Aided Diagnosis and Treatment of Tumors are highly cross-disciplinary that ask researchers know medicine and computer science, but few people are proficient in both, and not everyone can find a partner with expertise. This problem has led to a situation in the field where computer scientists do not know how to make medical advances in combination with specific conditions, and doctors do not know which deep learning methods can better achieve their goals. It is also the reason why a large number of studies have been conducted which cannot guide clinical tumor treatment. For now, this paper could quickly guide doctors to choose a proper deep learning method, and computer researchers may learn more about tumor diagnosis and treatment. In clinical practice, the international standard for tumor diagnosis and treatment refer to the National Comprehensive Cancer Network (NCCN) Clinical Practice Guidelines in Oncology. (see: https://www.nccn.org/professionals/ physician_gls/default.aspx). If researchers want to further improve the fit between their works and the medical task, clicking on it would be a good start. with sparse transformers, ArXiv Preprint ArXiv:1904.10509.

## Figure 1 :
1The structure of CNN.

## Figure 2 :
2The structure of DeepMedic.

## Figure 3 :
3The structure of FCN.

## Figure 4 :
4The structure of U-Net.

## Figure 5 :
5The structure of R-CNN.

## 3 .
3Gene expression by arrays obtained from the public datasets to discover if there exists a gene disorder. Currently, there are public datasets online with labels in this stage. Such as, National Cancer Institute Genomic Data Commons (GDC) Data Portal (see: https://portal. gdc.cancer.gov/), Genomics of Drug Sensitivity in Cancer (GDSC, see: https://www.cancerrxgene.org/), MICCAI Challenge on Circuit Reconstruction from Electron Microscopy Images (CREMI, see: https://cremi. org/data/), and LYmphocyte aSsessmenT hackathOn (LYSTO, see: https://lysto.grand-challenge. org/). The vast majority of open datasets can be found at Grand Challenge (see: https://grand-challenge. org/challenges/), or even the data types to be introduced in the next three stages in Computer-Aided Diagnosis and Treatment of Tumors.

## Figure 6 :Figure 7 :
67The pipeline of the research worked by falk et al.[67] which is basically different annotation types of data learning using U-Net. The pipeline of[86] depends on SegNet to segment WBCs and RBCs.

## Figure 8 :Figure 9 :
89is one of them. Doan et al. analysis the diagnostic potential of Imaging Flow Cytometry (FCM), which database contains the image of each cell and the quantified multiple properties constituents of interest indicators (including proteins, nucleic acids, The pipeline of the work written by Chang et al. [88] depends on two-step CNN to predict anticancer drugs responsiveness. The illustration of the work written by Doan et al. [87] depends on CNN to analysis the cells by classification. For instance, Class1 and 2 could correspond to leukemic and normal cells.

## Figure 15 :
15The structure of the work from Zhang et al.[52] which is a framework of the voxel-wise prediction of tumor growth via CNN and SVM.

## Figure 16 :Figure 17 :
1617The structure of the work from Ribli et al.[81] which is a framework of the object detection in tumor early screening via Faster R-CNN and SVM. The structure of the work from Li et al.[77] which adopt Faster R-CNN to detect thyroid papillary carcinoma.

## Figure 20 :
20The pipeline of the work written by Bychkov et al.[53] which using CNN and LSTM to predict survival rate.

## Table 1 :
1CNN in Computer-Aided Diagnosis and Treatment of TumorsTasks 
Reference 

Detection 
[33] 
Location 
[34] 
Classification 


## Table 2 :
2DeepMedic in Computer-Aided Diagnosis and Treatment of TumorsTasks 
Reference 



## Table 3 :
3FCN in Computer-Aided Diagnosis and Treatment of TumorsTasks 
Reference 



## Table 4 :
4U-Net in Computer-Aided Diagnosis and Treatment of TumorsTasks 
Reference 



## Table 5 :
5R-CNNs in Computer-Aided Diagnosis and Treatment of TumorsTasks 
Reference 



## Table 6 :
6Recent work in In-Vitro DiagnosisData 
Tasks 
Reference 

Image 
Detection 
[67] 
Segmentation [67], [86], [66] 
Indicators Classification 
[87] 
Gene 
Prediction 
[88], [89] 



## Table 7 :
7Recent work in Imaging Diagnosis


). Noticed that both Random Forest (RF)Cropped Slices 
Ground Truth 

U-Net 

Refinement 

U-Net 

Graph 
Construction 
Final Segmentation 

LOGISMOS 

Cost Design 

Initial Segmentation 



## Table 8 :
8Recent work in Pathological Diagnosis

## Table 9 :
9Recent work in Treatment PlanningData 
Tasks 
Reference 
MRI 

Prediction 




21, to predict Hepatocellular Carcinoma (HCC) survival.mRNA 

miRNA 

methylation 
Whole Dataset 

AutoEncoder 
(AE) 

Univariate 
Cox-PH 
models 

K-means 
clustering 

Inferred 
survival-risk 
subgroups 

SVM 

Omic 
dataset 
to predict 

Filtered 
omic 
dataset 
to predict 

mRNA 

miRNA 

methylation 
Train Dataset 

ANOVA 
feature 
ranking 

Selection of 
common top 
features 

mRNA 

miRNA 

methylation 

Filtered 

Predicted 
survival-risk 
subgroups 




). 2) arrays of cancer-associated genomic regions. Also, 3) numerical indices from a Flow Cytometer (FCM). • Stage of Image Diagnosis. In this stage, most data is images from various medical imaging devices, such as Magnetic Resonance Imaging (MRI), Computed Tomography (CT), Single-PPhoton EEmission Computed Tomography (SPECT), Positron Emission Tomography (PET), Ultrasound (US), mammography. • Stage of Pathological Diagnosis. In this stage, histology images stained by H & E is the mean medical data type.
AcknowledgmentsThis work was supported in part by the National Natural Science Foundation of China under grant 61906063, in part by the Natural Science Foundation of Tianjin, China, under grant 19JCQNJC00400, and in part by the Yuanguang Scholar Fund of Hebei University of Technology, China.
Global cancer statistics 2018: Globocan estimates of incidence and mortality worldwide for 36 cancers in 185 countries. F Bray, J Ferlay, I Soerjomataram, R L Siegel, L A Torre, A , CA: A Cancer Journal for Clinicians. 686F. Bray, J. Ferlay, I. Soerjomataram, R. L. Siegel, L. A. Torre, A. Jemal, Global cancer statistics 2018: Globocan estimates of incidence and mor- tality worldwide for 36 cancers in 185 countries, CA: A Cancer Journal for Clinicians 68 (6) (2018) 394-424.

Reducing the dimensionality of data with neural networks. G E Hinton, R R Salakhutdinov, Science. 3135786G. E. Hinton, R. R. Salakhutdinov, Reducing the dimensionality of data with neural networks, Science 313 (5786) (2006) 504-507.

Gradient-based learning applied to document recognition. Y Lecun, L Bottou, Y Bengio, P Haffner, Proceedings of the IEEE. 8611Y. LeCun, L. Bottou, Y. Bengio, P. Haffner, et al., Gradient-based learn- ing applied to document recognition, Proceedings of the IEEE 86 (11) (1998) 2278-2324.

Rich feature hierarchies for accurate object detection and semantic segmentation. R Girshick, J Donahue, T Darrell, J Malik, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionR. Girshick, J. Donahue, T. Darrell, J. Malik, Rich feature hierarchies for accurate object detection and semantic segmentation, in: In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2014, pp. 580-587.

Fast r-cnn. R Girshick, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer VisionR. Girshick, Fast r-cnn, in: In Proceedings of the IEEE International Conference on Computer Vision, 2015, pp. 1440-1448.

Faster r-cnn: Towards real-time object detection with region proposal networks. S Ren, K He, R Girshick, J Sun, Advances in Neural Information Processing Systems. S. Ren, K. He, R. Girshick, J. Sun, Faster r-cnn: Towards real-time ob- ject detection with region proposal networks, in: Advances in Neural Information Processing Systems, 2015, pp. 91-99.

Fully convolutional networks for semantic segmentation. J Long, E Shelhamer, T Darrell, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionJ. Long, E. Shelhamer, T. Darrell, Fully convolutional networks for se- mantic segmentation, in: In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2015, pp. 3431-3440.

U-net: Convolutional networks for biomedical image segmentation. O Ronneberger, P Fischer, T Brox, Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention. the International Conference on Medical Image Computing and Computer-Assisted InterventionO. Ronneberger, P. Fischer, T. Brox, U-net: Convolutional networks for biomedical image segmentation, in: In Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Inter- vention, 2015, pp. 234-241.

A critical review of recurrent neural networks for sequence learning. Z C Lipton, J Berkowitz, C Elkan, ArXiv:1506.00019ArXiv PreprintZ. C. Lipton, J. Berkowitz, C. Elkan, A critical review of recurrent neural networks for sequence learning, ArXiv Preprint ArXiv:1506.00019.

Long short-term memory. S Hochreiter, J Schmidhuber, Neural Computation. 98S. Hochreiter, J. Schmidhuber, Long short-term memory, Neural Com- putation 9 (8) (1997) 1735-1780.

Deep learning applications in medical image analysis. J Ker, L Wang, J Rao, T Lim, IEEE Access. 6J. Ker, L. Wang, J. Rao, T. Lim, Deep learning applications in medical image analysis, IEEE Access 6 (2017) 9375-9389.

Survey on deep learning for radiotherapy. P Meyer, V Noblet, C Mazzara, A Lallement, Computers in Biology and Medicine. 98P. Meyer, V. Noblet, C. Mazzara, A. Lallement, Survey on deep learning for radiotherapy, Computers in Biology and Medicine 98 (2018) 126- 146.

Deep learning with convolutional neural network in radiology. K Yasaka, H Akai, A Kunimatsu, S Kiryu, O Abe, Japanese Journal of Radiology. 364K. Yasaka, H. Akai, A. Kunimatsu, S. Kiryu, O. Abe, Deep learning with convolutional neural network in radiology, Japanese Journal of Ra- diology 36 (4) (2018) 257-272.

Deep learning in medical imaging and radiation therapy. B Sahiner, A Pezeshk, L M Hadjiiski, X Wang, K Drukker, K H Cha, R M Summers, M L Giger, Medical Physics. 461B. Sahiner, A. Pezeshk, L. M. Hadjiiski, X. Wang, K. Drukker, K. H. Cha, R. M. Summers, M. L. Giger, Deep learning in medical imaging and radiation therapy, Medical Physics 46 (1) (2019) e1-e36.

Deep learning for image-based cancer detection and diagnosis-a survey. Z Hu, J Tang, Z Wang, K Zhang, L Zhang, Q Sun, Pattern Recognition. 83Z. Hu, J. Tang, Z. Wang, K. Zhang, L. Zhang, Q. Sun, Deep learning for image-based cancer detection and diagnosis-a survey, Pattern Recogni- tion 83 (2018) 134-149.

Technical and clinical overview of deep learning in radiology. D Ueda, A Shimazaki, Y Miki, Japanese Journal of Radiology. 371D. Ueda, A. Shimazaki, Y. Miki, Technical and clinical overview of deep learning in radiology, Japanese Journal of Radiology 37 (1) (2019) 15- 33.

Applications of deep learning to mri images: A survey. J Liu, Y Pan, M Li, Z Chen, L Tang, C Lu, J Wang, Big Data Mining and Analytics. 11J. Liu, Y. Pan, M. Li, Z. Chen, L. Tang, C. Lu, J. Wang, Applications of deep learning to mri images: A survey, Big Data Mining and Analytics 1 (1) (2018) 1-18.

Deep learning in radiology: An overview of the concepts and a survey of the state of the art with focus on mri. M A Mazurowski, M Buda, A Saha, M R Bashir, Journal of Magnetic Resonance Imaging. 494M. A. Mazurowski, M. Buda, A. Saha, M. R. Bashir, Deep learning in radiology: An overview of the concepts and a survey of the state of the art with focus on mri, Journal of Magnetic Resonance Imaging 49 (4) (2019) 939-954.

Deep learning in medical ultrasound analysis: A review. S Liu, Y Wang, X Yang, B Lei, L Liu, S X Li, D Ni, T Wang, Engineering. 52S. Liu, Y. Wang, X. Yang, B. Lei, L. Liu, S. X. Li, D. Ni, T. Wang, Deep learning in medical ultrasound analysis: A review, Engineering 5 (2) (2019) 261-275.

Quantitative imaging of cancer in the postgenomic era: Radio (geno) mics, deep learning, and habitats. S Napel, W Mu, B V Jardim-Perassi, H J Aerts, R J Gillies, Cancer. 12424S. Napel, W. Mu, B. V. Jardim-Perassi, H. J. Aerts, R. J. Gillies, Quan- titative imaging of cancer in the postgenomic era: Radio (geno) mics, deep learning, and habitats, Cancer 124 (24) (2018) 4633-4649.

C Cao, F Liu, H Tan, D Song, W Shu, W Li, Y Zhou, X Bo, Z Xie, Deep learning and its applications in biomedicine. 16GenomicsC. Cao, F. Liu, H. Tan, D. Song, W. Shu, W. Li, Y. Zhou, X. Bo, Z. Xie, Deep learning and its applications in biomedicine, Genomics, Proteomics & Bioinformatics 16 (1) (2018) 17-32.

Deep learning in medical image analysis. D Shen, G Wu, H.-I Suk, Annual Review of Biomedical Engineering. 19D. Shen, G. Wu, H.-I. Suk, Deep learning in medical image analysis, Annual Review of Biomedical Engineering 19 (2017) 221-248.

Deep learning for medical image processing: Overview, challenges and the future. M I Razzak, S Naz, A Zaib, Classification in BioApps. M. I. Razzak, S. Naz, A. Zaib, Deep learning for medical image process- ing: Overview, challenges and the future, in: Classification in BioApps, 2018, pp. 323-350.

Opportunities and obstacles for deep learning in biology and medicine. T Ching, D S Himmelstein, B K Beaulieu-Jones, A A Kalinin, B T Do, G P Way, E Ferrero, P.-M Agapow, M Zietz, M M Hoffman, Journal of The Royal Society Interface. 15141T. Ching, D. S. Himmelstein, B. K. Beaulieu-Jones, A. A. Kalinin, B. T. Do, G. P. Way, E. Ferrero, P.-M. Agapow, M. Zietz, M. M. Hoff- man, et al., Opportunities and obstacles for deep learning in biology and medicine, Journal of The Royal Society Interface 15 (141) (2018) 20170387.

A survey of deep-learning applications in ultrasound: Artificial intelligence-powered ultrasound for improving clinical workflow. Z Akkus, J Cai, A Boonrod, A Zeinoddini, A D Weston, K A Philbrick, B J Erickson, Journal of the American College of Radiology. 169Z. Akkus, J. Cai, A. Boonrod, A. Zeinoddini, A. D. Weston, K. A. Philbrick, B. J. Erickson, A survey of deep-learning applications in ultra- sound: Artificial intelligence-powered ultrasound for improving clinical workflow, Journal of the American College of Radiology 16 (9) (2019) 1318-1328.

Adversarial attacks on medical machine learning. S G Finlayson, J D Bowers, J Ito, J L Zittrain, A L Beam, I S Kohane, Science. 3636433S. G. Finlayson, J. D. Bowers, J. Ito, J. L. Zittrain, A. L. Beam, I. S. Kohane, Adversarial attacks on medical machine learning, Science 363 (6433) (2019) 1287-1289.

K He, G Gkioxari, P Dollár, R Girshick, Mask r-cnn, in: In Proceedings of the IEEE international conference on computer vision. K. He, G. Gkioxari, P. Dollár, R. Girshick, Mask r-cnn, in: In Proceed- ings of the IEEE international conference on computer vision, 2017, pp. 2961-2969.

Attention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, Ł Kaiser, I Polosukhin, Advances in neural information processing systems. A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, I. Polosukhin, Attention is all you need, in: Advances in neu- ral information processing systems, 2017, pp. 5998-6008.

Efficient multi-scale 3d cnn with fully connected crf for accurate brain lesion segmentation. K Kamnitsas, C Ledig, V F Newcombe, J P Simpson, A D Kane, D K Menon, D Rueckert, B Glocker, Medical Image Analysis. 36K. Kamnitsas, C. Ledig, V. F. Newcombe, J. P. Simpson, A. D. Kane, D. K. Menon, D. Rueckert, B. Glocker, Efficient multi-scale 3d cnn with fully connected crf for accurate brain lesion segmentation, Medical Im- age Analysis 36 (2017) 61-78.

Very deep convolutional networks for large-scale image recognition. K Simonyan, A Zisserman, ArXiv:1409.1556ArXiv PreprintK. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale image recognition, ArXiv Preprint ArXiv:1409.1556.

Deep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionK. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recog- nition, in: In Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 770-778.

C Szegedy, W Liu, Y Jia, P Sermanet, S Reed, D Anguelov, D Erhan, V Vanhoucke, A Rabinovich, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionGoing deeper with convolutionsC. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Er- han, V. Vanhoucke, A. Rabinovich, Going deeper with convolutions, in: In Proceedings of the IEEE conference on computer vision and pattern recognition, 2015, pp. 1-9.

Detection-aided liver lesion segmentation using deep learning. M Bellver, K.-K Maninis, J Pont-Tuset, X Giró-I Nieto, J Torres, L Van Gool, ArXiv:1711.11069ArXiv PreprintM. Bellver, K.-K. Maninis, J. Pont-Tuset, X. Giró-i Nieto, J. Torres, L. Van Gool, Detection-aided liver lesion segmentation using deep learn- ing, ArXiv Preprint ArXiv:1711.11069.

Hough-cnn: deep learning for segmentation of deep brain regions in mri and ultrasound. F Milletari, S.-A Ahmadi, C Kroll, A Plate, V Rozanski, J Maiostre, J Levin, O Dietrich, B Ertl-Wagner, K Bötzel, Computer Vision and Image Understanding. 164F. Milletari, S.-A. Ahmadi, C. Kroll, A. Plate, V. Rozanski, J. Maiostre, J. Levin, O. Dietrich, B. Ertl-Wagner, K. Bötzel, et al., Hough-cnn: deep learning for segmentation of deep brain regions in mri and ultrasound, Computer Vision and Image Understanding 164 (2017) 92-102.

Classification of breast cancer histology images using convolutional neural networks. T Araújo, G Aresta, E Castro, J Rouco, P Aguiar, C Eloy, A Polónia, A Campilho, PloS One. 126177544T. Araújo, G. Aresta, E. Castro, J. Rouco, P. Aguiar, C. Eloy, A. Polónia, A. Campilho, Classification of breast cancer histology images using con- volutional neural networks, PloS One 12 (6) (2017) e0177544.

Accurate and reproducible invasive breast cancer detection in whole-slide images: A deep learning approach for quantifying tumor extent. A Cruz-Roa, H Gilmore, A Basavanhally, M Feldman, S Ganesan, N N Shih, J Tomaszewski, F A González, A Madabhushi, Scientific Reports. 746450A. Cruz-Roa, H. Gilmore, A. Basavanhally, M. Feldman, S. Ganesan, N. N. Shih, J. Tomaszewski, F. A. González, A. Madabhushi, Accurate and reproducible invasive breast cancer detection in whole-slide images: A deep learning approach for quantifying tumor extent, Scientific Re- ports 7 (2017) 46450.

Spatial organization and molecular correlation of tumor-infiltrating lymphocytes using deep learning on pathology images. J Saltz, R Gupta, L Hou, T Kurc, P Singh, V Nguyen, D Samaras, K R Shroyer, T Zhao, R Batiste, Cell Reports. 231J. Saltz, R. Gupta, L. Hou, T. Kurc, P. Singh, V. Nguyen, D. Samaras, K. R. Shroyer, T. Zhao, R. Batiste, et al., Spatial organization and molec- ular correlation of tumor-infiltrating lymphocytes using deep learning on pathology images, Cell Reports 23 (1) (2018) 181-193.

Classification of breast cancer histology using deep learning. A Golatkar, D Anand, A Sethi, Proceedings of the International Conference on Image Analysis and Recognition. the International Conference on Image Analysis and RecognitionA. Golatkar, D. Anand, A. Sethi, Classification of breast cancer histol- ogy using deep learning, in: In Proceedings of the International Confer- ence on Image Analysis and Recognition, 2018, pp. 837-844.

Deep learning models differentiate tumor grades from h&e stained histology sections, in: In Proceedings of the. M Khoshdeli, A Borowsky, B Parvin, IEEE Engineering in Medicine and Biology Society. M. Khoshdeli, A. Borowsky, B. Parvin, Deep learning models differen- tiate tumor grades from h&e stained histology sections, in: In Proceed- ings of the IEEE Engineering in Medicine and Biology Society, 2018, pp. 620-623.

P Khosravi, E Kazemi, M Imielinski, O Elemento, I Hajirasouliha, Deep convolutional neural networks enable discrimination of heterogeneous digital pathology images. 27P. Khosravi, E. Kazemi, M. Imielinski, O. Elemento, I. Hajirasouliha, Deep convolutional neural networks enable discrimination of heteroge- neous digital pathology images, EBioMedicine 27 (2018) 317-328.

Fully automatic brain tumor segmentation using end-to-end incremental deep neural networks in mri images. R Saouli, M Akil, R Kachouri, Computer Methods and Programs in Biomedicine. 166R. Saouli, M. Akil, R. Kachouri, et al., Fully automatic brain tumor segmentation using end-to-end incremental deep neural networks in mri images, Computer Methods and Programs in Biomedicine 166 (2018) 39-49.

Deep learning based radiomics (dlr) and its usage in noninvasive idh1 prediction for low grade glioma. Z Li, Y Wang, J Yu, Y Guo, W Cao, Scientific Reports. 715467Z. Li, Y. Wang, J. Yu, Y. Guo, W. Cao, Deep learning based radiomics (dlr) and its usage in noninvasive idh1 prediction for low grade glioma, Scientific Reports 7 (1) (2017) 5467.

Fully automated detection and segmentation of meningiomas using deep learning on routine multiparametric mri. K R Laukamp, F Thiele, G Shakirin, D Zopfs, A Faymonville, M Timmer, D Maintz, M Perkuhn, J Borggrefe, European Radiology. 291K. R. Laukamp, F. Thiele, G. Shakirin, D. Zopfs, A. Faymonville, M. Timmer, D. Maintz, M. Perkuhn, J. Borggrefe, Fully automated de- tection and segmentation of meningiomas using deep learning on routine multiparametric mri, European Radiology 29 (1) (2019) 124-132.

A deep-learning-based fully automated segmentation approach to delineate tumors in fdg-pet images of patients with lung cancer. K Leung, W Marashdeh, R Wray, S Ashrafinia, A Rahmim, M Pomper, A Jha, Journal of Nuclear Medicine. 59supplement 1)K. Leung, W. Marashdeh, R. Wray, S. Ashrafinia, A. Rahmim, M. Pom- per, A. Jha, A deep-learning-based fully automated segmentation ap- proach to delineate tumors in fdg-pet images of patients with lung can- cer, Journal of Nuclear Medicine 59 (supplement 1) (2018) 323-323.

Deep learning for fully-automated localization and segmentation of rectal cancer on multiparametric mr. S Trebeschi, J J Van Griethuysen, D M Lambregts, M J Lahaye, C Parmar, F C Bakers, N H Peters, R G Beets-Tan, H J Aerts, Scientific Reports. 715301S. Trebeschi, J. J. van Griethuysen, D. M. Lambregts, M. J. Lahaye, C. Parmar, F. C. Bakers, N. H. Peters, R. G. Beets-Tan, H. J. Aerts, Deep learning for fully-automated localization and segmentation of rec- tal cancer on multiparametric mr, Scientific Reports 7 (1) (2017) 5301.

Tumor segmentation in contrast-enhanced magnetic resonance imaging for nasopharyngeal carcinoma: Deep learning with convolutional neural network. Q Li, Y Xu, Z Chen, D Liu, S.-T Feng, M Law, Y Ye, B Huang, BioMed Research. 9128527Q. Li, Y. Xu, Z. Chen, D. Liu, S.-T. Feng, M. Law, Y. Ye, B. Huang, Tumor segmentation in contrast-enhanced magnetic resonance imaging for nasopharyngeal carcinoma: Deep learning with convolutional neural network, BioMed Research International 2018 (2018) 9128527.

A resolution adaptive deep hierarchical (radhical) learning scheme applied to nuclear segmentation of digital pathology images. A Janowczyk, S Doyle, H Gilmore, A Madabhushi, Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization. 63A. Janowczyk, S. Doyle, H. Gilmore, A. Madabhushi, A resolution adaptive deep hierarchical (radhical) learning scheme applied to nuclear segmentation of digital pathology images, Computer Methods in Biome- chanics and Biomedical Engineering: Imaging & Visualization 6 (3) (2018) 270-276.

Deep learning renal segmentation for fully automated radiation dose estimation in unsealed source therapy. P Jackson, N Hardcastle, N Dawe, T Kron, M Hofman, R J Hicks, Frontiers in Oncology. 8215P. Jackson, N. Hardcastle, N. Dawe, T. Kron, M. Hofman, R. J. Hicks, Deep learning renal segmentation for fully automated radiation dose es- timation in unsealed source therapy, Frontiers in Oncology 8 (2018) 215.

Real-time patientspecific lung radiotherapy targeting using deep learning. M D Foote, B Zimmerman, A Sawant, S Joshi, ArXiv:1807.08388ArXiv PreprintM. D. Foote, B. Zimmerman, A. Sawant, S. Joshi, Real-time patient- specific lung radiotherapy targeting using deep learning, ArXiv Preprint ArXiv:1807.08388.

Deep convolutional neural network with transfer learning for rectum toxicity prediction in cervical cancer radiotherapy: a feasibility study. X Zhen, J Chen, Z Zhong, B Hrycushko, L Zhou, S Jiang, K Albuquerque, X Gu, Physics in Medicine & Biology. 62218246X. Zhen, J. Chen, Z. Zhong, B. Hrycushko, L. Zhou, S. Jiang, K. Albu- querque, X. Gu, Deep convolutional neural network with transfer learn- ing for rectum toxicity prediction in cervical cancer radiotherapy: a fea- sibility study, Physics in Medicine & Biology 62 (21) (2017) 8246.

Precision radiology: predicting longevity using feature engineering and deep learning methods in a radiomics framework. L Oakden-Rayner, G Carneiro, T Bessen, J C Nascimento, A P Bradley, L J Palmer, Scientific Reports. 711648L. Oakden-Rayner, G. Carneiro, T. Bessen, J. C. Nascimento, A. P. Bradley, L. J. Palmer, Precision radiology: predicting longevity using feature engineering and deep learning methods in a radiomics frame- work, Scientific Reports 7 (1) (2017) 1648.

Personalized pancreatic tumor growth prediction via group learning. L Zhang, L Lu, R M Summers, E Kebebew, J Yao, Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention. the International Conference on Medical Image Computing and Computer-Assisted InterventionL. Zhang, L. Lu, R. M. Summers, E. Kebebew, J. Yao, Personalized pancreatic tumor growth prediction via group learning, in: In Proceed- ings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, 2017, pp. 424-432.

Deep learning based tissue analysis predicts outcome in colorectal cancer. D Bychkov, N Linder, R Turkki, S Nordling, P E Kovanen, C Verrill, M Walliander, M Lundin, C Haglund, J Lundin, Scientific Reports. 813395D. Bychkov, N. Linder, R. Turkki, S. Nordling, P. E. Kovanen, C. Verrill, M. Walliander, M. Lundin, C. Haglund, J. Lundin, Deep learning based tissue analysis predicts outcome in colorectal cancer, Scientific Reports 8 (1) (2018) 3395.

Deep learning provides a new computed tomography-based prognostic biomarker for recurrence prediction in high-grade serous ovarian cancer. S Wang, Z Liu, Y Rong, B Zhou, Y Bai, W Wei, M Wang, Y Guo, J Tian, Radiotherapy and Oncology. 132S. Wang, Z. Liu, Y. Rong, B. Zhou, Y. Bai, W. Wei, M. Wang, Y. Guo, J. Tian, Deep learning provides a new computed tomography-based prognostic biomarker for recurrence prediction in high-grade serous ovarian cancer, Radiotherapy and Oncology 132 (2019) 171-177.

3d deep learning from ct scans predicts tumor invasiveness of subcentimeter pulmonary adenocarcinomas. W Zhao, J Yang, Y Sun, C Li, W Wu, L Jin, Z Yang, B Ni, P Gao, P Wang, Cancer Research. 7824W. Zhao, J. Yang, Y. Sun, C. Li, W. Wu, L. Jin, Z. Yang, B. Ni, P. Gao, P. Wang, et al., 3d deep learning from ct scans predicts tumor invasive- ness of subcentimeter pulmonary adenocarcinomas, Cancer Research 78 (24) (2018) 6881-6889.

Epithelium segmentation using deep learning in h&e-stained prostate specimens with immunohistochemistry as reference standard. W Bulten, P Bándi, J Hoven, R Van De Loo, J Lotz, N Weiss, J Van Der Laak, B Van Ginneken, C Hulsbergen-Van De Kaa, G Litjens, Scientific Reports. 91864W. Bulten, P. Bándi, J. Hoven, R. van de Loo, J. Lotz, N. Weiss, J. van der Laak, B. van Ginneken, C. Hulsbergen-van de Kaa, G. Litjens, Epithelium segmentation using deep learning in h&e-stained prostate specimens with immunohistochemistry as reference standard, Scientific Reports 9 (1) (2019) 864.

Clinical evaluation of a multiparametric deep learning model for glioblastoma segmentation using heterogeneous magnetic resonance imaging data from clinical routine. M Perkuhn, P Stavrinou, F Thiele, G Shakirin, M Mohan, D Garmpis, C Kabbasch, J Borggrefe, Investigative Radiology. 5311M. Perkuhn, P. Stavrinou, F. Thiele, G. Shakirin, M. Mohan, D. Garmpis, C. Kabbasch, J. Borggrefe, Clinical evaluation of a mul- tiparametric deep learning model for glioblastoma segmentation using heterogeneous magnetic resonance imaging data from clinical routine, Investigative Radiology 53 (11) (2018) 647-654.

Brain tumor segmentation and tractographic feature extraction from structural mr images for overall survival prediction. P.-Y Kao, T Ngo, A Zhang, J W Chen, B Manjunath, Proceedings of the International Conference on Medical Image Computing and Computer Assisted Intervention Brainlesion Workshop. the International Conference on Medical Image Computing and Computer Assisted Intervention Brainlesion WorkshopP.-Y. Kao, T. Ngo, A. Zhang, J. W. Chen, B. Manjunath, Brain tumor segmentation and tractographic feature extraction from structural mr im- ages for overall survival prediction, in: In Proceedings of the Interna- tional Conference on Medical Image Computing and Computer Assisted Intervention Brainlesion Workshop, 2018, pp. 128-141.

Ensembles of multiple models and architectures for robust brain tumour segmentation. K Kamnitsas, W Bai, E Ferrante, S Mcdonagh, M Sinclair, N Pawlowski, M Rajchl, M Lee, B Kainz, D Rueckert, Proceedings of the International Conference on Medical Image Computing and Computer Assisted Intervention Brainlesion Workshop. the International Conference on Medical Image Computing and Computer Assisted Intervention Brainlesion WorkshopK. Kamnitsas, W. Bai, E. Ferrante, S. McDonagh, M. Sinclair, N. Pawlowski, M. Rajchl, M. Lee, B. Kainz, D. Rueckert, et al., Ensem- bles of multiple models and architectures for robust brain tumour seg- mentation, in: In Proceedings of the International Conference on Med- ical Image Computing and Computer Assisted Intervention Brainlesion Workshop, 2017, pp. 450-462.

Volumetric multimodality neural network for brain tumor segmentation. L S Castillo, L A Daza, L C Rivera, P Arbeláez, Proceedings of the International Conference on Medical Information Processing and Analysis. the International Conference on Medical Information Processing and Analysis10572105720L. S. Castillo, L. A. Daza, L. C. Rivera, P. Arbeláez, Volumetric multi- modality neural network for brain tumor segmentation, in: In Proceed- ings of the International Conference on Medical Information Processing and Analysis, Vol. 10572, 2017, p. 105720E.

Segmentation of organs at risk in thoracic ct images using a sharpmask architecture and conditional random fields. R Trullo, C Petitjean, S Ruan, B Dubray, D Nie, D Shen, Proceedings of the IEEE International Symposium on Biomedical Imaging. the IEEE International Symposium on Biomedical ImagingR. Trullo, C. Petitjean, S. Ruan, B. Dubray, D. Nie, D. Shen, Segmenta- tion of organs at risk in thoracic ct images using a sharpmask architecture and conditional random fields, in: In Proceedings of the IEEE Interna- tional Symposium on Biomedical Imaging, 2017, pp. 1003-1006.

Boundary-aware fully convolutional network for brain tumor segmentation. H Shen, R Wang, J Zhang, S J Mckenna, Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention. the International Conference on Medical Image Computing and Computer-Assisted InterventionH. Shen, R. Wang, J. Zhang, S. J. McKenna, Boundary-aware fully convolutional network for brain tumor segmentation, in: In Proceed- ings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, 2017, pp. 433-441.

A deep learning model integrating fcnns and crfs for brain tumor segmentation. X Zhao, Y Wu, G Song, Z Li, Y Zhang, Y Fan, Medical Image Analysis. 43X. Zhao, Y. Wu, G. Song, Z. Li, Y. Zhang, Y. Fan, A deep learning model integrating fcnns and crfs for brain tumor segmentation, Medical Image Analysis 43 (2018) 98-111.

Automatic liver and tumor segmentation of ct and mri volumes using cascaded fully convolutional neural networks. P F Christ, F Ettlinger, F Grün, M E A Elshaera, J Lipkova, S Schlecht, F Ahmaddy, S Tatavarty, M Bickel, P Bilic, ArXiv:1702.05970ArXiv PreprintP. F. Christ, F. Ettlinger, F. Grün, M. E. A. Elshaera, J. Lipkova, S. Schlecht, F. Ahmaddy, S. Tatavarty, M. Bickel, P. Bilic, et al., Automatic liver and tumor segmentation of ct and mri volumes us- ing cascaded fully convolutional neural networks, ArXiv Preprint ArXiv:1702.05970.

Automatic segmentation of colorectal cancer in 3d mri by combining deep learning and 3d level-set algorithm-a preliminary study. M H Soomro, G De Cola, S Conforto, M Schmid, G Giunta, E Guidi, E Neri, D Caruso, M Ciolina, A Laghi, Proceedings of the IEEE Middle East Conference. the IEEE Middle East ConferenceM. H. Soomro, G. De Cola, S. Conforto, M. Schmid, G. Giunta, E. Guidi, E. Neri, D. Caruso, M. Ciolina, A. Laghi, Automatic seg- mentation of colorectal cancer in 3d mri by combining deep learning and 3d level-set algorithm-a preliminary study, in: In Proceedings of the IEEE Middle East Conference on Biomedical Engineering, 2018, pp. 198-203.

Learning normalized inputs for iterative estimation in medical image segmentation. M Drozdzal, G Chartrand, E Vorontsov, M Shakeri, L Di Jorio, A Tang, A Romero, Y Bengio, C Pal, S Kadoury, Medical Image Analysis. 44M. Drozdzal, G. Chartrand, E. Vorontsov, M. Shakeri, L. Di Jorio, A. Tang, A. Romero, Y. Bengio, C. Pal, S. Kadoury, Learning normal- ized inputs for iterative estimation in medical image segmentation, Med- ical Image Analysis 44 (2018) 1-13.

U-net: deep learning for cell counting, detection, and morphometry. T Falk, D Mai, R Bensch, Ö Içek, A Abdulkadir, Y Marrakchi, A Böhm, J Deubner, Z Jäckel, K Seiwald, Nature Methods. 16167T. Falk, D. Mai, R. Bensch,Ö. Ç içek, A. Abdulkadir, Y. Marrakchi, A. Böhm, J. Deubner, Z. Jäckel, K. Seiwald, et al., U-net: deep learning for cell counting, detection, and morphometry, Nature Methods 16 (1) (2019) 67.

A Beers, K Chang, J Brown, E Sartor, C Mammen, E Gerstner, B Rosen, J Kalpathy-Cramer, ArXiv:1709.02967Sequential 3d u-nets for biologicallyinformed brain tumor segmentation. ArXiv PreprintA. Beers, K. Chang, J. Brown, E. Sartor, C. Mammen, E. Gerstner, B. Rosen, J. Kalpathy-Cramer, Sequential 3d u-nets for biologically- informed brain tumor segmentation, ArXiv Preprint ArXiv:1709.02967.

F Isensee, P Kickingereder, W Wick, M Bendszus, K H Maier-Hein, Proceedings of the International Conference on Medical Image Computing and Computer Assisted Intervention Brainlesion Workshop. the International Conference on Medical Image Computing and Computer Assisted Intervention Brainlesion WorkshopBrain tumor segmentation and radiomics survival prediction: Contribution to the brats 2017 challengeF. Isensee, P. Kickingereder, W. Wick, M. Bendszus, K. H. Maier-Hein, Brain tumor segmentation and radiomics survival prediction: Contribu- tion to the brats 2017 challenge, in: In Proceedings of the International Conference on Medical Image Computing and Computer Assisted Inter- vention Brainlesion Workshop, 2017, pp. 287-297.

Deep logismos: Deep learning graph-based 3d segmentation of pancreatic tumors on ct scans. Z Guo, L Zhang, L Lu, M Bagheri, R M Summers, M Sonka, J Yao, Proceedings of the IEEE International Symposium on Biomedical Imaging. the IEEE International Symposium on Biomedical ImagingZ. Guo, L. Zhang, L. Lu, M. Bagheri, R. M. Summers, M. Sonka, J. Yao, Deep logismos: Deep learning graph-based 3d segmentation of pancre- atic tumors on ct scans, in: In Proceedings of the IEEE International Symposium on Biomedical Imaging, 2018, pp. 1230-1233.

3d fully convolutional networks for co-segmentation of tumors on pet-ct images. Z Zhong, Y Kim, L Zhou, K Plichta, B Allen, J Buatti, X Wu, Proceedings of the IEEE International Symposium on Biomedical Imaging. the IEEE International Symposium on Biomedical ImagingZ. Zhong, Y. Kim, L. Zhou, K. Plichta, B. Allen, J. Buatti, X. Wu, 3d fully convolutional networks for co-segmentation of tumors on pet-ct images, in: In Proceedings of the IEEE International Symposium on Biomedical Imaging, 2018, pp. 228-231.

D Nguyen, T Long, X Jia, W Lu, X Gu, Z Iqbal, S Jiang, ArXiv:1709.09233Dose prediction with u-net: a feasibility study for predicting dose distributions from contours using deep learning on prostate imrt patients. ArXiv PreprintD. Nguyen, T. Long, X. Jia, W. Lu, X. Gu, Z. Iqbal, S. Jiang, Dose prediction with u-net: a feasibility study for predicting dose distribu- tions from contours using deep learning on prostate imrt patients, ArXiv Preprint ArXiv:1709.09233.

Threedimensional radiotherapy dose prediction on head and neck cancer patients with a hierarchically densely connected u-net deep learning architecture. D Nguyen, X Jia, D Sher, M.-H Lin, Z Iqbal, H Liu, S Jiang, ArXiv:1805.10397ArXiv PreprintD. Nguyen, X. Jia, D. Sher, M.-H. Lin, Z. Iqbal, H. Liu, S. Jiang, Three- dimensional radiotherapy dose prediction on head and neck cancer pa- tients with a hierarchically densely connected u-net deep learning archi- tecture, ArXiv Preprint ArXiv:1805.10397.

A feasibility study for predicting optimal radiation therapy dose distributions of prostate cancer patients from patient anatomy using deep learning. D Nguyen, T Long, X Jia, W Lu, X Gu, Z Iqbal, S Jiang, Scientific Reports. 911076D. Nguyen, T. Long, X. Jia, W. Lu, X. Gu, Z. Iqbal, S. Jiang, A fea- sibility study for predicting optimal radiation therapy dose distributions of prostate cancer patients from patient anatomy using deep learning, Scientific Reports 9 (1) (2019) 1076.

3d radiotherapy dose prediction on head and neck cancer patients with a hierarchically densely connected u-net deep learning architecture. D Nguyen, X Jia, D Sher, M.-H Lin, Z Iqbal, H Liu, S Jiang, Physics in Medicine & Biology. 64665020D. Nguyen, X. Jia, D. Sher, M.-H. Lin, Z. Iqbal, H. Liu, S. Jiang, 3d radiotherapy dose prediction on head and neck cancer patients with a hi- erarchically densely connected u-net deep learning architecture, Physics in Medicine & Biology 64 (6) (2019) 065020.

A tutorial on support vector machines for pattern recognition. C J Burges, Data Mining and Knowledge Discovery. 22C. J. Burges, A tutorial on support vector machines for pattern recogni- tion, Data Mining and Knowledge Discovery 2 (2) (1998) 121-167.

An improved deep learning approach for detection of thyroid papillary cancer in ultrasound images. H Li, J Weng, Y Shi, W Gu, Y Mao, Y Wang, W Liu, J Zhang, Scientific Reports. 86600H. Li, J. Weng, Y. Shi, W. Gu, Y. Mao, Y. Wang, W. Liu, J. Zhang, An improved deep learning approach for detection of thyroid papillary cancer in ultrasound images, Scientific Reports 8 (2018) 6600.

Mitos-rcnn: A novel approach to mitotic figure detection in breast cancer histopathology images using region based convolutional neural networks. S Rao, ArXiv:1807.01788ArXiv PreprintS. Rao, Mitos-rcnn: A novel approach to mitotic figure detection in breast cancer histopathology images using region based convolutional neural networks, ArXiv Preprint ArXiv:1807.01788.

Efficient mitosis detection in breast cancer histology images by rcnn. D Cai, X Sun, N Zhou, X Han, J Yao, Proceedings of the IEEE International Symposium on Biomedical Imaging. the IEEE International Symposium on Biomedical ImagingD. Cai, X. Sun, N. Zhou, X. Han, J. Yao, Efficient mitosis detection in breast cancer histology images by rcnn, in: In Proceedings of the IEEE International Symposium on Biomedical Imaging, 2019, pp. 919-922.

A cnn based method for automatic mass detection and classification in mammograms. A Akselrod-Ballin, L Karlinsky, S Alpert, S Hashoul, R Ben-Ari, E Barkan, Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization. 73A. Akselrod-Ballin, L. Karlinsky, S. Alpert, S. Hashoul, R. Ben-Ari, E. Barkan, A cnn based method for automatic mass detection and clas- sification in mammograms, Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization 7 (3) (2019) 242- 249.

Detecting and classifying lesions in mammograms with deep learning. D Ribli, A Horváth, Z Unger, P Pollner, I Csabai, Scientific Reports. 814165D. Ribli, A. Horváth, Z. Unger, P. Pollner, I. Csabai, Detecting and clas- sifying lesions in mammograms with deep learning, Scientific Reports 8 (1) (2018) 4165.

You only look once: Unified, real-time object detection. J Redmon, S Divvala, R Girshick, A Farhadi, Proceedings of the IEEE. the IEEEJ. Redmon, S. Divvala, R. Girshick, A. Farhadi, You only look once: Unified, real-time object detection, in: In Proceedings of the IEEE con- ference on computer vision and pattern recognition, 2016, pp. 779-788.

J Redmon, A Farhadi, Yolo9000: better, faster, stronger, in: In Proceedings of the IEEE conference on computer vision and pattern recognition. J. Redmon, A. Farhadi, Yolo9000: better, faster, stronger, in: In Proceed- ings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 7263-7271.

J Redmon, A Farhadi, ArXiv:1804.02767Yolov3: An incremental improvement. ArXiv PreprintJ. Redmon, A. Farhadi, Yolov3: An incremental improvement, ArXiv Preprint ArXiv:1804.02767.

Y Wu, Z Cheng, Z Xu, W Wang, ArXiv:1904.13300Segmentation is all you need. ArXiv PreprintY. Wu, Z. Cheng, Z. Xu, W. Wang, Segmentation is all you need, ArXiv Preprint ArXiv:1904.13300.

Blood cell images segmentation using deep learning semantic segmentation. T Tran, O.-H Kwon, K.-R Kwon, S.-H Lee, K.-W Kang, Proceedings of the IEEE International Conference on Electronics and Communication Engineering. the IEEE International Conference on Electronics and Communication EngineeringT. Tran, O.-H. Kwon, K.-R. Kwon, S.-H. Lee, K.-W. Kang, Blood cell images segmentation using deep learning semantic segmentation, in: In Proceedings of the IEEE International Conference on Electronics and Communication Engineering, 2018, pp. 13-16.

M Doan, I Vorobjev, P Rees, A Filby, O Wolkenhauer, A E Goldfeld, J Lieberman, N Barteneva, A E Carpenter, H Hennig, Diagnostic potential of imaging flow cytometry. 36M. Doan, I. Vorobjev, P. Rees, A. Filby, O. Wolkenhauer, A. E. Gold- feld, J. Lieberman, N. Barteneva, A. E. Carpenter, H. Hennig, Diagnos- tic potential of imaging flow cytometry, Trends in Biotechnology 36 (7) (2018) 649-652.

Cancer drug response profile scan (cdrscan): a deep learning model that predicts drug effectiveness from cancer genomic signature. Y Chang, H Park, H.-J Yang, S Lee, K.-Y Lee, T S Kim, J Jung, J.-M Shin, Scientific Reports. 818857Y. Chang, H. Park, H.-J. Yang, S. Lee, K.-Y. Lee, T. S. Kim, J. Jung, J.-M. Shin, Cancer drug response profile scan (cdrscan): a deep learning model that predicts drug effectiveness from cancer genomic signature, Scientific Reports 8 (1) (2018) 8857.

A deep learning-based multi-model ensemble method for cancer prediction. Y Xiao, J Wu, Z Lin, X Zhao, Computer Methods and Programs in Biomedicine. 153Y. Xiao, J. Wu, Z. Lin, X. Zhao, A deep learning-based multi-model en- semble method for cancer prediction, Computer Methods and Programs in Biomedicine 153 (2018) 1-9.

Segnet: A deep convolutional encoder-decoder architecture for image segmentation, IEEE transactions on pattern analysis and machine intelligence. V Badrinarayanan, A Kendall, R Cipolla, 39V. Badrinarayanan, A. Kendall, R. Cipolla, Segnet: A deep convolu- tional encoder-decoder architecture for image segmentation, IEEE trans- actions on pattern analysis and machine intelligence 39 (12) (2017) 2481-2495.

End-to-end lung cancer screening with three-dimensional deep learning on low-dose chest computed tomography. D Ardila, A P Kiraly, S Bharadwaj, B Choi, J J Reicher, L Peng, D Tse, M Etemadi, W Ye, G Corrado, Nature Medicine. 256954D. Ardila, A. P. Kiraly, S. Bharadwaj, B. Choi, J. J. Reicher, L. Peng, D. Tse, M. Etemadi, W. Ye, G. Corrado, et al., End-to-end lung can- cer screening with three-dimensional deep learning on low-dose chest computed tomography, Nature Medicine 25 (6) (2019) 954.

A region based convolutional network for tumor detection and classification in breast mammography. A Akselrod-Ballin, L Karlinsky, S Alpert, S Hasoul, R Ben-Ari, E Barkan, Deep Learning and Data Labeling for Medical Applications. A. Akselrod-Ballin, L. Karlinsky, S. Alpert, S. Hasoul, R. Ben-Ari, E. Barkan, A region based convolutional network for tumor detection and classification in breast mammography, in: Deep Learning and Data Labeling for Medical Applications, 2016, pp. 197-205.

The importance of skip connections in biomedical image segmentation. M Drozdzal, E Vorontsov, G Chartrand, S Kadoury, C , Deep Learning and Data Labeling for Medical Applications. M. Drozdzal, E. Vorontsov, G. Chartrand, S. Kadoury, C. Pal, The importance of skip connections in biomedical image segmentation, in: Deep Learning and Data Labeling for Medical Applications, 2016, pp. 179-187.

Random forests. L Breiman, Machine Learning. 451L. Breiman, Random forests, Machine Learning 45 (1) (2001) 5-32.

Maldi-imaging for classification of epithelial ovarian cancer histotypes from a tissue microarray using machine learning methods. O Klein, F Kanter, H Kulbe, P Jank, C Denkert, G Nebrich, W D Schmitt, Z Wu, C A Kunze, J Sehouli, Proteomics Clinical Applications. 1311700181O. Klein, F. Kanter, H. Kulbe, P. Jank, C. Denkert, G. Nebrich, W. D. Schmitt, Z. Wu, C. A. Kunze, J. Sehouli, et al., Maldi-imaging for clas- sification of epithelial ovarian cancer histotypes from a tissue microar- ray using machine learning methods, Proteomics Clinical Applications 13 (1) (2019) 1700181.

Classification and mutation prediction from non-small cell lung cancer histopathology images using deep learning. N Coudray, P S Ocampo, T Sakellaropoulos, N Narula, M Snuderl, D Fenyö, A L Moreira, N Razavian, A Tsirigos, Nature Medicine. 24101559N. Coudray, P. S. Ocampo, T. Sakellaropoulos, N. Narula, M. Snuderl, D. Fenyö, A. L. Moreira, N. Razavian, A. Tsirigos, Classification and mutation prediction from non-small cell lung cancer histopathology im- ages using deep learning, Nature Medicine 24 (10) (2018) 1559.

H&e-stained whole slide image deep learning predicts spop mutation state in prostate cancer. A J Schaumberg, M A Rubin, T J Fuchs, BioRxiv. 64279A. J. Schaumberg, M. A. Rubin, T. J. Fuchs, H&e-stained whole slide image deep learning predicts spop mutation state in prostate cancer, BioRxiv (2018) 064279.

Rethinking the inception architecture for computer vision. C Szegedy, V Vanhoucke, S Ioffe, J Shlens, Z Wojna, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionC. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, Z. Wojna, Rethinking the inception architecture for computer vision, in: In Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 2818-2826.

Deep learning-based multi-omics integration robustly predicts survival in liver cancer. K Chaudhary, O B Poirion, L Lu, L X Garmire, Clinical Cancer Research. 246K. Chaudhary, O. B. Poirion, L. Lu, L. X. Garmire, Deep learning-based multi-omics integration robustly predicts survival in liver cancer, Clini- cal Cancer Research 24 (6) (2018) 1248-1259.

Algorithm as 136: A k-means clustering algorithm. J A Hartigan, M A Wong, Journal of the Royal Statistical Society. Series C (Applied Statistics). 281J. A. Hartigan, M. A. Wong, Algorithm as 136: A k-means clustering algorithm, Journal of the Royal Statistical Society. Series C (Applied Statistics) 28 (1) (1979) 100-108.

J Devlin, M.-W Chang, K Lee, K Toutanova, Bert , ArXiv:1810.04805Pre-training of deep bidirectional transformers for language understanding. ArXiv PreprintJ. Devlin, M.-W. Chang, K. Lee, K. Toutanova, Bert: Pre-training of deep bidirectional transformers for language understanding, ArXiv Preprint ArXiv:1810.04805.

Transformer-xl: Attentive language models beyond a fixed-length context. Z Dai, Z Yang, Y Yang, W W Cohen, J Carbonell, Q V Le, R Salakhutdinov, ArXiv:1901.02860ArXiv PreprintZ. Dai, Z. Yang, Y. Yang, W. W. Cohen, J. Carbonell, Q. V. Le, R. Salakhutdinov, Transformer-xl: Attentive language models beyond a fixed-length context, ArXiv Preprint ArXiv:1901.02860.

Z Yang, Z Dai, Y Yang, J Carbonell, R Salakhutdinov, Q V Le, ArXiv:1906.08237Xlnet: Generalized autoregressive pretraining for language understanding. ArXiv PreprintZ. Yang, Z. Dai, Y. Yang, J. Carbonell, R. Salakhutdinov, Q. V. Le, Xl- net: Generalized autoregressive pretraining for language understanding, ArXiv Preprint ArXiv:1906.08237.

Generating long sequences. R Child, S Gray, A Radford, I Sutskever, R. Child, S. Gray, A. Radford, I. Sutskever, Generating long sequences